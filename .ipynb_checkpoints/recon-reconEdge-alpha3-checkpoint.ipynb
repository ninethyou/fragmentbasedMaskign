{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cbc95c-8c82-4b39-9acb-eac3d7dea845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'target': ['measured log solubility in mols per litre']}}\n",
      "Running on: cuda:1\n",
      "1127\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1127\n",
      "Generating scaffold 1000/1127\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 14.863460540771484\n",
      "Validation loss: 3.4459083396776586 RMSE: 1.8563157\n",
      "1 21 3.709362268447876\n",
      "Validation loss: 2.8304291910829797 RMSE: 1.682388\n",
      "Validation loss: 2.2538987651335454 RMSE: 1.501299\n",
      "3 13 2.933183193206787\n",
      "Validation loss: 3.8206697333175526 RMSE: 1.9546534\n",
      "Validation loss: 2.1873753155227256 RMSE: 1.4789779\n",
      "5 5 2.563375949859619\n",
      "Validation loss: 2.6249442944484476 RMSE: 1.6201681\n",
      "6 26 2.4324381351470947\n",
      "Validation loss: 2.6513028376925307 RMSE: 1.6282822\n",
      "Validation loss: 2.318828821182251 RMSE: 1.5227702\n",
      "8 18 2.985759735107422\n",
      "Validation loss: 1.5912356482142895 RMSE: 1.2614418\n",
      "Validation loss: 2.0520963679372737 RMSE: 1.432514\n",
      "10 10 2.1145591735839844\n",
      "Validation loss: 2.3604624165897876 RMSE: 1.5363796\n",
      "Validation loss: 3.0208651502575496 RMSE: 1.7380637\n",
      "12 2 1.5882309675216675\n",
      "Validation loss: 3.438126082968923 RMSE: 1.8542184\n",
      "13 23 1.402376651763916\n",
      "Validation loss: 2.2963607501139682 RMSE: 1.5153748\n",
      "Validation loss: 3.0735800603849697 RMSE: 1.7531629\n",
      "15 15 1.2734227180480957\n",
      "Validation loss: 1.7760159251964198 RMSE: 1.3326724\n",
      "Validation loss: 2.057976421001738 RMSE: 1.434565\n",
      "17 7 2.022213935852051\n",
      "Validation loss: 1.835582322778955 RMSE: 1.3548367\n",
      "18 28 1.5293021202087402\n",
      "Validation loss: 1.9917441606521606 RMSE: 1.4112917\n",
      "Validation loss: 1.8104013320619026 RMSE: 1.3455116\n",
      "20 20 2.24688458442688\n",
      "Validation loss: 2.164848177833895 RMSE: 1.4713423\n",
      "Validation loss: 1.4616228479199704 RMSE: 1.2089759\n",
      "22 12 1.4398468732833862\n",
      "Validation loss: 1.3644631668529679 RMSE: 1.1681024\n",
      "Validation loss: 1.928826732973082 RMSE: 1.3888221\n",
      "24 4 1.5874607563018799\n",
      "Validation loss: 2.2318584191060697 RMSE: 1.4939406\n",
      "25 25 1.1963772773742676\n",
      "Validation loss: 1.5652120324362695 RMSE: 1.2510843\n",
      "Validation loss: 2.0007160068613237 RMSE: 1.4144666\n",
      "27 17 1.1596763134002686\n",
      "Validation loss: 1.9714259299556767 RMSE: 1.4040747\n",
      "Validation loss: 1.919763309765706 RMSE: 1.3855551\n",
      "29 9 1.3175048828125\n",
      "Validation loss: 1.4618901130372444 RMSE: 1.2090865\n",
      "Validation loss: 2.703170978917485 RMSE: 1.6441324\n",
      "31 1 1.3436610698699951\n",
      "Validation loss: 1.5478687286376953 RMSE: 1.2441338\n",
      "32 22 1.1270190477371216\n",
      "Validation loss: 1.594048348148312 RMSE: 1.2625563\n",
      "Validation loss: 1.978385522302273 RMSE: 1.406551\n",
      "34 14 1.4662790298461914\n",
      "Validation loss: 1.5160376266040634 RMSE: 1.2312748\n",
      "Validation loss: 1.7444742327242826 RMSE: 1.3207855\n",
      "36 6 0.8209110498428345\n",
      "Validation loss: 1.3845846874524006 RMSE: 1.1766838\n",
      "37 27 1.5264866352081299\n",
      "Validation loss: 2.084522149204153 RMSE: 1.4437875\n",
      "Validation loss: 2.180260238394273 RMSE: 1.4765706\n",
      "39 19 1.095117449760437\n",
      "Validation loss: 2.0267406248413358 RMSE: 1.4236364\n",
      "Validation loss: 1.465744155698118 RMSE: 1.2106792\n",
      "41 11 1.2835543155670166\n",
      "Validation loss: 1.7665616200033543 RMSE: 1.3291206\n",
      "Validation loss: 1.9771599115523617 RMSE: 1.4061152\n",
      "43 3 0.9479626417160034\n",
      "Validation loss: 1.7079674300894272 RMSE: 1.3068923\n",
      "44 24 1.2832682132720947\n",
      "Validation loss: 1.5673941637562439 RMSE: 1.2519561\n",
      "Validation loss: 2.5518377249219775 RMSE: 1.5974473\n",
      "46 16 0.7731629610061646\n",
      "Validation loss: 1.7392005994256619 RMSE: 1.3187877\n",
      "Validation loss: 1.7220156651682559 RMSE: 1.3122559\n",
      "48 8 0.8285907506942749\n",
      "Validation loss: 1.838078557917502 RMSE: 1.3557577\n",
      "Validation loss: 1.9756459208716333 RMSE: 1.4055767\n",
      "50 0 0.7336530685424805\n",
      "Validation loss: 1.7761127484583221 RMSE: 1.3327088\n",
      "51 21 0.7763540744781494\n",
      "Validation loss: 1.8533330659950729 RMSE: 1.3613718\n",
      "Validation loss: 1.8076733741085087 RMSE: 1.3444974\n",
      "53 13 0.7876553535461426\n",
      "Validation loss: 1.6386666477254006 RMSE: 1.2801042\n",
      "Validation loss: 2.093366312769662 RMSE: 1.446847\n",
      "55 5 1.1409602165222168\n",
      "Validation loss: 2.009925551119104 RMSE: 1.4177184\n",
      "56 26 1.6236435174942017\n",
      "Validation loss: 1.4688271146959964 RMSE: 1.2119517\n",
      "Validation loss: 1.9259304135246615 RMSE: 1.387779\n",
      "58 18 1.1680374145507812\n",
      "Validation loss: 1.6500739017419055 RMSE: 1.284552\n",
      "Validation loss: 1.5205318569082074 RMSE: 1.2330985\n",
      "60 10 1.1574554443359375\n",
      "Validation loss: 1.8998403950075133 RMSE: 1.3783469\n",
      "Validation loss: 1.807571203307768 RMSE: 1.3444594\n",
      "62 2 0.6249538064002991\n",
      "Validation loss: 1.4277914926014115 RMSE: 1.1949023\n",
      "63 23 0.6563063263893127\n",
      "Validation loss: 1.6702064581676923 RMSE: 1.2923647\n",
      "Validation loss: 1.527775127275855 RMSE: 1.2360319\n",
      "65 15 0.5517813563346863\n",
      "Validation loss: 1.358008065054902 RMSE: 1.165336\n",
      "Validation loss: 1.4323205462599222 RMSE: 1.196796\n",
      "67 7 0.7572497725486755\n",
      "Validation loss: 1.4691140598955408 RMSE: 1.2120701\n",
      "68 28 3.754383087158203\n",
      "Validation loss: 1.739507295389091 RMSE: 1.3189038\n",
      "Validation loss: 1.8643204079265088 RMSE: 1.3654011\n",
      "70 20 1.0658714771270752\n",
      "Validation loss: 1.7678169085916164 RMSE: 1.3295928\n",
      "Validation loss: 1.887912449583543 RMSE: 1.3740132\n",
      "72 12 1.083752989768982\n",
      "Validation loss: 1.5955787844362512 RMSE: 1.2631621\n",
      "Validation loss: 1.924590851353333 RMSE: 1.3872962\n",
      "74 4 0.8180006742477417\n",
      "Validation loss: 1.9020713799822646 RMSE: 1.379156\n",
      "75 25 0.5241159200668335\n",
      "Validation loss: 1.785947234229704 RMSE: 1.3363934\n",
      "Validation loss: 1.501044452717874 RMSE: 1.2251712\n",
      "77 17 0.9477435350418091\n",
      "Validation loss: 1.5418535238873643 RMSE: 1.241714\n",
      "Validation loss: 1.3805583272360067 RMSE: 1.1749717\n",
      "79 9 0.846612811088562\n",
      "Validation loss: 1.8726156190433334 RMSE: 1.3684355\n",
      "Validation loss: 1.5685678625528792 RMSE: 1.2524248\n",
      "81 1 0.8948572278022766\n",
      "Validation loss: 1.9844249022745453 RMSE: 1.4086962\n",
      "82 22 0.6844273805618286\n",
      "Validation loss: 1.3585519126031251 RMSE: 1.1655693\n",
      "Validation loss: 1.4762986402595992 RMSE: 1.2150304\n",
      "84 14 0.8447586894035339\n",
      "Validation loss: 1.929073679763659 RMSE: 1.388911\n",
      "Validation loss: 1.6855716114550565 RMSE: 1.2982957\n",
      "86 6 0.8470931649208069\n",
      "Validation loss: 1.4554961244616889 RMSE: 1.2064395\n",
      "87 27 1.051446795463562\n",
      "Validation loss: 1.5611270149197198 RMSE: 1.2494507\n",
      "Validation loss: 1.7539458411984739 RMSE: 1.3243662\n",
      "89 19 0.5292825698852539\n",
      "Validation loss: 1.418227737983771 RMSE: 1.1908937\n",
      "Validation loss: 2.7138806317759827 RMSE: 1.6473861\n",
      "91 11 0.6511044502258301\n",
      "Validation loss: 1.2614888364234857 RMSE: 1.1231601\n",
      "Validation loss: 1.783184698197694 RMSE: 1.3353595\n",
      "93 3 0.44461917877197266\n",
      "Validation loss: 1.6313472522043548 RMSE: 1.2772421\n",
      "94 24 0.4888155460357666\n",
      "Validation loss: 1.611454147153196 RMSE: 1.2694306\n",
      "Validation loss: 1.4635978388575326 RMSE: 1.2097925\n",
      "96 16 0.3872493505477905\n",
      "Validation loss: 1.799969050736554 RMSE: 1.3416291\n",
      "Validation loss: 1.7785925316599618 RMSE: 1.3336389\n",
      "98 8 0.7060498595237732\n",
      "Validation loss: 1.6804536549390945 RMSE: 1.2963232\n",
      "Validation loss: 1.5268217989828734 RMSE: 1.2356462\n",
      "100 0 0.6217173933982849\n",
      "Validation loss: 1.5631058653899 RMSE: 1.2502422\n",
      "101 21 0.47925257682800293\n",
      "Validation loss: 1.5230066681330183 RMSE: 1.2341017\n",
      "Validation loss: 1.3445423809827957 RMSE: 1.159544\n",
      "103 13 0.447076678276062\n",
      "Validation loss: 1.7533408498342058 RMSE: 1.3241377\n",
      "Validation loss: 1.4691649453829876 RMSE: 1.2120912\n",
      "105 5 1.0895130634307861\n",
      "Validation loss: 1.6318657894050126 RMSE: 1.277445\n",
      "106 26 0.5130261182785034\n",
      "Validation loss: 1.3405230319605463 RMSE: 1.1578096\n",
      "Validation loss: 1.592643200823691 RMSE: 1.2619996\n",
      "108 18 0.4180719256401062\n",
      "Validation loss: 1.595821681275832 RMSE: 1.2632585\n",
      "Validation loss: 1.473256606971268 RMSE: 1.2137778\n",
      "110 10 1.190427303314209\n",
      "Validation loss: 1.5885463087959628 RMSE: 1.2603754\n",
      "Validation loss: 1.5129268327645495 RMSE: 1.230011\n",
      "112 2 0.837885320186615\n",
      "Validation loss: 1.563364185063185 RMSE: 1.2503457\n",
      "113 23 0.6779939532279968\n",
      "Validation loss: 1.3449937632653566 RMSE: 1.1597387\n",
      "Validation loss: 1.6482818432613813 RMSE: 1.2838542\n",
      "115 15 0.7701241970062256\n",
      "Validation loss: 1.4038378939164424 RMSE: 1.1848366\n",
      "Validation loss: 1.7598877691589625 RMSE: 1.3266076\n",
      "117 7 0.49787792563438416\n",
      "Validation loss: 1.4342047155430886 RMSE: 1.1975828\n",
      "118 28 0.6512809991836548\n",
      "Validation loss: 1.4090420334740024 RMSE: 1.1870308\n",
      "Validation loss: 1.6423607505528273 RMSE: 1.2815462\n",
      "120 20 0.43978187441825867\n",
      "Validation loss: 1.4626250783954047 RMSE: 1.2093904\n",
      "Validation loss: 1.3739698086164693 RMSE: 1.1721646\n",
      "122 12 0.579533040523529\n",
      "Validation loss: 1.6163871478190464 RMSE: 1.2713722\n",
      "Validation loss: 1.4338311157395354 RMSE: 1.197427\n",
      "124 4 0.5599042773246765\n",
      "Validation loss: 1.366322334888762 RMSE: 1.168898\n",
      "125 25 0.43688687682151794\n",
      "Validation loss: 1.2766701726786858 RMSE: 1.1298983\n",
      "Validation loss: 1.3657904958302995 RMSE: 1.1686704\n",
      "127 17 0.3746855854988098\n",
      "Validation loss: 1.4505823597443843 RMSE: 1.2044013\n",
      "Validation loss: 1.5285839559757604 RMSE: 1.2363591\n",
      "129 9 0.829605221748352\n",
      "Validation loss: 1.8446790781696285 RMSE: 1.3581897\n",
      "Validation loss: 1.344821623468821 RMSE: 1.1596644\n",
      "131 1 0.9421005249023438\n",
      "Validation loss: 1.4517200193573943 RMSE: 1.2048734\n",
      "132 22 0.4743533134460449\n",
      "Validation loss: 1.4258151729549982 RMSE: 1.1940751\n",
      "Validation loss: 1.2736652498751615 RMSE: 1.1285678\n",
      "134 14 0.6266142725944519\n",
      "Validation loss: 1.3506419088988177 RMSE: 1.1621712\n",
      "Validation loss: 1.8022989182345635 RMSE: 1.3424972\n",
      "136 6 0.9918990135192871\n",
      "Validation loss: 1.5930209254796526 RMSE: 1.2621493\n",
      "137 27 0.4982372224330902\n",
      "Validation loss: 1.4026596377381182 RMSE: 1.1843393\n",
      "Validation loss: 1.4306148069094768 RMSE: 1.1960831\n",
      "139 19 0.4578218460083008\n",
      "Validation loss: 1.628684125115386 RMSE: 1.2761991\n",
      "Validation loss: 1.55040050502372 RMSE: 1.2451508\n",
      "141 11 0.4106505513191223\n",
      "Validation loss: 1.1844364193688453 RMSE: 1.0883182\n",
      "Validation loss: 1.7509234341899906 RMSE: 1.3232247\n",
      "143 3 0.7627009749412537\n",
      "Validation loss: 1.4677512888359812 RMSE: 1.2115078\n",
      "144 24 0.7323789000511169\n",
      "Validation loss: 1.4201947672177204 RMSE: 1.1917193\n",
      "Validation loss: 1.3899522829899746 RMSE: 1.1789623\n",
      "146 16 0.8635448813438416\n",
      "Validation loss: 1.1892494026538545 RMSE: 1.0905272\n",
      "Validation loss: 1.4435570229471257 RMSE: 1.2014811\n",
      "148 8 1.1744093894958496\n",
      "Validation loss: 1.2889570556910692 RMSE: 1.1353225\n",
      "Validation loss: 1.428240828809485 RMSE: 1.1950903\n",
      "150 0 0.4694836735725403\n",
      "Validation loss: 1.3291747839049954 RMSE: 1.1528984\n",
      "151 21 0.41807466745376587\n",
      "Validation loss: 1.5481213689905353 RMSE: 1.2442353\n",
      "Validation loss: 1.5049686853864552 RMSE: 1.2267716\n",
      "153 13 0.34136563539505005\n",
      "Validation loss: 1.6773102642160602 RMSE: 1.2951102\n",
      "Validation loss: 1.5990890559896958 RMSE: 1.2645509\n",
      "155 5 0.4935076832771301\n",
      "Validation loss: 1.7331090922904226 RMSE: 1.3164761\n",
      "156 26 0.6451348066329956\n",
      "Validation loss: 1.6816841300609893 RMSE: 1.2967976\n",
      "Validation loss: 1.461737425453895 RMSE: 1.2090232\n",
      "158 18 0.5965012311935425\n",
      "Validation loss: 1.3340703597110986 RMSE: 1.1550198\n",
      "Validation loss: 1.2236478033318985 RMSE: 1.1061863\n",
      "160 10 0.4688921272754669\n",
      "Validation loss: 1.2471450092518224 RMSE: 1.1167564\n",
      "Validation loss: 1.274872977649216 RMSE: 1.1291027\n",
      "162 2 0.2489355355501175\n",
      "Validation loss: 1.5375474638643518 RMSE: 1.2399788\n",
      "163 23 0.27472126483917236\n",
      "Validation loss: 1.2822886789794516 RMSE: 1.1323819\n",
      "Validation loss: 1.1335502256334355 RMSE: 1.0646831\n",
      "165 15 0.3236079812049866\n",
      "Validation loss: 1.2999447425909803 RMSE: 1.1401511\n",
      "Validation loss: 1.3448269831395783 RMSE: 1.1596668\n",
      "167 7 0.503064751625061\n",
      "Validation loss: 1.523105068544371 RMSE: 1.2341415\n",
      "168 28 0.7449544668197632\n",
      "Validation loss: 1.3010662572573772 RMSE: 1.1406429\n",
      "Validation loss: 1.2145318130476286 RMSE: 1.1020579\n",
      "170 20 0.383819580078125\n",
      "Validation loss: 1.240341861691095 RMSE: 1.1137064\n",
      "Validation loss: 1.447288930943582 RMSE: 1.2030332\n",
      "172 12 0.44222068786621094\n",
      "Validation loss: 1.2467956041867754 RMSE: 1.1166\n",
      "Validation loss: 1.4205249563782616 RMSE: 1.1918578\n",
      "174 4 0.347251296043396\n",
      "Validation loss: 1.5125366185618714 RMSE: 1.2298522\n",
      "175 25 0.781570315361023\n",
      "Validation loss: 1.457271235179057 RMSE: 1.2071749\n",
      "Validation loss: 1.3699622059290388 RMSE: 1.1704539\n",
      "177 17 0.5603406429290771\n",
      "Validation loss: 1.2111189861213212 RMSE: 1.1005085\n",
      "Validation loss: 1.3745077458103145 RMSE: 1.172394\n",
      "179 9 0.24819180369377136\n",
      "Validation loss: 1.372087289801741 RMSE: 1.1713613\n",
      "Validation loss: 1.2788268185294835 RMSE: 1.1308523\n",
      "181 1 0.21828904747962952\n",
      "Validation loss: 1.3046447212717174 RMSE: 1.1422105\n",
      "182 22 0.4315691292285919\n",
      "Validation loss: 1.240462536305453 RMSE: 1.1137605\n",
      "Validation loss: 1.5000605920774748 RMSE: 1.2247696\n",
      "184 14 0.5810616612434387\n",
      "Validation loss: 1.2955139442882706 RMSE: 1.1382065\n",
      "Validation loss: 1.3377449259293819 RMSE: 1.1566092\n",
      "186 6 0.25855016708374023\n",
      "Validation loss: 1.459975424066054 RMSE: 1.2082945\n",
      "187 27 0.4785967171192169\n",
      "Validation loss: 1.2716038881149967 RMSE: 1.1276542\n",
      "Validation loss: 1.201453023252234 RMSE: 1.0961081\n",
      "189 19 0.22519707679748535\n",
      "Validation loss: 1.2133308053016663 RMSE: 1.101513\n",
      "Validation loss: 1.1172414722695816 RMSE: 1.0569965\n",
      "191 11 0.298261433839798\n",
      "Validation loss: 1.0907893402386555 RMSE: 1.0444087\n",
      "Validation loss: 1.403074556747369 RMSE: 1.1845144\n",
      "193 3 0.23123177886009216\n",
      "Validation loss: 1.3051351224426675 RMSE: 1.1424251\n",
      "194 24 0.3640204668045044\n",
      "Validation loss: 1.366551355978029 RMSE: 1.1689959\n",
      "Validation loss: 1.1928623767025703 RMSE: 1.0921824\n",
      "196 16 0.28196123242378235\n",
      "Validation loss: 1.430296769184349 RMSE: 1.1959502\n",
      "Validation loss: 1.4259273246326278 RMSE: 1.1941221\n",
      "198 8 0.8474187850952148\n",
      "Validation loss: 1.4098486088018503 RMSE: 1.1873705\n",
      "Validation loss: 1.3392021402848506 RMSE: 1.157239\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.1951284371646105 Test RMSE: 1.0932193\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 778, 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'target': ['measured log solubility in mols per litre']}}\n",
      "Running on: cuda:1\n",
      "1127\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1127\n",
      "Generating scaffold 1000/1127\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 24.437292098999023\n",
      "Validation loss: 4.717595501283629 RMSE: 2.1720026\n",
      "1 21 4.713019371032715\n",
      "Validation loss: 5.513450850427678 RMSE: 2.348074\n",
      "Validation loss: 3.9568563161698065 RMSE: 1.9891849\n",
      "3 13 3.831847906112671\n",
      "Validation loss: 5.775905085875925 RMSE: 2.4033115\n",
      "Validation loss: 3.512651186073776 RMSE: 1.8742068\n",
      "5 5 2.692359447479248\n",
      "Validation loss: 4.392493005347463 RMSE: 2.0958273\n",
      "6 26 2.431621551513672\n",
      "Validation loss: 3.462808659646363 RMSE: 1.8608624\n",
      "Validation loss: 3.9012730817879198 RMSE: 1.9751642\n",
      "8 18 1.7052850723266602\n",
      "Validation loss: 2.7364140063260507 RMSE: 1.6542109\n",
      "Validation loss: 1.6656705177990736 RMSE: 1.2906085\n",
      "10 10 1.345677137374878\n",
      "Validation loss: 2.4391792959871545 RMSE: 1.5617874\n",
      "Validation loss: 3.6595733819809637 RMSE: 1.9130011\n",
      "12 2 1.5243844985961914\n",
      "Validation loss: 2.4166096195710445 RMSE: 1.5545447\n",
      "13 23 1.372380018234253\n",
      "Validation loss: 5.4440534431322485 RMSE: 2.3332496\n",
      "Validation loss: 4.264484660815349 RMSE: 2.065063\n",
      "15 15 1.902685284614563\n",
      "Validation loss: 2.888148386921503 RMSE: 1.6994554\n",
      "Validation loss: 2.4035154254035613 RMSE: 1.5503275\n",
      "17 7 2.592951774597168\n",
      "Validation loss: 4.0983751558624535 RMSE: 2.0244443\n",
      "18 28 1.9331152439117432\n",
      "Validation loss: 1.9504912479788856 RMSE: 1.3965999\n",
      "Validation loss: 2.3756996256060305 RMSE: 1.5413305\n",
      "20 20 1.0923627614974976\n",
      "Validation loss: 2.1577222178467608 RMSE: 1.4689187\n",
      "Validation loss: 2.5670060773866368 RMSE: 1.602188\n",
      "22 12 2.8412437438964844\n",
      "Validation loss: 3.469680828330791 RMSE: 1.8627081\n",
      "Validation loss: 2.8718173503875732 RMSE: 1.6946437\n",
      "24 4 1.121143102645874\n",
      "Validation loss: 1.9566642362459572 RMSE: 1.3988082\n",
      "25 25 2.060429096221924\n",
      "Validation loss: 1.7713341997788015 RMSE: 1.3309147\n",
      "Validation loss: 1.7811468781623165 RMSE: 1.3345962\n",
      "27 17 1.5913729667663574\n",
      "Validation loss: 1.8701482874102298 RMSE: 1.3675334\n",
      "Validation loss: 2.045817024939883 RMSE: 1.4303205\n",
      "29 9 1.5982749462127686\n",
      "Validation loss: 2.377265670658213 RMSE: 1.5418385\n",
      "Validation loss: 1.5943921677834165 RMSE: 1.2626923\n",
      "31 1 0.930141806602478\n",
      "Validation loss: 1.992221486251966 RMSE: 1.4114609\n",
      "32 22 1.23258638381958\n",
      "Validation loss: 1.87588271208569 RMSE: 1.3696287\n",
      "Validation loss: 2.465895804683719 RMSE: 1.5703171\n",
      "34 14 0.8136590123176575\n",
      "Validation loss: 2.1477772904708323 RMSE: 1.4655298\n",
      "Validation loss: 1.6455890309494154 RMSE: 1.2828051\n",
      "36 6 1.2237505912780762\n",
      "Validation loss: 1.9331218373458998 RMSE: 1.3903675\n",
      "37 27 0.8018642067909241\n",
      "Validation loss: 3.2040318102963203 RMSE: 1.789981\n",
      "Validation loss: 2.0337142332465246 RMSE: 1.4260834\n",
      "39 19 0.9024652242660522\n",
      "Validation loss: 2.1578301824299637 RMSE: 1.4689555\n",
      "Validation loss: 3.2856322031105516 RMSE: 1.8126312\n",
      "41 11 1.6623613834381104\n",
      "Validation loss: 2.5951096906071216 RMSE: 1.6109344\n",
      "Validation loss: 1.9566832084571366 RMSE: 1.3988149\n",
      "43 3 1.1443909406661987\n",
      "Validation loss: 1.9760066239179763 RMSE: 1.405705\n",
      "44 24 0.6333773136138916\n",
      "Validation loss: 1.5998282643546045 RMSE: 1.2648432\n",
      "Validation loss: 2.115862352658162 RMSE: 1.4546005\n",
      "46 16 0.6736753582954407\n",
      "Validation loss: 2.3030668486536077 RMSE: 1.5175859\n",
      "Validation loss: 1.715496846004925 RMSE: 1.3097697\n",
      "48 8 0.9277382493019104\n",
      "Validation loss: 1.981169837765989 RMSE: 1.4075403\n",
      "Validation loss: 2.0530437420954746 RMSE: 1.4328446\n",
      "50 0 1.6509238481521606\n",
      "Validation loss: 2.2456830645029524 RMSE: 1.4985603\n",
      "51 21 0.6300902366638184\n",
      "Validation loss: 1.7723141940294114 RMSE: 1.331283\n",
      "Validation loss: 2.01067385631325 RMSE: 1.4179823\n",
      "53 13 0.7763235569000244\n",
      "Validation loss: 1.8991952058488288 RMSE: 1.3781129\n",
      "Validation loss: 2.108108242001154 RMSE: 1.4519325\n",
      "55 5 1.3720942735671997\n",
      "Validation loss: 2.814650149471992 RMSE: 1.6776919\n",
      "56 26 1.945031762123108\n",
      "Validation loss: 1.878018676707175 RMSE: 1.3704082\n",
      "Validation loss: 2.491509557825274 RMSE: 1.5784518\n",
      "58 18 0.7711431384086609\n",
      "Validation loss: 1.931949208268022 RMSE: 1.3899457\n",
      "Validation loss: 1.6162554932906565 RMSE: 1.2713203\n",
      "60 10 1.012423038482666\n",
      "Validation loss: 2.1350052820897734 RMSE: 1.4611658\n",
      "Validation loss: 1.484843769959644 RMSE: 1.2185417\n",
      "62 2 0.6788927316665649\n",
      "Validation loss: 1.9263411686483738 RMSE: 1.3879269\n",
      "63 23 0.8126489520072937\n",
      "Validation loss: 1.7135075193590823 RMSE: 1.3090103\n",
      "Validation loss: 1.7804296670761783 RMSE: 1.3343275\n",
      "65 15 0.8502830266952515\n",
      "Validation loss: 1.984386707829163 RMSE: 1.4086826\n",
      "Validation loss: 1.8904144785045522 RMSE: 1.3749235\n",
      "67 7 1.0303523540496826\n",
      "Validation loss: 2.3599858705976366 RMSE: 1.5362245\n",
      "68 28 2.4818968772888184\n",
      "Validation loss: 1.6359977616673023 RMSE: 1.2790612\n",
      "Validation loss: 1.4306864738464355 RMSE: 1.1961131\n",
      "70 20 0.7907351851463318\n",
      "Validation loss: 1.6263164260746104 RMSE: 1.275271\n",
      "Validation loss: 1.3930034690198645 RMSE: 1.1802557\n",
      "72 12 0.5363029837608337\n",
      "Validation loss: 1.8423261980039884 RMSE: 1.357323\n",
      "Validation loss: 1.4888560466006793 RMSE: 1.220187\n",
      "74 4 0.6838233470916748\n",
      "Validation loss: 1.488927130150584 RMSE: 1.220216\n",
      "75 25 1.1182448863983154\n",
      "Validation loss: 1.4409123057812716 RMSE: 1.2003801\n",
      "Validation loss: 1.5474436240913594 RMSE: 1.2439629\n",
      "77 17 0.6159230470657349\n",
      "Validation loss: 1.519022831874611 RMSE: 1.2324864\n",
      "Validation loss: 1.342059247261655 RMSE: 1.1584728\n",
      "79 9 0.4294639825820923\n",
      "Validation loss: 1.402577219811161 RMSE: 1.1843045\n",
      "Validation loss: 1.6353050628594592 RMSE: 1.2787905\n",
      "81 1 0.6166645288467407\n",
      "Validation loss: 1.5557509903359201 RMSE: 1.2472974\n",
      "82 22 0.8076972961425781\n",
      "Validation loss: 1.3008281657126097 RMSE: 1.1405386\n",
      "Validation loss: 1.574643611907959 RMSE: 1.254848\n",
      "84 14 0.7353899478912354\n",
      "Validation loss: 1.5539656608505588 RMSE: 1.2465816\n",
      "Validation loss: 1.74149662941958 RMSE: 1.3196578\n",
      "86 6 0.7192178964614868\n",
      "Validation loss: 1.5592533745596895 RMSE: 1.2487006\n",
      "87 27 0.8031675815582275\n",
      "Validation loss: 1.7764116704991433 RMSE: 1.332821\n",
      "Validation loss: 1.5887592345212413 RMSE: 1.2604599\n",
      "89 19 0.41021227836608887\n",
      "Validation loss: 1.7801006642063106 RMSE: 1.3342041\n",
      "Validation loss: 1.4977596259750097 RMSE: 1.2238299\n",
      "91 11 1.2116491794586182\n",
      "Validation loss: 1.705429153104799 RMSE: 1.3059208\n",
      "Validation loss: 2.685845718974561 RMSE: 1.6388551\n",
      "93 3 0.9870278835296631\n",
      "Validation loss: 1.471602455704613 RMSE: 1.2130963\n",
      "94 24 0.7226444482803345\n",
      "Validation loss: 1.4895918759624516 RMSE: 1.2204883\n",
      "Validation loss: 1.3950208267279431 RMSE: 1.18111\n",
      "96 16 0.5800643563270569\n",
      "Validation loss: 1.8709325452821444 RMSE: 1.3678204\n",
      "Validation loss: 1.4013803975772015 RMSE: 1.1837991\n",
      "98 8 0.6941499710083008\n",
      "Validation loss: 1.6130737393303256 RMSE: 1.2700684\n",
      "Validation loss: 1.5962353295984522 RMSE: 1.2634221\n",
      "100 0 0.6474522948265076\n",
      "Validation loss: 1.5991869415857096 RMSE: 1.2645897\n",
      "101 21 0.5279967784881592\n",
      "Validation loss: 1.4175852136274354 RMSE: 1.1906239\n",
      "Validation loss: 1.9062650235353318 RMSE: 1.3806757\n",
      "103 13 0.6218888163566589\n",
      "Validation loss: 1.5602298500263585 RMSE: 1.2490916\n",
      "Validation loss: 1.85913296927393 RMSE: 1.3635002\n",
      "105 5 0.7380833625793457\n",
      "Validation loss: 1.4933114642590548 RMSE: 1.2220112\n",
      "106 26 1.3834739923477173\n",
      "Validation loss: 1.6998995025601007 RMSE: 1.3038019\n",
      "Validation loss: 1.2809598055561031 RMSE: 1.1317949\n",
      "108 18 0.27969130873680115\n",
      "Validation loss: 1.4524618693157636 RMSE: 1.2051812\n",
      "Validation loss: 1.44202618577839 RMSE: 1.200844\n",
      "110 10 0.4434216320514679\n",
      "Validation loss: 2.3175297690703807 RMSE: 1.5223435\n",
      "Validation loss: 1.5505213463200933 RMSE: 1.2451993\n",
      "112 2 0.6373883485794067\n",
      "Validation loss: 1.6286982076357952 RMSE: 1.2762046\n",
      "113 23 0.889136552810669\n",
      "Validation loss: 2.4866127725196097 RMSE: 1.5768998\n",
      "Validation loss: 1.3102206972847998 RMSE: 1.1446487\n",
      "115 15 0.5999770164489746\n",
      "Validation loss: 2.277162454824532 RMSE: 1.509027\n",
      "Validation loss: 1.848794424428349 RMSE: 1.3597039\n",
      "117 7 0.8348994255065918\n",
      "Validation loss: 1.634655452407567 RMSE: 1.2785364\n",
      "118 28 0.44405102729797363\n",
      "Validation loss: 1.4342584282951016 RMSE: 1.1976053\n",
      "Validation loss: 1.7081630103356016 RMSE: 1.3069671\n",
      "120 20 0.42731550335884094\n",
      "Validation loss: 1.7128807422334114 RMSE: 1.3087707\n",
      "Validation loss: 1.6202848938714087 RMSE: 1.2729042\n",
      "122 12 0.5190004706382751\n",
      "Validation loss: 1.6604500101730886 RMSE: 1.2885846\n",
      "Validation loss: 1.5342533411705388 RMSE: 1.2386497\n",
      "124 4 0.7978400588035583\n",
      "Validation loss: 1.2914437867898856 RMSE: 1.1364172\n",
      "125 25 0.481190025806427\n",
      "Validation loss: 1.239229667503222 RMSE: 1.1132069\n",
      "Validation loss: 1.3743161838666527 RMSE: 1.1723124\n",
      "127 17 0.5822005271911621\n",
      "Validation loss: 1.4202673677849558 RMSE: 1.1917497\n",
      "Validation loss: 1.2675708036507125 RMSE: 1.1258644\n",
      "129 9 0.882180392742157\n",
      "Validation loss: 1.1920675429622685 RMSE: 1.0918185\n",
      "Validation loss: 1.2787541878961883 RMSE: 1.13082\n",
      "131 1 1.389682412147522\n",
      "Validation loss: 1.5597095900932245 RMSE: 1.2488834\n",
      "132 22 0.8137165307998657\n",
      "Validation loss: 1.4768305710986651 RMSE: 1.2152492\n",
      "Validation loss: 1.3852076171773724 RMSE: 1.1769485\n",
      "134 14 0.8300448060035706\n",
      "Validation loss: 1.3049549687225206 RMSE: 1.1423463\n",
      "Validation loss: 1.419218686829626 RMSE: 1.1913097\n",
      "136 6 1.1085126399993896\n",
      "Validation loss: 1.272755320093273 RMSE: 1.1281645\n",
      "137 27 0.7919811606407166\n",
      "Validation loss: 1.3300576336615908 RMSE: 1.1532813\n",
      "Validation loss: 1.3500964050799344 RMSE: 1.1619364\n",
      "139 19 0.3062140643596649\n",
      "Validation loss: 1.4023815963120587 RMSE: 1.1842219\n",
      "Validation loss: 1.2907361477877186 RMSE: 1.1361057\n",
      "141 11 0.3684520125389099\n",
      "Validation loss: 1.4408072001111192 RMSE: 1.2003362\n",
      "Validation loss: 1.3595116233403703 RMSE: 1.165981\n",
      "143 3 0.4811922609806061\n",
      "Validation loss: 1.3239461689923717 RMSE: 1.1506286\n",
      "144 24 0.6489060521125793\n",
      "Validation loss: 1.5900057185012682 RMSE: 1.2609543\n",
      "Validation loss: 1.429914994577391 RMSE: 1.1957905\n",
      "146 16 0.2843210697174072\n",
      "Validation loss: 1.053794454156825 RMSE: 1.0265449\n",
      "Validation loss: 1.3813359051679088 RMSE: 1.1753025\n",
      "148 8 0.3111649751663208\n",
      "Validation loss: 1.4429319231911044 RMSE: 1.2012211\n",
      "Validation loss: 1.7847979047657114 RMSE: 1.3359634\n",
      "150 0 0.4220413565635681\n",
      "Validation loss: 1.3300332358453126 RMSE: 1.1532706\n",
      "151 21 0.4975644052028656\n",
      "Validation loss: 1.3172658840111926 RMSE: 1.147722\n",
      "Validation loss: 1.0675361842180775 RMSE: 1.0332165\n",
      "153 13 0.5020279884338379\n",
      "Validation loss: 1.4048699414835566 RMSE: 1.1852721\n",
      "Validation loss: 1.2973783417085631 RMSE: 1.1390252\n",
      "155 5 0.49552667140960693\n",
      "Validation loss: 1.3611731676928764 RMSE: 1.1666933\n",
      "156 26 0.5091710090637207\n",
      "Validation loss: 2.4787236874082446 RMSE: 1.5743963\n",
      "Validation loss: 1.3416175557448802 RMSE: 1.1582822\n",
      "158 18 0.5024884343147278\n",
      "Validation loss: 1.4392984483094342 RMSE: 1.1997076\n",
      "Validation loss: 1.2186175732486015 RMSE: 1.1039101\n",
      "160 10 0.32420119643211365\n",
      "Validation loss: 1.4933569990428148 RMSE: 1.2220299\n",
      "Validation loss: 1.1300051138464329 RMSE: 1.063017\n",
      "162 2 1.3403434753417969\n",
      "Validation loss: 1.7928653417435367 RMSE: 1.3389792\n",
      "163 23 0.8533981442451477\n",
      "Validation loss: 1.3127276132592058 RMSE: 1.1457433\n",
      "Validation loss: 1.3000448847238997 RMSE: 1.1401951\n",
      "165 15 0.608791172504425\n",
      "Validation loss: 1.7444941470053343 RMSE: 1.320793\n",
      "Validation loss: 1.280362375014651 RMSE: 1.131531\n",
      "167 7 0.5118294358253479\n",
      "Validation loss: 1.247305334141824 RMSE: 1.1168282\n",
      "168 28 0.6187383532524109\n",
      "Validation loss: 1.2057533480424796 RMSE: 1.098068\n",
      "Validation loss: 1.437592290144051 RMSE: 1.1989963\n",
      "170 20 0.5232025384902954\n",
      "Validation loss: 1.2881999121303052 RMSE: 1.1349889\n",
      "Validation loss: 1.4834532653335977 RMSE: 1.217971\n",
      "172 12 0.3514001965522766\n",
      "Validation loss: 1.1653882555202044 RMSE: 1.0795314\n",
      "Validation loss: 1.096712394098265 RMSE: 1.0472404\n",
      "174 4 0.3772081434726715\n",
      "Validation loss: 1.1049101384340134 RMSE: 1.0511471\n",
      "175 25 0.41915076971054077\n",
      "Validation loss: 1.48199113807847 RMSE: 1.2173706\n",
      "Validation loss: 1.2320117586481887 RMSE: 1.1099603\n",
      "177 17 0.260579913854599\n",
      "Validation loss: 1.5474142933313826 RMSE: 1.2439511\n",
      "Validation loss: 1.3175754747559538 RMSE: 1.147857\n",
      "179 9 0.34440770745277405\n",
      "Validation loss: 1.237990939511662 RMSE: 1.1126504\n",
      "Validation loss: 1.2512959199669087 RMSE: 1.1186134\n",
      "181 1 0.6730126142501831\n",
      "Validation loss: 1.3114011372085166 RMSE: 1.1451643\n",
      "182 22 0.6227936744689941\n",
      "Validation loss: 1.6455913317941986 RMSE: 1.282806\n",
      "Validation loss: 1.6168620987276061 RMSE: 1.2715589\n",
      "184 14 0.39338499307632446\n",
      "Validation loss: 1.7183415742047066 RMSE: 1.3108554\n",
      "Validation loss: 1.4306703267899235 RMSE: 1.1961063\n",
      "186 6 0.33308297395706177\n",
      "Validation loss: 1.791486924728461 RMSE: 1.3384644\n",
      "187 27 0.261923611164093\n",
      "Validation loss: 1.2493478745485829 RMSE: 1.1177423\n",
      "Validation loss: 1.385863833722815 RMSE: 1.1772271\n",
      "189 19 0.6843057870864868\n",
      "Validation loss: 1.5806000665225814 RMSE: 1.2572192\n",
      "Validation loss: 1.3084014886248427 RMSE: 1.1438538\n",
      "191 11 0.43727195262908936\n",
      "Validation loss: 1.3788599704219178 RMSE: 1.1742487\n",
      "Validation loss: 1.4038392727353932 RMSE: 1.1848372\n",
      "193 3 0.25392845273017883\n",
      "Validation loss: 1.25399447964356 RMSE: 1.1198189\n",
      "194 24 0.5490193963050842\n",
      "Validation loss: 1.2163801583568608 RMSE: 1.1028962\n",
      "Validation loss: 1.3565132776192859 RMSE: 1.1646945\n",
      "196 16 0.3287304937839508\n",
      "Validation loss: 1.3191605911845654 RMSE: 1.1485472\n",
      "Validation loss: 1.19728118444966 RMSE: 1.0942035\n",
      "198 8 0.6291693449020386\n",
      "Validation loss: 1.3386908685211587 RMSE: 1.1570181\n",
      "Validation loss: 1.2198256090679 RMSE: 1.1044571\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.442728609110402 Test RMSE: 1.2011365\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 779, 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'target': ['measured log solubility in mols per litre']}}\n",
      "Running on: cuda:1\n",
      "1127\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1127\n",
      "Generating scaffold 1000/1127\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 22.0302677154541\n",
      "Validation loss: 3.673519862436615 RMSE: 1.9166429\n",
      "1 21 4.577767372131348\n",
      "Validation loss: 4.612072126000329 RMSE: 2.1475735\n",
      "Validation loss: 2.687875798318238 RMSE: 1.6394743\n",
      "3 13 3.7318270206451416\n",
      "Validation loss: 3.96038033476973 RMSE: 1.9900705\n",
      "Validation loss: 2.9871863348294148 RMSE: 1.7283478\n",
      "5 5 2.3654367923736572\n",
      "Validation loss: 3.0409845398590627 RMSE: 1.7438419\n",
      "6 26 2.8061914443969727\n",
      "Validation loss: 2.848754572657357 RMSE: 1.6878254\n",
      "Validation loss: 2.5409902260366795 RMSE: 1.5940483\n",
      "8 18 1.6834557056427002\n",
      "Validation loss: 2.35883000255686 RMSE: 1.5358483\n",
      "Validation loss: 2.7440205886300686 RMSE: 1.6565086\n",
      "10 10 2.0467982292175293\n",
      "Validation loss: 2.7107574317307597 RMSE: 1.6464378\n",
      "Validation loss: 2.11145228622234 RMSE: 1.4530836\n",
      "12 2 2.035703659057617\n",
      "Validation loss: 2.424220536662414 RMSE: 1.556991\n",
      "13 23 1.8881969451904297\n",
      "Validation loss: 1.705022327667844 RMSE: 1.305765\n",
      "Validation loss: 3.339208134507711 RMSE: 1.8273501\n",
      "15 15 2.0172321796417236\n",
      "Validation loss: 2.6438297212651345 RMSE: 1.6259857\n",
      "Validation loss: 2.1045016778253878 RMSE: 1.45069\n",
      "17 7 1.6542084217071533\n",
      "Validation loss: 2.0211840751951775 RMSE: 1.4216835\n",
      "18 28 3.07529354095459\n",
      "Validation loss: 2.774970704475335 RMSE: 1.6658243\n",
      "Validation loss: 3.367465052984457 RMSE: 1.8350654\n",
      "20 20 0.945307731628418\n",
      "Validation loss: 2.481611608403974 RMSE: 1.5753132\n",
      "Validation loss: 2.3079435677654976 RMSE: 1.5191916\n",
      "22 12 2.0366640090942383\n",
      "Validation loss: 1.758964605036035 RMSE: 1.3262596\n",
      "Validation loss: 3.5476592030145424 RMSE: 1.883523\n",
      "24 4 2.01021409034729\n",
      "Validation loss: 2.4192865148054814 RMSE: 1.5554056\n",
      "25 25 1.1830885410308838\n",
      "Validation loss: 2.044732072712046 RMSE: 1.4299413\n",
      "Validation loss: 2.1872361655783865 RMSE: 1.4789308\n",
      "27 17 0.9280275106430054\n",
      "Validation loss: 1.8323107451464222 RMSE: 1.3536286\n",
      "Validation loss: 2.176394802279177 RMSE: 1.475261\n",
      "29 9 1.556674838066101\n",
      "Validation loss: 1.4694679363638954 RMSE: 1.2122163\n",
      "Validation loss: 1.7167542814153485 RMSE: 1.3102497\n",
      "31 1 1.8759733438491821\n",
      "Validation loss: 1.601591972123205 RMSE: 1.2655401\n",
      "32 22 1.0966787338256836\n",
      "Validation loss: 1.4975793045178978 RMSE: 1.2237562\n",
      "Validation loss: 1.8096631828662568 RMSE: 1.3452373\n",
      "34 14 1.487952709197998\n",
      "Validation loss: 1.6768797161304845 RMSE: 1.2949439\n",
      "Validation loss: 1.5958733178872977 RMSE: 1.2632787\n",
      "36 6 1.3875560760498047\n",
      "Validation loss: 2.0739010836170837 RMSE: 1.4401046\n",
      "37 27 0.7725152969360352\n",
      "Validation loss: 1.8817213520539546 RMSE: 1.3717585\n",
      "Validation loss: 1.4267928415695124 RMSE: 1.1944844\n",
      "39 19 1.8885772228240967\n",
      "Validation loss: 2.456159728818235 RMSE: 1.567214\n",
      "Validation loss: 1.7734555343611051 RMSE: 1.3317114\n",
      "41 11 1.082063913345337\n",
      "Validation loss: 2.7654678642222312 RMSE: 1.6629697\n",
      "Validation loss: 2.109038642022462 RMSE: 1.452253\n",
      "43 3 0.7370572090148926\n",
      "Validation loss: 1.66118534792841 RMSE: 1.2888699\n",
      "44 24 0.6255342960357666\n",
      "Validation loss: 1.7345801465279234 RMSE: 1.3170347\n",
      "Validation loss: 2.658693971887099 RMSE: 1.6305501\n",
      "46 16 1.0459885597229004\n",
      "Validation loss: 1.6142787917525367 RMSE: 1.2705427\n",
      "Validation loss: 1.7178221360772057 RMSE: 1.3106571\n",
      "48 8 0.687145471572876\n",
      "Validation loss: 1.7599685265954617 RMSE: 1.3266381\n",
      "Validation loss: 1.488351072357819 RMSE: 1.21998\n",
      "50 0 0.7054765224456787\n",
      "Validation loss: 1.3952607950278089 RMSE: 1.1812116\n",
      "51 21 1.0078080892562866\n",
      "Validation loss: 2.0528159183738506 RMSE: 1.4327651\n",
      "Validation loss: 1.5234193084514247 RMSE: 1.2342688\n",
      "53 13 0.8307741284370422\n",
      "Validation loss: 1.9348686701428575 RMSE: 1.3909955\n",
      "Validation loss: 2.085607488598444 RMSE: 1.4441632\n",
      "55 5 0.8887960910797119\n",
      "Validation loss: 1.5667863155888244 RMSE: 1.2517134\n",
      "56 26 1.7230451107025146\n",
      "Validation loss: 1.7458640906663068 RMSE: 1.3213115\n",
      "Validation loss: 1.6821775425851873 RMSE: 1.2969879\n",
      "58 18 0.6952348947525024\n",
      "Validation loss: 1.623879349337215 RMSE: 1.2743152\n",
      "Validation loss: 1.7120914364283064 RMSE: 1.3084692\n",
      "60 10 1.1418452262878418\n",
      "Validation loss: 1.5501111956824243 RMSE: 1.2450346\n",
      "Validation loss: 2.4953819587167385 RMSE: 1.5796778\n",
      "62 2 0.584757387638092\n",
      "Validation loss: 1.9065328308966307 RMSE: 1.3807726\n",
      "63 23 0.42330700159072876\n",
      "Validation loss: 1.5791811879757232 RMSE: 1.2566547\n",
      "Validation loss: 1.818234482697681 RMSE: 1.3484193\n",
      "65 15 1.9600428342819214\n",
      "Validation loss: 1.660622213794067 RMSE: 1.2886513\n",
      "Validation loss: 1.6289922051725134 RMSE: 1.2763199\n",
      "67 7 0.5957999229431152\n",
      "Validation loss: 1.669940435780888 RMSE: 1.2922617\n",
      "68 28 1.8368580341339111\n",
      "Validation loss: 1.5984810727887449 RMSE: 1.2643105\n",
      "Validation loss: 1.6209714170050833 RMSE: 1.2731738\n",
      "70 20 0.7354621291160583\n",
      "Validation loss: 1.6100533372533006 RMSE: 1.2688787\n",
      "Validation loss: 1.6193993893344845 RMSE: 1.2725563\n",
      "72 12 0.8059840202331543\n",
      "Validation loss: 2.781135606554757 RMSE: 1.6676737\n",
      "Validation loss: 1.7083321081853546 RMSE: 1.3070318\n",
      "74 4 0.7052610516548157\n",
      "Validation loss: 1.7165853017199355 RMSE: 1.3101852\n",
      "75 25 0.607174277305603\n",
      "Validation loss: 1.3879766126649569 RMSE: 1.1781243\n",
      "Validation loss: 1.8282449055561978 RMSE: 1.352126\n",
      "77 17 1.092250943183899\n",
      "Validation loss: 1.5062715015580168 RMSE: 1.2273026\n",
      "Validation loss: 1.618779214082566 RMSE: 1.2723125\n",
      "79 9 0.6569653749465942\n",
      "Validation loss: 1.4988665633496985 RMSE: 1.2242821\n",
      "Validation loss: 1.928027387213918 RMSE: 1.3885343\n",
      "81 1 0.6942295432090759\n",
      "Validation loss: 1.5401187860860235 RMSE: 1.2410152\n",
      "82 22 0.6305162906646729\n",
      "Validation loss: 2.658220769029803 RMSE: 1.6304051\n",
      "Validation loss: 1.6137007063469 RMSE: 1.2703152\n",
      "84 14 0.7472902536392212\n",
      "Validation loss: 1.4167018901985304 RMSE: 1.1902529\n",
      "Validation loss: 1.7038394370965197 RMSE: 1.305312\n",
      "86 6 0.7694833874702454\n",
      "Validation loss: 1.4963122490233025 RMSE: 1.2232383\n",
      "87 27 0.8366530537605286\n",
      "Validation loss: 2.001693892267953 RMSE: 1.4148123\n",
      "Validation loss: 1.9536028351403971 RMSE: 1.3977134\n",
      "89 19 0.755683958530426\n",
      "Validation loss: 1.5779947664885394 RMSE: 1.2561826\n",
      "Validation loss: 1.5990086509063182 RMSE: 1.2645191\n",
      "91 11 0.7847435474395752\n",
      "Validation loss: 1.3318101716252555 RMSE: 1.1540408\n",
      "Validation loss: 1.4389592398584417 RMSE: 1.1995664\n",
      "93 3 0.47223538160324097\n",
      "Validation loss: 1.4305563896103244 RMSE: 1.1960586\n",
      "94 24 0.6660071015357971\n",
      "Validation loss: 1.8763914804543014 RMSE: 1.3698144\n",
      "Validation loss: 1.3805106551246304 RMSE: 1.1749514\n",
      "96 16 0.5800819993019104\n",
      "Validation loss: 1.4332213581135842 RMSE: 1.1971723\n",
      "Validation loss: 2.0196246773795745 RMSE: 1.421135\n",
      "98 8 0.3614492416381836\n",
      "Validation loss: 1.3306270458002005 RMSE: 1.1535281\n",
      "Validation loss: 1.5048664966515735 RMSE: 1.22673\n",
      "100 0 0.6044757962226868\n",
      "Validation loss: 1.6412240055810035 RMSE: 1.2811027\n",
      "101 21 0.9144632816314697\n",
      "Validation loss: 1.451900034879161 RMSE: 1.2049482\n",
      "Validation loss: 1.3508478023309622 RMSE: 1.1622598\n",
      "103 13 0.5443305969238281\n",
      "Validation loss: 1.9804497102720549 RMSE: 1.4072845\n",
      "Validation loss: 1.3623196836066458 RMSE: 1.1671845\n",
      "105 5 0.49389368295669556\n",
      "Validation loss: 1.6634651992173322 RMSE: 1.2897539\n",
      "106 26 0.6698302626609802\n",
      "Validation loss: 1.2333926584868304 RMSE: 1.1105821\n",
      "Validation loss: 1.6269836953255983 RMSE: 1.2755327\n",
      "108 18 0.2912510931491852\n",
      "Validation loss: 1.4099945494558959 RMSE: 1.1874319\n",
      "Validation loss: 1.8787457014607116 RMSE: 1.3706735\n",
      "110 10 0.5150431394577026\n",
      "Validation loss: 1.62560025464117 RMSE: 1.2749903\n",
      "Validation loss: 1.4645434217115418 RMSE: 1.2101833\n",
      "112 2 0.42489850521087646\n",
      "Validation loss: 1.2521291834063235 RMSE: 1.1189858\n",
      "113 23 0.7857317328453064\n",
      "Validation loss: 1.4489065197716773 RMSE: 1.2037053\n",
      "Validation loss: 1.6610530119026656 RMSE: 1.2888185\n",
      "115 15 0.9040826559066772\n",
      "Validation loss: 1.7766954582349388 RMSE: 1.3329275\n",
      "Validation loss: 1.5556843544529602 RMSE: 1.2472708\n",
      "117 7 1.0576825141906738\n",
      "Validation loss: 1.3298287845290868 RMSE: 1.153182\n",
      "118 28 0.9613913297653198\n",
      "Validation loss: 1.7060681866333547 RMSE: 1.3061653\n",
      "Validation loss: 1.5624755547109959 RMSE: 1.2499902\n",
      "120 20 0.4590985178947449\n",
      "Validation loss: 1.5507836879882138 RMSE: 1.2453046\n",
      "Validation loss: 1.4604812480707083 RMSE: 1.2085037\n",
      "122 12 0.33600515127182007\n",
      "Validation loss: 1.5317918863971676 RMSE: 1.2376558\n",
      "Validation loss: 1.6275254182055987 RMSE: 1.275745\n",
      "124 4 1.0374807119369507\n",
      "Validation loss: 1.4238648815492614 RMSE: 1.193258\n",
      "125 25 0.4909384250640869\n",
      "Validation loss: 1.4681049395451504 RMSE: 1.2116538\n",
      "Validation loss: 1.5558563945567714 RMSE: 1.2473397\n",
      "127 17 1.1347451210021973\n",
      "Validation loss: 1.5640268172837992 RMSE: 1.2506106\n",
      "Validation loss: 1.3859467981135951 RMSE: 1.1772623\n",
      "129 9 0.5486879944801331\n",
      "Validation loss: 1.6847663854075745 RMSE: 1.2979854\n",
      "Validation loss: 1.6794322243833963 RMSE: 1.2959291\n",
      "131 1 0.557607889175415\n",
      "Validation loss: 1.637824492116945 RMSE: 1.2797751\n",
      "132 22 0.35248300433158875\n",
      "Validation loss: 1.6109916573077177 RMSE: 1.2692485\n",
      "Validation loss: 1.6798647199056844 RMSE: 1.296096\n",
      "134 14 0.6014586687088013\n",
      "Validation loss: 1.6911135838095066 RMSE: 1.3004283\n",
      "Validation loss: 1.3781918276727727 RMSE: 1.1739641\n",
      "136 6 0.384234756231308\n",
      "Validation loss: 1.7031974148961295 RMSE: 1.3050661\n",
      "137 27 0.2539927065372467\n",
      "Validation loss: 1.5949807652329977 RMSE: 1.2629255\n",
      "Validation loss: 1.4696758183757817 RMSE: 1.2123019\n",
      "139 19 1.3001564741134644\n",
      "Validation loss: 1.5547569104000531 RMSE: 1.246899\n",
      "Validation loss: 1.5254695531541267 RMSE: 1.2350991\n",
      "141 11 0.6971874833106995\n",
      "Validation loss: 1.4766588042267657 RMSE: 1.2151785\n",
      "Validation loss: 1.228055751429195 RMSE: 1.1081768\n",
      "143 3 0.335357129573822\n",
      "Validation loss: 1.8105502877615194 RMSE: 1.3455669\n",
      "144 24 0.9060602188110352\n",
      "Validation loss: 1.599178987266743 RMSE: 1.2645864\n",
      "Validation loss: 1.1969822550241926 RMSE: 1.0940667\n",
      "146 16 1.1699130535125732\n",
      "Validation loss: 1.5113041896735673 RMSE: 1.2293512\n",
      "Validation loss: 1.236261958569552 RMSE: 1.1118733\n",
      "148 8 0.3162158727645874\n",
      "Validation loss: 1.4474702029101616 RMSE: 1.2031085\n",
      "Validation loss: 1.4694637566541149 RMSE: 1.2122145\n",
      "150 0 0.7726908922195435\n",
      "Validation loss: 1.3653305842813137 RMSE: 1.1684736\n",
      "151 21 0.4758337438106537\n",
      "Validation loss: 1.4094876335785451 RMSE: 1.1872184\n",
      "Validation loss: 1.682689605560978 RMSE: 1.2971852\n",
      "153 13 0.3209190368652344\n",
      "Validation loss: 1.5085473113355383 RMSE: 1.2282294\n",
      "Validation loss: 1.4516098309407193 RMSE: 1.2048277\n",
      "155 5 0.40222859382629395\n",
      "Validation loss: 1.3407199667618337 RMSE: 1.1578946\n",
      "156 26 0.606332540512085\n",
      "Validation loss: 1.3700576672511817 RMSE: 1.1704947\n",
      "Validation loss: 1.4463004580641214 RMSE: 1.2026223\n",
      "158 18 0.49057015776634216\n",
      "Validation loss: 1.5744343384177284 RMSE: 1.2547647\n",
      "Validation loss: 1.4739855369635388 RMSE: 1.2140781\n",
      "160 10 0.5432798862457275\n",
      "Validation loss: 1.5823090962604083 RMSE: 1.2578987\n",
      "Validation loss: 1.6956850132056043 RMSE: 1.3021847\n",
      "162 2 0.44099661707878113\n",
      "Validation loss: 1.3194323271776722 RMSE: 1.1486654\n",
      "163 23 0.440981388092041\n",
      "Validation loss: 1.3801733687915634 RMSE: 1.1748079\n",
      "Validation loss: 1.4243495770260297 RMSE: 1.1934612\n",
      "165 15 0.36373862624168396\n",
      "Validation loss: 1.270739680897873 RMSE: 1.1272709\n",
      "Validation loss: 1.2402284504038044 RMSE: 1.1136554\n",
      "167 7 0.3220624327659607\n",
      "Validation loss: 1.3954182272463773 RMSE: 1.1812782\n",
      "168 28 1.5850151777267456\n",
      "Validation loss: 1.457725761211024 RMSE: 1.2073631\n",
      "Validation loss: 1.7423801675307011 RMSE: 1.3199924\n",
      "170 20 0.39903563261032104\n",
      "Validation loss: 1.4498455382026403 RMSE: 1.2040954\n",
      "Validation loss: 1.5081601364422688 RMSE: 1.2280718\n",
      "172 12 0.5429165363311768\n",
      "Validation loss: 1.5372927542281363 RMSE: 1.239876\n",
      "Validation loss: 1.5166697238398865 RMSE: 1.2315315\n",
      "174 4 0.3241119086742401\n",
      "Validation loss: 1.453149615135868 RMSE: 1.2054665\n",
      "175 25 0.48897585272789\n",
      "Validation loss: 1.3760913547161406 RMSE: 1.1730692\n",
      "Validation loss: 1.209221360957728 RMSE: 1.099646\n",
      "177 17 0.3070816695690155\n",
      "Validation loss: 1.3684418655074804 RMSE: 1.1698042\n",
      "Validation loss: 1.5286496930417761 RMSE: 1.2363858\n",
      "179 9 0.8207840323448181\n",
      "Validation loss: 1.2435217061928943 RMSE: 1.1151332\n",
      "Validation loss: 1.4554692169206331 RMSE: 1.2064284\n",
      "181 1 0.30979281663894653\n",
      "Validation loss: 1.4241286906520878 RMSE: 1.1933686\n",
      "182 22 0.49502599239349365\n",
      "Validation loss: 1.561049345320305 RMSE: 1.2494197\n",
      "Validation loss: 1.3673338573590843 RMSE: 1.1693306\n",
      "184 14 0.32185351848602295\n",
      "Validation loss: 1.4533495808069685 RMSE: 1.2055495\n",
      "Validation loss: 1.2887525853857529 RMSE: 1.1352323\n",
      "186 6 0.6352970600128174\n",
      "Validation loss: 1.374574439715495 RMSE: 1.1724224\n",
      "187 27 0.36774617433547974\n",
      "Validation loss: 1.5579434137428756 RMSE: 1.2481761\n",
      "Validation loss: 1.590212226968951 RMSE: 1.2610362\n",
      "189 19 0.40911999344825745\n",
      "Validation loss: 1.2421806090700942 RMSE: 1.1145315\n",
      "Validation loss: 1.3386872584840892 RMSE: 1.1570165\n",
      "191 11 0.6516834497451782\n",
      "Validation loss: 2.063413328829065 RMSE: 1.4364586\n",
      "Validation loss: 1.3820827102239153 RMSE: 1.1756202\n",
      "193 3 0.7734231352806091\n",
      "Validation loss: 1.3372215306864375 RMSE: 1.1563829\n",
      "194 24 0.5757871866226196\n",
      "Validation loss: 1.3659216450378957 RMSE: 1.1687264\n",
      "Validation loss: 1.175511936170865 RMSE: 1.0842103\n",
      "196 16 0.25433188676834106\n",
      "Validation loss: 1.8046649209165995 RMSE: 1.3433782\n",
      "Validation loss: 1.3490513278319773 RMSE: 1.1614866\n",
      "198 8 0.8269137144088745\n",
      "Validation loss: 1.2815418011319322 RMSE: 1.1320521\n",
      "Validation loss: 1.5250169291960454 RMSE: 1.2349159\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.478107077885518 Test RMSE: 1.2157744\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 780, 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'target': ['measured log solubility in mols per litre']}}\n",
      "Running on: cuda:1\n",
      "1127\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1127\n",
      "Generating scaffold 1000/1127\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 24.28147315979004\n",
      "Validation loss: 3.1562812201744688 RMSE: 1.7765925\n",
      "1 21 6.672726631164551\n",
      "Validation loss: 8.138504830081907 RMSE: 2.8528066\n",
      "Validation loss: 4.423093122718608 RMSE: 2.103115\n",
      "3 13 3.8782219886779785\n",
      "Validation loss: 5.7385882993715 RMSE: 2.3955352\n",
      "Validation loss: 1.8895785048999618 RMSE: 1.3746194\n",
      "5 5 2.585880756378174\n",
      "Validation loss: 3.3286843827340453 RMSE: 1.8244683\n",
      "6 26 2.185965061187744\n",
      "Validation loss: 2.179970637886925 RMSE: 1.4764723\n",
      "Validation loss: 1.7372721507485989 RMSE: 1.3180562\n",
      "8 18 2.2455570697784424\n",
      "Validation loss: 2.399325927801892 RMSE: 1.5489758\n",
      "Validation loss: 3.2490199245182816 RMSE: 1.8025038\n",
      "10 10 1.733512043952942\n",
      "Validation loss: 3.4687360430185774 RMSE: 1.8624543\n",
      "Validation loss: 3.5525414120834484 RMSE: 1.8848187\n",
      "12 2 1.4610861539840698\n",
      "Validation loss: 4.13544008795139 RMSE: 2.0335782\n",
      "13 23 2.3128490447998047\n",
      "Validation loss: 2.994625530411712 RMSE: 1.7304986\n",
      "Validation loss: 4.225729098362205 RMSE: 2.0556579\n",
      "15 15 2.5738871097564697\n",
      "Validation loss: 2.5054478413235826 RMSE: 1.5828607\n",
      "Validation loss: 3.5043814393271386 RMSE: 1.8719994\n",
      "17 7 1.1451352834701538\n",
      "Validation loss: 3.4965128434442843 RMSE: 1.8698965\n",
      "18 28 5.388759613037109\n",
      "Validation loss: 1.9683359850824407 RMSE: 1.4029739\n",
      "Validation loss: 2.3488704419769015 RMSE: 1.5326025\n",
      "20 20 1.3833770751953125\n",
      "Validation loss: 1.935417168963272 RMSE: 1.3911927\n",
      "Validation loss: 2.10755678404749 RMSE: 1.4517426\n",
      "22 12 1.2641265392303467\n",
      "Validation loss: 2.17185632422962 RMSE: 1.473722\n",
      "Validation loss: 2.9683495074246835 RMSE: 1.7228899\n",
      "24 4 1.7826642990112305\n",
      "Validation loss: 2.203670940567962 RMSE: 1.4844767\n",
      "25 25 1.082596778869629\n",
      "Validation loss: 2.87835227915671 RMSE: 1.6965708\n",
      "Validation loss: 2.1571858899783245 RMSE: 1.4687362\n",
      "27 17 1.1613624095916748\n",
      "Validation loss: 1.8799884076667044 RMSE: 1.3711267\n",
      "Validation loss: 2.782837251646329 RMSE: 1.6681838\n",
      "29 9 0.9213255643844604\n",
      "Validation loss: 1.8089401067885678 RMSE: 1.3449684\n",
      "Validation loss: 2.5191572936235276 RMSE: 1.5871853\n",
      "31 1 1.0787910223007202\n",
      "Validation loss: 2.377381039931711 RMSE: 1.5418758\n",
      "32 22 0.9171782732009888\n",
      "Validation loss: 1.9608552339857659 RMSE: 1.4003054\n",
      "Validation loss: 2.1720292156776497 RMSE: 1.4737806\n",
      "34 14 1.2958835363388062\n",
      "Validation loss: 2.412906665717606 RMSE: 1.5533533\n",
      "Validation loss: 2.2669270966960267 RMSE: 1.5056318\n",
      "36 6 1.235178828239441\n",
      "Validation loss: 2.268038447979277 RMSE: 1.5060008\n",
      "37 27 1.5889437198638916\n",
      "Validation loss: 2.364954782798227 RMSE: 1.5378411\n",
      "Validation loss: 2.219838420901678 RMSE: 1.4899123\n",
      "39 19 1.8070766925811768\n",
      "Validation loss: 2.08558669026974 RMSE: 1.444156\n",
      "Validation loss: 1.6917625929402038 RMSE: 1.3006777\n",
      "41 11 0.7910254001617432\n",
      "Validation loss: 2.223362342446251 RMSE: 1.4910945\n",
      "Validation loss: 2.309105565062666 RMSE: 1.5195742\n",
      "43 3 0.763301432132721\n",
      "Validation loss: 3.932900156595011 RMSE: 1.983154\n",
      "44 24 0.6914699077606201\n",
      "Validation loss: 1.909758028730882 RMSE: 1.38194\n",
      "Validation loss: 2.0287605808899465 RMSE: 1.4243456\n",
      "46 16 1.3229343891143799\n",
      "Validation loss: 1.8226499937276925 RMSE: 1.3500556\n",
      "Validation loss: 1.7959317696832977 RMSE: 1.3401238\n",
      "48 8 0.9261502027511597\n",
      "Validation loss: 1.7989284422545306 RMSE: 1.3412414\n",
      "Validation loss: 2.729887981330399 RMSE: 1.6522373\n",
      "50 0 0.6058372259140015\n",
      "Validation loss: 1.5070893785594839 RMSE: 1.2276357\n",
      "51 21 1.0936964750289917\n",
      "Validation loss: 2.088482791871096 RMSE: 1.4451584\n",
      "Validation loss: 2.3860093365728328 RMSE: 1.5446712\n",
      "53 13 0.9719915390014648\n",
      "Validation loss: 2.1961238352598342 RMSE: 1.4819324\n",
      "Validation loss: 1.8647353395951534 RMSE: 1.3655533\n",
      "55 5 0.8330711126327515\n",
      "Validation loss: 2.00558478642354 RMSE: 1.4161867\n",
      "56 26 0.45566272735595703\n",
      "Validation loss: 1.5334593532359706 RMSE: 1.2383293\n",
      "Validation loss: 2.1283486321964094 RMSE: 1.458886\n",
      "58 18 0.6984386444091797\n",
      "Validation loss: 1.6690932765471196 RMSE: 1.2919339\n",
      "Validation loss: 2.0182905872311214 RMSE: 1.4206655\n",
      "60 10 0.9599354267120361\n",
      "Validation loss: 2.449447678253714 RMSE: 1.5650712\n",
      "Validation loss: 2.090280437891462 RMSE: 1.4457802\n",
      "62 2 0.736655056476593\n",
      "Validation loss: 1.7482805093832776 RMSE: 1.3222256\n",
      "63 23 0.9228414297103882\n",
      "Validation loss: 1.9021145769980101 RMSE: 1.3791717\n",
      "Validation loss: 2.012432758787037 RMSE: 1.4186025\n",
      "65 15 0.7113698720932007\n",
      "Validation loss: 2.1510046119183563 RMSE: 1.4666303\n",
      "Validation loss: 1.719835335174493 RMSE: 1.3114249\n",
      "67 7 0.6454644203186035\n",
      "Validation loss: 2.3230017386706527 RMSE: 1.5241396\n",
      "68 28 3.081637144088745\n",
      "Validation loss: 2.2024306976689703 RMSE: 1.4840589\n",
      "Validation loss: 1.590803966058039 RMSE: 1.2612708\n",
      "70 20 1.384091854095459\n",
      "Validation loss: 1.7155183854356277 RMSE: 1.309778\n",
      "Validation loss: 1.8944007348170322 RMSE: 1.3763723\n",
      "72 12 0.6469866037368774\n",
      "Validation loss: 1.4795292932375343 RMSE: 1.216359\n",
      "Validation loss: 1.6167311636747512 RMSE: 1.2715074\n",
      "74 4 1.325545310974121\n",
      "Validation loss: 1.7252615458142442 RMSE: 1.3134921\n",
      "75 25 0.7917214035987854\n",
      "Validation loss: 2.022556026424982 RMSE: 1.422166\n",
      "Validation loss: 1.5773093194033192 RMSE: 1.2559097\n",
      "77 17 1.0295357704162598\n",
      "Validation loss: 2.2141496565489645 RMSE: 1.4880018\n",
      "Validation loss: 1.7165224488857573 RMSE: 1.3101611\n",
      "79 9 1.083846092224121\n",
      "Validation loss: 1.6489436489290896 RMSE: 1.284112\n",
      "Validation loss: 1.693766849230876 RMSE: 1.301448\n",
      "81 1 0.5883848667144775\n",
      "Validation loss: 1.6420866082199908 RMSE: 1.2814393\n",
      "82 22 0.5107907652854919\n",
      "Validation loss: 1.7459247207219621 RMSE: 1.3213345\n",
      "Validation loss: 2.0116878589697644 RMSE: 1.4183397\n",
      "84 14 0.38507187366485596\n",
      "Validation loss: 2.053409835933584 RMSE: 1.4329723\n",
      "Validation loss: 1.4513009997595727 RMSE: 1.2046995\n",
      "86 6 0.7867960929870605\n",
      "Validation loss: 1.8086876679310757 RMSE: 1.3448745\n",
      "87 27 0.5858714580535889\n",
      "Validation loss: 1.6990821023957918 RMSE: 1.3034884\n",
      "Validation loss: 1.754613115724209 RMSE: 1.3246181\n",
      "89 19 1.1540929079055786\n",
      "Validation loss: 1.8823057571343615 RMSE: 1.3719715\n",
      "Validation loss: 1.7739071993701225 RMSE: 1.3318812\n",
      "91 11 0.7089870572090149\n",
      "Validation loss: 1.9001173719895625 RMSE: 1.3784474\n",
      "Validation loss: 2.033105594921956 RMSE: 1.4258702\n",
      "93 3 0.6331202387809753\n",
      "Validation loss: 1.8348190868850303 RMSE: 1.354555\n",
      "94 24 0.764941930770874\n",
      "Validation loss: 2.1120180461259013 RMSE: 1.4532784\n",
      "Validation loss: 1.5431952371006519 RMSE: 1.2422541\n",
      "96 16 0.8209579586982727\n",
      "Validation loss: 2.208839681296222 RMSE: 1.4862165\n",
      "Validation loss: 1.4506413124303903 RMSE: 1.2044257\n",
      "98 8 0.8903874754905701\n",
      "Validation loss: 1.6056924214405297 RMSE: 1.2671592\n",
      "Validation loss: 2.812126693472398 RMSE: 1.6769397\n",
      "100 0 0.2894671559333801\n",
      "Validation loss: 2.1602486414191997 RMSE: 1.4697784\n",
      "101 21 1.2837883234024048\n",
      "Validation loss: 1.580593245746815 RMSE: 1.2572165\n",
      "Validation loss: 1.6127598644357868 RMSE: 1.2699448\n",
      "103 13 0.34867364168167114\n",
      "Validation loss: 1.4764382575465516 RMSE: 1.2150877\n",
      "Validation loss: 1.5302695763849579 RMSE: 1.2370405\n",
      "105 5 0.6502774953842163\n",
      "Validation loss: 2.2054163628974846 RMSE: 1.4850644\n",
      "106 26 0.4094301164150238\n",
      "Validation loss: 1.4696008357326542 RMSE: 1.2122709\n",
      "Validation loss: 1.8077692816742754 RMSE: 1.3445331\n",
      "108 18 0.5566900372505188\n",
      "Validation loss: 1.844937107204336 RMSE: 1.3582846\n",
      "Validation loss: 1.7910580002101122 RMSE: 1.3383042\n",
      "110 10 1.1179980039596558\n",
      "Validation loss: 1.4442629940741885 RMSE: 1.201775\n",
      "Validation loss: 1.5315464587338203 RMSE: 1.2375566\n",
      "112 2 0.7269856333732605\n",
      "Validation loss: 1.3878534441500638 RMSE: 1.178072\n",
      "113 23 0.3201742172241211\n",
      "Validation loss: 1.4521333126895195 RMSE: 1.205045\n",
      "Validation loss: 1.6363534378794442 RMSE: 1.2792003\n",
      "115 15 1.0368080139160156\n",
      "Validation loss: 1.8154866357820223 RMSE: 1.3474\n",
      "Validation loss: 1.8246136545079998 RMSE: 1.3507826\n",
      "117 7 0.5495200753211975\n",
      "Validation loss: 1.5573545599405745 RMSE: 1.2479402\n",
      "118 28 0.7620777487754822\n",
      "Validation loss: 1.829416971291061 RMSE: 1.3525594\n",
      "Validation loss: 1.396426506802044 RMSE: 1.1817049\n",
      "120 20 0.27607178688049316\n",
      "Validation loss: 2.1893446920192345 RMSE: 1.4796435\n",
      "Validation loss: 1.3337083796484281 RMSE: 1.154863\n",
      "122 12 0.6126989126205444\n",
      "Validation loss: 1.9071123125278844 RMSE: 1.3809824\n",
      "Validation loss: 1.4453953061483602 RMSE: 1.2022461\n",
      "124 4 1.4400273561477661\n",
      "Validation loss: 1.3764754881901025 RMSE: 1.1732329\n",
      "125 25 0.3229820728302002\n",
      "Validation loss: 1.269546176479981 RMSE: 1.1267414\n",
      "Validation loss: 1.6931908826912399 RMSE: 1.3012266\n",
      "127 17 0.948071300983429\n",
      "Validation loss: 1.9309286501555316 RMSE: 1.3895786\n",
      "Validation loss: 1.4439874085704838 RMSE: 1.2016604\n",
      "129 9 0.9274769425392151\n",
      "Validation loss: 1.7485643382621023 RMSE: 1.322333\n",
      "Validation loss: 1.590392147545266 RMSE: 1.2611074\n",
      "131 1 0.48441535234451294\n",
      "Validation loss: 1.4538864910075096 RMSE: 1.2057722\n",
      "132 22 0.6419546604156494\n",
      "Validation loss: 1.4584821241091839 RMSE: 1.2076763\n",
      "Validation loss: 1.4991889970492474 RMSE: 1.2244138\n",
      "134 14 0.710233747959137\n",
      "Validation loss: 1.5431929752889988 RMSE: 1.2422532\n",
      "Validation loss: 1.3838856357388791 RMSE: 1.1763867\n",
      "136 6 0.4420701861381531\n",
      "Validation loss: 1.5254260269941482 RMSE: 1.2350814\n",
      "137 27 0.8017788529396057\n",
      "Validation loss: 1.6362003879209535 RMSE: 1.2791405\n",
      "Validation loss: 1.8017247029110395 RMSE: 1.3422834\n",
      "139 19 0.9143367409706116\n",
      "Validation loss: 1.69955415746807 RMSE: 1.3036696\n",
      "Validation loss: 1.5593833838943887 RMSE: 1.2487526\n",
      "141 11 0.5132409334182739\n",
      "Validation loss: 1.7465252897380728 RMSE: 1.3215617\n",
      "Validation loss: 1.4600687554452272 RMSE: 1.208333\n",
      "143 3 0.6348715424537659\n",
      "Validation loss: 1.6030934141800466 RMSE: 1.2661332\n",
      "144 24 0.3075338304042816\n",
      "Validation loss: 1.3003367628671427 RMSE: 1.140323\n",
      "Validation loss: 1.5701517921633426 RMSE: 1.253057\n",
      "146 16 0.410136878490448\n",
      "Validation loss: 1.4330804875466676 RMSE: 1.1971134\n",
      "Validation loss: 1.463262482027037 RMSE: 1.2096539\n",
      "148 8 0.6126508712768555\n",
      "Validation loss: 1.693036117384919 RMSE: 1.3011671\n",
      "Validation loss: 1.608534440530085 RMSE: 1.2682801\n",
      "150 0 0.34324175119400024\n",
      "Validation loss: 1.5371207193990724 RMSE: 1.2398068\n",
      "151 21 1.8273249864578247\n",
      "Validation loss: 2.8991456306086176 RMSE: 1.7026879\n",
      "Validation loss: 1.3948056054326285 RMSE: 1.181019\n",
      "153 13 0.4568632245063782\n",
      "Validation loss: 1.4624904003818477 RMSE: 1.2093347\n",
      "Validation loss: 1.543050777595655 RMSE: 1.242196\n",
      "155 5 0.3019370436668396\n",
      "Validation loss: 1.3945689802676176 RMSE: 1.1809187\n",
      "156 26 0.5176113247871399\n",
      "Validation loss: 1.504471415967013 RMSE: 1.2265688\n",
      "Validation loss: 1.6918637499345088 RMSE: 1.3007166\n",
      "158 18 0.4156278669834137\n",
      "Validation loss: 1.363210131636763 RMSE: 1.167566\n",
      "Validation loss: 1.615841500527036 RMSE: 1.2711575\n",
      "160 10 1.0357062816619873\n",
      "Validation loss: 1.8556856476100145 RMSE: 1.3622355\n",
      "Validation loss: 1.5615557527120134 RMSE: 1.2496221\n",
      "162 2 1.0451929569244385\n",
      "Validation loss: 1.3960688715487455 RMSE: 1.1815536\n",
      "163 23 0.6747641563415527\n",
      "Validation loss: 1.4293778723320074 RMSE: 1.1955659\n",
      "Validation loss: 1.6667892953990835 RMSE: 1.2910419\n",
      "165 15 0.3009050190448761\n",
      "Validation loss: 1.5793189221778803 RMSE: 1.2567096\n",
      "Validation loss: 1.5298747541630162 RMSE: 1.236881\n",
      "167 7 0.3710091710090637\n",
      "Validation loss: 1.4091588891712965 RMSE: 1.18708\n",
      "168 28 0.1689598709344864\n",
      "Validation loss: 1.3436343838683271 RMSE: 1.1591525\n",
      "Validation loss: 1.603562035391816 RMSE: 1.2663183\n",
      "170 20 0.47715309262275696\n",
      "Validation loss: 1.395903903826148 RMSE: 1.1814837\n",
      "Validation loss: 1.559747890033553 RMSE: 1.2488987\n",
      "172 12 0.5535060167312622\n",
      "Validation loss: 1.5794717284430444 RMSE: 1.2567704\n",
      "Validation loss: 1.4189274226669717 RMSE: 1.1911874\n",
      "174 4 0.43247172236442566\n",
      "Validation loss: 1.2375462282020433 RMSE: 1.1124505\n",
      "175 25 0.7477384805679321\n",
      "Validation loss: 1.547837917783619 RMSE: 1.2441213\n",
      "Validation loss: 1.423268171538294 RMSE: 1.1930081\n",
      "177 17 0.3747866451740265\n",
      "Validation loss: 1.2774589304375437 RMSE: 1.1302472\n",
      "Validation loss: 1.372475079203074 RMSE: 1.1715268\n",
      "179 9 0.38236188888549805\n",
      "Validation loss: 1.1792481082730588 RMSE: 1.0859319\n",
      "Validation loss: 1.211442310725693 RMSE: 1.1006554\n",
      "181 1 0.4547228515148163\n",
      "Validation loss: 1.431003950338448 RMSE: 1.1962458\n",
      "182 22 0.3415118157863617\n",
      "Validation loss: 1.6487302632458443 RMSE: 1.2840289\n",
      "Validation loss: 1.4903099199311922 RMSE: 1.2207825\n",
      "184 14 0.4623487591743469\n",
      "Validation loss: 1.3570046192776841 RMSE: 1.1649054\n",
      "Validation loss: 1.33813661917121 RMSE: 1.1567786\n",
      "186 6 0.4253472089767456\n",
      "Validation loss: 1.2264572033839942 RMSE: 1.1074554\n",
      "187 27 0.42454496026039124\n",
      "Validation loss: 1.3740938089590158 RMSE: 1.1722175\n",
      "Validation loss: 1.5896524201452205 RMSE: 1.2608142\n",
      "189 19 0.29971233010292053\n",
      "Validation loss: 1.458831879944928 RMSE: 1.2078211\n",
      "Validation loss: 1.1890645997714153 RMSE: 1.0904423\n",
      "191 11 0.4177011549472809\n",
      "Validation loss: 1.3783773880089278 RMSE: 1.1740432\n",
      "Validation loss: 1.1963470298632057 RMSE: 1.0937765\n",
      "193 3 0.2760004997253418\n",
      "Validation loss: 1.4740764271896498 RMSE: 1.2141155\n",
      "194 24 0.3745940625667572\n",
      "Validation loss: 1.368359633251629 RMSE: 1.169769\n",
      "Validation loss: 1.4199826432540354 RMSE: 1.1916302\n",
      "196 16 0.7125635147094727\n",
      "Validation loss: 1.4841874363148106 RMSE: 1.2182723\n",
      "Validation loss: 1.3406585750326645 RMSE: 1.1578681\n",
      "198 8 0.6729446053504944\n",
      "Validation loss: 1.5321819560717693 RMSE: 1.2378135\n",
      "Validation loss: 1.672224966825637 RMSE: 1.2931454\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.4642904131813388 Test RMSE: 1.2100786\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'target': ['measured log solubility in mols per litre']}}\n",
      "Running on: cuda:1\n",
      "1127\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1127\n",
      "Generating scaffold 1000/1127\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 21.872943878173828\n",
      "Validation loss: 5.302161615506738 RMSE: 2.3026426\n",
      "1 21 5.257112503051758\n",
      "Validation loss: 2.2669246471033686 RMSE: 1.505631\n",
      "Validation loss: 2.5008512450530467 RMSE: 1.5814081\n",
      "3 13 3.5502004623413086\n",
      "Validation loss: 2.9340418809283095 RMSE: 1.7129046\n",
      "Validation loss: 2.030925374115463 RMSE: 1.4251055\n",
      "5 5 2.9385921955108643\n",
      "Validation loss: 4.504502642471178 RMSE: 2.1223814\n",
      "6 26 1.8524677753448486\n",
      "Validation loss: 1.8224375184658355 RMSE: 1.3499769\n",
      "Validation loss: 2.9252495048320397 RMSE: 1.7103362\n",
      "8 18 2.1116397380828857\n",
      "Validation loss: 2.851647651301021 RMSE: 1.6886822\n",
      "Validation loss: 2.52672160515743 RMSE: 1.5895665\n",
      "10 10 2.7336812019348145\n",
      "Validation loss: 2.3376153042886108 RMSE: 1.5289261\n",
      "Validation loss: 3.503254303889992 RMSE: 1.8716983\n",
      "12 2 2.84584903717041\n",
      "Validation loss: 3.412494786017764 RMSE: 1.847294\n",
      "13 23 2.2272238731384277\n",
      "Validation loss: 2.2842139058408484 RMSE: 1.5113616\n",
      "Validation loss: 1.9495716485302006 RMSE: 1.3962706\n",
      "15 15 1.541883945465088\n",
      "Validation loss: 2.6390689284400604 RMSE: 1.6245211\n",
      "Validation loss: 2.6822597020495254 RMSE: 1.6377606\n",
      "17 7 1.697521686553955\n",
      "Validation loss: 1.9674411347482057 RMSE: 1.402655\n",
      "18 28 2.072965383529663\n",
      "Validation loss: 2.587661909846078 RMSE: 1.6086212\n",
      "Validation loss: 2.8503935695749467 RMSE: 1.6883109\n",
      "20 20 1.4505372047424316\n",
      "Validation loss: 2.618306886833326 RMSE: 1.6181183\n",
      "Validation loss: 2.4197732051916883 RMSE: 1.555562\n",
      "22 12 1.554697871208191\n",
      "Validation loss: 2.496657953853101 RMSE: 1.5800816\n",
      "Validation loss: 1.7664093696965582 RMSE: 1.3290634\n",
      "24 4 1.1557456254959106\n",
      "Validation loss: 2.3879248610639996 RMSE: 1.5452913\n",
      "25 25 0.9527400135993958\n",
      "Validation loss: 2.0865826184770704 RMSE: 1.4445009\n",
      "Validation loss: 2.90842127378008 RMSE: 1.7054094\n",
      "27 17 0.8854323625564575\n",
      "Validation loss: 2.353286122853777 RMSE: 1.5340424\n",
      "Validation loss: 2.0455744414202934 RMSE: 1.4302359\n",
      "29 9 1.3362025022506714\n",
      "Validation loss: 2.1753082971657274 RMSE: 1.4748927\n",
      "Validation loss: 1.6622958109442112 RMSE: 1.2893006\n",
      "31 1 1.071638584136963\n",
      "Validation loss: 2.2665380418828103 RMSE: 1.5055026\n",
      "32 22 1.5872859954833984\n",
      "Validation loss: 2.493854670398003 RMSE: 1.5791943\n",
      "Validation loss: 2.307846135797754 RMSE: 1.5191598\n",
      "34 14 1.3242660760879517\n",
      "Validation loss: 2.968463665616196 RMSE: 1.722923\n",
      "Validation loss: 2.047382650122178 RMSE: 1.4308678\n",
      "36 6 1.1206083297729492\n",
      "Validation loss: 1.9928269702776344 RMSE: 1.4116752\n",
      "37 27 1.1190059185028076\n",
      "Validation loss: 3.1613927625976834 RMSE: 1.7780306\n",
      "Validation loss: 1.9241014518569002 RMSE: 1.3871199\n",
      "39 19 1.3680143356323242\n",
      "Validation loss: 2.3138061033940946 RMSE: 1.5211201\n",
      "Validation loss: 1.8514969464951911 RMSE: 1.3606973\n",
      "41 11 0.9112111330032349\n",
      "Validation loss: 2.235366376100388 RMSE: 1.4951142\n",
      "Validation loss: 2.216125030433182 RMSE: 1.4886655\n",
      "43 3 0.8963385820388794\n",
      "Validation loss: 2.3328970839491987 RMSE: 1.5273823\n",
      "44 24 1.2061642408370972\n",
      "Validation loss: 1.640099046504603 RMSE: 1.2806635\n",
      "Validation loss: 2.2147890308261973 RMSE: 1.4882168\n",
      "46 16 1.3314852714538574\n",
      "Validation loss: 1.7776407879010765 RMSE: 1.333282\n",
      "Validation loss: 1.9161999046275047 RMSE: 1.3842686\n",
      "48 8 0.8795663714408875\n",
      "Validation loss: 2.142909147043144 RMSE: 1.4638679\n",
      "Validation loss: 1.9420395593727584 RMSE: 1.3935708\n",
      "50 0 0.7026972770690918\n",
      "Validation loss: 2.584121144978346 RMSE: 1.6075201\n",
      "51 21 0.6346903443336487\n",
      "Validation loss: 2.1091268505670326 RMSE: 1.4522833\n",
      "Validation loss: 1.8584266668927354 RMSE: 1.3632413\n",
      "53 13 0.6510050892829895\n",
      "Validation loss: 1.7704818491387155 RMSE: 1.3305945\n",
      "Validation loss: 1.5829809049589445 RMSE: 1.2581657\n",
      "55 5 0.9207108616828918\n",
      "Validation loss: 1.6637085095971031 RMSE: 1.2898482\n",
      "56 26 0.6866438388824463\n",
      "Validation loss: 2.7061380643760207 RMSE: 1.6450343\n",
      "Validation loss: 1.6782475403979815 RMSE: 1.2954719\n",
      "58 18 0.4134383201599121\n",
      "Validation loss: 2.128749081518798 RMSE: 1.4590234\n",
      "Validation loss: 1.9290069521000954 RMSE: 1.3888869\n",
      "60 10 1.9281516075134277\n",
      "Validation loss: 1.8291234447892788 RMSE: 1.352451\n",
      "Validation loss: 1.8915327302122538 RMSE: 1.37533\n",
      "62 2 0.8291465044021606\n",
      "Validation loss: 1.3676690411778678 RMSE: 1.1694738\n",
      "63 23 0.6368050575256348\n",
      "Validation loss: 1.756284418359267 RMSE: 1.3252488\n",
      "Validation loss: 1.6050953052740182 RMSE: 1.2669235\n",
      "65 15 0.8915202617645264\n",
      "Validation loss: 1.6298909387757292 RMSE: 1.2766718\n",
      "Validation loss: 2.3166212529207755 RMSE: 1.5220451\n",
      "67 7 0.8566039800643921\n",
      "Validation loss: 2.30653945851115 RMSE: 1.5187294\n",
      "68 28 2.51413893699646\n",
      "Validation loss: 1.520687218260976 RMSE: 1.2331614\n",
      "Validation loss: 2.0348243017112257 RMSE: 1.4264727\n",
      "70 20 1.244893193244934\n",
      "Validation loss: 1.8351555018298393 RMSE: 1.3546791\n",
      "Validation loss: 1.728614375654575 RMSE: 1.3147678\n",
      "72 12 1.067611813545227\n",
      "Validation loss: 1.8059022067922406 RMSE: 1.3438386\n",
      "Validation loss: 2.0766074087767477 RMSE: 1.4410439\n",
      "74 4 1.0976407527923584\n",
      "Validation loss: 1.7471847655498876 RMSE: 1.3218111\n",
      "75 25 0.5998287200927734\n",
      "Validation loss: 1.7128746330210594 RMSE: 1.3087683\n",
      "Validation loss: 2.1144906883746124 RMSE: 1.4541287\n",
      "77 17 0.7572926878929138\n",
      "Validation loss: 1.6647052638298643 RMSE: 1.2902346\n",
      "Validation loss: 2.542789291491551 RMSE: 1.5946126\n",
      "79 9 0.6348084211349487\n",
      "Validation loss: 2.0599055353519136 RMSE: 1.435237\n",
      "Validation loss: 2.0642961917725287 RMSE: 1.4367658\n",
      "81 1 0.561629056930542\n",
      "Validation loss: 1.844261247499854 RMSE: 1.3580358\n",
      "82 22 0.4693751335144043\n",
      "Validation loss: 1.5680567996691814 RMSE: 1.2522207\n",
      "Validation loss: 1.7729029676555532 RMSE: 1.3315041\n",
      "84 14 0.48046278953552246\n",
      "Validation loss: 1.891223550897784 RMSE: 1.3752176\n",
      "Validation loss: 1.8678369511545232 RMSE: 1.3666884\n",
      "86 6 0.9228560924530029\n",
      "Validation loss: 1.551150568818624 RMSE: 1.245452\n",
      "87 27 0.4659002423286438\n",
      "Validation loss: 2.0025107839466196 RMSE: 1.4151009\n",
      "Validation loss: 1.849774834329048 RMSE: 1.3600643\n",
      "89 19 0.6117491722106934\n",
      "Validation loss: 1.4672778997801046 RMSE: 1.2113124\n",
      "Validation loss: 1.7657386328266784 RMSE: 1.3288109\n",
      "91 11 0.8642514944076538\n",
      "Validation loss: 1.638468897448177 RMSE: 1.280027\n",
      "Validation loss: 2.445659489758247 RMSE: 1.5638603\n",
      "93 3 0.5282621383666992\n",
      "Validation loss: 1.9727879477813182 RMSE: 1.4045596\n",
      "94 24 0.5338872075080872\n",
      "Validation loss: 2.0157737594790164 RMSE: 1.4197795\n",
      "Validation loss: 1.8153523407151213 RMSE: 1.3473501\n",
      "96 16 0.6681658625602722\n",
      "Validation loss: 1.7700321421159053 RMSE: 1.3304255\n",
      "Validation loss: 1.5014793134368627 RMSE: 1.2253486\n",
      "98 8 0.6531285047531128\n",
      "Validation loss: 1.8277218452597086 RMSE: 1.3519326\n",
      "Validation loss: 1.739315485532305 RMSE: 1.3188311\n",
      "100 0 0.8669905066490173\n",
      "Validation loss: 1.7220574765078789 RMSE: 1.3122718\n",
      "101 21 0.5592549443244934\n",
      "Validation loss: 1.5146177389980418 RMSE: 1.230698\n",
      "Validation loss: 1.550986334285905 RMSE: 1.245386\n",
      "103 13 0.5551528930664062\n",
      "Validation loss: 1.6191569271340835 RMSE: 1.2724609\n",
      "Validation loss: 1.8876537195349161 RMSE: 1.3739191\n",
      "105 5 0.6889978647232056\n",
      "Validation loss: 1.9374425959798087 RMSE: 1.3919206\n",
      "106 26 0.6280533075332642\n",
      "Validation loss: 1.58858342824784 RMSE: 1.2603902\n",
      "Validation loss: 1.5734505421292466 RMSE: 1.2543726\n",
      "108 18 0.6701686382293701\n",
      "Validation loss: 1.8915700532693778 RMSE: 1.3753436\n",
      "Validation loss: 1.7888820635533966 RMSE: 1.337491\n",
      "110 10 0.5270704030990601\n",
      "Validation loss: 1.5883991960930612 RMSE: 1.2603171\n",
      "Validation loss: 1.8372866817280256 RMSE: 1.3554654\n",
      "112 2 0.5939035415649414\n",
      "Validation loss: 1.5339139963673278 RMSE: 1.2385128\n",
      "113 23 0.4448884129524231\n",
      "Validation loss: 1.809336227653301 RMSE: 1.3451158\n",
      "Validation loss: 1.5137487491675183 RMSE: 1.230345\n",
      "115 15 0.4059543311595917\n",
      "Validation loss: 1.5975902080535889 RMSE: 1.2639581\n",
      "Validation loss: 1.586796427195051 RMSE: 1.2596811\n",
      "117 7 0.7112289667129517\n",
      "Validation loss: 1.4908336063401888 RMSE: 1.220997\n",
      "118 28 0.15707513689994812\n",
      "Validation loss: 1.6418637817939825 RMSE: 1.2813524\n",
      "Validation loss: 1.472273254816511 RMSE: 1.2133727\n",
      "120 20 0.5504111647605896\n",
      "Validation loss: 2.76940736517442 RMSE: 1.6641536\n",
      "Validation loss: 2.078767876709457 RMSE: 1.4417932\n",
      "122 12 0.6566139459609985\n",
      "Validation loss: 2.0748702045035574 RMSE: 1.440441\n",
      "Validation loss: 1.2673945938591409 RMSE: 1.1257863\n",
      "124 4 0.7684006690979004\n",
      "Validation loss: 1.373332986789467 RMSE: 1.1718929\n",
      "125 25 0.5391848683357239\n",
      "Validation loss: 1.6152080455712512 RMSE: 1.2709084\n",
      "Validation loss: 1.6261044455840525 RMSE: 1.275188\n",
      "127 17 1.175784945487976\n",
      "Validation loss: 1.4680058734606853 RMSE: 1.2116129\n",
      "Validation loss: 1.7617511918059492 RMSE: 1.3273098\n",
      "129 9 0.3762637674808502\n",
      "Validation loss: 1.7632525230930969 RMSE: 1.3278751\n",
      "Validation loss: 1.390150434147995 RMSE: 1.1790465\n",
      "131 1 0.3779047131538391\n",
      "Validation loss: 1.5944412661864695 RMSE: 1.2627118\n",
      "132 22 0.4800684452056885\n",
      "Validation loss: 1.6688176171969524 RMSE: 1.2918272\n",
      "Validation loss: 1.4964982397788393 RMSE: 1.2233145\n",
      "134 14 0.36922210454940796\n",
      "Validation loss: 1.873750295786731 RMSE: 1.36885\n",
      "Validation loss: 1.4917824036252183 RMSE: 1.2213855\n",
      "136 6 0.6401997804641724\n",
      "Validation loss: 1.4863019622532667 RMSE: 1.2191398\n",
      "137 27 0.22529101371765137\n",
      "Validation loss: 1.392730677022343 RMSE: 1.1801401\n",
      "Validation loss: 1.3897846884432092 RMSE: 1.1788913\n",
      "139 19 0.5204856395721436\n",
      "Validation loss: 1.585453791955931 RMSE: 1.2591481\n",
      "Validation loss: 1.58221822080359 RMSE: 1.2578626\n",
      "141 11 0.39437878131866455\n",
      "Validation loss: 1.7201134694361053 RMSE: 1.311531\n",
      "Validation loss: 1.5014847822948896 RMSE: 1.225351\n",
      "143 3 0.30159103870391846\n",
      "Validation loss: 1.4684894169326377 RMSE: 1.2118124\n",
      "144 24 0.2641271650791168\n",
      "Validation loss: 1.5207182474895917 RMSE: 1.2331741\n",
      "Validation loss: 1.5409426372663109 RMSE: 1.2413471\n",
      "146 16 0.4213796555995941\n",
      "Validation loss: 1.449158572517665 RMSE: 1.20381\n",
      "Validation loss: 1.3832515108901842 RMSE: 1.1761171\n",
      "148 8 0.3557869493961334\n",
      "Validation loss: 1.4066185112548086 RMSE: 1.1860095\n",
      "Validation loss: 1.6901869911008176 RMSE: 1.3000718\n",
      "150 0 0.5843067765235901\n",
      "Validation loss: 1.4685583663197745 RMSE: 1.2118409\n",
      "151 21 0.6940903067588806\n",
      "Validation loss: 1.2686977186034212 RMSE: 1.1263648\n",
      "Validation loss: 1.566761513726901 RMSE: 1.2517034\n",
      "153 13 0.6574761271476746\n",
      "Validation loss: 1.3747143344541566 RMSE: 1.1724821\n",
      "Validation loss: 1.366452409630328 RMSE: 1.1689535\n",
      "155 5 0.6326799988746643\n",
      "Validation loss: 1.25429993182157 RMSE: 1.1199553\n",
      "156 26 0.6711982488632202\n",
      "Validation loss: 1.3054533869819303 RMSE: 1.1425644\n",
      "Validation loss: 1.5769018114140603 RMSE: 1.2557476\n",
      "158 18 0.6583707332611084\n",
      "Validation loss: 1.3726635823207618 RMSE: 1.1716073\n",
      "Validation loss: 1.3144408316738838 RMSE: 1.1464907\n",
      "160 10 0.6721588373184204\n",
      "Validation loss: 1.4560991114219732 RMSE: 1.2066894\n",
      "Validation loss: 1.442735439908188 RMSE: 1.2011391\n",
      "162 2 0.9224435687065125\n",
      "Validation loss: 1.4415906952545705 RMSE: 1.2006625\n",
      "163 23 0.7818130850791931\n",
      "Validation loss: 1.4813130904087979 RMSE: 1.217092\n",
      "Validation loss: 1.4257182494728966 RMSE: 1.1940345\n",
      "165 15 0.48762762546539307\n",
      "Validation loss: 1.6138248464702505 RMSE: 1.270364\n",
      "Validation loss: 1.6348724998204054 RMSE: 1.2786213\n",
      "167 7 0.5556694865226746\n",
      "Validation loss: 1.3829243125113766 RMSE: 1.1759781\n",
      "168 28 0.5572792291641235\n",
      "Validation loss: 1.254750278143756 RMSE: 1.1201564\n",
      "Validation loss: 1.7112826172229463 RMSE: 1.30816\n",
      "170 20 0.8284208178520203\n",
      "Validation loss: 1.391943069685877 RMSE: 1.1798064\n",
      "Validation loss: 1.4741037725347332 RMSE: 1.2141267\n",
      "172 12 0.39105066657066345\n",
      "Validation loss: 1.3575488729814513 RMSE: 1.165139\n",
      "Validation loss: 1.380645173840818 RMSE: 1.1750085\n",
      "174 4 0.7757343053817749\n",
      "Validation loss: 1.4782237879997862 RMSE: 1.2158223\n",
      "175 25 0.32097649574279785\n",
      "Validation loss: 1.2377732433049025 RMSE: 1.1125526\n",
      "Validation loss: 1.185442133287413 RMSE: 1.08878\n",
      "177 17 0.7031053304672241\n",
      "Validation loss: 1.4809224953693627 RMSE: 1.2169316\n",
      "Validation loss: 1.3888470303695815 RMSE: 1.1784935\n",
      "179 9 0.3298426866531372\n",
      "Validation loss: 1.3984260052706288 RMSE: 1.1825507\n",
      "Validation loss: 1.3888862312367531 RMSE: 1.1785102\n",
      "181 1 0.31123706698417664\n",
      "Validation loss: 1.49947048288531 RMSE: 1.2245286\n",
      "182 22 0.4423717260360718\n",
      "Validation loss: 1.7117065455006286 RMSE: 1.3083221\n",
      "Validation loss: 1.4549441400882417 RMSE: 1.2062106\n",
      "184 14 0.6306347250938416\n",
      "Validation loss: 1.7589345168223423 RMSE: 1.3262483\n",
      "Validation loss: 1.4239349708092952 RMSE: 1.1932874\n",
      "186 6 0.5493991374969482\n",
      "Validation loss: 1.639109506016284 RMSE: 1.2802771\n",
      "187 27 0.3983065187931061\n",
      "Validation loss: 1.246138996782556 RMSE: 1.1163061\n",
      "Validation loss: 1.4023503339396113 RMSE: 1.1842088\n",
      "189 19 0.5325638055801392\n",
      "Validation loss: 1.2522960447632105 RMSE: 1.1190603\n",
      "Validation loss: 1.5117382370265184 RMSE: 1.2295276\n",
      "191 11 0.5256651639938354\n",
      "Validation loss: 1.3928556790394067 RMSE: 1.1801931\n",
      "Validation loss: 1.3762273788452148 RMSE: 1.1731272\n",
      "193 3 0.42525652050971985\n",
      "Validation loss: 1.284667222900728 RMSE: 1.1334317\n",
      "194 24 0.34381425380706787\n",
      "Validation loss: 1.2481975703112846 RMSE: 1.1172277\n",
      "Validation loss: 1.4898255567635055 RMSE: 1.2205842\n",
      "196 16 0.5309672951698303\n",
      "Validation loss: 1.2202208833356873 RMSE: 1.1046361\n",
      "Validation loss: 1.3597802704414435 RMSE: 1.1660961\n",
      "198 8 0.3228370249271393\n",
      "Validation loss: 1.3200183621550028 RMSE: 1.1489205\n",
      "Validation loss: 1.6322690185192412 RMSE: 1.2776029\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.2994211084019822 Test RMSE: 1.1399215\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'target': ['exp']}}\n",
      "Running on: cuda:1\n",
      "4199\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/4199\n",
      "Generating scaffold 1000/4199\n",
      "Generating scaffold 2000/4199\n",
      "Generating scaffold 3000/4199\n",
      "Generating scaffold 4000/4199\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 14.3896484375\n",
      "0 50 3.113877296447754\n",
      "0 100 2.6111130714416504\n",
      "Validation loss: 1.317732452210926 RMSE: 1.1479253\n",
      "1 45 2.1747961044311523\n",
      "1 95 1.7820382118225098\n",
      "Validation loss: 1.1836394994031816 RMSE: 1.087952\n",
      "2 40 1.2876341342926025\n",
      "2 90 1.2459263801574707\n",
      "Validation loss: 1.0107255481538318 RMSE: 1.0053484\n",
      "3 35 1.25664484500885\n",
      "3 85 1.1913843154907227\n",
      "Validation loss: 0.964059313138326 RMSE: 0.9818652\n",
      "4 30 0.8707990646362305\n",
      "4 80 1.1332824230194092\n",
      "Validation loss: 0.8452539654005141 RMSE: 0.91937697\n",
      "5 25 1.1659672260284424\n",
      "5 75 0.8732553720474243\n",
      "Validation loss: 0.9397269737152826 RMSE: 0.96939516\n",
      "6 20 0.7974990606307983\n",
      "6 70 0.8896124958992004\n",
      "Validation loss: 1.12639160326549 RMSE: 1.061316\n",
      "7 15 0.97328782081604\n",
      "7 65 0.6744867563247681\n",
      "Validation loss: 0.8246294861748105 RMSE: 0.9080911\n",
      "8 10 1.0570390224456787\n",
      "8 60 1.402776837348938\n",
      "Validation loss: 1.085169505363419 RMSE: 1.0417147\n",
      "9 5 1.0339308977127075\n",
      "9 55 0.63572096824646\n",
      "Validation loss: 0.9685350239276886 RMSE: 0.98414177\n",
      "10 0 0.9093134999275208\n",
      "10 50 0.7229585647583008\n",
      "10 100 0.957123339176178\n",
      "Validation loss: 0.9207027128764561 RMSE: 0.95953256\n",
      "11 45 0.7996889352798462\n",
      "11 95 0.7951428890228271\n",
      "Validation loss: 0.8576521016302563 RMSE: 0.92609507\n",
      "12 40 0.6167348623275757\n",
      "12 90 0.8038992881774902\n",
      "Validation loss: 1.028050688902537 RMSE: 1.0139283\n",
      "13 35 0.7193524837493896\n",
      "13 85 0.5346534252166748\n",
      "Validation loss: 0.7992763428460984 RMSE: 0.8940225\n",
      "14 30 0.8331276178359985\n",
      "14 80 0.8732357621192932\n",
      "Validation loss: 0.7256721559024992 RMSE: 0.8518639\n",
      "15 25 0.6962882876396179\n",
      "15 75 0.4974289536476135\n",
      "Validation loss: 0.7621474618003482 RMSE: 0.8730106\n",
      "16 20 0.7273223996162415\n",
      "16 70 0.8254419565200806\n",
      "Validation loss: 0.6678548483621507 RMSE: 0.81722385\n",
      "17 15 1.1080981492996216\n",
      "17 65 0.6723770499229431\n",
      "Validation loss: 0.6645367971488407 RMSE: 0.81519127\n",
      "18 10 1.0454455614089966\n",
      "18 60 0.4760477840900421\n",
      "Validation loss: 0.7226995939300174 RMSE: 0.8501174\n",
      "19 5 0.9093483090400696\n",
      "19 55 0.47391650080680847\n",
      "Validation loss: 0.6681243135815575 RMSE: 0.81738865\n",
      "20 0 0.5497781038284302\n",
      "20 50 0.706207811832428\n",
      "20 100 0.7731291651725769\n",
      "Validation loss: 0.7387587229410807 RMSE: 0.8595108\n",
      "21 45 0.8171052932739258\n",
      "21 95 0.452001690864563\n",
      "Validation loss: 0.6525074192455836 RMSE: 0.8077794\n",
      "22 40 0.8044106960296631\n",
      "22 90 0.4817086160182953\n",
      "Validation loss: 0.8590162515640258 RMSE: 0.9268313\n",
      "23 35 0.9298256635665894\n",
      "23 85 0.3608477711677551\n",
      "Validation loss: 0.6851954164959135 RMSE: 0.8277653\n",
      "24 30 0.4803810715675354\n",
      "24 80 0.3944990038871765\n",
      "Validation loss: 0.6205080032348633 RMSE: 0.7877233\n",
      "25 25 0.6091755628585815\n",
      "25 75 0.9846609234809875\n",
      "Validation loss: 0.6965262631575266 RMSE: 0.8345815\n",
      "26 20 0.5782714486122131\n",
      "26 70 0.6089387536048889\n",
      "Validation loss: 0.6237491709845406 RMSE: 0.7897779\n",
      "27 15 0.7754793167114258\n",
      "27 65 0.7058393955230713\n",
      "Validation loss: 0.7486623985426767 RMSE: 0.86525285\n",
      "28 10 0.44811227917671204\n",
      "28 60 0.5523090958595276\n",
      "Validation loss: 0.6797009720688775 RMSE: 0.8244398\n",
      "29 5 0.692625105381012\n",
      "29 55 0.7424325942993164\n",
      "Validation loss: 0.8406699362255278 RMSE: 0.91688055\n",
      "30 0 0.7647562026977539\n",
      "30 50 0.7033582329750061\n",
      "30 100 0.35777804255485535\n",
      "Validation loss: 0.7190067444528853 RMSE: 0.84794265\n",
      "31 45 0.9024402499198914\n",
      "31 95 0.5662267804145813\n",
      "Validation loss: 0.6062834312518438 RMSE: 0.77864206\n",
      "32 40 0.41309720277786255\n",
      "32 90 0.5438554883003235\n",
      "Validation loss: 0.6818575359526134 RMSE: 0.82574666\n",
      "33 35 0.6957910656929016\n",
      "33 85 0.7359370589256287\n",
      "Validation loss: 0.7475012938181559 RMSE: 0.8645816\n",
      "34 30 0.46815890073776245\n",
      "34 80 0.5475224852561951\n",
      "Validation loss: 0.6500469755558741 RMSE: 0.80625486\n",
      "35 25 0.4318898916244507\n",
      "35 75 0.46591252088546753\n",
      "Validation loss: 0.6983131987707956 RMSE: 0.8356514\n",
      "36 20 0.38206034898757935\n",
      "36 70 0.655899703502655\n",
      "Validation loss: 0.6694779492559887 RMSE: 0.8182163\n",
      "37 15 0.756850004196167\n",
      "37 65 0.5497113466262817\n",
      "Validation loss: 0.7283732306389582 RMSE: 0.85344785\n",
      "38 10 0.7657428979873657\n",
      "38 60 0.6385095119476318\n",
      "Validation loss: 0.652711972736177 RMSE: 0.8079059\n",
      "39 5 0.3325954079627991\n",
      "39 55 0.916334331035614\n",
      "Validation loss: 0.7131526856195359 RMSE: 0.8444837\n",
      "40 0 0.40879014134407043\n",
      "40 50 0.4744904935359955\n",
      "40 100 0.4129619002342224\n",
      "Validation loss: 0.6115480479739961 RMSE: 0.7820154\n",
      "41 45 0.420041561126709\n",
      "41 95 0.49763724207878113\n",
      "Validation loss: 0.6519794072423662 RMSE: 0.80745244\n",
      "42 40 0.34012043476104736\n",
      "42 90 0.42186522483825684\n",
      "Validation loss: 0.6487221530505589 RMSE: 0.80543286\n",
      "43 35 0.6158217787742615\n",
      "43 85 0.5568640232086182\n",
      "Validation loss: 0.6284021411623274 RMSE: 0.7927182\n",
      "44 30 0.5110330581665039\n",
      "44 80 0.48764127492904663\n",
      "Validation loss: 0.6421389579772949 RMSE: 0.80133575\n",
      "45 25 0.2575342655181885\n",
      "45 75 0.44047218561172485\n",
      "Validation loss: 0.5732012930370513 RMSE: 0.7571006\n",
      "46 20 0.3018791973590851\n",
      "46 70 0.25306129455566406\n",
      "Validation loss: 0.6026407962753659 RMSE: 0.7762994\n",
      "47 15 0.4836995303630829\n",
      "47 65 0.3489809036254883\n",
      "Validation loss: 0.8715496534392947 RMSE: 0.93356824\n",
      "48 10 0.46720683574676514\n",
      "48 60 0.35692542791366577\n",
      "Validation loss: 0.5997057454926628 RMSE: 0.7744067\n",
      "49 5 0.41501855850219727\n",
      "49 55 0.38352248072624207\n",
      "Validation loss: 0.5987601354008629 RMSE: 0.7737959\n",
      "50 0 0.6014518737792969\n",
      "50 50 0.6190558671951294\n",
      "50 100 0.27020543813705444\n",
      "Validation loss: 0.6088851383754186 RMSE: 0.7803109\n",
      "51 45 0.6030663847923279\n",
      "51 95 0.6683688163757324\n",
      "Validation loss: 0.6193285011109851 RMSE: 0.78697425\n",
      "52 40 0.3758801221847534\n",
      "52 90 0.29110953211784363\n",
      "Validation loss: 0.5724968984013512 RMSE: 0.75663525\n",
      "53 35 0.6233397722244263\n",
      "53 85 0.42561063170433044\n",
      "Validation loss: 0.5710187497593108 RMSE: 0.75565785\n",
      "54 30 0.331897109746933\n",
      "54 80 0.1938498169183731\n",
      "Validation loss: 0.5724252720673879 RMSE: 0.7565879\n",
      "55 25 0.16789884865283966\n",
      "55 75 0.5053923726081848\n",
      "Validation loss: 0.5554497224943978 RMSE: 0.745285\n",
      "56 20 0.3031136989593506\n",
      "56 70 0.3162606358528137\n",
      "Validation loss: 0.5561070462067922 RMSE: 0.74572587\n",
      "57 15 0.37074366211891174\n",
      "57 65 0.44110867381095886\n",
      "Validation loss: 0.551485702537355 RMSE: 0.7426208\n",
      "58 10 0.4978543519973755\n",
      "58 60 0.3028874099254608\n",
      "Validation loss: 0.6166691484905424 RMSE: 0.78528285\n",
      "59 5 0.4880201816558838\n",
      "59 55 0.44938555359840393\n",
      "Validation loss: 0.691880821046375 RMSE: 0.8317938\n",
      "60 0 0.339726984500885\n",
      "60 50 0.4359368681907654\n",
      "60 100 0.39751362800598145\n",
      "Validation loss: 0.5625714710780553 RMSE: 0.7500477\n",
      "61 45 0.16959553956985474\n",
      "61 95 0.5659146308898926\n",
      "Validation loss: 0.5568984803699312 RMSE: 0.7462563\n",
      "62 40 0.541663408279419\n",
      "62 90 0.38758552074432373\n",
      "Validation loss: 0.5947479577291579 RMSE: 0.77119905\n",
      "63 35 0.42179930210113525\n",
      "63 85 0.2864663600921631\n",
      "Validation loss: 0.5550365050633749 RMSE: 0.7450077\n",
      "64 30 0.6822319030761719\n",
      "64 80 0.3153521418571472\n",
      "Validation loss: 0.6175874102683294 RMSE: 0.78586733\n",
      "65 25 0.3283313810825348\n",
      "65 75 0.12400498986244202\n",
      "Validation loss: 0.5681915237790063 RMSE: 0.7537848\n",
      "66 20 0.6708100438117981\n",
      "66 70 0.5771825909614563\n",
      "Validation loss: 0.572988536244347 RMSE: 0.75696003\n",
      "67 15 0.3512173891067505\n",
      "67 65 0.2542303502559662\n",
      "Validation loss: 0.5633809824784597 RMSE: 0.75058705\n",
      "68 10 0.6275861859321594\n",
      "68 60 0.3235756754875183\n",
      "Validation loss: 0.5710296789805095 RMSE: 0.75566506\n",
      "69 5 0.3524104356765747\n",
      "69 55 0.32449278235435486\n",
      "Validation loss: 0.5287260725384667 RMSE: 0.7271355\n",
      "70 0 0.4491084814071655\n",
      "70 50 0.2790054976940155\n",
      "70 100 0.6162369847297668\n",
      "Validation loss: 0.6323394386541276 RMSE: 0.7951977\n",
      "71 45 0.3210747241973877\n",
      "71 95 0.3310146927833557\n",
      "Validation loss: 0.5757611169701531 RMSE: 0.75878924\n",
      "72 40 0.3739053010940552\n",
      "72 90 0.38673079013824463\n",
      "Validation loss: 0.5532372451963878 RMSE: 0.7437992\n",
      "73 35 0.40779784321784973\n",
      "73 85 0.3421328067779541\n",
      "Validation loss: 0.5421938348384131 RMSE: 0.73633814\n",
      "74 30 0.18008412420749664\n",
      "74 80 0.2793732285499573\n",
      "Validation loss: 0.5330187760648273 RMSE: 0.7300813\n",
      "75 25 0.2708699405193329\n",
      "75 75 0.5800683498382568\n",
      "Validation loss: 0.5598364602951776 RMSE: 0.7482222\n",
      "76 20 0.28012630343437195\n",
      "76 70 0.3135860562324524\n",
      "Validation loss: 0.5908080858843667 RMSE: 0.7686404\n",
      "77 15 0.17691117525100708\n",
      "77 65 0.3704531788825989\n",
      "Validation loss: 0.5932546292032514 RMSE: 0.77023023\n",
      "78 10 0.6570619344711304\n",
      "78 60 0.2644028067588806\n",
      "Validation loss: 0.5519149451028733 RMSE: 0.7429098\n",
      "79 5 0.5238776206970215\n",
      "79 55 0.3153674900531769\n",
      "Validation loss: 0.5698146422704061 RMSE: 0.75486064\n",
      "80 0 0.22648261487483978\n",
      "80 50 0.2162693440914154\n",
      "80 100 0.45326152443885803\n",
      "Validation loss: 0.5456833799680074 RMSE: 0.73870385\n",
      "81 45 0.3121581971645355\n",
      "81 95 0.23259446024894714\n",
      "Validation loss: 0.5460411361285619 RMSE: 0.73894596\n",
      "82 40 0.21514339745044708\n",
      "82 90 0.24044229090213776\n",
      "Validation loss: 0.5680359542369843 RMSE: 0.75368154\n",
      "83 35 0.34811994433403015\n",
      "83 85 0.15087510645389557\n",
      "Validation loss: 0.5501607605389186 RMSE: 0.7417282\n",
      "84 30 0.30531829595565796\n",
      "84 80 0.29647570848464966\n",
      "Validation loss: 0.5393652512913658 RMSE: 0.73441494\n",
      "85 25 0.47916746139526367\n",
      "85 75 0.2994745373725891\n",
      "Validation loss: 0.5339573511055538 RMSE: 0.73072386\n",
      "86 20 0.3442912995815277\n",
      "86 70 0.15111081302165985\n",
      "Validation loss: 0.5547605105808803 RMSE: 0.7448225\n",
      "87 15 0.190665140748024\n",
      "87 65 0.31642255187034607\n",
      "Validation loss: 0.5269491910934448 RMSE: 0.7259127\n",
      "88 10 0.2575758397579193\n",
      "88 60 0.3303835988044739\n",
      "Validation loss: 0.5328181337742578 RMSE: 0.72994393\n",
      "89 5 0.23464751243591309\n",
      "89 55 0.22739887237548828\n",
      "Validation loss: 0.53222937697456 RMSE: 0.72954047\n",
      "90 0 0.34592849016189575\n",
      "90 50 0.31155645847320557\n",
      "90 100 0.3393312096595764\n",
      "Validation loss: 0.5615150377863929 RMSE: 0.7493431\n",
      "91 45 0.39324045181274414\n",
      "91 95 0.2618445158004761\n",
      "Validation loss: 0.5599794860397066 RMSE: 0.7483177\n",
      "92 40 0.2948475778102875\n",
      "92 90 0.3528037965297699\n",
      "Validation loss: 0.5531168358666556 RMSE: 0.7437182\n",
      "93 35 0.31481045484542847\n",
      "93 85 0.30115750432014465\n",
      "Validation loss: 0.494298399630047 RMSE: 0.70306355\n",
      "94 30 0.38532984256744385\n",
      "94 80 0.4854036569595337\n",
      "Validation loss: 0.5724290684575126 RMSE: 0.7565904\n",
      "95 25 0.24181677401065826\n",
      "95 75 0.2954292297363281\n",
      "Validation loss: 0.5647393618311201 RMSE: 0.7514914\n",
      "96 20 0.3281405568122864\n",
      "96 70 0.21595335006713867\n",
      "Validation loss: 0.5480096658070882 RMSE: 0.74027675\n",
      "97 15 0.2949235141277313\n",
      "97 65 0.2282208800315857\n",
      "Validation loss: 0.5156464386553992 RMSE: 0.7180853\n",
      "98 10 0.3944953680038452\n",
      "98 60 0.16638998687267303\n",
      "Validation loss: 0.5370849677494594 RMSE: 0.7328608\n",
      "99 5 0.38743066787719727\n",
      "99 55 0.4435230791568756\n",
      "Validation loss: 0.5429192293257941 RMSE: 0.7368306\n",
      "100 0 0.2556402385234833\n",
      "100 50 0.3495117425918579\n",
      "100 100 0.23155587911605835\n",
      "Validation loss: 0.5433564861615499 RMSE: 0.7371272\n",
      "101 45 0.272070974111557\n",
      "101 95 0.23705577850341797\n",
      "Validation loss: 0.5126127112479437 RMSE: 0.7159698\n",
      "102 40 0.29248443245887756\n",
      "102 90 0.2936094403266907\n",
      "Validation loss: 0.5287291907128834 RMSE: 0.7271377\n",
      "103 35 0.17146503925323486\n",
      "103 85 0.3267531394958496\n",
      "Validation loss: 0.532297136811983 RMSE: 0.72958696\n",
      "104 30 0.23518867790699005\n",
      "104 80 0.261322945356369\n",
      "Validation loss: 0.5435743346810341 RMSE: 0.737275\n",
      "105 25 0.2566094696521759\n",
      "105 75 0.1792270690202713\n",
      "Validation loss: 0.5068579889479138 RMSE: 0.7119396\n",
      "106 20 0.2731742262840271\n",
      "106 70 0.176492840051651\n",
      "Validation loss: 0.504712118421282 RMSE: 0.7104309\n",
      "107 15 0.3365420699119568\n",
      "107 65 0.3369702398777008\n",
      "Validation loss: 0.5103739550780683 RMSE: 0.7144046\n",
      "108 10 0.2527908682823181\n",
      "108 60 0.2936475872993469\n",
      "Validation loss: 0.516359369527726 RMSE: 0.7185815\n",
      "109 5 0.2742806077003479\n",
      "109 55 0.16486479341983795\n",
      "Validation loss: 0.5097824766522362 RMSE: 0.71399057\n",
      "110 0 0.27600130438804626\n",
      "110 50 0.20703497529029846\n",
      "110 100 0.38654637336730957\n",
      "Validation loss: 0.49834399223327636 RMSE: 0.7059348\n",
      "111 45 0.22895601391792297\n",
      "111 95 0.2325902134180069\n",
      "Validation loss: 0.5167538359051659 RMSE: 0.7188559\n",
      "112 40 0.15971483290195465\n",
      "112 90 0.15837521851062775\n",
      "Validation loss: 0.5243084641439574 RMSE: 0.7240915\n",
      "113 35 0.20540764927864075\n",
      "113 85 0.4452592432498932\n",
      "Validation loss: 0.4998993217945099 RMSE: 0.7070356\n",
      "114 30 0.215521901845932\n",
      "114 80 0.27751782536506653\n",
      "Validation loss: 0.5203852080163501 RMSE: 0.7213773\n",
      "115 25 0.16518761217594147\n",
      "115 75 0.20222899317741394\n",
      "Validation loss: 0.5085886569250198 RMSE: 0.713154\n",
      "116 20 0.30161452293395996\n",
      "116 70 0.5887963175773621\n",
      "Validation loss: 0.523708252679734 RMSE: 0.7236769\n",
      "117 15 0.26560109853744507\n",
      "117 65 0.29413217306137085\n",
      "Validation loss: 0.5215429567864963 RMSE: 0.7221793\n",
      "118 10 0.22660988569259644\n",
      "118 60 0.17645207047462463\n",
      "Validation loss: 0.5462048475941023 RMSE: 0.73905677\n",
      "119 5 0.11334773898124695\n",
      "119 55 0.19568674266338348\n",
      "Validation loss: 0.5225246731724058 RMSE: 0.72285867\n",
      "120 0 0.1718684434890747\n",
      "120 50 0.19163575768470764\n",
      "120 100 0.3887706398963928\n",
      "Validation loss: 0.4862303194545564 RMSE: 0.6973022\n",
      "121 45 0.2043822854757309\n",
      "121 95 0.2490772008895874\n",
      "Validation loss: 0.563725133169265 RMSE: 0.7508163\n",
      "122 40 0.30172231793403625\n",
      "122 90 0.22653985023498535\n",
      "Validation loss: 0.5241633454958597 RMSE: 0.7239913\n",
      "123 35 0.08607295900583267\n",
      "123 85 0.24019496142864227\n",
      "Validation loss: 0.5265064279238383 RMSE: 0.7256077\n",
      "124 30 0.3016503155231476\n",
      "124 80 0.4893752634525299\n",
      "Validation loss: 0.5147784769535064 RMSE: 0.71748066\n",
      "125 25 0.14103291928768158\n",
      "125 75 0.2836351692676544\n",
      "Validation loss: 0.544224116348085 RMSE: 0.7377155\n",
      "126 20 0.17876869440078735\n",
      "126 70 0.20093540847301483\n",
      "Validation loss: 0.5061039061773391 RMSE: 0.7114098\n",
      "127 15 0.20093625783920288\n",
      "127 65 0.28183555603027344\n",
      "Validation loss: 0.5299403448899587 RMSE: 0.72797\n",
      "128 10 0.28392142057418823\n",
      "128 60 0.16197243332862854\n",
      "Validation loss: 0.5060678561528523 RMSE: 0.7113845\n",
      "129 5 0.28320056200027466\n",
      "129 55 0.25224095582962036\n",
      "Validation loss: 0.5078769547598703 RMSE: 0.71265495\n",
      "130 0 0.2400047481060028\n",
      "130 50 0.4777279794216156\n",
      "130 100 0.17641985416412354\n",
      "Validation loss: 0.5111629707472665 RMSE: 0.71495664\n",
      "131 45 0.28050920367240906\n",
      "131 95 0.20855891704559326\n",
      "Validation loss: 0.5209014109202794 RMSE: 0.721735\n",
      "132 40 0.25190359354019165\n",
      "132 90 0.16126419603824615\n",
      "Validation loss: 0.5083579574312482 RMSE: 0.71299225\n",
      "133 35 0.23892861604690552\n",
      "133 85 0.320451021194458\n",
      "Validation loss: 0.5292899302073888 RMSE: 0.72752315\n",
      "134 30 0.2158472239971161\n",
      "134 80 0.276555597782135\n",
      "Validation loss: 0.5330840797651382 RMSE: 0.7301261\n",
      "135 25 0.22669288516044617\n",
      "135 75 0.29155051708221436\n",
      "Validation loss: 0.5286770028727396 RMSE: 0.72710174\n",
      "136 20 0.15150730311870575\n",
      "136 70 0.1866874396800995\n",
      "Validation loss: 0.5195306085404896 RMSE: 0.7207847\n",
      "137 15 0.2986524999141693\n",
      "137 65 0.359713613986969\n",
      "Validation loss: 0.49973570704460146 RMSE: 0.7069199\n",
      "138 10 0.23104213178157806\n",
      "138 60 0.184711754322052\n",
      "Validation loss: 0.49151548714864823 RMSE: 0.70108163\n",
      "139 5 0.14454202353954315\n",
      "139 55 0.3719484806060791\n",
      "Validation loss: 0.534749333383072 RMSE: 0.73126554\n",
      "140 0 0.20962360501289368\n",
      "140 50 0.21229851245880127\n",
      "140 100 0.15961089730262756\n",
      "Validation loss: 0.5318451574870519 RMSE: 0.72927713\n",
      "141 45 0.20915670692920685\n",
      "141 95 0.2215888798236847\n",
      "Validation loss: 0.5213541831289019 RMSE: 0.7220486\n",
      "142 40 0.20230883359909058\n",
      "142 90 0.13831216096878052\n",
      "Validation loss: 0.47597104481288366 RMSE: 0.68990654\n",
      "143 35 0.15172366797924042\n",
      "143 85 0.1450982689857483\n",
      "Validation loss: 0.5169565962893622 RMSE: 0.71899694\n",
      "144 30 0.2260470986366272\n",
      "144 80 0.20046377182006836\n",
      "Validation loss: 0.5082497349807195 RMSE: 0.7129164\n",
      "145 25 0.3026537299156189\n",
      "145 75 0.27125945687294006\n",
      "Validation loss: 0.515561314423879 RMSE: 0.718026\n",
      "146 20 0.2808743119239807\n",
      "146 70 0.22814005613327026\n",
      "Validation loss: 0.5104729615506671 RMSE: 0.7144739\n",
      "147 15 0.17993508279323578\n",
      "147 65 0.16019903123378754\n",
      "Validation loss: 0.5058727304140727 RMSE: 0.7112473\n",
      "148 10 0.3022225499153137\n",
      "148 60 0.24741818010807037\n",
      "Validation loss: 0.4796750023251488 RMSE: 0.6925857\n",
      "149 5 0.14743945002555847\n",
      "149 55 0.3093075156211853\n",
      "Validation loss: 0.47993085710775285 RMSE: 0.6927704\n",
      "150 0 0.21089695394039154\n",
      "150 50 0.3527640104293823\n",
      "150 100 0.3045121729373932\n",
      "Validation loss: 0.49926166988554455 RMSE: 0.7065845\n",
      "151 45 0.13078086078166962\n",
      "151 95 0.19022919237613678\n",
      "Validation loss: 0.5585921650841122 RMSE: 0.7473902\n",
      "152 40 0.3487418293952942\n",
      "152 90 0.3178543448448181\n",
      "Validation loss: 0.5038455344381787 RMSE: 0.7098208\n",
      "153 35 0.1834520846605301\n",
      "153 85 0.4024135172367096\n",
      "Validation loss: 0.5153136108602796 RMSE: 0.7178535\n",
      "154 30 0.34164848923683167\n",
      "154 80 0.23709075152873993\n",
      "Validation loss: 0.5018684432620094 RMSE: 0.7084267\n",
      "155 25 0.21774572134017944\n",
      "155 75 0.18408489227294922\n",
      "Validation loss: 0.5219571923925763 RMSE: 0.72246605\n",
      "156 20 0.11736683547496796\n",
      "156 70 0.21941038966178894\n",
      "Validation loss: 0.5336404741519973 RMSE: 0.73050696\n",
      "157 15 0.1595432162284851\n",
      "157 65 0.20955733954906464\n",
      "Validation loss: 0.47267431560016815 RMSE: 0.6875131\n",
      "158 10 0.1766635924577713\n",
      "158 60 0.2965184152126312\n",
      "Validation loss: 0.5028924328940255 RMSE: 0.70914906\n",
      "159 5 0.2089238464832306\n",
      "159 55 0.14621710777282715\n",
      "Validation loss: 0.47185756493182407 RMSE: 0.68691885\n",
      "160 0 0.12518879771232605\n",
      "160 50 0.3017929792404175\n",
      "160 100 0.26217156648635864\n",
      "Validation loss: 0.5162580765428997 RMSE: 0.718511\n",
      "161 45 0.17180600762367249\n",
      "161 95 0.14840179681777954\n",
      "Validation loss: 0.5527905492555527 RMSE: 0.74349886\n",
      "162 40 0.2168416976928711\n",
      "162 90 0.21294450759887695\n",
      "Validation loss: 0.5396893242994945 RMSE: 0.7346355\n",
      "163 35 0.2567306160926819\n",
      "163 85 0.16200502216815948\n",
      "Validation loss: 0.4962621013323466 RMSE: 0.7044587\n",
      "164 30 0.20441047847270966\n",
      "164 80 0.2000741809606552\n",
      "Validation loss: 0.5133460313081741 RMSE: 0.7164817\n",
      "165 25 0.1944567859172821\n",
      "165 75 0.2491663098335266\n",
      "Validation loss: 0.5636396215075539 RMSE: 0.75075936\n",
      "166 20 0.12046080082654953\n",
      "166 70 0.1758599877357483\n",
      "Validation loss: 0.5278456792944953 RMSE: 0.7265299\n",
      "167 15 0.1491357386112213\n",
      "167 65 0.2120790332555771\n",
      "Validation loss: 0.5266831324214027 RMSE: 0.72572935\n",
      "168 10 0.20669317245483398\n",
      "168 60 0.13928508758544922\n",
      "Validation loss: 0.49881892204284667 RMSE: 0.7062711\n",
      "169 5 0.14599625766277313\n",
      "169 55 0.19379350543022156\n",
      "Validation loss: 0.4970602977843512 RMSE: 0.705025\n",
      "170 0 0.13377252221107483\n",
      "170 50 0.20254462957382202\n",
      "170 100 0.11552847921848297\n",
      "Validation loss: 0.5494739116657348 RMSE: 0.74126506\n",
      "171 45 0.20137934386730194\n",
      "171 95 0.1828220933675766\n",
      "Validation loss: 0.543097930153211 RMSE: 0.73695177\n",
      "172 40 0.15254610776901245\n",
      "172 90 0.22529397904872894\n",
      "Validation loss: 0.5310725084372929 RMSE: 0.7287472\n",
      "173 35 0.15393328666687012\n",
      "173 85 0.20233669877052307\n",
      "Validation loss: 0.5049744787670317 RMSE: 0.7106155\n",
      "174 30 0.1663479506969452\n",
      "174 80 0.2550815939903259\n",
      "Validation loss: 0.5156168897946676 RMSE: 0.71806467\n",
      "175 25 0.16163229942321777\n",
      "175 75 0.4745318293571472\n",
      "Validation loss: 0.5235097050666809 RMSE: 0.7235397\n",
      "176 20 -1.049111247062683\n",
      "176 70 -9.873123168945312\n",
      "Validation loss: 0.6735488834835234 RMSE: 0.8207002\n",
      "177 15 -19.943204879760742\n",
      "177 65 -29.942399978637695\n",
      "Validation loss: 0.7332054580960955 RMSE: 0.8562742\n",
      "178 10 -36.1696662902832\n",
      "178 60 -50.75265121459961\n",
      "Validation loss: 0.7187562846002125 RMSE: 0.84779495\n",
      "179 5 -55.788734436035156\n",
      "179 55 -67.15989685058594\n",
      "Validation loss: 0.6643977934405917 RMSE: 0.815106\n",
      "180 0 -84.59329223632812\n",
      "180 50 -92.75923156738281\n",
      "180 100 -110.59617614746094\n",
      "Validation loss: 1.171586847305298 RMSE: 1.0823987\n",
      "181 45 -119.30411529541016\n",
      "181 95 -125.56665802001953\n",
      "Validation loss: 0.7683868175461179 RMSE: 0.8765768\n",
      "182 40 -140.10546875\n",
      "182 90 -144.8115692138672\n",
      "Validation loss: 1.1793954667590913 RMSE: 1.0859997\n",
      "183 35 -172.25152587890625\n",
      "183 85 -178.4791259765625\n",
      "Validation loss: 1.0161773045857747 RMSE: 1.0080562\n",
      "184 30 -217.20062255859375\n",
      "184 80 -218.31019592285156\n",
      "Validation loss: 0.9301619745436169 RMSE: 0.96444905\n",
      "185 25 -241.26536560058594\n",
      "185 75 -236.8248748779297\n",
      "Validation loss: 1.1097408748808362 RMSE: 1.0534425\n",
      "186 20 -258.1229553222656\n",
      "186 70 -262.10455322265625\n",
      "Validation loss: 1.208590152717772 RMSE: 1.0993589\n",
      "187 15 -292.3795166015625\n",
      "187 65 -310.7085266113281\n",
      "Validation loss: 0.9464435191381545 RMSE: 0.97285324\n",
      "188 10 -332.4190368652344\n",
      "188 60 -327.86749267578125\n",
      "Validation loss: 0.701124686286563 RMSE: 0.8373319\n",
      "189 5 -381.24945068359375\n",
      "189 55 -386.13720703125\n",
      "Validation loss: 1.042922385249819 RMSE: 1.0212357\n",
      "190 0 -412.91900634765625\n",
      "190 50 -442.2676086425781\n",
      "190 100 -455.87481689453125\n",
      "Validation loss: 0.8530620160556975 RMSE: 0.9236136\n",
      "191 45 -485.8221435546875\n",
      "191 95 -500.1657409667969\n",
      "Validation loss: 0.8159577838012151 RMSE: 0.9033038\n",
      "192 40 -507.1311340332031\n",
      "192 90 -524.776123046875\n",
      "Validation loss: 0.8630596285774594 RMSE: 0.92901003\n",
      "193 35 -504.9775390625\n",
      "193 85 -618.9523315429688\n",
      "Validation loss: 0.8074665251232329 RMSE: 0.89859146\n",
      "194 30 -599.9124755859375\n",
      "194 80 -605.2968139648438\n",
      "Validation loss: 0.8120703038715181 RMSE: 0.90114945\n",
      "195 25 -653.2965087890625\n",
      "195 75 -718.7478637695312\n",
      "Validation loss: 0.9364957116899036 RMSE: 0.96772707\n",
      "196 20 -711.340576171875\n",
      "196 70 -755.2005004882812\n",
      "Validation loss: 0.8323065700985136 RMSE: 0.91230834\n",
      "197 15 -762.7634887695312\n",
      "197 65 -737.6387329101562\n",
      "Validation loss: 1.0321712351980663 RMSE: 1.0159583\n",
      "198 10 -852.8836669921875\n",
      "198 60 -801.7161254882812\n",
      "Validation loss: 0.9664999780200777 RMSE: 0.9831073\n",
      "199 5 -841.0963134765625\n",
      "199 55 -843.9590454101562\n",
      "Validation loss: 0.9220261596498035 RMSE: 0.96022195\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.5540105899175009 Test RMSE: 0.74431884\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 778, 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'target': ['exp']}}\n",
      "Running on: cuda:1\n",
      "4199\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/4199\n",
      "Generating scaffold 1000/4199\n",
      "Generating scaffold 2000/4199\n",
      "Generating scaffold 3000/4199\n",
      "Generating scaffold 4000/4199\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 15.132486343383789\n",
      "0 50 3.674180507659912\n",
      "0 100 3.0687997341156006\n",
      "Validation loss: 1.3001621314457485 RMSE: 1.1402465\n",
      "1 45 2.0771050453186035\n",
      "1 95 1.890657901763916\n",
      "Validation loss: 1.085079349506469 RMSE: 1.0416714\n",
      "2 40 1.5651928186416626\n",
      "2 90 1.3650009632110596\n",
      "Validation loss: 1.5352484975542342 RMSE: 1.2390515\n",
      "3 35 1.6891899108886719\n",
      "3 85 1.5485647916793823\n",
      "Validation loss: 1.0510020443371364 RMSE: 1.0251839\n",
      "4 30 1.1906133890151978\n",
      "4 80 1.6177983283996582\n",
      "Validation loss: 1.014997852983929 RMSE: 1.007471\n",
      "5 25 1.0192816257476807\n",
      "5 75 0.9376152753829956\n",
      "Validation loss: 1.1575931400060653 RMSE: 1.075915\n",
      "6 20 1.083561897277832\n",
      "6 70 0.789027214050293\n",
      "Validation loss: 0.94903302022389 RMSE: 0.97418326\n",
      "7 15 0.8731431365013123\n",
      "7 65 0.9779545068740845\n",
      "Validation loss: 0.8254843410991487 RMSE: 0.9085617\n",
      "8 10 1.098793387413025\n",
      "8 60 0.9007929563522339\n",
      "Validation loss: 1.135471957070487 RMSE: 1.0655853\n",
      "9 5 1.5286999940872192\n",
      "9 55 0.7672148942947388\n",
      "Validation loss: 0.864830436025347 RMSE: 0.9299626\n",
      "10 0 1.1478822231292725\n",
      "10 50 0.6925411224365234\n",
      "10 100 0.5309944748878479\n",
      "Validation loss: 0.9242665885459809 RMSE: 0.9613879\n",
      "11 45 0.8014616370201111\n",
      "11 95 0.4523579776287079\n",
      "Validation loss: 0.7996706673077174 RMSE: 0.89424306\n",
      "12 40 0.9745694398880005\n",
      "12 90 0.8525070548057556\n",
      "Validation loss: 0.8434472742534819 RMSE: 0.91839385\n",
      "13 35 0.8450198769569397\n",
      "13 85 0.7891492247581482\n",
      "Validation loss: 0.9405576867716653 RMSE: 0.96982354\n",
      "14 30 0.6302168369293213\n",
      "14 80 0.5058737397193909\n",
      "Validation loss: 0.8928413266227359 RMSE: 0.9449028\n",
      "15 25 0.6679467558860779\n",
      "15 75 1.3806926012039185\n",
      "Validation loss: 0.7580489090510777 RMSE: 0.87066\n",
      "16 20 0.6900814175605774\n",
      "16 70 0.8832073211669922\n",
      "Validation loss: 0.963762541044326 RMSE: 0.9817141\n",
      "17 15 0.597392737865448\n",
      "17 65 0.39796364307403564\n",
      "Validation loss: 0.6896917626971291 RMSE: 0.8304768\n",
      "18 10 0.4511226415634155\n",
      "18 60 0.4648686349391937\n",
      "Validation loss: 1.1368649265595845 RMSE: 1.0662386\n",
      "19 5 0.6254112124443054\n",
      "19 55 0.5955588817596436\n",
      "Validation loss: 0.8072297539029802 RMSE: 0.8984597\n",
      "20 0 0.5425153374671936\n",
      "20 50 0.5449978113174438\n",
      "20 100 0.3865061104297638\n",
      "Validation loss: 0.8012200389589582 RMSE: 0.89510894\n",
      "21 45 0.5252950191497803\n",
      "21 95 1.0588246583938599\n",
      "Validation loss: 0.7455778581755502 RMSE: 0.8634685\n",
      "22 40 0.6200695633888245\n",
      "22 90 0.6185833811759949\n",
      "Validation loss: 0.7338327650512968 RMSE: 0.8566404\n",
      "23 35 0.6333736181259155\n",
      "23 85 0.6472987532615662\n",
      "Validation loss: 0.7844363917907079 RMSE: 0.88568413\n",
      "24 30 0.8611599206924438\n",
      "24 80 0.5922018885612488\n",
      "Validation loss: 0.724515396072751 RMSE: 0.85118467\n",
      "25 25 0.6784743666648865\n",
      "25 75 0.5349540114402771\n",
      "Validation loss: 0.6814735412597657 RMSE: 0.8255141\n",
      "26 20 0.8248661160469055\n",
      "26 70 0.5148380994796753\n",
      "Validation loss: 0.7965140232018062 RMSE: 0.8924763\n",
      "27 15 0.5770180821418762\n",
      "27 65 0.8124684691429138\n",
      "Validation loss: 0.7035246463049025 RMSE: 0.8387638\n",
      "28 10 0.7595828175544739\n",
      "28 60 0.7960027456283569\n",
      "Validation loss: 0.6823607512882778 RMSE: 0.8260513\n",
      "29 5 0.7413030862808228\n",
      "29 55 0.98846834897995\n",
      "Validation loss: 0.7077550286338443 RMSE: 0.8412818\n",
      "30 0 0.5957658290863037\n",
      "30 50 0.4039529860019684\n",
      "30 100 0.4309418499469757\n",
      "Validation loss: 0.7073379363332476 RMSE: 0.8410338\n",
      "31 45 0.4174819886684418\n",
      "31 95 0.4813847839832306\n",
      "Validation loss: 0.636636872802462 RMSE: 0.7978953\n",
      "32 40 0.426822692155838\n",
      "32 90 0.48226428031921387\n",
      "Validation loss: 0.7780190570013864 RMSE: 0.8820539\n",
      "33 35 0.7125669121742249\n",
      "33 85 0.8375316858291626\n",
      "Validation loss: 0.7217874711468106 RMSE: 0.84958076\n",
      "34 30 0.3996179401874542\n",
      "34 80 0.7227891087532043\n",
      "Validation loss: 0.6172234870138622 RMSE: 0.7856357\n",
      "35 25 0.602077305316925\n",
      "35 75 0.45886480808258057\n",
      "Validation loss: 0.6316729840778169 RMSE: 0.7947786\n",
      "36 20 0.5565042495727539\n",
      "36 70 1.0316213369369507\n",
      "Validation loss: 0.6672068805921645 RMSE: 0.81682736\n",
      "37 15 0.5452292561531067\n",
      "37 65 0.41148534417152405\n",
      "Validation loss: 0.7008162180582682 RMSE: 0.83714765\n",
      "38 10 0.536024808883667\n",
      "38 60 0.3433700501918793\n",
      "Validation loss: 0.6609190892605554 RMSE: 0.8129694\n",
      "39 5 0.4883146286010742\n",
      "39 55 0.3725717067718506\n",
      "Validation loss: 0.5728920732225691 RMSE: 0.7568964\n",
      "40 0 0.5355770587921143\n",
      "40 50 0.35010087490081787\n",
      "40 100 0.2491176277399063\n",
      "Validation loss: 0.7457242525049619 RMSE: 0.8635532\n",
      "41 45 0.49544429779052734\n",
      "41 95 0.6283158659934998\n",
      "Validation loss: 0.6744421201092856 RMSE: 0.82124424\n",
      "42 40 0.4489220976829529\n",
      "42 90 0.4910168945789337\n",
      "Validation loss: 0.6515109805833725 RMSE: 0.80716234\n",
      "43 35 0.4759664237499237\n",
      "43 85 0.4359356164932251\n",
      "Validation loss: 0.6959573129812876 RMSE: 0.83424056\n",
      "44 30 0.605372428894043\n",
      "44 80 0.24153873324394226\n",
      "Validation loss: 0.6220761026654925 RMSE: 0.78871804\n",
      "45 25 0.3391590118408203\n",
      "45 75 0.40352925658226013\n",
      "Validation loss: 0.605537234885352 RMSE: 0.7781627\n",
      "46 20 0.511748731136322\n",
      "46 70 0.9272453784942627\n",
      "Validation loss: 0.5914035621498313 RMSE: 0.76902765\n",
      "47 15 0.45404887199401855\n",
      "47 65 0.6260381937026978\n",
      "Validation loss: 0.6497079639207749 RMSE: 0.8060447\n",
      "48 10 0.5187081098556519\n",
      "48 60 0.4043874144554138\n",
      "Validation loss: 0.6868847688039144 RMSE: 0.8287851\n",
      "49 5 0.562764585018158\n",
      "49 55 0.36737093329429626\n",
      "Validation loss: 0.6461724479993184 RMSE: 0.80384845\n",
      "50 0 0.3489187955856323\n",
      "50 50 0.25513288378715515\n",
      "50 100 0.48782485723495483\n",
      "Validation loss: 0.7006686176572527 RMSE: 0.8370595\n",
      "51 45 0.23460103571414948\n",
      "51 95 0.3665401339530945\n",
      "Validation loss: 0.5854164339247204 RMSE: 0.7651251\n",
      "52 40 0.52186119556427\n",
      "52 90 0.39029794931411743\n",
      "Validation loss: 0.5730503899710518 RMSE: 0.7570009\n",
      "53 35 0.30156365036964417\n",
      "53 85 0.5172470808029175\n",
      "Validation loss: 0.599510585694086 RMSE: 0.7742807\n",
      "54 30 0.6637610197067261\n",
      "54 80 0.37920504808425903\n",
      "Validation loss: 0.5439253401188623 RMSE: 0.73751295\n",
      "55 25 0.38897961378097534\n",
      "55 75 0.3575822710990906\n",
      "Validation loss: 0.6774321391468956 RMSE: 0.82306266\n",
      "56 20 0.2143498808145523\n",
      "56 70 0.42181599140167236\n",
      "Validation loss: 0.6238954265912374 RMSE: 0.7898705\n",
      "57 15 0.6349862813949585\n",
      "57 65 0.8655688762664795\n",
      "Validation loss: 0.5690684954325358 RMSE: 0.7543663\n",
      "58 10 0.34726420044898987\n",
      "58 60 0.44714584946632385\n",
      "Validation loss: 0.6232456383251008 RMSE: 0.7894591\n",
      "59 5 0.3858720064163208\n",
      "59 55 0.3734124004840851\n",
      "Validation loss: 0.6487089495928514 RMSE: 0.8054247\n",
      "60 0 0.4353649616241455\n",
      "60 50 0.5928884744644165\n",
      "60 100 0.3403090238571167\n",
      "Validation loss: 0.5973045110702515 RMSE: 0.7728548\n",
      "61 45 0.5841518640518188\n",
      "61 95 0.44510704278945923\n",
      "Validation loss: 0.6563144303503491 RMSE: 0.8101324\n",
      "62 40 0.3820633292198181\n",
      "62 90 0.3128172755241394\n",
      "Validation loss: 0.6304888464155651 RMSE: 0.7940332\n",
      "63 35 0.4240284562110901\n",
      "63 85 0.3449074327945709\n",
      "Validation loss: 0.5616970096315657 RMSE: 0.74946445\n",
      "64 30 0.4673503041267395\n",
      "64 80 0.2966320216655731\n",
      "Validation loss: 0.6165936583564395 RMSE: 0.7852348\n",
      "65 25 0.36387765407562256\n",
      "65 75 0.44319063425064087\n",
      "Validation loss: 0.5887687280064537 RMSE: 0.76731265\n",
      "66 20 0.2762752175331116\n",
      "66 70 0.4425305128097534\n",
      "Validation loss: 0.5899497690654937 RMSE: 0.7680819\n",
      "67 15 0.40707463026046753\n",
      "67 65 0.6626331210136414\n",
      "Validation loss: 0.5765096437363397 RMSE: 0.75928235\n",
      "68 10 0.460992693901062\n",
      "68 60 0.43158483505249023\n",
      "Validation loss: 0.6101835205441429 RMSE: 0.7811424\n",
      "69 5 0.5950443148612976\n",
      "69 55 0.4127603769302368\n",
      "Validation loss: 0.6156591723362604 RMSE: 0.78463954\n",
      "70 0 0.34073910117149353\n",
      "70 50 0.3577738106250763\n",
      "70 100 0.4616687297821045\n",
      "Validation loss: 0.5572417912029085 RMSE: 0.7464863\n",
      "71 45 0.5584366321563721\n",
      "71 95 0.47451555728912354\n",
      "Validation loss: 0.562465553056626 RMSE: 0.74997705\n",
      "72 40 0.20056189596652985\n",
      "72 90 0.2662888467311859\n",
      "Validation loss: 0.5885665450777327 RMSE: 0.7671809\n",
      "73 35 0.27188801765441895\n",
      "73 85 0.4879407286643982\n",
      "Validation loss: 0.592274064109439 RMSE: 0.7695934\n",
      "74 30 0.3372443914413452\n",
      "74 80 0.45743122696876526\n",
      "Validation loss: 0.6148690870829991 RMSE: 0.7841359\n",
      "75 25 0.43187054991722107\n",
      "75 75 0.29774653911590576\n",
      "Validation loss: 0.5628035375050136 RMSE: 0.7502023\n",
      "76 20 0.32054704427719116\n",
      "76 70 0.39242008328437805\n",
      "Validation loss: 0.5475554988497779 RMSE: 0.7399699\n",
      "77 15 0.20470285415649414\n",
      "77 65 0.5524201989173889\n",
      "Validation loss: 0.5825415734733854 RMSE: 0.7632441\n",
      "78 10 0.27696818113327026\n",
      "78 60 0.2966073453426361\n",
      "Validation loss: 0.6165225822301138 RMSE: 0.78518957\n",
      "79 5 0.22592981159687042\n",
      "79 55 0.38370949029922485\n",
      "Validation loss: 0.6066607977662768 RMSE: 0.7788843\n",
      "80 0 0.2802281081676483\n",
      "80 50 0.3063907027244568\n",
      "80 100 0.2875276505947113\n",
      "Validation loss: 0.5152959712914058 RMSE: 0.7178412\n",
      "81 45 0.24755187332630157\n",
      "81 95 0.2693823277950287\n",
      "Validation loss: 0.5054467448166439 RMSE: 0.71094775\n",
      "82 40 0.4344900846481323\n",
      "82 90 0.2679026424884796\n",
      "Validation loss: 0.5894407192866008 RMSE: 0.76775044\n",
      "83 35 0.15634174644947052\n",
      "83 85 0.45029404759407043\n",
      "Validation loss: 0.5577815816515967 RMSE: 0.74684775\n",
      "84 30 0.35294485092163086\n",
      "84 80 0.2973211705684662\n",
      "Validation loss: 0.5796149787448701 RMSE: 0.7613245\n",
      "85 25 0.2542480230331421\n",
      "85 75 0.29710114002227783\n",
      "Validation loss: 0.5407753444853283 RMSE: 0.7353743\n",
      "86 20 0.492249071598053\n",
      "86 70 0.22086070477962494\n",
      "Validation loss: 0.5467957930905478 RMSE: 0.7394565\n",
      "87 15 0.2712464928627014\n",
      "87 65 0.2553088068962097\n",
      "Validation loss: 0.5529547452926635 RMSE: 0.74360925\n",
      "88 10 0.31505370140075684\n",
      "88 60 0.20889370143413544\n",
      "Validation loss: 0.5765382888771239 RMSE: 0.7593012\n",
      "89 5 0.6798118352890015\n",
      "89 55 0.30607497692108154\n",
      "Validation loss: 0.5291885086468288 RMSE: 0.7274535\n",
      "90 0 0.31918466091156006\n",
      "90 50 0.3285011053085327\n",
      "90 100 0.33795371651649475\n",
      "Validation loss: 0.5557684421539306 RMSE: 0.7454988\n",
      "91 45 0.5338262319564819\n",
      "91 95 0.29414278268814087\n",
      "Validation loss: 0.5230814280964079 RMSE: 0.72324365\n",
      "92 40 0.3010869026184082\n",
      "92 90 0.42889973521232605\n",
      "Validation loss: 0.5235157858757745 RMSE: 0.7235439\n",
      "93 35 0.4996790885925293\n",
      "93 85 0.17715226113796234\n",
      "Validation loss: 0.5023543877261025 RMSE: 0.7087697\n",
      "94 30 0.3084910213947296\n",
      "94 80 0.4378674030303955\n",
      "Validation loss: 0.5762014400391352 RMSE: 0.75907934\n",
      "95 25 0.12147979438304901\n",
      "95 75 0.3378587067127228\n",
      "Validation loss: 0.5393778460366385 RMSE: 0.7344235\n",
      "96 20 0.3525622487068176\n",
      "96 70 0.389334112405777\n",
      "Validation loss: 0.5417035552007812 RMSE: 0.7360051\n",
      "97 15 0.2842300832271576\n",
      "97 65 0.33458569645881653\n",
      "Validation loss: 0.5830157498518626 RMSE: 0.7635547\n",
      "98 10 0.38242560625076294\n",
      "98 60 0.2831296920776367\n",
      "Validation loss: 0.5271351002511524 RMSE: 0.72604066\n",
      "99 5 0.24079295992851257\n",
      "99 55 0.2367180436849594\n",
      "Validation loss: 0.5347006627491542 RMSE: 0.7312323\n",
      "100 0 0.30115097761154175\n",
      "100 50 0.21901436150074005\n",
      "100 100 0.30835065245628357\n",
      "Validation loss: 0.5109116151219323 RMSE: 0.7147808\n",
      "101 45 0.32048553228378296\n",
      "101 95 0.28785157203674316\n",
      "Validation loss: 0.5265758551302411 RMSE: 0.7256555\n",
      "102 40 0.20468643307685852\n",
      "102 90 0.31251466274261475\n",
      "Validation loss: 0.5150709061395554 RMSE: 0.7176844\n",
      "103 35 0.27691543102264404\n",
      "103 85 0.33172690868377686\n",
      "Validation loss: 0.5979475738746779 RMSE: 0.7732707\n",
      "104 30 0.1999809741973877\n",
      "104 80 0.25726407766342163\n",
      "Validation loss: 0.530195395151774 RMSE: 0.7281452\n",
      "105 25 0.28843170404434204\n",
      "105 75 0.2566099166870117\n",
      "Validation loss: 0.5415458577019828 RMSE: 0.73589796\n",
      "106 20 0.26943421363830566\n",
      "106 70 0.2201266586780548\n",
      "Validation loss: 0.531740961756025 RMSE: 0.7292057\n",
      "107 15 0.22449028491973877\n",
      "107 65 0.32333287596702576\n",
      "Validation loss: 0.5929174894378298 RMSE: 0.7700113\n",
      "108 10 0.25062766671180725\n",
      "108 60 0.1757460981607437\n",
      "Validation loss: 0.5355409843581064 RMSE: 0.7318067\n",
      "109 5 0.18582084774971008\n",
      "109 55 0.2556804120540619\n",
      "Validation loss: 0.5003871971652621 RMSE: 0.70738053\n",
      "110 0 0.3245471119880676\n",
      "110 50 0.3237146735191345\n",
      "110 100 0.3614470958709717\n",
      "Validation loss: 0.4938791678065345 RMSE: 0.70276535\n",
      "111 45 0.2919265925884247\n",
      "111 95 0.2970711886882782\n",
      "Validation loss: 0.5382621555101303 RMSE: 0.7336635\n",
      "112 40 0.3743722438812256\n",
      "112 90 0.4572456479072571\n",
      "Validation loss: 0.568211640346618 RMSE: 0.7537982\n",
      "113 35 0.271697998046875\n",
      "113 85 0.29459869861602783\n",
      "Validation loss: 0.5548467533929008 RMSE: 0.7448804\n",
      "114 30 0.2277182936668396\n",
      "114 80 0.4113593101501465\n",
      "Validation loss: 0.505311728091467 RMSE: 0.7108528\n",
      "115 25 0.4776875972747803\n",
      "115 75 0.25051239132881165\n",
      "Validation loss: 0.5177153927939279 RMSE: 0.71952444\n",
      "116 20 0.22116144001483917\n",
      "116 70 0.2534564733505249\n",
      "Validation loss: 0.5083029633476621 RMSE: 0.7129537\n",
      "117 15 0.32026395201683044\n",
      "117 65 0.32296308875083923\n",
      "Validation loss: 0.5058290981111072 RMSE: 0.7112166\n",
      "118 10 0.290945440530777\n",
      "118 60 0.37743642926216125\n",
      "Validation loss: 0.5461596091588338 RMSE: 0.7390261\n",
      "119 5 0.2158331573009491\n",
      "119 55 0.16437892615795135\n",
      "Validation loss: 0.5517139423461187 RMSE: 0.7427745\n",
      "120 0 0.23195788264274597\n",
      "120 50 0.1388070434331894\n",
      "120 100 0.25096622109413147\n",
      "Validation loss: 0.5051058684076581 RMSE: 0.710708\n",
      "121 45 0.12223818153142929\n",
      "121 95 0.3060595989227295\n",
      "Validation loss: 0.4965159292022387 RMSE: 0.7046389\n",
      "122 40 0.3642362058162689\n",
      "122 90 0.2192094475030899\n",
      "Validation loss: 0.5422193364018486 RMSE: 0.7363554\n",
      "123 35 0.15795482695102692\n",
      "123 85 0.17366701364517212\n",
      "Validation loss: 0.5032341809499832 RMSE: 0.70939\n",
      "124 30 0.24282807111740112\n",
      "124 80 0.3777071237564087\n",
      "Validation loss: 0.5393026743616377 RMSE: 0.73437226\n",
      "125 25 0.23389111459255219\n",
      "125 75 0.36550527811050415\n",
      "Validation loss: 0.5477090111800602 RMSE: 0.7400736\n",
      "126 20 0.13235794007778168\n",
      "126 70 0.31293031573295593\n",
      "Validation loss: 0.5253964844204131 RMSE: 0.72484237\n",
      "127 15 0.20367898046970367\n",
      "127 65 0.1621270775794983\n",
      "Validation loss: 0.5384793687434424 RMSE: 0.73381156\n",
      "128 10 0.15009860694408417\n",
      "128 60 0.2612779140472412\n",
      "Validation loss: 0.5666359384854635 RMSE: 0.75275224\n",
      "129 5 0.32224005460739136\n",
      "129 55 0.17340777814388275\n",
      "Validation loss: 0.5414266393298195 RMSE: 0.735817\n",
      "130 0 0.23334930837154388\n",
      "130 50 0.2455166131258011\n",
      "130 100 0.132765531539917\n",
      "Validation loss: 0.528345669451214 RMSE: 0.7268739\n",
      "131 45 0.4434312880039215\n",
      "131 95 0.22368715703487396\n",
      "Validation loss: 0.5808175654638381 RMSE: 0.76211387\n",
      "132 40 0.15166844427585602\n",
      "132 90 0.2670275866985321\n",
      "Validation loss: 0.5581428091440882 RMSE: 0.74708956\n",
      "133 35 0.2318364679813385\n",
      "133 85 0.175785630941391\n",
      "Validation loss: 0.5169707956768218 RMSE: 0.7190068\n",
      "134 30 0.20929916203022003\n",
      "134 80 0.1454673707485199\n",
      "Validation loss: 0.5474248212717828 RMSE: 0.73988163\n",
      "135 25 0.12581828236579895\n",
      "135 75 0.1578960418701172\n",
      "Validation loss: 0.540772260086877 RMSE: 0.7353722\n",
      "136 20 0.3559933006763458\n",
      "136 70 0.17046813666820526\n",
      "Validation loss: 0.5269656693651563 RMSE: 0.725924\n",
      "137 15 0.2543841302394867\n",
      "137 65 0.24947240948677063\n",
      "Validation loss: 0.54671168753079 RMSE: 0.7393996\n",
      "138 10 0.24781298637390137\n",
      "138 60 0.22619540989398956\n",
      "Validation loss: 0.527309368905567 RMSE: 0.7261607\n",
      "139 5 0.19514299929141998\n",
      "139 55 0.19894687831401825\n",
      "Validation loss: 0.5163021858249391 RMSE: 0.71854174\n",
      "140 0 0.13907353579998016\n",
      "140 50 0.17331808805465698\n",
      "140 100 0.35059940814971924\n",
      "Validation loss: 0.5449928749175299 RMSE: 0.73823637\n",
      "141 45 0.1597432792186737\n",
      "141 95 0.2471165657043457\n",
      "Validation loss: 0.5311307200363704 RMSE: 0.7287872\n",
      "142 40 0.1766534000635147\n",
      "142 90 0.22605590522289276\n",
      "Validation loss: 0.5336444780940102 RMSE: 0.73050976\n",
      "143 35 0.1885577142238617\n",
      "143 85 0.17925705015659332\n",
      "Validation loss: 0.5332403903915769 RMSE: 0.7302331\n",
      "144 30 0.3587733805179596\n",
      "144 80 0.14600352942943573\n",
      "Validation loss: 0.5114083744230724 RMSE: 0.7151282\n",
      "145 25 0.27098551392555237\n",
      "145 75 0.18481187522411346\n",
      "Validation loss: 0.547542470054967 RMSE: 0.7399611\n",
      "146 20 0.33152472972869873\n",
      "146 70 0.22543680667877197\n",
      "Validation loss: 0.57621664475827 RMSE: 0.75908935\n",
      "147 15 0.2646263539791107\n",
      "147 65 0.12187260389328003\n",
      "Validation loss: 0.4758860769725981 RMSE: 0.68984497\n",
      "148 10 0.25062990188598633\n",
      "148 60 0.15537698566913605\n",
      "Validation loss: 0.4990141187395368 RMSE: 0.70640934\n",
      "149 5 0.2788451015949249\n",
      "149 55 0.1423303782939911\n",
      "Validation loss: 0.4912772320565723 RMSE: 0.7009117\n",
      "150 0 0.1782519370317459\n",
      "150 50 0.1552073359489441\n",
      "150 100 0.11762412637472153\n",
      "Validation loss: 0.5312846024831136 RMSE: 0.7288927\n",
      "151 45 0.2360777109861374\n",
      "151 95 0.17288923263549805\n",
      "Validation loss: 0.5555965307213011 RMSE: 0.7453835\n",
      "152 40 0.3487168550491333\n",
      "152 90 0.2852095067501068\n",
      "Validation loss: 0.5295535655248733 RMSE: 0.72770435\n",
      "153 35 0.1983231157064438\n",
      "153 85 0.38388463854789734\n",
      "Validation loss: 0.5204901876903716 RMSE: 0.72145003\n",
      "154 30 0.28982341289520264\n",
      "154 80 0.28804659843444824\n",
      "Validation loss: 0.5254887413410914 RMSE: 0.724906\n",
      "155 25 0.1961962729692459\n",
      "155 75 0.1798374503850937\n",
      "Validation loss: 0.5304975262710027 RMSE: 0.7283526\n",
      "156 20 0.15437786281108856\n",
      "156 70 0.18443332612514496\n",
      "Validation loss: 0.5260157448904855 RMSE: 0.72526944\n",
      "157 15 0.18010342121124268\n",
      "157 65 0.1820662021636963\n",
      "Validation loss: 0.5253987780639103 RMSE: 0.724844\n",
      "158 10 0.3363323509693146\n",
      "158 60 0.15896961092948914\n",
      "Validation loss: 0.5278747149876186 RMSE: 0.72654986\n",
      "159 5 0.1747187077999115\n",
      "159 55 0.13811661303043365\n",
      "Validation loss: 0.549370500445366 RMSE: 0.7411953\n",
      "160 0 0.16656683385372162\n",
      "160 50 0.21426092088222504\n",
      "160 100 0.30417928099632263\n",
      "Validation loss: 0.48407090448197865 RMSE: 0.6957521\n",
      "161 45 0.16635043919086456\n",
      "161 95 0.25872424244880676\n",
      "Validation loss: 0.4984173896766844 RMSE: 0.7059868\n",
      "162 40 0.1132553294301033\n",
      "162 90 0.32527264952659607\n",
      "Validation loss: 0.5324631798835028 RMSE: 0.72970074\n",
      "163 35 0.2318137139081955\n",
      "163 85 0.11908204853534698\n",
      "Validation loss: 0.5435509301367261 RMSE: 0.73725903\n",
      "164 30 0.1941583901643753\n",
      "164 80 0.20766611397266388\n",
      "Validation loss: 0.5073051964952833 RMSE: 0.71225363\n",
      "165 25 0.20587795972824097\n",
      "165 75 0.20090346038341522\n",
      "Validation loss: 0.4960583351907276 RMSE: 0.70431405\n",
      "166 20 0.09572504460811615\n",
      "166 70 0.12379740923643112\n",
      "Validation loss: 0.6337059781664893 RMSE: 0.79605657\n",
      "167 15 0.3288382589817047\n",
      "167 65 0.18896548449993134\n",
      "Validation loss: 0.5045322790032342 RMSE: 0.7103044\n",
      "168 10 0.12848949432373047\n",
      "168 60 0.24462690949440002\n",
      "Validation loss: 0.5166496475537617 RMSE: 0.71878344\n",
      "169 5 0.07881335914134979\n",
      "169 55 0.13189473748207092\n",
      "Validation loss: 0.5321701912652879 RMSE: 0.72949994\n",
      "170 0 0.09930508583784103\n",
      "170 50 0.1911625862121582\n",
      "170 100 0.18991687893867493\n",
      "Validation loss: 0.5200302345412118 RMSE: 0.7211312\n",
      "171 45 0.11481411755084991\n",
      "171 95 0.1375008374452591\n",
      "Validation loss: 0.5222378123729002 RMSE: 0.7226602\n",
      "172 40 0.21131131052970886\n",
      "172 90 0.10488397628068924\n",
      "Validation loss: 0.528596838315328 RMSE: 0.72704667\n",
      "173 35 0.17976611852645874\n",
      "173 85 0.1247594952583313\n",
      "Validation loss: 0.49905596630913873 RMSE: 0.70643896\n",
      "174 30 0.07068616151809692\n",
      "174 80 -1.0386908054351807\n",
      "Validation loss: 0.938524178380058 RMSE: 0.9687745\n",
      "175 25 -9.617034912109375\n",
      "175 75 -17.352006912231445\n",
      "Validation loss: 0.7504986308869861 RMSE: 0.8663132\n",
      "176 20 -27.01961326599121\n",
      "176 70 -37.457637786865234\n",
      "Validation loss: 0.6582264809381394 RMSE: 0.81131154\n",
      "177 15 -49.68002700805664\n",
      "177 65 -59.07923126220703\n",
      "Validation loss: 0.6642484554222652 RMSE: 0.8150144\n",
      "178 10 -72.86138153076172\n",
      "178 60 -82.53087615966797\n",
      "Validation loss: 0.7218103686968486 RMSE: 0.84959424\n",
      "179 5 -92.4992904663086\n",
      "179 55 -103.18104553222656\n",
      "Validation loss: 0.7671922751835414 RMSE: 0.87589514\n",
      "180 0 -103.78092956542969\n",
      "180 50 -132.90745544433594\n",
      "180 100 -128.4968719482422\n",
      "Validation loss: 1.0038728804815382 RMSE: 1.0019345\n",
      "181 45 -158.1951446533203\n",
      "181 95 -173.78543090820312\n",
      "Validation loss: 1.1554641042436873 RMSE: 1.0749252\n",
      "182 40 -187.77293395996094\n",
      "182 90 -197.114501953125\n",
      "Validation loss: 1.0356589657919748 RMSE: 1.0176733\n",
      "183 35 -223.6498565673828\n",
      "183 85 -239.54638671875\n",
      "Validation loss: 0.9314205703281221 RMSE: 0.9651013\n",
      "184 30 -249.22128295898438\n",
      "184 80 -273.40234375\n",
      "Validation loss: 0.9514945228894551 RMSE: 0.9754458\n",
      "185 25 -289.50390625\n",
      "185 75 -308.5595703125\n",
      "Validation loss: 0.8700882258869352 RMSE: 0.9327852\n",
      "186 20 -307.0650939941406\n",
      "186 70 -345.9958190917969\n",
      "Validation loss: 1.1476443358830044 RMSE: 1.0712816\n",
      "187 15 -360.1908874511719\n",
      "187 65 -353.2550964355469\n",
      "Validation loss: 1.1750257653849465 RMSE: 1.083986\n",
      "188 10 -413.5043029785156\n",
      "188 60 -397.30120849609375\n",
      "Validation loss: 0.9856881516320365 RMSE: 0.9928183\n",
      "189 5 -396.24322509765625\n",
      "189 55 -439.9654541015625\n",
      "Validation loss: 0.8899366475286938 RMSE: 0.9433645\n",
      "190 0 -432.21502685546875\n",
      "190 50 -502.639892578125\n",
      "190 100 -517.5220336914062\n",
      "Validation loss: 0.8498625139395396 RMSE: 0.9218798\n",
      "191 45 -560.2431640625\n",
      "191 95 -549.4937744140625\n",
      "Validation loss: 0.9178557884125482 RMSE: 0.9580479\n",
      "192 40 -518.7031860351562\n",
      "192 90 -606.146240234375\n",
      "Validation loss: 0.9929796207518805 RMSE: 0.9964836\n",
      "193 35 -642.457763671875\n",
      "193 85 -652.5597534179688\n",
      "Validation loss: 0.8503030618031819 RMSE: 0.92211884\n",
      "194 30 -607.0364990234375\n",
      "194 80 -745.2902221679688\n",
      "Validation loss: 1.1913168384915307 RMSE: 1.0914747\n",
      "195 25 -697.3193969726562\n",
      "195 75 -743.5776977539062\n",
      "Validation loss: 0.9357126871744792 RMSE: 0.9673224\n",
      "196 20 -856.3985595703125\n",
      "196 70 -875.0255126953125\n",
      "Validation loss: 0.959001688730149 RMSE: 0.9792863\n",
      "197 15 -859.287353515625\n",
      "197 65 -934.1616821289062\n",
      "Validation loss: 0.8766233557746523 RMSE: 0.9362817\n",
      "198 10 -959.0275268554688\n",
      "198 60 -935.2279052734375\n",
      "Validation loss: 0.9249326206388928 RMSE: 0.9617342\n",
      "199 5 -914.130126953125\n",
      "199 55 -918.5858764648438\n",
      "Validation loss: 0.9293827749433972 RMSE: 0.964045\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.5050879086766924 Test RMSE: 0.7106954\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 779, 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'target': ['exp']}}\n",
      "Running on: cuda:1\n",
      "4199\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/4199\n",
      "Generating scaffold 1000/4199\n",
      "Generating scaffold 2000/4199\n",
      "Generating scaffold 3000/4199\n",
      "Generating scaffold 4000/4199\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 11.958316802978516\n",
      "0 50 3.6589531898498535\n",
      "0 100 2.179290771484375\n",
      "Validation loss: 1.2805427664802187 RMSE: 1.1316106\n",
      "1 45 1.4278810024261475\n",
      "1 95 1.7480477094650269\n",
      "Validation loss: 1.2073508597555616 RMSE: 1.0987952\n",
      "2 40 1.7729723453521729\n",
      "2 90 1.4052882194519043\n",
      "Validation loss: 1.2989653803053356 RMSE: 1.1397216\n",
      "3 35 1.3279727697372437\n",
      "3 85 1.365062952041626\n",
      "Validation loss: 1.277576496487572 RMSE: 1.1302993\n",
      "4 30 0.9916630983352661\n",
      "4 80 0.9256441593170166\n",
      "Validation loss: 0.9028808264505296 RMSE: 0.95020044\n",
      "5 25 1.0299828052520752\n",
      "5 75 1.0153812170028687\n",
      "Validation loss: 1.0861653509594145 RMSE: 1.0421926\n",
      "6 20 0.9062352180480957\n",
      "6 70 0.7461599707603455\n",
      "Validation loss: 0.871304595044681 RMSE: 0.93343693\n",
      "7 15 1.0718553066253662\n",
      "7 65 0.8558126091957092\n",
      "Validation loss: 0.9496338211354756 RMSE: 0.97449154\n",
      "8 10 0.8884062170982361\n",
      "8 60 0.8958160281181335\n",
      "Validation loss: 0.9882740764390855 RMSE: 0.99411976\n",
      "9 5 0.973347008228302\n",
      "9 55 0.929534912109375\n",
      "Validation loss: 0.7624984763917468 RMSE: 0.8732115\n",
      "10 0 0.639827311038971\n",
      "10 50 0.86363685131073\n",
      "10 100 1.1868667602539062\n",
      "Validation loss: 0.8365717445101056 RMSE: 0.914643\n",
      "11 45 0.7951549291610718\n",
      "11 95 0.7076074481010437\n",
      "Validation loss: 0.7357118714423406 RMSE: 0.85773647\n",
      "12 40 0.6638908982276917\n",
      "12 90 0.9593604803085327\n",
      "Validation loss: 1.0026747226715087 RMSE: 1.0013365\n",
      "13 35 0.7443872690200806\n",
      "13 85 1.05772066116333\n",
      "Validation loss: 0.7770931338980085 RMSE: 0.8815288\n",
      "14 30 0.7684795260429382\n",
      "14 80 0.49117302894592285\n",
      "Validation loss: 0.7564237344832647 RMSE: 0.8697263\n",
      "15 25 1.0268068313598633\n",
      "15 75 0.5541635751724243\n",
      "Validation loss: 0.8400001525878906 RMSE: 0.91651523\n",
      "16 20 0.6322903037071228\n",
      "16 70 0.4665597677230835\n",
      "Validation loss: 0.7277302185694376 RMSE: 0.85307103\n",
      "17 15 0.5113303661346436\n",
      "17 65 0.6721588373184204\n",
      "Validation loss: 0.7192510091123127 RMSE: 0.8480866\n",
      "18 10 0.6091558337211609\n",
      "18 60 0.6352542638778687\n",
      "Validation loss: 0.6678766591208322 RMSE: 0.8172372\n",
      "19 5 0.4738219678401947\n",
      "19 55 0.38518211245536804\n",
      "Validation loss: 0.6713538924853008 RMSE: 0.81936187\n",
      "20 0 0.6979172825813293\n",
      "20 50 0.7728925943374634\n",
      "20 100 0.37085628509521484\n",
      "Validation loss: 0.6821586092313131 RMSE: 0.825929\n",
      "21 45 0.4163615107536316\n",
      "21 95 0.5446311831474304\n",
      "Validation loss: 0.7363803664843241 RMSE: 0.85812604\n",
      "22 40 0.6685512661933899\n",
      "22 90 0.5768789052963257\n",
      "Validation loss: 0.9563619954245431 RMSE: 0.97793764\n",
      "23 35 0.6057834029197693\n",
      "23 85 0.5767567753791809\n",
      "Validation loss: 0.746575904744012 RMSE: 0.8640463\n",
      "24 30 0.629920244216919\n",
      "24 80 0.49694252014160156\n",
      "Validation loss: 0.6354226657322475 RMSE: 0.79713404\n",
      "25 25 0.48664823174476624\n",
      "25 75 0.6609753966331482\n",
      "Validation loss: 0.7089790784177326 RMSE: 0.84200895\n",
      "26 20 0.3144400417804718\n",
      "26 70 0.39307552576065063\n",
      "Validation loss: 0.7248996950331188 RMSE: 0.85141045\n",
      "27 15 0.5574751496315002\n",
      "27 65 0.6028856635093689\n",
      "Validation loss: 0.698817355292184 RMSE: 0.835953\n",
      "28 10 0.5638964772224426\n",
      "28 60 0.5172100067138672\n",
      "Validation loss: 0.5862013550031753 RMSE: 0.76563793\n",
      "29 5 0.34415626525878906\n",
      "29 55 0.643177330493927\n",
      "Validation loss: 0.6689455554598853 RMSE: 0.81789094\n",
      "30 0 0.5016891956329346\n",
      "30 50 0.4628877639770508\n",
      "30 100 0.750605583190918\n",
      "Validation loss: 0.765321550766627 RMSE: 0.8748266\n",
      "31 45 0.5452354550361633\n",
      "31 95 0.41114065051078796\n",
      "Validation loss: 0.635922276547977 RMSE: 0.7974473\n",
      "32 40 0.5152814388275146\n",
      "32 90 0.3979111909866333\n",
      "Validation loss: 0.6592478456951323 RMSE: 0.8119407\n",
      "33 35 0.49398794770240784\n",
      "33 85 0.7849286794662476\n",
      "Validation loss: 0.6189404348532359 RMSE: 0.7867276\n",
      "34 30 0.29788365960121155\n",
      "34 80 0.41780468821525574\n",
      "Validation loss: 0.6962684290749687 RMSE: 0.834427\n",
      "35 25 0.4936976730823517\n",
      "35 75 0.9222404956817627\n",
      "Validation loss: 0.6637662305718377 RMSE: 0.8147185\n",
      "36 20 0.4712546169757843\n",
      "36 70 0.4477483630180359\n",
      "Validation loss: 0.704018159139724 RMSE: 0.8390579\n",
      "37 15 0.4781491458415985\n",
      "37 65 0.31946706771850586\n",
      "Validation loss: 0.6207172410828726 RMSE: 0.7878561\n",
      "38 10 0.538529098033905\n",
      "38 60 0.3623669147491455\n",
      "Validation loss: 0.6409241230714888 RMSE: 0.8005774\n",
      "39 5 0.4564497768878937\n",
      "39 55 0.5219130516052246\n",
      "Validation loss: 0.6541681130727132 RMSE: 0.8088066\n",
      "40 0 0.5729186534881592\n",
      "40 50 0.689136266708374\n",
      "40 100 0.48279228806495667\n",
      "Validation loss: 0.6488567942664737 RMSE: 0.8055165\n",
      "41 45 0.35761600732803345\n",
      "41 95 0.3436688482761383\n",
      "Validation loss: 0.595912420182001 RMSE: 0.77195364\n",
      "42 40 0.3918239176273346\n",
      "42 90 0.4362782835960388\n",
      "Validation loss: 0.6475087483723958 RMSE: 0.8046793\n",
      "43 35 0.5094997882843018\n",
      "43 85 0.6603443622589111\n",
      "Validation loss: 0.6043665885925293 RMSE: 0.7774102\n",
      "44 30 0.3593212962150574\n",
      "44 80 0.27906015515327454\n",
      "Validation loss: 0.6130291489618165 RMSE: 0.7829618\n",
      "45 25 0.5993356108665466\n",
      "45 75 0.6527929902076721\n",
      "Validation loss: 0.5973183739752996 RMSE: 0.77286375\n",
      "46 20 0.6263844966888428\n",
      "46 70 0.411865234375\n",
      "Validation loss: 0.5801097949345907 RMSE: 0.76164937\n",
      "47 15 0.7528728246688843\n",
      "47 65 0.34099170565605164\n",
      "Validation loss: 0.5730856705279578 RMSE: 0.7570242\n",
      "48 10 0.26102399826049805\n",
      "48 60 0.5386602878570557\n",
      "Validation loss: 0.64106171471732 RMSE: 0.8006633\n",
      "49 5 0.5337409377098083\n",
      "49 55 0.4193471372127533\n",
      "Validation loss: 0.5592890570561091 RMSE: 0.7478563\n",
      "50 0 0.37749528884887695\n",
      "50 50 0.6181641817092896\n",
      "50 100 0.31155288219451904\n",
      "Validation loss: 0.5520318326495942 RMSE: 0.74298847\n",
      "51 45 0.4612220525741577\n",
      "51 95 0.39794841408729553\n",
      "Validation loss: 0.611228061573846 RMSE: 0.7818107\n",
      "52 40 0.35040098428726196\n",
      "52 90 0.5679635405540466\n",
      "Validation loss: 0.5979712528841836 RMSE: 0.773286\n",
      "53 35 0.35119396448135376\n",
      "53 85 0.28874239325523376\n",
      "Validation loss: 0.5379232254766283 RMSE: 0.73343253\n",
      "54 30 0.3260497450828552\n",
      "54 80 0.26912721991539\n",
      "Validation loss: 0.5764659035773504 RMSE: 0.7592535\n",
      "55 25 0.5520651936531067\n",
      "55 75 0.5959122180938721\n",
      "Validation loss: 0.6456583306902931 RMSE: 0.8035287\n",
      "56 20 0.45771709084510803\n",
      "56 70 0.4371676743030548\n",
      "Validation loss: 0.6085128795532954 RMSE: 0.78007233\n",
      "57 15 0.3052573800086975\n",
      "57 65 0.3652406334877014\n",
      "Validation loss: 0.5595682076045445 RMSE: 0.74804294\n",
      "58 10 0.33265066146850586\n",
      "58 60 0.4104255735874176\n",
      "Validation loss: 0.5797249521527972 RMSE: 0.7613967\n",
      "59 5 0.2722916603088379\n",
      "59 55 0.6326457858085632\n",
      "Validation loss: 0.5681972560428438 RMSE: 0.7537886\n",
      "60 0 0.28300485014915466\n",
      "60 50 0.5106850862503052\n",
      "60 100 0.33783358335494995\n",
      "Validation loss: 0.6481023998487563 RMSE: 0.80504805\n",
      "61 45 0.3188352584838867\n",
      "61 95 0.2941817343235016\n",
      "Validation loss: 0.5516373194399334 RMSE: 0.74272287\n",
      "62 40 0.43646684288978577\n",
      "62 90 0.5176582932472229\n",
      "Validation loss: 0.612801590419951 RMSE: 0.7828164\n",
      "63 35 0.18993712961673737\n",
      "63 85 0.673507809638977\n",
      "Validation loss: 0.605978034223829 RMSE: 0.7784459\n",
      "64 30 0.4593333899974823\n",
      "64 80 0.37511053681373596\n",
      "Validation loss: 0.5565245015280588 RMSE: 0.7460058\n",
      "65 25 0.3282519578933716\n",
      "65 75 0.42615583539009094\n",
      "Validation loss: 0.5657679103669666 RMSE: 0.75217545\n",
      "66 20 0.26700806617736816\n",
      "66 70 0.2867559790611267\n",
      "Validation loss: 0.6052093698864891 RMSE: 0.7779521\n",
      "67 15 0.21834297478199005\n",
      "67 65 0.25423434376716614\n",
      "Validation loss: 0.5776843699670974 RMSE: 0.76005554\n",
      "68 10 0.45219486951828003\n",
      "68 60 0.48721903562545776\n",
      "Validation loss: 0.5672583988734654 RMSE: 0.7531656\n",
      "69 5 0.32659658789634705\n",
      "69 55 0.25914621353149414\n",
      "Validation loss: 0.6031983375549317 RMSE: 0.7766584\n",
      "70 0 0.22833989560604095\n",
      "70 50 0.43261227011680603\n",
      "70 100 0.3369995951652527\n",
      "Validation loss: 0.5483331782477242 RMSE: 0.7404952\n",
      "71 45 0.3436903655529022\n",
      "71 95 0.39748772978782654\n",
      "Validation loss: 0.5727431615193684 RMSE: 0.75679797\n",
      "72 40 0.36264556646347046\n",
      "72 90 0.43449389934539795\n",
      "Validation loss: 0.580067887760344 RMSE: 0.7616219\n",
      "73 35 0.35776323080062866\n",
      "73 85 0.26057755947113037\n",
      "Validation loss: 0.5604190315519061 RMSE: 0.74861133\n",
      "74 30 0.3637693226337433\n",
      "74 80 0.3342873454093933\n",
      "Validation loss: 0.543813008921487 RMSE: 0.7374368\n",
      "75 25 0.7338249087333679\n",
      "75 75 0.3451671600341797\n",
      "Validation loss: 0.578898625146775 RMSE: 0.7608539\n",
      "76 20 0.25776970386505127\n",
      "76 70 0.42028966546058655\n",
      "Validation loss: 0.5918819643202282 RMSE: 0.76933867\n",
      "77 15 0.3884992301464081\n",
      "77 65 0.27693989872932434\n",
      "Validation loss: 0.5506447411718822 RMSE: 0.7420544\n",
      "78 10 0.19567464292049408\n",
      "78 60 0.5168828964233398\n",
      "Validation loss: 0.5187534399685405 RMSE: 0.72024536\n",
      "79 5 0.3155795931816101\n",
      "79 55 0.4513557255268097\n",
      "Validation loss: 0.5686127370312101 RMSE: 0.75406414\n",
      "80 0 0.6657682657241821\n",
      "80 50 0.408538818359375\n",
      "80 100 0.2645989954471588\n",
      "Validation loss: 0.5828813964412326 RMSE: 0.7634667\n",
      "81 45 0.29800060391426086\n",
      "81 95 0.369561105966568\n",
      "Validation loss: 0.5327901953742618 RMSE: 0.7299248\n",
      "82 40 0.4842621386051178\n",
      "82 90 0.3015866279602051\n",
      "Validation loss: 0.5606257143474761 RMSE: 0.74874943\n",
      "83 35 0.3981297016143799\n",
      "83 85 0.21262192726135254\n",
      "Validation loss: 0.6057457759266808 RMSE: 0.7782967\n",
      "84 30 0.27173101902008057\n",
      "84 80 0.23028329014778137\n",
      "Validation loss: 0.5489807418414525 RMSE: 0.74093235\n",
      "85 25 0.21449491381645203\n",
      "85 75 0.189263254404068\n",
      "Validation loss: 0.563632136015665 RMSE: 0.75075436\n",
      "86 20 0.39419105648994446\n",
      "86 70 0.3388836085796356\n",
      "Validation loss: 0.5818324832689195 RMSE: 0.7627795\n",
      "87 15 0.416066974401474\n",
      "87 65 0.45530134439468384\n",
      "Validation loss: 0.5404674302963983 RMSE: 0.7351649\n",
      "88 10 0.2597448229789734\n",
      "88 60 0.322164386510849\n",
      "Validation loss: 0.5753156349772499 RMSE: 0.7584956\n",
      "89 5 0.2569955587387085\n",
      "89 55 0.36422833800315857\n",
      "Validation loss: 0.5574131312824431 RMSE: 0.74660105\n",
      "90 0 0.36315321922302246\n",
      "90 50 0.21080970764160156\n",
      "90 100 0.3379870653152466\n",
      "Validation loss: 0.51744263058617 RMSE: 0.71933484\n",
      "91 45 0.3150886595249176\n",
      "91 95 0.34496840834617615\n",
      "Validation loss: 0.538393797760918 RMSE: 0.7337532\n",
      "92 40 0.3708050549030304\n",
      "92 90 0.2588690221309662\n",
      "Validation loss: 0.5290976354054042 RMSE: 0.727391\n",
      "93 35 0.1288813054561615\n",
      "93 85 0.38105157017707825\n",
      "Validation loss: 0.5313189199992588 RMSE: 0.7289162\n",
      "94 30 0.6418023109436035\n",
      "94 80 0.2698073089122772\n",
      "Validation loss: 0.5405012091000875 RMSE: 0.7351878\n",
      "95 25 0.43239498138427734\n",
      "95 75 0.26352033019065857\n",
      "Validation loss: 0.5308760383299419 RMSE: 0.7286124\n",
      "96 20 0.19482287764549255\n",
      "96 70 0.1573929786682129\n",
      "Validation loss: 0.5280937861828577 RMSE: 0.72670066\n",
      "97 15 0.3434470593929291\n",
      "97 65 0.39649152755737305\n",
      "Validation loss: 0.5206434147698539 RMSE: 0.72155625\n",
      "98 10 0.46237868070602417\n",
      "98 60 0.27002936601638794\n",
      "Validation loss: 0.517872192675159 RMSE: 0.71963334\n",
      "99 5 0.2930070757865906\n",
      "99 55 0.4108167588710785\n",
      "Validation loss: 0.5632805381502424 RMSE: 0.75052017\n",
      "100 0 0.232720285654068\n",
      "100 50 0.22515691816806793\n",
      "100 100 0.1883421093225479\n",
      "Validation loss: 0.5370426259580112 RMSE: 0.7328319\n",
      "101 45 0.2697407901287079\n",
      "101 95 0.2313980758190155\n",
      "Validation loss: 0.5523222291753406 RMSE: 0.7431838\n",
      "102 40 0.22028899192810059\n",
      "102 90 0.3067206144332886\n",
      "Validation loss: 0.5071826412564232 RMSE: 0.71216756\n",
      "103 35 0.2648773193359375\n",
      "103 85 0.33126696944236755\n",
      "Validation loss: 0.5005708387919835 RMSE: 0.7075103\n",
      "104 30 0.23430974781513214\n",
      "104 80 0.23785321414470673\n",
      "Validation loss: 0.523569221155984 RMSE: 0.72358084\n",
      "105 25 0.17998434603214264\n",
      "105 75 0.8600428700447083\n",
      "Validation loss: 0.5306366386867705 RMSE: 0.7284481\n",
      "106 20 0.14265435934066772\n",
      "106 70 0.29510658979415894\n",
      "Validation loss: 0.5174985105083102 RMSE: 0.7193737\n",
      "107 15 0.22701483964920044\n",
      "107 65 0.12875328958034515\n",
      "Validation loss: 0.5341306845347087 RMSE: 0.7308424\n",
      "108 10 0.18088214099407196\n",
      "108 60 0.2990531623363495\n",
      "Validation loss: 0.4924201216016497 RMSE: 0.7017265\n",
      "109 5 0.22192144393920898\n",
      "109 55 0.22632329165935516\n",
      "Validation loss: 0.5117938473111108 RMSE: 0.7153977\n",
      "110 0 0.4117358922958374\n",
      "110 50 0.33754920959472656\n",
      "110 100 0.35046809911727905\n",
      "Validation loss: 0.4822707653045654 RMSE: 0.6944572\n",
      "111 45 0.43583548069000244\n",
      "111 95 0.2832353115081787\n",
      "Validation loss: 0.5112555180277143 RMSE: 0.7150214\n",
      "112 40 0.29559147357940674\n",
      "112 90 0.29470905661582947\n",
      "Validation loss: 0.5125121802801178 RMSE: 0.7158996\n",
      "113 35 0.2858119308948517\n",
      "113 85 0.23218701779842377\n",
      "Validation loss: 0.49473142538751874 RMSE: 0.70337147\n",
      "114 30 0.19137993454933167\n",
      "114 80 0.2722296118736267\n",
      "Validation loss: 0.503548907098316 RMSE: 0.70961183\n",
      "115 25 0.5713137984275818\n",
      "115 75 0.28336548805236816\n",
      "Validation loss: 0.5109606595266433 RMSE: 0.71481514\n",
      "116 20 0.17349156737327576\n",
      "116 70 0.4866645336151123\n",
      "Validation loss: 0.49996575656391323 RMSE: 0.70708257\n",
      "117 15 0.14641982316970825\n",
      "117 65 0.30506598949432373\n",
      "Validation loss: 0.5084864580205508 RMSE: 0.7130824\n",
      "118 10 0.20738011598587036\n",
      "118 60 0.26509031653404236\n",
      "Validation loss: 0.5351654870169503 RMSE: 0.73155004\n",
      "119 5 0.2180730104446411\n",
      "119 55 0.29852795600891113\n",
      "Validation loss: 0.5271436674254281 RMSE: 0.7260466\n",
      "120 0 0.22165611386299133\n",
      "120 50 0.4248334467411041\n",
      "120 100 0.24705086648464203\n",
      "Validation loss: 0.4978812575340271 RMSE: 0.70560706\n",
      "121 45 0.1749819815158844\n",
      "121 95 0.28966274857521057\n",
      "Validation loss: 0.5343265289352054 RMSE: 0.73097646\n",
      "122 40 0.3213353753089905\n",
      "122 90 0.3017023503780365\n",
      "Validation loss: 0.5051200849669321 RMSE: 0.710718\n",
      "123 35 0.3789736032485962\n",
      "123 85 0.22887679934501648\n",
      "Validation loss: 0.512474622400034 RMSE: 0.7158733\n",
      "124 30 0.26472294330596924\n",
      "124 80 0.33122482895851135\n",
      "Validation loss: 0.5052296524956112 RMSE: 0.7107951\n",
      "125 25 0.19486548006534576\n",
      "125 75 0.1808580458164215\n",
      "Validation loss: 0.5415134339105515 RMSE: 0.7358759\n",
      "126 20 0.2503087818622589\n",
      "126 70 0.12571261823177338\n",
      "Validation loss: 0.5368378000599997 RMSE: 0.7326922\n",
      "127 15 0.20007964968681335\n",
      "127 65 0.33056169748306274\n",
      "Validation loss: 0.523283280645098 RMSE: 0.72338325\n",
      "128 10 0.5744710564613342\n",
      "128 60 0.2862306535243988\n",
      "Validation loss: 0.4749143530215536 RMSE: 0.6891403\n",
      "129 5 0.22580569982528687\n",
      "129 55 0.18637137115001678\n",
      "Validation loss: 0.5307591290701004 RMSE: 0.7285322\n",
      "130 0 0.4994087815284729\n",
      "130 50 0.12346988171339035\n",
      "130 100 0.22943036258220673\n",
      "Validation loss: 0.5206705438948813 RMSE: 0.721575\n",
      "131 45 0.3426920175552368\n",
      "131 95 0.1816243827342987\n",
      "Validation loss: 0.5049655514104026 RMSE: 0.71060926\n",
      "132 40 0.6141323447227478\n",
      "132 90 0.18188020586967468\n",
      "Validation loss: 0.5243860681851705 RMSE: 0.72414505\n",
      "133 35 0.16779419779777527\n",
      "133 85 0.2426822930574417\n",
      "Validation loss: 0.5333276771363757 RMSE: 0.73029286\n",
      "134 30 0.15026286244392395\n",
      "134 80 0.24514125287532806\n",
      "Validation loss: 0.48734308793431236 RMSE: 0.6980996\n",
      "135 25 0.32348722219467163\n",
      "135 75 0.4051446318626404\n",
      "Validation loss: 0.4986951606614249 RMSE: 0.7061835\n",
      "136 20 0.17317403852939606\n",
      "136 70 0.3001605272293091\n",
      "Validation loss: 0.49519802104859123 RMSE: 0.70370305\n",
      "137 15 0.17469453811645508\n",
      "137 65 0.29282793402671814\n",
      "Validation loss: 0.490025703396116 RMSE: 0.7000184\n",
      "138 10 0.16809335350990295\n",
      "138 60 0.2729036211967468\n",
      "Validation loss: 0.52827087583996 RMSE: 0.72682244\n",
      "139 5 0.273669570684433\n",
      "139 55 0.19290807843208313\n",
      "Validation loss: 0.5199269039290292 RMSE: 0.72105956\n",
      "140 0 0.1699962019920349\n",
      "140 50 0.28974461555480957\n",
      "140 100 0.3511009216308594\n",
      "Validation loss: 0.4947079116389865 RMSE: 0.7033548\n",
      "141 45 0.1678299903869629\n",
      "141 95 0.26605749130249023\n",
      "Validation loss: 0.5174696791739691 RMSE: 0.7193537\n",
      "142 40 0.23450466990470886\n",
      "142 90 0.256145179271698\n",
      "Validation loss: 0.5011580132302784 RMSE: 0.70792514\n",
      "143 35 0.26572269201278687\n",
      "143 85 0.16859599947929382\n",
      "Validation loss: 0.5181225254422143 RMSE: 0.71980727\n",
      "144 30 0.25513947010040283\n",
      "144 80 0.32317081093788147\n",
      "Validation loss: 0.5124205308301109 RMSE: 0.7158356\n",
      "145 25 0.31702497601509094\n",
      "145 75 0.25696656107902527\n",
      "Validation loss: 0.5071569192977179 RMSE: 0.7121495\n",
      "146 20 0.13554443418979645\n",
      "146 70 0.2110367715358734\n",
      "Validation loss: 0.5140168783210572 RMSE: 0.7169497\n",
      "147 15 0.10321953892707825\n",
      "147 65 0.19916127622127533\n",
      "Validation loss: 0.4878343167759123 RMSE: 0.69845134\n",
      "148 10 0.22548241913318634\n",
      "148 60 0.2235112190246582\n",
      "Validation loss: 0.488192465759459 RMSE: 0.6987077\n",
      "149 5 0.16236473619937897\n",
      "149 55 0.20870614051818848\n",
      "Validation loss: 0.500315458150137 RMSE: 0.7073298\n",
      "150 0 0.18686173856258392\n",
      "150 50 0.13732720911502838\n",
      "150 100 0.3275848925113678\n",
      "Validation loss: 0.511471472467695 RMSE: 0.71517235\n",
      "151 45 0.1507260650396347\n",
      "151 95 0.35520410537719727\n",
      "Validation loss: 0.49408534935542514 RMSE: 0.70291203\n",
      "152 40 0.13751305639743805\n",
      "152 90 0.2116357684135437\n",
      "Validation loss: 0.5190825961884998 RMSE: 0.7204738\n",
      "153 35 0.299527108669281\n",
      "153 85 0.1619638353586197\n",
      "Validation loss: 0.49840088401521954 RMSE: 0.7059751\n",
      "154 30 0.19342327117919922\n",
      "154 80 0.25392067432403564\n",
      "Validation loss: 0.48431187073389687 RMSE: 0.6959252\n",
      "155 25 0.21256737411022186\n",
      "155 75 0.15846076607704163\n",
      "Validation loss: 0.5096579144398371 RMSE: 0.7139033\n",
      "156 20 0.07326678931713104\n",
      "156 70 0.15650495886802673\n",
      "Validation loss: 0.47115863675162906 RMSE: 0.68640995\n",
      "157 15 0.1485368013381958\n",
      "157 65 0.4589766263961792\n",
      "Validation loss: 0.5097951023351579 RMSE: 0.7139994\n",
      "158 10 0.2940117418766022\n",
      "158 60 0.20938587188720703\n",
      "Validation loss: 0.5052816952977862 RMSE: 0.7108317\n",
      "159 5 0.12910039722919464\n",
      "159 55 0.1006556823849678\n",
      "Validation loss: 0.5306152562300365 RMSE: 0.7284334\n",
      "160 0 0.18349319696426392\n",
      "160 50 0.21414165198802948\n",
      "160 100 0.19241097569465637\n",
      "Validation loss: 0.4944489300251007 RMSE: 0.7031706\n",
      "161 45 0.2541654407978058\n",
      "161 95 0.3134618103504181\n",
      "Validation loss: 0.5077663319451469 RMSE: 0.7125773\n",
      "162 40 0.11263221502304077\n",
      "162 90 0.13471031188964844\n",
      "Validation loss: 0.5145594999903724 RMSE: 0.717328\n",
      "163 35 0.13982106745243073\n",
      "163 85 0.29205572605133057\n",
      "Validation loss: 0.5117530990214575 RMSE: 0.7153692\n",
      "164 30 0.21392999589443207\n",
      "164 80 0.22135384380817413\n",
      "Validation loss: 0.49885489429746355 RMSE: 0.7062966\n",
      "165 25 0.14794664084911346\n",
      "165 75 0.27058422565460205\n",
      "Validation loss: 0.4812740499065036 RMSE: 0.6937392\n",
      "166 20 0.3151368498802185\n",
      "166 70 0.1640695333480835\n",
      "Validation loss: 0.4760535296939668 RMSE: 0.6899663\n",
      "167 15 0.18035008013248444\n",
      "167 65 0.1612195521593094\n",
      "Validation loss: 0.48256816353116716 RMSE: 0.6946713\n",
      "168 10 0.23904702067375183\n",
      "168 60 0.14522592723369598\n",
      "Validation loss: 0.513863852478209 RMSE: 0.716843\n",
      "169 5 0.19734443724155426\n",
      "169 55 0.2888540029525757\n",
      "Validation loss: 0.4934040129184723 RMSE: 0.70242727\n",
      "170 0 0.20721164345741272\n",
      "170 50 0.23120638728141785\n",
      "170 100 0.10746017098426819\n",
      "Validation loss: 0.4857503811518351 RMSE: 0.69695795\n",
      "171 45 0.10065098106861115\n",
      "171 95 0.12869828939437866\n",
      "Validation loss: 0.504472298565365 RMSE: 0.7102621\n",
      "172 40 0.14210191369056702\n",
      "172 90 0.16009722650051117\n",
      "Validation loss: 0.5087887588001433 RMSE: 0.7132943\n",
      "173 35 0.162449449300766\n",
      "173 85 0.20091453194618225\n",
      "Validation loss: 0.4924299777973266 RMSE: 0.7017335\n",
      "174 30 0.2366524338722229\n",
      "174 80 0.14807990193367004\n",
      "Validation loss: 0.5061122829005832 RMSE: 0.7114157\n",
      "175 25 0.04600255936384201\n",
      "175 75 -3.783885955810547\n",
      "Validation loss: 0.8424470271383013 RMSE: 0.9178491\n",
      "176 20 -14.914073944091797\n",
      "176 70 -24.67639923095703\n",
      "Validation loss: 0.9610064296495346 RMSE: 0.98030937\n",
      "177 15 -32.8344841003418\n",
      "177 65 -42.900001525878906\n",
      "Validation loss: 1.4148392299811046 RMSE: 1.1894702\n",
      "178 10 -51.61796188354492\n",
      "178 60 -66.20052337646484\n",
      "Validation loss: 1.1756718397140502 RMSE: 1.084284\n",
      "179 5 -75.20958709716797\n",
      "179 55 -83.75337982177734\n",
      "Validation loss: 1.0018029928207397 RMSE: 1.0009011\n",
      "180 0 -96.18754577636719\n",
      "180 50 -109.4313735961914\n",
      "180 100 -120.57513427734375\n",
      "Validation loss: 0.8663534786020006 RMSE: 0.9307811\n",
      "181 45 -136.41732788085938\n",
      "181 95 -139.2487030029297\n",
      "Validation loss: 0.9210202259676797 RMSE: 0.95969796\n",
      "182 40 -153.6419677734375\n",
      "182 90 -161.52670288085938\n",
      "Validation loss: 0.8991940504028684 RMSE: 0.94825846\n",
      "183 35 -187.951904296875\n",
      "183 85 -194.9547882080078\n",
      "Validation loss: 1.1134641215914771 RMSE: 1.0552081\n",
      "184 30 -218.66561889648438\n",
      "184 80 -224.3366241455078\n",
      "Validation loss: 0.8956567537216913 RMSE: 0.94639146\n",
      "185 25 -252.9705810546875\n",
      "185 75 -248.61277770996094\n",
      "Validation loss: 0.8365805376143682 RMSE: 0.91464776\n",
      "186 20 -264.6459655761719\n",
      "186 70 -275.1828918457031\n",
      "Validation loss: 0.9014877537886302 RMSE: 0.94946706\n",
      "187 15 -332.5029602050781\n",
      "187 65 -314.51068115234375\n",
      "Validation loss: 1.0650557086581276 RMSE: 1.0320153\n",
      "188 10 -332.4835205078125\n",
      "188 60 -352.4761657714844\n",
      "Validation loss: 0.8179964593478611 RMSE: 0.9044316\n",
      "189 5 -361.4254150390625\n",
      "189 55 -409.6564636230469\n",
      "Validation loss: 0.9238233759289696 RMSE: 0.9611573\n",
      "190 0 -413.6518249511719\n",
      "190 50 -421.9517822265625\n",
      "190 100 -444.163330078125\n",
      "Validation loss: 0.9854860731533596 RMSE: 0.99271655\n",
      "191 45 -482.3094787597656\n",
      "191 95 -492.4673156738281\n",
      "Validation loss: 0.8689061987967718 RMSE: 0.9321514\n",
      "192 40 -509.5125732421875\n",
      "192 90 -552.8639526367188\n",
      "Validation loss: 0.852102944396791 RMSE: 0.9230942\n",
      "193 35 -535.4717407226562\n",
      "193 85 -602.04248046875\n",
      "Validation loss: 1.1803506967567263 RMSE: 1.0864395\n",
      "194 30 -590.1686401367188\n",
      "194 80 -630.7987060546875\n",
      "Validation loss: 1.00256615792002 RMSE: 1.0012823\n",
      "195 25 -625.544677734375\n",
      "195 75 -664.269775390625\n",
      "Validation loss: 0.9330068259012132 RMSE: 0.9659228\n",
      "196 20 -695.76953125\n",
      "196 70 -720.3153686523438\n",
      "Validation loss: 0.9085645942460923 RMSE: 0.9531865\n",
      "197 15 -740.1541137695312\n",
      "197 65 -758.2705688476562\n",
      "Validation loss: 0.9402940420877366 RMSE: 0.9696876\n",
      "198 10 -796.7300415039062\n",
      "198 60 -831.9756469726562\n",
      "Validation loss: 0.9520979114941188 RMSE: 0.9757551\n",
      "199 5 -802.3229370117188\n",
      "199 55 -901.2117919921875\n",
      "Validation loss: 0.9373989502588908 RMSE: 0.9681937\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.5402531731696356 Test RMSE: 0.7350192\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 780, 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'target': ['exp']}}\n",
      "Running on: cuda:1\n",
      "4199\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/4199\n",
      "Generating scaffold 1000/4199\n",
      "Generating scaffold 2000/4199\n",
      "Generating scaffold 3000/4199\n",
      "Generating scaffold 4000/4199\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 12.065613746643066\n",
      "0 50 3.3196263313293457\n",
      "0 100 2.550079107284546\n",
      "Validation loss: 1.5970869918664297 RMSE: 1.263759\n",
      "1 45 2.158301591873169\n",
      "1 95 1.7450790405273438\n",
      "Validation loss: 1.0612181748662677 RMSE: 1.0301545\n",
      "2 40 1.6429121494293213\n",
      "2 90 1.124137282371521\n",
      "Validation loss: 1.1228474849746342 RMSE: 1.0596449\n",
      "3 35 1.3830108642578125\n",
      "3 85 1.3021519184112549\n",
      "Validation loss: 1.1525194304330009 RMSE: 1.0735546\n",
      "4 30 1.3779101371765137\n",
      "4 80 0.9695395827293396\n",
      "Validation loss: 1.1118663061232794 RMSE: 1.0544506\n",
      "5 25 0.8012335896492004\n",
      "5 75 1.1812655925750732\n",
      "Validation loss: 0.927881079628354 RMSE: 0.96326584\n",
      "6 20 0.870824933052063\n",
      "6 70 1.0262465476989746\n",
      "Validation loss: 0.9259488446371896 RMSE: 0.96226233\n",
      "7 15 1.2455253601074219\n",
      "7 65 1.1418508291244507\n",
      "Validation loss: 0.9536202549934387 RMSE: 0.97653484\n",
      "8 10 0.8038188815116882\n",
      "8 60 0.7749394774436951\n",
      "Validation loss: 0.7523758218401955 RMSE: 0.867396\n",
      "9 5 0.6322187185287476\n",
      "9 55 0.7138921022415161\n",
      "Validation loss: 0.9264148269380842 RMSE: 0.96250445\n",
      "10 0 0.5037957429885864\n",
      "10 50 0.8491607308387756\n",
      "10 100 0.6909027099609375\n",
      "Validation loss: 0.7678744906470889 RMSE: 0.8762844\n",
      "11 45 0.6327387690544128\n",
      "11 95 0.7718299031257629\n",
      "Validation loss: 0.88810472261338 RMSE: 0.94239306\n",
      "12 40 0.7238197326660156\n",
      "12 90 1.0481282472610474\n",
      "Validation loss: 0.9174480619884673 RMSE: 0.9578351\n",
      "13 35 0.4847857356071472\n",
      "13 85 0.6909792423248291\n",
      "Validation loss: 0.8574248427436465 RMSE: 0.9259724\n",
      "14 30 0.6708353757858276\n",
      "14 80 0.7008081078529358\n",
      "Validation loss: 0.7188616820744106 RMSE: 0.84785706\n",
      "15 25 0.7904614806175232\n",
      "15 75 0.6511409878730774\n",
      "Validation loss: 0.7658257870447068 RMSE: 0.8751147\n",
      "16 20 1.0442626476287842\n",
      "16 70 0.6292168498039246\n",
      "Validation loss: 0.7276606071562994 RMSE: 0.8530302\n",
      "17 15 0.6260185241699219\n",
      "17 65 0.5877373218536377\n",
      "Validation loss: 0.7725482214064825 RMSE: 0.87894726\n",
      "18 10 0.6215209364891052\n",
      "18 60 0.842521071434021\n",
      "Validation loss: 0.7533906128434907 RMSE: 0.8679807\n",
      "19 5 0.6694836020469666\n",
      "19 55 0.6018783450126648\n",
      "Validation loss: 0.7228495458052272 RMSE: 0.8502056\n",
      "20 0 0.3824152946472168\n",
      "20 50 0.4180576503276825\n",
      "20 100 0.6895144581794739\n",
      "Validation loss: 1.0252449864432924 RMSE: 1.0125439\n",
      "21 45 0.3086605966091156\n",
      "21 95 0.515203058719635\n",
      "Validation loss: 0.7019926666503861 RMSE: 0.83785003\n",
      "22 40 0.5775974988937378\n",
      "22 90 0.4766330122947693\n",
      "Validation loss: 0.6560618897279104 RMSE: 0.80997646\n",
      "23 35 0.6444698572158813\n",
      "23 85 0.5032917857170105\n",
      "Validation loss: 0.7527297411646162 RMSE: 0.8676\n",
      "24 30 0.4035395681858063\n",
      "24 80 0.7786104083061218\n",
      "Validation loss: 0.7237931027298882 RMSE: 0.8507603\n",
      "25 25 0.3645382821559906\n",
      "25 75 0.39477279782295227\n",
      "Validation loss: 0.6990572310629345 RMSE: 0.83609647\n",
      "26 20 0.804941713809967\n",
      "26 70 0.8783543109893799\n",
      "Validation loss: 0.7762566248575846 RMSE: 0.8810543\n",
      "27 15 0.38780859112739563\n",
      "27 65 0.5260152816772461\n",
      "Validation loss: 0.6258480310440063 RMSE: 0.79110557\n",
      "28 10 0.42307400703430176\n",
      "28 60 0.8681913614273071\n",
      "Validation loss: 0.7159719864527384 RMSE: 0.8461513\n",
      "29 5 0.6405342817306519\n",
      "29 55 0.41164863109588623\n",
      "Validation loss: 0.7066143030212039 RMSE: 0.84060353\n",
      "30 0 0.7614495158195496\n",
      "30 50 0.8177264332771301\n",
      "30 100 0.5499160289764404\n",
      "Validation loss: 0.6275694688161214 RMSE: 0.7921928\n",
      "31 45 0.45745304226875305\n",
      "31 95 0.517937183380127\n",
      "Validation loss: 0.6304843634366989 RMSE: 0.7940304\n",
      "32 40 0.6216685175895691\n",
      "32 90 0.7442424297332764\n",
      "Validation loss: 0.6443784554799398 RMSE: 0.8027319\n",
      "33 35 0.43712255358695984\n",
      "33 85 0.48721471428871155\n",
      "Validation loss: 0.5798703676178342 RMSE: 0.7614922\n",
      "34 30 0.9695996642112732\n",
      "34 80 0.7309026718139648\n",
      "Validation loss: 0.7085516401699611 RMSE: 0.8417551\n",
      "35 25 0.7074527740478516\n",
      "35 75 1.214531660079956\n",
      "Validation loss: 0.6075599290075756 RMSE: 0.7794613\n",
      "36 20 0.8336614370346069\n",
      "36 70 0.4298049211502075\n",
      "Validation loss: 0.5858570689246768 RMSE: 0.76541305\n",
      "37 15 0.4309161901473999\n",
      "37 65 0.5379260182380676\n",
      "Validation loss: 0.6316241868904658 RMSE: 0.7947479\n",
      "38 10 0.4258151352405548\n",
      "38 60 0.5709426403045654\n",
      "Validation loss: 0.6277751230058216 RMSE: 0.79232264\n",
      "39 5 0.2849125266075134\n",
      "39 55 0.9873872399330139\n",
      "Validation loss: 0.5897716442743938 RMSE: 0.7679659\n",
      "40 0 0.8546540141105652\n",
      "40 50 0.5841782093048096\n",
      "40 100 0.23627465963363647\n",
      "Validation loss: 0.6360348440351941 RMSE: 0.79751796\n",
      "41 45 0.49807578325271606\n",
      "41 95 0.48870089650154114\n",
      "Validation loss: 0.6230591546921503 RMSE: 0.789341\n",
      "42 40 0.5130799412727356\n",
      "42 90 0.3812260925769806\n",
      "Validation loss: 0.5782995270831245 RMSE: 0.7604601\n",
      "43 35 0.3988754153251648\n",
      "43 85 0.6302754878997803\n",
      "Validation loss: 0.6174361314092364 RMSE: 0.7857711\n",
      "44 30 0.514074444770813\n",
      "44 80 0.2407890111207962\n",
      "Validation loss: 0.5967669152078174 RMSE: 0.7725069\n",
      "45 25 0.667015552520752\n",
      "45 75 0.7218396663665771\n",
      "Validation loss: 0.6323527018229167 RMSE: 0.79520607\n",
      "46 20 0.4196620583534241\n",
      "46 70 0.8011131882667542\n",
      "Validation loss: 0.5829452701977321 RMSE: 0.7635085\n",
      "47 15 0.45789068937301636\n",
      "47 65 0.47725293040275574\n",
      "Validation loss: 0.644904993829273 RMSE: 0.8030598\n",
      "48 10 0.24074114859104156\n",
      "48 60 0.6371139883995056\n",
      "Validation loss: 0.6284708457333701 RMSE: 0.7927615\n",
      "49 5 0.3599485158920288\n",
      "49 55 0.39422154426574707\n",
      "Validation loss: 0.5895555684963862 RMSE: 0.7678252\n",
      "50 0 0.3816916346549988\n",
      "50 50 0.41093891859054565\n",
      "50 100 0.45032382011413574\n",
      "Validation loss: 0.5733548209780739 RMSE: 0.75720197\n",
      "51 45 0.4135890007019043\n",
      "51 95 0.4693274199962616\n",
      "Validation loss: 0.6428512385913304 RMSE: 0.80178005\n",
      "52 40 0.23782944679260254\n",
      "52 90 0.44262707233428955\n",
      "Validation loss: 0.5943607805740265 RMSE: 0.770948\n",
      "53 35 0.5582271814346313\n",
      "53 85 0.42615580558776855\n",
      "Validation loss: 0.6708341706366766 RMSE: 0.81904465\n",
      "54 30 0.40985023975372314\n",
      "54 80 0.49619075655937195\n",
      "Validation loss: 0.6141073363167899 RMSE: 0.78365\n",
      "55 25 0.23940899968147278\n",
      "55 75 0.33965301513671875\n",
      "Validation loss: 0.5844542809895107 RMSE: 0.7644961\n",
      "56 20 0.5935675501823425\n",
      "56 70 0.4812384843826294\n",
      "Validation loss: 0.6328292358489264 RMSE: 0.79550564\n",
      "57 15 0.36915290355682373\n",
      "57 65 0.5915639400482178\n",
      "Validation loss: 0.5385489055088588 RMSE: 0.73385894\n",
      "58 10 0.46630674600601196\n",
      "58 60 0.4634503126144409\n",
      "Validation loss: 0.5969503970373244 RMSE: 0.7726257\n",
      "59 5 0.2570468783378601\n",
      "59 55 0.4041794240474701\n",
      "Validation loss: 0.5745488376844496 RMSE: 0.75799\n",
      "60 0 0.2759302258491516\n",
      "60 50 0.40669944882392883\n",
      "60 100 0.24613352119922638\n",
      "Validation loss: 0.6145983500140054 RMSE: 0.78396326\n",
      "61 45 0.3039146661758423\n",
      "61 95 0.3574804663658142\n",
      "Validation loss: 0.5935009786060879 RMSE: 0.77039015\n",
      "62 40 0.5783761143684387\n",
      "62 90 0.39273321628570557\n",
      "Validation loss: 0.6318253358205159 RMSE: 0.7948744\n",
      "63 35 0.35292720794677734\n",
      "63 85 0.4309825003147125\n",
      "Validation loss: 0.6287342288664409 RMSE: 0.7929276\n",
      "64 30 0.3548721671104431\n",
      "64 80 0.9164499640464783\n",
      "Validation loss: 0.602944116365342 RMSE: 0.77649474\n",
      "65 25 0.2818050682544708\n",
      "65 75 0.3027403652667999\n",
      "Validation loss: 0.5684752157756261 RMSE: 0.75397295\n",
      "66 20 0.684967041015625\n",
      "66 70 0.3728610575199127\n",
      "Validation loss: 0.5871540989194598 RMSE: 0.7662598\n",
      "67 15 0.26705893874168396\n",
      "67 65 0.43832892179489136\n",
      "Validation loss: 0.5559844743637812 RMSE: 0.7456437\n",
      "68 10 0.41635802388191223\n",
      "68 60 0.3131219446659088\n",
      "Validation loss: 0.5299440613814763 RMSE: 0.72797257\n",
      "69 5 0.3550233244895935\n",
      "69 55 0.3122182786464691\n",
      "Validation loss: 0.6128666457675752 RMSE: 0.782858\n",
      "70 0 0.5574855208396912\n",
      "70 50 0.2790684700012207\n",
      "70 100 0.33338800072669983\n",
      "Validation loss: 0.5860662214812778 RMSE: 0.76554966\n",
      "71 45 0.39196404814720154\n",
      "71 95 0.5476336479187012\n",
      "Validation loss: 0.5546386622247241 RMSE: 0.74474066\n",
      "72 40 0.49897488951683044\n",
      "72 90 0.6498127579689026\n",
      "Validation loss: 0.5687362988789876 RMSE: 0.7541461\n",
      "73 35 0.4194992482662201\n",
      "73 85 0.5544031858444214\n",
      "Validation loss: 0.5947164467402867 RMSE: 0.77117866\n",
      "74 30 0.46282634139060974\n",
      "74 80 0.3807811439037323\n",
      "Validation loss: 0.5895528305144537 RMSE: 0.76782346\n",
      "75 25 0.26677069067955017\n",
      "75 75 0.3204771876335144\n",
      "Validation loss: 0.5614719290108908 RMSE: 0.7493143\n",
      "76 20 0.3269585371017456\n",
      "76 70 0.33492764830589294\n",
      "Validation loss: 0.5811455204373315 RMSE: 0.76232904\n",
      "77 15 0.8980816006660461\n",
      "77 65 0.341472327709198\n",
      "Validation loss: 0.5401629323051089 RMSE: 0.73495775\n",
      "78 10 0.31568005681037903\n",
      "78 60 0.2629344165325165\n",
      "Validation loss: 0.5455482243072419 RMSE: 0.73861235\n",
      "79 5 0.3091314733028412\n",
      "79 55 0.3010709881782532\n",
      "Validation loss: 0.5826954862901143 RMSE: 0.76334494\n",
      "80 0 0.4207943379878998\n",
      "80 50 0.2461909055709839\n",
      "80 100 0.3663806617259979\n",
      "Validation loss: 0.5219210590635027 RMSE: 0.722441\n",
      "81 45 0.34890225529670715\n",
      "81 95 0.551476776599884\n",
      "Validation loss: 0.5334892877510615 RMSE: 0.7304035\n",
      "82 40 0.29270103573799133\n",
      "82 90 0.40495482087135315\n",
      "Validation loss: 0.5457878209295727 RMSE: 0.73877454\n",
      "83 35 0.6267734169960022\n",
      "83 85 0.41170796751976013\n",
      "Validation loss: 0.6232231384231931 RMSE: 0.7894448\n",
      "84 30 0.3061431050300598\n",
      "84 80 0.3170861601829529\n",
      "Validation loss: 0.5358765443166097 RMSE: 0.7320359\n",
      "85 25 0.36809492111206055\n",
      "85 75 0.2802625298500061\n",
      "Validation loss: 0.5273878665197463 RMSE: 0.72621477\n",
      "86 20 0.29199710488319397\n",
      "86 70 0.32978785037994385\n",
      "Validation loss: 0.551779025509244 RMSE: 0.74281836\n",
      "87 15 0.4499202370643616\n",
      "87 65 0.2914123237133026\n",
      "Validation loss: 0.5139902669759023 RMSE: 0.71693116\n",
      "88 10 0.3015199601650238\n",
      "88 60 0.4112081825733185\n",
      "Validation loss: 0.5066585222880046 RMSE: 0.7117995\n",
      "89 5 0.25347402691841125\n",
      "89 55 0.3672764003276825\n",
      "Validation loss: 0.5153532825765156 RMSE: 0.7178811\n",
      "90 0 0.5270942449569702\n",
      "90 50 0.26648032665252686\n",
      "90 100 0.22763249278068542\n",
      "Validation loss: 0.5834854029473804 RMSE: 0.7638622\n",
      "91 45 0.3177289366722107\n",
      "91 95 0.17680411040782928\n",
      "Validation loss: 0.5502269486586253 RMSE: 0.7417729\n",
      "92 40 0.37904247641563416\n",
      "92 90 0.32320669293403625\n",
      "Validation loss: 0.5616910571143741 RMSE: 0.7494605\n",
      "93 35 0.5072590112686157\n",
      "93 85 0.39908334612846375\n",
      "Validation loss: 0.5456752016430809 RMSE: 0.7386983\n",
      "94 30 0.2112841010093689\n",
      "94 80 0.15407945215702057\n",
      "Validation loss: 0.5269733928498768 RMSE: 0.7259294\n",
      "95 25 0.23069067299365997\n",
      "95 75 0.46450909972190857\n",
      "Validation loss: 0.5339233926364354 RMSE: 0.7307006\n",
      "96 20 0.2442065328359604\n",
      "96 70 0.27854862809181213\n",
      "Validation loss: 0.5334184845288594 RMSE: 0.730355\n",
      "97 15 0.36313995718955994\n",
      "97 65 0.2783932387828827\n",
      "Validation loss: 0.5299534854434785 RMSE: 0.72797906\n",
      "98 10 0.307744562625885\n",
      "98 60 0.42244797945022583\n",
      "Validation loss: 0.5454167235465277 RMSE: 0.7385233\n",
      "99 5 0.22207079827785492\n",
      "99 55 0.34030622243881226\n",
      "Validation loss: 0.561307943718774 RMSE: 0.7492049\n",
      "100 0 0.2537263333797455\n",
      "100 50 0.33074837923049927\n",
      "100 100 0.3247329294681549\n",
      "Validation loss: 0.5444335182507832 RMSE: 0.7378574\n",
      "101 45 0.3668139576911926\n",
      "101 95 0.32529738545417786\n",
      "Validation loss: 0.4890517717316037 RMSE: 0.69932234\n",
      "102 40 0.3354382812976837\n",
      "102 90 0.37366288900375366\n",
      "Validation loss: 0.5119067101251511 RMSE: 0.7154766\n",
      "103 35 0.24570824205875397\n",
      "103 85 0.2391444891691208\n",
      "Validation loss: 0.5262693200792585 RMSE: 0.7254442\n",
      "104 30 0.30799320340156555\n",
      "104 80 0.34831079840660095\n",
      "Validation loss: 0.5324774410043444 RMSE: 0.72971046\n",
      "105 25 0.19423125684261322\n",
      "105 75 0.4016273617744446\n",
      "Validation loss: 0.5392639313425337 RMSE: 0.7343459\n",
      "106 20 0.33972203731536865\n",
      "106 70 0.37000834941864014\n",
      "Validation loss: 0.4963476694765545 RMSE: 0.70451945\n",
      "107 15 0.19331060349941254\n",
      "107 65 0.2749374508857727\n",
      "Validation loss: 0.5191732669870058 RMSE: 0.72053677\n",
      "108 10 0.35141128301620483\n",
      "108 60 0.22491183876991272\n",
      "Validation loss: 0.5032810608545939 RMSE: 0.70942307\n",
      "109 5 0.3922179043292999\n",
      "109 55 0.28809306025505066\n",
      "Validation loss: 0.5355690734017463 RMSE: 0.7318258\n",
      "110 0 0.11159735918045044\n",
      "110 50 0.21296361088752747\n",
      "110 100 0.219091534614563\n",
      "Validation loss: 0.5284653396833511 RMSE: 0.7269562\n",
      "111 45 0.17885777354240417\n",
      "111 95 0.41389957070350647\n",
      "Validation loss: 0.51436693412917 RMSE: 0.7171938\n",
      "112 40 0.172714963555336\n",
      "112 90 0.2747310698032379\n",
      "Validation loss: 0.4966475486755371 RMSE: 0.70473224\n",
      "113 35 0.34320762753486633\n",
      "113 85 0.3930644690990448\n",
      "Validation loss: 0.5239843814145951 RMSE: 0.72386765\n",
      "114 30 0.28094398975372314\n",
      "114 80 0.1412104368209839\n",
      "Validation loss: 0.5098334698449998 RMSE: 0.7140263\n",
      "115 25 0.3553348183631897\n",
      "115 75 0.3335406184196472\n",
      "Validation loss: 0.4839678378332229 RMSE: 0.69567794\n",
      "116 20 0.18866638839244843\n",
      "116 70 0.22262045741081238\n",
      "Validation loss: 0.5194734356233052 RMSE: 0.720745\n",
      "117 15 0.2267647385597229\n",
      "117 65 0.3835298717021942\n",
      "Validation loss: 0.5689198412355922 RMSE: 0.75426775\n",
      "118 10 0.15991754829883575\n",
      "118 60 0.2438882738351822\n",
      "Validation loss: 0.46794832206907727 RMSE: 0.6840675\n",
      "119 5 0.22512386739253998\n",
      "119 55 0.2139037400484085\n",
      "Validation loss: 0.5156637248538789 RMSE: 0.7180973\n",
      "120 0 0.5567095279693604\n",
      "120 50 0.4302907884120941\n",
      "120 100 0.23080123960971832\n",
      "Validation loss: 0.5110922728266035 RMSE: 0.71490717\n",
      "121 45 0.36823585629463196\n",
      "121 95 0.199003666639328\n",
      "Validation loss: 0.5089813669522604 RMSE: 0.7134293\n",
      "122 40 0.2314165234565735\n",
      "122 90 0.2121129184961319\n",
      "Validation loss: 0.4977581597509838 RMSE: 0.70551974\n",
      "123 35 0.509146511554718\n",
      "123 85 0.1971687376499176\n",
      "Validation loss: 0.5325298462595258 RMSE: 0.7297464\n",
      "124 30 0.20902177691459656\n",
      "124 80 0.2763682007789612\n",
      "Validation loss: 0.4741691714241391 RMSE: 0.68859947\n",
      "125 25 0.3531606197357178\n",
      "125 75 0.14718826115131378\n",
      "Validation loss: 0.4770838805607387 RMSE: 0.6907126\n",
      "126 20 0.18710048496723175\n",
      "126 70 0.2432866096496582\n",
      "Validation loss: 0.5413521795045761 RMSE: 0.73576635\n",
      "127 15 0.24681082367897034\n",
      "127 65 0.4643968939781189\n",
      "Validation loss: 0.5526333899725051 RMSE: 0.7433932\n",
      "128 10 0.31482747197151184\n",
      "128 60 0.23151108622550964\n",
      "Validation loss: 0.5067231047721136 RMSE: 0.71184486\n",
      "129 5 0.19633741676807404\n",
      "129 55 0.19466347992420197\n",
      "Validation loss: 0.5168334966614133 RMSE: 0.7189113\n",
      "130 0 0.3707825839519501\n",
      "130 50 0.42931878566741943\n",
      "130 100 0.2589464783668518\n",
      "Validation loss: 0.5288604844184149 RMSE: 0.727228\n",
      "131 45 0.3657481372356415\n",
      "131 95 0.3118065893650055\n",
      "Validation loss: 0.4967675595056443 RMSE: 0.70481735\n",
      "132 40 0.2387036383152008\n",
      "132 90 0.24437572062015533\n",
      "Validation loss: 0.5160123918116802 RMSE: 0.71834004\n",
      "133 35 0.30039119720458984\n",
      "133 85 0.16073037683963776\n",
      "Validation loss: 0.5071549659683591 RMSE: 0.71214813\n",
      "134 30 0.17690514028072357\n",
      "134 80 0.285918265581131\n",
      "Validation loss: 0.5386907895406087 RMSE: 0.7339556\n",
      "135 25 0.2104446291923523\n",
      "135 75 0.18062801659107208\n",
      "Validation loss: 0.5523627874397096 RMSE: 0.74321115\n",
      "136 20 0.18117287755012512\n",
      "136 70 0.13369718194007874\n",
      "Validation loss: 0.5325578094947906 RMSE: 0.7297656\n",
      "137 15 0.16316033899784088\n",
      "137 65 0.20157405734062195\n",
      "Validation loss: 0.48031435580480664 RMSE: 0.69304717\n",
      "138 10 0.25487688183784485\n",
      "138 60 0.19105581939220428\n",
      "Validation loss: 0.4799406151686396 RMSE: 0.69277745\n",
      "139 5 0.2402212768793106\n",
      "139 55 0.2399074137210846\n",
      "Validation loss: 0.5429131394340878 RMSE: 0.7368264\n",
      "140 0 0.2917972207069397\n",
      "140 50 0.19623762369155884\n",
      "140 100 0.21333104372024536\n",
      "Validation loss: 0.5262215455373128 RMSE: 0.7254113\n",
      "141 45 0.18311993777751923\n",
      "141 95 0.206304132938385\n",
      "Validation loss: 0.5220562704971858 RMSE: 0.7225346\n",
      "142 40 0.2625587284564972\n",
      "142 90 0.18218070268630981\n",
      "Validation loss: 0.5167516799200149 RMSE: 0.7188544\n",
      "143 35 0.2176164984703064\n",
      "143 85 0.23437130451202393\n",
      "Validation loss: 0.5028113379364922 RMSE: 0.7090919\n",
      "144 30 0.13842856884002686\n",
      "144 80 0.11865328252315521\n",
      "Validation loss: 0.5145922870863051 RMSE: 0.7173509\n",
      "145 25 0.22627563774585724\n",
      "145 75 0.17948469519615173\n",
      "Validation loss: 0.5193159478051322 RMSE: 0.7206358\n",
      "146 20 0.17435245215892792\n",
      "146 70 0.2934766113758087\n",
      "Validation loss: 0.5001932575589134 RMSE: 0.70724344\n",
      "147 15 0.2189047634601593\n",
      "147 65 0.21920229494571686\n",
      "Validation loss: 0.539640235900879 RMSE: 0.7346021\n",
      "148 10 0.18058466911315918\n",
      "148 60 0.22411613166332245\n",
      "Validation loss: 0.5127607470466977 RMSE: 0.71607316\n",
      "149 5 0.17229093611240387\n",
      "149 55 0.23808403313159943\n",
      "Validation loss: 0.5783341796625228 RMSE: 0.7604829\n",
      "150 0 0.23369961977005005\n",
      "150 50 0.2571355104446411\n",
      "150 100 0.33576828241348267\n",
      "Validation loss: 0.5100562686011905 RMSE: 0.71418226\n",
      "151 45 0.20728467404842377\n",
      "151 95 0.1357875019311905\n",
      "Validation loss: 0.5558158888703301 RMSE: 0.7455306\n",
      "152 40 0.11599275469779968\n",
      "152 90 0.24581840634346008\n",
      "Validation loss: 0.4813261730330331 RMSE: 0.6937768\n",
      "153 35 0.19027835130691528\n",
      "153 85 0.1976231038570404\n",
      "Validation loss: 0.5194402354104178 RMSE: 0.720722\n",
      "154 30 0.30368366837501526\n",
      "154 80 0.09026134759187698\n",
      "Validation loss: 0.5281807626996722 RMSE: 0.72676045\n",
      "155 25 0.20119240880012512\n",
      "155 75 0.2049534171819687\n",
      "Validation loss: 0.527661903699239 RMSE: 0.7264034\n",
      "156 20 0.23032203316688538\n",
      "156 70 0.2743528187274933\n",
      "Validation loss: 0.5017486878803799 RMSE: 0.7083422\n",
      "157 15 0.2856842279434204\n",
      "157 65 0.23040157556533813\n",
      "Validation loss: 0.5043324206556593 RMSE: 0.71016365\n",
      "158 10 0.15474896132946014\n",
      "158 60 0.2009044736623764\n",
      "Validation loss: 0.500031807592937 RMSE: 0.70712924\n",
      "159 5 0.2375159114599228\n",
      "159 55 0.291517972946167\n",
      "Validation loss: 0.508463716506958 RMSE: 0.71306646\n",
      "160 0 0.08959190547466278\n",
      "160 50 0.23744675517082214\n",
      "160 100 0.19861271977424622\n",
      "Validation loss: 0.5048525509380158 RMSE: 0.7105298\n",
      "161 45 0.10541251301765442\n",
      "161 95 0.2475620061159134\n",
      "Validation loss: 0.4901842508997236 RMSE: 0.7001316\n",
      "162 40 0.13592974841594696\n",
      "162 90 0.22423751652240753\n",
      "Validation loss: 0.5326823450270153 RMSE: 0.7298509\n",
      "163 35 0.1900976151227951\n",
      "163 85 0.11393684148788452\n",
      "Validation loss: 0.5226435232730139 RMSE: 0.72294086\n",
      "164 30 0.18321983516216278\n",
      "164 80 0.2682112455368042\n",
      "Validation loss: 0.5022063973404113 RMSE: 0.7086652\n",
      "165 25 0.2162124365568161\n",
      "165 75 0.1707846224308014\n",
      "Validation loss: 0.5072160996141888 RMSE: 0.7121911\n",
      "166 20 0.14115677773952484\n",
      "166 70 0.1701073795557022\n",
      "Validation loss: 0.5166166359470004 RMSE: 0.7187605\n",
      "167 15 0.09827932715415955\n",
      "167 65 0.11302650719881058\n",
      "Validation loss: 0.5719226485206967 RMSE: 0.7562557\n",
      "168 10 0.14790642261505127\n",
      "168 60 0.1876779943704605\n",
      "Validation loss: 0.5099228399140494 RMSE: 0.7140888\n",
      "169 5 0.1289246678352356\n",
      "169 55 0.29111209511756897\n",
      "Validation loss: 0.5128269950548808 RMSE: 0.7161194\n",
      "170 0 0.23422610759735107\n",
      "170 50 0.3328985869884491\n",
      "170 100 0.2044467329978943\n",
      "Validation loss: 0.5423298532054538 RMSE: 0.73643047\n",
      "171 45 0.2503051459789276\n",
      "171 95 0.16543008387088776\n",
      "Validation loss: 0.5784483009860629 RMSE: 0.7605579\n",
      "172 40 0.10857664048671722\n",
      "172 90 0.16638702154159546\n",
      "Validation loss: 0.5086093017033169 RMSE: 0.7131685\n",
      "173 35 0.20660337805747986\n",
      "173 85 0.32724621891975403\n",
      "Validation loss: 0.5413271120616368 RMSE: 0.73574936\n",
      "174 30 0.1581098735332489\n",
      "174 80 0.1895597130060196\n",
      "Validation loss: 0.5180927004132952 RMSE: 0.7197866\n",
      "175 25 -2.162649631500244\n",
      "175 75 -10.369733810424805\n",
      "Validation loss: 0.714252952166966 RMSE: 0.8451349\n",
      "176 20 -22.91373634338379\n",
      "176 70 -28.527076721191406\n",
      "Validation loss: 0.9342928682054792 RMSE: 0.96658826\n",
      "177 15 -41.52919006347656\n",
      "177 65 -50.38047409057617\n",
      "Validation loss: 1.017790709223066 RMSE: 1.008856\n",
      "178 10 -58.72452163696289\n",
      "178 60 -67.28119659423828\n",
      "Validation loss: 0.6551841264679319 RMSE: 0.8094345\n",
      "179 5 -80.23107147216797\n",
      "179 55 -96.8290786743164\n",
      "Validation loss: 0.7051430583000183 RMSE: 0.839728\n",
      "180 0 -104.67848205566406\n",
      "180 50 -116.91742706298828\n",
      "180 100 -133.51309204101562\n",
      "Validation loss: 0.8164784198715573 RMSE: 0.90359193\n",
      "181 45 -141.29251098632812\n",
      "181 95 -159.3740997314453\n",
      "Validation loss: 0.7566808677854993 RMSE: 0.86987406\n",
      "182 40 -183.11471557617188\n",
      "182 90 -180.6195526123047\n",
      "Validation loss: 0.9315011183420817 RMSE: 0.965143\n",
      "183 35 -213.09796142578125\n",
      "183 85 -202.39431762695312\n",
      "Validation loss: 0.9537778377532959 RMSE: 0.9766155\n",
      "184 30 -256.4570007324219\n",
      "184 80 -231.01231384277344\n",
      "Validation loss: 1.0747172940345038 RMSE: 1.0366858\n",
      "185 25 -277.5618896484375\n",
      "185 75 -288.527099609375\n",
      "Validation loss: 0.8604777177174886 RMSE: 0.92761934\n",
      "186 20 -309.271484375\n",
      "186 70 -282.6719970703125\n",
      "Validation loss: 0.8429536388033912 RMSE: 0.91812503\n",
      "187 15 -329.2080078125\n",
      "187 65 -344.62225341796875\n",
      "Validation loss: 0.8009899241583688 RMSE: 0.89498043\n",
      "188 10 -369.15948486328125\n",
      "188 60 -365.9529724121094\n",
      "Validation loss: 0.9057821926616487 RMSE: 0.9517259\n",
      "189 5 -400.91973876953125\n",
      "189 55 -447.9985656738281\n",
      "Validation loss: 0.9383629094986689 RMSE: 0.96869135\n",
      "190 0 -475.726318359375\n",
      "190 50 -525.6551513671875\n",
      "190 100 -503.78350830078125\n",
      "Validation loss: 0.8129552111739204 RMSE: 0.90164036\n",
      "191 45 -459.5448913574219\n",
      "191 95 -513.0164184570312\n",
      "Validation loss: 0.8807314215671449 RMSE: 0.9384729\n",
      "192 40 -572.68798828125\n",
      "192 90 -617.6843872070312\n",
      "Validation loss: 0.883570235258057 RMSE: 0.93998414\n",
      "193 35 -526.9759521484375\n",
      "193 85 -634.1888427734375\n",
      "Validation loss: 1.2214137894766672 RMSE: 1.1051759\n",
      "194 30 -678.8687133789062\n",
      "194 80 -679.1867065429688\n",
      "Validation loss: 0.9460454458282107 RMSE: 0.97264874\n",
      "195 25 -731.5580444335938\n",
      "195 75 -654.3526000976562\n",
      "Validation loss: 0.9111565578551519 RMSE: 0.9545452\n",
      "196 20 -776.5338134765625\n",
      "196 70 -791.5499267578125\n",
      "Validation loss: 0.9236568519047328 RMSE: 0.9610707\n",
      "197 15 -831.4647827148438\n",
      "197 65 -885.2244262695312\n",
      "Validation loss: 1.2725482849847702 RMSE: 1.1280729\n",
      "198 10 -930.9591674804688\n",
      "198 60 -868.6893310546875\n",
      "Validation loss: 0.9808769226074219 RMSE: 0.9903923\n",
      "199 5 -945.0886840820312\n",
      "199 55 -934.7720947265625\n",
      "Validation loss: 0.9310451870872861 RMSE: 0.9649069\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.5219384860424768 Test RMSE: 0.7224531\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'target': ['exp']}}\n",
      "Running on: cuda:1\n",
      "4199\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/4199\n",
      "Generating scaffold 1000/4199\n",
      "Generating scaffold 2000/4199\n",
      "Generating scaffold 3000/4199\n",
      "Generating scaffold 4000/4199\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 13.835044860839844\n",
      "0 50 3.5378870964050293\n",
      "0 100 2.5325589179992676\n",
      "Validation loss: 1.2142414933159238 RMSE: 1.1019263\n",
      "1 45 1.8878018856048584\n",
      "1 95 1.5144388675689697\n",
      "Validation loss: 1.022984950883048 RMSE: 1.0114272\n",
      "2 40 1.6691616773605347\n",
      "2 90 1.73439359664917\n",
      "Validation loss: 1.008201255117144 RMSE: 1.0040922\n",
      "3 35 3.0018880367279053\n",
      "3 85 1.2677464485168457\n",
      "Validation loss: 1.3101325951871419 RMSE: 1.1446102\n",
      "4 30 1.1259324550628662\n",
      "4 80 1.2952775955200195\n",
      "Validation loss: 1.2582062403361003 RMSE: 1.1216979\n",
      "5 25 1.03831148147583\n",
      "5 75 0.9013508558273315\n",
      "Validation loss: 0.8931497420583453 RMSE: 0.945066\n",
      "6 20 1.121786117553711\n",
      "6 70 0.7350711822509766\n",
      "Validation loss: 0.8744174679120381 RMSE: 0.93510294\n",
      "7 15 0.7930516004562378\n",
      "7 65 1.4721240997314453\n",
      "Validation loss: 0.8334515230996268 RMSE: 0.9129357\n",
      "8 10 0.764684796333313\n",
      "8 60 0.6365037560462952\n",
      "Validation loss: 1.0026581383886792 RMSE: 1.0013282\n",
      "9 5 1.133199691772461\n",
      "9 55 0.7445755004882812\n",
      "Validation loss: 0.7929800564334506 RMSE: 0.8904943\n",
      "10 0 0.563391923904419\n",
      "10 50 0.7450882196426392\n",
      "10 100 0.9305728673934937\n",
      "Validation loss: 1.0204683014324734 RMSE: 1.0101823\n",
      "11 45 0.8545754551887512\n",
      "11 95 0.5725606083869934\n",
      "Validation loss: 0.87616630004985 RMSE: 0.9360376\n",
      "12 40 0.6489920020103455\n",
      "12 90 0.8245988488197327\n",
      "Validation loss: 0.7526567609537216 RMSE: 0.86755794\n",
      "13 35 0.702584981918335\n",
      "13 85 0.7424988746643066\n",
      "Validation loss: 0.8859984261648995 RMSE: 0.9412749\n",
      "14 30 0.6341731548309326\n",
      "14 80 0.54437255859375\n",
      "Validation loss: 0.7931407653150104 RMSE: 0.89058447\n",
      "15 25 0.5710675120353699\n",
      "15 75 0.9727886915206909\n",
      "Validation loss: 0.7771539619990757 RMSE: 0.88156337\n",
      "16 20 1.0091111660003662\n",
      "16 70 0.7729980945587158\n",
      "Validation loss: 0.7900052189826965 RMSE: 0.8888224\n",
      "17 15 0.6256504058837891\n",
      "17 65 0.6614545583724976\n",
      "Validation loss: 0.8924398297355288 RMSE: 0.9446903\n",
      "18 10 0.7497549057006836\n",
      "18 60 0.4363665282726288\n",
      "Validation loss: 0.6903234300159272 RMSE: 0.8308571\n",
      "19 5 0.46937936544418335\n",
      "19 55 1.0269445180892944\n",
      "Validation loss: 0.7727967733428591 RMSE: 0.8790886\n",
      "20 0 0.6192218661308289\n",
      "20 50 0.8680822253227234\n",
      "20 100 0.6494624614715576\n",
      "Validation loss: 0.9214638034502666 RMSE: 0.95992905\n",
      "21 45 0.7598600387573242\n",
      "21 95 0.5664442181587219\n",
      "Validation loss: 0.8502236797696068 RMSE: 0.92207575\n",
      "22 40 0.5980716943740845\n",
      "22 90 0.3779536187648773\n",
      "Validation loss: 0.67358307157244 RMSE: 0.8207211\n",
      "23 35 0.7173248529434204\n",
      "23 85 0.7264571785926819\n",
      "Validation loss: 0.7452925494738988 RMSE: 0.8633033\n",
      "24 30 0.43106406927108765\n",
      "24 80 0.3703233003616333\n",
      "Validation loss: 0.712328842424211 RMSE: 0.84399575\n",
      "25 25 0.5691113471984863\n",
      "25 75 0.7775839567184448\n",
      "Validation loss: 0.7763428353127979 RMSE: 0.88110316\n",
      "26 20 0.452141135931015\n",
      "26 70 0.886714518070221\n",
      "Validation loss: 0.7413508074624198 RMSE: 0.86101735\n",
      "27 15 0.28595519065856934\n",
      "27 65 0.2846742272377014\n",
      "Validation loss: 0.8007713181631906 RMSE: 0.89485824\n",
      "28 10 0.678054690361023\n",
      "28 60 0.6736330986022949\n",
      "Validation loss: 0.660287720816476 RMSE: 0.8125809\n",
      "29 5 0.3993116617202759\n",
      "29 55 0.7543291449546814\n",
      "Validation loss: 0.6406154124509721 RMSE: 0.8003845\n",
      "30 0 0.6824570894241333\n",
      "30 50 0.6720613241195679\n",
      "30 100 0.45249736309051514\n",
      "Validation loss: 0.6359677859715053 RMSE: 0.7974759\n",
      "31 45 0.5653752684593201\n",
      "31 95 0.5377816557884216\n",
      "Validation loss: 0.8620475712276641 RMSE: 0.9284652\n",
      "32 40 0.3714786171913147\n",
      "32 90 0.49892666935920715\n",
      "Validation loss: 0.6583183521316165 RMSE: 0.81136817\n",
      "33 35 0.5096256732940674\n",
      "33 85 0.6759148240089417\n",
      "Validation loss: 0.6438195518084935 RMSE: 0.8023837\n",
      "34 30 0.7050111889839172\n",
      "34 80 0.4221557676792145\n",
      "Validation loss: 0.6323180740787869 RMSE: 0.79518425\n",
      "35 25 0.4364854395389557\n",
      "35 75 0.37651535868644714\n",
      "Validation loss: 0.6841153860092163 RMSE: 0.8271127\n",
      "36 20 0.49090608954429626\n",
      "36 70 0.6246539354324341\n",
      "Validation loss: 0.6634239361399696 RMSE: 0.81450844\n",
      "37 15 0.5241085886955261\n",
      "37 65 0.41236746311187744\n",
      "Validation loss: 0.6704288187481108 RMSE: 0.81879723\n",
      "38 10 0.42554157972335815\n",
      "38 60 0.44686511158943176\n",
      "Validation loss: 0.6287453327860151 RMSE: 0.7929346\n",
      "39 5 0.29832029342651367\n",
      "39 55 0.4408371150493622\n",
      "Validation loss: 0.6242290689831689 RMSE: 0.7900817\n",
      "40 0 0.32143154740333557\n",
      "40 50 0.34100568294525146\n",
      "40 100 0.45633235573768616\n",
      "Validation loss: 0.6322450873397646 RMSE: 0.7951385\n",
      "41 45 0.5136760473251343\n",
      "41 95 0.4507388472557068\n",
      "Validation loss: 0.6999669097718738 RMSE: 0.83664024\n",
      "42 40 0.6293538808822632\n",
      "42 90 0.2819700539112091\n",
      "Validation loss: 0.6331467401413691 RMSE: 0.7957052\n",
      "43 35 0.5121729969978333\n",
      "43 85 0.46005627512931824\n",
      "Validation loss: 0.6275511639458793 RMSE: 0.79218125\n",
      "44 30 0.6095134615898132\n",
      "44 80 0.4082888662815094\n",
      "Validation loss: 0.6259141300405775 RMSE: 0.79114735\n",
      "45 25 0.41708678007125854\n",
      "45 75 0.524186909198761\n",
      "Validation loss: 0.6384585465703692 RMSE: 0.799036\n",
      "46 20 0.679393470287323\n",
      "46 70 0.43835529685020447\n",
      "Validation loss: 0.5944584582533156 RMSE: 0.77101135\n",
      "47 15 0.6482250690460205\n",
      "47 65 0.32890185713768005\n",
      "Validation loss: 0.5710650387264433 RMSE: 0.7556885\n",
      "48 10 0.35351303219795227\n",
      "48 60 0.5079800486564636\n",
      "Validation loss: 0.6156335817916053 RMSE: 0.7846232\n",
      "49 5 0.7662267684936523\n",
      "49 55 0.29752805829048157\n",
      "Validation loss: 0.5957695601951508 RMSE: 0.77186114\n",
      "50 0 0.6055916547775269\n",
      "50 50 0.21733880043029785\n",
      "50 100 0.3448999524116516\n",
      "Validation loss: 0.6428796433267139 RMSE: 0.80179775\n",
      "51 45 0.4850035011768341\n",
      "51 95 0.7168356776237488\n",
      "Validation loss: 0.5866924126942953 RMSE: 0.7659585\n",
      "52 40 0.4276653528213501\n",
      "52 90 0.4036438465118408\n",
      "Validation loss: 0.5724973251422246 RMSE: 0.75663555\n",
      "53 35 0.3779051899909973\n",
      "53 85 0.2728734612464905\n",
      "Validation loss: 0.58537903825442 RMSE: 0.76510066\n",
      "54 30 0.36325713992118835\n",
      "54 80 0.426770955324173\n",
      "Validation loss: 0.5725382645924886 RMSE: 0.7566626\n",
      "55 25 0.5805739164352417\n",
      "55 75 0.29723936319351196\n",
      "Validation loss: 0.5867602087202526 RMSE: 0.7660028\n",
      "56 20 0.3995865285396576\n",
      "56 70 0.4339381158351898\n",
      "Validation loss: 0.5738125619434175 RMSE: 0.75750417\n",
      "57 15 0.5473422408103943\n",
      "57 65 0.30080682039260864\n",
      "Validation loss: 0.6285125160501117 RMSE: 0.79278785\n",
      "58 10 0.3808348476886749\n",
      "58 60 0.2639152705669403\n",
      "Validation loss: 0.5472473297800337 RMSE: 0.73976165\n",
      "59 5 0.28895696997642517\n",
      "59 55 0.38122832775115967\n",
      "Validation loss: 0.5747846726860318 RMSE: 0.7581455\n",
      "60 0 0.37749072909355164\n",
      "60 50 0.409376323223114\n",
      "60 100 0.41030824184417725\n",
      "Validation loss: 0.549448663847787 RMSE: 0.7412481\n",
      "61 45 0.3647680878639221\n",
      "61 95 0.2612570524215698\n",
      "Validation loss: 0.6092982269468762 RMSE: 0.7805755\n",
      "62 40 0.37962353229522705\n",
      "62 90 0.4566211700439453\n",
      "Validation loss: 0.6975034208524795 RMSE: 0.8351667\n",
      "63 35 0.1868218332529068\n",
      "63 85 0.29914990067481995\n",
      "Validation loss: 0.6356933309918358 RMSE: 0.7973038\n",
      "64 30 0.344968318939209\n",
      "64 80 0.6564950942993164\n",
      "Validation loss: 0.5973215324538095 RMSE: 0.7728658\n",
      "65 25 0.322976291179657\n",
      "65 75 0.2274571806192398\n",
      "Validation loss: 0.5548064691679818 RMSE: 0.7448533\n",
      "66 20 0.13924889266490936\n",
      "66 70 0.5905022025108337\n",
      "Validation loss: 0.5694156879470462 RMSE: 0.75459635\n",
      "67 15 0.44472044706344604\n",
      "67 65 0.34402671456336975\n",
      "Validation loss: 0.54109683349019 RMSE: 0.73559284\n",
      "68 10 0.2715938687324524\n",
      "68 60 0.5829324126243591\n",
      "Validation loss: 0.5516007423400879 RMSE: 0.74269825\n",
      "69 5 0.2608847916126251\n",
      "69 55 0.44255170226097107\n",
      "Validation loss: 0.5795285337028049 RMSE: 0.7612677\n",
      "70 0 0.20697270333766937\n",
      "70 50 0.46471330523490906\n",
      "70 100 0.42584913969039917\n",
      "Validation loss: 0.5608511271930876 RMSE: 0.74889994\n",
      "71 45 0.33412548899650574\n",
      "71 95 0.5922822952270508\n",
      "Validation loss: 0.5580091425350734 RMSE: 0.7470001\n",
      "72 40 0.3102312982082367\n",
      "72 90 0.35013583302497864\n",
      "Validation loss: 0.560640590815317 RMSE: 0.7487594\n",
      "73 35 0.3368425965309143\n",
      "73 85 0.28720200061798096\n",
      "Validation loss: 0.5745053045806431 RMSE: 0.7579613\n",
      "74 30 0.3103390634059906\n",
      "74 80 0.33123254776000977\n",
      "Validation loss: 0.5447788153375898 RMSE: 0.73809135\n",
      "75 25 0.26604413986206055\n",
      "75 75 0.3552974760532379\n",
      "Validation loss: 0.5534827033678691 RMSE: 0.7439642\n",
      "76 20 0.35604798793792725\n",
      "76 70 0.24930621683597565\n",
      "Validation loss: 0.5945205035663786 RMSE: 0.7710516\n",
      "77 15 0.41553995013237\n",
      "77 65 0.3426218330860138\n",
      "Validation loss: 0.5491233062176477 RMSE: 0.74102855\n",
      "78 10 0.44074440002441406\n",
      "78 60 0.48862215876579285\n",
      "Validation loss: 0.5344803971903664 RMSE: 0.73108166\n",
      "79 5 0.34283772110939026\n",
      "79 55 0.44453227519989014\n",
      "Validation loss: 0.5101024312632424 RMSE: 0.7142145\n",
      "80 0 0.19511136412620544\n",
      "80 50 0.21936726570129395\n",
      "80 100 0.26348209381103516\n",
      "Validation loss: 0.5373068457558041 RMSE: 0.7330122\n",
      "81 45 0.30285680294036865\n",
      "81 95 0.3834012448787689\n",
      "Validation loss: 0.5951000673430307 RMSE: 0.77142733\n",
      "82 40 0.45208320021629333\n",
      "82 90 0.3071660101413727\n",
      "Validation loss: 0.573061872663952 RMSE: 0.7570085\n",
      "83 35 0.3188420236110687\n",
      "83 85 0.24815864861011505\n",
      "Validation loss: 0.5951296540952864 RMSE: 0.77144647\n",
      "84 30 0.3482760488986969\n",
      "84 80 0.46834006905555725\n",
      "Validation loss: 0.5710501940477462 RMSE: 0.75567865\n",
      "85 25 0.46591007709503174\n",
      "85 75 0.16109271347522736\n",
      "Validation loss: 0.5641417298998151 RMSE: 0.7510937\n",
      "86 20 0.2959052324295044\n",
      "86 70 0.3306657075881958\n",
      "Validation loss: 0.5306808874720619 RMSE: 0.7284785\n",
      "87 15 0.2569851279258728\n",
      "87 65 0.1794065684080124\n",
      "Validation loss: 0.5156746319362095 RMSE: 0.7181049\n",
      "88 10 0.31639721989631653\n",
      "88 60 0.3871757686138153\n",
      "Validation loss: 0.4923835357030233 RMSE: 0.70170045\n",
      "89 5 0.19406476616859436\n",
      "89 55 0.2173876166343689\n",
      "Validation loss: 0.5468520726476397 RMSE: 0.7394945\n",
      "90 0 0.24911078810691833\n",
      "90 50 0.5491487979888916\n",
      "90 100 0.20882277190685272\n",
      "Validation loss: 0.6574035772255489 RMSE: 0.8108043\n",
      "91 45 0.26109254360198975\n",
      "91 95 0.21808134019374847\n",
      "Validation loss: 0.567315510624931 RMSE: 0.7532035\n",
      "92 40 0.35550373792648315\n",
      "92 90 0.30675849318504333\n",
      "Validation loss: 0.5325738833064124 RMSE: 0.7297766\n",
      "93 35 0.2554093301296234\n",
      "93 85 0.20815874636173248\n",
      "Validation loss: 0.5853840710151763 RMSE: 0.76510394\n",
      "94 30 0.25699010491371155\n",
      "94 80 0.3068390488624573\n",
      "Validation loss: 0.538726304258619 RMSE: 0.73397976\n",
      "95 25 0.3191821575164795\n",
      "95 75 0.15313081443309784\n",
      "Validation loss: 0.5299681601070222 RMSE: 0.72798914\n",
      "96 20 0.24566057324409485\n",
      "96 70 0.21733860671520233\n",
      "Validation loss: 0.546928056932631 RMSE: 0.7395459\n",
      "97 15 0.42469900846481323\n",
      "97 65 0.6339898109436035\n",
      "Validation loss: 0.5490540918849763 RMSE: 0.7409818\n",
      "98 10 0.2099214643239975\n",
      "98 60 0.2944953739643097\n",
      "Validation loss: 0.5055646975835164 RMSE: 0.7110308\n",
      "99 5 0.1406978964805603\n",
      "99 55 0.21980419754981995\n",
      "Validation loss: 0.5385657869634174 RMSE: 0.7338704\n",
      "100 0 0.3615753650665283\n",
      "100 50 0.23991304636001587\n",
      "100 100 0.29676103591918945\n",
      "Validation loss: 0.5146703565404529 RMSE: 0.7174053\n",
      "101 45 0.4274584949016571\n",
      "101 95 0.4318426251411438\n",
      "Validation loss: 0.5091711417550132 RMSE: 0.7135623\n",
      "102 40 0.28008273243904114\n",
      "102 90 0.21850530803203583\n",
      "Validation loss: 0.6523089272635324 RMSE: 0.80765647\n",
      "103 35 0.2265615016222\n",
      "103 85 0.3669765293598175\n",
      "Validation loss: 0.5529848745891026 RMSE: 0.7436295\n",
      "104 30 0.378349632024765\n",
      "104 80 0.32254037261009216\n",
      "Validation loss: 0.5221829329218183 RMSE: 0.7226223\n",
      "105 25 0.505253791809082\n",
      "105 75 0.23856636881828308\n",
      "Validation loss: 0.5397545153186435 RMSE: 0.7346799\n",
      "106 20 0.3233047127723694\n",
      "106 70 0.4167494475841522\n",
      "Validation loss: 0.48327607058343436 RMSE: 0.6951806\n",
      "107 15 0.17526330053806305\n",
      "107 65 0.30053040385246277\n",
      "Validation loss: 0.5227996377717881 RMSE: 0.72304887\n",
      "108 10 0.41981104016304016\n",
      "108 60 0.24379882216453552\n",
      "Validation loss: 0.538620225304649 RMSE: 0.7339075\n",
      "109 5 0.16119246184825897\n",
      "109 55 0.2364707738161087\n",
      "Validation loss: 0.5337206505593799 RMSE: 0.7305619\n",
      "110 0 0.16545525193214417\n",
      "110 50 0.21503618359565735\n",
      "110 100 0.2629247307777405\n",
      "Validation loss: 0.5084566706702822 RMSE: 0.7130615\n",
      "111 45 0.20693674683570862\n",
      "111 95 0.19026902318000793\n",
      "Validation loss: 0.514573853072666 RMSE: 0.717338\n",
      "112 40 0.19020618498325348\n",
      "112 90 0.2758198380470276\n",
      "Validation loss: 0.5302015460672833 RMSE: 0.7281494\n",
      "113 35 0.24832865595817566\n",
      "113 85 0.2261458784341812\n",
      "Validation loss: 0.5326928547450475 RMSE: 0.7298581\n",
      "114 30 0.2921217381954193\n",
      "114 80 0.18409818410873413\n",
      "Validation loss: 0.47757048975853694 RMSE: 0.6910647\n",
      "115 25 0.19074051082134247\n",
      "115 75 0.24951612949371338\n",
      "Validation loss: 0.5084040755317325 RMSE: 0.7130246\n",
      "116 20 0.18896536529064178\n",
      "116 70 0.15697215497493744\n",
      "Validation loss: 0.5056763268652417 RMSE: 0.7111092\n",
      "117 15 0.2287471443414688\n",
      "117 65 0.2961762249469757\n",
      "Validation loss: 0.5296544347490583 RMSE: 0.7277736\n",
      "118 10 0.30678799748420715\n",
      "118 60 0.23178637027740479\n",
      "Validation loss: 0.5120173667867979 RMSE: 0.7155539\n",
      "119 5 0.20218238234519958\n",
      "119 55 0.19689011573791504\n",
      "Validation loss: 0.5349106087571098 RMSE: 0.7313758\n",
      "120 0 0.19247257709503174\n",
      "120 50 0.37089744210243225\n",
      "120 100 0.27153709530830383\n",
      "Validation loss: 0.5029008842649914 RMSE: 0.7091551\n",
      "121 45 0.26620328426361084\n",
      "121 95 0.12133918702602386\n",
      "Validation loss: 0.47735281331198554 RMSE: 0.69090724\n",
      "122 40 0.2964041531085968\n",
      "122 90 0.30050453543663025\n",
      "Validation loss: 0.5575305356865837 RMSE: 0.74667966\n",
      "123 35 0.1403684765100479\n",
      "123 85 0.4986613988876343\n",
      "Validation loss: 0.5230995271887098 RMSE: 0.72325623\n",
      "124 30 0.2281743884086609\n",
      "124 80 0.337807834148407\n",
      "Validation loss: 0.4906158095314389 RMSE: 0.70043975\n",
      "125 25 0.24339590966701508\n",
      "125 75 0.15673795342445374\n",
      "Validation loss: 0.4915738216468266 RMSE: 0.7011233\n",
      "126 20 0.21415814757347107\n",
      "126 70 0.3598339557647705\n",
      "Validation loss: 0.5265536474063992 RMSE: 0.7256402\n",
      "127 15 0.25868600606918335\n",
      "127 65 0.39117592573165894\n",
      "Validation loss: 0.519189563251677 RMSE: 0.7205481\n",
      "128 10 0.24055224657058716\n",
      "128 60 0.1355522871017456\n",
      "Validation loss: 0.516896931330363 RMSE: 0.7189554\n",
      "129 5 0.176796093583107\n",
      "129 55 0.23326802253723145\n",
      "Validation loss: 0.5155305414682343 RMSE: 0.7180045\n",
      "130 0 0.2646428048610687\n",
      "130 50 0.14466524124145508\n",
      "130 100 0.2944369912147522\n",
      "Validation loss: 0.560807557616915 RMSE: 0.74887085\n",
      "131 45 0.37918779253959656\n",
      "131 95 0.30448445677757263\n",
      "Validation loss: 0.5585157981940678 RMSE: 0.7473391\n",
      "132 40 0.3666057288646698\n",
      "132 90 0.33620062470436096\n",
      "Validation loss: 0.5298071272316434 RMSE: 0.7278785\n",
      "133 35 0.22720295190811157\n",
      "133 85 0.26165488362312317\n",
      "Validation loss: 0.5344884174210685 RMSE: 0.73108715\n",
      "134 30 0.19399850070476532\n",
      "134 80 0.22578418254852295\n",
      "Validation loss: 0.4884831022648584 RMSE: 0.69891566\n",
      "135 25 0.18367940187454224\n",
      "135 75 0.26418519020080566\n",
      "Validation loss: 0.48947788079579674 RMSE: 0.699627\n",
      "136 20 0.27415570616722107\n",
      "136 70 0.21111714839935303\n",
      "Validation loss: 0.5046507438023885 RMSE: 0.71038777\n",
      "137 15 0.15477050840854645\n",
      "137 65 0.428416907787323\n",
      "Validation loss: 0.5094692647457123 RMSE: 0.71377116\n",
      "138 10 0.2453392893075943\n",
      "138 60 0.15333861112594604\n",
      "Validation loss: 0.48948292618706113 RMSE: 0.69963056\n",
      "139 5 0.19941943883895874\n",
      "139 55 0.2771497368812561\n",
      "Validation loss: 0.5236873649415515 RMSE: 0.72366244\n",
      "140 0 0.23801733553409576\n",
      "140 50 0.17900021374225616\n",
      "140 100 0.20113633573055267\n",
      "Validation loss: 0.5079430506342933 RMSE: 0.71270126\n",
      "141 45 0.27347850799560547\n",
      "141 95 0.17324887216091156\n",
      "Validation loss: 0.49788262446721393 RMSE: 0.705608\n",
      "142 40 0.2708982825279236\n",
      "142 90 0.178976371884346\n",
      "Validation loss: 0.5040561863354274 RMSE: 0.70996916\n",
      "143 35 0.158504918217659\n",
      "143 85 0.21839745342731476\n",
      "Validation loss: 0.5077667917524066 RMSE: 0.7125776\n",
      "144 30 0.17618316411972046\n",
      "144 80 0.1747579425573349\n",
      "Validation loss: 0.4997080900839397 RMSE: 0.70690036\n",
      "145 25 0.20867644250392914\n",
      "145 75 0.1715320646762848\n",
      "Validation loss: 0.508083575112479 RMSE: 0.71279985\n",
      "146 20 0.16430100798606873\n",
      "146 70 0.29496893286705017\n",
      "Validation loss: 0.5100883349421479 RMSE: 0.71420467\n",
      "147 15 0.24339883029460907\n",
      "147 65 0.1445993036031723\n",
      "Validation loss: 0.4794651136511848 RMSE: 0.6924342\n",
      "148 10 0.2872067391872406\n",
      "148 60 0.18166454136371613\n",
      "Validation loss: 0.5025591711203258 RMSE: 0.7089141\n",
      "149 5 0.1312827467918396\n",
      "149 55 0.1784454584121704\n",
      "Validation loss: 0.46143347308749244 RMSE: 0.6792889\n",
      "150 0 0.16929985582828522\n",
      "150 50 0.3291025161743164\n",
      "150 100 0.17927072942256927\n",
      "Validation loss: 0.5464249849319458 RMSE: 0.7392056\n",
      "151 45 0.1787661612033844\n",
      "151 95 0.23367416858673096\n",
      "Validation loss: 0.5001870864913577 RMSE: 0.7072391\n",
      "152 40 0.22434766590595245\n",
      "152 90 0.14819148182868958\n",
      "Validation loss: 0.5488807665450233 RMSE: 0.7408649\n",
      "153 35 0.3044242858886719\n",
      "153 85 0.2632458508014679\n",
      "Validation loss: 0.5263100873856318 RMSE: 0.72547233\n",
      "154 30 0.31825965642929077\n",
      "154 80 0.13134394586086273\n",
      "Validation loss: 0.5240956085068839 RMSE: 0.7239445\n",
      "155 25 0.22026164829730988\n",
      "155 75 0.2022169530391693\n",
      "Validation loss: 0.5209156050568535 RMSE: 0.7217449\n",
      "156 20 0.1823720932006836\n",
      "156 70 0.20450642704963684\n",
      "Validation loss: 0.4728893377951213 RMSE: 0.6876695\n",
      "157 15 0.27536144852638245\n",
      "157 65 0.3476458489894867\n",
      "Validation loss: 0.509076247044972 RMSE: 0.7134958\n",
      "158 10 0.2054097056388855\n",
      "158 60 0.18781711161136627\n",
      "Validation loss: 0.5132555706160409 RMSE: 0.71641856\n",
      "159 5 0.17464962601661682\n",
      "159 55 0.16899839043617249\n",
      "Validation loss: 0.5228641725721813 RMSE: 0.7230935\n",
      "160 0 0.202183797955513\n",
      "160 50 0.15058882534503937\n",
      "160 100 0.35970303416252136\n",
      "Validation loss: 0.5158365913799831 RMSE: 0.7182176\n",
      "161 45 0.13502070307731628\n",
      "161 95 0.2588422894477844\n",
      "Validation loss: 0.5316995559703737 RMSE: 0.7291773\n",
      "162 40 0.2664308249950409\n",
      "162 90 0.270780473947525\n",
      "Validation loss: 0.5157614756198157 RMSE: 0.71816534\n",
      "163 35 0.1647711992263794\n",
      "163 85 0.21736761927604675\n",
      "Validation loss: 0.5316425272396632 RMSE: 0.72913826\n",
      "164 30 0.17906571924686432\n",
      "164 80 0.22972406446933746\n",
      "Validation loss: 0.5215178146248772 RMSE: 0.7221619\n",
      "165 25 0.2195865660905838\n",
      "165 75 0.17460781335830688\n",
      "Validation loss: 0.49346176442645845 RMSE: 0.70246834\n",
      "166 20 0.1447877287864685\n",
      "166 70 0.15870241820812225\n",
      "Validation loss: 0.5191761110510145 RMSE: 0.72053874\n",
      "167 15 0.1505913883447647\n",
      "167 65 0.12326281517744064\n",
      "Validation loss: 0.5142160927965528 RMSE: 0.71708864\n",
      "168 10 0.1536206752061844\n",
      "168 60 0.3335866928100586\n",
      "Validation loss: 0.5499603326831545 RMSE: 0.7415931\n",
      "169 5 0.2867301106452942\n",
      "169 55 0.12962737679481506\n",
      "Validation loss: 0.5033639496281034 RMSE: 0.7094815\n",
      "170 0 0.4574809968471527\n",
      "170 50 0.1018761694431305\n",
      "170 100 0.20918913185596466\n",
      "Validation loss: 0.5033700511569068 RMSE: 0.70948577\n",
      "171 45 0.14396309852600098\n",
      "171 95 0.18026679754257202\n",
      "Validation loss: 0.5040116247676668 RMSE: 0.70993775\n",
      "172 40 0.19234061241149902\n",
      "172 90 0.19806388020515442\n",
      "Validation loss: 0.4988409114735467 RMSE: 0.7062867\n",
      "173 35 0.1729813516139984\n",
      "173 85 0.191465824842453\n",
      "Validation loss: 0.47319023098264423 RMSE: 0.68788826\n",
      "174 30 0.13976988196372986\n",
      "174 80 0.15776115655899048\n",
      "Validation loss: 0.5260842834200178 RMSE: 0.7253167\n",
      "175 25 0.15761983394622803\n",
      "175 75 0.09139247983694077\n",
      "Validation loss: 0.47921605791364397 RMSE: 0.69225436\n",
      "176 20 -0.5150474905967712\n",
      "176 70 -9.763866424560547\n",
      "Validation loss: 0.8547337827228364 RMSE: 0.9245181\n",
      "177 15 -19.60822296142578\n",
      "177 65 -30.036441802978516\n",
      "Validation loss: 1.0560631956372941 RMSE: 1.0276494\n",
      "178 10 -38.42417907714844\n",
      "178 60 -49.70484924316406\n",
      "Validation loss: 1.3223903120983214 RMSE: 1.1499523\n",
      "179 5 -64.0241928100586\n",
      "179 55 -73.70205688476562\n",
      "Validation loss: 0.89995303551356 RMSE: 0.9486585\n",
      "180 0 -89.48800659179688\n",
      "180 50 -94.80460357666016\n",
      "180 100 -88.92034149169922\n",
      "Validation loss: 0.7989286661148072 RMSE: 0.8938281\n",
      "181 45 -114.35485076904297\n",
      "181 95 -126.31941986083984\n",
      "Validation loss: 1.4383394309452602 RMSE: 1.1993079\n",
      "182 40 -152.1475372314453\n",
      "182 90 -147.80667114257812\n",
      "Validation loss: 0.8182241354669844 RMSE: 0.9045574\n",
      "183 35 -174.7557830810547\n",
      "183 85 -182.9155731201172\n",
      "Validation loss: 0.8279724666050502 RMSE: 0.90992993\n",
      "184 30 -196.1593475341797\n",
      "184 80 -224.15512084960938\n",
      "Validation loss: 1.0204661843322573 RMSE: 1.0101813\n",
      "185 25 -244.65255737304688\n",
      "185 75 -240.46527099609375\n",
      "Validation loss: 0.9973110925583613 RMSE: 0.99865466\n",
      "186 20 -249.51705932617188\n",
      "186 70 -284.2369689941406\n",
      "Validation loss: 1.0799823999404907 RMSE: 1.039222\n",
      "187 15 -309.1508483886719\n",
      "187 65 -316.61761474609375\n",
      "Validation loss: 0.8090065399805705 RMSE: 0.899448\n",
      "188 10 -361.8493957519531\n",
      "188 60 -281.79034423828125\n",
      "Validation loss: 0.8631204832167853 RMSE: 0.92904276\n",
      "189 5 -369.55194091796875\n",
      "189 55 -387.71356201171875\n",
      "Validation loss: 0.9307643447603499 RMSE: 0.9647613\n",
      "190 0 -413.60888671875\n",
      "190 50 -443.9043884277344\n",
      "190 100 -429.26202392578125\n",
      "Validation loss: 0.8789149148123605 RMSE: 0.9375046\n",
      "191 45 -458.4021911621094\n",
      "191 95 -453.7380676269531\n",
      "Validation loss: 0.9236668989771888 RMSE: 0.9610759\n",
      "192 40 -472.89117431640625\n",
      "192 90 -563.6923828125\n",
      "Validation loss: 0.9396404141471499 RMSE: 0.9693505\n",
      "193 35 -582.9296875\n",
      "193 85 -595.6045532226562\n",
      "Validation loss: 0.8473558295340765 RMSE: 0.92051935\n",
      "194 30 -648.1730346679688\n",
      "194 80 -576.4529418945312\n",
      "Validation loss: 0.8790684067067646 RMSE: 0.9375865\n",
      "195 25 -571.06103515625\n",
      "195 75 -671.4232177734375\n",
      "Validation loss: 1.0038704486120316 RMSE: 1.0019333\n",
      "196 20 -683.1926879882812\n",
      "196 70 -702.7778930664062\n",
      "Validation loss: 0.9037004777363369 RMSE: 0.9506316\n",
      "197 15 -727.550048828125\n",
      "197 65 -777.677001953125\n",
      "Validation loss: 1.1875880627405075 RMSE: 1.0897652\n",
      "198 10 -852.2003173828125\n",
      "198 60 -942.5053100585938\n",
      "Validation loss: 0.9435184081395467 RMSE: 0.9713487\n",
      "199 5 -870.6810302734375\n",
      "199 55 -944.1746215820312\n",
      "Validation loss: 1.0268307254427955 RMSE: 1.0133266\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.5174680380594163 Test RMSE: 0.7193525\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'qm7', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'regression', 'data_path': 'data/qm7/qm7.csv', 'target': ['u0_atom']}}\n",
      "Running on: cuda:1\n",
      "6833\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/6833\n",
      "Generating scaffold 1000/6833\n",
      "Generating scaffold 2000/6833\n",
      "Generating scaffold 3000/6833\n",
      "Generating scaffold 4000/6833\n",
      "Generating scaffold 5000/6833\n",
      "Generating scaffold 6000/6833\n",
      "About to sort in scaffold sets\n",
      "tensor(-1553.3462) tensor(228.3718) torch.Size([5466, 1])\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 8.884771347045898\n",
      "0 50 2.7366628646850586\n",
      "0 100 2.0571136474609375\n",
      "0 150 1.3994702100753784\n",
      "Validation loss: 0.4378137532730549 MAE: 99.98431\n",
      "1 29 1.40385103225708\n",
      "1 79 1.2921721935272217\n",
      "1 129 1.4767215251922607\n",
      "Validation loss: 0.39500137248583006 MAE: 90.20716\n",
      "2 8 1.1042439937591553\n",
      "2 58 1.3240611553192139\n",
      "2 108 0.7396204471588135\n",
      "2 158 1.1249523162841797\n",
      "Validation loss: 0.48989426915408574 MAE: 111.87801\n",
      "3 37 0.891403317451477\n",
      "3 87 0.8915457129478455\n",
      "3 137 0.7928664684295654\n",
      "Validation loss: 0.4811342679269133 MAE: 109.87748\n",
      "4 16 0.8474677801132202\n",
      "4 66 1.0219650268554688\n",
      "4 116 0.7157121896743774\n",
      "4 166 1.0762031078338623\n",
      "Validation loss: 0.5650832973725615 MAE: 129.04907\n",
      "5 45 0.8425836563110352\n",
      "5 95 0.776387095451355\n",
      "5 145 0.9176933765411377\n",
      "Validation loss: 0.4077551208044353 MAE: 93.11975\n",
      "6 24 0.7711365222930908\n",
      "6 74 1.0076758861541748\n",
      "6 124 0.5844138860702515\n",
      "Validation loss: 0.43354575919826127 MAE: 99.00962\n",
      "7 3 0.6869847774505615\n",
      "7 53 0.6779572367668152\n",
      "7 103 0.8253777027130127\n",
      "7 153 0.46169769763946533\n",
      "Validation loss: 0.4941183732964142 MAE: 112.84269\n",
      "8 32 0.5498812198638916\n",
      "8 82 0.6813532114028931\n",
      "8 132 0.659887969493866\n",
      "Validation loss: 0.47089527259793196 MAE: 107.5392\n",
      "9 11 0.6495971083641052\n",
      "9 61 0.6030880808830261\n",
      "9 111 0.5230011940002441\n",
      "9 161 0.8462692499160767\n",
      "Validation loss: 0.4672056710162358 MAE: 106.696594\n",
      "10 40 0.664808988571167\n",
      "10 90 0.6337197422981262\n",
      "10 140 0.5905843377113342\n",
      "Validation loss: 0.4587423991390139 MAE: 104.76382\n",
      "11 19 0.7736944556236267\n",
      "11 69 0.6147841811180115\n",
      "11 119 0.4438314139842987\n",
      "11 169 0.6261661052703857\n",
      "Validation loss: 0.4663181053964715 MAE: 106.493904\n",
      "12 48 0.5792836546897888\n",
      "12 98 0.5714548230171204\n",
      "12 148 0.5552098155021667\n",
      "Validation loss: 0.4546869639416187 MAE: 103.83768\n",
      "13 27 0.5704358816146851\n",
      "13 77 0.6355600357055664\n",
      "13 127 0.5251455903053284\n",
      "Validation loss: 0.4032992314525515 MAE: 92.102165\n",
      "14 6 0.564139723777771\n",
      "14 56 0.6159184575080872\n",
      "14 106 0.6024911403656006\n",
      "14 156 0.45377135276794434\n",
      "Validation loss: 0.5340262839668676 MAE: 121.95653\n",
      "15 35 0.5275048017501831\n",
      "15 85 0.6607251167297363\n",
      "15 135 0.6559049487113953\n",
      "Validation loss: 0.411431266201867 MAE: 93.95929\n",
      "16 14 0.6416885852813721\n",
      "16 64 0.42244434356689453\n",
      "16 114 0.4670334756374359\n",
      "16 164 0.33350852131843567\n",
      "Validation loss: 0.46342620828695463 MAE: 105.83347\n",
      "17 43 0.4160696864128113\n",
      "17 93 0.4374132752418518\n",
      "17 143 0.4544800817966461\n",
      "Validation loss: 0.4472349939639108 MAE: 102.13585\n",
      "18 22 0.5156024098396301\n",
      "18 72 0.5312365293502808\n",
      "18 122 0.7166589498519897\n",
      "Validation loss: 0.45917107278143454 MAE: 104.8617\n",
      "19 1 0.6470648050308228\n",
      "19 51 0.5561039447784424\n",
      "19 101 0.5001382827758789\n",
      "19 151 0.4908895194530487\n",
      "Validation loss: 0.44023597449587104 MAE: 100.53746\n",
      "20 30 0.5386748313903809\n",
      "20 80 0.5371671915054321\n",
      "20 130 0.4503755271434784\n",
      "Validation loss: 0.414583953151926 MAE: 94.67927\n",
      "21 9 0.5369389057159424\n",
      "21 59 0.2593556046485901\n",
      "21 109 0.699118435382843\n",
      "21 159 0.4189564883708954\n",
      "Validation loss: 0.4465330121112846 MAE: 101.97553\n",
      "22 38 0.377895712852478\n",
      "22 88 0.5480618476867676\n",
      "22 138 0.5876516103744507\n",
      "Validation loss: 0.47402476305850066 MAE: 108.25386\n",
      "23 17 0.48053744435310364\n",
      "23 67 0.36736416816711426\n",
      "23 117 0.5460769534111023\n",
      "23 167 0.4053356647491455\n",
      "Validation loss: 0.43437416267673873 MAE: 99.1988\n",
      "24 46 0.48392900824546814\n",
      "24 96 0.5967580676078796\n",
      "24 146 0.440947949886322\n",
      "Validation loss: 0.49669397103856183 MAE: 113.43088\n",
      "25 25 0.585702657699585\n",
      "25 75 0.49623969197273254\n",
      "25 125 0.4141573905944824\n",
      "Validation loss: 0.44108302202838207 MAE: 100.73091\n",
      "26 4 0.4504452645778656\n",
      "26 54 0.4923095107078552\n",
      "26 104 0.5094616413116455\n",
      "26 154 0.43972980976104736\n",
      "Validation loss: 0.43416907459671733 MAE: 99.151955\n",
      "27 33 0.36065125465393066\n",
      "27 83 0.3390108346939087\n",
      "27 133 0.4273708164691925\n",
      "Validation loss: 0.41288061309279056 MAE: 94.290276\n",
      "28 12 0.4725428521633148\n",
      "28 62 0.4267800450325012\n",
      "28 112 0.4372401833534241\n",
      "28 162 0.45333242416381836\n",
      "Validation loss: 0.41500720887156256 MAE: 94.775925\n",
      "29 41 0.5705486536026001\n",
      "29 91 0.42450806498527527\n",
      "29 141 0.3532352149486542\n",
      "Validation loss: 0.44536233244583623 MAE: 101.70818\n",
      "30 20 0.37545570731163025\n",
      "30 70 0.6027108430862427\n",
      "30 120 0.5957508087158203\n",
      "30 170 0.37241289019584656\n",
      "Validation loss: 0.3907921328182109 MAE: 89.24589\n",
      "31 49 0.3639405071735382\n",
      "31 99 0.44063588976860046\n",
      "31 149 0.6302099823951721\n",
      "Validation loss: 0.4763085669592807 MAE: 108.77542\n",
      "32 28 0.32675743103027344\n",
      "32 78 0.4751339554786682\n",
      "32 128 0.3794799745082855\n",
      "Validation loss: 0.38579815870140033 MAE: 88.105415\n",
      "33 7 0.4148283302783966\n",
      "33 57 0.43784797191619873\n",
      "33 107 0.4603099226951599\n",
      "33 157 0.4174540936946869\n",
      "Validation loss: 0.4284423558335555 MAE: 97.84414\n",
      "34 36 0.3881209194660187\n",
      "34 86 0.5008910894393921\n",
      "34 136 0.5415879487991333\n",
      "Validation loss: 0.42978247930431923 MAE: 98.150185\n",
      "35 15 0.4045632779598236\n",
      "35 65 0.3571932315826416\n",
      "35 115 0.3628574311733246\n",
      "35 165 0.316096693277359\n",
      "Validation loss: 0.4217349217649092 MAE: 96.312355\n",
      "36 44 0.31959742307662964\n",
      "36 94 0.4586009681224823\n",
      "36 144 0.3957611620426178\n",
      "Validation loss: 0.4130124536871213 MAE: 94.32039\n",
      "37 23 0.368278831243515\n",
      "37 73 0.35283327102661133\n",
      "37 123 0.4914448857307434\n",
      "Validation loss: 0.4335119814900627 MAE: 99.0019\n",
      "38 2 0.3140377104282379\n",
      "38 52 0.45261338353157043\n",
      "38 102 0.7520089745521545\n",
      "38 152 0.4974278509616852\n",
      "Validation loss: 0.466322031983158 MAE: 106.49479\n",
      "39 31 0.46603676676750183\n",
      "39 81 0.3453899025917053\n",
      "39 131 0.35933682322502136\n",
      "Validation loss: 0.47429240272756207 MAE: 108.31499\n",
      "40 10 0.5243426561355591\n",
      "40 60 0.2787708342075348\n",
      "40 110 0.4475814998149872\n",
      "40 160 0.5048254728317261\n",
      "Validation loss: 0.42351874987981475 MAE: 96.719734\n",
      "41 39 0.3788474202156067\n",
      "41 89 0.44617581367492676\n",
      "41 139 0.3324064314365387\n",
      "Validation loss: 0.5651178122961034 MAE: 129.05696\n",
      "42 18 0.4769096374511719\n",
      "42 68 0.3873852491378784\n",
      "42 118 0.37087109684944153\n",
      "42 168 0.5319269299507141\n",
      "Validation loss: 0.500617100655684 MAE: 114.32682\n",
      "43 47 0.4543766379356384\n",
      "43 97 0.3732079267501831\n",
      "43 147 0.44778090715408325\n",
      "Validation loss: 0.43754363495704024 MAE: 99.92261\n",
      "44 26 0.33103886246681213\n",
      "44 76 0.3395737409591675\n",
      "44 126 0.4645930230617523\n",
      "Validation loss: 0.4247237081416169 MAE: 96.9949\n",
      "45 5 0.5457323789596558\n",
      "45 55 0.3080967664718628\n",
      "45 105 0.4367416203022003\n",
      "45 155 0.5324655771255493\n",
      "Validation loss: 0.44928431179788375 MAE: 102.60386\n",
      "46 34 0.4000761806964874\n",
      "46 84 0.44092246890068054\n",
      "46 134 0.36851614713668823\n",
      "Validation loss: 0.4305012309760378 MAE: 98.31433\n",
      "47 13 0.5873998403549194\n",
      "47 63 0.41258370876312256\n",
      "47 113 0.3739642798900604\n",
      "47 163 0.3408201336860657\n",
      "Validation loss: 0.41727648631871095 MAE: 95.294174\n",
      "48 42 0.45736968517303467\n",
      "48 92 0.3816225528717041\n",
      "48 142 0.4498054087162018\n",
      "Validation loss: 0.46907713434152437 MAE: 107.12397\n",
      "49 21 0.35112443566322327\n",
      "49 71 0.510578989982605\n",
      "49 121 0.41651347279548645\n",
      "Validation loss: 0.4666373520566706 MAE: 106.566795\n",
      "50 0 0.3996739685535431\n",
      "50 50 0.36323997378349304\n",
      "50 100 0.33591389656066895\n",
      "50 150 0.3938603699207306\n",
      "Validation loss: 0.46661447014725 MAE: 106.56156\n",
      "51 29 0.31205981969833374\n",
      "51 79 0.3382091522216797\n",
      "51 129 0.3303396701812744\n",
      "Validation loss: 0.5230599931109021 MAE: 119.45214\n",
      "52 8 0.3832727074623108\n",
      "52 58 0.566461443901062\n",
      "52 108 0.32529136538505554\n",
      "52 158 0.3060225546360016\n",
      "Validation loss: 0.4388565072539257 MAE: 100.22243\n",
      "53 37 0.301119863986969\n",
      "53 87 0.40450647473335266\n",
      "53 137 0.285623162984848\n",
      "Validation loss: 0.4758594409067031 MAE: 108.67287\n",
      "54 16 0.5781875848770142\n",
      "54 66 0.41998106241226196\n",
      "54 116 0.36338916420936584\n",
      "54 166 0.6176633238792419\n",
      "Validation loss: 0.5522019782958673 MAE: 126.107346\n",
      "55 45 0.49837902188301086\n",
      "55 95 0.38583168387413025\n",
      "55 145 0.3573324382305145\n",
      "Validation loss: 0.43949315631598757 MAE: 100.36783\n",
      "56 24 0.25057461857795715\n",
      "56 74 0.4987027049064636\n",
      "56 124 0.3395349383354187\n",
      "Validation loss: 0.5097834487058963 MAE: 116.42015\n",
      "57 3 0.4421823024749756\n",
      "57 53 0.29259443283081055\n",
      "57 103 0.3835394084453583\n",
      "57 153 0.3368664085865021\n",
      "Validation loss: 0.544763039427194 MAE: 124.40851\n",
      "58 32 0.48179811239242554\n",
      "58 82 0.32877716422080994\n",
      "58 132 0.4236929416656494\n",
      "Validation loss: 0.4589369244742812 MAE: 104.80823\n",
      "59 11 0.3266049921512604\n",
      "59 61 0.3028095066547394\n",
      "59 111 0.5002585649490356\n",
      "59 161 0.536078691482544\n",
      "Validation loss: 0.40916133144794153 MAE: 93.4409\n",
      "60 40 0.3878073990345001\n",
      "60 90 0.419289231300354\n",
      "60 140 0.28231945633888245\n",
      "Validation loss: 0.5007931861961097 MAE: 114.36703\n",
      "61 19 0.4176428020000458\n",
      "61 69 0.3127073645591736\n",
      "61 119 0.3448857069015503\n",
      "61 169 0.39871564507484436\n",
      "Validation loss: 0.4733482747398622 MAE: 108.099396\n",
      "62 48 0.2132691890001297\n",
      "62 98 0.36230841279029846\n",
      "62 148 0.30218565464019775\n",
      "Validation loss: 0.5128693605027004 MAE: 117.124886\n",
      "63 27 0.35392531752586365\n",
      "63 77 0.3996180295944214\n",
      "63 127 0.3381178677082062\n",
      "Validation loss: 0.41001045285609733 MAE: 93.63481\n",
      "64 6 0.32589060068130493\n",
      "64 56 0.3318612575531006\n",
      "64 106 0.45535802841186523\n",
      "64 156 0.4756167232990265\n",
      "Validation loss: 0.533904889173675 MAE: 121.928795\n",
      "65 35 0.33159342408180237\n",
      "65 85 0.43651270866394043\n",
      "65 135 0.397738516330719\n",
      "Validation loss: 0.5422123175615455 MAE: 123.82599\n",
      "66 14 0.35999733209609985\n",
      "66 64 0.3035261332988739\n",
      "66 114 0.3850451111793518\n",
      "66 164 0.3289632201194763\n",
      "Validation loss: 0.5478739386413529 MAE: 125.11895\n",
      "67 43 0.38691356778144836\n",
      "67 93 0.28747209906578064\n",
      "67 143 0.4378783702850342\n",
      "Validation loss: 0.6204020086436244 MAE: 141.68231\n",
      "68 22 0.233873650431633\n",
      "68 72 0.4029012620449066\n",
      "68 122 0.3999614417552948\n",
      "Validation loss: 0.4746250599099879 MAE: 108.39097\n",
      "69 1 0.27947378158569336\n",
      "69 51 0.4094153940677643\n",
      "69 101 0.28042447566986084\n",
      "69 151 0.3256795108318329\n",
      "Validation loss: 0.5096811035223174 MAE: 116.39677\n",
      "70 30 0.3857065737247467\n",
      "70 80 0.4967721402645111\n",
      "70 130 0.4228232800960541\n",
      "Validation loss: 0.7051129355068095 MAE: 161.0279\n",
      "71 9 0.2521495819091797\n",
      "71 59 0.3062281906604767\n",
      "71 109 0.3107648491859436\n",
      "71 159 0.39054611325263977\n",
      "Validation loss: 0.5169889278579176 MAE: 118.065674\n",
      "72 38 0.23169690370559692\n",
      "72 88 0.3422684073448181\n",
      "72 138 0.34647226333618164\n",
      "Validation loss: 0.4812724715784976 MAE: 109.90906\n",
      "73 17 0.34503597021102905\n",
      "73 67 0.4248340427875519\n",
      "73 117 0.263873815536499\n",
      "73 167 0.2679178714752197\n",
      "Validation loss: 0.5417185668011157 MAE: 123.713234\n",
      "74 46 0.24153289198875427\n",
      "74 96 0.37655186653137207\n",
      "74 146 0.35842543840408325\n",
      "Validation loss: 0.5467813170095633 MAE: 124.869415\n",
      "75 25 0.3164158761501312\n",
      "75 75 0.36983612179756165\n",
      "75 125 0.3472985029220581\n",
      "Validation loss: 0.46657654695343553 MAE: 106.55292\n",
      "76 4 0.4924859404563904\n",
      "76 54 0.3406405746936798\n",
      "76 104 0.3516654372215271\n",
      "76 154 0.4403611421585083\n",
      "Validation loss: 0.45573437858743276 MAE: 104.076866\n",
      "77 33 0.28609830141067505\n",
      "77 83 0.27181532979011536\n",
      "77 133 0.3561975955963135\n",
      "Validation loss: 0.43588663585353316 MAE: 99.544205\n",
      "78 12 0.46744444966316223\n",
      "78 62 0.38109663128852844\n",
      "78 112 0.6399286389350891\n",
      "78 162 0.4213922321796417\n",
      "Validation loss: 0.5589217515716776 MAE: 127.64195\n",
      "79 41 0.3085630536079407\n",
      "79 91 0.39485684037208557\n",
      "79 141 0.25811639428138733\n",
      "Validation loss: 0.49569527586998297 MAE: 113.202805\n",
      "80 20 0.4338337481021881\n",
      "80 70 0.33954378962516785\n",
      "80 120 0.23215174674987793\n",
      "80 170 0.3265751302242279\n",
      "Validation loss: 0.562932036424938 MAE: 128.55779\n",
      "81 49 0.4149826169013977\n",
      "81 99 0.3638833165168762\n",
      "81 149 0.4149616062641144\n",
      "Validation loss: 0.5366071232578211 MAE: 122.54591\n",
      "82 28 0.32088685035705566\n",
      "82 78 0.27002042531967163\n",
      "82 128 0.3174007534980774\n",
      "Validation loss: 0.6229277967709547 MAE: 142.25912\n",
      "83 7 0.2943052649497986\n",
      "83 57 0.49557554721832275\n",
      "83 107 0.4013500511646271\n",
      "83 157 0.42116469144821167\n",
      "Validation loss: 0.5286405891702887 MAE: 120.726585\n",
      "84 36 0.489063024520874\n",
      "84 86 0.419731080532074\n",
      "84 136 0.43220090866088867\n",
      "Validation loss: 0.5317009785021954 MAE: 121.42548\n",
      "85 15 0.28965744376182556\n",
      "85 65 0.23200581967830658\n",
      "85 115 0.3175193965435028\n",
      "85 165 0.28858858346939087\n",
      "Validation loss: 0.48436477205209566 MAE: 110.615234\n",
      "86 44 0.3530583381652832\n",
      "86 94 0.6313242316246033\n",
      "86 144 0.42963653802871704\n",
      "Validation loss: 0.6187162071640728 MAE: 141.29732\n",
      "87 23 0.3038159906864166\n",
      "87 73 0.3288060128688812\n",
      "87 123 0.3386547863483429\n",
      "Validation loss: 0.4961155304434704 MAE: 113.2988\n",
      "88 2 0.33176717162132263\n",
      "88 52 0.2973496913909912\n",
      "88 102 0.1929415613412857\n",
      "88 152 0.2756299674510956\n",
      "Validation loss: 0.44435540695636594 MAE: 101.47823\n",
      "89 31 0.36236196756362915\n",
      "89 81 0.4149249196052551\n",
      "89 131 0.38991737365722656\n",
      "Validation loss: 0.4285307523102788 MAE: 97.86432\n",
      "90 10 0.2938522696495056\n",
      "90 60 0.30728065967559814\n",
      "90 110 0.3309056758880615\n",
      "90 160 0.32297930121421814\n",
      "Validation loss: 0.5328769994060896 MAE: 121.69407\n",
      "91 39 0.28946733474731445\n",
      "91 89 0.43182456493377686\n",
      "91 139 0.37275075912475586\n",
      "Validation loss: 0.6288061518418161 MAE: 143.60158\n",
      "92 18 0.3490828275680542\n",
      "92 68 0.41113826632499695\n",
      "92 118 0.29347261786460876\n",
      "92 168 0.36348283290863037\n",
      "Validation loss: 0.504397211716189 MAE: 115.190094\n",
      "93 47 0.2083912342786789\n",
      "93 97 0.5246805548667908\n",
      "93 147 0.19871313869953156\n",
      "Validation loss: 0.5792918407429032 MAE: 132.2939\n",
      "94 26 0.3977769911289215\n",
      "94 76 0.32976236939430237\n",
      "94 126 0.2607767581939697\n",
      "Validation loss: 0.4689036799453155 MAE: 107.08437\n",
      "95 5 0.30257147550582886\n",
      "95 55 0.2863672077655792\n",
      "95 105 0.3831675946712494\n",
      "95 155 0.3392636775970459\n",
      "Validation loss: 0.634894289468464 MAE: 144.99194\n",
      "96 34 0.40765613317489624\n",
      "96 84 0.3967909812927246\n",
      "96 134 0.2936179041862488\n",
      "Validation loss: 0.489456333350717 MAE: 111.77801\n",
      "97 13 0.34343865513801575\n",
      "97 63 0.3229719400405884\n",
      "97 113 0.3134545683860779\n",
      "97 163 0.535386860370636\n",
      "Validation loss: 0.5264499558691393 MAE: 120.22631\n",
      "98 42 0.3664797246456146\n",
      "98 92 0.37319648265838623\n",
      "98 142 0.4572705924510956\n",
      "Validation loss: 0.564081819433915 MAE: 128.82037\n",
      "99 21 0.27703794836997986\n",
      "99 71 0.4156567454338074\n",
      "99 121 0.2620082199573517\n",
      "Validation loss: 0.6249322113935013 MAE: 142.71687\n",
      "100 0 0.2643546462059021\n",
      "100 50 0.5135470032691956\n",
      "100 100 0.31504082679748535\n",
      "100 150 0.18186725676059723\n",
      "Validation loss: 0.4796248203829715 MAE: 109.53277\n",
      "101 29 0.3085944652557373\n",
      "101 79 0.42393288016319275\n",
      "101 129 0.2799581289291382\n",
      "Validation loss: 0.6107593767824229 MAE: 139.4802\n",
      "102 8 0.4246474504470825\n",
      "102 58 0.2786315381526947\n",
      "102 108 0.4722089469432831\n",
      "102 158 0.3444346785545349\n",
      "Validation loss: 0.56713086471223 MAE: 129.5167\n",
      "103 37 0.2511462867259979\n",
      "103 87 0.3712329566478729\n",
      "103 137 0.21997752785682678\n",
      "Validation loss: 0.46538620768931876 MAE: 106.28107\n",
      "104 16 0.3825682997703552\n",
      "104 66 0.27460697293281555\n",
      "104 116 0.40850135684013367\n",
      "104 166 0.4089486002922058\n",
      "Validation loss: 0.44696802737420066 MAE: 102.07488\n",
      "105 45 0.3395073413848877\n",
      "105 95 0.2408808171749115\n",
      "105 145 0.4045252203941345\n",
      "Validation loss: 0.5918061344595681 MAE: 135.15182\n",
      "106 24 0.2615516483783722\n",
      "106 74 0.25647786259651184\n",
      "106 124 0.20267467200756073\n",
      "Validation loss: 0.5639962811916195 MAE: 128.80084\n",
      "107 3 0.4401146471500397\n",
      "107 53 0.410411536693573\n",
      "107 103 0.37036871910095215\n",
      "107 153 0.3386649489402771\n",
      "Validation loss: 0.5522991317754601 MAE: 126.129524\n",
      "108 32 0.24051257967948914\n",
      "108 82 0.3991748094558716\n",
      "108 132 0.40278539061546326\n",
      "Validation loss: 0.4932380329098618 MAE: 112.641655\n",
      "109 11 0.2792063057422638\n",
      "109 61 0.43000897765159607\n",
      "109 111 0.2492634803056717\n",
      "109 161 0.3122110068798065\n",
      "Validation loss: 0.5418482572711699 MAE: 123.74285\n",
      "110 40 0.39637491106987\n",
      "110 90 0.30895039439201355\n",
      "110 140 0.3248136043548584\n",
      "Validation loss: 0.5525730339407223 MAE: 126.19209\n",
      "111 19 0.3221389353275299\n",
      "111 69 0.5109117031097412\n",
      "111 119 0.30544862151145935\n",
      "111 169 0.25911369919776917\n",
      "Validation loss: 0.581305380104578 MAE: 132.75374\n",
      "112 48 0.25161343812942505\n",
      "112 98 0.19505105912685394\n",
      "112 148 0.23172937333583832\n",
      "Validation loss: 0.5429183629869717 MAE: 123.98723\n",
      "113 27 0.25426697731018066\n",
      "113 77 0.4399711489677429\n",
      "113 127 0.20535294711589813\n",
      "Validation loss: 0.5713191178807041 MAE: 130.47316\n",
      "114 6 0.24981795251369476\n",
      "114 56 0.28155437111854553\n",
      "114 106 0.3552444279193878\n",
      "114 156 0.5590510964393616\n",
      "Validation loss: 0.5656245103356434 MAE: 129.17267\n",
      "115 35 0.2679367959499359\n",
      "115 85 0.3550060987472534\n",
      "115 135 0.3251557946205139\n",
      "Validation loss: 0.5820340915032994 MAE: 132.92017\n",
      "116 14 0.2828837037086487\n",
      "116 64 0.28081682324409485\n",
      "116 114 0.30355435609817505\n",
      "116 164 0.3376266360282898\n",
      "Validation loss: 0.5332242717519838 MAE: 121.773384\n",
      "117 43 0.3402881920337677\n",
      "117 93 0.4976057708263397\n",
      "117 143 0.5787158608436584\n",
      "Validation loss: 0.48984541356215006 MAE: 111.86687\n",
      "118 22 0.2509790360927582\n",
      "118 72 0.4281853437423706\n",
      "118 122 0.2902340888977051\n",
      "Validation loss: 0.4771361178473422 MAE: 108.96443\n",
      "119 1 0.22787311673164368\n",
      "119 51 0.2578752636909485\n",
      "119 101 0.3383111357688904\n",
      "119 151 0.35094213485717773\n",
      "Validation loss: 0.6693711270365799 MAE: 152.86548\n",
      "120 30 0.2797362506389618\n",
      "120 80 0.3135174512863159\n",
      "120 130 0.21946357190608978\n",
      "Validation loss: 0.583965283736848 MAE: 133.36119\n",
      "121 9 0.3572936952114105\n",
      "121 59 0.3558047115802765\n",
      "121 109 0.3809146285057068\n",
      "121 159 0.27365371584892273\n",
      "Validation loss: 0.5781093400124221 MAE: 132.02385\n",
      "122 38 0.35972967743873596\n",
      "122 88 0.36630532145500183\n",
      "122 138 0.29333075881004333\n",
      "Validation loss: 0.7133720527615464 MAE: 162.91405\n",
      "123 17 0.33078494668006897\n",
      "123 67 0.17044322192668915\n",
      "123 117 0.3230937123298645\n",
      "123 167 0.24471206963062286\n",
      "Validation loss: 0.6072977164335418 MAE: 138.68965\n",
      "124 46 0.32607531547546387\n",
      "124 96 0.33908289670944214\n",
      "124 146 0.3946530222892761\n",
      "Validation loss: 0.5892533100487893 MAE: 134.56883\n",
      "125 25 0.3268754780292511\n",
      "125 75 0.3668442666530609\n",
      "125 125 0.27482953667640686\n",
      "Validation loss: 0.5594403496262623 MAE: 127.76038\n",
      "126 4 0.35068559646606445\n",
      "126 54 0.3048211932182312\n",
      "126 104 0.30883121490478516\n",
      "126 154 0.3757551908493042\n",
      "Validation loss: 0.6437835668959813 MAE: 147.022\n",
      "127 33 0.36848607659339905\n",
      "127 83 0.21917226910591125\n",
      "127 133 0.36780399084091187\n",
      "Validation loss: 0.5325414475641752 MAE: 121.61744\n",
      "128 12 0.32437455654144287\n",
      "128 62 0.5162007212638855\n",
      "128 112 0.34735551476478577\n",
      "128 162 0.4086863696575165\n",
      "Validation loss: 0.48344932836398746 MAE: 110.40618\n",
      "129 41 0.24492664635181427\n",
      "129 91 0.23374411463737488\n",
      "129 141 0.16853360831737518\n",
      "Validation loss: 0.5037946087575098 MAE: 115.052475\n",
      "130 20 0.334003746509552\n",
      "130 70 0.3362603783607483\n",
      "130 120 0.18922236561775208\n",
      "130 170 0.3816477656364441\n",
      "Validation loss: 0.48675926264963654 MAE: 111.16208\n",
      "131 49 0.37539634108543396\n",
      "131 99 0.24853262305259705\n",
      "131 149 0.4206189513206482\n",
      "Validation loss: 0.49702298449493987 MAE: 113.50602\n",
      "132 28 0.6241568922996521\n",
      "132 78 0.3404747545719147\n",
      "132 128 0.35090672969818115\n",
      "Validation loss: 0.6714460201430739 MAE: 153.33932\n",
      "133 7 0.2916059195995331\n",
      "133 57 0.2842336595058441\n",
      "133 107 0.22325675189495087\n",
      "133 157 0.3310340642929077\n",
      "Validation loss: 0.4844376598185266 MAE: 110.63189\n",
      "134 36 0.3113011121749878\n",
      "134 86 0.36363357305526733\n",
      "134 136 0.21000252664089203\n",
      "Validation loss: 0.6705878059766446 MAE: 153.14333\n",
      "135 15 0.3311232030391693\n",
      "135 65 0.2478906810283661\n",
      "135 115 0.20184944570064545\n",
      "135 165 0.4799239933490753\n",
      "Validation loss: 0.6166140018847951 MAE: 140.81723\n",
      "136 44 0.5346354246139526\n",
      "136 94 0.1840560883283615\n",
      "136 144 0.171758234500885\n",
      "Validation loss: 0.560553168692784 MAE: 128.01451\n",
      "137 23 0.4969700276851654\n",
      "137 73 0.36426958441734314\n",
      "137 123 0.3608148396015167\n",
      "Validation loss: 0.5916013654909635 MAE: 135.10506\n",
      "138 2 0.41911229491233826\n",
      "138 52 0.46815910935401917\n",
      "138 102 0.43779894709587097\n",
      "138 152 0.25922393798828125\n",
      "Validation loss: 0.5310582835771884 MAE: 121.278725\n",
      "139 31 0.32505449652671814\n",
      "139 81 0.35229066014289856\n",
      "139 131 0.2879716455936432\n",
      "Validation loss: 0.6055583779574835 MAE: 138.29245\n",
      "140 10 0.23486454784870148\n",
      "140 60 0.2667037546634674\n",
      "140 110 0.18785320222377777\n",
      "140 160 0.3540237843990326\n",
      "Validation loss: 0.5882840801400748 MAE: 134.34749\n",
      "141 39 0.2783871591091156\n",
      "141 89 0.23927417397499084\n",
      "141 139 0.2843642830848694\n",
      "Validation loss: 0.5493950209422418 MAE: 125.46632\n",
      "142 18 -0.3120769262313843\n",
      "142 68 -9.218511581420898\n",
      "142 118 -16.176395416259766\n",
      "142 168 -27.51873016357422\n",
      "Validation loss: 0.5132593446307712 MAE: 117.21393\n",
      "143 47 -35.33259201049805\n",
      "143 97 -43.61374282836914\n",
      "143 147 -54.310386657714844\n",
      "Validation loss: 0.5441635090705247 MAE: 124.271576\n",
      "144 26 -61.18621063232422\n",
      "144 76 -81.49124145507812\n",
      "144 126 -94.67303466796875\n",
      "Validation loss: 0.5894106013035914 MAE: 134.60475\n",
      "145 5 -100.1338882446289\n",
      "145 55 -110.82142639160156\n",
      "145 105 -142.32260131835938\n",
      "145 155 -152.08993530273438\n",
      "Validation loss: 0.5468923968878406 MAE: 124.89478\n",
      "146 34 -147.00820922851562\n",
      "146 84 -170.70433044433594\n",
      "146 134 -191.43243408203125\n",
      "Validation loss: 0.547261546404041 MAE: 124.97909\n",
      "147 13 -201.92652893066406\n",
      "147 63 -210.60525512695312\n",
      "147 113 -237.66452026367188\n",
      "147 163 -249.085205078125\n",
      "Validation loss: 0.5307060528916923 MAE: 121.19828\n",
      "148 42 -273.0484619140625\n",
      "148 92 -297.90447998046875\n",
      "148 142 -304.0083312988281\n",
      "Validation loss: 0.541296458732315 MAE: 123.61682\n",
      "149 21 -367.2027893066406\n",
      "149 71 -339.7523193359375\n",
      "149 121 -381.2836608886719\n",
      "Validation loss: 0.5317480957996078 MAE: 121.43626\n",
      "150 0 -390.7956237792969\n",
      "150 50 -389.88043212890625\n",
      "150 100 -436.6555480957031\n",
      "150 150 -456.6724548339844\n",
      "Validation loss: 0.5817127968484198 MAE: 132.84677\n",
      "151 29 -493.852294921875\n",
      "151 79 -532.9234008789062\n",
      "151 129 -530.4049072265625\n",
      "Validation loss: 0.5830025418460021 MAE: 133.14133\n",
      "152 8 -607.71826171875\n",
      "152 58 -649.1307373046875\n",
      "152 108 -576.818603515625\n",
      "152 158 -649.7693481445312\n",
      "Validation loss: 0.5513944329574094 MAE: 125.92291\n",
      "153 37 -687.5406494140625\n",
      "153 87 -701.662353515625\n",
      "153 137 -711.8394165039062\n",
      "Validation loss: 0.5815369980028499 MAE: 132.80663\n",
      "154 16 -747.9022827148438\n",
      "154 66 -803.3274536132812\n",
      "154 116 -756.9534301757812\n",
      "154 166 -806.2762451171875\n",
      "Validation loss: 0.6399255809728165 MAE: 146.14095\n",
      "155 45 -881.15087890625\n",
      "155 95 -950.1336669921875\n",
      "155 145 -909.4201049804688\n",
      "Validation loss: 0.5801625921015154 MAE: 132.49275\n",
      "156 24 -936.8165283203125\n",
      "156 74 -991.3978271484375\n",
      "156 124 -1022.8073120117188\n",
      "Validation loss: 0.6000910997390747 MAE: 137.04387\n",
      "157 3 -987.5432739257812\n",
      "157 53 -1159.2459716796875\n",
      "157 103 -1215.9676513671875\n",
      "157 153 -1174.897705078125\n",
      "Validation loss: 0.6186249242191426 MAE: 141.27647\n",
      "158 32 -1258.2022705078125\n",
      "158 82 -1247.515625\n",
      "158 132 -1422.58642578125\n",
      "Validation loss: 0.6277134871622275 MAE: 143.35204\n",
      "159 11 -1316.8455810546875\n",
      "159 61 -1368.43701171875\n",
      "159 111 -1260.26171875\n",
      "159 161 -1523.699951171875\n",
      "Validation loss: 0.5984909485655221 MAE: 136.67844\n",
      "160 40 -1488.9105224609375\n",
      "160 90 -1594.8106689453125\n",
      "160 140 -1688.9591064453125\n",
      "Validation loss: 0.6468885676902637 MAE: 147.73108\n",
      "161 19 -1696.0865478515625\n",
      "161 69 -1686.900390625\n",
      "161 119 -1671.000732421875\n",
      "161 169 -1828.583740234375\n",
      "Validation loss: 0.6518689909873651 MAE: 148.86848\n",
      "162 48 -1649.4010009765625\n",
      "162 98 -1700.810791015625\n",
      "162 148 -1924.946533203125\n",
      "Validation loss: 0.6283563713581242 MAE: 143.49886\n",
      "163 27 -1900.2425537109375\n",
      "163 77 -1876.5589599609375\n",
      "163 127 -1987.0523681640625\n",
      "Validation loss: 0.6246082116985878 MAE: 142.64288\n",
      "164 6 -2200.8916015625\n",
      "164 56 -2197.41845703125\n",
      "164 106 -2259.9091796875\n",
      "164 156 -2460.4404296875\n",
      "Validation loss: 0.6482616537495663 MAE: 148.04466\n",
      "165 35 -2190.10888671875\n",
      "165 85 -2222.33544921875\n",
      "165 135 -2436.92138671875\n",
      "Validation loss: 0.673243726903235 MAE: 153.74986\n",
      "166 14 -2412.13623046875\n",
      "166 64 -2406.48583984375\n",
      "166 114 -2276.77734375\n",
      "166 164 -2541.883544921875\n",
      "Validation loss: 0.6377312917458383 MAE: 145.63983\n",
      "167 43 -2720.909423828125\n",
      "167 93 -3062.142822265625\n",
      "167 143 -2721.929931640625\n",
      "Validation loss: 0.7000173689329137 MAE: 159.8642\n",
      "168 22 -2692.0400390625\n",
      "168 72 -3178.542236328125\n",
      "168 122 -2998.15966796875\n",
      "Validation loss: 0.6539452905543366 MAE: 149.34264\n",
      "169 1 -3284.9765625\n",
      "169 51 -2936.420166015625\n",
      "169 101 -3418.822265625\n",
      "169 151 -3300.76953125\n",
      "Validation loss: 0.6339673877459521 MAE: 144.78026\n",
      "170 30 -3044.891845703125\n",
      "170 80 -3320.5234375\n",
      "170 130 -3576.637451171875\n",
      "Validation loss: 0.7068836877220556 MAE: 161.43227\n",
      "171 9 -3360.509033203125\n",
      "171 59 -3156.54150390625\n",
      "171 109 -3776.495361328125\n",
      "171 159 -3741.80322265625\n",
      "Validation loss: 0.668920115769258 MAE: 152.76247\n",
      "172 38 -3834.368896484375\n",
      "172 88 -3979.895751953125\n",
      "172 138 -3955.73828125\n",
      "Validation loss: 0.6754447312382926 MAE: 154.25252\n",
      "173 17 -4164.115234375\n",
      "173 67 -4240.87158203125\n",
      "173 117 -4104.8779296875\n",
      "173 167 -4313.2099609375\n",
      "Validation loss: 0.6125223218348989 MAE: 139.88281\n",
      "174 46 -4601.69921875\n",
      "174 96 -4485.07080078125\n",
      "174 146 -4075.302001953125\n",
      "Validation loss: 0.7548637979211863 MAE: 172.38959\n",
      "175 25 -4396.6220703125\n",
      "175 75 -4786.28271484375\n",
      "175 125 -4703.025390625\n",
      "Validation loss: 0.6753649690694976 MAE: 154.2343\n",
      "176 4 -4373.1806640625\n",
      "176 54 -4931.03369140625\n",
      "176 104 -4746.23388671875\n",
      "176 154 -5206.0400390625\n",
      "Validation loss: 0.7232579100898832 MAE: 165.17169\n",
      "177 33 -5263.63330078125\n",
      "177 83 -5311.57568359375\n",
      "177 133 -5126.71435546875\n",
      "Validation loss: 0.7013305188619603 MAE: 160.16408\n",
      "178 12 -5271.7763671875\n",
      "178 62 -5536.3076171875\n",
      "178 112 -5430.056640625\n",
      "178 162 -5509.10400390625\n",
      "Validation loss: 0.6718349223248443 MAE: 153.42813\n",
      "179 41 -5384.1474609375\n",
      "179 91 -5659.384765625\n",
      "179 141 -5713.8154296875\n",
      "Validation loss: 0.7141577374865438 MAE: 163.09348\n",
      "180 20 -5566.64697265625\n",
      "180 70 -6168.44775390625\n",
      "180 120 -6079.15380859375\n",
      "180 170 -5630.42333984375\n",
      "Validation loss: 0.6853066794356407 MAE: 156.5047\n",
      "181 49 -6518.36962890625\n",
      "181 99 -6009.69482421875\n",
      "181 149 -6256.2666015625\n",
      "Validation loss: 0.7247776113755522 MAE: 165.51874\n",
      "182 28 -6334.1572265625\n",
      "182 78 -6975.94921875\n",
      "182 128 -6765.36474609375\n",
      "Validation loss: 0.6702705147670723 MAE: 153.07086\n",
      "183 7 -6905.9599609375\n",
      "183 57 -6667.21240234375\n",
      "183 107 -6722.14892578125\n",
      "183 157 -7263.6328125\n",
      "Validation loss: 0.6822633101926212 MAE: 155.80968\n",
      "184 36 -7385.4814453125\n",
      "184 86 -7042.9482421875\n",
      "184 136 -7212.7529296875\n",
      "Validation loss: 0.6765412855566594 MAE: 154.50293\n",
      "185 15 -7142.884765625\n",
      "185 65 -6556.59619140625\n",
      "185 115 -7972.53662109375\n",
      "185 165 -7683.046875\n",
      "Validation loss: 0.7193138947960926 MAE: 164.271\n",
      "186 44 -8123.740234375\n",
      "186 94 -7776.14501953125\n",
      "186 144 -7416.1201171875\n",
      "Validation loss: 0.7324996524386935 MAE: 167.28226\n",
      "187 23 -8162.2705078125\n",
      "187 73 -7929.30712890625\n",
      "187 123 -8447.2900390625\n",
      "Validation loss: 0.64945706149988 MAE: 148.31766\n",
      "188 2 -8755.623046875\n",
      "188 52 -7820.138671875\n",
      "188 102 -8831.2490234375\n",
      "188 152 -8565.1005859375\n",
      "Validation loss: 0.6855396921174568 MAE: 156.5579\n",
      "189 31 -9324.146484375\n",
      "189 81 -8615.0966796875\n",
      "189 131 -9653.208984375\n",
      "Validation loss: 0.6808434261216058 MAE: 155.48543\n",
      "190 10 -8537.94140625\n",
      "190 60 -10165.2646484375\n",
      "190 110 -10064.521484375\n",
      "190 160 -9386.2060546875\n",
      "Validation loss: 0.7660445058554933 MAE: 174.94293\n",
      "191 39 -10076.03125\n",
      "191 89 -9807.56640625\n",
      "191 139 -10018.61328125\n",
      "Validation loss: 0.7090498679562619 MAE: 161.92697\n",
      "192 18 -10600.1591796875\n",
      "192 68 -9376.7568359375\n",
      "192 118 -10563.6796875\n",
      "192 168 -10771.271484375\n",
      "Validation loss: 0.6475117422683895 MAE: 147.8734\n",
      "193 47 -9856.6748046875\n",
      "193 97 -11720.115234375\n",
      "193 147 -11536.0810546875\n",
      "Validation loss: 0.6727436460249605 MAE: 153.63565\n",
      "194 26 -11550.826171875\n",
      "194 76 -11256.791015625\n",
      "194 126 -11376.427734375\n",
      "Validation loss: 0.7122683016180295 MAE: 162.66196\n",
      "195 5 -11958.6328125\n",
      "195 55 -11851.7685546875\n",
      "195 105 -12340.7509765625\n",
      "195 155 -12139.8583984375\n",
      "Validation loss: 0.7069150118799935 MAE: 161.43944\n",
      "196 34 -12787.5263671875\n",
      "196 84 -12429.501953125\n",
      "196 134 -12743.8564453125\n",
      "Validation loss: 0.6775505730980321 MAE: 154.73341\n",
      "197 13 -12247.1748046875\n",
      "197 63 -13812.212890625\n",
      "197 113 -13506.3232421875\n",
      "197 163 -13570.5126953125\n",
      "Validation loss: 0.6829101234151606 MAE: 155.95738\n",
      "198 42 -12433.52734375\n",
      "198 92 -13718.16015625\n",
      "198 142 -12639.056640625\n",
      "Validation loss: 0.6961745633716472 MAE: 158.98662\n",
      "199 21 -14385.078125\n",
      "199 71 -14924.6484375\n",
      "199 121 -14259.5322265625\n",
      "Validation loss: 0.6855429710700498 MAE: 156.55865\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.3398716988186536 Test MAE: 77.617096\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'qm7', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 778, 'task': 'regression', 'data_path': 'data/qm7/qm7.csv', 'target': ['u0_atom']}}\n",
      "Running on: cuda:1\n",
      "6833\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/6833\n",
      "Generating scaffold 1000/6833\n",
      "Generating scaffold 2000/6833\n",
      "Generating scaffold 3000/6833\n",
      "Generating scaffold 4000/6833\n",
      "Generating scaffold 5000/6833\n",
      "Generating scaffold 6000/6833\n",
      "About to sort in scaffold sets\n",
      "tensor(-1553.3462) tensor(228.3718) torch.Size([5466, 1])\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 8.182696342468262\n",
      "0 50 2.7759480476379395\n",
      "0 100 2.2311525344848633\n",
      "0 150 1.5156500339508057\n",
      "Validation loss: 0.6725878095069127 MAE: 153.60008\n",
      "1 29 1.2562389373779297\n",
      "1 79 1.4160964488983154\n",
      "1 129 1.2293832302093506\n",
      "Validation loss: 0.6258123604177731 MAE: 142.9179\n",
      "2 8 0.9968225359916687\n",
      "2 58 0.9293277263641357\n",
      "2 108 0.9489345550537109\n",
      "2 158 1.1320140361785889\n",
      "Validation loss: 0.5923532784333703 MAE: 135.27678\n",
      "3 37 0.9390866756439209\n",
      "3 87 1.007826566696167\n",
      "3 137 0.806160569190979\n",
      "Validation loss: 0.4722716912888644 MAE: 107.85352\n",
      "4 16 0.6666514873504639\n",
      "4 66 0.7888450622558594\n",
      "4 116 0.6959476470947266\n",
      "4 166 0.8626397252082825\n",
      "Validation loss: 0.4895016136225204 MAE: 111.78835\n",
      "5 45 0.797103226184845\n",
      "5 95 0.6501777172088623\n",
      "5 145 0.8483939170837402\n",
      "Validation loss: 0.4165256164575878 MAE: 95.122696\n",
      "6 24 0.775374174118042\n",
      "6 74 0.8283029794692993\n",
      "6 124 0.8073698282241821\n",
      "Validation loss: 0.44297134266262167 MAE: 101.16214\n",
      "7 3 0.5605210661888123\n",
      "7 53 0.76286381483078\n",
      "7 103 0.936673641204834\n",
      "7 153 0.8270301818847656\n",
      "Validation loss: 0.4126963972696784 MAE: 94.24821\n",
      "8 32 0.837727427482605\n",
      "8 82 0.42019641399383545\n",
      "8 132 0.6316665410995483\n",
      "Validation loss: 0.5066506996837973 MAE: 115.70471\n",
      "9 11 0.6249264478683472\n",
      "9 61 0.5286000370979309\n",
      "9 111 0.9060623645782471\n",
      "9 161 0.606036901473999\n",
      "Validation loss: 0.4507981245977837 MAE: 102.94956\n",
      "10 40 0.6119175553321838\n",
      "10 90 0.6084370613098145\n",
      "10 140 0.7714273929595947\n",
      "Validation loss: 0.4970961007458425 MAE: 113.52272\n",
      "11 19 0.38644638657569885\n",
      "11 69 0.4873208999633789\n",
      "11 119 0.3941397964954376\n",
      "11 169 0.5680894255638123\n",
      "Validation loss: 0.4785643016037188 MAE: 109.29058\n",
      "12 48 0.7814977169036865\n",
      "12 98 0.5769882798194885\n",
      "12 148 0.39907485246658325\n",
      "Validation loss: 0.45375083317185005 MAE: 103.62388\n",
      "13 27 0.6677067279815674\n",
      "13 77 0.561487078666687\n",
      "13 127 0.47214287519454956\n",
      "Validation loss: 0.46554001346666213 MAE: 106.3162\n",
      "14 6 0.5616117715835571\n",
      "14 56 0.7145931124687195\n",
      "14 106 0.6824421286582947\n",
      "14 156 0.6610375046730042\n",
      "Validation loss: 0.462413241640169 MAE: 105.602135\n",
      "15 35 0.4874361455440521\n",
      "15 85 0.26426368951797485\n",
      "15 135 0.5506063103675842\n",
      "Validation loss: 0.45556459667389854 MAE: 104.0381\n",
      "16 14 0.4883892238140106\n",
      "16 64 0.5612727403640747\n",
      "16 114 0.544513463973999\n",
      "16 164 0.4927937984466553\n",
      "Validation loss: 0.4756293870203676 MAE: 108.620316\n",
      "17 43 0.46001648902893066\n",
      "17 93 0.6638147830963135\n",
      "17 143 0.42732158303260803\n",
      "Validation loss: 0.43775611732438297 MAE: 99.971146\n",
      "18 22 0.6531445384025574\n",
      "18 72 0.445999413728714\n",
      "18 122 0.6296894550323486\n",
      "Validation loss: 0.420979638894399 MAE: 96.13987\n",
      "19 1 0.41538798809051514\n",
      "19 51 0.5949795842170715\n",
      "19 101 0.7527081966400146\n",
      "19 151 0.5812198519706726\n",
      "Validation loss: 0.4149668314303571 MAE: 94.7667\n",
      "20 30 0.7739410996437073\n",
      "20 80 0.4309740662574768\n",
      "20 130 0.5770678520202637\n",
      "Validation loss: 0.46701570700483713 MAE: 106.65321\n",
      "21 9 0.5166659951210022\n",
      "21 59 0.49750903248786926\n",
      "21 109 0.5053936243057251\n",
      "21 159 0.6577563881874084\n",
      "Validation loss: 0.4792707091883609 MAE: 109.45189\n",
      "22 38 0.40599870681762695\n",
      "22 88 0.23163092136383057\n",
      "22 138 0.3625883460044861\n",
      "Validation loss: 0.42743989755535683 MAE: 97.615204\n",
      "23 17 0.4158427119255066\n",
      "23 67 0.4503273367881775\n",
      "23 117 0.5195159316062927\n",
      "23 167 0.4119313657283783\n",
      "Validation loss: 0.4300296545377252 MAE: 98.206635\n",
      "24 46 0.5402073860168457\n",
      "24 96 0.37955155968666077\n",
      "24 146 0.5075817704200745\n",
      "Validation loss: 0.4444781967073853 MAE: 101.506256\n",
      "25 25 0.3325173854827881\n",
      "25 75 0.3751816749572754\n",
      "25 125 0.43851327896118164\n",
      "Validation loss: 0.4602154078539352 MAE: 105.10021\n",
      "26 4 0.3463733494281769\n",
      "26 54 0.3322879672050476\n",
      "26 104 0.5323705077171326\n",
      "26 154 0.35760775208473206\n",
      "Validation loss: 0.39783981503450383 MAE: 90.85538\n",
      "27 33 0.5222089886665344\n",
      "27 83 0.3291163146495819\n",
      "27 133 0.6660001873970032\n",
      "Validation loss: 0.41526650615602906 MAE: 94.83515\n",
      "28 12 0.5648121237754822\n",
      "28 62 0.38866907358169556\n",
      "28 112 0.6487970948219299\n",
      "28 162 0.46703314781188965\n",
      "Validation loss: 0.397865546202799 MAE: 90.86126\n",
      "29 41 0.4190789759159088\n",
      "29 91 0.3515285849571228\n",
      "29 141 0.44417107105255127\n",
      "Validation loss: 0.43830893489352446 MAE: 100.09738\n",
      "30 20 0.47311946749687195\n",
      "30 70 0.42792531847953796\n",
      "30 120 0.44096875190734863\n",
      "30 170 0.3157913088798523\n",
      "Validation loss: 0.5006037361440603 MAE: 114.32376\n",
      "31 49 0.5489223599433899\n",
      "31 99 0.46896106004714966\n",
      "31 149 0.30213746428489685\n",
      "Validation loss: 0.4463824500814516 MAE: 101.94115\n",
      "32 28 0.51036137342453\n",
      "32 78 0.5271245241165161\n",
      "32 128 0.5524253845214844\n",
      "Validation loss: 0.3994129120606428 MAE: 91.21463\n",
      "33 7 0.3550162613391876\n",
      "33 57 0.39797890186309814\n",
      "33 107 0.2750817537307739\n",
      "33 157 0.3633694350719452\n",
      "Validation loss: 0.4147518589134105 MAE: 94.71762\n",
      "34 36 0.383774995803833\n",
      "34 86 0.3787051737308502\n",
      "34 136 0.2803874909877777\n",
      "Validation loss: 0.39545881329921256 MAE: 90.31163\n",
      "35 15 0.3796320855617523\n",
      "35 65 0.31697726249694824\n",
      "35 115 0.39887160062789917\n",
      "35 165 0.5953356027603149\n",
      "Validation loss: 0.440523414235366 MAE: 100.6031\n",
      "36 44 0.47209179401397705\n",
      "36 94 0.4407530128955841\n",
      "36 144 0.546497106552124\n",
      "Validation loss: 0.3962530087657839 MAE: 90.493\n",
      "37 23 0.33710354566574097\n",
      "37 73 0.34802794456481934\n",
      "37 123 0.5066253542900085\n",
      "Validation loss: 0.4464852130203916 MAE: 101.964615\n",
      "38 2 0.4104743003845215\n",
      "38 52 0.46212056279182434\n",
      "38 102 0.2631133794784546\n",
      "38 152 0.3918320834636688\n",
      "Validation loss: 0.4584928744020518 MAE: 104.706825\n",
      "39 31 0.52420973777771\n",
      "39 81 0.47435060143470764\n",
      "39 131 0.5256018042564392\n",
      "Validation loss: 0.41484975675393265 MAE: 94.739975\n",
      "40 10 0.3071891963481903\n",
      "40 60 0.3519318103790283\n",
      "40 110 0.44949665665626526\n",
      "40 160 0.2530398666858673\n",
      "Validation loss: 0.4862766922914494 MAE: 111.05188\n",
      "41 39 0.3428133428096771\n",
      "41 89 0.48802435398101807\n",
      "41 139 0.45952922105789185\n",
      "Validation loss: 0.47964580365788867 MAE: 109.53755\n",
      "42 18 0.38930025696754456\n",
      "42 68 0.5004767775535583\n",
      "42 118 0.3950743079185486\n",
      "42 168 0.34496772289276123\n",
      "Validation loss: 0.44570870296648374 MAE: 101.78728\n",
      "43 47 0.2901565134525299\n",
      "43 97 0.3248329758644104\n",
      "43 147 0.37962719798088074\n",
      "Validation loss: 0.4799369231999269 MAE: 109.60404\n",
      "44 26 0.2941057085990906\n",
      "44 76 0.3577819764614105\n",
      "44 126 0.32590779662132263\n",
      "Validation loss: 0.4638573177028121 MAE: 105.931915\n",
      "45 5 0.3823179602622986\n",
      "45 55 0.40666648745536804\n",
      "45 105 0.38347673416137695\n",
      "45 155 0.2844688892364502\n",
      "Validation loss: 0.4101983005540413 MAE: 93.67771\n",
      "46 34 0.46489453315734863\n",
      "46 84 0.41128337383270264\n",
      "46 134 0.30038073658943176\n",
      "Validation loss: 0.4055792135104798 MAE: 92.62285\n",
      "47 13 0.36924582719802856\n",
      "47 63 0.397158145904541\n",
      "47 113 0.3831670880317688\n",
      "47 163 0.3097298741340637\n",
      "Validation loss: 0.5470373658408896 MAE: 124.927895\n",
      "48 42 0.48245227336883545\n",
      "48 92 0.4441918432712555\n",
      "48 142 0.3165525197982788\n",
      "Validation loss: 0.47642884216113396 MAE: 108.8029\n",
      "49 21 0.3751690685749054\n",
      "49 71 0.4947216808795929\n",
      "49 121 0.418947696685791\n",
      "Validation loss: 0.5345603919517227 MAE: 122.0785\n",
      "50 0 0.31859055161476135\n",
      "50 50 0.3761318027973175\n",
      "50 100 0.2557787001132965\n",
      "50 150 0.4193294942378998\n",
      "Validation loss: 0.553811706646144 MAE: 126.47496\n",
      "51 29 0.4265938699245453\n",
      "51 79 0.2811499834060669\n",
      "51 129 0.29907938838005066\n",
      "Validation loss: 0.4420385149835843 MAE: 100.94913\n",
      "52 8 0.3701585829257965\n",
      "52 58 0.4451712667942047\n",
      "52 108 0.35351479053497314\n",
      "52 158 0.34530922770500183\n",
      "Validation loss: 0.4816064006752438 MAE: 109.9853\n",
      "53 37 0.38401710987091064\n",
      "53 87 0.4645647406578064\n",
      "53 137 0.3673168420791626\n",
      "Validation loss: 0.4674232758973774 MAE: 106.746284\n",
      "54 16 0.39899587631225586\n",
      "54 66 0.30507078766822815\n",
      "54 116 0.3208661675453186\n",
      "54 166 0.3074055016040802\n",
      "Validation loss: 0.5840224020662363 MAE: 133.37422\n",
      "55 45 0.45575493574142456\n",
      "55 95 0.39529740810394287\n",
      "55 145 0.42548632621765137\n",
      "Validation loss: 0.516475762888702 MAE: 117.94849\n",
      "56 24 0.36793309450149536\n",
      "56 74 0.35942453145980835\n",
      "56 124 0.5075373649597168\n",
      "Validation loss: 0.5890904323399415 MAE: 134.53163\n",
      "57 3 0.40058448910713196\n",
      "57 53 0.3699541687965393\n",
      "57 103 0.4585295617580414\n",
      "57 153 0.4364551603794098\n",
      "Validation loss: 0.5318828493530987 MAE: 121.467026\n",
      "58 32 0.4598667621612549\n",
      "58 82 0.4134358763694763\n",
      "58 132 0.3844680190086365\n",
      "Validation loss: 0.4531149043325792 MAE: 103.47865\n",
      "59 11 0.6005361676216125\n",
      "59 61 0.3656684160232544\n",
      "59 111 0.4130493104457855\n",
      "59 161 0.36760449409484863\n",
      "Validation loss: 0.5356136274616621 MAE: 122.31903\n",
      "60 40 0.29654380679130554\n",
      "60 90 0.42522984743118286\n",
      "60 140 0.25149139761924744\n",
      "Validation loss: 0.5962680484119215 MAE: 136.1708\n",
      "61 19 0.3785973787307739\n",
      "61 69 0.5004743337631226\n",
      "61 119 0.31376996636390686\n",
      "61 169 0.543683648109436\n",
      "Validation loss: 0.5355149277469569 MAE: 122.296486\n",
      "62 48 0.38374072313308716\n",
      "62 98 0.38465696573257446\n",
      "62 148 0.42578086256980896\n",
      "Validation loss: 0.4859561006925259 MAE: 110.97866\n",
      "63 27 0.35678157210350037\n",
      "63 77 0.3906250596046448\n",
      "63 127 0.31424450874328613\n",
      "Validation loss: 0.6619461802711264 MAE: 151.16983\n",
      "64 6 0.4071829915046692\n",
      "64 56 0.47210967540740967\n",
      "64 106 0.3921285569667816\n",
      "64 156 0.2772090435028076\n",
      "Validation loss: 0.520859229982945 MAE: 118.94955\n",
      "65 35 0.3639001250267029\n",
      "65 85 0.4738337993621826\n",
      "65 135 0.555676281452179\n",
      "Validation loss: 0.4232315654643098 MAE: 96.65415\n",
      "66 14 0.3703329265117645\n",
      "66 64 0.4173251986503601\n",
      "66 114 0.40876469016075134\n",
      "66 164 0.24957221746444702\n",
      "Validation loss: 0.4372484908815016 MAE: 99.85522\n",
      "67 43 0.43501874804496765\n",
      "67 93 0.373501718044281\n",
      "67 143 0.3761945366859436\n",
      "Validation loss: 0.6275431109450714 MAE: 143.31314\n",
      "68 22 0.2009565532207489\n",
      "68 72 0.40155524015426636\n",
      "68 122 0.3496953547000885\n",
      "Validation loss: 0.6224866108587611 MAE: 142.15837\n",
      "69 1 0.4096880853176117\n",
      "69 51 0.5009695887565613\n",
      "69 101 0.40247273445129395\n",
      "69 151 0.2892208397388458\n",
      "Validation loss: 0.509653546831064 MAE: 116.39049\n",
      "70 30 0.3947019875049591\n",
      "70 80 0.4109185039997101\n",
      "70 130 0.21670247614383698\n",
      "Validation loss: 0.6242599476847732 MAE: 142.56335\n",
      "71 9 0.4078145921230316\n",
      "71 59 0.3235388398170471\n",
      "71 109 0.3669789135456085\n",
      "71 159 0.6427404284477234\n",
      "Validation loss: 0.4725734093035871 MAE: 107.922424\n",
      "72 38 0.42943939566612244\n",
      "72 88 0.3389207124710083\n",
      "72 138 0.2997010052204132\n",
      "Validation loss: 0.4272701503240574 MAE: 97.57643\n",
      "73 17 0.3437213599681854\n",
      "73 67 0.48151031136512756\n",
      "73 117 0.48115506768226624\n",
      "73 167 0.5163160562515259\n",
      "Validation loss: 0.49149429867839256 MAE: 112.24342\n",
      "74 46 0.3891136944293976\n",
      "74 96 0.4994144141674042\n",
      "74 146 0.3508239984512329\n",
      "Validation loss: 0.4487491609060276 MAE: 102.481636\n",
      "75 25 0.24060915410518646\n",
      "75 75 0.44606783986091614\n",
      "75 125 0.37480852007865906\n",
      "Validation loss: 0.5107528961192794 MAE: 116.64154\n",
      "76 4 0.4591522812843323\n",
      "76 54 0.3487791121006012\n",
      "76 104 0.3240445852279663\n",
      "76 154 0.4819834530353546\n",
      "Validation loss: 0.7439845932854546 MAE: 169.90509\n",
      "77 33 0.39492377638816833\n",
      "77 83 0.3255726397037506\n",
      "77 133 0.29801231622695923\n",
      "Validation loss: 0.5534773597940367 MAE: 126.3986\n",
      "78 12 0.241925448179245\n",
      "78 62 0.24080891907215118\n",
      "78 112 0.32411104440689087\n",
      "78 162 0.5136472582817078\n",
      "Validation loss: 0.4946929408095733 MAE: 112.973915\n",
      "79 41 0.28856179118156433\n",
      "79 91 0.39125776290893555\n",
      "79 141 0.28042376041412354\n",
      "Validation loss: 0.4537786743794268 MAE: 103.63024\n",
      "80 20 0.4572487473487854\n",
      "80 70 0.38184645771980286\n",
      "80 120 0.4602780342102051\n",
      "80 170 0.30507710576057434\n",
      "Validation loss: 0.5053274840639349 MAE: 115.40253\n",
      "81 49 0.4310901165008545\n",
      "81 99 0.345339298248291\n",
      "81 149 0.3749253451824188\n",
      "Validation loss: 0.4431554002371448 MAE: 101.20418\n",
      "82 28 0.4852045774459839\n",
      "82 78 0.3173653483390808\n",
      "82 128 0.27736660838127136\n",
      "Validation loss: 0.6229602161206698 MAE: 142.26653\n",
      "83 7 0.37241876125335693\n",
      "83 57 0.41266411542892456\n",
      "83 107 0.30132484436035156\n",
      "83 157 0.3294440805912018\n",
      "Validation loss: 0.5432294002401898 MAE: 124.05827\n",
      "84 36 0.4483407735824585\n",
      "84 86 0.41808581352233887\n",
      "84 136 0.31614384055137634\n",
      "Validation loss: 0.549733548310765 MAE: 125.54363\n",
      "85 15 0.29747235774993896\n",
      "85 65 0.462677925825119\n",
      "85 115 0.45072031021118164\n",
      "85 165 0.2532810866832733\n",
      "Validation loss: 0.5660627348381176 MAE: 129.27275\n",
      "86 44 0.2992923855781555\n",
      "86 94 0.42761659622192383\n",
      "86 144 0.31180980801582336\n",
      "Validation loss: 0.5765007999208238 MAE: 131.65652\n",
      "87 23 0.300569623708725\n",
      "87 73 0.4606415629386902\n",
      "87 123 0.27136945724487305\n",
      "Validation loss: 0.5239597642630861 MAE: 119.65762\n",
      "88 2 0.3589673638343811\n",
      "88 52 0.3987712562084198\n",
      "88 102 0.5519477725028992\n",
      "88 152 0.3476734757423401\n",
      "Validation loss: 0.5358804907017981 MAE: 122.37998\n",
      "89 31 0.4487893879413605\n",
      "89 81 0.3940618634223938\n",
      "89 131 0.3128933012485504\n",
      "Validation loss: 0.5734050347093951 MAE: 130.94952\n",
      "90 10 0.3660471737384796\n",
      "90 60 0.248238667845726\n",
      "90 110 0.34017178416252136\n",
      "90 160 0.3149506747722626\n",
      "Validation loss: 0.6515915310173704 MAE: 148.80511\n",
      "91 39 0.3032795190811157\n",
      "91 89 0.28741124272346497\n",
      "91 139 0.38037559390068054\n",
      "Validation loss: 0.4639154778935059 MAE: 105.9452\n",
      "92 18 0.3870798647403717\n",
      "92 68 0.25755709409713745\n",
      "92 118 0.2536263167858124\n",
      "92 168 0.21739302575588226\n",
      "Validation loss: 0.5703848666614957 MAE: 130.2598\n",
      "93 47 0.26742348074913025\n",
      "93 97 0.43820858001708984\n",
      "93 147 0.2685256600379944\n",
      "Validation loss: 0.5160132311938102 MAE: 117.84285\n",
      "94 26 0.3531421422958374\n",
      "94 76 0.2173198014497757\n",
      "94 126 0.3200153708457947\n",
      "Validation loss: 0.4734328631420582 MAE: 108.118706\n",
      "95 5 0.33243823051452637\n",
      "95 55 0.4389769434928894\n",
      "95 105 0.32802340388298035\n",
      "95 155 0.43405088782310486\n",
      "Validation loss: 0.46020588470481294 MAE: 105.09803\n",
      "96 34 0.39684972167015076\n",
      "96 84 0.2803749442100525\n",
      "96 134 0.24633033573627472\n",
      "Validation loss: 0.41997071525506807 MAE: 95.90946\n",
      "97 13 0.3052012324333191\n",
      "97 63 0.313332736492157\n",
      "97 113 0.2937757074832916\n",
      "97 163 0.30499735474586487\n",
      "Validation loss: 0.5680690698804911 MAE: 129.73094\n",
      "98 42 0.36165088415145874\n",
      "98 92 0.428634375333786\n",
      "98 142 0.3730356991291046\n",
      "Validation loss: 0.6135550744352285 MAE: 140.11867\n",
      "99 21 0.3744965195655823\n",
      "99 71 0.26686421036720276\n",
      "99 121 0.4146865904331207\n",
      "Validation loss: 0.5836094501074295 MAE: 133.27992\n",
      "100 0 0.38448646664619446\n",
      "100 50 0.29023247957229614\n",
      "100 100 0.40961509943008423\n",
      "100 150 0.43838387727737427\n",
      "Validation loss: 0.4849986974258869 MAE: 110.76002\n",
      "101 29 0.37374797463417053\n",
      "101 79 0.4474555552005768\n",
      "101 129 0.4816358983516693\n",
      "Validation loss: 0.4309833854959722 MAE: 98.42443\n",
      "102 8 0.2825588285923004\n",
      "102 58 0.30716708302497864\n",
      "102 108 0.31540632247924805\n",
      "102 158 0.30521732568740845\n",
      "Validation loss: 0.5113390760812145 MAE: 116.77541\n",
      "103 37 0.4434470534324646\n",
      "103 87 0.34191882610321045\n",
      "103 137 0.37920936942100525\n",
      "Validation loss: 0.5388089522980807 MAE: 123.04875\n",
      "104 16 0.19707390666007996\n",
      "104 66 0.4190187454223633\n",
      "104 116 0.3528909385204315\n",
      "104 166 0.2830744683742523\n",
      "Validation loss: 0.40230140421125626 MAE: 91.87428\n",
      "105 45 0.35160452127456665\n",
      "105 95 0.40079420804977417\n",
      "105 145 0.4116467833518982\n",
      "Validation loss: 0.5178240957664467 MAE: 118.25641\n",
      "106 24 0.372839093208313\n",
      "106 74 0.23902040719985962\n",
      "106 124 0.293334037065506\n",
      "Validation loss: 0.6072800483619958 MAE: 138.68562\n",
      "107 3 0.4205615222454071\n",
      "107 53 0.27624377608299255\n",
      "107 103 0.2457597404718399\n",
      "107 153 0.17100423574447632\n",
      "Validation loss: 0.49094140738771674 MAE: 112.11716\n",
      "108 32 0.25584107637405396\n",
      "108 82 0.39141592383384705\n",
      "108 132 0.36787149310112\n",
      "Validation loss: 0.4751258450641967 MAE: 108.50533\n",
      "109 11 0.37373629212379456\n",
      "109 61 0.27849581837654114\n",
      "109 111 0.36923789978027344\n",
      "109 161 0.26390811800956726\n",
      "Validation loss: 0.5073741883562323 MAE: 115.86994\n",
      "110 40 0.25858554244041443\n",
      "110 90 0.38737156987190247\n",
      "110 140 0.2750526964664459\n",
      "Validation loss: 0.6447848384840447 MAE: 147.25066\n",
      "111 19 0.36845001578330994\n",
      "111 69 0.4472059905529022\n",
      "111 119 0.3041960299015045\n",
      "111 169 0.37691372632980347\n",
      "Validation loss: 0.4698837697505951 MAE: 107.3082\n",
      "112 48 0.46519720554351807\n",
      "112 98 0.4210323989391327\n",
      "112 148 0.39974725246429443\n",
      "Validation loss: 0.5619530949676246 MAE: 128.33423\n",
      "113 27 0.2478170245885849\n",
      "113 77 0.36759746074676514\n",
      "113 127 0.333359956741333\n",
      "Validation loss: 0.5593669972224542 MAE: 127.74364\n",
      "114 6 0.3107732832431793\n",
      "114 56 0.23095695674419403\n",
      "114 106 0.23422400653362274\n",
      "114 156 0.4248502850532532\n",
      "Validation loss: 0.5702743579072562 MAE: 130.23456\n",
      "115 35 0.24909362196922302\n",
      "115 85 0.2887014150619507\n",
      "115 135 0.3254833519458771\n",
      "Validation loss: 0.6090906576106423 MAE: 139.09912\n",
      "116 14 0.24867933988571167\n",
      "116 64 0.30210453271865845\n",
      "116 114 0.33170807361602783\n",
      "116 164 0.30918702483177185\n",
      "Validation loss: 0.5829188102170041 MAE: 133.12221\n",
      "117 43 0.39406052231788635\n",
      "117 93 0.4794744849205017\n",
      "117 143 0.28791841864585876\n",
      "Validation loss: 0.4943760419101046 MAE: 112.901535\n",
      "118 22 0.36018240451812744\n",
      "118 72 0.4391266107559204\n",
      "118 122 0.3623969256877899\n",
      "Validation loss: 0.4710239921396936 MAE: 107.56857\n",
      "119 1 0.18906289339065552\n",
      "119 51 0.26010560989379883\n",
      "119 101 0.38261011242866516\n",
      "119 151 0.23000401258468628\n",
      "Validation loss: 0.5542065177047462 MAE: 126.565125\n",
      "120 30 0.2700619399547577\n",
      "120 80 0.31372347474098206\n",
      "120 130 0.31030017137527466\n",
      "Validation loss: 0.47759044240092674 MAE: 109.06818\n",
      "121 9 0.22423936426639557\n",
      "121 59 0.42496705055236816\n",
      "121 109 0.329012393951416\n",
      "121 159 0.25447529554367065\n",
      "Validation loss: 0.7213018825876782 MAE: 164.72499\n",
      "122 38 0.22448311746120453\n",
      "122 88 0.16758231818675995\n",
      "122 138 0.2805924117565155\n",
      "Validation loss: 0.5045792465670067 MAE: 115.23166\n",
      "123 17 0.23830434679985046\n",
      "123 67 0.409973680973053\n",
      "123 117 0.3988804817199707\n",
      "123 167 0.2880309522151947\n",
      "Validation loss: 0.6269484144902369 MAE: 143.17732\n",
      "124 46 0.41315576434135437\n",
      "124 96 0.4040931761264801\n",
      "124 146 0.49096235632896423\n",
      "Validation loss: 0.6164563441137124 MAE: 140.78123\n",
      "125 25 0.46105244755744934\n",
      "125 75 0.47588276863098145\n",
      "125 125 0.3355242908000946\n",
      "Validation loss: 0.6615269776673345 MAE: 151.0741\n",
      "126 4 0.354717880487442\n",
      "126 54 0.2960708439350128\n",
      "126 104 0.28812673687934875\n",
      "126 154 0.3526575267314911\n",
      "Validation loss: 0.5896564396152719 MAE: 134.66089\n",
      "127 33 0.30246108770370483\n",
      "127 83 0.25895753502845764\n",
      "127 133 0.3221937417984009\n",
      "Validation loss: 0.5314846143387911 MAE: 121.37608\n",
      "128 12 0.5260859131813049\n",
      "128 62 0.41057121753692627\n",
      "128 112 0.36768192052841187\n",
      "128 162 0.4223729372024536\n",
      "Validation loss: 0.5310756625139226 MAE: 121.28269\n",
      "129 41 0.4136944115161896\n",
      "129 91 0.29805058240890503\n",
      "129 141 0.33724215626716614\n",
      "Validation loss: 0.6421125890218724 MAE: 146.64038\n",
      "130 20 0.2545320391654968\n",
      "130 70 0.290237694978714\n",
      "130 120 0.25577011704444885\n",
      "130 170 0.3090437352657318\n",
      "Validation loss: 0.5161883545200727 MAE: 117.88284\n",
      "131 49 0.3541838526725769\n",
      "131 99 0.26571106910705566\n",
      "131 149 0.3339124619960785\n",
      "Validation loss: 0.5573382238198442 MAE: 127.28031\n",
      "132 28 0.2809436023235321\n",
      "132 78 0.3309085965156555\n",
      "132 128 0.22196906805038452\n",
      "Validation loss: 0.6010808613565233 MAE: 137.2699\n",
      "133 7 0.41304129362106323\n",
      "133 57 0.2857763469219208\n",
      "133 107 0.2676851153373718\n",
      "133 157 0.21716292202472687\n",
      "Validation loss: 0.5467012141183106 MAE: 124.85113\n",
      "134 36 0.2753940522670746\n",
      "134 86 0.3003140091896057\n",
      "134 136 0.22486336529254913\n",
      "Validation loss: 0.6573332628311469 MAE: 150.11636\n",
      "135 15 0.27363231778144836\n",
      "135 65 0.23090767860412598\n",
      "135 115 0.4046594500541687\n",
      "135 165 0.21559171378612518\n",
      "Validation loss: 0.561788032626548 MAE: 128.29654\n",
      "136 44 0.46042707562446594\n",
      "136 94 0.2645051181316376\n",
      "136 144 0.3731091320514679\n",
      "Validation loss: 0.5355878364272982 MAE: 122.31314\n",
      "137 23 0.31511563062667847\n",
      "137 73 0.3883024752140045\n",
      "137 123 0.3983530104160309\n",
      "Validation loss: 0.5557065972110682 MAE: 126.9077\n",
      "138 2 0.21467329561710358\n",
      "138 52 0.27204424142837524\n",
      "138 102 0.19769015908241272\n",
      "138 152 0.22421741485595703\n",
      "Validation loss: 0.6070277694373103 MAE: 138.628\n",
      "139 31 0.22161275148391724\n",
      "139 81 0.49762317538261414\n",
      "139 131 0.2769041955471039\n",
      "Validation loss: 0.7376466623523779 MAE: 168.45767\n",
      "140 10 -0.03278309106826782\n",
      "140 60 -6.257933139801025\n",
      "140 110 -16.4432430267334\n",
      "140 160 -25.699617385864258\n",
      "Validation loss: 0.5501026932956182 MAE: 125.62792\n",
      "141 39 -34.53433609008789\n",
      "141 89 -39.82853698730469\n",
      "141 139 -43.435218811035156\n",
      "Validation loss: 0.5335292401369552 MAE: 121.84302\n",
      "142 18 -54.78436279296875\n",
      "142 68 -72.75299072265625\n",
      "142 118 -71.43693542480469\n",
      "142 168 -92.8169174194336\n",
      "Validation loss: 0.6192580946007668 MAE: 141.42108\n",
      "143 47 -100.15190124511719\n",
      "143 97 -127.78498840332031\n",
      "143 147 -136.20025634765625\n",
      "Validation loss: 0.6355540180764003 MAE: 145.14261\n",
      "144 26 -153.76654052734375\n",
      "144 76 -151.17750549316406\n",
      "144 126 -180.18930053710938\n",
      "Validation loss: 0.5069294923927352 MAE: 115.76838\n",
      "145 5 -203.54620361328125\n",
      "145 55 -204.82962036132812\n",
      "145 105 -237.6114501953125\n",
      "145 155 -265.93304443359375\n",
      "Validation loss: 0.6228209967501679 MAE: 142.23473\n",
      "146 34 -285.1930236816406\n",
      "146 84 -299.4590759277344\n",
      "146 134 -330.3410949707031\n",
      "Validation loss: 0.578060015251762 MAE: 132.01259\n",
      "147 13 -325.31732177734375\n",
      "147 63 -358.3831481933594\n",
      "147 113 -362.1825256347656\n",
      "147 163 -368.77734375\n",
      "Validation loss: 0.48748971094862065 MAE: 111.32888\n",
      "148 42 -385.2598571777344\n",
      "148 92 -399.0725402832031\n",
      "148 142 -460.08880615234375\n",
      "Validation loss: 0.5442642628798011 MAE: 124.29459\n",
      "149 21 -560.4305419921875\n",
      "149 71 -531.047119140625\n",
      "149 121 -546.4723510742188\n",
      "Validation loss: 0.5493729632151755 MAE: 125.46128\n",
      "150 0 -536.5804443359375\n",
      "150 50 -614.9884033203125\n",
      "150 100 -608.0162963867188\n",
      "150 150 -589.1636352539062\n",
      "Validation loss: 0.6353101632748431 MAE: 145.0869\n",
      "151 29 -617.19970703125\n",
      "151 79 -679.0157470703125\n",
      "151 129 -710.140380859375\n",
      "Validation loss: 0.6624549163712395 MAE: 151.286\n",
      "152 8 -852.4959716796875\n",
      "152 58 -716.2544555664062\n",
      "152 108 -779.1428833007812\n",
      "152 158 -916.251220703125\n",
      "Validation loss: 0.5938841916664303 MAE: 135.62639\n",
      "153 37 -931.0156860351562\n",
      "153 87 -872.151611328125\n",
      "153 137 -977.6705932617188\n",
      "Validation loss: 0.5922896717375482 MAE: 135.26224\n",
      "154 16 -1067.7413330078125\n",
      "154 66 -974.2434692382812\n",
      "154 116 -950.5980834960938\n",
      "154 166 -1052.6427001953125\n",
      "Validation loss: 0.5791615993655913 MAE: 132.26416\n",
      "155 45 -1029.6781005859375\n",
      "155 95 -1200.0732421875\n",
      "155 145 -1168.3277587890625\n",
      "Validation loss: 0.6028422654023644 MAE: 137.67215\n",
      "156 24 -1300.170166015625\n",
      "156 74 -1284.7191162109375\n",
      "156 124 -1299.564453125\n",
      "Validation loss: 0.6096414118482355 MAE: 139.2249\n",
      "157 3 -1340.6259765625\n",
      "157 53 -1475.655029296875\n",
      "157 103 -1412.1514892578125\n",
      "157 153 -1510.7943115234375\n",
      "Validation loss: 0.594695592484279 MAE: 135.81169\n",
      "158 32 -1519.648193359375\n",
      "158 82 -1542.6767578125\n",
      "158 132 -1613.9464111328125\n",
      "Validation loss: 0.6047321157148707 MAE: 138.10374\n",
      "159 11 -1610.3336181640625\n",
      "159 61 -1558.144775390625\n",
      "159 111 -1873.87255859375\n",
      "159 161 -1877.041259765625\n",
      "Validation loss: 0.6432293845199005 MAE: 146.89542\n",
      "160 40 -1908.209228515625\n",
      "160 90 -1695.5072021484375\n",
      "160 140 -2013.1502685546875\n",
      "Validation loss: 0.6205361412282575 MAE: 141.71294\n",
      "161 19 -1907.3023681640625\n",
      "161 69 -1853.552734375\n",
      "161 119 -1936.0931396484375\n",
      "161 169 -1910.16162109375\n",
      "Validation loss: 0.6896279241606506 MAE: 157.49155\n",
      "162 48 -2236.6962890625\n",
      "162 98 -2037.3583984375\n",
      "162 148 -2297.14697265625\n",
      "Validation loss: 0.6463275680765074 MAE: 147.60298\n",
      "163 27 -2394.66748046875\n",
      "163 77 -2398.094970703125\n",
      "163 127 -2441.530517578125\n",
      "Validation loss: 0.6481718041046322 MAE: 148.02414\n",
      "164 6 -2480.42822265625\n",
      "164 56 -2312.451904296875\n",
      "164 106 -2548.62060546875\n",
      "164 156 -2304.188720703125\n",
      "Validation loss: 0.7165250332034819 MAE: 163.6341\n",
      "165 35 -2268.1083984375\n",
      "165 85 -2808.71484375\n",
      "165 135 -2780.246826171875\n",
      "Validation loss: 0.6520498295625051 MAE: 148.90977\n",
      "166 14 -2986.051025390625\n",
      "166 64 -2864.984619140625\n",
      "166 114 -2740.06787109375\n",
      "166 164 -3175.45849609375\n",
      "Validation loss: 0.6411080227957832 MAE: 146.41096\n",
      "167 43 -3083.83056640625\n",
      "167 93 -3350.538818359375\n",
      "167 143 -3010.3720703125\n",
      "Validation loss: 0.678111589791482 MAE: 154.86154\n",
      "168 22 -3258.593994140625\n",
      "168 72 -3183.690185546875\n",
      "168 122 -3378.00927734375\n",
      "Validation loss: 0.6809741042510807 MAE: 155.51526\n",
      "169 1 -3487.193359375\n",
      "169 51 -3299.9765625\n",
      "169 101 -3647.76806640625\n",
      "169 151 -3630.294921875\n",
      "Validation loss: 0.6450505619160614 MAE: 147.31134\n",
      "170 30 -3828.9375\n",
      "170 80 -3785.352783203125\n",
      "170 130 -3701.05419921875\n",
      "Validation loss: 0.6421045406520018 MAE: 146.63855\n",
      "171 9 -3855.993408203125\n",
      "171 59 -4081.603759765625\n",
      "171 109 -3518.578369140625\n",
      "171 159 -4346.3623046875\n",
      "Validation loss: 0.6155533821959245 MAE: 140.57501\n",
      "172 38 -4591.63720703125\n",
      "172 88 -4345.68359375\n",
      "172 138 -4613.947265625\n",
      "Validation loss: 0.7131345036782717 MAE: 162.85979\n",
      "173 17 -4404.49951171875\n",
      "173 67 -4336.71435546875\n",
      "173 117 -4584.46923828125\n",
      "173 167 -4759.51171875\n",
      "Validation loss: 0.6904441564403779 MAE: 157.67795\n",
      "174 46 -4626.96630859375\n",
      "174 96 -4476.66845703125\n",
      "174 146 -5135.9375\n",
      "Validation loss: 0.6356008903324952 MAE: 145.1533\n",
      "175 25 -5011.69287109375\n",
      "175 75 -5352.46044921875\n",
      "175 125 -5363.9501953125\n",
      "Validation loss: 0.7374704640511184 MAE: 168.41743\n",
      "176 4 -5431.53125\n",
      "176 54 -5108.29638671875\n",
      "176 104 -4981.455078125\n",
      "176 154 -5755.33154296875\n",
      "Validation loss: 0.670790571915476 MAE: 153.18964\n",
      "177 33 -5546.81396484375\n",
      "177 83 -5561.74951171875\n",
      "177 133 -6332.49365234375\n",
      "Validation loss: 0.7377146224529423 MAE: 168.47318\n",
      "178 12 -6260.66796875\n",
      "178 62 -5938.83056640625\n",
      "178 112 -5806.05078125\n",
      "178 162 -6338.42333984375\n",
      "Validation loss: 0.6911225486219975 MAE: 157.83287\n",
      "179 41 -6065.9306640625\n",
      "179 91 -6296.86572265625\n",
      "179 141 -6608.064453125\n",
      "Validation loss: 0.6786622011173539 MAE: 154.98729\n",
      "180 20 -6013.451171875\n",
      "180 70 -7067.0771484375\n",
      "180 120 -7089.10009765625\n",
      "180 170 -5932.23681640625\n",
      "Validation loss: 0.7060196748253895 MAE: 161.23497\n",
      "181 49 -6143.17919921875\n",
      "181 99 -6526.17236328125\n",
      "181 149 -6913.2041015625\n",
      "Validation loss: 0.7075953839118021 MAE: 161.59482\n",
      "182 28 -6991.90087890625\n",
      "182 78 -7195.037109375\n",
      "182 128 -7208.93310546875\n",
      "Validation loss: 0.7380860318914492 MAE: 168.55801\n",
      "183 7 -7633.9892578125\n",
      "183 57 -7301.44091796875\n",
      "183 107 -7531.20361328125\n",
      "183 157 -8204.1103515625\n",
      "Validation loss: 0.6982499538806447 MAE: 159.46057\n",
      "184 36 -8385.3447265625\n",
      "184 86 -8667.91796875\n",
      "184 136 -8044.62255859375\n",
      "Validation loss: 0.6505642048796715 MAE: 148.5705\n",
      "185 15 -8610.7265625\n",
      "185 65 -8655.2392578125\n",
      "185 115 -8574.859375\n",
      "185 165 -8285.287109375\n",
      "Validation loss: 0.6534173164451331 MAE: 149.22208\n",
      "186 44 -8953.353515625\n",
      "186 94 -8942.6064453125\n",
      "186 144 -9099.205078125\n",
      "Validation loss: 0.7190670437282987 MAE: 164.21461\n",
      "187 23 -9738.5615234375\n",
      "187 73 -9088.2626953125\n",
      "187 123 -9266.9248046875\n",
      "Validation loss: 0.6997015343772041 MAE: 159.79208\n",
      "188 2 -9160.5859375\n",
      "188 52 -9283.841796875\n",
      "188 102 -10076.123046875\n",
      "188 152 -10252.169921875\n",
      "Validation loss: 0.7105974063538668 MAE: 162.28038\n",
      "189 31 -9935.625\n",
      "189 81 -10195.974609375\n",
      "189 131 -9752.1796875\n",
      "Validation loss: 0.6643356496130514 MAE: 151.7155\n",
      "190 10 -10299.04296875\n",
      "190 60 -10442.419921875\n",
      "190 110 -10522.1689453125\n",
      "190 160 -10584.5361328125\n",
      "Validation loss: 0.71337237030442 MAE: 162.91411\n",
      "191 39 -9798.9794921875\n",
      "191 89 -10187.556640625\n",
      "191 139 -9448.654296875\n",
      "Validation loss: 0.6582931499732169 MAE: 150.33557\n",
      "192 18 -10540.9228515625\n",
      "192 68 -11716.5869140625\n",
      "192 118 -11626.3427734375\n",
      "192 168 -11849.6748046875\n",
      "Validation loss: 0.7086871102539419 MAE: 161.84413\n",
      "193 47 -11938.57421875\n",
      "193 97 -11211.837890625\n",
      "193 147 -12397.404296875\n",
      "Validation loss: 0.7064130006477847 MAE: 161.32478\n",
      "194 26 -11882.9248046875\n",
      "194 76 -12335.5556640625\n",
      "194 126 -11602.9033203125\n",
      "Validation loss: 0.7627224803668017 MAE: 174.18428\n",
      "195 5 -12051.3017578125\n",
      "195 55 -13006.404296875\n",
      "195 105 -11901.0888671875\n",
      "195 155 -12982.640625\n",
      "Validation loss: 0.7099435322465952 MAE: 162.13107\n",
      "196 34 -12172.0126953125\n",
      "196 84 -13866.765625\n",
      "196 134 -13350.978515625\n",
      "Validation loss: 0.7080756509513185 MAE: 161.7045\n",
      "197 13 -13981.9775390625\n",
      "197 63 -13697.1875\n",
      "197 113 -12902.1845703125\n",
      "197 163 -14162.771484375\n",
      "Validation loss: 0.733281836175082 MAE: 167.46088\n",
      "198 42 -14083.7724609375\n",
      "198 92 -14560.31640625\n",
      "198 142 -14724.1943359375\n",
      "Validation loss: 0.7713187640173393 MAE: 176.14743\n",
      "199 21 -15174.23046875\n",
      "199 71 -14323.814453125\n",
      "199 121 -13870.310546875\n",
      "Validation loss: 0.7082724630484107 MAE: 161.74944\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.35072637191192296 Test MAE: 80.096\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'qm7', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 779, 'task': 'regression', 'data_path': 'data/qm7/qm7.csv', 'target': ['u0_atom']}}\n",
      "Running on: cuda:1\n",
      "6833\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/6833\n",
      "Generating scaffold 1000/6833\n",
      "Generating scaffold 2000/6833\n",
      "Generating scaffold 3000/6833\n",
      "Generating scaffold 4000/6833\n",
      "Generating scaffold 5000/6833\n",
      "Generating scaffold 6000/6833\n",
      "About to sort in scaffold sets\n",
      "tensor(-1553.3462) tensor(228.3718) torch.Size([5466, 1])\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 8.23105525970459\n",
      "0 50 2.9238553047180176\n",
      "0 100 1.9203388690948486\n",
      "0 150 1.6785213947296143\n",
      "Validation loss: 0.44113781647375455 MAE: 100.74342\n",
      "1 29 1.5780969858169556\n",
      "1 79 1.2868165969848633\n",
      "1 129 1.340829610824585\n",
      "Validation loss: 0.5997692377943742 MAE: 136.97037\n",
      "2 8 1.0307590961456299\n",
      "2 58 1.3484430313110352\n",
      "2 108 1.3043148517608643\n",
      "2 158 0.8139214515686035\n",
      "Validation loss: 0.4585463394198501 MAE: 104.71905\n",
      "3 37 1.1782727241516113\n",
      "3 87 0.986407458782196\n",
      "3 137 1.117460012435913\n",
      "Validation loss: 0.6225340143281813 MAE: 142.1692\n",
      "4 16 0.866276204586029\n",
      "4 66 0.6443182229995728\n",
      "4 116 0.7000383138656616\n",
      "4 166 0.9305634498596191\n",
      "Validation loss: 0.47031097070515504 MAE: 107.40575\n",
      "5 45 0.8523348569869995\n",
      "5 95 0.7368359565734863\n",
      "5 145 0.8227594494819641\n",
      "Validation loss: 0.44960864524395144 MAE: 102.67792\n",
      "6 24 0.8024311065673828\n",
      "6 74 0.8112244606018066\n",
      "6 124 0.5572665929794312\n",
      "Validation loss: 0.4241658966792257 MAE: 96.86751\n",
      "7 3 0.9256699085235596\n",
      "7 53 0.6543153524398804\n",
      "7 103 0.7471147775650024\n",
      "7 153 0.658687949180603\n",
      "Validation loss: 0.5794859092835097 MAE: 132.33823\n",
      "8 32 0.620538592338562\n",
      "8 82 0.6656128764152527\n",
      "8 132 0.5818535089492798\n",
      "Validation loss: 0.4493253192706415 MAE: 102.61321\n",
      "9 11 0.789128303527832\n",
      "9 61 0.6546399593353271\n",
      "9 111 0.550137460231781\n",
      "9 161 0.7237318754196167\n",
      "Validation loss: 0.4007608500140452 MAE: 91.52247\n",
      "10 40 0.48653507232666016\n",
      "10 90 0.49670273065567017\n",
      "10 140 0.6669437885284424\n",
      "Validation loss: 0.5553497461199063 MAE: 126.8262\n",
      "11 19 0.48257893323898315\n",
      "11 69 0.5168595910072327\n",
      "11 119 0.5476412773132324\n",
      "11 169 0.49100250005722046\n",
      "Validation loss: 0.40090906733309317 MAE: 91.55631\n",
      "12 48 0.4288102686405182\n",
      "12 98 0.44189560413360596\n",
      "12 148 0.6662639379501343\n",
      "Validation loss: 0.553551331249594 MAE: 126.415504\n",
      "13 27 0.6733352541923523\n",
      "13 77 0.39480018615722656\n",
      "13 127 0.39954325556755066\n",
      "Validation loss: 0.45480176719308596 MAE: 103.863884\n",
      "14 6 0.5318779945373535\n",
      "14 56 0.5152890682220459\n",
      "14 106 0.6089577078819275\n",
      "14 156 0.48818543553352356\n",
      "Validation loss: 0.5032181283186751 MAE: 114.920815\n",
      "15 35 0.6109502911567688\n",
      "15 85 0.5781489014625549\n",
      "15 135 0.45653483271598816\n",
      "Validation loss: 0.45373751475797064 MAE: 103.62084\n",
      "16 14 0.6163222789764404\n",
      "16 64 0.4664209485054016\n",
      "16 114 0.6168124675750732\n",
      "16 164 0.49363070726394653\n",
      "Validation loss: 0.507819624323594 MAE: 115.971664\n",
      "17 43 0.6410582661628723\n",
      "17 93 0.4777524173259735\n",
      "17 143 0.6108043789863586\n",
      "Validation loss: 0.6164493567762319 MAE: 140.77963\n",
      "18 22 0.63504958152771\n",
      "18 72 0.6292257308959961\n",
      "18 122 0.5819686651229858\n",
      "Validation loss: 0.4729218434172067 MAE: 108.002\n",
      "19 1 0.4955328702926636\n",
      "19 51 0.4288073480129242\n",
      "19 101 0.38712310791015625\n",
      "19 151 0.6663824319839478\n",
      "Validation loss: 0.4286475436032167 MAE: 97.89099\n",
      "20 30 0.46526578068733215\n",
      "20 80 0.4910944104194641\n",
      "20 130 0.592986524105072\n",
      "Validation loss: 0.42140939779448927 MAE: 96.23801\n",
      "21 9 0.433555543422699\n",
      "21 59 0.4608710706233978\n",
      "21 109 0.5782668590545654\n",
      "21 159 0.4725416898727417\n",
      "Validation loss: 0.397317639045548 MAE: 90.73614\n",
      "22 38 0.45619043707847595\n",
      "22 88 0.5466318130493164\n",
      "22 138 0.7004651427268982\n",
      "Validation loss: 0.40883890020917035 MAE: 93.36726\n",
      "23 17 0.6894524097442627\n",
      "23 67 0.6274838447570801\n",
      "23 117 0.4999687075614929\n",
      "23 167 0.48420459032058716\n",
      "Validation loss: 0.4439215395185683 MAE: 101.37914\n",
      "24 46 0.4907124936580658\n",
      "24 96 0.3805760145187378\n",
      "24 146 0.36366575956344604\n",
      "Validation loss: 0.45836836622472393 MAE: 104.6784\n",
      "25 25 0.38683778047561646\n",
      "25 75 0.2969859838485718\n",
      "25 125 0.43676769733428955\n",
      "Validation loss: 0.46733346076039545 MAE: 106.72576\n",
      "26 4 0.36823347210884094\n",
      "26 54 0.49268507957458496\n",
      "26 104 0.3358128070831299\n",
      "26 154 0.5744035840034485\n",
      "Validation loss: 0.4065864124493292 MAE: 92.85286\n",
      "27 33 0.48286858201026917\n",
      "27 83 0.613983154296875\n",
      "27 133 0.4380508363246918\n",
      "Validation loss: 0.4504906392236899 MAE: 102.87934\n",
      "28 12 0.5935498476028442\n",
      "28 62 0.46367812156677246\n",
      "28 112 0.3590611219406128\n",
      "28 162 0.6059073209762573\n",
      "Validation loss: 0.4206503664540966 MAE: 96.06467\n",
      "29 41 0.33910682797431946\n",
      "29 91 0.49895018339157104\n",
      "29 141 0.3846031427383423\n",
      "Validation loss: 0.4170292222011856 MAE: 95.2377\n",
      "30 20 0.4219529330730438\n",
      "30 70 0.4491032660007477\n",
      "30 120 0.24707630276679993\n",
      "30 170 0.5727709531784058\n",
      "Validation loss: 0.43294949350301287 MAE: 98.87344\n",
      "31 49 0.6180891990661621\n",
      "31 99 0.4490531086921692\n",
      "31 149 0.44345980882644653\n",
      "Validation loss: 0.45940505726295605 MAE: 104.915146\n",
      "32 28 0.2976812422275543\n",
      "32 78 0.3986799418926239\n",
      "32 128 0.44247594475746155\n",
      "Validation loss: 0.4315742498252824 MAE: 98.55937\n",
      "33 7 0.3871226906776428\n",
      "33 57 0.3721840977668762\n",
      "33 107 0.387590616941452\n",
      "33 157 0.6326308250427246\n",
      "Validation loss: 0.41492132502689694 MAE: 94.756325\n",
      "34 36 0.42494383454322815\n",
      "34 86 0.27243149280548096\n",
      "34 136 0.2099463939666748\n",
      "Validation loss: 0.42641077491275053 MAE: 97.38019\n",
      "35 15 0.5261546969413757\n",
      "35 65 0.5883470773696899\n",
      "35 115 0.3689895570278168\n",
      "35 165 0.5355045199394226\n",
      "Validation loss: 0.3906269763645373 MAE: 89.208176\n",
      "36 44 0.4359588325023651\n",
      "36 94 0.3126876652240753\n",
      "36 144 0.30897417664527893\n",
      "Validation loss: 0.41342188112917 MAE: 94.41389\n",
      "37 23 0.38976696133613586\n",
      "37 73 0.44654378294944763\n",
      "37 123 0.21305090188980103\n",
      "Validation loss: 0.4230588050613626 MAE: 96.614685\n",
      "38 2 0.23677566647529602\n",
      "38 52 0.4357863962650299\n",
      "38 102 0.5377062559127808\n",
      "38 152 0.43637964129447937\n",
      "Validation loss: 0.4149322506279973 MAE: 94.75882\n",
      "39 31 0.447107195854187\n",
      "39 81 0.41846877336502075\n",
      "39 131 0.3810785114765167\n",
      "Validation loss: 0.4260043565467087 MAE: 97.28737\n",
      "40 10 0.29225558042526245\n",
      "40 60 0.26885858178138733\n",
      "40 110 0.5158576369285583\n",
      "40 160 0.31969717144966125\n",
      "Validation loss: 0.4323672488418936 MAE: 98.74047\n",
      "41 39 0.31915634870529175\n",
      "41 89 0.3519993722438812\n",
      "41 139 0.39514148235321045\n",
      "Validation loss: 0.43144900373548095 MAE: 98.53077\n",
      "42 18 0.33496350049972534\n",
      "42 68 0.31563395261764526\n",
      "42 118 0.39977937936782837\n",
      "42 168 0.41953879594802856\n",
      "Validation loss: 0.4293297008115646 MAE: 98.04678\n",
      "43 47 0.4215199053287506\n",
      "43 97 0.3434097170829773\n",
      "43 147 0.3619960844516754\n",
      "Validation loss: 0.4240507197658918 MAE: 96.84122\n",
      "44 26 0.2742496728897095\n",
      "44 76 0.6670947074890137\n",
      "44 126 0.5911286473274231\n",
      "Validation loss: 0.4099725704444082 MAE: 93.62617\n",
      "45 5 0.5513498187065125\n",
      "45 55 0.3427790403366089\n",
      "45 105 0.34061047434806824\n",
      "45 155 0.38906076550483704\n",
      "Validation loss: 0.4616812498945939 MAE: 105.43497\n",
      "46 34 0.2352902591228485\n",
      "46 84 0.2783559262752533\n",
      "46 134 0.34332534670829773\n",
      "Validation loss: 0.4555177566600822 MAE: 104.02739\n",
      "47 13 0.5674086213111877\n",
      "47 63 0.49306580424308777\n",
      "47 113 0.39566951990127563\n",
      "47 163 0.6259263157844543\n",
      "Validation loss: 0.4463394894237407 MAE: 101.931335\n",
      "48 42 0.4956173002719879\n",
      "48 92 0.3689254820346832\n",
      "48 142 0.44046133756637573\n",
      "Validation loss: 0.46857789176249365 MAE: 107.00996\n",
      "49 21 0.4980177879333496\n",
      "49 71 0.387244313955307\n",
      "49 121 0.4639795124530792\n",
      "Validation loss: 0.4670743220730832 MAE: 106.666595\n",
      "50 0 0.6963782906532288\n",
      "50 50 0.46352773904800415\n",
      "50 100 0.47183239459991455\n",
      "50 150 0.3231509327888489\n",
      "Validation loss: 0.50370979239369 MAE: 115.033104\n",
      "51 29 0.5154013633728027\n",
      "51 79 0.35056090354919434\n",
      "51 129 0.33934485912323\n",
      "Validation loss: 0.4901035034168533 MAE: 111.925804\n",
      "52 8 0.3429926037788391\n",
      "52 58 0.3663072884082794\n",
      "52 108 0.3262060582637787\n",
      "52 158 0.3189102113246918\n",
      "Validation loss: 0.5097354033537078 MAE: 116.40917\n",
      "53 37 0.3920240104198456\n",
      "53 87 0.3633721172809601\n",
      "53 137 0.27708566188812256\n",
      "Validation loss: 0.4825144277678596 MAE: 110.19267\n",
      "54 16 0.3447533845901489\n",
      "54 66 0.4109685719013214\n",
      "54 116 0.3389662504196167\n",
      "54 166 0.3826168477535248\n",
      "Validation loss: 0.41835329581422415 MAE: 95.540085\n",
      "55 45 0.4654640555381775\n",
      "55 95 0.5756447315216064\n",
      "55 145 0.4924617409706116\n",
      "Validation loss: 0.4159581943562156 MAE: 94.99311\n",
      "56 24 0.2193879783153534\n",
      "56 74 0.4341663420200348\n",
      "56 124 0.5417056679725647\n",
      "Validation loss: 0.46715723579390006 MAE: 106.685524\n",
      "57 3 0.45914310216903687\n",
      "57 53 0.3395952582359314\n",
      "57 103 0.5657472014427185\n",
      "57 153 0.4614916145801544\n",
      "Validation loss: 0.6523232048715067 MAE: 148.97221\n",
      "58 32 0.340695321559906\n",
      "58 82 0.4006726145744324\n",
      "58 132 0.579378604888916\n",
      "Validation loss: 0.4091598461245933 MAE: 93.44055\n",
      "59 11 0.4087770879268646\n",
      "59 61 0.3029211759567261\n",
      "59 111 0.28187495470046997\n",
      "59 161 0.5329738259315491\n",
      "Validation loss: 0.44066455785991154 MAE: 100.635345\n",
      "60 40 0.3480326235294342\n",
      "60 90 0.2900942265987396\n",
      "60 140 0.3668384850025177\n",
      "Validation loss: 0.6114842487357514 MAE: 139.64574\n",
      "61 19 0.4754955768585205\n",
      "61 69 0.3302335739135742\n",
      "61 119 0.370286226272583\n",
      "61 169 0.4230611324310303\n",
      "Validation loss: 0.5672383162013271 MAE: 129.54121\n",
      "62 48 0.29758313298225403\n",
      "62 98 0.3467627167701721\n",
      "62 148 0.3825570046901703\n",
      "Validation loss: 0.5731018809547201 MAE: 130.8803\n",
      "63 27 0.36687716841697693\n",
      "63 77 0.259264200925827\n",
      "63 127 0.37796714901924133\n",
      "Validation loss: 0.4656007018005639 MAE: 106.33007\n",
      "64 6 0.28255078196525574\n",
      "64 56 0.4016381502151489\n",
      "64 106 0.5574317574501038\n",
      "64 156 0.3307405412197113\n",
      "Validation loss: 0.5102029864551031 MAE: 116.51597\n",
      "65 35 0.3244144916534424\n",
      "65 85 0.38727280497550964\n",
      "65 135 0.3696119487285614\n",
      "Validation loss: 0.616398002669128 MAE: 140.76791\n",
      "66 14 0.2859012186527252\n",
      "66 64 0.302560031414032\n",
      "66 114 0.3215283751487732\n",
      "66 164 0.31513720750808716\n",
      "Validation loss: 0.624399307178475 MAE: 142.59518\n",
      "67 43 0.45392000675201416\n",
      "67 93 0.29468750953674316\n",
      "67 143 0.2871456742286682\n",
      "Validation loss: 0.5421578615729572 MAE: 123.81355\n",
      "68 22 0.4312324821949005\n",
      "68 72 0.4189904034137726\n",
      "68 122 0.4272177815437317\n",
      "Validation loss: 0.5719451625444736 MAE: 130.61613\n",
      "69 1 0.3526150584220886\n",
      "69 51 0.35322436690330505\n",
      "69 101 0.39530935883522034\n",
      "69 151 0.30258047580718994\n",
      "Validation loss: 0.5361736601556254 MAE: 122.44692\n",
      "70 30 0.46924012899398804\n",
      "70 80 0.39578676223754883\n",
      "70 130 0.28822508454322815\n",
      "Validation loss: 0.434063048042052 MAE: 99.12774\n",
      "71 9 0.43309247493743896\n",
      "71 59 0.37155190110206604\n",
      "71 109 0.4382854104042053\n",
      "71 159 0.28508853912353516\n",
      "Validation loss: 0.5408678598571242 MAE: 123.51896\n",
      "72 38 0.39798569679260254\n",
      "72 88 0.36473163962364197\n",
      "72 138 0.4337652027606964\n",
      "Validation loss: 0.5274593314232184 MAE: 120.456825\n",
      "73 17 0.46491754055023193\n",
      "73 67 0.5021499395370483\n",
      "73 117 0.5209383368492126\n",
      "73 167 0.3874231278896332\n",
      "Validation loss: 0.495011778254258 MAE: 113.046715\n",
      "74 46 0.2920650839805603\n",
      "74 96 0.5062622427940369\n",
      "74 146 0.2785061299800873\n",
      "Validation loss: 0.5852555761560362 MAE: 133.65587\n",
      "75 25 0.4462002217769623\n",
      "75 75 0.24104876816272736\n",
      "75 125 0.5074856877326965\n",
      "Validation loss: 0.6362697708676432 MAE: 145.30606\n",
      "76 4 0.35290148854255676\n",
      "76 54 0.33471882343292236\n",
      "76 104 0.24154189229011536\n",
      "76 154 0.4371113181114197\n",
      "Validation loss: 0.5531853956785816 MAE: 126.33194\n",
      "77 33 0.45582300424575806\n",
      "77 83 0.37324947118759155\n",
      "77 133 0.288389652967453\n",
      "Validation loss: 0.5709556616537752 MAE: 130.39015\n",
      "78 12 0.3467414081096649\n",
      "78 62 0.27492955327033997\n",
      "78 112 0.3508024513721466\n",
      "78 162 0.4656025767326355\n",
      "Validation loss: 0.5639207471183866 MAE: 128.78358\n",
      "79 41 0.6449147462844849\n",
      "79 91 0.34864771366119385\n",
      "79 141 0.26724785566329956\n",
      "Validation loss: 0.5057319495064473 MAE: 115.4949\n",
      "80 20 0.39893895387649536\n",
      "80 70 0.3491329550743103\n",
      "80 120 0.3061780035495758\n",
      "80 170 0.37895652651786804\n",
      "Validation loss: 0.5608174800872803 MAE: 128.07487\n",
      "81 49 0.49035221338272095\n",
      "81 99 0.28156760334968567\n",
      "81 149 0.32635822892189026\n",
      "Validation loss: 0.5085455158300567 MAE: 116.13745\n",
      "82 28 0.28979334235191345\n",
      "82 78 0.5077784657478333\n",
      "82 128 0.30061835050582886\n",
      "Validation loss: 0.4751231422898365 MAE: 108.504715\n",
      "83 7 0.36760401725769043\n",
      "83 57 0.34965378046035767\n",
      "83 107 0.4191342294216156\n",
      "83 157 0.31199920177459717\n",
      "Validation loss: 0.5925541537546972 MAE: 135.32265\n",
      "84 36 0.42338040471076965\n",
      "84 86 0.5116432309150696\n",
      "84 136 0.35554856061935425\n",
      "Validation loss: 0.5661547190961782 MAE: 129.29375\n",
      "85 15 0.4117976725101471\n",
      "85 65 0.22306285798549652\n",
      "85 115 0.3057667016983032\n",
      "85 165 0.4031012952327728\n",
      "Validation loss: 0.516441051374402 MAE: 117.94055\n",
      "86 44 0.23308059573173523\n",
      "86 94 0.26861903071403503\n",
      "86 144 0.33486396074295044\n",
      "Validation loss: 0.5817746476471772 MAE: 132.86092\n",
      "87 23 0.37122759222984314\n",
      "87 73 0.4795376658439636\n",
      "87 123 0.43119925260543823\n",
      "Validation loss: 0.5032910024910643 MAE: 114.937454\n",
      "88 2 0.2619468569755554\n",
      "88 52 0.431142657995224\n",
      "88 102 0.43512848019599915\n",
      "88 152 0.2365071177482605\n",
      "Validation loss: 0.5259241479182104 MAE: 120.106224\n",
      "89 31 0.3927759826183319\n",
      "89 81 0.22469018399715424\n",
      "89 131 0.3217008709907532\n",
      "Validation loss: 0.6212767840128893 MAE: 141.88208\n",
      "90 10 0.5052711367607117\n",
      "90 60 0.2753785252571106\n",
      "90 110 0.3641895651817322\n",
      "90 160 0.36665549874305725\n",
      "Validation loss: 0.44435191398475604 MAE: 101.47743\n",
      "91 39 0.3568725287914276\n",
      "91 89 0.30029523372650146\n",
      "91 139 0.520391583442688\n",
      "Validation loss: 0.6020655454250804 MAE: 137.49477\n",
      "92 18 0.3618720471858978\n",
      "92 68 0.42420583963394165\n",
      "92 118 0.2903997600078583\n",
      "92 168 0.3326748311519623\n",
      "Validation loss: 0.5410300925461172 MAE: 123.556\n",
      "93 47 0.36782771348953247\n",
      "93 97 0.35515159368515015\n",
      "93 147 0.3868655860424042\n",
      "Validation loss: 0.4691675127598277 MAE: 107.14461\n",
      "94 26 0.3686635196208954\n",
      "94 76 0.44151005148887634\n",
      "94 126 0.3155212998390198\n",
      "Validation loss: 0.7047519077334488 MAE: 160.94545\n",
      "95 5 0.3178243339061737\n",
      "95 55 0.2621102035045624\n",
      "95 105 0.5349606275558472\n",
      "95 155 0.28594642877578735\n",
      "Validation loss: 0.524658127137792 MAE: 119.817116\n",
      "96 34 0.25471240282058716\n",
      "96 84 0.3033094108104706\n",
      "96 134 0.15621910989284515\n",
      "Validation loss: 0.6323183042961255 MAE: 144.40366\n",
      "97 13 0.3661966323852539\n",
      "97 63 0.2782897651195526\n",
      "97 113 0.3274303674697876\n",
      "97 163 0.2991269826889038\n",
      "Validation loss: 0.48858536074036046 MAE: 111.57911\n",
      "98 42 0.3330693244934082\n",
      "98 92 0.34612852334976196\n",
      "98 142 0.22472836077213287\n",
      "Validation loss: 0.5281974833611159 MAE: 120.6254\n",
      "99 21 0.2832343280315399\n",
      "99 71 0.2563363313674927\n",
      "99 121 0.42071735858917236\n",
      "Validation loss: 0.4680480908232126 MAE: 106.88897\n",
      "100 0 0.3952692151069641\n",
      "100 50 0.2999311685562134\n",
      "100 100 0.3711394965648651\n",
      "100 150 0.33158424496650696\n",
      "Validation loss: 0.4407334261470371 MAE: 100.65108\n",
      "101 29 0.6030629277229309\n",
      "101 79 0.26141077280044556\n",
      "101 129 0.3756882846355438\n",
      "Validation loss: 0.513426149100588 MAE: 117.252045\n",
      "102 8 0.31012487411499023\n",
      "102 58 0.3709663152694702\n",
      "102 108 0.3171963691711426\n",
      "102 158 0.3212164640426636\n",
      "Validation loss: 0.586934937371148 MAE: 134.03938\n",
      "103 37 0.3627414405345917\n",
      "103 87 0.30976229906082153\n",
      "103 137 0.2632152736186981\n",
      "Validation loss: 0.48123359261897575 MAE: 109.90018\n",
      "104 16 0.39065462350845337\n",
      "104 66 0.2365545779466629\n",
      "104 116 0.2657281160354614\n",
      "104 166 0.26011019945144653\n",
      "Validation loss: 0.5062157649394364 MAE: 115.6054\n",
      "105 45 0.5809074640274048\n",
      "105 95 0.27223339676856995\n",
      "105 145 0.2673453986644745\n",
      "Validation loss: 0.6336035116722709 MAE: 144.69716\n",
      "106 24 0.3240891993045807\n",
      "106 74 0.387828528881073\n",
      "106 124 0.23903241753578186\n",
      "Validation loss: 0.4833539288643508 MAE: 110.3844\n",
      "107 3 0.3154037594795227\n",
      "107 53 0.31096261739730835\n",
      "107 103 0.2883913218975067\n",
      "107 153 0.44329068064689636\n",
      "Validation loss: 0.5216687147380316 MAE: 119.134415\n",
      "108 32 0.4289165735244751\n",
      "108 82 0.35254421830177307\n",
      "108 132 0.3299270570278168\n",
      "Validation loss: 0.5822272705055817 MAE: 132.96428\n",
      "109 11 0.3522491455078125\n",
      "109 61 0.4098431468009949\n",
      "109 111 0.3215177357196808\n",
      "109 161 0.29238593578338623\n",
      "Validation loss: 0.5524711082553306 MAE: 126.1688\n",
      "110 40 0.23558689653873444\n",
      "110 90 0.4228012263774872\n",
      "110 140 0.39844346046447754\n",
      "Validation loss: 0.5615522973021568 MAE: 128.2427\n",
      "111 19 0.38338154554367065\n",
      "111 69 0.41590216755867004\n",
      "111 119 0.3001318871974945\n",
      "111 169 0.2370501309633255\n",
      "Validation loss: 0.5090661566508444 MAE: 116.256325\n",
      "112 48 0.273834764957428\n",
      "112 98 0.24541808664798737\n",
      "112 148 0.4204978048801422\n",
      "Validation loss: 0.47781879302353886 MAE: 109.120316\n",
      "113 27 0.22998256981372833\n",
      "113 77 0.372042715549469\n",
      "113 127 0.49771928787231445\n",
      "Validation loss: 0.535869086346431 MAE: 122.377365\n",
      "114 6 0.4028569459915161\n",
      "114 56 0.3203861713409424\n",
      "114 106 0.2896535396575928\n",
      "114 156 0.3380180895328522\n",
      "Validation loss: 0.44774639048771553 MAE: 102.25265\n",
      "115 35 0.36675113439559937\n",
      "115 85 0.26050862669944763\n",
      "115 135 0.2248603105545044\n",
      "Validation loss: 0.6099801171592801 MAE: 139.30226\n",
      "116 14 0.47843751311302185\n",
      "116 64 0.24701827764511108\n",
      "116 114 0.3110799491405487\n",
      "116 164 0.2757888734340668\n",
      "Validation loss: 0.627593003169835 MAE: 143.32451\n",
      "117 43 0.36395347118377686\n",
      "117 93 0.29915347695350647\n",
      "117 143 0.2496296465396881\n",
      "Validation loss: 0.5659460327778644 MAE: 129.24611\n",
      "118 22 0.5116246342658997\n",
      "118 72 0.35136324167251587\n",
      "118 122 0.38084661960601807\n",
      "Validation loss: 0.6000448576888145 MAE: 137.03331\n",
      "119 1 0.33112645149230957\n",
      "119 51 0.3695456087589264\n",
      "119 101 0.2700662910938263\n",
      "119 151 0.35172906517982483\n",
      "Validation loss: 0.6208709771173042 MAE: 141.7894\n",
      "120 30 0.2916494905948639\n",
      "120 80 0.2657761573791504\n",
      "120 130 0.29542094469070435\n",
      "Validation loss: 0.5857152785474097 MAE: 133.76083\n",
      "121 9 0.3627735674381256\n",
      "121 59 0.3482261896133423\n",
      "121 109 0.27506017684936523\n",
      "121 159 0.2932470440864563\n",
      "Validation loss: 0.6106862687228019 MAE: 139.4635\n",
      "122 38 0.30208322405815125\n",
      "122 88 0.352349191904068\n",
      "122 138 0.4973115622997284\n",
      "Validation loss: 0.6587578016414977 MAE: 150.44168\n",
      "123 17 0.17931680381298065\n",
      "123 67 0.26400572061538696\n",
      "123 117 0.2869971990585327\n",
      "123 167 0.35230427980422974\n",
      "Validation loss: 0.5112061409922372 MAE: 116.74504\n",
      "124 46 0.39523860812187195\n",
      "124 96 0.3089413642883301\n",
      "124 146 0.3492067754268646\n",
      "Validation loss: 0.5227262349853738 MAE: 119.375916\n",
      "125 25 0.2948820888996124\n",
      "125 75 0.2786475718021393\n",
      "125 125 0.36688002943992615\n",
      "Validation loss: 0.6479595247765033 MAE: 147.97568\n",
      "126 4 0.24978028237819672\n",
      "126 54 0.36965203285217285\n",
      "126 104 0.4467036724090576\n",
      "126 154 0.3375188410282135\n",
      "Validation loss: 0.5858143798091955 MAE: 133.78346\n",
      "127 33 0.2547481954097748\n",
      "127 83 0.24595312774181366\n",
      "127 133 0.30226343870162964\n",
      "Validation loss: 0.5720756752797734 MAE: 130.64595\n",
      "128 12 0.3139568269252777\n",
      "128 62 0.3341454565525055\n",
      "128 112 0.3878052234649658\n",
      "128 162 0.3672347664833069\n",
      "Validation loss: 0.5505797183304503 MAE: 125.73686\n",
      "129 41 0.2864327132701874\n",
      "129 91 0.3275112807750702\n",
      "129 141 0.2743767499923706\n",
      "Validation loss: 0.5189728865846556 MAE: 118.51875\n",
      "130 20 0.3585808277130127\n",
      "130 70 0.35793980956077576\n",
      "130 120 0.353536456823349\n",
      "130 170 0.21199752390384674\n",
      "Validation loss: 0.5920873880386353 MAE: 135.21605\n",
      "131 49 0.2547621726989746\n",
      "131 99 0.3263493478298187\n",
      "131 149 0.4156505763530731\n",
      "Validation loss: 0.6355194268170853 MAE: 145.1347\n",
      "132 28 0.30258700251579285\n",
      "132 78 0.35331979393959045\n",
      "132 128 0.28572583198547363\n",
      "Validation loss: 0.628954333520075 MAE: 143.63542\n",
      "133 7 0.33689308166503906\n",
      "133 57 0.4202634394168854\n",
      "133 107 0.2230033427476883\n",
      "133 157 0.5101967453956604\n",
      "Validation loss: 0.5334440532483553 MAE: 121.823555\n",
      "134 36 0.2804314196109772\n",
      "134 86 0.22480475902557373\n",
      "134 136 0.2811691462993622\n",
      "Validation loss: 0.5610167704827604 MAE: 128.12039\n",
      "135 15 0.38476383686065674\n",
      "135 65 0.22353032231330872\n",
      "135 115 0.3870437741279602\n",
      "135 165 0.15131473541259766\n",
      "Validation loss: 0.5645603593329938 MAE: 128.92966\n",
      "136 44 0.40899065136909485\n",
      "136 94 0.31260842084884644\n",
      "136 144 0.33880630135536194\n",
      "Validation loss: 0.5732916070703875 MAE: 130.92363\n",
      "137 23 0.22739197313785553\n",
      "137 73 0.25610557198524475\n",
      "137 123 0.3085596561431885\n",
      "Validation loss: 0.5791493382370263 MAE: 132.26137\n",
      "138 2 0.2710017263889313\n",
      "138 52 0.3732641339302063\n",
      "138 102 0.29806581139564514\n",
      "138 152 0.3842499554157257\n",
      "Validation loss: 0.593403631135037 MAE: 135.51665\n",
      "139 31 0.26275911927223206\n",
      "139 81 0.17853674292564392\n",
      "139 131 0.21998532116413116\n",
      "Validation loss: 0.6271858082877265 MAE: 143.23154\n",
      "140 10 0.30573391914367676\n",
      "140 60 0.3011998236179352\n",
      "140 110 0.22127369046211243\n",
      "140 160 0.35855111479759216\n",
      "Validation loss: 0.6396481823502925 MAE: 146.0776\n",
      "141 39 0.24276012182235718\n",
      "141 89 0.24018900096416473\n",
      "141 139 0.34210139513015747\n",
      "Validation loss: 0.5587014238736783 MAE: 127.59165\n",
      "142 18 0.2632426619529724\n",
      "142 68 0.42124882340431213\n",
      "142 118 -0.1126706600189209\n",
      "142 168 -6.592979907989502\n",
      "Validation loss: 0.599115016167624 MAE: 136.82095\n",
      "143 47 -15.857969284057617\n",
      "143 97 -24.52952766418457\n",
      "143 147 -33.50630187988281\n",
      "Validation loss: 0.42846300274307964 MAE: 97.84887\n",
      "144 26 -36.53605651855469\n",
      "144 76 -44.14207458496094\n",
      "144 126 -54.295501708984375\n",
      "Validation loss: 0.46843667197645755 MAE: 106.97771\n",
      "145 5 -71.02974700927734\n",
      "145 55 -85.47911071777344\n",
      "145 105 -98.63134765625\n",
      "145 155 -103.65921783447266\n",
      "Validation loss: 0.5704515252196998 MAE: 130.27502\n",
      "146 34 -112.90587615966797\n",
      "146 84 -132.9869384765625\n",
      "146 134 -152.5962371826172\n",
      "Validation loss: 0.496981505239219 MAE: 113.49655\n",
      "147 13 -151.94131469726562\n",
      "147 63 -193.9114227294922\n",
      "147 113 -170.5592803955078\n",
      "147 163 -211.5021514892578\n",
      "Validation loss: 0.5080123083633289 MAE: 116.01567\n",
      "148 42 -219.79373168945312\n",
      "148 92 -223.10423278808594\n",
      "148 142 -254.6498260498047\n",
      "Validation loss: 0.46437244335113215 MAE: 106.049545\n",
      "149 21 -298.9889221191406\n",
      "149 71 -302.4946594238281\n",
      "149 121 -317.4281005859375\n",
      "Validation loss: 0.6040579575544213 MAE: 137.94978\n",
      "150 0 -349.82366943359375\n",
      "150 50 -359.72998046875\n",
      "150 100 -373.0193786621094\n",
      "150 150 -394.0834655761719\n",
      "Validation loss: 0.5759866181869953 MAE: 131.53908\n",
      "151 29 -407.15606689453125\n",
      "151 79 -494.9782409667969\n",
      "151 129 -492.18707275390625\n",
      "Validation loss: 0.5474711137208325 MAE: 125.02695\n",
      "152 8 -504.4583435058594\n",
      "152 58 -476.8590087890625\n",
      "152 108 -521.6162109375\n",
      "152 158 -584.2282104492188\n",
      "Validation loss: 0.5577321540542514 MAE: 127.37027\n",
      "153 37 -589.8322143554688\n",
      "153 87 -578.8446044921875\n",
      "153 137 -642.3922729492188\n",
      "Validation loss: 0.5880482461717393 MAE: 134.29362\n",
      "154 16 -710.9678955078125\n",
      "154 66 -681.7628784179688\n",
      "154 116 -696.9168090820312\n",
      "154 166 -788.4472045898438\n",
      "Validation loss: 0.5928338996151037 MAE: 135.38654\n",
      "155 45 -794.1934814453125\n",
      "155 95 -871.3959350585938\n",
      "155 145 -796.31689453125\n",
      "Validation loss: 0.6037341614215694 MAE: 137.87584\n",
      "156 24 -872.3868408203125\n",
      "156 74 -844.2922973632812\n",
      "156 124 -895.2525024414062\n",
      "Validation loss: 0.6353342438998976 MAE: 145.0924\n",
      "157 3 -902.0816650390625\n",
      "157 53 -1029.366943359375\n",
      "157 103 -1086.12548828125\n",
      "157 153 -1124.1904296875\n",
      "Validation loss: 0.6121862298912473 MAE: 139.80605\n",
      "158 32 -1233.9840087890625\n",
      "158 82 -1245.1605224609375\n",
      "158 132 -1176.6776123046875\n",
      "Validation loss: 0.5898738235060932 MAE: 134.71053\n",
      "159 11 -1238.2525634765625\n",
      "159 61 -1288.8946533203125\n",
      "159 111 -1330.7713623046875\n",
      "159 161 -1302.5155029296875\n",
      "Validation loss: 0.6056312399300915 MAE: 138.30907\n",
      "160 40 -1325.87939453125\n",
      "160 90 -1367.78125\n",
      "160 140 -1694.85791015625\n",
      "Validation loss: 0.6020162553466551 MAE: 137.48352\n",
      "161 19 -1455.535400390625\n",
      "161 69 -1578.7403564453125\n",
      "161 119 -1555.6781005859375\n",
      "161 169 -1455.8587646484375\n",
      "Validation loss: 0.6737361710671096 MAE: 153.8623\n",
      "162 48 -1682.098876953125\n",
      "162 98 -1652.0614013671875\n",
      "162 148 -1721.385009765625\n",
      "Validation loss: 0.7202382997462624 MAE: 164.48209\n",
      "163 27 -1758.669921875\n",
      "163 77 -1855.69775390625\n",
      "163 127 -1920.125732421875\n",
      "Validation loss: 0.7337603516745985 MAE: 167.57014\n",
      "164 6 -2041.304931640625\n",
      "164 56 -1852.460693359375\n",
      "164 106 -1987.368896484375\n",
      "164 156 -2090.653564453125\n",
      "Validation loss: 0.6979480507778145 MAE: 159.39163\n",
      "165 35 -2074.021240234375\n",
      "165 85 -2136.9599609375\n",
      "165 135 -2268.583251953125\n",
      "Validation loss: 0.6582741991818299 MAE: 150.33124\n",
      "166 14 -2396.10205078125\n",
      "166 64 -2346.202392578125\n",
      "166 114 -2483.28564453125\n",
      "166 164 -2629.642822265625\n",
      "Validation loss: 0.6242721380546079 MAE: 142.56612\n",
      "167 43 -2454.794189453125\n",
      "167 93 -2578.52001953125\n",
      "167 143 -2830.3486328125\n",
      "Validation loss: 0.6153194235082258 MAE: 140.52159\n",
      "168 22 -2572.9296875\n",
      "168 72 -2676.1796875\n",
      "168 122 -2594.4921875\n",
      "Validation loss: 0.712865528307463 MAE: 162.79836\n",
      "169 1 -2903.362548828125\n",
      "169 51 -2583.263671875\n",
      "169 101 -3073.67431640625\n",
      "169 151 -2843.777587890625\n",
      "Validation loss: 0.6384344059124327 MAE: 145.8004\n",
      "170 30 -3444.917236328125\n",
      "170 80 -3388.59619140625\n",
      "170 130 -3252.4111328125\n",
      "Validation loss: 0.6980279147276405 MAE: 159.40987\n",
      "171 9 -3292.197265625\n",
      "171 59 -3059.623046875\n",
      "171 109 -3374.899169921875\n",
      "171 159 -3612.557861328125\n",
      "Validation loss: 0.7440936098321836 MAE: 169.92998\n",
      "172 38 -3503.674560546875\n",
      "172 88 -3835.2919921875\n",
      "172 138 -3749.20849609375\n",
      "Validation loss: 0.6664952071089494 MAE: 152.2087\n",
      "173 17 -3936.10498046875\n",
      "173 67 -3648.89501953125\n",
      "173 117 -3905.830810546875\n",
      "173 167 -3960.27685546875\n",
      "Validation loss: 0.6630556869227984 MAE: 151.4232\n",
      "174 46 -4041.891845703125\n",
      "174 96 -4132.75439453125\n",
      "174 146 -4366.76953125\n",
      "Validation loss: 0.6318712136898822 MAE: 144.30154\n",
      "175 25 -4461.78369140625\n",
      "175 75 -4239.14892578125\n",
      "175 125 -4593.431640625\n",
      "Validation loss: 0.6587564948706599 MAE: 150.44139\n",
      "176 4 -4408.08154296875\n",
      "176 54 -4334.4267578125\n",
      "176 104 -4743.5048828125\n",
      "176 154 -4580.09716796875\n",
      "Validation loss: 0.6761927775472228 MAE: 154.42336\n",
      "177 33 -4930.322265625\n",
      "177 83 -5086.43017578125\n",
      "177 133 -5369.818359375\n",
      "Validation loss: 0.6579240417619895 MAE: 150.25128\n",
      "178 12 -4766.58154296875\n",
      "178 62 -5018.07373046875\n",
      "178 112 -5157.48095703125\n",
      "178 162 -5566.72265625\n",
      "Validation loss: 0.6891877281735515 MAE: 157.391\n",
      "179 41 -5321.37255859375\n",
      "179 91 -5431.7060546875\n",
      "179 141 -5782.462890625\n",
      "Validation loss: 0.7069062088665209 MAE: 161.43742\n",
      "180 20 -5836.21826171875\n",
      "180 70 -4930.306640625\n",
      "180 120 -5813.14990234375\n",
      "180 170 -5489.5654296875\n",
      "Validation loss: 0.6568635506936681 MAE: 150.0091\n",
      "181 49 -6495.7451171875\n",
      "181 99 -6030.86767578125\n",
      "181 149 -6255.56982421875\n",
      "Validation loss: 0.6846500143670199 MAE: 156.35474\n",
      "182 28 -6784.47705078125\n",
      "182 78 -6302.3251953125\n",
      "182 128 -5813.625\n",
      "Validation loss: 0.6873746399293866 MAE: 156.97696\n",
      "183 7 -6967.7275390625\n",
      "183 57 -6752.2353515625\n",
      "183 107 -6329.7685546875\n",
      "183 157 -6598.1484375\n",
      "Validation loss: 0.6827058868798596 MAE: 155.91075\n",
      "184 36 -7260.2529296875\n",
      "184 86 -6438.84033203125\n",
      "184 136 -6935.75634765625\n",
      "Validation loss: 0.6958135965971919 MAE: 158.90417\n",
      "185 15 -7174.02880859375\n",
      "185 65 -7943.6357421875\n",
      "185 115 -7489.12890625\n",
      "185 165 -7621.828125\n",
      "Validation loss: 0.6756189538721453 MAE: 154.2923\n",
      "186 44 -7890.96728515625\n",
      "186 94 -8105.42041015625\n",
      "186 144 -7883.91455078125\n",
      "Validation loss: 0.6321889988163061 MAE: 144.37411\n",
      "187 23 -8363.7392578125\n",
      "187 73 -8811.251953125\n",
      "187 123 -7972.8515625\n",
      "Validation loss: 0.6795844585574858 MAE: 155.1979\n",
      "188 2 -8318.412109375\n",
      "188 52 -8325.6630859375\n",
      "188 102 -8501.8515625\n",
      "188 152 -8623.240234375\n",
      "Validation loss: 0.6620670424567329 MAE: 151.19742\n",
      "189 31 -8823.294921875\n",
      "189 81 -9084.5244140625\n",
      "189 131 -8840.345703125\n",
      "Validation loss: 0.6766538801249008 MAE: 154.52864\n",
      "190 10 -9603.8017578125\n",
      "190 60 -9467.328125\n",
      "190 110 -8946.2060546875\n",
      "190 160 -9034.3212890625\n",
      "Validation loss: 0.6367184634794268 MAE: 145.40852\n",
      "191 39 -9825.7734375\n",
      "191 89 -9810.525390625\n",
      "191 139 -9755.814453125\n",
      "Validation loss: 0.7355152309289452 MAE: 167.97092\n",
      "192 18 -10716.662109375\n",
      "192 68 -9871.5244140625\n",
      "192 118 -9898.2861328125\n",
      "192 168 -10088.6591796875\n",
      "Validation loss: 0.7077646663314417 MAE: 161.63347\n",
      "193 47 -10012.048828125\n",
      "193 97 -10768.5400390625\n",
      "193 147 -11060.1591796875\n",
      "Validation loss: 0.6743383170568455 MAE: 153.99985\n",
      "194 26 -10229.0947265625\n",
      "194 76 -10619.078125\n",
      "194 126 -10010.6630859375\n",
      "Validation loss: 0.7465407269739965 MAE: 170.48883\n",
      "195 5 -11373.0126953125\n",
      "195 55 -11713.970703125\n",
      "195 105 -11640.7197265625\n",
      "195 155 -12069.1806640625\n",
      "Validation loss: 0.6674917636559023 MAE: 152.43628\n",
      "196 34 -12212.9501953125\n",
      "196 84 -12647.7216796875\n",
      "196 134 -11929.1279296875\n",
      "Validation loss: 0.7022305873402378 MAE: 160.36966\n",
      "197 13 -11362.701171875\n",
      "197 63 -12567.2353515625\n",
      "197 113 -12647.619140625\n",
      "197 163 -12446.0107421875\n",
      "Validation loss: 0.6920280881792481 MAE: 158.03967\n",
      "198 42 -12695.462890625\n",
      "198 92 -11831.4072265625\n",
      "198 142 -11042.1748046875\n",
      "Validation loss: 0.7271532384972823 MAE: 166.06126\n",
      "199 21 -12924.0732421875\n",
      "199 71 -13366.2138671875\n",
      "199 121 -12478.0859375\n",
      "Validation loss: 0.7481736418796562 MAE: 170.86172\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.33608870908596156 Test MAE: 76.75317\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'qm7', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 780, 'task': 'regression', 'data_path': 'data/qm7/qm7.csv', 'target': ['u0_atom']}}\n",
      "Running on: cuda:1\n",
      "6833\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/6833\n",
      "Generating scaffold 1000/6833\n",
      "Generating scaffold 2000/6833\n",
      "Generating scaffold 3000/6833\n",
      "Generating scaffold 4000/6833\n",
      "Generating scaffold 5000/6833\n",
      "Generating scaffold 6000/6833\n",
      "About to sort in scaffold sets\n",
      "tensor(-1553.3462) tensor(228.3718) torch.Size([5466, 1])\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 8.91563892364502\n",
      "0 50 2.8447189331054688\n",
      "0 100 1.9376500844955444\n",
      "0 150 1.6586852073669434\n",
      "Validation loss: 0.4711772576410171 MAE: 107.603584\n",
      "1 29 1.6764237880706787\n",
      "1 79 1.4074668884277344\n",
      "1 129 1.2680132389068604\n",
      "Validation loss: 0.5636826819843717 MAE: 128.72922\n",
      "2 8 1.083562970161438\n",
      "2 58 1.167574405670166\n",
      "2 108 1.17165207862854\n",
      "2 158 1.2111599445343018\n",
      "Validation loss: 0.48684045027571116 MAE: 111.18061\n",
      "3 37 0.9769989252090454\n",
      "3 87 1.0567426681518555\n",
      "3 137 0.9742313623428345\n",
      "Validation loss: 0.4120563910021419 MAE: 94.10204\n",
      "4 16 0.9876042604446411\n",
      "4 66 1.0931296348571777\n",
      "4 116 1.0203126668930054\n",
      "4 166 0.8534461855888367\n",
      "Validation loss: 0.44798984870924585 MAE: 102.30823\n",
      "5 45 0.7216640710830688\n",
      "5 95 0.9861752986907959\n",
      "5 145 0.5510296821594238\n",
      "Validation loss: 0.4704231361896671 MAE: 107.43136\n",
      "6 24 0.8683386445045471\n",
      "6 74 0.6605690717697144\n",
      "6 124 0.9708126187324524\n",
      "Validation loss: 0.4827288662829594 MAE: 110.24165\n",
      "7 3 0.7694640755653381\n",
      "7 53 0.5671814680099487\n",
      "7 103 0.8085744380950928\n",
      "7 153 0.7179935574531555\n",
      "Validation loss: 0.42072980585154035 MAE: 96.08281\n",
      "8 32 0.6405689716339111\n",
      "8 82 0.7739836573600769\n",
      "8 132 0.4957192838191986\n",
      "Validation loss: 0.4468498948024727 MAE: 102.047905\n",
      "9 11 0.49648892879486084\n",
      "9 61 0.6930863261222839\n",
      "9 111 0.41033586859703064\n",
      "9 161 0.7563635110855103\n",
      "Validation loss: 0.4395680716860364 MAE: 100.38493\n",
      "10 40 0.5890148282051086\n",
      "10 90 0.7341442704200745\n",
      "10 140 0.5319522619247437\n",
      "Validation loss: 0.4031207760175069 MAE: 92.0614\n",
      "11 19 0.5274895429611206\n",
      "11 69 0.7034686207771301\n",
      "11 119 0.5487637519836426\n",
      "11 169 0.5701456665992737\n",
      "Validation loss: 0.49861747932712935 MAE: 113.870155\n",
      "12 48 0.6202743649482727\n",
      "12 98 0.75978022813797\n",
      "12 148 0.47470900416374207\n",
      "Validation loss: 0.5062705203455095 MAE: 115.6179\n",
      "13 27 0.6206730008125305\n",
      "13 77 0.6011197566986084\n",
      "13 127 0.5223261117935181\n",
      "Validation loss: 0.43500272014684843 MAE: 99.34233\n",
      "14 6 0.43476414680480957\n",
      "14 56 0.5609990954399109\n",
      "14 106 0.48896822333335876\n",
      "14 156 0.5853421688079834\n",
      "Validation loss: 0.4645975042156309 MAE: 106.100945\n",
      "15 35 0.5964967608451843\n",
      "15 85 0.6428696513175964\n",
      "15 135 0.5419903993606567\n",
      "Validation loss: 0.4926142399771172 MAE: 112.49919\n",
      "16 14 0.6167581677436829\n",
      "16 64 0.39567098021507263\n",
      "16 114 0.5101092457771301\n",
      "16 164 0.3548855483531952\n",
      "Validation loss: 0.46860103527007746 MAE: 107.01525\n",
      "17 43 0.5022462606430054\n",
      "17 93 0.400443434715271\n",
      "17 143 0.33551061153411865\n",
      "Validation loss: 0.3979631894164615 MAE: 90.88355\n",
      "18 22 0.458503782749176\n",
      "18 72 0.4228484034538269\n",
      "18 122 0.5984724164009094\n",
      "Validation loss: 0.3888870927325466 MAE: 88.81083\n",
      "19 1 0.7233812808990479\n",
      "19 51 0.3988938331604004\n",
      "19 101 0.6611400246620178\n",
      "19 151 0.6920245885848999\n",
      "Validation loss: 0.4040160991295039 MAE: 92.26587\n",
      "20 30 0.45679453015327454\n",
      "20 80 0.5897899270057678\n",
      "20 130 0.4921659231185913\n",
      "Validation loss: 0.40220874373675786 MAE: 91.85312\n",
      "21 9 0.47363150119781494\n",
      "21 59 0.3780905604362488\n",
      "21 109 0.4777444005012512\n",
      "21 159 0.3879222869873047\n",
      "Validation loss: 0.4253002474879661 MAE: 97.126564\n",
      "22 38 0.4696789085865021\n",
      "22 88 0.6469443440437317\n",
      "22 138 0.7351289391517639\n",
      "Validation loss: 0.4610458795438733 MAE: 105.28986\n",
      "23 17 0.4870924651622772\n",
      "23 67 0.40259572863578796\n",
      "23 117 0.4486807584762573\n",
      "23 167 0.6970542669296265\n",
      "Validation loss: 0.4561001689810502 MAE: 104.16041\n",
      "24 46 0.6533504128456116\n",
      "24 96 0.5668110847473145\n",
      "24 146 0.4628770351409912\n",
      "Validation loss: 0.43501480490143535 MAE: 99.3451\n",
      "25 25 0.49125710129737854\n",
      "25 75 0.49225687980651855\n",
      "25 125 0.44677531719207764\n",
      "Validation loss: 0.40990559538902593 MAE: 93.61086\n",
      "26 4 0.5407063961029053\n",
      "26 54 0.34266397356987\n",
      "26 104 0.42042654752731323\n",
      "26 154 0.44464758038520813\n",
      "Validation loss: 0.4528782820841025 MAE: 103.424614\n",
      "27 33 0.713499128818512\n",
      "27 83 0.3996043801307678\n",
      "27 133 0.5103038549423218\n",
      "Validation loss: 0.41296329658631 MAE: 94.30916\n",
      "28 12 0.5163382291793823\n",
      "28 62 0.343567430973053\n",
      "28 112 0.4998842179775238\n",
      "28 162 0.4548300802707672\n",
      "Validation loss: 0.4170909621562177 MAE: 95.2518\n",
      "29 41 0.4600529968738556\n",
      "29 91 0.3229815661907196\n",
      "29 141 0.45479074120521545\n",
      "Validation loss: 0.4169864107293692 MAE: 95.22792\n",
      "30 20 0.3220284879207611\n",
      "30 70 0.6520141363143921\n",
      "30 120 0.47592008113861084\n",
      "30 170 0.24501633644104004\n",
      "Validation loss: 0.44590016572098984 MAE: 101.831\n",
      "31 49 0.48274293541908264\n",
      "31 99 0.3787999749183655\n",
      "31 149 0.5279923677444458\n",
      "Validation loss: 0.4032770928583647 MAE: 92.09711\n",
      "32 28 0.431196004152298\n",
      "32 78 0.5125107169151306\n",
      "32 128 0.3687901794910431\n",
      "Validation loss: 0.40762230335620414 MAE: 93.089424\n",
      "33 7 0.6329715847969055\n",
      "33 57 0.46210727095603943\n",
      "33 107 0.31624478101730347\n",
      "33 157 0.364490270614624\n",
      "Validation loss: 0.43372037431649996 MAE: 99.04948\n",
      "34 36 0.3353058993816376\n",
      "34 86 0.6313822865486145\n",
      "34 136 0.440573513507843\n",
      "Validation loss: 0.4228639695030904 MAE: 96.5702\n",
      "35 15 0.44342830777168274\n",
      "35 65 0.5700134634971619\n",
      "35 115 0.4197152554988861\n",
      "35 165 0.4536164402961731\n",
      "Validation loss: 0.4481749377752605 MAE: 102.3505\n",
      "36 44 0.5798882246017456\n",
      "36 94 0.3321533799171448\n",
      "36 144 0.45038872957229614\n",
      "Validation loss: 0.42316345164650365 MAE: 96.63858\n",
      "37 23 0.40236517786979675\n",
      "37 73 0.3500937521457672\n",
      "37 123 0.4416455030441284\n",
      "Validation loss: 0.4530906621475666 MAE: 103.473114\n",
      "38 2 0.28329741954803467\n",
      "38 52 0.5606779456138611\n",
      "38 102 0.45093095302581787\n",
      "38 152 0.3856915533542633\n",
      "Validation loss: 0.4246848779812194 MAE: 96.98603\n",
      "39 31 0.39402952790260315\n",
      "39 81 0.4584469199180603\n",
      "39 131 0.3861300051212311\n",
      "Validation loss: 0.4269050331840738 MAE: 97.49306\n",
      "40 10 0.3073025941848755\n",
      "40 60 0.34058892726898193\n",
      "40 110 0.5217499136924744\n",
      "40 160 0.5552985668182373\n",
      "Validation loss: 0.4291412188992863 MAE: 98.00374\n",
      "41 39 0.2744874954223633\n",
      "41 89 0.4370940327644348\n",
      "41 139 0.3667159676551819\n",
      "Validation loss: 0.5225006118852492 MAE: 119.32438\n",
      "42 18 0.5993010997772217\n",
      "42 68 0.43619081377983093\n",
      "42 118 0.3452838361263275\n",
      "42 168 0.4107351005077362\n",
      "Validation loss: 0.449452857525028 MAE: 102.64234\n",
      "43 47 0.33562275767326355\n",
      "43 97 0.42828842997550964\n",
      "43 147 0.49816685914993286\n",
      "Validation loss: 0.42556252883888823 MAE: 97.18647\n",
      "44 26 0.45184996724128723\n",
      "44 76 0.4450604021549225\n",
      "44 126 0.48287293314933777\n",
      "Validation loss: 0.49334517905586645 MAE: 112.666115\n",
      "45 5 0.5201430916786194\n",
      "45 55 0.5088719129562378\n",
      "45 105 0.4792819321155548\n",
      "45 155 0.6333214044570923\n",
      "Validation loss: 0.5016477348511679 MAE: 114.56218\n",
      "46 34 0.3428132236003876\n",
      "46 84 0.4545725882053375\n",
      "46 134 0.5438337326049805\n",
      "Validation loss: 0.45993030733532375 MAE: 105.0351\n",
      "47 13 0.39593997597694397\n",
      "47 63 0.39463427662849426\n",
      "47 113 0.3369753360748291\n",
      "47 163 0.37998440861701965\n",
      "Validation loss: 0.5944017180573871 MAE: 135.74457\n",
      "48 42 0.3617263436317444\n",
      "48 92 0.4187050759792328\n",
      "48 142 0.5463152527809143\n",
      "Validation loss: 0.45493802689669427 MAE: 103.89501\n",
      "49 21 0.5057535171508789\n",
      "49 71 0.4746590256690979\n",
      "49 121 0.30077269673347473\n",
      "Validation loss: 0.4524357906210492 MAE: 103.323555\n",
      "50 0 0.41609370708465576\n",
      "50 50 0.4235492944717407\n",
      "50 100 0.37776297330856323\n",
      "50 150 0.36961376667022705\n",
      "Validation loss: 0.4460847992994632 MAE: 101.87317\n",
      "51 29 0.33493420481681824\n",
      "51 79 0.4045298397541046\n",
      "51 129 0.47621816396713257\n",
      "Validation loss: 0.48152381077147366 MAE: 109.966446\n",
      "52 8 0.38513079285621643\n",
      "52 58 0.3972761034965515\n",
      "52 108 0.4558863639831543\n",
      "52 158 0.4988842308521271\n",
      "Validation loss: 0.5807477092882346 MAE: 132.62639\n",
      "53 37 0.47786757349967957\n",
      "53 87 0.3693590462207794\n",
      "53 137 0.49199068546295166\n",
      "Validation loss: 0.5152174962891473 MAE: 117.66114\n",
      "54 16 0.5736167430877686\n",
      "54 66 0.2511790096759796\n",
      "54 116 0.5226221084594727\n",
      "54 166 0.42281574010849\n",
      "Validation loss: 0.4721835611159341 MAE: 107.833405\n",
      "55 45 0.3727568984031677\n",
      "55 95 0.5099048614501953\n",
      "55 145 0.37549343705177307\n",
      "Validation loss: 0.5849939856612891 MAE: 133.59612\n",
      "56 24 0.38483378291130066\n",
      "56 74 0.4975695312023163\n",
      "56 124 0.317826509475708\n",
      "Validation loss: 0.4699436865354839 MAE: 107.32188\n",
      "57 3 0.30175644159317017\n",
      "57 53 0.4014419913291931\n",
      "57 103 0.3058655261993408\n",
      "57 153 0.49607935547828674\n",
      "Validation loss: 0.4854686012742115 MAE: 110.867325\n",
      "58 32 0.3583604395389557\n",
      "58 82 0.46034783124923706\n",
      "58 132 0.45074304938316345\n",
      "Validation loss: 0.5004203647200824 MAE: 114.28189\n",
      "59 11 0.36365774273872375\n",
      "59 61 0.27949297428131104\n",
      "59 111 0.5009365677833557\n",
      "59 161 0.37466245889663696\n",
      "Validation loss: 0.5688608104025411 MAE: 129.91176\n",
      "60 40 0.41810885071754456\n",
      "60 90 0.3874482810497284\n",
      "60 140 0.26468294858932495\n",
      "Validation loss: 0.5075745854461402 MAE: 115.91571\n",
      "61 19 0.27643829584121704\n",
      "61 69 0.2664494812488556\n",
      "61 119 0.36653396487236023\n",
      "61 169 0.24602073431015015\n",
      "Validation loss: 0.6095354783604716 MAE: 139.2007\n",
      "62 48 0.5371690988540649\n",
      "62 98 0.5195695161819458\n",
      "62 148 0.4266793727874756\n",
      "Validation loss: 0.48591733763092443 MAE: 110.9698\n",
      "63 27 0.5735267400741577\n",
      "63 77 0.4845483899116516\n",
      "63 127 0.3822489380836487\n",
      "Validation loss: 0.5128316832216162 MAE: 117.11629\n",
      "64 6 0.3181137442588806\n",
      "64 56 0.25361934304237366\n",
      "64 106 0.29416584968566895\n",
      "64 156 0.25869521498680115\n",
      "Validation loss: 0.5222650405607725 MAE: 119.270584\n",
      "65 35 0.3858746588230133\n",
      "65 85 0.3014974892139435\n",
      "65 135 0.3267539143562317\n",
      "Validation loss: 0.6668509478457489 MAE: 152.28993\n",
      "66 14 0.3661910593509674\n",
      "66 64 0.3618336617946625\n",
      "66 114 0.46766790747642517\n",
      "66 164 0.3340156376361847\n",
      "Validation loss: 0.4592884339784321 MAE: 104.88851\n",
      "67 43 0.5639368295669556\n",
      "67 93 0.36343061923980713\n",
      "67 143 0.33451226353645325\n",
      "Validation loss: 0.4319368895382909 MAE: 98.64219\n",
      "68 22 0.47853803634643555\n",
      "68 72 0.3168698847293854\n",
      "68 122 0.32721731066703796\n",
      "Validation loss: 0.4878156247891878 MAE: 111.40333\n",
      "69 1 0.24829724431037903\n",
      "69 51 0.3650180697441101\n",
      "69 101 0.34612876176834106\n",
      "69 151 0.4048970341682434\n",
      "Validation loss: 0.4921832077684458 MAE: 112.40074\n",
      "70 30 0.5159754753112793\n",
      "70 80 0.4132545292377472\n",
      "70 130 0.2692318558692932\n",
      "Validation loss: 0.4490178382536124 MAE: 102.543\n",
      "71 9 0.3843800723552704\n",
      "71 59 0.4207479655742645\n",
      "71 109 0.4810316562652588\n",
      "71 159 0.3376631736755371\n",
      "Validation loss: 0.5786431550282484 MAE: 132.14577\n",
      "72 38 0.3409595787525177\n",
      "72 88 0.28653937578201294\n",
      "72 138 0.38149651885032654\n",
      "Validation loss: 0.48345246161633765 MAE: 110.4069\n",
      "73 17 0.2374957948923111\n",
      "73 67 0.3744889497756958\n",
      "73 117 0.3817142844200134\n",
      "73 167 0.4643424153327942\n",
      "Validation loss: 0.7227293531797085 MAE: 165.05098\n",
      "74 46 0.3373270630836487\n",
      "74 96 0.417217493057251\n",
      "74 146 0.4868178367614746\n",
      "Validation loss: 0.5199528465494078 MAE: 118.74255\n",
      "75 25 0.3236180245876312\n",
      "75 75 0.35634952783584595\n",
      "75 125 0.347459614276886\n",
      "Validation loss: 0.41533872014597845 MAE: 94.85164\n",
      "76 4 0.5568777918815613\n",
      "76 54 0.4980230927467346\n",
      "76 104 0.20641550421714783\n",
      "76 154 0.3081454634666443\n",
      "Validation loss: 0.4986746813121595 MAE: 113.883224\n",
      "77 33 0.3886280059814453\n",
      "77 83 0.2889297902584076\n",
      "77 133 0.4166763424873352\n",
      "Validation loss: 0.7546082299355178 MAE: 172.33122\n",
      "78 12 0.18624064326286316\n",
      "78 62 0.3387598693370819\n",
      "78 112 0.2246265560388565\n",
      "78 162 0.3528466820716858\n",
      "Validation loss: 0.6171669806653296 MAE: 140.94351\n",
      "79 41 0.3594432473182678\n",
      "79 91 0.26826369762420654\n",
      "79 141 0.5104765892028809\n",
      "Validation loss: 0.5129053899419238 MAE: 117.13311\n",
      "80 20 0.3637953996658325\n",
      "80 70 0.36549854278564453\n",
      "80 120 0.3632213771343231\n",
      "80 170 0.42569342255592346\n",
      "Validation loss: 0.5803683114330671 MAE: 132.53973\n",
      "81 49 0.27291837334632874\n",
      "81 99 0.3909231722354889\n",
      "81 149 0.4247499108314514\n",
      "Validation loss: 0.4641309784866913 MAE: 105.994415\n",
      "82 28 0.24271012842655182\n",
      "82 78 0.36111539602279663\n",
      "82 128 0.4752033054828644\n",
      "Validation loss: 0.6022799510007714 MAE: 137.54375\n",
      "83 7 0.35439345240592957\n",
      "83 57 0.546415388584137\n",
      "83 107 0.2836247682571411\n",
      "83 157 0.5006862282752991\n",
      "Validation loss: 0.4414191136234685 MAE: 100.80768\n",
      "84 36 0.30287906527519226\n",
      "84 86 0.29383382201194763\n",
      "84 136 0.4842194616794586\n",
      "Validation loss: 0.5194279054800669 MAE: 118.62267\n",
      "85 15 0.37191084027290344\n",
      "85 65 0.38186022639274597\n",
      "85 115 0.3289002776145935\n",
      "85 165 0.30077242851257324\n",
      "Validation loss: 0.5302042964606257 MAE: 121.0837\n",
      "86 44 0.30895131826400757\n",
      "86 94 0.3965286314487457\n",
      "86 144 0.33194082975387573\n",
      "Validation loss: 0.47751665638204205 MAE: 109.05133\n",
      "87 23 0.33814412355422974\n",
      "87 73 0.3208533525466919\n",
      "87 123 0.3268200755119324\n",
      "Validation loss: 0.4934760886326171 MAE: 112.696\n",
      "88 2 0.2608574330806732\n",
      "88 52 0.3083784878253937\n",
      "88 102 0.3479757308959961\n",
      "88 152 0.27796971797943115\n",
      "Validation loss: 0.5273826986725567 MAE: 120.43933\n",
      "89 31 0.2895941436290741\n",
      "89 81 0.2738879919052124\n",
      "89 131 0.35763970017433167\n",
      "Validation loss: 0.49201214662072257 MAE: 112.36168\n",
      "90 10 0.39042142033576965\n",
      "90 60 0.26043903827667236\n",
      "90 110 0.2642449736595154\n",
      "90 160 0.31281596422195435\n",
      "Validation loss: 0.49872499530078374 MAE: 113.894714\n",
      "91 39 0.3112811744213104\n",
      "91 89 0.28273651003837585\n",
      "91 139 0.31501731276512146\n",
      "Validation loss: 0.5377863858178346 MAE: 122.81523\n",
      "92 18 0.319231778383255\n",
      "92 68 0.5145419836044312\n",
      "92 118 0.4669351577758789\n",
      "92 168 0.30593428015708923\n",
      "Validation loss: 0.45284123744880944 MAE: 103.41615\n",
      "93 47 0.3272021412849426\n",
      "93 97 0.30388909578323364\n",
      "93 147 0.44791001081466675\n",
      "Validation loss: 0.6605378249932451 MAE: 150.8482\n",
      "94 26 0.41515883803367615\n",
      "94 76 0.3714515268802643\n",
      "94 126 0.5321515202522278\n",
      "Validation loss: 0.42731484892772653 MAE: 97.58665\n",
      "95 5 0.4329676926136017\n",
      "95 55 0.19736672937870026\n",
      "95 105 0.33681395649909973\n",
      "95 155 0.17644160985946655\n",
      "Validation loss: 0.5112700777792791 MAE: 116.75965\n",
      "96 34 0.4598868191242218\n",
      "96 84 0.1866712123155594\n",
      "96 134 0.38988086581230164\n",
      "Validation loss: 0.5767068918685467 MAE: 131.70358\n",
      "97 13 0.4363708794116974\n",
      "97 63 0.533890962600708\n",
      "97 113 0.26517802476882935\n",
      "97 163 0.38604289293289185\n",
      "Validation loss: 0.5682425317708512 MAE: 129.77055\n",
      "98 42 0.32551056146621704\n",
      "98 92 0.3196239471435547\n",
      "98 142 0.2804194688796997\n",
      "Validation loss: 0.45621243938367967 MAE: 104.186035\n",
      "99 21 0.4893076419830322\n",
      "99 71 0.19692271947860718\n",
      "99 121 0.21654701232910156\n",
      "Validation loss: 0.5623148812188042 MAE: 128.41685\n",
      "100 0 0.27490663528442383\n",
      "100 50 0.3696225583553314\n",
      "100 100 0.3148152232170105\n",
      "100 150 0.43938905000686646\n",
      "Validation loss: 0.5295018090142144 MAE: 120.92327\n",
      "101 29 0.2406613528728485\n",
      "101 79 0.2576821744441986\n",
      "101 129 0.36955374479293823\n",
      "Validation loss: 0.5383377981464765 MAE: 122.941154\n",
      "102 8 0.21472103893756866\n",
      "102 58 0.3115280568599701\n",
      "102 108 0.2581106722354889\n",
      "102 158 0.34042346477508545\n",
      "Validation loss: 0.5369845485826682 MAE: 122.63212\n",
      "103 37 0.4126051068305969\n",
      "103 87 0.3154657185077667\n",
      "103 137 0.460098534822464\n",
      "Validation loss: 0.5084146170588265 MAE: 116.107544\n",
      "104 16 0.24714338779449463\n",
      "104 66 0.374355286359787\n",
      "104 116 0.3562987148761749\n",
      "104 166 0.39195552468299866\n",
      "Validation loss: 0.4317526758065698 MAE: 98.60012\n",
      "105 45 0.5399176478385925\n",
      "105 95 0.4005517065525055\n",
      "105 145 0.4048057198524475\n",
      "Validation loss: 0.6371134024614479 MAE: 145.49872\n",
      "106 24 0.28478261828422546\n",
      "106 74 0.21013551950454712\n",
      "106 124 0.2872951328754425\n",
      "Validation loss: 0.4852035889151501 MAE: 110.80681\n",
      "107 3 0.45343446731567383\n",
      "107 53 0.3803596496582031\n",
      "107 103 0.23338396847248077\n",
      "107 153 0.32251518964767456\n",
      "Validation loss: 0.49238103523589016 MAE: 112.44593\n",
      "108 32 0.38295626640319824\n",
      "108 82 0.5084629654884338\n",
      "108 132 0.2880220413208008\n",
      "Validation loss: 0.4653811107950601 MAE: 106.2799\n",
      "109 11 0.424302875995636\n",
      "109 61 0.29801145195961\n",
      "109 111 0.45156827569007874\n",
      "109 161 0.27516865730285645\n",
      "Validation loss: 0.6982133883481835 MAE: 159.45224\n",
      "110 40 0.25214728713035583\n",
      "110 90 0.25703296065330505\n",
      "110 140 0.4118365943431854\n",
      "Validation loss: 0.5169454443524455 MAE: 118.05575\n",
      "111 19 0.4330742359161377\n",
      "111 69 0.3616914451122284\n",
      "111 119 0.3807792663574219\n",
      "111 169 0.3267922103404999\n",
      "Validation loss: 0.40508311063225505 MAE: 92.50955\n",
      "112 48 0.24618956446647644\n",
      "112 98 0.3412914276123047\n",
      "112 148 0.2799958288669586\n",
      "Validation loss: 0.5172051980830076 MAE: 118.11507\n",
      "113 27 0.44586706161499023\n",
      "113 77 0.2964455187320709\n",
      "113 127 0.2519039511680603\n",
      "Validation loss: 0.6077484108551204 MAE: 138.79259\n",
      "114 6 0.48957452178001404\n",
      "114 56 0.29136067628860474\n",
      "114 106 0.2790220081806183\n",
      "114 156 0.46915972232818604\n",
      "Validation loss: 0.5013545253123456 MAE: 114.495224\n",
      "115 35 0.3113652467727661\n",
      "115 85 0.4405291676521301\n",
      "115 135 0.251242995262146\n",
      "Validation loss: 0.5019835062891419 MAE: 114.63886\n",
      "116 14 0.4416293501853943\n",
      "116 64 0.32197949290275574\n",
      "116 114 0.48149198293685913\n",
      "116 164 0.3431920111179352\n",
      "Validation loss: 0.6898015472624037 MAE: 157.5312\n",
      "117 43 0.25333383679389954\n",
      "117 93 0.37279173731803894\n",
      "117 143 0.35984519124031067\n",
      "Validation loss: 0.5960401547582526 MAE: 136.11874\n",
      "118 22 0.4569028913974762\n",
      "118 72 0.18118397891521454\n",
      "118 122 0.437227338552475\n",
      "Validation loss: 0.5858878148229498 MAE: 133.80023\n",
      "119 1 0.31760549545288086\n",
      "119 51 0.25691747665405273\n",
      "119 101 0.2949160635471344\n",
      "119 151 0.5406869649887085\n",
      "Validation loss: 0.7261027791346722 MAE: 165.82138\n",
      "120 30 0.3208802342414856\n",
      "120 80 0.26284557580947876\n",
      "120 130 0.3740684390068054\n",
      "Validation loss: 0.5238090767497905 MAE: 119.62321\n",
      "121 9 0.2515845000743866\n",
      "121 59 0.37069129943847656\n",
      "121 109 0.416556715965271\n",
      "121 159 0.2899245321750641\n",
      "Validation loss: 0.7566875916475441 MAE: 172.8061\n",
      "122 38 0.29277658462524414\n",
      "122 88 0.29325273633003235\n",
      "122 138 0.328288733959198\n",
      "Validation loss: 0.5294254899722094 MAE: 120.90584\n",
      "123 17 0.18428905308246613\n",
      "123 67 0.22804297506809235\n",
      "123 117 0.21143989264965057\n",
      "123 167 0.2581535279750824\n",
      "Validation loss: 0.4939571517949913 MAE: 112.80588\n",
      "124 46 0.33521100878715515\n",
      "124 96 0.5147348046302795\n",
      "124 146 0.29158687591552734\n",
      "Validation loss: 0.5343135895087705 MAE: 122.02213\n",
      "125 25 0.3244052827358246\n",
      "125 75 0.4376956522464752\n",
      "125 125 0.2960236072540283\n",
      "Validation loss: 0.5016467236635977 MAE: 114.56195\n",
      "126 4 0.31181102991104126\n",
      "126 54 0.5209290981292725\n",
      "126 104 0.41549691557884216\n",
      "126 154 0.4011477828025818\n",
      "Validation loss: 0.7235326327775654 MAE: 165.23444\n",
      "127 33 0.3604564666748047\n",
      "127 83 0.3544313311576843\n",
      "127 133 0.27108246088027954\n",
      "Validation loss: 0.5568443062709786 MAE: 127.16751\n",
      "128 12 0.41297832131385803\n",
      "128 62 0.2393454611301422\n",
      "128 112 0.5338987112045288\n",
      "128 162 0.4259834289550781\n",
      "Validation loss: 0.5022934751901013 MAE: 114.70965\n",
      "129 41 0.26407915353775024\n",
      "129 91 0.2153511941432953\n",
      "129 141 0.2541659474372864\n",
      "Validation loss: 0.6101111630250139 MAE: 139.33217\n",
      "130 20 0.2750355005264282\n",
      "130 70 0.27067703008651733\n",
      "130 120 0.3776586949825287\n",
      "130 170 0.4723036289215088\n",
      "Validation loss: 0.580792961064835 MAE: 132.63672\n",
      "131 49 0.532739520072937\n",
      "131 99 0.3197498619556427\n",
      "131 149 0.2777238190174103\n",
      "Validation loss: 0.5044091209682108 MAE: 115.19281\n",
      "132 28 0.46355336904525757\n",
      "132 78 0.277812659740448\n",
      "132 128 0.4704790413379669\n",
      "Validation loss: 0.6362357021075243 MAE: 145.29826\n",
      "133 7 0.28001609444618225\n",
      "133 57 0.4645731449127197\n",
      "133 107 0.42245247960090637\n",
      "133 157 0.2387055903673172\n",
      "Validation loss: 0.6045901865987052 MAE: 138.07133\n",
      "134 36 0.20400525629520416\n",
      "134 86 0.4546563923358917\n",
      "134 136 0.33757174015045166\n",
      "Validation loss: 0.6462631563694157 MAE: 147.58827\n",
      "135 15 0.49717000126838684\n",
      "135 65 0.2674664258956909\n",
      "135 115 0.2972117066383362\n",
      "135 165 0.25153648853302\n",
      "Validation loss: 0.48569913949185645 MAE: 110.919975\n",
      "136 44 0.35197147727012634\n",
      "136 94 0.4370812773704529\n",
      "136 144 0.4700655937194824\n",
      "Validation loss: 0.7758317432905498 MAE: 177.17807\n",
      "137 23 0.3574748635292053\n",
      "137 73 0.23264151811599731\n",
      "137 123 0.31125393509864807\n",
      "Validation loss: 0.5513486809897841 MAE: 125.912476\n",
      "138 2 0.4174758493900299\n",
      "138 52 0.3870217800140381\n",
      "138 102 0.3349204957485199\n",
      "138 152 0.29693499207496643\n",
      "Validation loss: 0.516555444887507 MAE: 117.966675\n",
      "139 31 0.32196664810180664\n",
      "139 81 0.3976448178291321\n",
      "139 131 0.26418188214302063\n",
      "Validation loss: 0.6255747177447492 MAE: 142.8636\n",
      "140 10 0.35140085220336914\n",
      "140 60 0.31215566396713257\n",
      "140 110 0.4120958149433136\n",
      "140 160 0.3709794282913208\n",
      "Validation loss: 0.5301862536815175 MAE: 121.07957\n",
      "141 39 0.38387182354927063\n",
      "141 89 0.24954965710639954\n",
      "141 139 0.18143174052238464\n",
      "Validation loss: 0.5964027929027178 MAE: 136.20157\n",
      "142 18 0.31658175587654114\n",
      "142 68 0.2940935790538788\n",
      "142 118 0.34841322898864746\n",
      "142 168 0.2162790596485138\n",
      "Validation loss: 0.5428512730793646 MAE: 123.9719\n",
      "143 47 0.3898927569389343\n",
      "143 97 0.17695696651935577\n",
      "143 147 -0.10464033484458923\n",
      "Validation loss: 0.6127294169531928 MAE: 139.93011\n",
      "144 26 -8.280895233154297\n",
      "144 76 -15.422379493713379\n",
      "144 126 -24.095714569091797\n",
      "Validation loss: 0.5414838926833972 MAE: 123.65963\n",
      "145 5 -29.962995529174805\n",
      "145 55 -42.97892379760742\n",
      "145 105 -49.913421630859375\n",
      "145 155 -61.773258209228516\n",
      "Validation loss: 0.6282066451875787 MAE: 143.46466\n",
      "146 34 -73.53516387939453\n",
      "146 84 -93.91625213623047\n",
      "146 134 -103.73052215576172\n",
      "Validation loss: 0.536797585194571 MAE: 122.58941\n",
      "147 13 -106.30522155761719\n",
      "147 63 -121.08517456054688\n",
      "147 113 -146.14825439453125\n",
      "147 163 -161.8927001953125\n",
      "Validation loss: 0.5030617591930412 MAE: 114.88509\n",
      "148 42 -151.39059448242188\n",
      "148 92 -204.33824157714844\n",
      "148 142 -192.83724975585938\n",
      "Validation loss: 0.5208510732093052 MAE: 118.94768\n",
      "149 21 -235.8190155029297\n",
      "149 71 -250.59805297851562\n",
      "149 121 -237.2213134765625\n",
      "Validation loss: 0.5661308936208312 MAE: 129.28831\n",
      "150 0 -301.5463562011719\n",
      "150 50 -304.1594543457031\n",
      "150 100 -346.24591064453125\n",
      "150 150 -310.1614685058594\n",
      "Validation loss: 0.5154965132997748 MAE: 117.72486\n",
      "151 29 -357.52911376953125\n",
      "151 79 -377.57073974609375\n",
      "151 129 -381.2943115234375\n",
      "Validation loss: 0.5456336492683456 MAE: 124.60732\n",
      "152 8 -419.7320861816406\n",
      "152 58 -404.15643310546875\n",
      "152 108 -426.8699645996094\n",
      "152 158 -467.9117736816406\n",
      "Validation loss: 0.5652551542945773 MAE: 129.08832\n",
      "153 37 -508.6859436035156\n",
      "153 87 -563.1692504882812\n",
      "153 137 -496.0910949707031\n",
      "Validation loss: 0.5640644626310695 MAE: 128.81639\n",
      "154 16 -606.1984252929688\n",
      "154 66 -585.6807250976562\n",
      "154 116 -607.36962890625\n",
      "154 166 -658.8050537109375\n",
      "Validation loss: 0.587579515942356 MAE: 134.18657\n",
      "155 45 -619.0960693359375\n",
      "155 95 -756.9264526367188\n",
      "155 145 -832.0016479492188\n",
      "Validation loss: 0.6341748004071197 MAE: 144.82762\n",
      "156 24 -686.4823608398438\n",
      "156 74 -798.3673095703125\n",
      "156 124 -803.7160034179688\n",
      "Validation loss: 0.5905692974726359 MAE: 134.86935\n",
      "157 3 -857.0426635742188\n",
      "157 53 -840.4180908203125\n",
      "157 103 -930.89013671875\n",
      "157 153 -1005.7492065429688\n",
      "Validation loss: 0.6227175089699483 MAE: 142.21109\n",
      "158 32 -1096.8756103515625\n",
      "158 82 -1056.862548828125\n",
      "158 132 -1158.603271484375\n",
      "Validation loss: 0.6133713736171611 MAE: 140.0767\n",
      "159 11 -1122.240234375\n",
      "159 61 -1143.8260498046875\n",
      "159 111 -1028.02587890625\n",
      "159 161 -1173.1778564453125\n",
      "Validation loss: 0.6362256292711225 MAE: 145.29599\n",
      "160 40 -1327.93994140625\n",
      "160 90 -1274.5076904296875\n",
      "160 140 -1298.5184326171875\n",
      "Validation loss: 0.5966521749022411 MAE: 136.25851\n",
      "161 19 -1412.822265625\n",
      "161 69 -1443.9122314453125\n",
      "161 119 -1353.910400390625\n",
      "161 169 -1580.26611328125\n",
      "Validation loss: 0.5826059560678158 MAE: 133.05077\n",
      "162 48 -1444.5693359375\n",
      "162 98 -1698.8768310546875\n",
      "162 148 -1559.0809326171875\n",
      "Validation loss: 0.6133878126479032 MAE: 140.08046\n",
      "163 27 -1535.115478515625\n",
      "163 77 -1670.49169921875\n",
      "163 127 -1581.93212890625\n",
      "Validation loss: 0.6624277331675702 MAE: 151.27979\n",
      "164 6 -1798.3536376953125\n",
      "164 56 -2053.56396484375\n",
      "164 106 -1846.05615234375\n",
      "164 156 -1936.8878173828125\n",
      "Validation loss: 0.667039468274479 MAE: 152.333\n",
      "165 35 -1918.9942626953125\n",
      "165 85 -1953.9090576171875\n",
      "165 135 -2085.372802734375\n",
      "Validation loss: 0.6670065720876058 MAE: 152.32547\n",
      "166 14 -2105.421630859375\n",
      "166 64 -2045.95556640625\n",
      "166 114 -2381.84814453125\n",
      "166 164 -2510.927001953125\n",
      "Validation loss: 0.6489148558231822 MAE: 148.19383\n",
      "167 43 -2364.210205078125\n",
      "167 93 -2339.14794921875\n",
      "167 143 -2494.388427734375\n",
      "Validation loss: 0.6550788607513696 MAE: 149.60152\n",
      "168 22 -2392.270751953125\n",
      "168 72 -2682.12060546875\n",
      "168 122 -2580.03076171875\n",
      "Validation loss: 0.659267250557392 MAE: 150.55803\n",
      "169 1 -2709.0625\n",
      "169 51 -2713.902587890625\n",
      "169 101 -2749.96533203125\n",
      "169 151 -2933.5087890625\n",
      "Validation loss: 0.6483537638396547 MAE: 148.0657\n",
      "170 30 -3083.282958984375\n",
      "170 80 -2917.781005859375\n",
      "170 130 -3013.63720703125\n",
      "Validation loss: 0.6257067730552272 MAE: 142.89375\n",
      "171 9 -3154.36328125\n",
      "171 59 -3134.46044921875\n",
      "171 109 -3370.073974609375\n",
      "171 159 -3395.3466796875\n",
      "Validation loss: 0.7164906733914426 MAE: 163.62624\n",
      "172 38 -3599.44677734375\n",
      "172 88 -3464.222412109375\n",
      "172 138 -3399.7236328125\n",
      "Validation loss: 0.6051020360829538 MAE: 138.18822\n",
      "173 17 -3694.205078125\n",
      "173 67 -3425.6279296875\n",
      "173 117 -3763.167724609375\n",
      "173 167 -3782.62939453125\n",
      "Validation loss: 0.6133065129581251 MAE: 140.06189\n",
      "174 46 -3818.82470703125\n",
      "174 96 -4088.100830078125\n",
      "174 146 -3769.2333984375\n",
      "Validation loss: 0.6514088257014403 MAE: 148.76338\n",
      "175 25 -3588.06689453125\n",
      "175 75 -4065.947265625\n",
      "175 125 -4295.4189453125\n",
      "Validation loss: 0.642078611585829 MAE: 146.63263\n",
      "176 4 -4676.97314453125\n",
      "176 54 -4022.196044921875\n",
      "176 104 -4316.3095703125\n",
      "176 154 -3969.314208984375\n",
      "Validation loss: 0.6383587358987819 MAE: 145.78313\n",
      "177 33 -4202.1181640625\n",
      "177 83 -4787.19384765625\n",
      "177 133 -4760.40576171875\n",
      "Validation loss: 0.6732674460662039 MAE: 153.75528\n",
      "178 12 -4589.86328125\n",
      "178 62 -4225.46533203125\n",
      "178 112 -4604.83935546875\n",
      "178 162 -5028.15185546875\n",
      "Validation loss: 0.6105223749464715 MAE: 139.42607\n",
      "179 41 -5411.21240234375\n",
      "179 91 -5118.431640625\n",
      "179 141 -5321.80615234375\n",
      "Validation loss: 0.671216542957819 MAE: 153.28691\n",
      "180 20 -4760.388671875\n",
      "180 70 -5108.68603515625\n",
      "180 120 -4981.34033203125\n",
      "180 170 -5101.53369140625\n",
      "Validation loss: 0.6403517918279994 MAE: 146.23828\n",
      "181 49 -5564.5263671875\n",
      "181 99 -6039.79736328125\n",
      "181 149 -5350.9716796875\n",
      "Validation loss: 0.7362704674402872 MAE: 168.14339\n",
      "182 28 -5863.43701171875\n",
      "182 78 -6230.77880859375\n",
      "182 128 -6603.73583984375\n",
      "Validation loss: 0.6830293832466616 MAE: 155.98462\n",
      "183 7 -5928.005859375\n",
      "183 57 -6482.10302734375\n",
      "183 107 -6485.2841796875\n",
      "183 157 -6791.23779296875\n",
      "Validation loss: 0.6928586158138966 MAE: 158.22935\n",
      "184 36 -6275.92724609375\n",
      "184 86 -7148.74609375\n",
      "184 136 -7284.49951171875\n",
      "Validation loss: 0.6710823559970186 MAE: 153.25627\n",
      "185 15 -6829.466796875\n",
      "185 65 -6895.3125\n",
      "185 115 -6981.49755859375\n",
      "185 165 -7299.68310546875\n",
      "Validation loss: 0.7019227122702794 MAE: 160.29935\n",
      "186 44 -7236.27490234375\n",
      "186 94 -7738.8134765625\n",
      "186 144 -7504.1669921875\n",
      "Validation loss: 0.6778788040255943 MAE: 154.80838\n",
      "187 23 -7417.00048828125\n",
      "187 73 -8464.177734375\n",
      "187 123 -7827.31640625\n",
      "Validation loss: 0.7317109763273719 MAE: 167.10213\n",
      "188 2 -7960.1005859375\n",
      "188 52 -7921.5751953125\n",
      "188 102 -7692.56298828125\n",
      "188 152 -8305.7666015625\n",
      "Validation loss: 0.6867391610006143 MAE: 156.83185\n",
      "189 31 -7918.482421875\n",
      "189 81 -8677.568359375\n",
      "189 131 -8297.6240234375\n",
      "Validation loss: 0.6431166512227198 MAE: 146.86969\n",
      "190 10 -9239.1552734375\n",
      "190 60 -8494.3818359375\n",
      "190 110 -8603.185546875\n",
      "190 160 -9127.9775390625\n",
      "Validation loss: 0.6888648173962421 MAE: 157.31728\n",
      "191 39 -9344.87109375\n",
      "191 89 -9800.845703125\n",
      "191 139 -10315.693359375\n",
      "Validation loss: 0.6940592021970023 MAE: 158.50352\n",
      "192 18 -9806.494140625\n",
      "192 68 -10385.373046875\n",
      "192 118 -10006.619140625\n",
      "192 168 -10395.853515625\n",
      "Validation loss: 0.6825975259842231 MAE: 155.88602\n",
      "193 47 -10289.412109375\n",
      "193 97 -10305.4765625\n",
      "193 147 -11056.431640625\n",
      "Validation loss: 0.7191839207682693 MAE: 164.2413\n",
      "194 26 -10664.66015625\n",
      "194 76 -10246.203125\n",
      "194 126 -9965.0185546875\n",
      "Validation loss: 0.7353694543503878 MAE: 167.93762\n",
      "195 5 -10615.9462890625\n",
      "195 55 -11256.8603515625\n",
      "195 105 -11482.9384765625\n",
      "195 155 -11803.603515625\n",
      "Validation loss: 0.7557288122455976 MAE: 172.58713\n",
      "196 34 -11889.1259765625\n",
      "196 84 -11940.1015625\n",
      "196 134 -11081.2119140625\n",
      "Validation loss: 0.7166737039186801 MAE: 163.66805\n",
      "197 13 -13003.2734375\n",
      "197 63 -11406.134765625\n",
      "197 113 -11855.3662109375\n",
      "197 163 -11792.673828125\n",
      "Validation loss: 0.7180522509485657 MAE: 163.98286\n",
      "198 42 -12782.2529296875\n",
      "198 92 -12884.25390625\n",
      "198 142 -11914.939453125\n",
      "Validation loss: 0.6900500205525181 MAE: 157.58795\n",
      "199 21 -14021.0869140625\n",
      "199 71 -12488.5908203125\n",
      "199 121 -12700.8515625\n",
      "Validation loss: 0.705846393317507 MAE: 161.19539\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.3201410511664032 Test MAE: 73.111176\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'qm7', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'regression', 'data_path': 'data/qm7/qm7.csv', 'target': ['u0_atom']}}\n",
      "Running on: cuda:1\n",
      "6833\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/6833\n",
      "Generating scaffold 1000/6833\n",
      "Generating scaffold 2000/6833\n",
      "Generating scaffold 3000/6833\n",
      "Generating scaffold 4000/6833\n",
      "Generating scaffold 5000/6833\n",
      "Generating scaffold 6000/6833\n",
      "About to sort in scaffold sets\n",
      "tensor(-1553.3463) tensor(228.3718) torch.Size([5466, 1])\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 8.499809265136719\n",
      "0 50 2.7327818870544434\n",
      "0 100 1.8839699029922485\n",
      "0 150 1.6129155158996582\n",
      "Validation loss: 0.4153600017926846 MAE: 94.8565\n",
      "1 29 1.4159486293792725\n",
      "1 79 1.5754823684692383\n",
      "1 129 1.2999441623687744\n",
      "Validation loss: 0.45266720914004144 MAE: 103.37642\n",
      "2 8 1.1362489461898804\n",
      "2 58 1.0029704570770264\n",
      "2 108 1.007258415222168\n",
      "2 158 1.1850135326385498\n",
      "Validation loss: 0.9693491549519767 MAE: 221.37198\n",
      "3 37 0.883315920829773\n",
      "3 87 0.8610580563545227\n",
      "3 137 0.9871797561645508\n",
      "Validation loss: 0.4805806819458454 MAE: 109.751076\n",
      "4 16 1.2093782424926758\n",
      "4 66 0.9574283361434937\n",
      "4 116 0.7990788221359253\n",
      "4 166 0.6272648572921753\n",
      "Validation loss: 0.4387917215364021 MAE: 100.20765\n",
      "5 45 0.7474008798599243\n",
      "5 95 0.7965765595436096\n",
      "5 145 0.9696202278137207\n",
      "Validation loss: 0.48997831170321904 MAE: 111.89722\n",
      "6 24 0.8914209604263306\n",
      "6 74 0.7769304513931274\n",
      "6 124 0.8079913854598999\n",
      "Validation loss: 0.5625432187702224 MAE: 128.469\n",
      "7 3 0.5695334076881409\n",
      "7 53 0.7346735000610352\n",
      "7 103 0.7574578523635864\n",
      "7 153 0.6807520389556885\n",
      "Validation loss: 0.5987892262419762 MAE: 136.74655\n",
      "8 32 0.6545515060424805\n",
      "8 82 0.7415269613265991\n",
      "8 132 0.7941715717315674\n",
      "Validation loss: 0.5523440126787152 MAE: 126.13978\n",
      "9 11 0.5268726944923401\n",
      "9 61 0.7807979583740234\n",
      "9 111 0.5989245772361755\n",
      "9 161 0.4664387106895447\n",
      "Validation loss: 0.4477823857675519 MAE: 102.26085\n",
      "10 40 0.5795724987983704\n",
      "10 90 0.8238203525543213\n",
      "10 140 0.5548820495605469\n",
      "Validation loss: 0.41466664884522647 MAE: 94.69816\n",
      "11 19 0.8529767990112305\n",
      "11 69 0.7187089920043945\n",
      "11 119 0.6357223987579346\n",
      "11 169 0.7070934176445007\n",
      "Validation loss: 0.45231604506397804 MAE: 103.29621\n",
      "12 48 0.6233583092689514\n",
      "12 98 0.5401769876480103\n",
      "12 148 0.5085816979408264\n",
      "Validation loss: 0.3948697344950068 MAE: 90.17709\n",
      "13 27 0.6008496880531311\n",
      "13 77 0.7131874561309814\n",
      "13 127 0.6171243190765381\n",
      "Validation loss: 0.4276951927887766 MAE: 97.6735\n",
      "14 6 0.5693879723548889\n",
      "14 56 0.5548092126846313\n",
      "14 106 0.4549661874771118\n",
      "14 156 0.46878236532211304\n",
      "Validation loss: 0.4057195221471508 MAE: 92.65489\n",
      "15 35 0.6627994775772095\n",
      "15 85 0.5669746398925781\n",
      "15 135 0.46398404240608215\n",
      "Validation loss: 0.43414276428738535 MAE: 99.14595\n",
      "16 14 0.5924393534660339\n",
      "16 64 0.6434922814369202\n",
      "16 114 0.5496969223022461\n",
      "16 164 0.5178682804107666\n",
      "Validation loss: 0.4175121916664971 MAE: 95.347984\n",
      "17 43 0.5383119583129883\n",
      "17 93 0.6301372051239014\n",
      "17 143 0.6893435716629028\n",
      "Validation loss: 0.4159636413841917 MAE: 94.99435\n",
      "18 22 0.4708796739578247\n",
      "18 72 0.5056970715522766\n",
      "18 122 0.5008322596549988\n",
      "Validation loss: 0.3958816158841228 MAE: 90.40818\n",
      "19 1 0.38148197531700134\n",
      "19 51 0.43220579624176025\n",
      "19 101 0.6088178157806396\n",
      "19 151 0.6349356770515442\n",
      "Validation loss: 0.4588358900700396 MAE: 104.78516\n",
      "20 30 0.52031409740448\n",
      "20 80 0.5079173445701599\n",
      "20 130 0.33976587653160095\n",
      "Validation loss: 0.41402878468496757 MAE: 94.55249\n",
      "21 9 0.7562539577484131\n",
      "21 59 0.43063095211982727\n",
      "21 109 0.5320098996162415\n",
      "21 159 0.35127779841423035\n",
      "Validation loss: 0.41953980783272904 MAE: 95.81105\n",
      "22 38 0.6142131090164185\n",
      "22 88 0.45405733585357666\n",
      "22 138 0.8785000443458557\n",
      "Validation loss: 0.44661755258576913 MAE: 101.994835\n",
      "23 17 0.45392540097236633\n",
      "23 67 0.7078464031219482\n",
      "23 117 0.5101893544197083\n",
      "23 167 0.48486506938934326\n",
      "Validation loss: 0.41044192861395273 MAE: 93.733345\n",
      "24 46 0.5363834500312805\n",
      "24 96 0.6150940656661987\n",
      "24 146 0.506503701210022\n",
      "Validation loss: 0.44910776440860234 MAE: 102.56353\n",
      "25 25 0.5429879426956177\n",
      "25 75 0.45916634798049927\n",
      "25 125 0.5787816643714905\n",
      "Validation loss: 0.38628675549002417 MAE: 88.21699\n",
      "26 4 0.4979657828807831\n",
      "26 54 0.3085959851741791\n",
      "26 104 0.6044467091560364\n",
      "26 154 0.39454835653305054\n",
      "Validation loss: 0.4189618883425729 MAE: 95.67906\n",
      "27 33 0.4942512512207031\n",
      "27 83 0.6485189199447632\n",
      "27 133 0.4670458137989044\n",
      "Validation loss: 0.4346612982931193 MAE: 99.264366\n",
      "28 12 0.6013274192810059\n",
      "28 62 0.35907599329948425\n",
      "28 112 0.5275039672851562\n",
      "28 162 0.4013291895389557\n",
      "Validation loss: 0.3952519991244489 MAE: 90.264404\n",
      "29 41 0.3848947584629059\n",
      "29 91 0.327013224363327\n",
      "29 141 0.5318511724472046\n",
      "Validation loss: 0.4392316843333997 MAE: 100.30811\n",
      "30 20 0.4679498076438904\n",
      "30 70 0.4346455931663513\n",
      "30 120 0.35884442925453186\n",
      "30 170 0.30665987730026245\n",
      "Validation loss: 0.445691290306069 MAE: 101.7833\n",
      "31 49 0.3159196078777313\n",
      "31 99 0.6010944843292236\n",
      "31 149 0.8445707559585571\n",
      "Validation loss: 0.44104867650751484 MAE: 100.72307\n",
      "32 28 0.3960273265838623\n",
      "32 78 0.3580358326435089\n",
      "32 128 0.43174150586128235\n",
      "Validation loss: 0.4226549037715845 MAE: 96.522446\n",
      "33 7 0.5137196779251099\n",
      "33 57 0.5444482564926147\n",
      "33 107 0.4030977785587311\n",
      "33 157 0.3890286386013031\n",
      "Validation loss: 0.4157712046514478 MAE: 94.9504\n",
      "34 36 0.5937625169754028\n",
      "34 86 0.5372174978256226\n",
      "34 136 0.25845324993133545\n",
      "Validation loss: 0.4006216379634121 MAE: 91.49067\n",
      "35 15 0.3520890474319458\n",
      "35 65 0.5558522343635559\n",
      "35 115 0.5284045934677124\n",
      "35 165 0.3053922653198242\n",
      "Validation loss: 0.4852383534113566 MAE: 110.814735\n",
      "36 44 0.3259861171245575\n",
      "36 94 0.36427053809165955\n",
      "36 144 0.6518784165382385\n",
      "Validation loss: 0.39561940511764837 MAE: 90.348305\n",
      "37 23 0.44724375009536743\n",
      "37 73 0.4717809855937958\n",
      "37 123 0.42495474219322205\n",
      "Validation loss: 0.4182729109337455 MAE: 95.52172\n",
      "38 2 0.4014725685119629\n",
      "38 52 0.41682642698287964\n",
      "38 102 0.4626038074493408\n",
      "38 152 0.48710981011390686\n",
      "Validation loss: 0.445816184170762 MAE: 101.81184\n",
      "39 31 0.28191542625427246\n",
      "39 81 0.4675544202327728\n",
      "39 131 0.4389846920967102\n",
      "Validation loss: 0.4900450052922232 MAE: 111.91244\n",
      "40 10 0.4980606138706207\n",
      "40 60 0.35141459107398987\n",
      "40 110 0.3566268980503082\n",
      "40 160 0.47333505749702454\n",
      "Validation loss: 0.4661902574419278 MAE: 106.4647\n",
      "41 39 0.5147005319595337\n",
      "41 89 0.3548997640609741\n",
      "41 139 0.578866720199585\n",
      "Validation loss: 0.4357790455483554 MAE: 99.519646\n",
      "42 18 0.3900536894798279\n",
      "42 68 0.36887669563293457\n",
      "42 118 0.5115461349487305\n",
      "42 168 0.3639582097530365\n",
      "Validation loss: 0.39903523637885935 MAE: 91.12838\n",
      "43 47 0.5118145942687988\n",
      "43 97 0.4382600784301758\n",
      "43 147 0.401644229888916\n",
      "Validation loss: 0.4514677608222292 MAE: 103.1025\n",
      "44 26 0.4022396206855774\n",
      "44 76 0.2934458255767822\n",
      "44 126 0.6239805221557617\n",
      "Validation loss: 0.46464336981550297 MAE: 106.11143\n",
      "45 5 0.37534651160240173\n",
      "45 55 0.45864084362983704\n",
      "45 105 0.3989958167076111\n",
      "45 155 0.39899736642837524\n",
      "Validation loss: 0.6838762927473637 MAE: 156.17804\n",
      "46 34 0.3876650333404541\n",
      "46 84 0.3810462951660156\n",
      "46 134 0.34846970438957214\n",
      "Validation loss: 0.4785239473420974 MAE: 109.281364\n",
      "47 13 0.3564221262931824\n",
      "47 63 0.3766605257987976\n",
      "47 113 0.3493766486644745\n",
      "47 163 0.37491172552108765\n",
      "Validation loss: 0.49961545767142757 MAE: 114.09807\n",
      "48 42 0.40892481803894043\n",
      "48 92 0.38143599033355713\n",
      "48 142 0.38535937666893005\n",
      "Validation loss: 0.6330309876224451 MAE: 144.5664\n",
      "49 21 0.36387336254119873\n",
      "49 71 0.45077744126319885\n",
      "49 121 0.28690987825393677\n",
      "Validation loss: 0.4995156171029074 MAE: 114.07527\n",
      "50 0 0.2588713765144348\n",
      "50 50 0.27591341733932495\n",
      "50 100 0.25292566418647766\n",
      "50 150 0.4704650044441223\n",
      "Validation loss: 0.5165121865551374 MAE: 117.9568\n",
      "51 29 0.33780181407928467\n",
      "51 79 0.29799801111221313\n",
      "51 129 0.38245388865470886\n",
      "Validation loss: 0.44769984100297183 MAE: 102.242\n",
      "52 8 0.40353450179100037\n",
      "52 58 0.35816994309425354\n",
      "52 108 0.25584402680397034\n",
      "52 158 0.37817659974098206\n",
      "Validation loss: 0.4852519929409027 MAE: 110.81787\n",
      "53 37 0.49587735533714294\n",
      "53 87 0.3255971670150757\n",
      "53 137 0.48014992475509644\n",
      "Validation loss: 0.5453950428126151 MAE: 124.55283\n",
      "54 16 0.31520581245422363\n",
      "54 66 0.41028085350990295\n",
      "54 116 0.5975964665412903\n",
      "54 166 0.3959379196166992\n",
      "Validation loss: 0.49949554985726785 MAE: 114.07068\n",
      "55 45 0.3743894100189209\n",
      "55 95 0.37292250990867615\n",
      "55 145 0.5652106404304504\n",
      "Validation loss: 0.5990863853727865 MAE: 136.81442\n",
      "56 24 0.30225667357444763\n",
      "56 74 0.4864456355571747\n",
      "56 124 0.2932819724082947\n",
      "Validation loss: 0.46728373166413334 MAE: 106.71441\n",
      "57 3 0.5504468083381653\n",
      "57 53 0.27759045362472534\n",
      "57 103 0.44907069206237793\n",
      "57 153 0.4492565393447876\n",
      "Validation loss: 0.45685278480513053 MAE: 104.33228\n",
      "58 32 0.3675490617752075\n",
      "58 82 0.39218786358833313\n",
      "58 132 0.4044972062110901\n",
      "Validation loss: 0.49953136283751814 MAE: 114.07886\n",
      "59 11 0.2982151508331299\n",
      "59 61 0.3479517996311188\n",
      "59 111 0.46038389205932617\n",
      "59 161 0.4472046494483948\n",
      "Validation loss: 0.6080700368211981 MAE: 138.86603\n",
      "60 40 0.29846712946891785\n",
      "60 90 0.31664490699768066\n",
      "60 140 0.2054411917924881\n",
      "Validation loss: 0.4890051731589245 MAE: 111.67498\n",
      "61 19 0.36420026421546936\n",
      "61 69 0.4586828947067261\n",
      "61 119 0.30695462226867676\n",
      "61 169 0.32939472794532776\n",
      "Validation loss: 0.6096401068202236 MAE: 139.2246\n",
      "62 48 0.25249314308166504\n",
      "62 98 0.48116427659988403\n",
      "62 148 0.3897022604942322\n",
      "Validation loss: 0.549342491821936 MAE: 125.454315\n",
      "63 27 0.49507132172584534\n",
      "63 77 0.38360166549682617\n",
      "63 127 0.2665860950946808\n",
      "Validation loss: 0.5573541494140848 MAE: 127.28394\n",
      "64 6 0.3515951335430145\n",
      "64 56 0.38332006335258484\n",
      "64 106 0.3537181615829468\n",
      "64 156 0.2634543478488922\n",
      "Validation loss: 0.5546383052541498 MAE: 126.663734\n",
      "65 35 0.4797426760196686\n",
      "65 85 0.3839651048183441\n",
      "65 135 0.3123520612716675\n",
      "Validation loss: 0.5709156021040086 MAE: 130.38101\n",
      "66 14 0.3310142755508423\n",
      "66 64 0.5004552006721497\n",
      "66 114 0.27313125133514404\n",
      "66 164 0.4351755380630493\n",
      "Validation loss: 0.5411374920990035 MAE: 123.58052\n",
      "67 43 0.5031688213348389\n",
      "67 93 0.551736056804657\n",
      "67 143 0.4758220613002777\n",
      "Validation loss: 0.5415196038826168 MAE: 123.667786\n",
      "68 22 0.4193974733352661\n",
      "68 72 0.3823162019252777\n",
      "68 122 0.3277442455291748\n",
      "Validation loss: 0.6371744752627367 MAE: 145.51268\n",
      "69 1 0.26670974493026733\n",
      "69 51 0.320596843957901\n",
      "69 101 0.29175692796707153\n",
      "69 151 0.33129191398620605\n",
      "Validation loss: 0.4883544225441782 MAE: 111.52636\n",
      "70 30 0.33331605792045593\n",
      "70 80 0.45419225096702576\n",
      "70 130 0.2878923714160919\n",
      "Validation loss: 0.5543447211820479 MAE: 126.59667\n",
      "71 9 0.38740164041519165\n",
      "71 59 0.316457062959671\n",
      "71 109 0.2321767508983612\n",
      "71 159 0.28507333993911743\n",
      "Validation loss: 0.7463132156963237 MAE: 170.43687\n",
      "72 38 0.43277496099472046\n",
      "72 88 0.5536377429962158\n",
      "72 138 0.3026704490184784\n",
      "Validation loss: 0.4859012171887515 MAE: 110.966125\n",
      "73 17 0.41560885310173035\n",
      "73 67 0.3933452367782593\n",
      "73 117 0.21964357793331146\n",
      "73 167 0.45965373516082764\n",
      "Validation loss: 0.5737383571284557 MAE: 131.02565\n",
      "74 46 0.43028950691223145\n",
      "74 96 0.3835933208465576\n",
      "74 146 0.2763650417327881\n",
      "Validation loss: 0.5304564042398107 MAE: 121.141266\n",
      "75 25 0.44874775409698486\n",
      "75 75 0.44904375076293945\n",
      "75 125 0.3963707685470581\n",
      "Validation loss: 0.6367864765618977 MAE: 145.42407\n",
      "76 4 0.33775657415390015\n",
      "76 54 0.3676253855228424\n",
      "76 104 0.28369155526161194\n",
      "76 154 0.25691673159599304\n",
      "Validation loss: 0.45962968486094335 MAE: 104.966446\n",
      "77 33 0.36805659532546997\n",
      "77 83 0.42260923981666565\n",
      "77 133 0.2441907674074173\n",
      "Validation loss: 0.5024478968821073 MAE: 114.74492\n",
      "78 12 0.25675052404403687\n",
      "78 62 0.4804374873638153\n",
      "78 112 0.2840213477611542\n",
      "78 162 0.639771044254303\n",
      "Validation loss: 0.5557841132258812 MAE: 126.92539\n",
      "79 41 0.5277058482170105\n",
      "79 91 0.3294871151447296\n",
      "79 141 0.33221790194511414\n",
      "Validation loss: 0.551247457314653 MAE: 125.88936\n",
      "80 20 0.4796472191810608\n",
      "80 70 0.22391176223754883\n",
      "80 120 0.388766348361969\n",
      "80 170 0.30966895818710327\n",
      "Validation loss: 0.4797885477194312 MAE: 109.57015\n",
      "81 49 0.48048800230026245\n",
      "81 99 0.28026339411735535\n",
      "81 149 0.4384794235229492\n",
      "Validation loss: 0.5627528537086576 MAE: 128.51686\n",
      "82 28 0.306784987449646\n",
      "82 78 0.2962515354156494\n",
      "82 128 0.47714126110076904\n",
      "Validation loss: 0.7664758364359537 MAE: 175.04144\n",
      "83 7 0.30021384358406067\n",
      "83 57 0.5999846458435059\n",
      "83 107 0.35811886191368103\n",
      "83 157 0.2595318853855133\n",
      "Validation loss: 0.5749188177069725 MAE: 131.29523\n",
      "84 36 0.3800070583820343\n",
      "84 86 0.42508721351623535\n",
      "84 136 0.22811901569366455\n",
      "Validation loss: 0.5109377147858603 MAE: 116.683754\n",
      "85 15 0.2300272434949875\n",
      "85 65 0.4396592080593109\n",
      "85 115 0.2611933648586273\n",
      "85 165 0.3282546401023865\n",
      "Validation loss: 0.6238066634239509 MAE: 142.45984\n",
      "86 44 0.23253001272678375\n",
      "86 94 0.5397748947143555\n",
      "86 144 0.37469804286956787\n",
      "Validation loss: 0.5271846415006627 MAE: 120.3941\n",
      "87 23 0.25480788946151733\n",
      "87 73 0.3500809073448181\n",
      "87 123 0.36072003841400146\n",
      "Validation loss: 0.48883547908381414 MAE: 111.63623\n",
      "88 2 0.3394770920276642\n",
      "88 52 0.3882901966571808\n",
      "88 102 0.3734470307826996\n",
      "88 152 0.4018326997756958\n",
      "Validation loss: 0.4258856111102634 MAE: 97.260254\n",
      "89 31 0.2467433661222458\n",
      "89 81 0.24851281940937042\n",
      "89 131 0.3836163282394409\n",
      "Validation loss: 0.4007261358855063 MAE: 91.514534\n",
      "90 10 0.32504501938819885\n",
      "90 60 0.35390162467956543\n",
      "90 110 0.49444547295570374\n",
      "90 160 0.38510027527809143\n",
      "Validation loss: 0.6535657734898795 MAE: 149.25598\n",
      "91 39 0.4485538899898529\n",
      "91 89 0.34268835186958313\n",
      "91 139 0.4799578785896301\n",
      "Validation loss: 0.5378618240356445 MAE: 122.832466\n",
      "92 18 0.35131484270095825\n",
      "92 68 0.30236876010894775\n",
      "92 118 0.2798137366771698\n",
      "92 168 0.3734809160232544\n",
      "Validation loss: 0.6695144291509662 MAE: 152.89821\n",
      "93 47 0.3558276295661926\n",
      "93 97 0.23315081000328064\n",
      "93 147 0.4374449551105499\n",
      "Validation loss: 0.5028003311296653 MAE: 114.82541\n",
      "94 26 0.3318256735801697\n",
      "94 76 0.34555310010910034\n",
      "94 126 0.4459863305091858\n",
      "Validation loss: 0.5790224336741263 MAE: 132.23239\n",
      "95 5 0.3431568741798401\n",
      "95 55 0.36900195479393005\n",
      "95 105 0.33610421419143677\n",
      "95 155 0.3488680422306061\n",
      "Validation loss: 0.5572467352214613 MAE: 127.259415\n",
      "96 34 0.30250999331474304\n",
      "96 84 0.35259732604026794\n",
      "96 134 0.36068472266197205\n",
      "Validation loss: 0.6518117719226413 MAE: 148.85542\n",
      "97 13 0.24224041402339935\n",
      "97 63 0.4031950533390045\n",
      "97 113 0.3056500256061554\n",
      "97 163 0.38271045684814453\n",
      "Validation loss: 0.5189108660346583 MAE: 118.50459\n",
      "98 42 0.19848807156085968\n",
      "98 92 0.30978697538375854\n",
      "98 142 0.26529863476753235\n",
      "Validation loss: 0.5528551103078831 MAE: 126.2565\n",
      "99 21 0.5384808778762817\n",
      "99 71 0.45903560519218445\n",
      "99 121 0.317130982875824\n",
      "Validation loss: 0.5653215646743774 MAE: 129.10349\n",
      "100 0 0.2841900587081909\n",
      "100 50 0.2805047035217285\n",
      "100 100 0.25584763288497925\n",
      "100 150 0.3352561593055725\n",
      "Validation loss: 0.5621574960256878 MAE: 128.3809\n",
      "101 29 0.26547160744667053\n",
      "101 79 0.3959144353866577\n",
      "101 129 0.31495973467826843\n",
      "Validation loss: 0.5233842740979111 MAE: 119.5262\n",
      "102 8 0.3765774667263031\n",
      "102 58 0.326205313205719\n",
      "102 108 0.4085337817668915\n",
      "102 158 0.40948256850242615\n",
      "Validation loss: 0.5386079600331379 MAE: 123.00285\n",
      "103 37 0.2068977952003479\n",
      "103 87 0.4910411536693573\n",
      "103 137 0.3615127503871918\n",
      "Validation loss: 0.4795204244161907 MAE: 109.508934\n",
      "104 16 0.4078989028930664\n",
      "104 66 0.23653028905391693\n",
      "104 116 0.28350377082824707\n",
      "104 166 0.30054953694343567\n",
      "Validation loss: 0.6458159336569713 MAE: 147.48613\n",
      "105 45 0.33013439178466797\n",
      "105 95 0.31114092469215393\n",
      "105 145 0.43367862701416016\n",
      "Validation loss: 0.6241945962459721 MAE: 142.54843\n",
      "106 24 0.31642523407936096\n",
      "106 74 0.3271104395389557\n",
      "106 124 0.29096829891204834\n",
      "Validation loss: 0.5759802188789636 MAE: 131.53763\n",
      "107 3 0.2779037356376648\n",
      "107 53 0.22589457035064697\n",
      "107 103 0.36122187972068787\n",
      "107 153 0.26348641514778137\n",
      "Validation loss: 0.6512643970244112 MAE: 148.73041\n",
      "108 32 0.2675842046737671\n",
      "108 82 0.314575731754303\n",
      "108 132 0.3659130036830902\n",
      "Validation loss: 0.5352142066286322 MAE: 122.22782\n",
      "109 11 0.38968896865844727\n",
      "109 61 0.272845983505249\n",
      "109 111 0.26735720038414\n",
      "109 161 0.37427088618278503\n",
      "Validation loss: 0.6384153996991833 MAE: 145.79605\n",
      "110 40 0.3664121627807617\n",
      "110 90 0.2514246702194214\n",
      "110 140 0.4866674244403839\n",
      "Validation loss: 0.6547992700024655 MAE: 149.53767\n",
      "111 19 0.4972071349620819\n",
      "111 69 0.40589189529418945\n",
      "111 119 0.33408603072166443\n",
      "111 169 0.36481520533561707\n",
      "Validation loss: 0.545444491313912 MAE: 124.564125\n",
      "112 48 0.34108006954193115\n",
      "112 98 0.3077365458011627\n",
      "112 148 0.214351624250412\n",
      "Validation loss: 0.4720150417054606 MAE: 107.794914\n",
      "113 27 0.3812966048717499\n",
      "113 77 0.41542738676071167\n",
      "113 127 0.27926555275917053\n",
      "Validation loss: 0.5593754840873139 MAE: 127.74557\n",
      "114 6 0.30061525106430054\n",
      "114 56 0.2598817050457001\n",
      "114 106 0.40844839811325073\n",
      "114 156 0.3681447505950928\n",
      "Validation loss: 0.5114282041962384 MAE: 116.79577\n",
      "115 35 0.3419487476348877\n",
      "115 85 0.33800172805786133\n",
      "115 135 0.3542809784412384\n",
      "Validation loss: 0.4362021247197313 MAE: 99.61625\n",
      "116 14 0.2768912613391876\n",
      "116 64 0.3131275773048401\n",
      "116 114 0.30516812205314636\n",
      "116 164 0.32648828625679016\n",
      "Validation loss: 0.7200036777390374 MAE: 164.42853\n",
      "117 43 0.3236992657184601\n",
      "117 93 0.3979426324367523\n",
      "117 143 0.3097149133682251\n",
      "Validation loss: 0.6463825225132948 MAE: 147.61552\n",
      "118 22 0.38656356930732727\n",
      "118 72 0.3468681275844574\n",
      "118 122 0.22637608647346497\n",
      "Validation loss: 0.4893681907165817 MAE: 111.75788\n",
      "119 1 0.32078251242637634\n",
      "119 51 0.2907933294773102\n",
      "119 101 0.3859378397464752\n",
      "119 151 0.23209768533706665\n",
      "Validation loss: 0.615197381429505 MAE: 140.49371\n",
      "120 30 0.3335717022418976\n",
      "120 80 0.23471520841121674\n",
      "120 130 0.19969679415225983\n",
      "Validation loss: 0.4827867830008791 MAE: 110.25487\n",
      "121 9 0.3151063323020935\n",
      "121 59 0.25365951657295227\n",
      "121 109 0.4800187945365906\n",
      "121 159 0.3035612106323242\n",
      "Validation loss: 0.6915556533991942 MAE: 157.9318\n",
      "122 38 0.42870768904685974\n",
      "122 88 0.4219464063644409\n",
      "122 138 0.2657420039176941\n",
      "Validation loss: 0.6038695706261529 MAE: 137.90677\n",
      "123 17 0.31098753213882446\n",
      "123 67 0.4230460822582245\n",
      "123 117 0.3406861126422882\n",
      "123 167 0.30143216252326965\n",
      "Validation loss: 0.5889713168144226 MAE: 134.50443\n",
      "124 46 0.40009891986846924\n",
      "124 96 0.4352227449417114\n",
      "124 146 0.3678555488586426\n",
      "Validation loss: 0.5376845709761681 MAE: 122.791985\n",
      "125 25 0.34529176354408264\n",
      "125 75 0.3744949698448181\n",
      "125 125 0.3435029983520508\n",
      "Validation loss: 0.6527355749007554 MAE: 149.06639\n",
      "126 4 0.20560795068740845\n",
      "126 54 0.2849476635456085\n",
      "126 104 0.2818513810634613\n",
      "126 154 0.2586948573589325\n",
      "Validation loss: 0.692715272917385 MAE: 158.19661\n",
      "127 33 0.4722214639186859\n",
      "127 83 0.27261868119239807\n",
      "127 133 0.3269953429698944\n",
      "Validation loss: 0.5913610005239297 MAE: 135.05017\n",
      "128 12 0.3777469992637634\n",
      "128 62 0.35720294713974\n",
      "128 112 0.3203127980232239\n",
      "128 162 0.2885834276676178\n",
      "Validation loss: 0.5722404352405615 MAE: 130.68358\n",
      "129 41 0.29830682277679443\n",
      "129 91 0.2597012519836426\n",
      "129 141 0.16622038185596466\n",
      "Validation loss: 0.549107799753111 MAE: 125.40072\n",
      "130 20 0.2844269871711731\n",
      "130 70 0.4230667054653168\n",
      "130 120 0.43946269154548645\n",
      "130 170 0.2963089048862457\n",
      "Validation loss: 0.5120343067492658 MAE: 116.93419\n",
      "131 49 0.25992971658706665\n",
      "131 99 0.3036971986293793\n",
      "131 149 0.2948334515094757\n",
      "Validation loss: 0.6563036626542521 MAE: 149.88124\n",
      "132 28 0.23723483085632324\n",
      "132 78 0.34058094024658203\n",
      "132 128 0.295780748128891\n",
      "Validation loss: 0.6950981805199071 MAE: 158.74081\n",
      "133 7 0.2825317978858948\n",
      "133 57 0.38806989789009094\n",
      "133 107 0.33583196997642517\n",
      "133 157 0.2758954167366028\n",
      "Validation loss: 0.5056541879274692 MAE: 115.47714\n",
      "134 36 0.36918947100639343\n",
      "134 86 0.49549832940101624\n",
      "134 136 0.3408724069595337\n",
      "Validation loss: 0.6504170173092892 MAE: 148.5369\n",
      "135 15 0.2708318829536438\n",
      "135 65 0.31447237730026245\n",
      "135 115 0.29248350858688354\n",
      "135 165 0.23965679109096527\n",
      "Validation loss: 0.5735609315292179 MAE: 130.98512\n",
      "136 44 0.26789480447769165\n",
      "136 94 0.42038923501968384\n",
      "136 144 0.25180110335350037\n",
      "Validation loss: 0.47219366166326737 MAE: 107.83571\n",
      "137 23 0.40549299120903015\n",
      "137 73 0.3383287191390991\n",
      "137 123 0.2724534869194031\n",
      "Validation loss: 0.5442716148164537 MAE: 124.29628\n",
      "138 2 0.39137542247772217\n",
      "138 52 0.2912694215774536\n",
      "138 102 0.28816112875938416\n",
      "138 152 0.25404810905456543\n",
      "Validation loss: 0.6623303144298799 MAE: 151.25755\n",
      "139 31 0.29227420687675476\n",
      "139 81 0.26795291900634766\n",
      "139 131 0.2883932292461395\n",
      "Validation loss: 0.683884889061688 MAE: 156.18001\n",
      "140 10 0.25970369577407837\n",
      "140 60 0.3166394829750061\n",
      "140 110 0.19465935230255127\n",
      "140 160 0.34300696849823\n",
      "Validation loss: 0.6260783498050176 MAE: 142.97862\n",
      "141 39 0.37422963976860046\n",
      "141 89 0.4554564654827118\n",
      "141 139 0.4197913408279419\n",
      "Validation loss: 0.6533392674741689 MAE: 149.20425\n",
      "142 18 0.23538021743297577\n",
      "142 68 0.5293639898300171\n",
      "142 118 0.4931391477584839\n",
      "142 168 -1.0455225706100464\n",
      "Validation loss: 0.9670959237026192 MAE: 220.8574\n",
      "143 47 -7.962347030639648\n",
      "143 97 -16.418954849243164\n",
      "143 147 -25.029151916503906\n",
      "Validation loss: 0.5487297644392092 MAE: 125.314384\n",
      "144 26 -32.92753982543945\n",
      "144 76 -40.980831146240234\n",
      "144 126 -50.09126663208008\n",
      "Validation loss: 0.49101750543940137 MAE: 112.13453\n",
      "145 5 -61.074527740478516\n",
      "145 55 -62.992225646972656\n",
      "145 105 -81.50233459472656\n",
      "145 155 -90.46983337402344\n",
      "Validation loss: 0.4788003570852224 MAE: 109.34448\n",
      "146 34 -102.8043441772461\n",
      "146 84 -114.73290252685547\n",
      "146 134 -118.40040588378906\n",
      "Validation loss: 0.49796667607904177 MAE: 113.721535\n",
      "147 13 -138.09500122070312\n",
      "147 63 -151.44436645507812\n",
      "147 113 -167.91360473632812\n",
      "147 163 -166.69593811035156\n",
      "Validation loss: 0.5306278834043191 MAE: 121.18042\n",
      "148 42 -179.07504272460938\n",
      "148 92 -204.93739318847656\n",
      "148 142 -212.49362182617188\n",
      "Validation loss: 0.49950685696295133 MAE: 114.07326\n",
      "149 21 -241.82321166992188\n",
      "149 71 -242.22938537597656\n",
      "149 121 -237.3038330078125\n",
      "Validation loss: 0.5552547049452687 MAE: 126.804504\n",
      "150 0 -280.2177429199219\n",
      "150 50 -290.734130859375\n",
      "150 100 -305.3698425292969\n",
      "150 150 -322.05615234375\n",
      "Validation loss: 0.4965784856450488 MAE: 113.4045\n",
      "151 29 -347.68475341796875\n",
      "151 79 -364.9215087890625\n",
      "151 129 -388.40179443359375\n",
      "Validation loss: 0.5363255620699877 MAE: 122.48161\n",
      "152 8 -384.5572509765625\n",
      "152 58 -389.6581115722656\n",
      "152 108 -441.93511962890625\n",
      "152 158 -469.25616455078125\n",
      "Validation loss: 0.5470434929195204 MAE: 124.92929\n",
      "153 37 -452.0923156738281\n",
      "153 87 -484.8119812011719\n",
      "153 137 -527.08740234375\n",
      "Validation loss: 0.5550450626869647 MAE: 126.75662\n",
      "154 16 -574.5362548828125\n",
      "154 66 -543.9527587890625\n",
      "154 116 -576.772216796875\n",
      "154 166 -610.79052734375\n",
      "Validation loss: 0.5533144481000845 MAE: 126.3614\n",
      "155 45 -652.0765380859375\n",
      "155 95 -571.8880004882812\n",
      "155 145 -608.7162475585938\n",
      "Validation loss: 0.5619667625566672 MAE: 128.33733\n",
      "156 24 -701.9931030273438\n",
      "156 74 -720.6748046875\n",
      "156 124 -723.6251220703125\n",
      "Validation loss: 0.5598266372206615 MAE: 127.848595\n",
      "157 3 -702.8106689453125\n",
      "157 53 -769.7726440429688\n",
      "157 103 -762.644775390625\n",
      "157 153 -879.9710083007812\n",
      "Validation loss: 0.5897952178765459 MAE: 134.69257\n",
      "158 32 -860.1817016601562\n",
      "158 82 -874.2098388671875\n",
      "158 132 -981.1000366210938\n",
      "Validation loss: 0.5961445120342991 MAE: 136.14258\n",
      "159 11 -914.4512329101562\n",
      "159 61 -964.3849487304688\n",
      "159 111 -980.4827880859375\n",
      "159 161 -1097.9281005859375\n",
      "Validation loss: 0.5804122442390487 MAE: 132.54977\n",
      "160 40 -1102.4991455078125\n",
      "160 90 -1191.10791015625\n",
      "160 140 -1150.3306884765625\n",
      "Validation loss: 0.6287208370297973 MAE: 143.58209\n",
      "161 19 -1217.4075927734375\n",
      "161 69 -1214.4178466796875\n",
      "161 119 -1235.792724609375\n",
      "161 169 -1223.3421630859375\n",
      "Validation loss: 0.5773251853142566 MAE: 131.84477\n",
      "162 48 -1405.97900390625\n",
      "162 98 -1441.789306640625\n",
      "162 148 -1442.829345703125\n",
      "Validation loss: 0.6195915655085915 MAE: 141.49721\n",
      "163 27 -1438.67626953125\n",
      "163 77 -1462.5797119140625\n",
      "163 127 -1421.4461669921875\n",
      "Validation loss: 0.5932789326411242 MAE: 135.48817\n",
      "164 6 -1599.92578125\n",
      "164 56 -1630.427001953125\n",
      "164 106 -1560.662109375\n",
      "164 156 -1406.3544921875\n",
      "Validation loss: 0.6320493186426441 MAE: 144.34222\n",
      "165 35 -1658.065673828125\n",
      "165 85 -1700.1944580078125\n",
      "165 135 -1657.7298583984375\n",
      "Validation loss: 0.6140275367519312 MAE: 140.22656\n",
      "166 14 -1768.0361328125\n",
      "166 64 -1920.223876953125\n",
      "166 114 -1888.8876953125\n",
      "166 164 -2031.413330078125\n",
      "Validation loss: 0.6319634558861715 MAE: 144.3226\n",
      "167 43 -1993.717529296875\n",
      "167 93 -2187.652099609375\n",
      "167 143 -1978.7587890625\n",
      "Validation loss: 0.6465116920526962 MAE: 147.645\n",
      "168 22 -1965.60009765625\n",
      "168 72 -1967.5728759765625\n",
      "168 122 -1981.1109619140625\n",
      "Validation loss: 0.6312160687139857 MAE: 144.15193\n",
      "169 1 -2224.72900390625\n",
      "169 51 -2240.2353515625\n",
      "169 101 -2359.66748046875\n",
      "169 151 -2434.514892578125\n",
      "Validation loss: 0.6240791099810461 MAE: 142.52205\n",
      "170 30 -2178.86376953125\n",
      "170 80 -2406.06201171875\n",
      "170 130 -2449.819091796875\n",
      "Validation loss: 0.6296854928920144 MAE: 143.80238\n",
      "171 9 -2671.396728515625\n",
      "171 59 -2837.201904296875\n",
      "171 109 -2489.1650390625\n",
      "171 159 -2812.812255859375\n",
      "Validation loss: 0.6264134931285479 MAE: 143.05516\n",
      "172 38 -2907.026611328125\n",
      "172 88 -2876.392333984375\n",
      "172 138 -2719.02734375\n",
      "Validation loss: 0.613215498756944 MAE: 140.0411\n",
      "173 17 -2746.128662109375\n",
      "173 67 -2801.927734375\n",
      "173 117 -2865.455810546875\n",
      "173 167 -3231.835693359375\n",
      "Validation loss: 0.6219243006399501 MAE: 142.02995\n",
      "174 46 -2961.031494140625\n",
      "174 96 -3130.46533203125\n",
      "174 146 -3055.249755859375\n",
      "Validation loss: 0.641084599216082 MAE: 146.40564\n",
      "175 25 -3311.12548828125\n",
      "175 75 -3393.203125\n",
      "175 125 -3413.831298828125\n",
      "Validation loss: 0.6189975030938087 MAE: 141.36156\n",
      "176 4 -3106.774658203125\n",
      "176 54 -3145.849609375\n",
      "176 104 -3378.4833984375\n",
      "176 154 -3865.1435546875\n",
      "Validation loss: 0.64444339066221 MAE: 147.17267\n",
      "177 33 -3772.357666015625\n",
      "177 83 -3636.983642578125\n",
      "177 133 -3820.3193359375\n",
      "Validation loss: 0.6289059188630846 MAE: 143.62436\n",
      "178 12 -3687.40478515625\n",
      "178 62 -4149.43896484375\n",
      "178 112 -3907.44140625\n",
      "178 162 -4405.634765625\n",
      "Validation loss: 0.6554076549602531 MAE: 149.6766\n",
      "179 41 -4016.0830078125\n",
      "179 91 -3972.28271484375\n",
      "179 141 -4355.98388671875\n",
      "Validation loss: 0.6541050442478114 MAE: 149.37914\n",
      "180 20 -4334.9375\n",
      "180 70 -4723.81005859375\n",
      "180 120 -4591.60986328125\n",
      "180 170 -4874.05517578125\n",
      "Validation loss: 0.6449792148077 MAE: 147.29504\n",
      "181 49 -4756.29638671875\n",
      "181 99 -4531.927734375\n",
      "181 149 -4530.50732421875\n",
      "Validation loss: 0.6305992533588967 MAE: 144.01106\n",
      "182 28 -4628.90380859375\n",
      "182 78 -4959.7421875\n",
      "182 128 -5181.6005859375\n",
      "Validation loss: 0.655546452218329 MAE: 149.7083\n",
      "183 7 -4968.87939453125\n",
      "183 57 -5075.72216796875\n",
      "183 107 -5073.2314453125\n",
      "183 157 -5322.09912109375\n",
      "Validation loss: 0.6694460239326745 MAE: 152.88257\n",
      "184 36 -5665.5\n",
      "184 86 -4692.48095703125\n",
      "184 136 -4835.65576171875\n",
      "Validation loss: 0.6479118372264662 MAE: 147.96478\n",
      "185 15 -5654.3701171875\n",
      "185 65 -5112.580078125\n",
      "185 115 -5699.9423828125\n",
      "185 165 -6216.71435546875\n",
      "Validation loss: 0.6636447212849444 MAE: 151.55771\n",
      "186 44 -6139.45068359375\n",
      "186 94 -5789.916015625\n",
      "186 144 -5976.82080078125\n",
      "Validation loss: 0.6546333731963621 MAE: 149.49977\n",
      "187 23 -6109.16845703125\n",
      "187 73 -6222.32568359375\n",
      "187 123 -6254.5869140625\n",
      "Validation loss: 0.6917430587679322 MAE: 157.9746\n",
      "188 2 -6257.626953125\n",
      "188 52 -6426.298828125\n",
      "188 102 -6632.66015625\n",
      "188 152 -6678.92724609375\n",
      "Validation loss: 0.6951479577181632 MAE: 158.75217\n",
      "189 31 -5940.6142578125\n",
      "189 81 -6581.46728515625\n",
      "189 131 -6823.9091796875\n",
      "Validation loss: 0.6772129420648542 MAE: 154.65631\n",
      "190 10 -7624.33056640625\n",
      "190 60 -6981.7353515625\n",
      "190 110 -7124.91796875\n",
      "190 160 -7279.365234375\n",
      "Validation loss: 0.6508649162381713 MAE: 148.63916\n",
      "191 39 -7278.5234375\n",
      "191 89 -7529.07958984375\n",
      "191 139 -7252.2216796875\n",
      "Validation loss: 0.6776188312218203 MAE: 154.74901\n",
      "192 18 -7636.2568359375\n",
      "192 68 -7301.3310546875\n",
      "192 118 -7537.1591796875\n",
      "192 168 -7868.70458984375\n",
      "Validation loss: 0.6606320362342032 MAE: 150.8697\n",
      "193 47 -8227.703125\n",
      "193 97 -8141.3125\n",
      "193 147 -8200.4853515625\n",
      "Validation loss: 0.6616785369421306 MAE: 151.10869\n",
      "194 26 -7473.630859375\n",
      "194 76 -8584.0537109375\n",
      "194 126 -8269.7431640625\n",
      "Validation loss: 0.6690805355707804 MAE: 152.79912\n",
      "195 5 -9078.70703125\n",
      "195 55 -8459.0927734375\n",
      "195 105 -8278.6611328125\n",
      "195 155 -8701.115234375\n",
      "Validation loss: 0.6500769613081949 MAE: 148.45923\n",
      "196 34 -9294.0810546875\n",
      "196 84 -8519.25\n",
      "196 134 -9362.3798828125\n",
      "Validation loss: 0.6982015901141696 MAE: 159.44954\n",
      "197 13 -9077.8310546875\n",
      "197 63 -8857.4287109375\n",
      "197 113 -9659.9248046875\n",
      "197 163 -9691.6279296875\n",
      "Validation loss: 0.6817732247692799 MAE: 155.69775\n",
      "198 42 -9013.1376953125\n",
      "198 92 -10151.1162109375\n",
      "198 142 -9834.083984375\n",
      "Validation loss: 0.6746182012976262 MAE: 154.06375\n",
      "199 21 -9871.4169921875\n",
      "199 71 -9940.0712890625\n",
      "199 121 -11347.29296875\n",
      "Validation loss: 0.696350145758244 MAE: 159.02673\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.3303571429818127 Test MAE: 75.444244\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bace', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'classification', 'data_path': 'data/bace/bace.csv', 'target': ['Class']}}\n",
      "Running on: cuda:1\n",
      "1512\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1512\n",
      "Generating scaffold 1000/1512\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 8.171480178833008\n",
      "Validation loss: 0.711366099632339 ROC AUC: 0.5364989369241673\n",
      "1 12 2.624234199523926\n",
      "Validation loss: 0.7247488767106012 ROC AUC: 0.5646704464918497\n",
      "2 24 1.9796149730682373\n",
      "Validation loss: 0.6767254898090236 ROC AUC: 0.6174698795180723\n",
      "3 36 1.598533034324646\n",
      "Validation loss: 0.7526479170022421 ROC AUC: 0.6180014174344436\n",
      "Validation loss: 0.9029254494913367 ROC AUC: 0.5653791637136782\n",
      "5 10 1.3465831279754639\n",
      "Validation loss: 1.0252538722082478 ROC AUC: 0.5861091424521616\n",
      "6 22 1.2443886995315552\n",
      "Validation loss: 0.9671628305454127 ROC AUC: 0.5892983699503898\n",
      "7 34 1.1042767763137817\n",
      "Validation loss: 1.1673571491083563 ROC AUC: 0.6123316796598157\n",
      "Validation loss: 0.8799433810821432 ROC AUC: 0.6194188518781006\n",
      "9 8 0.8422760367393494\n",
      "Validation loss: 0.936813355281653 ROC AUC: 0.6187101346562721\n",
      "10 20 0.9143061637878418\n",
      "Validation loss: 0.8035446156729136 ROC AUC: 0.6371367824238129\n",
      "11 32 0.8109976649284363\n",
      "Validation loss: 0.9749085875536432 ROC AUC: 0.6252657689581858\n",
      "Validation loss: 0.7659665519828038 ROC AUC: 0.6307583274273564\n",
      "13 6 0.7233227491378784\n",
      "Validation loss: 0.8620940265276574 ROC AUC: 0.6385542168674699\n",
      "14 18 0.6311467885971069\n",
      "Validation loss: 0.7495530216109674 ROC AUC: 0.6330616583982991\n",
      "15 30 0.7630565166473389\n",
      "Validation loss: 0.8138770690027451 ROC AUC: 0.6041814316087881\n",
      "Validation loss: 0.9443048021651261 ROC AUC: 0.6513111268603827\n",
      "17 4 0.7346002459526062\n",
      "Validation loss: 1.4156919007269753 ROC AUC: 0.6552090715804395\n",
      "18 16 0.5581659078598022\n",
      "Validation loss: 1.0275235097139876 ROC AUC: 0.6527285613040397\n",
      "19 28 0.6385455131530762\n",
      "Validation loss: 0.8941667972021545 ROC AUC: 0.6571580439404678\n",
      "Validation loss: 1.1276119757961753 ROC AUC: 0.6385542168674698\n",
      "21 2 0.4309055209159851\n",
      "Validation loss: 0.9654155440677871 ROC AUC: 0.6442239546420978\n",
      "22 14 0.5889768600463867\n",
      "Validation loss: 1.0748873996418833 ROC AUC: 0.6656626506024097\n",
      "23 26 0.3999882936477661\n",
      "Validation loss: 0.9504684261138866 ROC AUC: 0.6243798724309001\n",
      "Validation loss: 0.916090815667285 ROC AUC: 0.6465272856130404\n",
      "25 0 0.41192615032196045\n",
      "Validation loss: 0.8219748238064596 ROC AUC: 0.6541459957476966\n",
      "26 12 0.4605672359466553\n",
      "Validation loss: 0.9435083664805684 ROC AUC: 0.6376683203401843\n",
      "27 24 0.4562375843524933\n",
      "Validation loss: 0.7717160803592757 ROC AUC: 0.6626506024096385\n",
      "28 36 0.44237399101257324\n",
      "Validation loss: 0.8038466485920331 ROC AUC: 0.6481218993621546\n",
      "Validation loss: 0.7450317874649502 ROC AUC: 0.6725726435152374\n",
      "30 10 0.435445100069046\n",
      "Validation loss: 0.8585112718556891 ROC AUC: 0.6683203401842664\n",
      "31 22 0.6184338331222534\n",
      "Validation loss: 1.179136940975063 ROC AUC: 0.6472360028348688\n",
      "32 34 0.5312268733978271\n",
      "Validation loss: 1.0152863003560249 ROC AUC: 0.6793054571226081\n",
      "Validation loss: 0.867411665569078 ROC AUC: 0.6568036853295534\n",
      "34 8 0.3923801779747009\n",
      "Validation loss: 1.0599329886057518 ROC AUC: 0.6610559886605246\n",
      "35 20 0.4285714030265808\n",
      "Validation loss: 1.1024297823179636 ROC AUC: 0.676470588235294\n",
      "36 32 0.3267035484313965\n",
      "Validation loss: 1.205472138543792 ROC AUC: 0.6500708717221828\n",
      "Validation loss: 0.8020114985522845 ROC AUC: 0.6683203401842664\n",
      "38 6 0.5827388167381287\n",
      "Validation loss: 0.9431456639277225 ROC AUC: 0.6771793054571227\n",
      "39 18 0.41200321912765503\n",
      "Validation loss: 0.820010187215363 ROC AUC: 0.6396172927002126\n",
      "40 30 0.29987436532974243\n",
      "Validation loss: 0.8832279104270683 ROC AUC: 0.6823175053153793\n",
      "Validation loss: 0.8248031348582135 ROC AUC: 0.705173635719348\n",
      "42 4 0.42212146520614624\n",
      "Validation loss: 1.0441814933391595 ROC AUC: 0.6550318922749823\n",
      "43 16 0.4967719614505768\n",
      "Validation loss: 1.0738949002019618 ROC AUC: 0.6812544294826364\n",
      "44 28 0.4596948027610779\n",
      "Validation loss: 0.8000032534662461 ROC AUC: 0.6645995747696669\n",
      "Validation loss: 0.7642783755498217 ROC AUC: 0.6871013465627214\n",
      "46 2 0.43972158432006836\n",
      "Validation loss: 0.7916230669874229 ROC AUC: 0.6731041814316087\n",
      "47 14 0.3319270610809326\n",
      "Validation loss: 0.7713148842584219 ROC AUC: 0.7037562012756909\n",
      "48 26 0.445947527885437\n",
      "Validation loss: 1.1149864836244394 ROC AUC: 0.6621190644932671\n",
      "Validation loss: 0.7482316695301738 ROC AUC: 0.6823175053153792\n",
      "50 0 0.28857186436653137\n",
      "Validation loss: 0.8563747070483024 ROC AUC: 0.6438695960311835\n",
      "51 12 0.3600318729877472\n",
      "Validation loss: 0.8148119591719267 ROC AUC: 0.6697377746279235\n",
      "52 24 0.2819646894931793\n",
      "Validation loss: 0.8000308910742501 ROC AUC: 0.6663713678242381\n",
      "53 36 0.25946399569511414\n",
      "Validation loss: 0.7521757665059424 ROC AUC: 0.7069454287739192\n",
      "Validation loss: 0.898907002234301 ROC AUC: 0.6633593196314671\n",
      "55 10 0.47815772891044617\n",
      "Validation loss: 1.119173139925824 ROC AUC: 0.6644223954642098\n",
      "56 22 0.4488452672958374\n",
      "Validation loss: 1.0641289475737818 ROC AUC: 0.6520198440822111\n",
      "57 34 0.43146127462387085\n",
      "Validation loss: 0.824876319493679 ROC AUC: 0.6445783132530121\n",
      "Validation loss: 0.8439396481640291 ROC AUC: 0.6925939050318922\n",
      "59 8 0.3662673532962799\n",
      "Validation loss: 0.9210090278000231 ROC AUC: 0.6817859673990078\n",
      "60 20 0.4277704656124115\n",
      "Validation loss: 1.0362445739720831 ROC AUC: 0.6583982990786676\n",
      "61 32 0.2899719178676605\n",
      "Validation loss: 0.7557588136748762 ROC AUC: 0.6766477675407513\n",
      "Validation loss: 0.8795673551148926 ROC AUC: 0.6823175053153792\n",
      "63 6 0.45231330394744873\n",
      "Validation loss: 0.9596566790776537 ROC AUC: 0.6787739192062368\n",
      "64 18 0.5077108144760132\n",
      "Validation loss: 0.9539151578549517 ROC AUC: 0.6605244507441531\n",
      "65 30 0.30684202909469604\n",
      "Validation loss: 0.9627493327816591 ROC AUC: 0.6867469879518072\n",
      "Validation loss: 0.7557724698489865 ROC AUC: 0.7069454287739192\n",
      "67 4 0.26620733737945557\n",
      "Validation loss: 0.839965480447605 ROC AUC: 0.673458540042523\n",
      "68 16 0.5198609828948975\n",
      "Validation loss: 0.9464011326530911 ROC AUC: 0.6982636428065203\n",
      "69 28 0.3536268174648285\n",
      "Validation loss: 0.8292251604282304 ROC AUC: 0.6809000708717222\n",
      "Validation loss: 0.8097661852047143 ROC AUC: 0.7062367115520907\n",
      "71 2 0.3604697287082672\n",
      "Validation loss: 0.7863660813956861 ROC AUC: 0.695074415308292\n",
      "72 14 0.42194902896881104\n",
      "Validation loss: 0.8625638492849489 ROC AUC: 0.6532600992204112\n",
      "73 26 0.4511834681034088\n",
      "Validation loss: 0.9284320406566392 ROC AUC: 0.683557760453579\n",
      "Validation loss: 0.840582137865736 ROC AUC: 0.7005669737774628\n",
      "75 0 0.35933855175971985\n",
      "Validation loss: 1.1889239936474933 ROC AUC: 0.6986180014174345\n",
      "76 12 0.2753444015979767\n",
      "Validation loss: 0.8477623048207618 ROC AUC: 0.7044649184975196\n",
      "77 24 0.3602351248264313\n",
      "Validation loss: 0.80497314361547 ROC AUC: 0.7237774627923458\n",
      "78 36 0.3315240144729614\n",
      "Validation loss: 0.9839830295929056 ROC AUC: 0.6927710843373495\n",
      "Validation loss: 0.9766420797006974 ROC AUC: 0.6876328844790929\n",
      "80 10 0.5667761564254761\n",
      "Validation loss: 0.8712884337696808 ROC AUC: 0.7055279943302621\n",
      "81 22 0.28481924533843994\n",
      "Validation loss: 0.8317713157230655 ROC AUC: 0.7250177179305457\n",
      "82 34 0.2560940682888031\n",
      "Validation loss: 1.005157584386156 ROC AUC: 0.6917080085046067\n",
      "Validation loss: 0.9609617819849229 ROC AUC: 0.6529057406094968\n",
      "84 8 0.26145341992378235\n",
      "Validation loss: 1.029221618807079 ROC AUC: 0.6979092841956059\n",
      "85 20 0.3566306531429291\n",
      "Validation loss: 0.7836445806831713 ROC AUC: 0.718284904323175\n",
      "86 32 0.4102567136287689\n",
      "Validation loss: 0.8424597406229436 ROC AUC: 0.7057051736357194\n",
      "Validation loss: 0.9009150033755018 ROC AUC: 0.711020552799433\n",
      "88 6 0.31013917922973633\n",
      "Validation loss: 1.065103682461164 ROC AUC: 0.6915308291991495\n",
      "89 18 0.29170119762420654\n",
      "Validation loss: 0.833788861896818 ROC AUC: 0.7400779588944012\n",
      "90 30 0.27063968777656555\n",
      "Validation loss: 0.8966268591138701 ROC AUC: 0.7246633593196314\n",
      "Validation loss: 0.908778309032617 ROC AUC: 0.7057051736357193\n",
      "92 4 0.24506689608097076\n",
      "Validation loss: 1.017939001519159 ROC AUC: 0.6709780297661234\n",
      "93 16 0.32852184772491455\n",
      "Validation loss: 0.7760045094205844 ROC AUC: 0.700921332388377\n",
      "94 28 0.42797279357910156\n",
      "Validation loss: 0.8876645261088744 ROC AUC: 0.6775336640680368\n",
      "Validation loss: 1.2274423727136574 ROC AUC: 0.6872785258681786\n",
      "96 2 0.2565903663635254\n",
      "Validation loss: 0.9214304211913356 ROC AUC: 0.6871013465627216\n",
      "97 14 0.3310091197490692\n",
      "Validation loss: 0.9045637174947372 ROC AUC: 0.7347625797306875\n",
      "98 26 0.27536946535110474\n",
      "Validation loss: 0.7728633710880153 ROC AUC: 0.7221828490432317\n",
      "Validation loss: 0.8845517220876075 ROC AUC: 0.669029057406095\n",
      "100 0 0.35078126192092896\n",
      "Validation loss: 0.8650409591119022 ROC AUC: 0.6959603118355776\n",
      "101 12 0.43004468083381653\n",
      "Validation loss: 0.8093522704200239 ROC AUC: 0.7329907866761163\n",
      "102 24 0.35950711369514465\n",
      "Validation loss: 0.9982301355987195 ROC AUC: 0.6975549255846918\n",
      "103 36 0.32709547877311707\n",
      "Validation loss: 0.8333753367133488 ROC AUC: 0.7342310418143161\n",
      "Validation loss: 0.8791406142790585 ROC AUC: 0.7127923458540042\n",
      "105 10 0.20450495183467865\n",
      "Validation loss: 0.9229396107970484 ROC AUC: 0.7198795180722891\n",
      "106 22 0.32469913363456726\n",
      "Validation loss: 0.9426904222033671 ROC AUC: 0.6823175053153792\n",
      "107 34 0.2995622158050537\n",
      "Validation loss: 0.8600952447644922 ROC AUC: 0.7172218284904324\n",
      "Validation loss: 1.0162826504138922 ROC AUC: 0.6847980155917788\n",
      "109 8 0.3798827528953552\n",
      "Validation loss: 0.8433066144684292 ROC AUC: 0.6972005669737775\n",
      "110 20 0.3022150695323944\n",
      "Validation loss: 0.9602045614198343 ROC AUC: 0.6734585400425229\n",
      "111 32 0.2936953902244568\n",
      "Validation loss: 0.7770434223263469 ROC AUC: 0.7347625797306875\n",
      "Validation loss: 1.026879756655914 ROC AUC: 0.7005669737774627\n",
      "113 6 0.2269577980041504\n",
      "Validation loss: 0.9543465750896378 ROC AUC: 0.6943656980864634\n",
      "114 18 0.18001140654087067\n",
      "Validation loss: 1.0045749549044678 ROC AUC: 0.7044649184975195\n",
      "115 30 0.3179336190223694\n",
      "Validation loss: 1.1101625932762955 ROC AUC: 0.695074415308292\n",
      "Validation loss: 0.878432225707351 ROC AUC: 0.6897590361445783\n",
      "117 4 0.24757803976535797\n",
      "Validation loss: 1.0739702578411987 ROC AUC: 0.7280297661233167\n",
      "118 16 0.17416295409202576\n",
      "Validation loss: 0.9072504335681334 ROC AUC: 0.7019844082211197\n",
      "119 28 0.2419842630624771\n",
      "Validation loss: 0.9366976208244728 ROC AUC: 0.693656980864635\n",
      "Validation loss: 1.0617570861285885 ROC AUC: 0.7232459248759744\n",
      "121 2 0.22291013598442078\n",
      "Validation loss: 0.9365588331854107 ROC AUC: 0.7092487597448618\n",
      "122 14 0.13726706802845\n",
      "Validation loss: 1.0300333488066464 ROC AUC: 0.7145641389085755\n",
      "123 26 0.2824508845806122\n",
      "Validation loss: 0.9527253086203771 ROC AUC: 0.7342310418143161\n",
      "Validation loss: 0.824532341483413 ROC AUC: 0.7360028348688873\n",
      "125 0 0.37654292583465576\n",
      "Validation loss: 0.9799204614778229 ROC AUC: 0.7104890148830617\n",
      "126 12 0.27808624505996704\n",
      "Validation loss: 0.9661715674084543 ROC AUC: 0.69950389794472\n",
      "127 24 0.22878798842430115\n",
      "Validation loss: 1.041292814229498 ROC AUC: 0.7007441530829198\n",
      "128 36 0.41245707869529724\n",
      "Validation loss: 1.0372347397520052 ROC AUC: 0.7106661941885188\n",
      "Validation loss: 1.1982197728970192 ROC AUC: 0.657512402551382\n",
      "130 10 0.2792956531047821\n",
      "Validation loss: 0.8855985710952455 ROC AUC: 0.7289156626506024\n",
      "131 22 0.23052357137203217\n",
      "Validation loss: 0.9934841177321427 ROC AUC: 0.7250177179305457\n",
      "132 34 0.19419054687023163\n",
      "Validation loss: 1.131521789443414 ROC AUC: 0.695251594613749\n",
      "Validation loss: 1.1381342545250395 ROC AUC: 0.7028703047484054\n",
      "134 8 0.22295962274074554\n",
      "Validation loss: 1.0383351409672112 ROC AUC: 0.7289156626506024\n",
      "135 20 0.30180132389068604\n",
      "Validation loss: 1.1153797116500652 ROC AUC: 0.7046420978029766\n",
      "136 32 0.28151631355285645\n",
      "Validation loss: 1.036757413125196 ROC AUC: 0.7104890148830616\n",
      "Validation loss: 0.8999390104748556 ROC AUC: 0.7418497519489724\n",
      "138 6 0.2732819616794586\n",
      "Validation loss: 1.1846510803462653 ROC AUC: 0.7244861800141743\n",
      "139 18 0.24081778526306152\n",
      "Validation loss: 1.2197931823351524 ROC AUC: 0.6917080085046066\n",
      "140 30 0.22819606959819794\n",
      "Validation loss: 1.1591260827929768 ROC AUC: 0.705173635719348\n",
      "Validation loss: 1.1584358791641842 ROC AUC: 0.679305457122608\n",
      "142 4 0.26175835728645325\n",
      "Validation loss: 1.0871057526165286 ROC AUC: 0.7161587526576896\n",
      "143 16 0.29510432481765747\n",
      "Validation loss: 1.3362206433782515 ROC AUC: 0.6972005669737775\n",
      "144 28 0.3620026707649231\n",
      "Validation loss: 0.9722946412515956 ROC AUC: 0.7149184975194898\n",
      "Validation loss: 1.1737111814764163 ROC AUC: 0.7111977321048901\n",
      "146 2 0.23433062434196472\n",
      "Validation loss: 0.9253130188051438 ROC AUC: 0.7218284904323174\n",
      "147 14 0.26963353157043457\n",
      "Validation loss: 0.8860743424750321 ROC AUC: 0.7437987243090006\n",
      "148 26 0.24953924119472504\n",
      "Validation loss: 1.2734279308887506 ROC AUC: 0.6890503189227498\n",
      "Validation loss: 1.0891434739757058 ROC AUC: 0.6979092841956059\n",
      "150 0 0.25876933336257935\n",
      "Validation loss: 0.9802923920928248 ROC AUC: 0.7188164422395464\n",
      "151 12 0.283354789018631\n",
      "Validation loss: 0.935455450159035 ROC AUC: 0.6959603118355775\n",
      "152 24 0.392042875289917\n",
      "Validation loss: 1.0758769433229964 ROC AUC: 0.71243798724309\n",
      "153 36 0.32213616371154785\n",
      "Validation loss: 0.9230475871768219 ROC AUC: 0.7234231041814316\n",
      "Validation loss: 1.1045158138338305 ROC AUC: 0.7177533664068038\n",
      "155 10 0.2163877785205841\n",
      "Validation loss: 1.0525561318492258 ROC AUC: 0.7129695251594614\n",
      "156 22 0.22080886363983154\n",
      "Validation loss: 1.2219382216598813 ROC AUC: 0.702161587526577\n",
      "157 34 0.23762181401252747\n",
      "Validation loss: 1.1521626971415337 ROC AUC: 0.7289156626506024\n",
      "Validation loss: 0.9613058184156354 ROC AUC: 0.6987951807228916\n",
      "159 8 0.2733165919780731\n",
      "Validation loss: 1.3076857723147663 ROC AUC: 0.6920623671155208\n",
      "160 20 0.29468294978141785\n",
      "Validation loss: 1.0559571140649302 ROC AUC: 0.7120836286321758\n",
      "161 32 0.4150645434856415\n",
      "Validation loss: 1.0267091736888254 ROC AUC: 0.7218284904323176\n",
      "Validation loss: 0.9954568104238699 ROC AUC: 0.7009213323883771\n",
      "163 6 0.21729743480682373\n",
      "Validation loss: 1.198822804831511 ROC AUC: 0.6895818568391211\n",
      "164 18 0.17720690369606018\n",
      "Validation loss: 1.5348859228045735 ROC AUC: 0.6945428773919207\n",
      "165 30 0.2811202108860016\n",
      "Validation loss: 0.923768502592251 ROC AUC: 0.6927710843373495\n",
      "Validation loss: 1.061146336280747 ROC AUC: 0.7021615875265769\n",
      "167 4 0.22412633895874023\n",
      "Validation loss: 1.2203705145033779 ROC AUC: 0.6924167257264351\n",
      "168 16 0.23907145857810974\n",
      "Validation loss: 1.0740590020520797 ROC AUC: 0.7315733522324593\n",
      "169 28 0.2061324566602707\n",
      "Validation loss: 1.1157091737582983 ROC AUC: 0.6823175053153792\n",
      "Validation loss: 1.1859556247066978 ROC AUC: 0.7030474840538625\n",
      "171 2 0.15297921001911163\n",
      "Validation loss: 1.0585935534230921 ROC AUC: 0.7205882352941176\n",
      "172 14 0.26986801624298096\n",
      "Validation loss: 1.2551323262271503 ROC AUC: 0.7087172218284905\n",
      "173 26 0.28733399510383606\n",
      "Validation loss: 0.9713105472507856 ROC AUC: 0.7158043940467753\n",
      "Validation loss: 1.4602704206049837 ROC AUC: 0.699326718639263\n",
      "175 0 0.23030789196491241\n",
      "Validation loss: 1.1304098501900175 ROC AUC: 0.6913536498936925\n",
      "176 12 0.32861199975013733\n",
      "Validation loss: 1.174529392987687 ROC AUC: 0.7195251594613749\n",
      "177 24 0.287536084651947\n",
      "Validation loss: 1.3205337587571302 ROC AUC: 0.7221828490432317\n",
      "178 36 0.7341893315315247\n",
      "Validation loss: 1.0952982657792552 ROC AUC: 0.718284904323175\n",
      "Validation loss: 1.2228974364451226 ROC AUC: 0.6814316087880935\n",
      "180 10 0.21832451224327087\n",
      "Validation loss: 1.4420320782440388 ROC AUC: 0.6968462083628633\n",
      "181 22 0.24450983107089996\n",
      "Validation loss: 0.9904624969753998 ROC AUC: 0.7368887313961731\n",
      "182 34 0.26137128472328186\n",
      "Validation loss: 1.1069337109856259 ROC AUC: 0.7308646350106308\n",
      "Validation loss: 1.1477944724607152 ROC AUC: 0.7207654145995748\n",
      "184 8 0.12263023853302002\n",
      "Validation loss: 1.0554328916088636 ROC AUC: 0.7285613040396882\n",
      "185 20 0.35273945331573486\n",
      "Validation loss: 1.0230933538335838 ROC AUC: 0.7149184975194898\n",
      "186 32 0.3561875820159912\n",
      "Validation loss: 1.0570583651397403 ROC AUC: 0.7111977321048901\n",
      "Validation loss: 1.3475533123837402 ROC AUC: 0.7019844082211197\n",
      "188 6 0.1910175383090973\n",
      "Validation loss: 1.2913181434403982 ROC AUC: 0.7034018426647768\n",
      "189 18 0.34667521715164185\n",
      "Validation loss: 1.4586176414363432 ROC AUC: 0.6915308291991495\n",
      "190 30 0.14002586901187897\n",
      "Validation loss: 1.0010235491177895 ROC AUC: 0.7053508150248051\n",
      "Validation loss: 1.1665648518019165 ROC AUC: 0.7170446491849751\n",
      "192 4 0.09264729917049408\n",
      "Validation loss: 1.219074007691137 ROC AUC: 0.6796598157335223\n",
      "193 16 0.304373174905777\n",
      "Validation loss: 1.1804729850086946 ROC AUC: 0.7097802976612332\n",
      "194 28 0.2652338147163391\n",
      "Validation loss: 1.2541729543382758 ROC AUC: 0.7227143869596031\n",
      "Validation loss: 1.3278651545379336 ROC AUC: 0.682317505315379\n",
      "196 2 0.27287712693214417\n",
      "Validation loss: 1.1694390509302253 ROC AUC: 0.6833805811481218\n",
      "197 14 0.3149276673793793\n",
      "Validation loss: 1.245486139461694 ROC AUC: 0.6929482636428066\n",
      "198 26 0.2712135314941406\n",
      "Validation loss: 1.3191685147632826 ROC AUC: 0.6972005669737774\n",
      "Validation loss: 1.1446343423514966 ROC AUC: 0.685152374202693\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.1008455690584684 Test ROC AUC: 0.7972826086956522\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bace', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 778, 'task': 'classification', 'data_path': 'data/bace/bace.csv', 'target': ['Class']}}\n",
      "Running on: cuda:1\n",
      "1512\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1512\n",
      "Generating scaffold 1000/1512\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 8.493636131286621\n",
      "Validation loss: 0.7456857779168136 ROC AUC: 0.565024805102764\n",
      "1 12 2.5821399688720703\n",
      "Validation loss: 0.7676204517977128 ROC AUC: 0.5407512402551382\n",
      "2 24 1.8255455493927002\n",
      "Validation loss: 0.7668121172892337 ROC AUC: 0.5253366406803686\n",
      "3 36 1.712547779083252\n",
      "Validation loss: 0.8091114518658215 ROC AUC: 0.5294117647058824\n",
      "Validation loss: 1.0571778981101434 ROC AUC: 0.5198440822111977\n",
      "5 10 1.1369150876998901\n",
      "Validation loss: 1.3007784150294122 ROC AUC: 0.6110914245216158\n",
      "6 22 1.2533349990844727\n",
      "Validation loss: 0.8516314613898068 ROC AUC: 0.5811481218993622\n",
      "7 34 1.130017876625061\n",
      "Validation loss: 0.7472618841967046 ROC AUC: 0.6077250177179305\n",
      "Validation loss: 0.9740577470387844 ROC AUC: 0.6461729270021261\n",
      "9 8 0.9464435577392578\n",
      "Validation loss: 0.8563308068458607 ROC AUC: 0.601346562721474\n",
      "10 20 0.977292001247406\n",
      "Validation loss: 0.8927330840502353 ROC AUC: 0.6114457831325302\n",
      "11 32 0.8850311040878296\n",
      "Validation loss: 0.9263630919898582 ROC AUC: 0.6203047484053863\n",
      "Validation loss: 0.8388655106752914 ROC AUC: 0.6350106307583274\n",
      "13 6 0.9955168962478638\n",
      "Validation loss: 0.7924535894236028 ROC AUC: 0.635719347980156\n",
      "14 18 0.8570162057876587\n",
      "Validation loss: 0.9084567293426059 ROC AUC: 0.6238483345145287\n",
      "15 30 0.668118953704834\n",
      "Validation loss: 0.8708867205689285 ROC AUC: 0.6422749822820695\n",
      "Validation loss: 0.6852751370297362 ROC AUC: 0.621367824238129\n",
      "17 4 0.5941381454467773\n",
      "Validation loss: 0.8170926180106914 ROC AUC: 0.6282778171509568\n",
      "18 16 0.6472521424293518\n",
      "Validation loss: 1.0686375739558642 ROC AUC: 0.609851169383416\n",
      "19 28 0.6755216717720032\n",
      "Validation loss: 0.800253784419685 ROC AUC: 0.6791282778171509\n",
      "Validation loss: 0.9921097364646709 ROC AUC: 0.6406803685329553\n",
      "21 2 0.46037980914115906\n",
      "Validation loss: 0.7246739118304474 ROC AUC: 0.6635364989369241\n",
      "22 14 0.7355728149414062\n",
      "Validation loss: 0.8330309284443886 ROC AUC: 0.6385542168674698\n",
      "23 26 0.4818469285964966\n",
      "Validation loss: 0.8524953347957687 ROC AUC: 0.6491849751948973\n",
      "Validation loss: 0.8114521985022437 ROC AUC: 0.6284549964564139\n",
      "25 0 0.5242658853530884\n",
      "Validation loss: 0.8344843656022027 ROC AUC: 0.6585754783841248\n",
      "26 12 0.5352826118469238\n",
      "Validation loss: 1.147836552550461 ROC AUC: 0.6165839829907866\n",
      "27 24 0.5664634108543396\n",
      "Validation loss: 0.7798435830122588 ROC AUC: 0.624202693125443\n",
      "28 36 0.5360940098762512\n",
      "Validation loss: 0.8444508523341047 ROC AUC: 0.6348334514528703\n",
      "Validation loss: 0.7237783378323183 ROC AUC: 0.6688518781006378\n",
      "30 10 0.5456591248512268\n",
      "Validation loss: 0.6786659024409111 ROC AUC: 0.6885187810063784\n",
      "31 22 0.4336581826210022\n",
      "Validation loss: 0.7284721767665535 ROC AUC: 0.666371367824238\n",
      "32 34 0.41356271505355835\n",
      "Validation loss: 0.7901125605532665 ROC AUC: 0.6824946846208363\n",
      "Validation loss: 1.1513934190699597 ROC AUC: 0.6070163004961021\n",
      "34 8 0.4862061142921448\n",
      "Validation loss: 0.914338036088754 ROC AUC: 0.6642452161587526\n",
      "35 20 0.32684412598609924\n",
      "Validation loss: 0.7836748953686644 ROC AUC: 0.6619418851878102\n",
      "36 32 0.4247454106807709\n",
      "Validation loss: 0.7454199100172283 ROC AUC: 0.6699149539333805\n",
      "Validation loss: 0.7965822547476813 ROC AUC: 0.6631821403260099\n",
      "38 6 0.35545164346694946\n",
      "Validation loss: 1.0224336251517794 ROC AUC: 0.6704464918497519\n",
      "39 18 0.380452036857605\n",
      "Validation loss: 0.7391492448105718 ROC AUC: 0.6700921332388377\n",
      "40 30 0.3106074631214142\n",
      "Validation loss: 0.7463582821239699 ROC AUC: 0.6837349397590362\n",
      "Validation loss: 0.7286578645769334 ROC AUC: 0.6761162296243798\n",
      "42 4 0.46595287322998047\n",
      "Validation loss: 1.2032474066248002 ROC AUC: 0.6302267895109851\n",
      "43 16 0.41541293263435364\n",
      "Validation loss: 0.8799126037698708 ROC AUC: 0.6339475549255847\n",
      "44 28 0.37323084473609924\n",
      "Validation loss: 0.8607919626678062 ROC AUC: 0.6768249468462083\n",
      "Validation loss: 0.9532276048565542 ROC AUC: 0.6343019135364989\n",
      "46 2 0.3784765303134918\n",
      "Validation loss: 1.0165070504542217 ROC AUC: 0.6523742026931255\n",
      "47 14 0.26931437849998474\n",
      "Validation loss: 0.9110153692447587 ROC AUC: 0.6534372785258682\n",
      "48 26 0.2751975357532501\n",
      "Validation loss: 0.8661564438548309 ROC AUC: 0.692239546420978\n",
      "Validation loss: 1.0026383107861145 ROC AUC: 0.6669029057406095\n",
      "50 0 0.2850847542285919\n",
      "Validation loss: 0.856480528187278 ROC AUC: 0.6653082919914954\n",
      "51 12 0.5514135360717773\n",
      "Validation loss: 0.9170588450321299 ROC AUC: 0.6793054571226081\n",
      "52 24 0.4283312261104584\n",
      "Validation loss: 0.866022057880629 ROC AUC: 0.6614103472714387\n",
      "53 36 0.4245000183582306\n",
      "Validation loss: 0.9853489067380792 ROC AUC: 0.6720411055988661\n",
      "Validation loss: 0.8434038391176438 ROC AUC: 0.6736357193479802\n",
      "55 10 0.3610357344150543\n",
      "Validation loss: 1.1046713543254019 ROC AUC: 0.6755846917080085\n",
      "56 22 0.4773027300834656\n",
      "Validation loss: 0.8410727496178735 ROC AUC: 0.6695605953224664\n",
      "57 34 0.4270211458206177\n",
      "Validation loss: 0.834353191568362 ROC AUC: 0.6846208362863218\n",
      "Validation loss: 0.8352089303218766 ROC AUC: 0.6961374911410347\n",
      "59 8 0.2989684045314789\n",
      "Validation loss: 0.876599979716421 ROC AUC: 0.6862154500354358\n",
      "60 20 0.5612261295318604\n",
      "Validation loss: 0.9104570647738627 ROC AUC: 0.6529057406094968\n",
      "61 32 0.3826320171356201\n",
      "Validation loss: 1.0423088152677018 ROC AUC: 0.68781006378455\n",
      "Validation loss: 1.2895710373556377 ROC AUC: 0.6516654854712969\n",
      "63 6 0.3312014937400818\n",
      "Validation loss: 0.8547747786471386 ROC AUC: 0.7032246633593197\n",
      "64 18 0.2833104729652405\n",
      "Validation loss: 1.1495930982741298 ROC AUC: 0.6924167257264352\n",
      "65 30 0.2491200864315033\n",
      "Validation loss: 1.033450479539025 ROC AUC: 0.6894046775336641\n",
      "Validation loss: 0.8045010314082468 ROC AUC: 0.7133238837703756\n",
      "67 4 0.3674078583717346\n",
      "Validation loss: 0.7132016191419387 ROC AUC: 0.7154500354358612\n",
      "68 16 0.3140573799610138\n",
      "Validation loss: 0.7389542409126332 ROC AUC: 0.734053862508859\n",
      "69 28 0.4016120135784149\n",
      "Validation loss: 0.8004549587799223 ROC AUC: 0.7173990077958894\n",
      "Validation loss: 0.9687265532695695 ROC AUC: 0.6871013465627215\n",
      "71 2 0.36779478192329407\n",
      "Validation loss: 0.9667352599813449 ROC AUC: 0.6635364989369241\n",
      "72 14 0.22031629085540771\n",
      "Validation loss: 0.881044404790891 ROC AUC: 0.6995038979447199\n",
      "73 26 0.24585317075252533\n",
      "Validation loss: 1.0935235035340518 ROC AUC: 0.6541459957476967\n",
      "Validation loss: 0.8081284039067906 ROC AUC: 0.7067682494684621\n",
      "75 0 0.2905009388923645\n",
      "Validation loss: 1.1755854317684047 ROC AUC: 0.6332388377037562\n",
      "76 12 0.47318559885025024\n",
      "Validation loss: 1.0474540389926228 ROC AUC: 0.7057051736357193\n",
      "77 24 0.3642054498195648\n",
      "Validation loss: 1.0619636797747076 ROC AUC: 0.6697377746279234\n",
      "78 36 0.5079657435417175\n",
      "Validation loss: 0.8472504296050166 ROC AUC: 0.6830262225372077\n",
      "Validation loss: 0.911733552320114 ROC AUC: 0.702161587526577\n",
      "80 10 0.24665504693984985\n",
      "Validation loss: 0.7936914038184463 ROC AUC: 0.7042877391920622\n",
      "81 22 0.2615255117416382\n",
      "Validation loss: 1.0263720300813384 ROC AUC: 0.7046420978029766\n",
      "82 34 0.29972147941589355\n",
      "Validation loss: 1.0444286169595276 ROC AUC: 0.6676116229624379\n",
      "Validation loss: 0.8588001834635703 ROC AUC: 0.67487597448618\n",
      "84 8 0.43907487392425537\n",
      "Validation loss: 0.9722023026043216 ROC AUC: 0.7204110559886605\n",
      "85 20 0.41798341274261475\n",
      "Validation loss: 0.9759138988343296 ROC AUC: 0.6847980155917789\n",
      "86 32 0.3017086982727051\n",
      "Validation loss: 0.809947014644446 ROC AUC: 0.7177533664068037\n",
      "Validation loss: 1.0293984507882832 ROC AUC: 0.7062367115520907\n",
      "88 6 0.1599855124950409\n",
      "Validation loss: 0.8583907674479958 ROC AUC: 0.693656980864635\n",
      "89 18 0.34512606263160706\n",
      "Validation loss: 0.8770792259285781 ROC AUC: 0.6809000708717222\n",
      "90 30 0.3649526536464691\n",
      "Validation loss: 1.106410202601098 ROC AUC: 0.6770021261516654\n",
      "Validation loss: 0.8592560101818565 ROC AUC: 0.7315733522324592\n",
      "92 4 0.4721401333808899\n",
      "Validation loss: 0.8702026605606079 ROC AUC: 0.7191708008504606\n",
      "93 16 0.2665935456752777\n",
      "Validation loss: 1.1277276277542114 ROC AUC: 0.6832034018426647\n",
      "94 28 0.46987593173980713\n",
      "Validation loss: 0.7855534474581283 ROC AUC: 0.7241318214032602\n",
      "Validation loss: 0.8167137641780424 ROC AUC: 0.6922395464209781\n",
      "96 2 0.25643572211265564\n",
      "Validation loss: 0.8710642685953355 ROC AUC: 0.7129695251594613\n",
      "97 14 0.21272966265678406\n",
      "Validation loss: 0.9410935742965597 ROC AUC: 0.7041105598866052\n",
      "98 26 0.3768292963504791\n",
      "Validation loss: 1.0014830046142174 ROC AUC: 0.7165131112686038\n",
      "Validation loss: 0.8875100360011423 ROC AUC: 0.7032246633593197\n",
      "100 0 0.3243330419063568\n",
      "Validation loss: 1.042232680794419 ROC AUC: 0.6952515946137491\n",
      "101 12 0.29515159130096436\n",
      "Validation loss: 0.9012872521450978 ROC AUC: 0.7186392629340893\n",
      "102 24 0.2494402378797531\n",
      "Validation loss: 1.0635834036283935 ROC AUC: 0.6739900779588944\n",
      "103 36 0.3236527442932129\n",
      "Validation loss: 0.8185034788996968 ROC AUC: 0.7044649184975195\n",
      "Validation loss: 1.2181759456925045 ROC AUC: 0.660347271438696\n",
      "105 10 0.4460955858230591\n",
      "Validation loss: 0.7940236472136137 ROC AUC: 0.7259036144578312\n",
      "106 22 0.3449004590511322\n",
      "Validation loss: 1.058939996934095 ROC AUC: 0.7076541459957477\n",
      "107 34 0.30318331718444824\n",
      "Validation loss: 1.0628765442513473 ROC AUC: 0.6952515946137492\n",
      "Validation loss: 1.1483339631794305 ROC AUC: 0.673458540042523\n",
      "109 8 0.39359918236732483\n",
      "Validation loss: 1.0464653021452444 ROC AUC: 0.6601700921332387\n",
      "110 20 0.2790101170539856\n",
      "Validation loss: 0.8826245093187749 ROC AUC: 0.6986180014174344\n",
      "111 32 0.37552931904792786\n",
      "Validation loss: 0.9564242943233212 ROC AUC: 0.6954287739192062\n",
      "Validation loss: 0.9105454770145037 ROC AUC: 0.6948972360028349\n",
      "113 6 0.20559145510196686\n",
      "Validation loss: 0.8684849912757115 ROC AUC: 0.7163359319631466\n",
      "114 18 0.4325772225856781\n",
      "Validation loss: 1.1392795565902003 ROC AUC: 0.6708008504606661\n",
      "115 30 0.4152531921863556\n",
      "Validation loss: 1.1558655689883706 ROC AUC: 0.6369596031183558\n",
      "Validation loss: 0.9665951630137614 ROC AUC: 0.6934798015591779\n",
      "117 4 0.22611521184444427\n",
      "Validation loss: 0.9098258326385195 ROC AUC: 0.7124379872430899\n",
      "118 16 0.3868103325366974\n",
      "Validation loss: 1.1455647487514067 ROC AUC: 0.6725726435152374\n",
      "119 28 0.32241272926330566\n",
      "Validation loss: 0.9820210894212028 ROC AUC: 0.6608788093550673\n",
      "Validation loss: 0.9588566836931848 ROC AUC: 0.6757618710134656\n",
      "121 2 0.2548760771751404\n",
      "Validation loss: 0.8973114143144216 ROC AUC: 0.6899362154500355\n",
      "122 14 0.27374550700187683\n",
      "Validation loss: 0.9357158932464802 ROC AUC: 0.683380581148122\n",
      "123 26 0.32162460684776306\n",
      "Validation loss: 0.9813859383791488 ROC AUC: 0.6837349397590361\n",
      "Validation loss: 1.0182735647586798 ROC AUC: 0.6809000708717222\n",
      "125 0 0.13550478219985962\n",
      "Validation loss: 1.1649969200424801 ROC AUC: 0.6897590361445783\n",
      "126 12 0.2685222923755646\n",
      "Validation loss: 1.1236326864223607 ROC AUC: 0.6872785258681786\n",
      "127 24 0.34027737379074097\n",
      "Validation loss: 0.8953568888026358 ROC AUC: 0.6972005669737774\n",
      "128 36 0.38913923501968384\n",
      "Validation loss: 0.986513212421872 ROC AUC: 0.6406803685329554\n",
      "Validation loss: 0.9334870880802736 ROC AUC: 0.7046420978029765\n",
      "130 10 0.2534087598323822\n",
      "Validation loss: 1.075541939956463 ROC AUC: 0.6970233876683204\n",
      "131 22 0.17441631853580475\n",
      "Validation loss: 0.865650934888827 ROC AUC: 0.7106661941885188\n",
      "132 34 0.23310908675193787\n",
      "Validation loss: 1.0749503642518 ROC AUC: 0.6973777462792345\n",
      "Validation loss: 1.0918468355343043 ROC AUC: 0.6878100637845499\n",
      "134 8 0.28581881523132324\n",
      "Validation loss: 1.091084633836683 ROC AUC: 0.6986180014174345\n",
      "135 20 0.22107425332069397\n",
      "Validation loss: 1.0233447618831861 ROC AUC: 0.679305457122608\n",
      "136 32 0.43944236636161804\n",
      "Validation loss: 1.1188437974216132 ROC AUC: 0.6925939050318922\n",
      "Validation loss: 0.9558567085013484 ROC AUC: 0.6803685329553508\n",
      "138 6 0.2641533613204956\n",
      "Validation loss: 0.8198164488306109 ROC AUC: 0.6998582565556343\n",
      "139 18 0.25409582257270813\n",
      "Validation loss: 1.0735695638403988 ROC AUC: 0.680545712260808\n",
      "140 30 0.27455171942710876\n",
      "Validation loss: 1.072627999924666 ROC AUC: 0.7259036144578314\n",
      "Validation loss: 1.0162441959444262 ROC AUC: 0.6886959603118356\n",
      "142 4 0.31468963623046875\n",
      "Validation loss: 1.0259732615868777 ROC AUC: 0.6996810772501773\n",
      "143 16 0.1999252438545227\n",
      "Validation loss: 1.1684657066863104 ROC AUC: 0.6708008504606662\n",
      "144 28 0.3319147825241089\n",
      "Validation loss: 1.020334850478646 ROC AUC: 0.6947200566973777\n",
      "Validation loss: 0.9649058098824609 ROC AUC: 0.7251948972360027\n",
      "146 2 0.2755742073059082\n",
      "Validation loss: 1.0695381969805584 ROC AUC: 0.6826718639262934\n",
      "147 14 0.17932197451591492\n",
      "Validation loss: 1.3620121479034424 ROC AUC: 0.682140326009922\n",
      "148 26 0.22960050404071808\n",
      "Validation loss: 1.1776497900880725 ROC AUC: 0.6901133947554925\n",
      "Validation loss: 0.8737927683141847 ROC AUC: 0.6966690290574061\n",
      "150 0 0.33130207657814026\n",
      "Validation loss: 1.1903810331363551 ROC AUC: 0.689227498228207\n",
      "151 12 0.21087102591991425\n",
      "Validation loss: 1.4956047274419013 ROC AUC: 0.7140326009922041\n",
      "152 24 0.2434074878692627\n",
      "Validation loss: 1.0340212378280842 ROC AUC: 0.7104890148830616\n",
      "153 36 0.4429658055305481\n",
      "Validation loss: 1.1481316886990276 ROC AUC: 0.6871013465627215\n",
      "Validation loss: 1.1548892188545883 ROC AUC: 0.7246633593196314\n",
      "155 10 0.2740182876586914\n",
      "Validation loss: 1.1142562462004604 ROC AUC: 0.6986180014174344\n",
      "156 22 0.11165139079093933\n",
      "Validation loss: 1.0671614167706067 ROC AUC: 0.7172218284904323\n",
      "157 34 0.27295029163360596\n",
      "Validation loss: 1.1429955461956807 ROC AUC: 0.6778880226789512\n",
      "Validation loss: 1.1394937204209385 ROC AUC: 0.6952515946137491\n",
      "159 8 0.10000085085630417\n",
      "Validation loss: 1.1379904028595678 ROC AUC: 0.6839121190644932\n",
      "160 20 0.2276703417301178\n",
      "Validation loss: 1.28873949493004 ROC AUC: 0.6856839121190644\n",
      "161 32 0.28747981786727905\n",
      "Validation loss: 1.0687734243885572 ROC AUC: 0.6998582565556343\n",
      "Validation loss: 1.0951906750533755 ROC AUC: 0.6582211197732104\n",
      "163 6 0.24603530764579773\n",
      "Validation loss: 0.9865111538905971 ROC AUC: 0.7172218284904324\n",
      "164 18 0.35899683833122253\n",
      "Validation loss: 1.0302082363343397 ROC AUC: 0.684975194897236\n",
      "165 30 0.21227383613586426\n",
      "Validation loss: 1.0191049654752213 ROC AUC: 0.7165131112686037\n",
      "Validation loss: 1.1080129233417133 ROC AUC: 0.6752303330970942\n",
      "167 4 0.16472426056861877\n",
      "Validation loss: 1.0534516099272975 ROC AUC: 0.7131467044649185\n",
      "168 16 0.22899556159973145\n",
      "Validation loss: 1.4464920443414853 ROC AUC: 0.6906449326718639\n",
      "169 28 0.21625688672065735\n",
      "Validation loss: 1.0492557839842032 ROC AUC: 0.6860382707299787\n",
      "Validation loss: 1.0432444960865754 ROC AUC: 0.6888731396172927\n",
      "171 2 0.21215254068374634\n",
      "Validation loss: 1.116853339387881 ROC AUC: 0.7115520907158044\n",
      "172 14 0.1708388477563858\n",
      "Validation loss: 1.1922940315789734 ROC AUC: 0.702338766832034\n",
      "173 26 0.49492117762565613\n",
      "Validation loss: 0.9490491495227182 ROC AUC: 0.7255492558469171\n",
      "Validation loss: 1.349618738850221 ROC AUC: 0.7087172218284904\n",
      "175 0 0.10764878988265991\n",
      "Validation loss: 1.1636070991983476 ROC AUC: 0.6973777462792345\n",
      "176 12 0.29305601119995117\n",
      "Validation loss: 1.2709474003078132 ROC AUC: 0.7207654145995748\n",
      "177 24 0.19986943900585175\n",
      "Validation loss: 1.3586037218175977 ROC AUC: 0.7042877391920623\n",
      "178 36 0.15393732488155365\n",
      "Validation loss: 1.1401863516561244 ROC AUC: 0.682140326009922\n",
      "Validation loss: 1.4191273135065243 ROC AUC: 0.7034018426647768\n",
      "180 10 0.26433855295181274\n",
      "Validation loss: 1.209685215886855 ROC AUC: 0.6938341601700921\n",
      "181 22 0.21442988514900208\n",
      "Validation loss: 1.151061626459589 ROC AUC: 0.7212969525159462\n",
      "182 34 0.20092365145683289\n",
      "Validation loss: 1.2528723715156909 ROC AUC: 0.7140326009922041\n",
      "Validation loss: 1.0879872678131457 ROC AUC: 0.7147413182140326\n",
      "184 8 0.29651904106140137\n",
      "Validation loss: 1.320684728243493 ROC AUC: 0.6927710843373495\n",
      "185 20 0.2012910693883896\n",
      "Validation loss: 1.2892104845173311 ROC AUC: 0.6977321048901488\n",
      "186 32 0.2324463427066803\n",
      "Validation loss: 1.1837673897774803 ROC AUC: 0.6888731396172927\n",
      "Validation loss: 1.221177445342209 ROC AUC: 0.7046420978029767\n",
      "188 6 0.16432170569896698\n",
      "Validation loss: 1.5256101327226652 ROC AUC: 0.7028703047484054\n",
      "189 18 0.17279402911663055\n",
      "Validation loss: 1.093654345992385 ROC AUC: 0.6911764705882354\n",
      "190 30 0.19144511222839355\n",
      "Validation loss: 1.2979101779445117 ROC AUC: 0.7212969525159462\n",
      "Validation loss: 1.066314516478027 ROC AUC: 0.7115520907158043\n",
      "192 4 0.22671157121658325\n",
      "Validation loss: 1.1708440299065697 ROC AUC: 0.677710843373494\n",
      "193 16 0.15659496188163757\n",
      "Validation loss: 1.3560913248567392 ROC AUC: 0.6871013465627215\n",
      "194 28 0.30578863620758057\n",
      "Validation loss: 1.1922378255831485 ROC AUC: 0.7156272147413182\n",
      "Validation loss: 1.2852337099858466 ROC AUC: 0.7010985116938342\n",
      "196 2 0.41463956236839294\n",
      "Validation loss: 1.2820065676771253 ROC AUC: 0.6948972360028348\n",
      "197 14 0.2844032645225525\n",
      "Validation loss: 1.6024494218510508 ROC AUC: 0.6855067328136074\n",
      "198 26 0.3036659359931946\n",
      "Validation loss: 1.2981338966761204 ROC AUC: 0.6947200566973777\n",
      "Validation loss: 1.3888487815856934 ROC AUC: 0.6863926293408931\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.8147105417753521 Test ROC AUC: 0.7942028985507247\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bace', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 779, 'task': 'classification', 'data_path': 'data/bace/bace.csv', 'target': ['Class']}}\n",
      "Running on: cuda:1\n",
      "1512\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1512\n",
      "Generating scaffold 1000/1512\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 8.219457626342773\n",
      "Validation loss: 0.6931391851791483 ROC AUC: 0.5228561304039688\n",
      "1 12 2.859516143798828\n",
      "Validation loss: 0.7203284553344677 ROC AUC: 0.586640680368533\n",
      "2 24 1.8867321014404297\n",
      "Validation loss: 0.8483730463792156 ROC AUC: 0.5602409638554217\n",
      "3 36 1.5645160675048828\n",
      "Validation loss: 0.8642526565008606 ROC AUC: 0.5933734939759037\n",
      "Validation loss: 0.9120154850530309 ROC AUC: 0.5710489014883062\n",
      "5 10 1.333267092704773\n",
      "Validation loss: 0.704245104694998 ROC AUC: 0.5981573352232459\n",
      "6 22 1.0862399339675903\n",
      "Validation loss: 0.929277526621787 ROC AUC: 0.5931963146704464\n",
      "7 34 1.001205563545227\n",
      "Validation loss: 0.7538066530069768 ROC AUC: 0.5976257973068746\n",
      "Validation loss: 0.7806479101938917 ROC AUC: 0.6188873139617292\n",
      "9 8 0.9200514554977417\n",
      "Validation loss: 1.189159957778375 ROC AUC: 0.5976257973068746\n",
      "10 20 0.9807267785072327\n",
      "Validation loss: 1.4223478550942528 ROC AUC: 0.6100283486888731\n",
      "11 32 0.9204393625259399\n",
      "Validation loss: 0.857717565353343 ROC AUC: 0.6261516654854713\n",
      "Validation loss: 1.5309304464731786 ROC AUC: 0.6374911410347271\n",
      "13 6 0.640738844871521\n",
      "Validation loss: 0.7765845703762888 ROC AUC: 0.6295180722891567\n",
      "14 18 0.6386753916740417\n",
      "Validation loss: 1.0946508728905229 ROC AUC: 0.6624734231041814\n",
      "15 30 0.5468029975891113\n",
      "Validation loss: 0.9265214690309487 ROC AUC: 0.6376683203401843\n",
      "Validation loss: 1.272860226252221 ROC AUC: 0.6638908575478384\n",
      "17 4 0.6107444763183594\n",
      "Validation loss: 0.8324522579347851 ROC AUC: 0.634479092841956\n",
      "18 16 0.484741747379303\n",
      "Validation loss: 1.2881920538990703 ROC AUC: 0.6532600992204111\n",
      "19 28 0.6327037811279297\n",
      "Validation loss: 1.0934464686753733 ROC AUC: 0.6576895818568391\n",
      "Validation loss: 0.8507381421051278 ROC AUC: 0.6599929128277817\n",
      "21 2 0.6360036134719849\n",
      "Validation loss: 0.8445607471150278 ROC AUC: 0.6429836995038979\n",
      "22 14 0.5719332098960876\n",
      "Validation loss: 0.8457894704199784 ROC AUC: 0.6350106307583274\n",
      "23 26 0.37465471029281616\n",
      "Validation loss: 0.7291133956403921 ROC AUC: 0.6651311126860383\n",
      "Validation loss: 0.8829569662643584 ROC AUC: 0.6491849751948973\n",
      "25 0 0.41178321838378906\n",
      "Validation loss: 0.8471523432542156 ROC AUC: 0.6472360028348688\n",
      "26 12 0.43886598944664\n",
      "Validation loss: 0.7823414482817744 ROC AUC: 0.6380226789510984\n",
      "27 24 0.41478317975997925\n",
      "Validation loss: 0.8636669248145148 ROC AUC: 0.651665485471297\n",
      "28 36 0.4944854974746704\n",
      "Validation loss: 0.8303922675303276 ROC AUC: 0.6661941885187811\n",
      "Validation loss: 0.8878182149091304 ROC AUC: 0.6523742026931254\n",
      "30 10 0.5545586347579956\n",
      "Validation loss: 0.9378040306615514 ROC AUC: 0.6796598157335224\n",
      "31 22 0.46454158425331116\n",
      "Validation loss: 0.8111075210255503 ROC AUC: 0.666194188518781\n",
      "32 34 0.4750812351703644\n",
      "Validation loss: 0.9247781685646007 ROC AUC: 0.6383770375620127\n",
      "Validation loss: 0.85922209237585 ROC AUC: 0.6684975194897236\n",
      "34 8 0.345730721950531\n",
      "Validation loss: 0.7676019779104271 ROC AUC: 0.6796598157335223\n",
      "35 20 0.5635301470756531\n",
      "Validation loss: 0.8386994126616725 ROC AUC: 0.6904677533664068\n",
      "36 32 0.5604934692382812\n",
      "Validation loss: 1.1966151334592048 ROC AUC: 0.6874557051736357\n",
      "Validation loss: 0.7465703957128209 ROC AUC: 0.6649539333805812\n",
      "38 6 0.45316022634506226\n",
      "Validation loss: 0.8250373720333276 ROC AUC: 0.6766477675407512\n",
      "39 18 0.43114203214645386\n",
      "Validation loss: 0.8672398589304741 ROC AUC: 0.660347271438696\n",
      "40 30 0.31083211302757263\n",
      "Validation loss: 0.7550697691787948 ROC AUC: 0.6824946846208363\n",
      "Validation loss: 0.6832183488946877 ROC AUC: 0.6986180014174346\n",
      "42 4 0.55583655834198\n",
      "Validation loss: 0.8288584466012109 ROC AUC: 0.6798369950389794\n",
      "43 16 0.32763734459877014\n",
      "Validation loss: 0.849119490740315 ROC AUC: 0.6766477675407512\n",
      "44 28 0.29034096002578735\n",
      "Validation loss: 0.8369035365565723 ROC AUC: 0.6617647058823529\n",
      "Validation loss: 0.7845281492795376 ROC AUC: 0.6598157335223244\n",
      "46 2 0.5583305358886719\n",
      "Validation loss: 0.8005808278030118 ROC AUC: 0.669029057406095\n",
      "47 14 0.4982392191886902\n",
      "Validation loss: 0.8568120780370093 ROC AUC: 0.6853295535081503\n",
      "48 26 0.37427568435668945\n",
      "Validation loss: 1.0151458094451602 ROC AUC: 0.6654854712969525\n",
      "Validation loss: 0.8333270683983304 ROC AUC: 0.6796598157335223\n",
      "50 0 0.28518080711364746\n",
      "Validation loss: 0.7691627429021115 ROC AUC: 0.6709780297661234\n",
      "51 12 0.47591519355773926\n",
      "Validation loss: 0.8141491018383709 ROC AUC: 0.6881644223954642\n",
      "52 24 0.3863523006439209\n",
      "Validation loss: 0.87593361241928 ROC AUC: 0.6913536498936924\n",
      "53 36 0.41219815611839294\n",
      "Validation loss: 0.942245364189148 ROC AUC: 0.6592841956059533\n",
      "Validation loss: 0.9525316495769072 ROC AUC: 0.6539688164422395\n",
      "55 10 0.4356290400028229\n",
      "Validation loss: 0.8447462126908712 ROC AUC: 0.6888731396172927\n",
      "56 22 0.38017019629478455\n",
      "Validation loss: 0.8119459592348692 ROC AUC: 0.6653082919914953\n",
      "57 34 0.3736943006515503\n",
      "Validation loss: 0.8760616266174822 ROC AUC: 0.6782423812898654\n",
      "Validation loss: 0.8267362003294837 ROC AUC: 0.6697377746279235\n",
      "59 8 0.3192828595638275\n",
      "Validation loss: 1.0531707686304257 ROC AUC: 0.6885187810063784\n",
      "60 20 0.3890368938446045\n",
      "Validation loss: 0.9945780903298334 ROC AUC: 0.6608788093550674\n",
      "61 32 0.5762597322463989\n",
      "Validation loss: 1.0057358986494558 ROC AUC: 0.6683203401842664\n",
      "Validation loss: 0.7858829336450589 ROC AUC: 0.6752303330970941\n",
      "63 6 0.2617453634738922\n",
      "Validation loss: 0.8769129806796446 ROC AUC: 0.7014528703047485\n",
      "64 18 0.4191323220729828\n",
      "Validation loss: 0.9167137627570044 ROC AUC: 0.6789510985116938\n",
      "65 30 0.41522154211997986\n",
      "Validation loss: 0.7677094411376296 ROC AUC: 0.6895818568391211\n",
      "Validation loss: 0.8196231229415792 ROC AUC: 0.6927710843373495\n",
      "67 4 0.29464033246040344\n",
      "Validation loss: 0.8392216772433149 ROC AUC: 0.6909992912827781\n",
      "68 16 0.34108132123947144\n",
      "Validation loss: 0.8969394600154549 ROC AUC: 0.6904677533664068\n",
      "69 28 0.3713020980358124\n",
      "Validation loss: 0.8625603997154742 ROC AUC: 0.7002126151665484\n",
      "Validation loss: 0.8565022463830102 ROC AUC: 0.6883416017009213\n",
      "71 2 0.3199065625667572\n",
      "Validation loss: 0.8662295669119879 ROC AUC: 0.6913536498936924\n",
      "72 14 0.23505178093910217\n",
      "Validation loss: 0.7908010707785752 ROC AUC: 0.6752303330970943\n",
      "73 26 0.38850468397140503\n",
      "Validation loss: 0.9365033037615138 ROC AUC: 0.7111977321048901\n",
      "Validation loss: 0.8235699396259737 ROC AUC: 0.7048192771084337\n",
      "75 0 0.29560208320617676\n",
      "Validation loss: 0.8691748333293081 ROC AUC: 0.6883416017009214\n",
      "76 12 0.33654725551605225\n",
      "Validation loss: 0.858693700752511 ROC AUC: 0.7005669737774628\n",
      "77 24 0.4306897521018982\n",
      "Validation loss: 0.8528179407909217 ROC AUC: 0.689227498228207\n",
      "78 36 0.3994846045970917\n",
      "Validation loss: 1.116945249355392 ROC AUC: 0.6686746987951807\n",
      "Validation loss: 0.799837908997441 ROC AUC: 0.6867469879518072\n",
      "80 10 0.43245795369148254\n",
      "Validation loss: 0.7730352791729352 ROC AUC: 0.7184620836286321\n",
      "81 22 0.4721682667732239\n",
      "Validation loss: 0.8672122517168916 ROC AUC: 0.6911764705882353\n",
      "82 34 0.566129207611084\n",
      "Validation loss: 0.9212143097492244 ROC AUC: 0.6700921332388378\n",
      "Validation loss: 0.9979009249352462 ROC AUC: 0.6383770375620128\n",
      "84 8 0.3876437842845917\n",
      "Validation loss: 0.9066330005001548 ROC AUC: 0.6918851878100637\n",
      "85 20 0.41899633407592773\n",
      "Validation loss: 0.8934937468822429 ROC AUC: 0.6885187810063784\n",
      "86 32 0.2607397139072418\n",
      "Validation loss: 0.89588677567362 ROC AUC: 0.6750531537916371\n",
      "Validation loss: 0.9653761781604084 ROC AUC: 0.6895818568391211\n",
      "88 6 0.4425412118434906\n",
      "Validation loss: 1.0450501347219707 ROC AUC: 0.6791282778171509\n",
      "89 18 0.26608365774154663\n",
      "Validation loss: 0.8165396096690601 ROC AUC: 0.7227143869596031\n",
      "90 30 0.2968340218067169\n",
      "Validation loss: 0.9995015354345966 ROC AUC: 0.7071226080793764\n",
      "Validation loss: 1.0229655046336699 ROC AUC: 0.6941885187810064\n",
      "92 4 0.38064950704574585\n",
      "Validation loss: 0.8750226458176872 ROC AUC: 0.7170446491849752\n",
      "93 16 0.45236724615097046\n",
      "Validation loss: 0.7862225001221461 ROC AUC: 0.670623671155209\n",
      "94 28 0.49145960807800293\n",
      "Validation loss: 0.8663925670630095 ROC AUC: 0.6883416017009213\n",
      "Validation loss: 0.9777430532783862 ROC AUC: 0.6874557051736356\n",
      "96 2 0.38425615429878235\n",
      "Validation loss: 1.070522034405083 ROC AUC: 0.6653082919914954\n",
      "97 14 0.3052527904510498\n",
      "Validation loss: 0.8833882879737197 ROC AUC: 0.6860382707299787\n",
      "98 26 0.30418097972869873\n",
      "Validation loss: 0.8414347827039808 ROC AUC: 0.6814316087880936\n",
      "Validation loss: 1.000467416071734 ROC AUC: 0.7165131112686037\n",
      "100 0 0.39745697379112244\n",
      "Validation loss: 0.9925374384747435 ROC AUC: 0.6849751948972359\n",
      "101 12 0.3235698640346527\n",
      "Validation loss: 1.0333411543574553 ROC AUC: 0.683557760453579\n",
      "102 24 0.24691297113895416\n",
      "Validation loss: 0.9151193629826931 ROC AUC: 0.7181077250177179\n",
      "103 36 0.4074835777282715\n",
      "Validation loss: 0.9005073226050825 ROC AUC: 0.6925939050318922\n",
      "Validation loss: 0.9813460680033197 ROC AUC: 0.6952515946137492\n",
      "105 10 0.29666608572006226\n",
      "Validation loss: 0.9469869973643726 ROC AUC: 0.6633593196314671\n",
      "106 22 0.21502384543418884\n",
      "Validation loss: 0.9108183253679843 ROC AUC: 0.6977321048901489\n",
      "107 34 0.4743250012397766\n",
      "Validation loss: 0.8448418584090984 ROC AUC: 0.6871013465627215\n",
      "Validation loss: 0.8910493937549212 ROC AUC: 0.6824946846208363\n",
      "109 8 0.28362053632736206\n",
      "Validation loss: 1.1461516523992779 ROC AUC: 0.7101346562721474\n",
      "110 20 0.2649645209312439\n",
      "Validation loss: 0.9629694144457381 ROC AUC: 0.6789510985116939\n",
      "111 32 0.3695666193962097\n",
      "Validation loss: 0.8341625534146038 ROC AUC: 0.6954287739192062\n",
      "Validation loss: 0.8759898705198276 ROC AUC: 0.710843373493976\n",
      "113 6 0.7032792568206787\n",
      "Validation loss: 1.0459094458068443 ROC AUC: 0.6869241672572644\n",
      "114 18 0.3492027223110199\n",
      "Validation loss: 0.947133004270642 ROC AUC: 0.6934798015591779\n",
      "115 30 0.29154878854751587\n",
      "Validation loss: 0.9904857546288446 ROC AUC: 0.7058823529411764\n",
      "Validation loss: 0.9400270924662912 ROC AUC: 0.7207654145995748\n",
      "117 4 0.2849518358707428\n",
      "Validation loss: 0.9309967018121126 ROC AUC: 0.7035790219702338\n",
      "118 16 0.22270329296588898\n",
      "Validation loss: 1.149233971210505 ROC AUC: 0.66194188518781\n",
      "119 28 0.30779436230659485\n",
      "Validation loss: 0.9299363219580113 ROC AUC: 0.7046420978029765\n",
      "Validation loss: 0.8362309032718077 ROC AUC: 0.7218284904323176\n",
      "121 2 0.2827584147453308\n",
      "Validation loss: 0.9931845617610098 ROC AUC: 0.6869241672572644\n",
      "122 14 0.20966129004955292\n",
      "Validation loss: 0.836469010406772 ROC AUC: 0.7278525868178597\n",
      "123 26 0.5797887444496155\n",
      "Validation loss: 1.023716992100343 ROC AUC: 0.6773564847625797\n",
      "Validation loss: 1.001025988566165 ROC AUC: 0.6723954642097804\n",
      "125 0 0.3568798899650574\n",
      "Validation loss: 0.9430430417029273 ROC AUC: 0.7250177179305456\n",
      "126 12 0.19909757375717163\n",
      "Validation loss: 1.0495869308118 ROC AUC: 0.683557760453579\n",
      "127 24 0.2749767303466797\n",
      "Validation loss: 1.0283401715044944 ROC AUC: 0.6895818568391212\n",
      "128 36 0.2889627516269684\n",
      "Validation loss: 0.931398924612841 ROC AUC: 0.6874557051736357\n",
      "Validation loss: 1.0134777454350958 ROC AUC: 0.7135010630758327\n",
      "130 10 0.24794265627861023\n",
      "Validation loss: 0.8987162973707086 ROC AUC: 0.7012756909992913\n",
      "131 22 0.1737470030784607\n",
      "Validation loss: 0.9863520647516314 ROC AUC: 0.7055279943302623\n",
      "132 34 0.31119969487190247\n",
      "Validation loss: 1.163531056303062 ROC AUC: 0.7122608079376329\n",
      "Validation loss: 0.9551100028271706 ROC AUC: 0.6750531537916371\n",
      "134 8 0.33681225776672363\n",
      "Validation loss: 1.0582279030060926 ROC AUC: 0.6940113394755493\n",
      "135 20 0.21516120433807373\n",
      "Validation loss: 1.0092509728393808 ROC AUC: 0.7179305457122608\n",
      "136 32 0.21068713068962097\n",
      "Validation loss: 0.8926563105046355 ROC AUC: 0.7197023387668321\n",
      "Validation loss: 1.0968408249071893 ROC AUC: 0.6934798015591779\n",
      "138 6 0.20107370615005493\n",
      "Validation loss: 1.2283416204894615 ROC AUC: 0.6550318922749823\n",
      "139 18 0.16591957211494446\n",
      "Validation loss: 1.0378829485533254 ROC AUC: 0.6851523742026931\n",
      "140 30 0.1991480439901352\n",
      "Validation loss: 1.0147310400640728 ROC AUC: 0.7062367115520907\n",
      "Validation loss: 1.0300379312591048 ROC AUC: 0.6858610914245216\n",
      "142 4 0.3621271550655365\n",
      "Validation loss: 1.0594930329070187 ROC AUC: 0.7087172218284905\n",
      "143 16 0.1788327395915985\n",
      "Validation loss: 0.9533957708750339 ROC AUC: 0.7083628632175762\n",
      "144 28 0.24429161846637726\n",
      "Validation loss: 0.98631559263002 ROC AUC: 0.7163359319631467\n",
      "Validation loss: 0.9370318982774848 ROC AUC: 0.7005669737774628\n",
      "146 2 0.2054571509361267\n",
      "Validation loss: 1.1668227982047379 ROC AUC: 0.657335223245925\n",
      "147 14 0.1265323907136917\n",
      "Validation loss: 1.0461282990626153 ROC AUC: 0.7106661941885188\n",
      "148 26 0.217335507273674\n",
      "Validation loss: 1.2533344906686947 ROC AUC: 0.6860382707299788\n",
      "Validation loss: 1.2780136994968188 ROC AUC: 0.6828490432317504\n",
      "150 0 0.13388127088546753\n",
      "Validation loss: 1.354753212423514 ROC AUC: 0.6996810772501771\n",
      "151 12 0.27567189931869507\n",
      "Validation loss: 1.1130516773817556 ROC AUC: 0.7035790219702339\n",
      "152 24 0.2833009958267212\n",
      "Validation loss: 1.314660883502455 ROC AUC: 0.6523742026931254\n",
      "153 36 0.18176671862602234\n",
      "Validation loss: 1.3756518963946411 ROC AUC: 0.6688518781006378\n",
      "Validation loss: 1.1242444337598536 ROC AUC: 0.6963146704464919\n",
      "155 10 0.20012059807777405\n",
      "Validation loss: 1.163112991693004 ROC AUC: 0.6812544294826365\n",
      "156 22 0.34693968296051025\n",
      "Validation loss: 1.0914397373894194 ROC AUC: 0.6911764705882353\n",
      "157 34 0.24360330402851105\n",
      "Validation loss: 1.147931627879869 ROC AUC: 0.6940113394755493\n",
      "Validation loss: 1.0366396288208615 ROC AUC: 0.6979092841956059\n",
      "159 8 0.30631956458091736\n",
      "Validation loss: 1.1725031788775464 ROC AUC: 0.6927710843373494\n",
      "160 20 0.1974705159664154\n",
      "Validation loss: 0.8691920507822605 ROC AUC: 0.729801559177888\n",
      "161 32 0.3073437213897705\n",
      "Validation loss: 1.1256449798874508 ROC AUC: 0.6922395464209781\n",
      "Validation loss: 1.227107498424732 ROC AUC: 0.6922395464209781\n",
      "163 6 0.29754507541656494\n",
      "Validation loss: 1.2247331730577329 ROC AUC: 0.6894046775336641\n",
      "164 18 0.2894010543823242\n",
      "Validation loss: 1.2077419726264398 ROC AUC: 0.6909992912827783\n",
      "165 30 0.16173191368579865\n",
      "Validation loss: 1.0560095041792914 ROC AUC: 0.6746987951807228\n",
      "Validation loss: 1.2617004478214593 ROC AUC: 0.6541459957476967\n",
      "167 4 0.2999379336833954\n",
      "Validation loss: 1.273407279458267 ROC AUC: 0.6617647058823529\n",
      "168 16 0.1919858604669571\n",
      "Validation loss: 1.1508648166593336 ROC AUC: 0.6743444365698086\n",
      "169 28 0.24398551881313324\n",
      "Validation loss: 1.231903383273952 ROC AUC: 0.6771793054571226\n",
      "Validation loss: 1.241362945133487 ROC AUC: 0.702338766832034\n",
      "171 2 0.08237844705581665\n",
      "Validation loss: 1.149105548069177 ROC AUC: 0.6390857547838412\n",
      "172 14 0.27427732944488525\n",
      "Validation loss: 1.1268814806117127 ROC AUC: 0.6964918497519489\n",
      "173 26 0.16109025478363037\n",
      "Validation loss: 1.1177378837635974 ROC AUC: 0.7088944011339475\n",
      "Validation loss: 1.2032216586024556 ROC AUC: 0.6881644223954643\n",
      "175 0 0.1495293825864792\n",
      "Validation loss: 1.1334145617800833 ROC AUC: 0.7136782423812899\n",
      "176 12 0.2335413545370102\n",
      "Validation loss: 1.3192199934397313 ROC AUC: 0.6794826364280652\n",
      "177 24 0.3587917685508728\n",
      "Validation loss: 1.2655526119352176 ROC AUC: 0.6956059532246635\n",
      "178 36 0.20101839303970337\n",
      "Validation loss: 1.0450244889354074 ROC AUC: 0.7117292700212615\n",
      "Validation loss: 1.2005601671357817 ROC AUC: 0.7186392629340893\n",
      "180 10 0.2524110972881317\n",
      "Validation loss: 1.0572505763034947 ROC AUC: 0.6979092841956059\n",
      "181 22 0.3444823920726776\n",
      "Validation loss: 1.1093410762730023 ROC AUC: 0.6739900779588943\n",
      "182 34 0.21520784497261047\n",
      "Validation loss: 1.2041752930508545 ROC AUC: 0.7103118355776045\n",
      "Validation loss: 1.2443356790289974 ROC AUC: 0.7064138908575478\n",
      "184 8 0.12454283237457275\n",
      "Validation loss: 1.3034985175985374 ROC AUC: 0.6996810772501773\n",
      "185 20 0.14009059965610504\n",
      "Validation loss: 1.1642052037826438 ROC AUC: 0.7202338766832034\n",
      "186 32 0.16885718703269958\n",
      "Validation loss: 1.2010407416236322 ROC AUC: 0.7163359319631467\n",
      "Validation loss: 1.2746162785599564 ROC AUC: 0.6938341601700921\n",
      "188 6 0.18031840026378632\n",
      "Validation loss: 1.3272501814444333 ROC AUC: 0.7032246633593197\n",
      "189 18 0.16203923523426056\n",
      "Validation loss: 1.2812918661445971 ROC AUC: 0.6927710843373494\n",
      "190 30 0.15868327021598816\n",
      "Validation loss: 1.407678874912641 ROC AUC: 0.6888731396172927\n",
      "Validation loss: 1.3559518815665845 ROC AUC: 0.6837349397590362\n",
      "192 4 0.15821655094623566\n",
      "Validation loss: 1.2765526250498185 ROC AUC: 0.6725726435152375\n",
      "193 16 0.07127968221902847\n",
      "Validation loss: 1.2556933275121727 ROC AUC: 0.6998582565556343\n",
      "194 28 0.19015753269195557\n",
      "Validation loss: 1.1291382644350165 ROC AUC: 0.7209425939050319\n",
      "Validation loss: 1.2520712203537392 ROC AUC: 0.695074415308292\n",
      "196 2 0.10315565019845963\n",
      "Validation loss: 1.3020152161452945 ROC AUC: 0.7094259390503188\n",
      "197 14 0.12409151345491409\n",
      "Validation loss: 1.0913615664898955 ROC AUC: 0.7035790219702338\n",
      "198 26 0.20000457763671875\n",
      "Validation loss: 1.1835667652799593 ROC AUC: 0.6826718639262933\n",
      "Validation loss: 1.1330009209399192 ROC AUC: 0.6886959603118356\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.980212173963848 Test ROC AUC: 0.7940217391304348\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bace', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 780, 'task': 'classification', 'data_path': 'data/bace/bace.csv', 'target': ['Class']}}\n",
      "Running on: cuda:1\n",
      "1512\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1512\n",
      "Generating scaffold 1000/1512\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 8.320860862731934\n",
      "Validation loss: 0.7212384741827352 ROC AUC: 0.48830616583982994\n",
      "1 12 2.628450870513916\n",
      "Validation loss: 0.7109084646433395 ROC AUC: 0.5710489014883061\n",
      "2 24 1.9024138450622559\n",
      "Validation loss: 0.8015232930909719 ROC AUC: 0.6001063075832743\n",
      "3 36 1.4088366031646729\n",
      "Validation loss: 0.8437228550184641 ROC AUC: 0.5777817150956769\n",
      "Validation loss: 0.8927245222969561 ROC AUC: 0.5558114812189936\n",
      "5 10 1.3141310214996338\n",
      "Validation loss: 1.0817230481975126 ROC AUC: 0.6298724309000708\n",
      "6 22 1.0629799365997314\n",
      "Validation loss: 0.9724912469750209 ROC AUC: 0.5444720056697377\n",
      "7 34 1.0283982753753662\n",
      "Validation loss: 0.7953374117415473 ROC AUC: 0.6344790928419559\n",
      "Validation loss: 0.6764463103370161 ROC AUC: 0.6686746987951808\n",
      "9 8 0.8962830305099487\n",
      "Validation loss: 0.9239124651776244 ROC AUC: 0.6017009213323883\n",
      "10 20 0.7511600852012634\n",
      "Validation loss: 0.735284397538924 ROC AUC: 0.6112686038270729\n",
      "11 32 0.6991647481918335\n",
      "Validation loss: 0.8522078461994399 ROC AUC: 0.6218993621545004\n",
      "Validation loss: 0.7366742156199272 ROC AUC: 0.6381998582565556\n",
      "13 6 0.5433109998703003\n",
      "Validation loss: 0.86185798108183 ROC AUC: 0.6525513819985825\n",
      "14 18 0.6449999213218689\n",
      "Validation loss: 0.7253166614778784 ROC AUC: 0.6467044649184975\n",
      "15 30 0.6598292589187622\n",
      "Validation loss: 0.9402621104227786 ROC AUC: 0.5862863217576187\n",
      "Validation loss: 0.8139831723756348 ROC AUC: 0.5777817150956768\n",
      "17 4 0.6744369864463806\n",
      "Validation loss: 1.2466815623226544 ROC AUC: 0.6215450035435862\n",
      "18 16 0.49659454822540283\n",
      "Validation loss: 1.0920831525562615 ROC AUC: 0.6731041814316088\n",
      "19 28 0.5747975707054138\n",
      "Validation loss: 0.8188708444304814 ROC AUC: 0.6566265060240963\n",
      "Validation loss: 0.9973678091503927 ROC AUC: 0.66194188518781\n",
      "21 2 0.5834991335868835\n",
      "Validation loss: 1.1093959950453398 ROC AUC: 0.6373139617292699\n",
      "22 14 0.47396308183670044\n",
      "Validation loss: 0.8821880813466002 ROC AUC: 0.6654854712969525\n",
      "23 26 0.538747251033783\n",
      "Validation loss: 0.7742021482511862 ROC AUC: 0.6716867469879518\n",
      "Validation loss: 0.7046158451907683 ROC AUC: 0.6812544294826364\n",
      "25 0 0.6364490389823914\n",
      "Validation loss: 0.8791107176155444 ROC AUC: 0.6546775336640679\n",
      "26 12 0.4879918396472931\n",
      "Validation loss: 0.8712312448893161 ROC AUC: 0.6647767540751239\n",
      "27 24 0.46483373641967773\n",
      "Validation loss: 0.8494505005956485 ROC AUC: 0.6610559886605245\n",
      "28 36 0.5071491003036499\n",
      "Validation loss: 0.8111328466838559 ROC AUC: 0.6665485471296951\n",
      "Validation loss: 0.8636331897697701 ROC AUC: 0.6024096385542168\n",
      "30 10 0.588309645652771\n",
      "Validation loss: 0.9323314977007986 ROC AUC: 0.6709780297661234\n",
      "31 22 0.5090775489807129\n",
      "Validation loss: 0.8344467345452466 ROC AUC: 0.6406803685329553\n",
      "32 34 0.525040864944458\n",
      "Validation loss: 0.7678064621047468 ROC AUC: 0.7025159461374911\n",
      "Validation loss: 0.9258651251824487 ROC AUC: 0.6530829199149539\n",
      "34 8 0.393919974565506\n",
      "Validation loss: 0.99027551009955 ROC AUC: 0.677710843373494\n",
      "35 20 0.5206812024116516\n",
      "Validation loss: 0.7494261505588001 ROC AUC: 0.6775336640680368\n",
      "36 32 0.5702389478683472\n",
      "Validation loss: 0.7861109214113248 ROC AUC: 0.6305811481218995\n",
      "Validation loss: 0.9214456795856653 ROC AUC: 0.6663713678242381\n",
      "38 6 0.37430262565612793\n",
      "Validation loss: 0.8748394053503378 ROC AUC: 0.6314670446491849\n",
      "39 18 0.6476100087165833\n",
      "Validation loss: 0.7756494563936398 ROC AUC: 0.6474131821403261\n",
      "40 30 0.41931554675102234\n",
      "Validation loss: 0.9547837546329625 ROC AUC: 0.6683203401842664\n",
      "Validation loss: 0.9582197745114762 ROC AUC: 0.6621190644932672\n",
      "42 4 0.42204082012176514\n",
      "Validation loss: 0.7322503265166125 ROC AUC: 0.6768249468462083\n",
      "43 16 0.42066705226898193\n",
      "Validation loss: 0.8724209780724633 ROC AUC: 0.6874557051736357\n",
      "44 28 0.4721122980117798\n",
      "Validation loss: 0.7981701552473157 ROC AUC: 0.6809000708717221\n",
      "Validation loss: 0.7932778766613133 ROC AUC: 0.6970233876683204\n",
      "46 2 0.44434526562690735\n",
      "Validation loss: 0.735229818828848 ROC AUC: 0.7003897944720058\n",
      "47 14 0.4801638722419739\n",
      "Validation loss: 0.8453598906662291 ROC AUC: 0.645995747696669\n",
      "48 26 0.3657791018486023\n",
      "Validation loss: 0.8329897984763645 ROC AUC: 0.6674344436569809\n",
      "Validation loss: 0.8602424165270975 ROC AUC: 0.6729270021261516\n",
      "50 0 0.47311440110206604\n",
      "Validation loss: 0.9656946303828663 ROC AUC: 0.6830262225372076\n",
      "51 12 0.4200417101383209\n",
      "Validation loss: 0.8546002483525813 ROC AUC: 0.6904677533664068\n",
      "52 24 0.5403254628181458\n",
      "Validation loss: 0.7429214826482811 ROC AUC: 0.6846208362863218\n",
      "53 36 0.529854953289032\n",
      "Validation loss: 0.8228669056039772 ROC AUC: 0.6858610914245216\n",
      "Validation loss: 0.7639041795635855 ROC AUC: 0.6723954642097804\n",
      "55 10 0.3875466287136078\n",
      "Validation loss: 0.7679392225694972 ROC AUC: 0.6906449326718639\n",
      "56 22 0.44331663846969604\n",
      "Validation loss: 0.928947173996477 ROC AUC: 0.6764705882352942\n",
      "57 34 0.4252232313156128\n",
      "Validation loss: 0.8805153117274607 ROC AUC: 0.660347271438696\n",
      "Validation loss: 0.9911545215063537 ROC AUC: 0.6614103472714387\n",
      "59 8 0.45728805661201477\n",
      "Validation loss: 0.8134797819402834 ROC AUC: 0.6807228915662651\n",
      "60 20 0.3723021149635315\n",
      "Validation loss: 0.8171286302686527 ROC AUC: 0.6814316087880935\n",
      "61 32 0.42353948950767517\n",
      "Validation loss: 0.8478983968298957 ROC AUC: 0.6956059532246633\n",
      "Validation loss: 0.8221665541857284 ROC AUC: 0.7140326009922041\n",
      "63 6 0.4053565561771393\n",
      "Validation loss: 0.8445177042721123 ROC AUC: 0.6812544294826364\n",
      "64 18 0.5689381957054138\n",
      "Validation loss: 1.0416617148759348 ROC AUC: 0.6863926293408931\n",
      "65 30 0.4115961194038391\n",
      "Validation loss: 0.771747068458835 ROC AUC: 0.7085400425230333\n",
      "Validation loss: 0.9046906651250574 ROC AUC: 0.6952515946137491\n",
      "67 4 0.25529706478118896\n",
      "Validation loss: 0.9001711985922807 ROC AUC: 0.6832034018426647\n",
      "68 16 0.3530418276786804\n",
      "Validation loss: 0.9582941413715186 ROC AUC: 0.7103118355776046\n",
      "69 28 0.3521806597709656\n",
      "Validation loss: 0.7365981107516004 ROC AUC: 0.7166902905740609\n",
      "Validation loss: 0.9822882619125164 ROC AUC: 0.6684975194897236\n",
      "71 2 0.33825546503067017\n",
      "Validation loss: 0.9757708453184721 ROC AUC: 0.684975194897236\n",
      "72 14 0.2961897850036621\n",
      "Validation loss: 1.1557628547908454 ROC AUC: 0.6332388377037561\n",
      "73 26 0.2763376235961914\n",
      "Validation loss: 0.7609025275470406 ROC AUC: 0.67363571934798\n",
      "Validation loss: 0.9363287971509213 ROC AUC: 0.6628277817150957\n",
      "75 0 0.2786220908164978\n",
      "Validation loss: 1.0284575444973068 ROC AUC: 0.7057051736357193\n",
      "76 12 0.26759591698646545\n",
      "Validation loss: 0.9454207120352234 ROC AUC: 0.7083628632175762\n",
      "77 24 0.5167739987373352\n",
      "Validation loss: 0.9221119351734389 ROC AUC: 0.7025159461374911\n",
      "78 36 0.48491740226745605\n",
      "Validation loss: 0.8926075337738391 ROC AUC: 0.6637136782423814\n",
      "Validation loss: 0.8395603741241606 ROC AUC: 0.6901133947554925\n",
      "80 10 0.43993431329727173\n",
      "Validation loss: 0.8496433768840815 ROC AUC: 0.7092487597448618\n",
      "81 22 0.23431459069252014\n",
      "Validation loss: 0.8638373893617795 ROC AUC: 0.7023387668320341\n",
      "82 34 0.4279775619506836\n",
      "Validation loss: 1.1481220915617532 ROC AUC: 0.6055988660524451\n",
      "Validation loss: 0.8556566068668239 ROC AUC: 0.6821403260099219\n",
      "84 8 0.3703538477420807\n",
      "Validation loss: 0.9493348519533675 ROC AUC: 0.6679659815733523\n",
      "85 20 0.38870006799697876\n",
      "Validation loss: 0.9114048216516608 ROC AUC: 0.6909992912827781\n",
      "86 32 0.31376180052757263\n",
      "Validation loss: 0.9061862182932974 ROC AUC: 0.708185683912119\n",
      "Validation loss: 0.8180300269695308 ROC AUC: 0.7005669737774629\n",
      "88 6 0.27540066838264465\n",
      "Validation loss: 0.7674550650925036 ROC AUC: 0.6954287739192062\n",
      "89 18 0.3398922383785248\n",
      "Validation loss: 0.9365021337736521 ROC AUC: 0.6986180014174345\n",
      "90 30 0.3798222243785858\n",
      "Validation loss: 0.9176050566679594 ROC AUC: 0.6787739192062368\n",
      "Validation loss: 0.962293142514513 ROC AUC: 0.682140326009922\n",
      "92 4 0.2819809913635254\n",
      "Validation loss: 0.8757029361282753 ROC AUC: 0.7078313253012047\n",
      "93 16 0.3165338635444641\n",
      "Validation loss: 0.9234898335096852 ROC AUC: 0.6897590361445783\n",
      "94 28 0.23189376294612885\n",
      "Validation loss: 0.9140298366546631 ROC AUC: 0.7067682494684622\n",
      "Validation loss: 0.9370598307508506 ROC AUC: 0.7124379872430899\n",
      "96 2 0.2222827523946762\n",
      "Validation loss: 0.7951215272707655 ROC AUC: 0.7236002834868887\n",
      "97 14 0.3033866286277771\n",
      "Validation loss: 0.8109227482056776 ROC AUC: 0.7227143869596031\n",
      "98 26 0.24702765047550201\n",
      "Validation loss: 0.785243534883916 ROC AUC: 0.7088944011339475\n",
      "Validation loss: 0.8942478437297392 ROC AUC: 0.6909992912827781\n",
      "100 0 0.18245357275009155\n",
      "Validation loss: 0.8574855998651871 ROC AUC: 0.6947200566973777\n",
      "101 12 0.32048219442367554\n",
      "Validation loss: 0.8313961609309872 ROC AUC: 0.7099574769666903\n",
      "102 24 0.4634622037410736\n",
      "Validation loss: 0.9321513768063475 ROC AUC: 0.7285613040396882\n",
      "103 36 0.1991899162530899\n",
      "Validation loss: 0.898429204296592 ROC AUC: 0.687987243090007\n",
      "Validation loss: 0.8974936391344134 ROC AUC: 0.715450035435861\n",
      "105 10 0.21965184807777405\n",
      "Validation loss: 0.7848271842034448 ROC AUC: 0.7340538625088591\n",
      "106 22 0.38000670075416565\n",
      "Validation loss: 0.9347201506823104 ROC AUC: 0.6991495393338059\n",
      "107 34 0.2431229203939438\n",
      "Validation loss: 0.8412935907477574 ROC AUC: 0.7096031183557759\n",
      "Validation loss: 0.8364381533584847 ROC AUC: 0.731218993621545\n",
      "109 8 0.3644220232963562\n",
      "Validation loss: 0.9249552117278245 ROC AUC: 0.7060595322466336\n",
      "110 20 0.25363650918006897\n",
      "Validation loss: 0.8541112984253081 ROC AUC: 0.6989723600283487\n",
      "111 32 0.3937256932258606\n",
      "Validation loss: 0.9503364014309763 ROC AUC: 0.7108433734939759\n",
      "Validation loss: 0.8221330970328375 ROC AUC: 0.7184620836286322\n",
      "113 6 0.2565150260925293\n",
      "Validation loss: 0.9697719011085713 ROC AUC: 0.6826718639262934\n",
      "114 18 0.2892541289329529\n",
      "Validation loss: 0.7314633067869982 ROC AUC: 0.7383061658398299\n",
      "115 30 0.3204006552696228\n",
      "Validation loss: 0.8129567807873354 ROC AUC: 0.7159815733522324\n",
      "Validation loss: 1.005646863915273 ROC AUC: 0.7103118355776046\n",
      "117 4 0.26170068979263306\n",
      "Validation loss: 0.8378216391367628 ROC AUC: 0.6993267186392629\n",
      "118 16 0.31416165828704834\n",
      "Validation loss: 0.8555543454277594 ROC AUC: 0.7161587526576896\n",
      "119 28 0.21681107580661774\n",
      "Validation loss: 0.830432850004032 ROC AUC: 0.7057051736357193\n",
      "Validation loss: 1.1370255426065812 ROC AUC: 0.6732813607370659\n",
      "121 2 0.2564030587673187\n",
      "Validation loss: 1.0400587284801812 ROC AUC: 0.666194188518781\n",
      "122 14 0.34474217891693115\n",
      "Validation loss: 0.9490793240780862 ROC AUC: 0.6883416017009213\n",
      "123 26 0.3716941773891449\n",
      "Validation loss: 1.1991981836344232 ROC AUC: 0.7104890148830617\n",
      "Validation loss: 0.7729931919779999 ROC AUC: 0.7064138908575479\n",
      "125 0 0.3534504473209381\n",
      "Validation loss: 1.014072981891253 ROC AUC: 0.7197023387668321\n",
      "126 12 0.3704909086227417\n",
      "Validation loss: 0.9475278068851951 ROC AUC: 0.7143869596031184\n",
      "127 24 0.34173306822776794\n",
      "Validation loss: 1.007952017499911 ROC AUC: 0.7104890148830617\n",
      "128 36 0.32792630791664124\n",
      "Validation loss: 0.7704245598110931 ROC AUC: 0.7391920623671155\n",
      "Validation loss: 0.8467121795313248 ROC AUC: 0.7048192771084337\n",
      "130 10 0.49234214425086975\n",
      "Validation loss: 1.053567147412837 ROC AUC: 0.6826718639262934\n",
      "131 22 0.2558208107948303\n",
      "Validation loss: 0.8217341718294763 ROC AUC: 0.7299787384833452\n",
      "132 34 0.3863236606121063\n",
      "Validation loss: 1.180267648981107 ROC AUC: 0.6775336640680368\n",
      "Validation loss: 0.9342709621846281 ROC AUC: 0.7062367115520908\n",
      "134 8 0.19766397774219513\n",
      "Validation loss: 0.9026244187986614 ROC AUC: 0.7142097802976612\n",
      "135 20 0.4203917384147644\n",
      "Validation loss: 0.9455736676194021 ROC AUC: 0.7168674698795181\n",
      "136 32 0.3868187963962555\n",
      "Validation loss: 0.9901532414338446 ROC AUC: 0.7127923458540043\n",
      "Validation loss: 0.9064842040175634 ROC AUC: 0.7120836286321758\n",
      "138 6 0.41652610898017883\n",
      "Validation loss: 0.889876315925295 ROC AUC: 0.6970233876683203\n",
      "139 18 0.29885607957839966\n",
      "Validation loss: 0.9912562074250733 ROC AUC: 0.7018072289156626\n",
      "140 30 0.22417041659355164\n",
      "Validation loss: 1.0144208251245763 ROC AUC: 0.7271438695960312\n",
      "Validation loss: 0.9990199141155015 ROC AUC: 0.7067682494684621\n",
      "142 4 0.170108363032341\n",
      "Validation loss: 0.9001204726711803 ROC AUC: 0.7078313253012047\n",
      "143 16 0.1824893206357956\n",
      "Validation loss: 1.07227982432637 ROC AUC: 0.6911764705882353\n",
      "144 28 0.3763125538825989\n",
      "Validation loss: 0.9705029781291027 ROC AUC: 0.7227143869596031\n",
      "Validation loss: 0.9506153188004399 ROC AUC: 0.6812544294826364\n",
      "146 2 0.2143474817276001\n",
      "Validation loss: 0.9326574387929297 ROC AUC: 0.7209425939050319\n",
      "147 14 0.23453691601753235\n",
      "Validation loss: 1.1890499899718936 ROC AUC: 0.7067682494684621\n",
      "148 26 0.27876415848731995\n",
      "Validation loss: 0.9962777487489561 ROC AUC: 0.7182849043231749\n",
      "Validation loss: 0.926545789304948 ROC AUC: 0.705173635719348\n",
      "150 0 0.2522618770599365\n",
      "Validation loss: 0.9406164935882518 ROC AUC: 0.7003897944720057\n",
      "151 12 0.23016220331192017\n",
      "Validation loss: 1.343387991387323 ROC AUC: 0.669029057406095\n",
      "152 24 0.4805084764957428\n",
      "Validation loss: 0.9591153575884586 ROC AUC: 0.7161587526576895\n",
      "153 36 0.22479762136936188\n",
      "Validation loss: 0.9400474590970981 ROC AUC: 0.6894046775336641\n",
      "Validation loss: 1.194843565391389 ROC AUC: 0.6842664776754075\n",
      "155 10 0.3275657594203949\n",
      "Validation loss: 0.9600689486162552 ROC AUC: 0.7377746279234586\n",
      "156 22 0.31761234998703003\n",
      "Validation loss: 1.1147891756714574 ROC AUC: 0.7085400425230333\n",
      "157 34 0.5760822296142578\n",
      "Validation loss: 0.9758691856797957 ROC AUC: 0.719702338766832\n",
      "Validation loss: 1.1189382680204532 ROC AUC: 0.7018072289156626\n",
      "159 8 0.19215433299541473\n",
      "Validation loss: 1.079666819793499 ROC AUC: 0.6920623671155208\n",
      "160 20 0.49226123094558716\n",
      "Validation loss: 0.870765538405109 ROC AUC: 0.7179305457122608\n",
      "161 32 0.3246586322784424\n",
      "Validation loss: 1.1429236440469097 ROC AUC: 0.68781006378455\n",
      "Validation loss: 1.0265315072425942 ROC AUC: 0.6979092841956058\n",
      "163 6 0.34264570474624634\n",
      "Validation loss: 0.8908695945676589 ROC AUC: 0.6977321048901488\n",
      "164 18 0.2405596673488617\n",
      "Validation loss: 1.038715546494288 ROC AUC: 0.7475194897236003\n",
      "165 30 0.4025386869907379\n",
      "Validation loss: 1.1471617490250543 ROC AUC: 0.7094259390503189\n",
      "Validation loss: 1.0066661234723022 ROC AUC: 0.7347625797306875\n",
      "167 4 0.22856780886650085\n",
      "Validation loss: 1.295648465093398 ROC AUC: 0.7108433734939759\n",
      "168 16 0.21593083441257477\n",
      "Validation loss: 1.1220892048039972 ROC AUC: 0.7092487597448618\n",
      "169 28 0.2756783366203308\n",
      "Validation loss: 0.9895687462478284 ROC AUC: 0.6986180014174345\n",
      "Validation loss: 1.1622337402886902 ROC AUC: 0.6904677533664068\n",
      "171 2 0.3363252878189087\n",
      "Validation loss: 1.2945026609281831 ROC AUC: 0.703756201275691\n",
      "172 14 0.2668290436267853\n",
      "Validation loss: 1.2556021710894756 ROC AUC: 0.7044649184975195\n",
      "173 26 0.2203720510005951\n",
      "Validation loss: 1.2188704151980925 ROC AUC: 0.6982636428065202\n",
      "Validation loss: 1.3153760101621514 ROC AUC: 0.7172218284904323\n",
      "175 0 0.30701181292533875\n",
      "Validation loss: 0.9722402893154827 ROC AUC: 0.7104890148830617\n",
      "176 12 0.20692497491836548\n",
      "Validation loss: 1.0878144171064263 ROC AUC: 0.7028703047484055\n",
      "177 24 0.2023198902606964\n",
      "Validation loss: 1.0853484229536245 ROC AUC: 0.7207654145995748\n",
      "178 36 0.23232565820217133\n",
      "Validation loss: 1.1171694153192027 ROC AUC: 0.7071226080793763\n",
      "Validation loss: 0.9634791967884594 ROC AUC: 0.7260807937632885\n",
      "180 10 0.4919675290584564\n",
      "Validation loss: 1.1192855092863374 ROC AUC: 0.661764705882353\n",
      "181 22 0.2553080916404724\n",
      "Validation loss: 1.110825206270281 ROC AUC: 0.6959603118355776\n",
      "182 34 0.3925999701023102\n",
      "Validation loss: 0.9093047348868768 ROC AUC: 0.7397236002834869\n",
      "Validation loss: 1.1274207854113043 ROC AUC: 0.7319277108433734\n",
      "184 8 0.2805306911468506\n",
      "Validation loss: 1.1097774710876263 ROC AUC: 0.7212969525159462\n",
      "185 20 0.17934314906597137\n",
      "Validation loss: 1.2488575364580217 ROC AUC: 0.6855067328136074\n",
      "186 32 0.3009209930896759\n",
      "Validation loss: 1.0065075845907856 ROC AUC: 0.7111977321048902\n",
      "Validation loss: 1.0459744042118653 ROC AUC: 0.7099574769666903\n",
      "188 6 0.256779283285141\n",
      "Validation loss: 1.32667864079507 ROC AUC: 0.6901133947554925\n",
      "189 18 0.3391135036945343\n",
      "Validation loss: 0.8711462802444863 ROC AUC: 0.7298015591778879\n",
      "190 30 0.1057019755244255\n",
      "Validation loss: 1.0692892765367268 ROC AUC: 0.7026931254429483\n",
      "Validation loss: 1.2418955825022515 ROC AUC: 0.682140326009922\n",
      "192 4 0.13783825933933258\n",
      "Validation loss: 1.0389361397320072 ROC AUC: 0.7313961729270021\n",
      "193 16 0.12467249482870102\n",
      "Validation loss: 1.2035127136091524 ROC AUC: 0.6986180014174345\n",
      "194 28 0.272304892539978\n",
      "Validation loss: 1.0485214634446909 ROC AUC: 0.7209425939050319\n",
      "Validation loss: 1.11072411363488 ROC AUC: 0.7058823529411764\n",
      "196 2 0.27353864908218384\n",
      "Validation loss: 1.2080277058462434 ROC AUC: 0.7119064493267186\n",
      "197 14 0.34623897075653076\n",
      "Validation loss: 0.9914036116852666 ROC AUC: 0.7170446491849752\n",
      "198 26 0.17397648096084595\n",
      "Validation loss: 1.1218904233136713 ROC AUC: 0.7381289865343729\n",
      "Validation loss: 1.368563583749809 ROC AUC: 0.6933026222537207\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.2839038246556331 Test ROC AUC: 0.7739130434782608\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bace', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'classification', 'data_path': 'data/bace/bace.csv', 'target': ['Class']}}\n",
      "Running on: cuda:1\n",
      "1512\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1512\n",
      "Generating scaffold 1000/1512\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 8.47144889831543\n",
      "Validation loss: 0.7648529141943976 ROC AUC: 0.531715095676825\n",
      "1 12 2.7374672889709473\n",
      "Validation loss: 0.7519658618415428 ROC AUC: 0.6192416725726436\n",
      "2 24 1.9590375423431396\n",
      "Validation loss: 0.6743874652496237 ROC AUC: 0.6128632175761871\n",
      "3 36 1.6395131349563599\n",
      "Validation loss: 0.7602640378554135 ROC AUC: 0.6231396172927002\n",
      "Validation loss: 1.0273391489951027 ROC AUC: 0.6226080793763289\n",
      "5 10 1.3286190032958984\n",
      "Validation loss: 0.8244285851914361 ROC AUC: 0.5951452870304749\n",
      "6 22 1.0582399368286133\n",
      "Validation loss: 0.8645272179944625 ROC AUC: 0.5946137491141035\n",
      "7 34 1.069824457168579\n",
      "Validation loss: 0.7051620838657909 ROC AUC: 0.5889440113394756\n",
      "Validation loss: 0.9468275924392094 ROC AUC: 0.5283486888731397\n",
      "9 8 0.9974386692047119\n",
      "Validation loss: 1.1084808032244247 ROC AUC: 0.5308291991495393\n",
      "10 20 0.9413626790046692\n",
      "Validation loss: 0.9299612329495663 ROC AUC: 0.5910701630049611\n",
      "11 32 0.8060742616653442\n",
      "Validation loss: 1.274576446078471 ROC AUC: 0.6194188518781006\n",
      "Validation loss: 1.3421433840366388 ROC AUC: 0.6622962437987243\n",
      "13 6 0.7139543294906616\n",
      "Validation loss: 1.2149824961921236 ROC AUC: 0.6266832034018427\n",
      "14 18 0.6280956268310547\n",
      "Validation loss: 0.727024495601654 ROC AUC: 0.5947909284195606\n",
      "15 30 0.5545961260795593\n",
      "Validation loss: 0.8393213247621296 ROC AUC: 0.6493621545003544\n",
      "Validation loss: 0.8690705934897164 ROC AUC: 0.6137491141034727\n",
      "17 4 0.5793830752372742\n",
      "Validation loss: 0.7881862722485271 ROC AUC: 0.6599929128277817\n",
      "18 16 0.5400115251541138\n",
      "Validation loss: 0.9843488919813901 ROC AUC: 0.6121545003543586\n",
      "19 28 0.5384389162063599\n",
      "Validation loss: 0.829743217553524 ROC AUC: 0.6479447200566973\n",
      "Validation loss: 1.136954417291856 ROC AUC: 0.6711552090715804\n",
      "21 2 0.47603511810302734\n",
      "Validation loss: 0.9866125954697463 ROC AUC: 0.618355776045358\n",
      "22 14 0.7427493929862976\n",
      "Validation loss: 1.2127142836716 ROC AUC: 0.6506024096385542\n",
      "23 26 0.4389575719833374\n",
      "Validation loss: 0.8100105910901202 ROC AUC: 0.6651311126860383\n",
      "Validation loss: 1.6106345732480485 ROC AUC: 0.6305811481218994\n",
      "25 0 0.577685534954071\n",
      "Validation loss: 0.8237346402856688 ROC AUC: 0.6775336640680368\n",
      "26 12 0.58338463306427\n",
      "Validation loss: 0.9480720726859491 ROC AUC: 0.6474131821403261\n",
      "27 24 0.6102640628814697\n",
      "Validation loss: 0.7086720490297734 ROC AUC: 0.6924167257264351\n",
      "28 36 0.547870397567749\n",
      "Validation loss: 1.057480297341252 ROC AUC: 0.6669029057406095\n",
      "Validation loss: 0.9761803237018206 ROC AUC: 0.6695605953224664\n",
      "30 10 0.5156678557395935\n",
      "Validation loss: 0.870927695801716 ROC AUC: 0.7092487597448619\n",
      "31 22 0.6263293623924255\n",
      "Validation loss: 0.9716622553124333 ROC AUC: 0.6355421686746988\n",
      "32 34 0.4279930293560028\n",
      "Validation loss: 0.8909839083816832 ROC AUC: 0.6759390503189228\n",
      "Validation loss: 0.9418447436086389 ROC AUC: 0.6571580439404677\n",
      "34 8 0.3991332948207855\n",
      "Validation loss: 0.8222357753096827 ROC AUC: 0.6536144578313253\n",
      "35 20 0.5643682479858398\n",
      "Validation loss: 0.8811662540530527 ROC AUC: 0.6321757618710134\n",
      "36 32 0.4189543128013611\n",
      "Validation loss: 0.9703739470993447 ROC AUC: 0.6690290574060949\n",
      "Validation loss: 0.872057385792006 ROC AUC: 0.6599929128277817\n",
      "38 6 0.4164166748523712\n",
      "Validation loss: 0.8521744158883758 ROC AUC: 0.6651311126860382\n",
      "39 18 0.4991013705730438\n",
      "Validation loss: 0.8411524039230599 ROC AUC: 0.6782423812898654\n",
      "40 30 0.3964877724647522\n",
      "Validation loss: 0.8930398336309471 ROC AUC: 0.6755846917080085\n",
      "Validation loss: 0.8408881410068234 ROC AUC: 0.6963146704464919\n",
      "42 4 0.3681778311729431\n",
      "Validation loss: 0.7737270218647079 ROC AUC: 0.6803685329553508\n",
      "43 16 0.4103996455669403\n",
      "Validation loss: 0.7429848715959005 ROC AUC: 0.7035790219702339\n",
      "44 28 0.425743043422699\n",
      "Validation loss: 0.8621487120129415 ROC AUC: 0.7058823529411764\n",
      "Validation loss: 0.9639182138127207 ROC AUC: 0.6630049610205527\n",
      "46 2 0.29887300729751587\n",
      "Validation loss: 1.0621392959790514 ROC AUC: 0.6676116229624379\n",
      "47 14 0.25615841150283813\n",
      "Validation loss: 1.015310519578441 ROC AUC: 0.6676116229624379\n",
      "48 26 0.4088232219219208\n",
      "Validation loss: 0.8751689266684829 ROC AUC: 0.676293408929837\n",
      "Validation loss: 0.8113010841489627 ROC AUC: 0.6695605953224664\n",
      "50 0 0.4128962457180023\n",
      "Validation loss: 1.0721905105161351 ROC AUC: 0.6828490432317506\n",
      "51 12 0.2624526619911194\n",
      "Validation loss: 0.8691754289810231 ROC AUC: 0.6442239546420978\n",
      "52 24 0.4385385811328888\n",
      "Validation loss: 0.8453709135781851 ROC AUC: 0.6633593196314671\n",
      "53 36 0.4740746021270752\n",
      "Validation loss: 0.8009394979634822 ROC AUC: 0.6801913536498937\n",
      "Validation loss: 0.9579365174501937 ROC AUC: 0.6583982990786675\n",
      "55 10 0.4280557930469513\n",
      "Validation loss: 0.9002398410380281 ROC AUC: 0.685152374202693\n",
      "56 22 0.4334157109260559\n",
      "Validation loss: 0.8082089167557015 ROC AUC: 0.67487597448618\n",
      "57 34 0.41730523109436035\n",
      "Validation loss: 0.8517926023495908 ROC AUC: 0.7026931254429483\n",
      "Validation loss: 0.7679668412303293 ROC AUC: 0.673458540042523\n",
      "59 8 0.33057519793510437\n",
      "Validation loss: 0.9285548400405227 ROC AUC: 0.6911764705882353\n",
      "60 20 0.22824516892433167\n",
      "Validation loss: 1.0004666901582124 ROC AUC: 0.6523742026931254\n",
      "61 32 0.387188196182251\n",
      "Validation loss: 0.8009033586015765 ROC AUC: 0.6856839121190644\n",
      "Validation loss: 0.8714669927066525 ROC AUC: 0.6883416017009213\n",
      "63 6 0.39742520451545715\n",
      "Validation loss: 0.8625631883049643 ROC AUC: 0.6750531537916371\n",
      "64 18 0.4220871031284332\n",
      "Validation loss: 1.0019352917639626 ROC AUC: 0.6925939050318922\n",
      "65 30 0.37224268913269043\n",
      "Validation loss: 0.8444509415437054 ROC AUC: 0.6902905740609497\n",
      "Validation loss: 0.9046646928945125 ROC AUC: 0.6918851878100638\n",
      "67 4 0.40118953585624695\n",
      "Validation loss: 0.8740699725435269 ROC AUC: 0.6713323883770376\n",
      "68 16 0.5571264028549194\n",
      "Validation loss: 0.8541406961466302 ROC AUC: 0.7049964564138907\n",
      "69 28 0.3273092806339264\n",
      "Validation loss: 0.7322723565512146 ROC AUC: 0.721119773210489\n",
      "Validation loss: 0.7766367078616919 ROC AUC: 0.7289156626506025\n",
      "71 2 0.3424583077430725\n",
      "Validation loss: 0.9530312201834672 ROC AUC: 0.6807228915662651\n",
      "72 14 0.426607608795166\n",
      "Validation loss: 0.9918244204773808 ROC AUC: 0.6897590361445783\n",
      "73 26 0.3227212429046631\n",
      "Validation loss: 0.93217311947551 ROC AUC: 0.7049964564138909\n",
      "Validation loss: 0.8410266310173944 ROC AUC: 0.683380581148122\n",
      "75 0 0.36523500084877014\n",
      "Validation loss: 1.039215326309204 ROC AUC: 0.6989723600283487\n",
      "76 12 0.42504099011421204\n",
      "Validation loss: 0.7666166381330679 ROC AUC: 0.6940113394755493\n",
      "77 24 0.27894654870033264\n",
      "Validation loss: 1.1110492486827421 ROC AUC: 0.6879872430900071\n",
      "78 36 0.33276262879371643\n",
      "Validation loss: 1.0159115743952871 ROC AUC: 0.6789510985116938\n",
      "Validation loss: 0.9887908949757254 ROC AUC: 0.6679659815733522\n",
      "80 10 0.38142526149749756\n",
      "Validation loss: 1.0337238517028606 ROC AUC: 0.6830262225372077\n",
      "81 22 0.4342223107814789\n",
      "Validation loss: 1.0026303083691377 ROC AUC: 0.6506024096385542\n",
      "82 34 0.4148145020008087\n",
      "Validation loss: 0.8107226380449257 ROC AUC: 0.6716867469879518\n",
      "Validation loss: 0.8326193445565685 ROC AUC: 0.6858610914245216\n",
      "84 8 0.43862566351890564\n",
      "Validation loss: 0.9203415516985963 ROC AUC: 0.6693834160170092\n",
      "85 20 0.28404587507247925\n",
      "Validation loss: 0.7531263173021228 ROC AUC: 0.7071226080793762\n",
      "86 32 0.46224865317344666\n",
      "Validation loss: 0.9576856257110242 ROC AUC: 0.689404677533664\n",
      "Validation loss: 0.8387447536386401 ROC AUC: 0.667611622962438\n",
      "88 6 0.2857268154621124\n",
      "Validation loss: 1.1421918920333811 ROC AUC: 0.696669029057406\n",
      "89 18 0.22125931084156036\n",
      "Validation loss: 1.005205368758827 ROC AUC: 0.6925939050318922\n",
      "90 30 0.5313540697097778\n",
      "Validation loss: 1.1418760099158383 ROC AUC: 0.6309355067328136\n",
      "Validation loss: 0.8141712755556928 ROC AUC: 0.7094259390503189\n",
      "92 4 0.183317169547081\n",
      "Validation loss: 1.0087887250035015 ROC AUC: 0.6931254429482636\n",
      "93 16 0.37582045793533325\n",
      "Validation loss: 0.9101334012896809 ROC AUC: 0.6908221119773211\n",
      "94 28 0.5924590826034546\n",
      "Validation loss: 0.8928057504016043 ROC AUC: 0.6972005669737775\n",
      "Validation loss: 0.8685717393230918 ROC AUC: 0.6885187810063784\n",
      "96 2 0.3153339922428131\n",
      "Validation loss: 1.0029629082079754 ROC AUC: 0.6683203401842664\n",
      "97 14 0.26763367652893066\n",
      "Validation loss: 0.9319978553727762 ROC AUC: 0.6984408221119772\n",
      "98 26 0.29773038625717163\n",
      "Validation loss: 1.0447204460371409 ROC AUC: 0.7057051736357193\n",
      "Validation loss: 0.8602295020558187 ROC AUC: 0.6886959603118356\n",
      "100 0 0.2592476010322571\n",
      "Validation loss: 0.9142602374222105 ROC AUC: 0.6846208362863218\n",
      "101 12 0.3046562969684601\n",
      "Validation loss: 1.1562439455891287 ROC AUC: 0.6961374911410347\n",
      "102 24 0.34454429149627686\n",
      "Validation loss: 1.0078223075298285 ROC AUC: 0.6442239546420978\n",
      "103 36 0.32695239782333374\n",
      "Validation loss: 0.7813497398862775 ROC AUC: 0.7313961729270021\n",
      "Validation loss: 0.9469842441034633 ROC AUC: 0.7012756909992913\n",
      "105 10 0.2908720076084137\n",
      "Validation loss: 0.8056084876818372 ROC AUC: 0.7099574769666903\n",
      "106 22 0.2120661586523056\n",
      "Validation loss: 0.9347236748562743 ROC AUC: 0.7230687455705173\n",
      "107 34 0.20156298577785492\n",
      "Validation loss: 0.8717231521543288 ROC AUC: 0.7019844082211198\n",
      "Validation loss: 0.9267356087829893 ROC AUC: 0.6883416017009214\n",
      "109 8 0.2791109085083008\n",
      "Validation loss: 0.9510437850131105 ROC AUC: 0.6837349397590361\n",
      "110 20 0.31242936849594116\n",
      "Validation loss: 1.1344810574259978 ROC AUC: 0.6725726435152374\n",
      "111 32 0.3920292258262634\n",
      "Validation loss: 1.1498525584770354 ROC AUC: 0.6582211197732105\n",
      "Validation loss: 0.9341324228324638 ROC AUC: 0.6902905740609496\n",
      "113 6 0.20848196744918823\n",
      "Validation loss: 1.025454956569419 ROC AUC: 0.6771793054571227\n",
      "114 18 0.2110896110534668\n",
      "Validation loss: 1.125675832198945 ROC AUC: 0.695074415308292\n",
      "115 30 0.2876647412776947\n",
      "Validation loss: 0.8323425994014109 ROC AUC: 0.6855067328136073\n",
      "Validation loss: 1.2051509745073634 ROC AUC: 0.6507795889440113\n",
      "117 4 0.2594454288482666\n",
      "Validation loss: 0.874159467733459 ROC AUC: 0.7133238837703756\n",
      "118 16 0.1405685991048813\n",
      "Validation loss: 1.1692955174193478 ROC AUC: 0.684975194897236\n",
      "119 28 0.6365053653717041\n",
      "Validation loss: 1.0761145815154574 ROC AUC: 0.6725726435152375\n",
      "Validation loss: 1.1271248669024334 ROC AUC: 0.7108433734939759\n",
      "121 2 0.43527859449386597\n",
      "Validation loss: 0.9756213584483064 ROC AUC: 0.6706236711552092\n",
      "122 14 0.36871278285980225\n",
      "Validation loss: 0.8306236673664573 ROC AUC: 0.7087172218284904\n",
      "123 26 0.2446087896823883\n",
      "Validation loss: 1.068084956794385 ROC AUC: 0.7010985116938342\n",
      "Validation loss: 1.1880810387087184 ROC AUC: 0.6847980155917789\n",
      "125 0 0.2131872922182083\n",
      "Validation loss: 1.0421573018396137 ROC AUC: 0.679305457122608\n",
      "126 12 0.23260000348091125\n",
      "Validation loss: 0.9646009767292351 ROC AUC: 0.7113749114103473\n",
      "127 24 0.24736160039901733\n",
      "Validation loss: 1.1427534518652405 ROC AUC: 0.7173990077958894\n",
      "128 36 0.43270426988601685\n",
      "Validation loss: 0.8939270783733848 ROC AUC: 0.7099574769666903\n",
      "Validation loss: 0.9642172633417395 ROC AUC: 0.7099574769666902\n",
      "130 10 0.27246877551078796\n",
      "Validation loss: 0.9992560503498608 ROC AUC: 0.7135010630758327\n",
      "131 22 0.34798792004585266\n",
      "Validation loss: 0.9545382995479155 ROC AUC: 0.6871013465627214\n",
      "132 34 0.31104758381843567\n",
      "Validation loss: 0.906772661288053 ROC AUC: 0.7156272147413183\n",
      "Validation loss: 1.0114243796329625 ROC AUC: 0.7005669737774628\n",
      "134 8 0.15882061421871185\n",
      "Validation loss: 0.9694503545761108 ROC AUC: 0.6975549255846916\n",
      "135 20 0.3407610058784485\n",
      "Validation loss: 0.8496462465911512 ROC AUC: 0.7375974486180015\n",
      "136 32 0.35474202036857605\n",
      "Validation loss: 0.906481732990568 ROC AUC: 0.7032246633593195\n",
      "Validation loss: 0.8999223278847751 ROC AUC: 0.7207654145995748\n",
      "138 6 0.19020511209964752\n",
      "Validation loss: 0.9117586498228919 ROC AUC: 0.7244861800141744\n",
      "139 18 0.295461505651474\n",
      "Validation loss: 0.9026724735632637 ROC AUC: 0.7046420978029766\n",
      "140 30 0.46395182609558105\n",
      "Validation loss: 1.0125720268053724 ROC AUC: 0.7126151665485471\n",
      "Validation loss: 0.9068769192853511 ROC AUC: 0.6904677533664069\n",
      "142 4 0.379013329744339\n",
      "Validation loss: 0.9842267875245075 ROC AUC: 0.7018072289156626\n",
      "143 16 0.3122117519378662\n",
      "Validation loss: 0.8787518948908674 ROC AUC: 0.6956059532246633\n",
      "144 28 0.2791805863380432\n",
      "Validation loss: 1.0393741276879973 ROC AUC: 0.69950389794472\n",
      "Validation loss: 0.8929925359637532 ROC AUC: 0.7352941176470589\n",
      "146 2 0.502750813961029\n",
      "Validation loss: 1.0957291185461133 ROC AUC: 0.7124379872430899\n",
      "147 14 0.14859473705291748\n",
      "Validation loss: 1.0158544163040768 ROC AUC: 0.7016300496102055\n",
      "148 26 0.2371143251657486\n",
      "Validation loss: 0.8276304369730665 ROC AUC: 0.7035790219702339\n",
      "Validation loss: 0.8842904307194893 ROC AUC: 0.7133238837703757\n",
      "150 0 0.2811743915081024\n",
      "Validation loss: 1.2672202255552178 ROC AUC: 0.6777108433734939\n",
      "151 12 0.24519026279449463\n",
      "Validation loss: 1.0771075100298748 ROC AUC: 0.7120836286321757\n",
      "152 24 0.26653149724006653\n",
      "Validation loss: 0.9806629814059529 ROC AUC: 0.705350815024805\n",
      "153 36 0.3434845805168152\n",
      "Validation loss: 1.12509489454181 ROC AUC: 0.7124379872430899\n",
      "Validation loss: 1.1561293388834062 ROC AUC: 0.6824946846208363\n",
      "155 10 0.1429758220911026\n",
      "Validation loss: 1.0127370049621884 ROC AUC: 0.7262579730687456\n",
      "156 22 0.20761418342590332\n",
      "Validation loss: 1.048369935806224 ROC AUC: 0.702515946137491\n",
      "157 34 0.2984956204891205\n",
      "Validation loss: 1.0596236645780652 ROC AUC: 0.729978738483345\n",
      "Validation loss: 1.1486936823421756 ROC AUC: 0.7260807937632885\n",
      "159 8 0.18276354670524597\n",
      "Validation loss: 1.0692313420062034 ROC AUC: 0.7058823529411764\n",
      "160 20 0.26284059882164\n",
      "Validation loss: 1.1302426611350862 ROC AUC: 0.7010985116938342\n",
      "161 32 0.3494003117084503\n",
      "Validation loss: 1.0647928434491947 ROC AUC: 0.7189936215450036\n",
      "Validation loss: 1.0465408974135948 ROC AUC: 0.7074769666902905\n",
      "163 6 0.15859463810920715\n",
      "Validation loss: 1.0831055518807164 ROC AUC: 0.6933026222537207\n",
      "164 18 0.16707153618335724\n",
      "Validation loss: 1.0164274182540691 ROC AUC: 0.7140326009922041\n",
      "165 30 0.186773881316185\n",
      "Validation loss: 1.0372601692250232 ROC AUC: 0.7019844082211197\n",
      "Validation loss: 1.0412628832242348 ROC AUC: 0.7457476966690291\n",
      "167 4 0.24835488200187683\n",
      "Validation loss: 0.9954872123453001 ROC AUC: 0.7186392629340893\n",
      "168 16 0.14862868189811707\n",
      "Validation loss: 1.250090724585072 ROC AUC: 0.7165131112686038\n",
      "169 28 0.19113199412822723\n",
      "Validation loss: 1.1694966096751738 ROC AUC: 0.7021615875265769\n",
      "Validation loss: 1.2205373554040264 ROC AUC: 0.7071226080793763\n",
      "171 2 0.12212047725915909\n",
      "Validation loss: 0.9658506895532671 ROC AUC: 0.7106661941885188\n",
      "172 14 0.26815590262413025\n",
      "Validation loss: 1.1715771930896683 ROC AUC: 0.7127923458540043\n",
      "173 26 0.41170668601989746\n",
      "Validation loss: 1.275303695770289 ROC AUC: 0.6913536498936924\n",
      "Validation loss: 1.1122751441222942 ROC AUC: 0.7150956768249468\n",
      "175 0 0.1480237990617752\n",
      "Validation loss: 1.2509415887838957 ROC AUC: 0.7106661941885187\n",
      "176 12 0.16352009773254395\n",
      "Validation loss: 1.1010018650269666 ROC AUC: 0.6954287739192062\n",
      "177 24 0.13317136466503143\n",
      "Validation loss: 1.1326568655620348 ROC AUC: 0.7391920623671155\n",
      "178 36 0.37069830298423767\n",
      "Validation loss: 1.1109911645485075 ROC AUC: 0.6963146704464918\n",
      "Validation loss: 1.120687967894093 ROC AUC: 0.6874557051736356\n",
      "180 10 0.3713650405406952\n",
      "Validation loss: 1.292972445487976 ROC AUC: 0.6858610914245217\n",
      "181 22 0.40439373254776\n",
      "Validation loss: 0.9115361006844123 ROC AUC: 0.7315733522324592\n",
      "182 34 0.27123889327049255\n",
      "Validation loss: 1.1718845272695781 ROC AUC: 0.7117292700212615\n",
      "Validation loss: 1.1040720710691236 ROC AUC: 0.7103118355776045\n",
      "184 8 0.2651250660419464\n",
      "Validation loss: 1.1643998725524802 ROC AUC: 0.7032246633593195\n",
      "185 20 0.17381130158901215\n",
      "Validation loss: 1.2889359392077717 ROC AUC: 0.6961374911410347\n",
      "186 32 0.23984821140766144\n",
      "Validation loss: 1.1795433530744337 ROC AUC: 0.7055279943302621\n",
      "Validation loss: 1.1637837965756852 ROC AUC: 0.6865698086463501\n",
      "188 6 0.2561006546020508\n",
      "Validation loss: 0.9464683493241569 ROC AUC: 0.7119064493267186\n",
      "189 18 0.35733333230018616\n",
      "Validation loss: 1.2290632937917647 ROC AUC: 0.7147413182140326\n",
      "190 30 0.30959731340408325\n",
      "Validation loss: 1.0152704332837996 ROC AUC: 0.7294472005669737\n",
      "Validation loss: 1.0595660174129815 ROC AUC: 0.7041105598866053\n",
      "192 4 0.2689107656478882\n",
      "Validation loss: 1.4315353213556554 ROC AUC: 0.7184620836286322\n",
      "193 16 0.3148452937602997\n",
      "Validation loss: 1.0878116555561292 ROC AUC: 0.7191708008504607\n",
      "194 28 0.28157201409339905\n",
      "Validation loss: 1.178015432610417 ROC AUC: 0.7143869596031184\n",
      "Validation loss: 1.325331529244682 ROC AUC: 0.6980864635010631\n",
      "196 2 0.13272620737552643\n",
      "Validation loss: 1.209577779896212 ROC AUC: 0.7009213323883771\n",
      "197 14 0.14219464361667633\n",
      "Validation loss: 1.1915645500682048 ROC AUC: 0.6899362154500355\n",
      "198 26 0.1307918280363083\n",
      "Validation loss: 1.0647975687949074 ROC AUC: 0.7158043940467753\n",
      "Validation loss: 1.201028772537282 ROC AUC: 0.6998582565556343\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.2105056361148232 Test ROC AUC: 0.790036231884058\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bbbp', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'classification', 'data_path': 'data/bbbp/BBBP.csv', 'target': ['p_np']}}\n",
      "Running on: cuda:1\n",
      "2038\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/2038\n",
      "Generating scaffold 1000/2038\n",
      "Generating scaffold 2000/2038\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 8.38571548461914\n",
      "0 50 2.5603957176208496\n",
      "Validation loss: 0.9140842405020022 ROC AUC: 0.8363742236024846\n",
      "1 49 1.4839495420455933\n",
      "Validation loss: 0.47555674291124533 ROC AUC: 0.8989712732919255\n",
      "2 48 1.2451223134994507\n",
      "Validation loss: 0.5138561935985789 ROC AUC: 0.8962538819875775\n",
      "3 47 1.2434794902801514\n",
      "Validation loss: 0.4669681226505953 ROC AUC: 0.9170225155279503\n",
      "4 46 1.033466100692749\n",
      "Validation loss: 0.47355597860672893 ROC AUC: 0.9084821428571429\n",
      "5 45 0.9839084148406982\n",
      "Validation loss: 0.653910195126253 ROC AUC: 0.8937305900621119\n",
      "6 44 0.7458279728889465\n",
      "Validation loss: 0.4226716628261641 ROC AUC: 0.922748447204969\n",
      "7 43 0.6636015176773071\n",
      "Validation loss: 0.3993922472000122 ROC AUC: 0.9302212732919254\n",
      "8 42 0.6974220871925354\n",
      "Validation loss: 0.43111592297460516 ROC AUC: 0.9186723602484471\n",
      "9 41 0.8831652998924255\n",
      "Validation loss: 0.37552472773720236 ROC AUC: 0.92090450310559\n",
      "10 40 0.7826137542724609\n",
      "Validation loss: 0.4479936559995015 ROC AUC: 0.9229425465838509\n",
      "11 39 0.45656532049179077\n",
      "Validation loss: 0.49696197463016883 ROC AUC: 0.9171195652173912\n",
      "12 38 0.43593698740005493\n",
      "Validation loss: 0.3966478524254818 ROC AUC: 0.9284743788819875\n",
      "13 37 0.48068147897720337\n",
      "Validation loss: 0.5294901120896433 ROC AUC: 0.9114906832298135\n",
      "14 36 0.40586772561073303\n",
      "Validation loss: 0.3864506959330802 ROC AUC: 0.9149844720496894\n",
      "15 35 0.34256255626678467\n",
      "Validation loss: 0.3844757144357644 ROC AUC: 0.9284743788819876\n",
      "16 34 0.38200467824935913\n",
      "Validation loss: 0.41251662578068526 ROC AUC: 0.9086762422360248\n",
      "17 33 0.35190528631210327\n",
      "Validation loss: 0.4070029772964178 ROC AUC: 0.9254658385093167\n",
      "18 32 0.42933592200279236\n",
      "Validation loss: 0.49689362037415596 ROC AUC: 0.9127523291925466\n",
      "19 31 0.3579277992248535\n",
      "Validation loss: 0.38856424953715474 ROC AUC: 0.9293478260869565\n",
      "20 30 0.2849120497703552\n",
      "Validation loss: 0.35624446763711815 ROC AUC: 0.9297360248447204\n",
      "21 29 0.4204097390174866\n",
      "Validation loss: 0.3893681926762356 ROC AUC: 0.921972049689441\n",
      "22 28 0.30950990319252014\n",
      "Validation loss: 0.4561986254126418 ROC AUC: 0.9129464285714286\n",
      "23 27 0.32977020740509033\n",
      "Validation loss: 0.45185813132454367 ROC AUC: 0.9194487577639752\n",
      "24 26 0.33294570446014404\n",
      "Validation loss: 0.4272146195757623 ROC AUC: 0.9318711180124224\n",
      "25 25 0.3190367519855499\n",
      "Validation loss: 0.45343854380588905 ROC AUC: 0.9141110248447205\n",
      "26 24 0.33065396547317505\n",
      "Validation loss: 0.3560003536004646 ROC AUC: 0.9368206521739131\n",
      "27 23 0.28392311930656433\n",
      "Validation loss: 0.4106236760522805 ROC AUC: 0.9230395962732919\n",
      "28 22 0.30072927474975586\n",
      "Validation loss: 0.5051861720926621 ROC AUC: 0.9063470496894409\n",
      "29 21 0.3391309380531311\n",
      "Validation loss: 0.5628798966314278 ROC AUC: 0.8944099378881988\n",
      "30 20 0.521374523639679\n",
      "Validation loss: 0.500250157772326 ROC AUC: 0.9022709627329192\n",
      "31 19 0.20902718603610992\n",
      "Validation loss: 0.3737131631841846 ROC AUC: 0.937597049689441\n",
      "32 18 0.1863689124584198\n",
      "Validation loss: 0.7503584325313568 ROC AUC: 0.8590838509316769\n",
      "33 17 0.30684560537338257\n",
      "Validation loss: 0.44292428096135456 ROC AUC: 0.9214868012422359\n",
      "34 16 0.40991654992103577\n",
      "Validation loss: 0.4348348595348059 ROC AUC: 0.922069099378882\n",
      "35 15 0.3421749770641327\n",
      "Validation loss: 0.4043356180921489 ROC AUC: 0.9258540372670808\n",
      "36 14 0.32338324189186096\n",
      "Validation loss: 0.5524489003069261 ROC AUC: 0.9080939440993788\n",
      "37 13 0.15827281773090363\n",
      "Validation loss: 0.46899087171928555 ROC AUC: 0.9191576086956522\n",
      "38 12 0.39230865240097046\n",
      "Validation loss: 0.4210479057887021 ROC AUC: 0.9232336956521741\n",
      "39 11 0.3297831118106842\n",
      "Validation loss: 0.6949811428785324 ROC AUC: 0.8300659937888198\n",
      "40 10 0.2031172513961792\n",
      "Validation loss: 0.5548208057880402 ROC AUC: 0.8981948757763975\n",
      "41 9 0.16554386913776398\n",
      "Validation loss: 0.46598923045630547 ROC AUC: 0.9162461180124222\n",
      "42 8 0.11231714487075806\n",
      "Validation loss: 0.4500717981627174 ROC AUC: 0.9126552795031057\n",
      "43 7 0.2517715394496918\n",
      "Validation loss: 0.5910340769618165 ROC AUC: 0.8888781055900622\n",
      "44 6 0.25063759088516235\n",
      "Validation loss: 0.4713504929460731 ROC AUC: 0.9145962732919254\n",
      "45 5 0.3371889889240265\n",
      "Validation loss: 0.4048987130324046 ROC AUC: 0.9345885093167701\n",
      "46 4 0.1868886649608612\n",
      "Validation loss: 0.4842833584430171 ROC AUC: 0.9112965838509317\n",
      "47 3 0.2591792345046997\n",
      "Validation loss: 0.4689953744995828 ROC AUC: 0.9244953416149069\n",
      "48 2 0.35035696625709534\n",
      "Validation loss: 0.48560454711025836 ROC AUC: 0.9187694099378882\n",
      "49 1 0.29867157340049744\n",
      "Validation loss: 0.587471132184945 ROC AUC: 0.8877135093167702\n",
      "50 0 0.2963334023952484\n",
      "50 50 0.28733664751052856\n",
      "Validation loss: 0.5402238294482231 ROC AUC: 0.8757763975155279\n",
      "51 49 0.2430053949356079\n",
      "Validation loss: 0.3956501834532794 ROC AUC: 0.9293478260869565\n",
      "52 48 0.35544511675834656\n",
      "Validation loss: 0.4295286428110272 ROC AUC: 0.921875\n",
      "53 47 0.18162322044372559\n",
      "Validation loss: 0.4342912879644656 ROC AUC: 0.9271156832298137\n",
      "54 46 0.2288341522216797\n",
      "Validation loss: 0.781631192740272 ROC AUC: 0.8798524844720497\n",
      "55 45 0.11518700420856476\n",
      "Validation loss: 0.3747386526243359 ROC AUC: 0.9358501552795031\n",
      "56 44 0.1916295289993286\n",
      "Validation loss: 0.4496644056018661 ROC AUC: 0.9098408385093169\n",
      "57 43 0.13266627490520477\n",
      "Validation loss: 0.4449273803654839 ROC AUC: 0.9033385093167702\n",
      "58 42 0.21422822773456573\n",
      "Validation loss: 0.34823015858145323 ROC AUC: 0.9317740683229812\n",
      "59 41 0.24952565133571625\n",
      "Validation loss: 0.4778811271284141 ROC AUC: 0.9223602484472051\n",
      "60 40 0.2818559408187866\n",
      "Validation loss: 0.5014888860431372 ROC AUC: 0.921486801242236\n",
      "61 39 0.19593101739883423\n",
      "Validation loss: 0.5433035592238108 ROC AUC: 0.904211956521739\n",
      "62 38 0.3609884977340698\n",
      "Validation loss: 0.47176577998142616 ROC AUC: 0.906832298136646\n",
      "63 37 0.2667102813720703\n",
      "Validation loss: 0.4376018275232876 ROC AUC: 0.921875\n",
      "64 36 0.16523310542106628\n",
      "Validation loss: 0.4748843259671155 ROC AUC: 0.9112965838509317\n",
      "65 35 0.22915565967559814\n",
      "Validation loss: 0.4223265390770108 ROC AUC: 0.9217779503105591\n",
      "66 34 0.19951611757278442\n",
      "Validation loss: 0.4783231312153386 ROC AUC: 0.9223602484472049\n",
      "67 33 0.21211813390254974\n",
      "Validation loss: 0.44338856403734167 ROC AUC: 0.9180900621118012\n",
      "68 32 0.14146587252616882\n",
      "Validation loss: 0.42458188679872777 ROC AUC: 0.9242041925465837\n",
      "69 31 0.29899847507476807\n",
      "Validation loss: 0.6439635864659852 ROC AUC: 0.8964479813664595\n",
      "70 30 0.33501553535461426\n",
      "Validation loss: 0.5765381940439636 ROC AUC: 0.8922748447204969\n",
      "71 29 0.19526250660419464\n",
      "Validation loss: 0.46898984967493546 ROC AUC: 0.9015916149068324\n",
      "72 28 0.13556458055973053\n",
      "Validation loss: 0.5477020889520645 ROC AUC: 0.9066381987577639\n",
      "73 27 0.16860812902450562\n",
      "Validation loss: 0.4970606460290797 ROC AUC: 0.9129464285714286\n",
      "74 26 0.1995917558670044\n",
      "Validation loss: 0.6372330142002479 ROC AUC: 0.9118788819875776\n",
      "75 25 0.22544369101524353\n",
      "Validation loss: 0.4385695165278865 ROC AUC: 0.9215838509316769\n",
      "76 24 0.21441586315631866\n",
      "Validation loss: 0.41827809226279167 ROC AUC: 0.9286684782608694\n",
      "77 23 0.1968502253293991\n",
      "Validation loss: 0.6239035924275717 ROC AUC: 0.9117818322981366\n",
      "78 22 0.1535070836544037\n",
      "Validation loss: 0.6536698645236445 ROC AUC: 0.891498447204969\n",
      "79 21 0.2549747824668884\n",
      "Validation loss: 0.7439940443225935 ROC AUC: 0.8707298136645963\n",
      "80 20 0.16507618129253387\n",
      "Validation loss: 0.6793816291234073 ROC AUC: 0.8680124223602484\n",
      "81 19 0.15045008063316345\n",
      "Validation loss: 0.4922276782054527 ROC AUC: 0.9155667701863354\n",
      "82 18 0.15887047350406647\n",
      "Validation loss: 0.5741151988360227 ROC AUC: 0.9129464285714286\n",
      "83 17 0.07719571888446808\n",
      "Validation loss: 0.5048086127521945 ROC AUC: 0.9100349378881987\n",
      "84 16 0.19589704275131226\n",
      "Validation loss: 0.5895518539838639 ROC AUC: 0.9160520186335404\n",
      "85 15 0.22273454070091248\n",
      "Validation loss: 0.5708804276644015 ROC AUC: 0.9144992236024845\n",
      "86 14 0.276408851146698\n",
      "Validation loss: 0.5816228129700118 ROC AUC: 0.9135287267080745\n",
      "87 13 0.06824444234371185\n",
      "Validation loss: 0.6167502917495429 ROC AUC: 0.9010093167701864\n",
      "88 12 0.30506202578544617\n",
      "Validation loss: 0.7510591961589514 ROC AUC: 0.8957686335403726\n",
      "89 11 0.1653478592634201\n",
      "Validation loss: 0.5179931278906617 ROC AUC: 0.9151785714285715\n",
      "90 10 0.17122870683670044\n",
      "Validation loss: 0.4392833603801681 ROC AUC: 0.9345885093167702\n",
      "91 9 0.2227853238582611\n",
      "Validation loss: 0.6753900810783985 ROC AUC: 0.8912072981366459\n",
      "92 8 0.14689898490905762\n",
      "Validation loss: 0.5005436842055881 ROC AUC: 0.9181871118012421\n",
      "93 7 0.2446610927581787\n",
      "Validation loss: 0.7060823580797981 ROC AUC: 0.905376552795031\n",
      "94 6 0.17073789238929749\n",
      "Validation loss: 0.5955168786002141 ROC AUC: 0.8925659937888197\n",
      "95 5 0.1983584463596344\n",
      "Validation loss: 0.5360304944071115 ROC AUC: 0.9157608695652174\n",
      "96 4 0.09541508555412292\n",
      "Validation loss: 0.7005176146825155 ROC AUC: 0.8895574534161491\n",
      "97 3 0.1843060702085495\n",
      "Validation loss: 0.5396105202243608 ROC AUC: 0.9100349378881986\n",
      "98 2 0.10949050635099411\n",
      "Validation loss: 0.5609552042157042 ROC AUC: 0.9247864906832297\n",
      "99 1 0.2620987892150879\n",
      "Validation loss: 0.3608844400036569 ROC AUC: 0.9393439440993789\n",
      "100 0 0.155149444937706\n",
      "100 50 0.1224924847483635\n",
      "Validation loss: 0.6434759818309662 ROC AUC: 0.8996506211180124\n",
      "101 49 0.21081510186195374\n",
      "Validation loss: 0.6629921735501757 ROC AUC: 0.8980978260869564\n",
      "102 48 0.3429378867149353\n",
      "Validation loss: 0.51240813907455 ROC AUC: 0.9186723602484471\n",
      "103 47 0.08914535492658615\n",
      "Validation loss: 0.5211664309688643 ROC AUC: 0.920710403726708\n",
      "104 46 0.12030567228794098\n",
      "Validation loss: 0.48541483458350687 ROC AUC: 0.9177989130434782\n",
      "105 45 0.09347279369831085\n",
      "Validation loss: 0.5039410006766226 ROC AUC: 0.9171195652173912\n",
      "106 44 0.2007339894771576\n",
      "Validation loss: 0.7539911164956934 ROC AUC: 0.889848602484472\n",
      "107 43 0.06525765359401703\n",
      "Validation loss: 0.7119957652746463 ROC AUC: 0.8971273291925465\n",
      "108 42 0.18348854780197144\n",
      "Validation loss: 0.6291091249269598 ROC AUC: 0.9074145962732919\n",
      "109 41 0.11611653864383698\n",
      "Validation loss: 0.5034038016901297 ROC AUC: 0.9251746894409938\n",
      "110 40 0.16362887620925903\n",
      "Validation loss: 0.6832162653114281 ROC AUC: 0.8947010869565217\n",
      "111 39 0.18917815387248993\n",
      "Validation loss: 0.68861951927344 ROC AUC: 0.9005240683229814\n",
      "112 38 0.1103183701634407\n",
      "Validation loss: 0.8923455441699308 ROC AUC: 0.8944099378881987\n",
      "113 37 0.08055467158555984\n",
      "Validation loss: 0.43031958242257434 ROC AUC: 0.9309006211180124\n",
      "114 36 0.09402036666870117\n",
      "Validation loss: 0.5569207492996665 ROC AUC: 0.9111995341614907\n",
      "115 35 0.2307933270931244\n",
      "Validation loss: 0.8287597544053021 ROC AUC: 0.8914013975155279\n",
      "116 34 0.19678115844726562\n",
      "Validation loss: 0.6374330709085745 ROC AUC: 0.9128493788819876\n",
      "117 33 0.17351794242858887\n",
      "Validation loss: 0.83451153717789 ROC AUC: 0.9087732919254657\n",
      "118 32 0.2504458725452423\n",
      "Validation loss: 0.6633471495964948 ROC AUC: 0.8950892857142857\n",
      "119 31 0.15698948502540588\n",
      "Validation loss: 0.72811794164134 ROC AUC: 0.8971273291925466\n",
      "120 30 0.085377536714077\n",
      "Validation loss: 0.9310859605377796 ROC AUC: 0.8913043478260869\n",
      "121 29 0.12418686598539352\n",
      "Validation loss: 0.5660607803101633 ROC AUC: 0.9277950310559007\n",
      "122 28 0.11878425627946854\n",
      "Validation loss: 0.5006388846565696 ROC AUC: 0.9253687888198756\n",
      "123 27 0.05317642167210579\n",
      "Validation loss: 0.7855208186323152 ROC AUC: 0.9041149068322981\n",
      "124 26 0.45682811737060547\n",
      "Validation loss: 0.6273742294779011 ROC AUC: 0.9224572981366459\n",
      "125 25 0.31669849157333374\n",
      "Validation loss: 0.7000307884870791 ROC AUC: 0.9013004658385093\n",
      "126 24 0.1725204437971115\n",
      "Validation loss: 0.5510155888018655 ROC AUC: 0.922360248447205\n",
      "127 23 0.0738360732793808\n",
      "Validation loss: 1.02374580560946 ROC AUC: 0.8789790372670808\n",
      "128 22 0.2220289409160614\n",
      "Validation loss: 0.48439433644799623 ROC AUC: 0.9314829192546583\n",
      "129 21 0.06752490252256393\n",
      "Validation loss: 0.6198503217276405 ROC AUC: 0.91993400621118\n",
      "130 20 0.19710512459278107\n",
      "Validation loss: 0.7504638547406477 ROC AUC: 0.9106172360248447\n",
      "131 19 0.17509205639362335\n",
      "Validation loss: 0.6550823029349832 ROC AUC: 0.9148874223602486\n",
      "132 18 0.1261431872844696\n",
      "Validation loss: 0.5305521885553995 ROC AUC: 0.9211956521739132\n",
      "133 17 0.23604141175746918\n",
      "Validation loss: 0.588025010099598 ROC AUC: 0.9332298136645962\n",
      "134 16 0.08866934478282928\n",
      "Validation loss: 0.8362635209718171 ROC AUC: 0.8953804347826086\n",
      "135 15 0.05402655899524689\n",
      "Validation loss: 0.8473857366571239 ROC AUC: 0.8999417701863354\n",
      "136 14 0.057153064757585526\n",
      "Validation loss: 0.47792773328575433 ROC AUC: 0.9260481366459627\n",
      "137 13 0.026770636439323425\n",
      "Validation loss: 0.5836081393793517 ROC AUC: 0.9267274844720496\n",
      "138 12 0.09250076860189438\n",
      "Validation loss: 0.8269938633722418 ROC AUC: 0.8901397515527949\n",
      "139 11 0.06397169828414917\n",
      "Validation loss: 0.41564902940801546 ROC AUC: 0.9406055900621118\n",
      "140 10 0.08513987809419632\n",
      "Validation loss: 0.6990917827568802 ROC AUC: 0.9134316770186335\n",
      "141 9 0.08394501358270645\n",
      "Validation loss: 0.6736510734932095 ROC AUC: 0.9165372670807455\n",
      "142 8 0.04326995462179184\n",
      "Validation loss: 0.7150779027564853 ROC AUC: 0.907705745341615\n",
      "143 7 0.250852108001709\n",
      "Validation loss: 0.6652807675155938 ROC AUC: 0.9267274844720497\n",
      "144 6 0.07889451086521149\n",
      "Validation loss: 0.8178103466828665 ROC AUC: 0.923427795031056\n",
      "145 5 0.21760401129722595\n",
      "Validation loss: 0.8078717577691171 ROC AUC: 0.8968361801242236\n",
      "146 4 0.08088076859712601\n",
      "Validation loss: 0.9873335361480713 ROC AUC: 0.918866459627329\n",
      "147 3 0.082506462931633\n",
      "Validation loss: 0.5066319820927638 ROC AUC: 0.9376940993788822\n",
      "148 2 0.06673361361026764\n",
      "Validation loss: 0.682396320735707 ROC AUC: 0.924398291925466\n",
      "149 1 0.08796140551567078\n",
      "Validation loss: 0.6231453646631802 ROC AUC: 0.9128493788819876\n",
      "150 0 0.07514538615942001\n",
      "150 50 0.19030635058879852\n",
      "Validation loss: 0.5849988133299584 ROC AUC: 0.9170225155279503\n",
      "151 49 0.10989189147949219\n",
      "Validation loss: 0.6906148405636058 ROC AUC: 0.9102290372670807\n",
      "152 48 0.10509662330150604\n",
      "Validation loss: 0.7680294043293187 ROC AUC: 0.9100349378881987\n",
      "153 47 0.08042126893997192\n",
      "Validation loss: 0.9932271335639206 ROC AUC: 0.8948951863354038\n",
      "154 46 0.2627028524875641\n",
      "Validation loss: 0.9179463830648684 ROC AUC: 0.8849961180124223\n",
      "155 45 0.13707730174064636\n",
      "Validation loss: 0.7362429137323417 ROC AUC: 0.9074145962732919\n",
      "156 44 0.050712160766124725\n",
      "Validation loss: 0.5314069209145564 ROC AUC: 0.9343944099378882\n",
      "157 43 0.20121388137340546\n",
      "Validation loss: 0.8279162598591224 ROC AUC: 0.8948951863354038\n",
      "158 42 0.19931459426879883\n",
      "Validation loss: 1.0125278807153888 ROC AUC: 0.8848020186335404\n",
      "159 41 0.0569126270711422\n",
      "Validation loss: 0.8415076765140482 ROC AUC: 0.9089673913043479\n",
      "160 40 0.05173686891794205\n",
      "Validation loss: 0.8584836253932878 ROC AUC: 0.891110248447205\n",
      "161 39 0.05013010650873184\n",
      "Validation loss: 0.5270694914986106 ROC AUC: 0.9266304347826088\n",
      "162 38 0.024490125477313995\n",
      "Validation loss: 0.6577479769201839 ROC AUC: 0.9189635093167702\n",
      "163 37 0.11324810236692429\n",
      "Validation loss: 0.6853099348498326 ROC AUC: 0.9278920807453416\n",
      "164 36 0.03702620789408684\n",
      "Validation loss: 0.8208416000684249 ROC AUC: 0.9000388198757764\n",
      "165 35 0.13291151821613312\n",
      "Validation loss: 0.5257219029407875 ROC AUC: 0.9374999999999999\n",
      "166 34 0.06907311826944351\n",
      "Validation loss: 0.8344432524606293 ROC AUC: 0.906541149068323\n",
      "167 33 0.041403986513614655\n",
      "Validation loss: 0.9200026821710315 ROC AUC: 0.8883928571428571\n",
      "168 32 0.10890024155378342\n",
      "Validation loss: 1.0583911187508528 ROC AUC: 0.8967391304347827\n",
      "169 31 0.11111649125814438\n",
      "Validation loss: 0.8094701582894606 ROC AUC: 0.8947981366459626\n",
      "170 30 0.051154449582099915\n",
      "Validation loss: 0.7603304713380103 ROC AUC: 0.9125582298136646\n",
      "171 29 0.09587248414754868\n",
      "Validation loss: 0.8554853449265162 ROC AUC: 0.9037267080745341\n",
      "172 28 0.11016164720058441\n",
      "Validation loss: 0.7214793194742763 ROC AUC: 0.90430900621118\n",
      "173 27 0.10777559131383896\n",
      "Validation loss: 0.821175173217175 ROC AUC: 0.9121700310559006\n",
      "174 26 0.05384844169020653\n",
      "Validation loss: 0.8743591840360679 ROC AUC: 0.8993594720496894\n",
      "175 25 0.0983935296535492\n",
      "Validation loss: 1.0667914140458201 ROC AUC: 0.8804347826086956\n",
      "176 24 0.07579086720943451\n",
      "Validation loss: 0.7767139328461067 ROC AUC: 0.9090644409937887\n",
      "177 23 0.09733063727617264\n",
      "Validation loss: 0.9220032575083714 ROC AUC: 0.8976125776397516\n",
      "178 22 0.0474325492978096\n",
      "Validation loss: 0.839347412115803 ROC AUC: 0.8964479813664596\n",
      "179 21 0.03287835046648979\n",
      "Validation loss: 0.7852520007713168 ROC AUC: 0.9135287267080745\n",
      "180 20 0.042814239859580994\n",
      "Validation loss: 0.7486868699391683 ROC AUC: 0.9109083850931676\n",
      "181 19 0.07977606356143951\n",
      "Validation loss: 0.7215209784461003 ROC AUC: 0.920613354037267\n",
      "182 18 0.029153907671570778\n",
      "Validation loss: 0.7909337854852864 ROC AUC: 0.8942158385093167\n",
      "183 17 0.13943004608154297\n",
      "Validation loss: 0.634338388000341 ROC AUC: 0.9231366459627329\n",
      "184 16 0.1459047943353653\n",
      "Validation loss: 0.5836243629455566 ROC AUC: 0.9291537267080744\n",
      "185 15 0.0521477535367012\n",
      "Validation loss: 0.8975916586670221 ROC AUC: 0.8818905279503105\n",
      "186 14 0.09680220484733582\n",
      "Validation loss: 0.7134989523420147 ROC AUC: 0.906055900621118\n",
      "187 13 0.09988954663276672\n",
      "Validation loss: 0.9093446988685459 ROC AUC: 0.9098408385093166\n",
      "188 12 0.06744873523712158\n",
      "Validation loss: 0.6242184841311446 ROC AUC: 0.9266304347826088\n",
      "189 11 0.029990792274475098\n",
      "Validation loss: 0.961798185226964 ROC AUC: 0.8930512422360248\n",
      "190 10 0.024284426122903824\n",
      "Validation loss: 0.797178655278449 ROC AUC: 0.9078027950310558\n",
      "191 9 0.05138488858938217\n",
      "Validation loss: 0.6726573619023696 ROC AUC: 0.9230395962732919\n",
      "192 8 0.029285671189427376\n",
      "Validation loss: 0.5881914888307744 ROC AUC: 0.9340062111801243\n",
      "193 7 0.03496728837490082\n",
      "Validation loss: 0.6612901757745182 ROC AUC: 0.9262422360248448\n",
      "194 6 0.18263545632362366\n",
      "Validation loss: 0.7824888252744487 ROC AUC: 0.9033385093167702\n",
      "195 5 0.04576139152050018\n",
      "Validation loss: 0.7511087211908078 ROC AUC: 0.9114906832298137\n",
      "196 4 0.02347227744758129\n",
      "Validation loss: 0.8778679869046399 ROC AUC: 0.9104231366459627\n",
      "197 3 0.05560993030667305\n",
      "Validation loss: 0.9608006664350921 ROC AUC: 0.8849961180124223\n",
      "198 2 0.051581475883722305\n",
      "Validation loss: 0.7326278826769661 ROC AUC: 0.9199340062111802\n",
      "199 1 0.018053218722343445\n",
      "Validation loss: 0.6559133646534938 ROC AUC: 0.9240100931677019\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.480814260594985 Test ROC AUC: 0.7150977936217361\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bbbp', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 778, 'task': 'classification', 'data_path': 'data/bbbp/BBBP.csv', 'target': ['p_np']}}\n",
      "Running on: cuda:1\n",
      "2038\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/2038\n",
      "Generating scaffold 1000/2038\n",
      "Generating scaffold 2000/2038\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 8.496545791625977\n",
      "0 50 2.3895366191864014\n",
      "Validation loss: 0.7708610366372501 ROC AUC: 0.8576281055900621\n",
      "1 49 1.5413107872009277\n",
      "Validation loss: 0.5330266870704352 ROC AUC: 0.8975155279503105\n",
      "2 48 1.565104365348816\n",
      "Validation loss: 0.475020170211792 ROC AUC: 0.8962538819875775\n",
      "3 47 1.0528557300567627\n",
      "Validation loss: 0.5910117065205294 ROC AUC: 0.9020768633540373\n",
      "4 46 0.9798552989959717\n",
      "Validation loss: 0.45338938984216426 ROC AUC: 0.8978066770186335\n",
      "5 45 1.0978071689605713\n",
      "Validation loss: 0.4731010969947366 ROC AUC: 0.9124611801242235\n",
      "6 44 0.875252366065979\n",
      "Validation loss: 0.5035187344925076 ROC AUC: 0.8990683229813664\n",
      "7 43 0.9772627353668213\n",
      "Validation loss: 0.4032726699815077 ROC AUC: 0.9036296583850929\n",
      "8 42 0.6546658873558044\n",
      "Validation loss: 0.5142344096127678 ROC AUC: 0.891110248447205\n",
      "9 41 0.6258500814437866\n",
      "Validation loss: 0.4117509640899359 ROC AUC: 0.9263392857142857\n",
      "10 40 0.6052187085151672\n",
      "Validation loss: 0.4211130153899099 ROC AUC: 0.9144021739130435\n",
      "11 39 0.518197238445282\n",
      "Validation loss: 0.38192112305585074 ROC AUC: 0.9180900621118012\n",
      "12 38 0.5502830743789673\n",
      "Validation loss: 0.5392311846508699 ROC AUC: 0.8969332298136645\n",
      "13 37 0.42090460658073425\n",
      "Validation loss: 0.4286804213827732 ROC AUC: 0.9332298136645962\n",
      "14 36 0.47652435302734375\n",
      "Validation loss: 0.4671743114789327 ROC AUC: 0.9144992236024845\n",
      "15 35 0.4114536941051483\n",
      "Validation loss: 0.38492661480810125 ROC AUC: 0.9289596273291925\n",
      "16 34 0.3595923185348511\n",
      "Validation loss: 0.5080749719750648 ROC AUC: 0.8960597826086956\n",
      "17 33 0.3935577869415283\n",
      "Validation loss: 0.4805336822481716 ROC AUC: 0.8927600931677018\n",
      "18 32 0.5277153849601746\n",
      "Validation loss: 0.3645002660798092 ROC AUC: 0.9286684782608697\n",
      "19 31 0.31586259603500366\n",
      "Validation loss: 0.35975104102901384 ROC AUC: 0.9331327639751552\n",
      "20 30 0.5629652142524719\n",
      "Validation loss: 0.39431870721426665 ROC AUC: 0.9264363354037266\n",
      "21 29 0.5013423562049866\n",
      "Validation loss: 0.5161864815973768 ROC AUC: 0.8998447204968945\n",
      "22 28 0.3107738792896271\n",
      "Validation loss: 0.49744564411686915 ROC AUC: 0.9149844720496895\n",
      "23 27 0.32005757093429565\n",
      "Validation loss: 0.4354197070294735 ROC AUC: 0.9144992236024845\n",
      "24 26 0.3766832947731018\n",
      "Validation loss: 0.41252029058980005 ROC AUC: 0.9320652173913044\n",
      "25 25 0.5356705784797668\n",
      "Validation loss: 0.3761589427789052 ROC AUC: 0.9276009316770187\n",
      "26 24 0.37346142530441284\n",
      "Validation loss: 0.4938753235573862 ROC AUC: 0.9181871118012421\n",
      "27 23 0.18431037664413452\n",
      "Validation loss: 0.5408800852064993 ROC AUC: 0.8833462732919254\n",
      "28 22 0.31318020820617676\n",
      "Validation loss: 0.40513141949971515 ROC AUC: 0.9177018633540371\n",
      "29 21 0.3261200487613678\n",
      "Validation loss: 0.5288016720145357 ROC AUC: 0.9103260869565217\n",
      "30 20 0.23539409041404724\n",
      "Validation loss: 0.44153028960321467 ROC AUC: 0.9037267080745341\n",
      "31 19 0.3684402406215668\n",
      "Validation loss: 0.4143161645122603 ROC AUC: 0.9252717391304346\n",
      "32 18 0.29579347372055054\n",
      "Validation loss: 0.39545944800563887 ROC AUC: 0.920710403726708\n",
      "33 17 0.320604145526886\n",
      "Validation loss: 0.40184050973723917 ROC AUC: 0.9346855590062112\n",
      "34 16 0.2466961145401001\n",
      "Validation loss: 0.4259289655030942 ROC AUC: 0.9284743788819875\n",
      "35 15 0.25578004121780396\n",
      "Validation loss: 0.44401392808147505 ROC AUC: 0.9190605590062111\n",
      "36 14 0.2268742322921753\n",
      "Validation loss: 0.42436714967091876 ROC AUC: 0.9292507763975155\n",
      "37 13 0.2921174168586731\n",
      "Validation loss: 0.6015120534335866 ROC AUC: 0.8802406832298136\n",
      "38 12 0.20116649568080902\n",
      "Validation loss: 0.5422572435117236 ROC AUC: 0.9012034161490684\n",
      "39 11 0.3649943768978119\n",
      "Validation loss: 0.4646613539433947 ROC AUC: 0.9273097826086956\n",
      "40 10 0.18429267406463623\n",
      "Validation loss: 0.5171306939686046 ROC AUC: 0.8977096273291925\n",
      "41 9 0.16058214008808136\n",
      "Validation loss: 0.44729745066633414 ROC AUC: 0.9141110248447205\n",
      "42 8 0.18762823939323425\n",
      "Validation loss: 0.4642393811076295 ROC AUC: 0.903144409937888\n",
      "43 7 0.32103124260902405\n",
      "Validation loss: 0.46459776338408976 ROC AUC: 0.9210015527950312\n",
      "44 6 0.3138003349304199\n",
      "Validation loss: 0.45847146213054657 ROC AUC: 0.9252717391304348\n",
      "45 5 0.30913376808166504\n",
      "Validation loss: 0.4228495756785075 ROC AUC: 0.9263392857142857\n",
      "46 4 0.19598455727100372\n",
      "Validation loss: 0.5420247573478549 ROC AUC: 0.889751552795031\n",
      "47 3 0.10984684526920319\n",
      "Validation loss: 0.4073980538284077 ROC AUC: 0.9278920807453417\n",
      "48 2 0.43175598978996277\n",
      "Validation loss: 0.5214048904531142 ROC AUC: 0.8939246894409938\n",
      "49 1 0.2567133903503418\n",
      "Validation loss: 0.4140000281234582 ROC AUC: 0.9127523291925466\n",
      "50 0 0.274812787771225\n",
      "50 50 0.15220612287521362\n",
      "Validation loss: 0.6661893012476903 ROC AUC: 0.8475349378881987\n",
      "51 49 0.19600071012973785\n",
      "Validation loss: 0.38501546663396496 ROC AUC: 0.9316770186335404\n",
      "52 48 0.14988481998443604\n",
      "Validation loss: 0.4757410065800536 ROC AUC: 0.9183812111801243\n",
      "53 47 0.4911583662033081\n",
      "Validation loss: 0.49037201965556426 ROC AUC: 0.8999417701863354\n",
      "54 46 0.18804234266281128\n",
      "Validation loss: 0.5094196915480436 ROC AUC: 0.9013975155279503\n",
      "55 45 0.22290140390396118\n",
      "Validation loss: 0.7902495627309761 ROC AUC: 0.8675271739130435\n",
      "56 44 0.18329459428787231\n",
      "Validation loss: 0.3943638976882486 ROC AUC: 0.9329386645962733\n",
      "57 43 0.11665515601634979\n",
      "Validation loss: 0.41410093506177265 ROC AUC: 0.9243012422360248\n",
      "58 42 0.2646164298057556\n",
      "Validation loss: 0.6579867098845688 ROC AUC: 0.8945069875776399\n",
      "59 41 0.13921315968036652\n",
      "Validation loss: 0.6282247228949678 ROC AUC: 0.8815023291925467\n",
      "60 40 0.19060233235359192\n",
      "Validation loss: 0.48397064092112524 ROC AUC: 0.9181871118012424\n",
      "61 39 0.3187709450721741\n",
      "Validation loss: 0.506468811455895 ROC AUC: 0.9161490683229813\n",
      "62 38 0.3181498050689697\n",
      "Validation loss: 0.4667942290212594 ROC AUC: 0.9246894409937888\n",
      "63 37 0.23277713358402252\n",
      "Validation loss: 0.5019786825367049 ROC AUC: 0.9140139751552795\n",
      "64 36 0.2543029487133026\n",
      "Validation loss: 0.5296786111943862 ROC AUC: 0.9083850931677019\n",
      "65 35 0.0691283717751503\n",
      "Validation loss: 0.7283881411832922 ROC AUC: 0.8999417701863354\n",
      "66 34 0.14791445434093475\n",
      "Validation loss: 0.5176344747636833 ROC AUC: 0.9138198757763976\n",
      "67 33 0.13300365209579468\n",
      "Validation loss: 0.5514984761967379 ROC AUC: 0.9006211180124224\n",
      "68 32 0.0734972134232521\n",
      "Validation loss: 0.6014186520786846 ROC AUC: 0.8939246894409938\n",
      "69 31 0.2210749089717865\n",
      "Validation loss: 0.6299096182280896 ROC AUC: 0.8784937888198758\n",
      "70 30 0.33093011379241943\n",
      "Validation loss: 0.5580528749554765 ROC AUC: 0.9013004658385094\n",
      "71 29 0.35782724618911743\n",
      "Validation loss: 0.5655241667055616 ROC AUC: 0.9149844720496894\n",
      "72 28 0.11860260367393494\n",
      "Validation loss: 0.514815187921711 ROC AUC: 0.9185753105590063\n",
      "73 27 0.10795147716999054\n",
      "Validation loss: 0.4295537991850984 ROC AUC: 0.9276979813664595\n",
      "74 26 0.10527173429727554\n",
      "Validation loss: 0.46124749674516563 ROC AUC: 0.9226513975155279\n",
      "75 25 0.27714964747428894\n",
      "Validation loss: 0.6407115658124288 ROC AUC: 0.890430900621118\n",
      "76 24 0.2718062400817871\n",
      "Validation loss: 0.4647141735927731 ROC AUC: 0.9334239130434783\n",
      "77 23 0.21433007717132568\n",
      "Validation loss: 0.6871099489576676 ROC AUC: 0.858501552795031\n",
      "78 22 0.0964292362332344\n",
      "Validation loss: 0.46895478110687405 ROC AUC: 0.9223602484472049\n",
      "79 21 0.17576180398464203\n",
      "Validation loss: 0.7308843392951816 ROC AUC: 0.8864518633540373\n",
      "80 20 0.11489062756299973\n",
      "Validation loss: 0.5683947781137392 ROC AUC: 0.9059588509316772\n",
      "81 19 0.282757431268692\n",
      "Validation loss: 0.47539451835202234 ROC AUC: 0.90722049689441\n",
      "82 18 0.34060847759246826\n",
      "Validation loss: 0.48773155609766644 ROC AUC: 0.9185753105590062\n",
      "83 17 0.11240461468696594\n",
      "Validation loss: 1.0585078164642931 ROC AUC: 0.8454968944099378\n",
      "84 16 0.12631802260875702\n",
      "Validation loss: 0.5500888029734293 ROC AUC: 0.9022709627329193\n",
      "85 15 0.16572386026382446\n",
      "Validation loss: 0.5641179017576516 ROC AUC: 0.9177989130434783\n",
      "86 14 0.15400081872940063\n",
      "Validation loss: 0.6244086097268498 ROC AUC: 0.9043090062111802\n",
      "87 13 0.2009841501712799\n",
      "Validation loss: 0.85516652172687 ROC AUC: 0.8911102484472049\n",
      "88 12 0.17058128118515015\n",
      "Validation loss: 0.4063729959375718 ROC AUC: 0.9309976708074535\n",
      "89 11 0.159083753824234\n",
      "Validation loss: 0.4444703842495002 ROC AUC: 0.922651397515528\n",
      "90 10 0.16579562425613403\n",
      "Validation loss: 0.5930217370098713 ROC AUC: 0.9180900621118012\n",
      "91 9 0.11664500832557678\n",
      "Validation loss: 0.6309131582578024 ROC AUC: 0.9058618012422361\n",
      "92 8 0.07680163532495499\n",
      "Validation loss: 0.7205007520376467 ROC AUC: 0.9100349378881988\n",
      "93 7 0.2161409854888916\n",
      "Validation loss: 0.5190937963186526 ROC AUC: 0.9123641304347827\n",
      "94 6 0.07478151470422745\n",
      "Validation loss: 0.6163781682650248 ROC AUC: 0.920807453416149\n",
      "95 5 0.10202092677354813\n",
      "Validation loss: 0.7423597948223937 ROC AUC: 0.9116847826086957\n",
      "96 4 0.25782305002212524\n",
      "Validation loss: 0.547260935838316 ROC AUC: 0.9188664596273293\n",
      "97 3 0.17392581701278687\n",
      "Validation loss: 0.6133140489166858 ROC AUC: 0.9100349378881987\n",
      "98 2 0.11013492941856384\n",
      "Validation loss: 0.5361670781584347 ROC AUC: 0.9184782608695651\n",
      "99 1 0.2247718721628189\n",
      "Validation loss: 0.7035674838458791 ROC AUC: 0.90625\n",
      "100 0 0.14411745965480804\n",
      "100 50 0.2080773115158081\n",
      "Validation loss: 0.5123124812163559 ROC AUC: 0.9222631987577639\n",
      "101 49 0.046772897243499756\n",
      "Validation loss: 0.5551606881998333 ROC AUC: 0.9187694099378881\n",
      "102 48 0.11398350447416306\n",
      "Validation loss: 0.6397365837120542 ROC AUC: 0.904600155279503\n",
      "103 47 0.18630802631378174\n",
      "Validation loss: 0.659511008683373 ROC AUC: 0.9063470496894409\n",
      "104 46 0.21665747463703156\n",
      "Validation loss: 0.6157264727003434 ROC AUC: 0.8942158385093169\n",
      "105 45 0.07230713218450546\n",
      "Validation loss: 0.49311595220191806 ROC AUC: 0.9327445652173912\n",
      "106 44 0.14413927495479584\n",
      "Validation loss: 0.5753986319052238 ROC AUC: 0.9353649068322981\n",
      "107 43 0.5821163058280945\n",
      "Validation loss: 0.8487371591960683 ROC AUC: 0.8957686335403727\n",
      "108 42 0.07543539255857468\n",
      "Validation loss: 0.6453799511872086 ROC AUC: 0.891498447204969\n",
      "109 41 0.11766094714403152\n",
      "Validation loss: 0.8158874651964974 ROC AUC: 0.890625\n",
      "110 40 0.36972466111183167\n",
      "Validation loss: 0.6127075547096776 ROC AUC: 0.9196428571428571\n",
      "111 39 0.16823945939540863\n",
      "Validation loss: 0.5051693757082901 ROC AUC: 0.9326475155279503\n",
      "112 38 0.17706605792045593\n",
      "Validation loss: 0.8256857395172119 ROC AUC: 0.8968361801242236\n",
      "113 37 0.251375675201416\n",
      "Validation loss: 0.5927159634290957 ROC AUC: 0.9263392857142857\n",
      "114 36 0.1889243721961975\n",
      "Validation loss: 0.5557277810339835 ROC AUC: 0.9183812111801242\n",
      "115 35 0.23048672080039978\n",
      "Validation loss: 0.5413301771908414 ROC AUC: 0.9178959627329192\n",
      "116 34 0.47352978587150574\n",
      "Validation loss: 0.6145551473486657 ROC AUC: 0.9014945652173912\n",
      "117 33 0.10469448566436768\n",
      "Validation loss: 0.5206376357259703 ROC AUC: 0.922457298136646\n",
      "118 32 0.19390903413295746\n",
      "Validation loss: 0.5619653784761242 ROC AUC: 0.9185753105590062\n",
      "119 31 0.1262291967868805\n",
      "Validation loss: 0.6291650521988962 ROC AUC: 0.9121700310559006\n",
      "120 30 0.10142156481742859\n",
      "Validation loss: 0.5812985908751395 ROC AUC: 0.9302212732919254\n",
      "121 29 0.09006507694721222\n",
      "Validation loss: 0.5546679017590541 ROC AUC: 0.9260481366459627\n",
      "122 28 0.1231745108962059\n",
      "Validation loss: 0.49810360810335946 ROC AUC: 0.9461374223602484\n",
      "123 27 0.1278373897075653\n",
      "Validation loss: 0.5337151686350504 ROC AUC: 0.9334239130434783\n",
      "124 26 0.10638623684644699\n",
      "Validation loss: 0.6876271285262763 ROC AUC: 0.9094526397515528\n",
      "125 25 0.12085762619972229\n",
      "Validation loss: 0.8494948388314715 ROC AUC: 0.8937305900621119\n",
      "126 24 0.12303192168474197\n",
      "Validation loss: 0.48908018832113226 ROC AUC: 0.9338121118012422\n",
      "127 23 0.03786907717585564\n",
      "Validation loss: 0.6828401094558192 ROC AUC: 0.8996506211180124\n",
      "128 22 0.06518065929412842\n",
      "Validation loss: 0.5618828521201423 ROC AUC: 0.9305124223602484\n",
      "129 21 0.0390169583261013\n",
      "Validation loss: 0.5707748879988989 ROC AUC: 0.9186723602484471\n",
      "130 20 0.05221494287252426\n",
      "Validation loss: 0.6279439926147461 ROC AUC: 0.9211956521739131\n",
      "131 19 0.04044709727168083\n",
      "Validation loss: 0.7039278219727909 ROC AUC: 0.9114906832298136\n",
      "132 18 0.03133959323167801\n",
      "Validation loss: 0.48319512247747065 ROC AUC: 0.9265333850931677\n",
      "133 17 0.48875585198402405\n",
      "Validation loss: 0.5293342810051114 ROC AUC: 0.9300271739130433\n",
      "134 16 0.03601260483264923\n",
      "Validation loss: 0.58380519175062 ROC AUC: 0.9268245341614908\n",
      "135 15 0.1663503348827362\n",
      "Validation loss: 0.732710201366275 ROC AUC: 0.9187694099378882\n",
      "136 14 0.18124233186244965\n",
      "Validation loss: 0.6277138976489797 ROC AUC: 0.9272127329192547\n",
      "137 13 0.13907456398010254\n",
      "Validation loss: 0.6574135685668272 ROC AUC: 0.9171195652173914\n",
      "138 12 0.08669599145650864\n",
      "Validation loss: 0.5672952180509182 ROC AUC: 0.9273097826086957\n",
      "139 11 0.20638786256313324\n",
      "Validation loss: 0.6343810184329164 ROC AUC: 0.9316770186335404\n",
      "140 10 0.15210360288619995\n",
      "Validation loss: 0.9818048500547222 ROC AUC: 0.9021739130434782\n",
      "141 9 0.045712511986494064\n",
      "Validation loss: 0.5923399434370153 ROC AUC: 0.9326475155279503\n",
      "142 8 0.1486467719078064\n",
      "Validation loss: 0.7768048211640003 ROC AUC: 0.921486801242236\n",
      "143 7 0.13897328078746796\n",
      "Validation loss: 0.8207469687742346 ROC AUC: 0.9077057453416149\n",
      "144 6 0.17371508479118347\n",
      "Validation loss: 0.7384278154840657 ROC AUC: 0.9168284161490684\n",
      "145 5 0.08264143019914627\n",
      "Validation loss: 0.7194848446285024 ROC AUC: 0.9265333850931677\n",
      "146 4 0.10467234253883362\n",
      "Validation loss: 0.6328812919411004 ROC AUC: 0.9205163043478259\n",
      "147 3 0.05874304100871086\n",
      "Validation loss: 0.6278878654919419 ROC AUC: 0.9303183229813665\n",
      "148 2 0.05462650954723358\n",
      "Validation loss: 0.8466794420691097 ROC AUC: 0.9216809006211181\n",
      "149 1 0.1316886693239212\n",
      "Validation loss: 0.7623849733203065 ROC AUC: 0.9121700310559007\n",
      "150 0 0.1714690923690796\n",
      "150 50 0.058189116418361664\n",
      "Validation loss: 0.6233681475414949 ROC AUC: 0.9145962732919255\n",
      "151 49 0.05803004652261734\n",
      "Validation loss: 0.6019418788891212 ROC AUC: 0.9243982919254659\n",
      "152 48 0.04741459712386131\n",
      "Validation loss: 0.8058118890313541 ROC AUC: 0.9057647515527949\n",
      "153 47 0.11531023681163788\n",
      "Validation loss: 0.8584086959268532 ROC AUC: 0.9041149068322982\n",
      "154 46 0.11355122178792953\n",
      "Validation loss: 0.5225645534548105 ROC AUC: 0.9309006211180124\n",
      "155 45 0.14402668178081512\n",
      "Validation loss: 0.5931703961801296 ROC AUC: 0.9176048136645963\n",
      "156 44 0.06818779557943344\n",
      "Validation loss: 0.687368631362915 ROC AUC: 0.9131405279503106\n",
      "157 43 0.06938037276268005\n",
      "Validation loss: 0.9201957891676941 ROC AUC: 0.9041149068322981\n",
      "158 42 0.2363991141319275\n",
      "Validation loss: 0.7357146628931457 ROC AUC: 0.9260481366459627\n",
      "159 41 0.10179015249013901\n",
      "Validation loss: 0.7042491921022827 ROC AUC: 0.921972049689441\n",
      "160 40 0.15101636946201324\n",
      "Validation loss: 0.6775614790910599 ROC AUC: 0.9138198757763976\n",
      "161 39 0.05596841871738434\n",
      "Validation loss: 0.7724147041638693 ROC AUC: 0.9053765527950308\n",
      "162 38 0.03414876386523247\n",
      "Validation loss: 0.6849403614726137 ROC AUC: 0.9161490683229814\n",
      "163 37 0.054256197065114975\n",
      "Validation loss: 0.6323675730941343 ROC AUC: 0.9283773291925467\n",
      "164 36 0.10983190685510635\n",
      "Validation loss: 0.6286764600697685 ROC AUC: 0.9357531055900621\n",
      "165 35 0.039819248020648956\n",
      "Validation loss: 0.7425908387876025 ROC AUC: 0.9282802795031055\n",
      "166 34 0.005458597093820572\n",
      "Validation loss: 0.6779264328526515 ROC AUC: 0.9277950310559006\n",
      "167 33 0.04669248312711716\n",
      "Validation loss: 0.5164180665331728 ROC AUC: 0.9426436335403725\n",
      "168 32 0.03277607262134552\n",
      "Validation loss: 0.8154420817599577 ROC AUC: 0.9136257763975155\n",
      "169 31 0.22891607880592346\n",
      "Validation loss: 0.7023113864455738 ROC AUC: 0.9241071428571429\n",
      "170 30 0.08176977932453156\n",
      "Validation loss: 0.7599755511710456 ROC AUC: 0.9257569875776397\n",
      "171 29 0.02527076005935669\n",
      "Validation loss: 0.7580782502305274 ROC AUC: 0.9104231366459627\n",
      "172 28 0.07032692432403564\n",
      "Validation loss: 0.9866119646558574 ROC AUC: 0.9105201863354037\n",
      "173 27 0.06176004186272621\n",
      "Validation loss: 0.7726428234109691 ROC AUC: 0.9071234472049691\n",
      "174 26 0.13085219264030457\n",
      "Validation loss: 0.6612091181324977 ROC AUC: 0.9271156832298136\n",
      "175 25 0.15263745188713074\n",
      "Validation loss: 0.5193018697056115 ROC AUC: 0.9371118012422359\n",
      "176 24 0.11416138708591461\n",
      "Validation loss: 0.9007749101694893 ROC AUC: 0.9118788819875777\n",
      "177 23 0.0708632692694664\n",
      "Validation loss: 0.5854997693323621 ROC AUC: 0.9264363354037266\n",
      "178 22 0.1296277493238449\n",
      "Validation loss: 0.69511545697848 ROC AUC: 0.9231366459627328\n",
      "179 21 0.12131132185459137\n",
      "Validation loss: 0.5220292029427547 ROC AUC: 0.936917701863354\n",
      "180 20 0.15358947217464447\n",
      "Validation loss: 0.6374509194317985 ROC AUC: 0.9144992236024844\n",
      "181 19 0.05221845209598541\n",
      "Validation loss: 0.7028581091001922 ROC AUC: 0.9219720496894409\n",
      "182 18 0.027918267995119095\n",
      "Validation loss: 0.6370633358464521 ROC AUC: 0.936141304347826\n",
      "183 17 0.08775477111339569\n",
      "Validation loss: 0.6782505640796587 ROC AUC: 0.9127523291925466\n",
      "184 16 0.07179059833288193\n",
      "Validation loss: 0.6619597039386338 ROC AUC: 0.9304153726708074\n",
      "185 15 0.034394197165966034\n",
      "Validation loss: 0.7268037760958952 ROC AUC: 0.922069099378882\n",
      "186 14 0.052335552871227264\n",
      "Validation loss: 0.7150375661896724 ROC AUC: 0.9086762422360247\n",
      "187 13 0.04317916929721832\n",
      "Validation loss: 0.8298399463003757 ROC AUC: 0.9080939440993788\n",
      "188 12 0.05737818032503128\n",
      "Validation loss: 0.6295736584008909 ROC AUC: 0.9231366459627329\n",
      "189 11 0.13544349372386932\n",
      "Validation loss: 0.5521578297895544 ROC AUC: 0.9371118012422361\n",
      "190 10 0.09691689908504486\n",
      "Validation loss: 0.6384445288602043 ROC AUC: 0.9195458074534162\n",
      "191 9 0.031987518072128296\n",
      "Validation loss: 0.8622442705958497 ROC AUC: 0.9131405279503106\n",
      "192 8 0.06322333216667175\n",
      "Validation loss: 0.8255738031630423 ROC AUC: 0.9179930124223603\n",
      "193 7 0.05239678919315338\n",
      "Validation loss: 0.5703046637422898 ROC AUC: 0.9289596273291927\n",
      "194 6 0.037197526544332504\n",
      "Validation loss: 0.6216177192388797 ROC AUC: 0.9255628881987578\n",
      "195 5 0.027760004624724388\n",
      "Validation loss: 0.7287347421926611 ROC AUC: 0.9198369565217391\n",
      "196 4 0.018731828778982162\n",
      "Validation loss: 0.6094979120820176 ROC AUC: 0.9330357142857142\n",
      "197 3 0.11239570379257202\n",
      "Validation loss: 0.6409454380764681 ROC AUC: 0.9292507763975155\n",
      "198 2 0.04578276723623276\n",
      "Validation loss: 0.5993786769754746 ROC AUC: 0.9381793478260869\n",
      "199 1 0.017115505412220955\n",
      "Validation loss: 0.6313232169943113 ROC AUC: 0.9295419254658386\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.6333956239270229 Test ROC AUC: 0.7552750746700067\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bbbp', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 779, 'task': 'classification', 'data_path': 'data/bbbp/BBBP.csv', 'target': ['p_np']}}\n",
      "Running on: cuda:1\n",
      "2038\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/2038\n",
      "Generating scaffold 1000/2038\n",
      "Generating scaffold 2000/2038\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 8.357583999633789\n",
      "0 50 2.533517360687256\n",
      "Validation loss: 0.8024212951753654 ROC AUC: 0.8253105590062111\n",
      "1 49 1.6210589408874512\n",
      "Validation loss: 0.5810875331654268 ROC AUC: 0.8947981366459627\n",
      "2 48 1.3321242332458496\n",
      "Validation loss: 0.5551562671567879 ROC AUC: 0.9080939440993788\n",
      "3 47 0.9396325349807739\n",
      "Validation loss: 0.71627018030952 ROC AUC: 0.8873253105590063\n",
      "4 46 0.9748297929763794\n",
      "Validation loss: 0.6017443344873541 ROC AUC: 0.906152950310559\n",
      "5 45 0.9716593623161316\n",
      "Validation loss: 0.4370337689624113 ROC AUC: 0.9121700310559007\n",
      "6 44 0.6953976154327393\n",
      "Validation loss: 0.5090821712624793 ROC AUC: 0.8924689440993789\n",
      "7 43 0.9149968028068542\n",
      "Validation loss: 0.5593594324355032 ROC AUC: 0.8973214285714286\n",
      "8 42 0.6543239951133728\n",
      "Validation loss: 0.4866272994116241 ROC AUC: 0.9099378881987579\n",
      "9 41 0.6394091844558716\n",
      "Validation loss: 0.4507546297767583 ROC AUC: 0.9110054347826086\n",
      "10 40 0.42483270168304443\n",
      "Validation loss: 0.3839121539803112 ROC AUC: 0.9287655279503105\n",
      "11 39 0.45468220114707947\n",
      "Validation loss: 0.4524218393307106 ROC AUC: 0.9206133540372671\n",
      "12 38 0.5415956974029541\n",
      "Validation loss: 0.4590841122702056 ROC AUC: 0.9259510869565216\n",
      "13 37 0.6786075830459595\n",
      "Validation loss: 0.3816187568739349 ROC AUC: 0.9215838509316769\n",
      "14 36 0.3382543623447418\n",
      "Validation loss: 0.4921806822804844 ROC AUC: 0.9054736024844721\n",
      "15 35 0.3753620386123657\n",
      "Validation loss: 0.39450706979807687 ROC AUC: 0.9349767080745341\n",
      "16 34 0.611395001411438\n",
      "Validation loss: 0.3770713338664934 ROC AUC: 0.9349767080745341\n",
      "17 33 0.4073042571544647\n",
      "Validation loss: 0.3923299090535033 ROC AUC: 0.9192546583850933\n",
      "18 32 0.5389983057975769\n",
      "Validation loss: 0.42834000610837747 ROC AUC: 0.9316770186335404\n",
      "19 31 0.48768746852874756\n",
      "Validation loss: 0.3648841544693592 ROC AUC: 0.938373447204969\n",
      "20 30 0.48560047149658203\n",
      "Validation loss: 0.3597442203877019 ROC AUC: 0.9298330745341614\n",
      "21 29 0.33504295349121094\n",
      "Validation loss: 0.42648566236682967 ROC AUC: 0.9317740683229813\n",
      "22 28 0.3862737715244293\n",
      "Validation loss: 0.5010839572139815 ROC AUC: 0.9184782608695652\n",
      "23 27 0.30982351303100586\n",
      "Validation loss: 0.3950869183914334 ROC AUC: 0.9181871118012422\n",
      "24 26 0.25153475999832153\n",
      "Validation loss: 0.4186665228768891 ROC AUC: 0.90430900621118\n",
      "25 25 0.22775742411613464\n",
      "Validation loss: 0.48236480530570536 ROC AUC: 0.8846079192546584\n",
      "26 24 0.2506939172744751\n",
      "Validation loss: 0.4326649132896872 ROC AUC: 0.921777950310559\n",
      "27 23 0.3115066885948181\n",
      "Validation loss: 0.3947263663890315 ROC AUC: 0.9229425465838508\n",
      "28 22 0.3130187690258026\n",
      "Validation loss: 0.3612900738622628 ROC AUC: 0.9332298136645962\n",
      "29 21 0.27675101161003113\n",
      "Validation loss: 0.45507242282231647 ROC AUC: 0.906055900621118\n",
      "30 20 0.27290087938308716\n",
      "Validation loss: 0.41747963121708703 ROC AUC: 0.9216809006211181\n",
      "31 19 0.12303788959980011\n",
      "Validation loss: 0.3969236778862336 ROC AUC: 0.9175077639751553\n",
      "32 18 0.22701901197433472\n",
      "Validation loss: 0.36743103289136697 ROC AUC: 0.938567546583851\n",
      "33 17 0.5433436632156372\n",
      "Validation loss: 0.32068611009448184 ROC AUC: 0.9396350931677019\n",
      "34 16 0.1609911322593689\n",
      "Validation loss: 0.39792421854594173 ROC AUC: 0.9201281055900621\n",
      "35 15 0.17037054896354675\n",
      "Validation loss: 0.42795075680695327 ROC AUC: 0.9186723602484472\n",
      "36 14 0.28365644812583923\n",
      "Validation loss: 0.35225629324422164 ROC AUC: 0.9211956521739131\n",
      "37 13 0.19820988178253174\n",
      "Validation loss: 0.41340677286772165 ROC AUC: 0.9290566770186335\n",
      "38 12 0.1563219428062439\n",
      "Validation loss: 0.4029540419578552 ROC AUC: 0.9238159937888197\n",
      "39 11 0.2718541622161865\n",
      "Validation loss: 0.37665796338343155 ROC AUC: 0.9299301242236024\n",
      "40 10 0.2404085397720337\n",
      "Validation loss: 0.48299645150409026 ROC AUC: 0.9063470496894409\n",
      "41 9 0.3933987617492676\n",
      "Validation loss: 0.3655997780608196 ROC AUC: 0.9277950310559007\n",
      "42 8 0.20563411712646484\n",
      "Validation loss: 0.42352868923369574 ROC AUC: 0.9346855590062112\n",
      "43 7 0.3382177948951721\n",
      "Validation loss: 0.5114314091556212 ROC AUC: 0.904600155279503\n",
      "44 6 0.2349211573600769\n",
      "Validation loss: 0.5194650526140251 ROC AUC: 0.9050854037267081\n",
      "45 5 0.2446395456790924\n",
      "Validation loss: 0.5541177301430235 ROC AUC: 0.9046972049689441\n",
      "46 4 0.30521512031555176\n",
      "Validation loss: 0.41725489716319475 ROC AUC: 0.9351708074534161\n",
      "47 3 0.22251030802726746\n",
      "Validation loss: 0.42907750255921306 ROC AUC: 0.9280861801242236\n",
      "48 2 0.23547610640525818\n",
      "Validation loss: 0.4872674018728967 ROC AUC: 0.9138198757763975\n",
      "49 1 0.17858706414699554\n",
      "Validation loss: 0.4311870384011783 ROC AUC: 0.92381599378882\n",
      "50 0 0.2288864254951477\n",
      "50 50 0.3232170343399048\n",
      "Validation loss: 0.3966999679219489 ROC AUC: 0.9238159937888197\n",
      "51 49 0.2668127715587616\n",
      "Validation loss: 0.4298929064443298 ROC AUC: 0.9261451863354038\n",
      "52 48 0.17688705027103424\n",
      "Validation loss: 0.40438717077760133 ROC AUC: 0.9424495341614907\n",
      "53 47 0.279300332069397\n",
      "Validation loss: 0.4127013630726758 ROC AUC: 0.9263392857142858\n",
      "54 46 0.20199176669120789\n",
      "Validation loss: 0.4094802950527154 ROC AUC: 0.9299301242236024\n",
      "55 45 0.3255648910999298\n",
      "Validation loss: 0.4377720881910885 ROC AUC: 0.9342973602484472\n",
      "56 44 0.1596813201904297\n",
      "Validation loss: 0.6779423870292365 ROC AUC: 0.8943128881987578\n",
      "57 43 0.3032851219177246\n",
      "Validation loss: 0.4391038502548255 ROC AUC: 0.9206133540372672\n",
      "58 42 0.48597100377082825\n",
      "Validation loss: 0.6174986736447203 ROC AUC: 0.875194099378882\n",
      "59 41 0.189652681350708\n",
      "Validation loss: 0.5821320227548188 ROC AUC: 0.9022709627329193\n",
      "60 40 0.2881065607070923\n",
      "Validation loss: 0.5098366643868241 ROC AUC: 0.905085403726708\n",
      "61 39 0.28825777769088745\n",
      "Validation loss: 0.4705839589530346 ROC AUC: 0.9177018633540373\n",
      "62 38 0.36980584263801575\n",
      "Validation loss: 0.4312989273492028 ROC AUC: 0.9231366459627329\n",
      "63 37 0.15749357640743256\n",
      "Validation loss: 0.5730310023999682 ROC AUC: 0.9021739130434783\n",
      "64 36 0.21633625030517578\n",
      "Validation loss: 0.3800929501360538 ROC AUC: 0.937111801242236\n",
      "65 35 0.08445379137992859\n",
      "Validation loss: 0.3957157512651939 ROC AUC: 0.9379852484472049\n",
      "66 34 0.10980286449193954\n",
      "Validation loss: 0.49735374076693667 ROC AUC: 0.9236218944099379\n",
      "67 33 0.3213733434677124\n",
      "Validation loss: 0.60514462111043 ROC AUC: 0.9082880434782608\n",
      "68 32 0.219829261302948\n",
      "Validation loss: 0.5750422004391166 ROC AUC: 0.9190605590062112\n",
      "69 31 0.07061554491519928\n",
      "Validation loss: 0.3956841656974718 ROC AUC: 0.9308035714285714\n",
      "70 30 0.14238965511322021\n",
      "Validation loss: 0.4324437134406146 ROC AUC: 0.9266304347826086\n",
      "71 29 0.34495240449905396\n",
      "Validation loss: 0.6537390070803025 ROC AUC: 0.8939246894409938\n",
      "72 28 0.2929186522960663\n",
      "Validation loss: 0.4859924035913804 ROC AUC: 0.922166149068323\n",
      "73 27 0.13503096997737885\n",
      "Validation loss: 0.5427371926751792 ROC AUC: 0.9185753105590062\n",
      "74 26 0.2275073230266571\n",
      "Validation loss: 0.5944093618468911 ROC AUC: 0.9110054347826088\n",
      "75 25 0.3475278615951538\n",
      "Validation loss: 0.5536155662700242 ROC AUC: 0.9215838509316769\n",
      "76 24 0.1240597814321518\n",
      "Validation loss: 0.6018323657267234 ROC AUC: 0.889266304347826\n",
      "77 23 0.2036212980747223\n",
      "Validation loss: 0.4788615469839059 ROC AUC: 0.9149844720496895\n",
      "78 22 0.12666937708854675\n",
      "Validation loss: 0.3738065072353564 ROC AUC: 0.9350737577639753\n",
      "79 21 0.21455921232700348\n",
      "Validation loss: 0.6220220771490359 ROC AUC: 0.905376552795031\n",
      "80 20 0.09980061650276184\n",
      "Validation loss: 0.6004641836545631 ROC AUC: 0.9125582298136646\n",
      "81 19 0.06380921602249146\n",
      "Validation loss: 0.5262530919383553 ROC AUC: 0.9101319875776398\n",
      "82 18 0.18176712095737457\n",
      "Validation loss: 0.5198323679905311 ROC AUC: 0.9108113354037268\n",
      "83 17 0.13112522661685944\n",
      "Validation loss: 0.7717287470312679 ROC AUC: 0.8802406832298135\n",
      "84 16 0.22763171792030334\n",
      "Validation loss: 0.4576951417268491 ROC AUC: 0.9243012422360248\n",
      "85 15 0.16612674295902252\n",
      "Validation loss: 0.5789328188288445 ROC AUC: 0.8993594720496894\n",
      "86 14 0.11167140305042267\n",
      "Validation loss: 0.4550499904389475 ROC AUC: 0.9263392857142857\n",
      "87 13 0.21992477774620056\n",
      "Validation loss: 0.43564333284602447 ROC AUC: 0.9304153726708074\n",
      "88 12 0.11192770302295685\n",
      "Validation loss: 0.7581447836230782 ROC AUC: 0.9003299689440993\n",
      "89 11 0.28952574729919434\n",
      "Validation loss: 0.8113352808297849 ROC AUC: 0.8703416149068323\n",
      "90 10 0.09423261880874634\n",
      "Validation loss: 0.48470300143840267 ROC AUC: 0.9236218944099379\n",
      "91 9 0.12566153705120087\n",
      "Validation loss: 0.48180217018314436 ROC AUC: 0.9241071428571428\n",
      "92 8 0.1759095937013626\n",
      "Validation loss: 0.7627040118563408 ROC AUC: 0.8880046583850931\n",
      "93 7 0.18838158249855042\n",
      "Validation loss: 0.6138047038340101 ROC AUC: 0.9248835403726708\n",
      "94 6 0.20734035968780518\n",
      "Validation loss: 0.6073504546109367 ROC AUC: 0.9040178571428573\n",
      "95 5 0.11606138199567795\n",
      "Validation loss: 0.5617843137360087 ROC AUC: 0.9253687888198757\n",
      "96 4 0.15648695826530457\n",
      "Validation loss: 0.5183906775771403 ROC AUC: 0.923913043478261\n",
      "97 3 0.22259731590747833\n",
      "Validation loss: 0.4956087877645212 ROC AUC: 0.9280861801242236\n",
      "98 2 0.08987171202898026\n",
      "Validation loss: 0.5806432078574219 ROC AUC: 0.9287655279503105\n",
      "99 1 0.2098320871591568\n",
      "Validation loss: 0.4005533881923732 ROC AUC: 0.9419642857142856\n",
      "100 0 0.14633622765541077\n",
      "100 50 0.2221904695034027\n",
      "Validation loss: 0.6326031544629265 ROC AUC: 0.9121700310559007\n",
      "101 49 0.23355387151241302\n",
      "Validation loss: 0.510751507153698 ROC AUC: 0.9342973602484471\n",
      "102 48 0.09365318715572357\n",
      "Validation loss: 0.538004542682685 ROC AUC: 0.9041149068322981\n",
      "103 47 0.18264998495578766\n",
      "Validation loss: 0.5452717601084242 ROC AUC: 0.9262422360248446\n",
      "104 46 0.0469806045293808\n",
      "Validation loss: 0.6455146527173472 ROC AUC: 0.9243012422360247\n",
      "105 45 0.08802790939807892\n",
      "Validation loss: 0.5487466495411069 ROC AUC: 0.9215838509316769\n",
      "106 44 0.0893065482378006\n",
      "Validation loss: 0.5555339359185275 ROC AUC: 0.9288625776397516\n",
      "107 43 0.10661940276622772\n",
      "Validation loss: 0.5542320071482191 ROC AUC: 0.9158579192546583\n",
      "108 42 0.11013765633106232\n",
      "Validation loss: 0.8130743670112947 ROC AUC: 0.8989712732919255\n",
      "109 41 0.1853806972503662\n",
      "Validation loss: 0.6908811032772064 ROC AUC: 0.9141110248447204\n",
      "110 40 0.41220709681510925\n",
      "Validation loss: 0.6837509242342967 ROC AUC: 0.905667701863354\n",
      "111 39 0.08221974968910217\n",
      "Validation loss: 0.6763502686631446 ROC AUC: 0.9211956521739131\n",
      "112 38 0.16737310588359833\n",
      "Validation loss: 0.508427586625604 ROC AUC: 0.9315799689440994\n",
      "113 37 0.12290477007627487\n",
      "Validation loss: 0.557943813941058 ROC AUC: 0.9367236024844721\n",
      "114 36 0.10893788188695908\n",
      "Validation loss: 0.5721706901403034 ROC AUC: 0.9116847826086958\n",
      "115 35 0.08636969327926636\n",
      "Validation loss: 0.6011411676219865 ROC AUC: 0.8995535714285714\n",
      "116 34 0.25169873237609863\n",
      "Validation loss: 0.688649855408014 ROC AUC: 0.9026591614906831\n",
      "117 33 0.08178906887769699\n",
      "Validation loss: 0.565853184929081 ROC AUC: 0.9097437888198758\n",
      "118 32 0.08482304960489273\n",
      "Validation loss: 0.5790916844910267 ROC AUC: 0.9165372670807455\n",
      "119 31 0.03411189466714859\n",
      "Validation loss: 0.7065870972240672 ROC AUC: 0.9095496894409938\n",
      "120 30 0.1619160771369934\n",
      "Validation loss: 0.9361899316895241 ROC AUC: 0.906638198757764\n",
      "121 29 0.08468425273895264\n",
      "Validation loss: 0.5787799428491032 ROC AUC: 0.9249805900621118\n",
      "122 28 0.21703872084617615\n",
      "Validation loss: 0.5186406572659811 ROC AUC: 0.92284549689441\n",
      "123 27 0.04566563665866852\n",
      "Validation loss: 0.5729663612677113 ROC AUC: 0.9314829192546583\n",
      "124 26 0.10878127068281174\n",
      "Validation loss: 0.6316472607500413 ROC AUC: 0.9284743788819877\n",
      "125 25 0.15918470919132233\n",
      "Validation loss: 0.7099713577943689 ROC AUC: 0.8967391304347827\n",
      "126 24 0.14566859602928162\n",
      "Validation loss: 0.6137619018554688 ROC AUC: 0.9157608695652173\n",
      "127 23 0.07955555617809296\n",
      "Validation loss: 0.9815739615290773 ROC AUC: 0.8802406832298136\n",
      "128 22 0.2644782066345215\n",
      "Validation loss: 0.6481737774961135 ROC AUC: 0.9156638198757765\n",
      "129 21 0.0988607406616211\n",
      "Validation loss: 0.6265165659726835 ROC AUC: 0.9100349378881988\n",
      "130 20 0.18015851080417633\n",
      "Validation loss: 0.7066255854625328 ROC AUC: 0.9158579192546583\n",
      "131 19 0.20968623459339142\n",
      "Validation loss: 0.6610280064975514 ROC AUC: 0.9230395962732919\n",
      "132 18 0.05349808558821678\n",
      "Validation loss: 0.7848763419132606 ROC AUC: 0.8792701863354038\n",
      "133 17 0.08214004337787628\n",
      "Validation loss: 0.649901667061974 ROC AUC: 0.9196428571428571\n",
      "134 16 0.05971023067831993\n",
      "Validation loss: 0.7323059410441155 ROC AUC: 0.8964479813664595\n",
      "135 15 0.11005168408155441\n",
      "Validation loss: 0.5949485816207587 ROC AUC: 0.9169254658385093\n",
      "136 14 0.07288476824760437\n",
      "Validation loss: 0.7952119486004698 ROC AUC: 0.9153726708074534\n",
      "137 13 0.05086589232087135\n",
      "Validation loss: 0.819953211090144 ROC AUC: 0.9141110248447205\n",
      "138 12 0.08629454672336578\n",
      "Validation loss: 0.6586678074855431 ROC AUC: 0.9203222049689441\n",
      "139 11 0.25145459175109863\n",
      "Validation loss: 0.6626485153740528 ROC AUC: 0.920516304347826\n",
      "140 10 0.06962000578641891\n",
      "Validation loss: 0.7568721899799272 ROC AUC: 0.9149844720496895\n",
      "141 9 0.09231831133365631\n",
      "Validation loss: 0.9702131625484017 ROC AUC: 0.9025621118012421\n",
      "142 8 0.12659448385238647\n",
      "Validation loss: 0.790941854317983 ROC AUC: 0.9088703416149068\n",
      "143 7 0.21095247566699982\n",
      "Validation loss: 0.9979851713367537 ROC AUC: 0.8969332298136646\n",
      "144 6 0.44088271260261536\n",
      "Validation loss: 0.693336240582022 ROC AUC: 0.9194487577639752\n",
      "145 5 0.32246240973472595\n",
      "Validation loss: 0.7231208495065278 ROC AUC: 0.908967391304348\n",
      "146 4 0.037824597209692\n",
      "Validation loss: 0.7218914639716055 ROC AUC: 0.9089673913043477\n",
      "147 3 0.04973205551505089\n",
      "Validation loss: 0.9383254542070276 ROC AUC: 0.9099378881987576\n",
      "148 2 0.14823146164417267\n",
      "Validation loss: 0.7166354001737109 ROC AUC: 0.9181871118012422\n",
      "149 1 0.16405345499515533\n",
      "Validation loss: 0.542648552679548 ROC AUC: 0.9392468944099377\n",
      "150 0 0.026051506400108337\n",
      "150 50 0.13542288541793823\n",
      "Validation loss: 0.7222143399949167 ROC AUC: 0.922166149068323\n",
      "151 49 0.08942997455596924\n",
      "Validation loss: 0.7618092883597402 ROC AUC: 0.9009122670807452\n",
      "152 48 0.01978175900876522\n",
      "Validation loss: 0.7791914355521109 ROC AUC: 0.9076086956521738\n",
      "153 47 0.045721858739852905\n",
      "Validation loss: 0.6578470947695714 ROC AUC: 0.9247864906832298\n",
      "154 46 0.19654229283332825\n",
      "Validation loss: 0.7301992823680242 ROC AUC: 0.9250776397515527\n",
      "155 45 0.11334168165922165\n",
      "Validation loss: 0.8485836316557491 ROC AUC: 0.9106172360248448\n",
      "156 44 0.10028846561908722\n",
      "Validation loss: 0.9381441649268655 ROC AUC: 0.9005240683229814\n",
      "157 43 0.07692089676856995\n",
      "Validation loss: 0.8968445132760441 ROC AUC: 0.8916925465838508\n",
      "158 42 0.0454973429441452\n",
      "Validation loss: 0.8408507792388692 ROC AUC: 0.9114906832298137\n",
      "159 41 0.0507906898856163\n",
      "Validation loss: 0.6897450218013689 ROC AUC: 0.920322204968944\n",
      "160 40 0.04467438906431198\n",
      "Validation loss: 0.6755843402123919 ROC AUC: 0.9276979813664594\n",
      "161 39 0.05517309159040451\n",
      "Validation loss: 0.7515288008486524 ROC AUC: 0.9141110248447204\n",
      "162 38 0.1202206015586853\n",
      "Validation loss: 0.6637549306832108 ROC AUC: 0.9192546583850931\n",
      "163 37 0.2783454358577728\n",
      "Validation loss: 0.6165771925566244 ROC AUC: 0.9251746894409938\n",
      "164 36 0.07962656021118164\n",
      "Validation loss: 0.5487856260117363 ROC AUC: 0.922166149068323\n",
      "165 35 0.08153389394283295\n",
      "Validation loss: 0.622418260457469 ROC AUC: 0.9267274844720497\n",
      "166 34 0.16033735871315002\n",
      "Validation loss: 0.8779058815801845 ROC AUC: 0.905958850931677\n",
      "167 33 0.22611208260059357\n",
      "Validation loss: 0.9466721567453122 ROC AUC: 0.889557453416149\n",
      "168 32 0.08521667867898941\n",
      "Validation loss: 0.7470930639435264 ROC AUC: 0.919351708074534\n",
      "169 31 0.17986220121383667\n",
      "Validation loss: 0.8006470255991992 ROC AUC: 0.9032414596273292\n",
      "170 30 0.01759285479784012\n",
      "Validation loss: 0.9132331866844028 ROC AUC: 0.8997476708074533\n",
      "171 29 0.18641270697116852\n",
      "Validation loss: 1.101250681222654 ROC AUC: 0.9022709627329193\n",
      "172 28 0.022886015474796295\n",
      "Validation loss: 0.6733915899314132 ROC AUC: 0.9279891304347825\n",
      "173 27 0.15069633722305298\n",
      "Validation loss: 0.807125927770839 ROC AUC: 0.9100349378881987\n",
      "174 26 0.13134899735450745\n",
      "Validation loss: 0.7379857062124738 ROC AUC: 0.9189635093167703\n",
      "175 25 0.05071142315864563\n",
      "Validation loss: 0.9321230112337598 ROC AUC: 0.8852872670807453\n",
      "176 24 0.13634087145328522\n",
      "Validation loss: 0.895094585623227 ROC AUC: 0.9156638198757764\n",
      "177 23 0.010074317455291748\n",
      "Validation loss: 0.8108000404694501 ROC AUC: 0.9076086956521738\n",
      "178 22 0.11875907331705093\n",
      "Validation loss: 0.7772413116751933 ROC AUC: 0.9285714285714285\n",
      "179 21 0.04633690416812897\n",
      "Validation loss: 0.8543686288244584 ROC AUC: 0.920516304347826\n",
      "180 20 0.10048259794712067\n",
      "Validation loss: 1.018995884586783 ROC AUC: 0.9037267080745343\n",
      "181 19 0.35306215286254883\n",
      "Validation loss: 0.5667845250344744 ROC AUC: 0.9346855590062111\n",
      "182 18 0.054887425154447556\n",
      "Validation loss: 0.9982979145704531 ROC AUC: 0.9076086956521738\n",
      "183 17 0.10725560784339905\n",
      "Validation loss: 0.7278586783829857 ROC AUC: 0.9255628881987579\n",
      "184 16 0.01946626976132393\n",
      "Validation loss: 0.8399868747767281 ROC AUC: 0.8878105590062112\n",
      "185 15 0.04529479518532753\n",
      "Validation loss: 0.8710780587850833 ROC AUC: 0.9038237577639752\n",
      "186 14 0.18343251943588257\n",
      "Validation loss: 0.8153057519127341 ROC AUC: 0.8933423913043478\n",
      "187 13 0.04096505045890808\n",
      "Validation loss: 0.8652882634424696 ROC AUC: 0.9100349378881988\n",
      "188 12 0.16482195258140564\n",
      "Validation loss: 0.8491587989470538 ROC AUC: 0.9094526397515527\n",
      "189 11 0.06224604323506355\n",
      "Validation loss: 0.9130075895318798 ROC AUC: 0.8981948757763975\n",
      "190 10 0.11500837653875351\n",
      "Validation loss: 0.8866452411109326 ROC AUC: 0.8923718944099378\n",
      "191 9 0.19972549378871918\n",
      "Validation loss: 1.0141872161743688 ROC AUC: 0.8833462732919255\n",
      "192 8 0.03732938691973686\n",
      "Validation loss: 0.8875538555576521 ROC AUC: 0.9140139751552795\n",
      "193 7 0.039873432368040085\n",
      "Validation loss: 0.8329459592407825 ROC AUC: 0.921001552795031\n",
      "194 6 0.23803743720054626\n",
      "Validation loss: 0.8252895711099401 ROC AUC: 0.9153726708074534\n",
      "195 5 0.06594201922416687\n",
      "Validation loss: 0.8362813159531238 ROC AUC: 0.9173136645962733\n",
      "196 4 0.010764934122562408\n",
      "Validation loss: 0.9098880618226295 ROC AUC: 0.9118788819875775\n",
      "197 3 0.1193087100982666\n",
      "Validation loss: 1.2720246940266853 ROC AUC: 0.907123447204969\n",
      "198 2 0.010354160331189632\n",
      "Validation loss: 0.8016709650264067 ROC AUC: 0.9198369565217391\n",
      "199 1 0.0466301254928112\n",
      "Validation loss: 0.8372306988081512 ROC AUC: 0.9087732919254657\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.2963834743873746 Test ROC AUC: 0.7282011754504287\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bbbp', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 780, 'task': 'classification', 'data_path': 'data/bbbp/BBBP.csv', 'target': ['p_np']}}\n",
      "Running on: cuda:1\n",
      "2038\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/2038\n",
      "Generating scaffold 1000/2038\n",
      "Generating scaffold 2000/2038\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 8.05662727355957\n",
      "0 50 2.1590487957000732\n",
      "Validation loss: 0.6910335450780158 ROC AUC: 0.8545225155279503\n",
      "1 49 1.6175183057785034\n",
      "Validation loss: 0.5034838020801544 ROC AUC: 0.8927600931677018\n",
      "2 48 1.3227241039276123\n",
      "Validation loss: 0.5845194382994783 ROC AUC: 0.8898486024844721\n",
      "3 47 1.1143603324890137\n",
      "Validation loss: 0.42339904109636944 ROC AUC: 0.8914013975155278\n",
      "4 46 0.9205867052078247\n",
      "Validation loss: 0.5315263259644601 ROC AUC: 0.9094526397515528\n",
      "5 45 0.7722302675247192\n",
      "Validation loss: 0.3687633118208717 ROC AUC: 0.9319681677018634\n",
      "6 44 0.8065767288208008\n",
      "Validation loss: 0.41989532638998595 ROC AUC: 0.9263392857142857\n",
      "7 43 0.8904913663864136\n",
      "Validation loss: 0.43753789978868823 ROC AUC: 0.9248835403726707\n",
      "8 42 0.6071036458015442\n",
      "Validation loss: 0.38966625227647667 ROC AUC: 0.9160520186335404\n",
      "9 41 0.6366891860961914\n",
      "Validation loss: 0.5150256472475389 ROC AUC: 0.9181871118012422\n",
      "10 40 0.5805037617683411\n",
      "Validation loss: 0.4055795587745367 ROC AUC: 0.9229425465838509\n",
      "11 39 0.6453268527984619\n",
      "Validation loss: 0.4209597272907986 ROC AUC: 0.9074145962732918\n",
      "12 38 0.3820980191230774\n",
      "Validation loss: 0.4941067508622712 ROC AUC: 0.9092585403726707\n",
      "13 37 0.6574724912643433\n",
      "Validation loss: 0.4093344795937632 ROC AUC: 0.9171195652173912\n",
      "14 36 0.3709604740142822\n",
      "Validation loss: 0.479602198974759 ROC AUC: 0.9049883540372671\n",
      "15 35 0.5009326934814453\n",
      "Validation loss: 0.45031077721539664 ROC AUC: 0.9181871118012422\n",
      "16 34 0.4139613211154938\n",
      "Validation loss: 0.48679042329975203 ROC AUC: 0.921389751552795\n",
      "17 33 0.4370601177215576\n",
      "Validation loss: 0.3481297037180732 ROC AUC: 0.9329386645962733\n",
      "18 32 0.41896945238113403\n",
      "Validation loss: 0.38916559999479966 ROC AUC: 0.921777950310559\n",
      "19 31 0.27104026079177856\n",
      "Validation loss: 0.46440723187783184 ROC AUC: 0.936820652173913\n",
      "20 30 0.46698230504989624\n",
      "Validation loss: 0.5104952597734975 ROC AUC: 0.8876164596273293\n",
      "21 29 0.2916335463523865\n",
      "Validation loss: 0.4885139634796217 ROC AUC: 0.9138198757763976\n",
      "22 28 0.16264718770980835\n",
      "Validation loss: 0.4416161343163135 ROC AUC: 0.9214868012422359\n",
      "23 27 0.44928401708602905\n",
      "Validation loss: 0.43730177628059014 ROC AUC: 0.9155667701863355\n",
      "24 26 0.3926261067390442\n",
      "Validation loss: 0.49290529653137805 ROC AUC: 0.9171195652173912\n",
      "25 25 0.25381726026535034\n",
      "Validation loss: 0.5266434103250504 ROC AUC: 0.9124611801242237\n",
      "26 24 0.40637314319610596\n",
      "Validation loss: 0.4296565289590873 ROC AUC: 0.9259510869565217\n",
      "27 23 0.21585261821746826\n",
      "Validation loss: 0.43657999529558067 ROC AUC: 0.9310947204968945\n",
      "28 22 0.7959657907485962\n",
      "Validation loss: 0.46014948569092096 ROC AUC: 0.9198369565217391\n",
      "29 21 0.21724575757980347\n",
      "Validation loss: 0.462437300121083 ROC AUC: 0.9128493788819875\n",
      "30 20 0.2117731124162674\n",
      "Validation loss: 0.37271951971685185 ROC AUC: 0.9382763975155278\n",
      "31 19 0.5446359515190125\n",
      "Validation loss: 0.4306675207381155 ROC AUC: 0.9257569875776399\n",
      "32 18 0.40707123279571533\n",
      "Validation loss: 0.5811744986795911 ROC AUC: 0.906055900621118\n",
      "33 17 0.15631672739982605\n",
      "Validation loss: 0.7327466028578141 ROC AUC: 0.8776203416149068\n",
      "34 16 0.2659863829612732\n",
      "Validation loss: 0.4407857399360806 ROC AUC: 0.921486801242236\n",
      "35 15 0.23783648014068604\n",
      "Validation loss: 0.5138743014312258 ROC AUC: 0.919254658385093\n",
      "36 14 0.5915672779083252\n",
      "Validation loss: 0.4221424112717311 ROC AUC: 0.905182453416149\n",
      "37 13 0.19558840990066528\n",
      "Validation loss: 0.48406772096367445 ROC AUC: 0.9266304347826086\n",
      "38 12 0.3066266179084778\n",
      "Validation loss: 0.48206835064817877 ROC AUC: 0.9188664596273292\n",
      "39 11 0.38070449233055115\n",
      "Validation loss: 0.4799085282811932 ROC AUC: 0.9259510869565217\n",
      "40 10 0.19945292174816132\n",
      "Validation loss: 0.6079238115572462 ROC AUC: 0.8867430124223602\n",
      "41 9 0.44983309507369995\n",
      "Validation loss: 0.4921337429653196 ROC AUC: 0.9236218944099378\n",
      "42 8 0.36208221316337585\n",
      "Validation loss: 0.5233121699489215 ROC AUC: 0.9239130434782608\n",
      "43 7 0.18025702238082886\n",
      "Validation loss: 0.7041117440836102 ROC AUC: 0.874805900621118\n",
      "44 6 0.1962183713912964\n",
      "Validation loss: 0.6143154583725274 ROC AUC: 0.9036296583850931\n",
      "45 5 0.22442373633384705\n",
      "Validation loss: 0.40403442815238355 ROC AUC: 0.9314829192546583\n",
      "46 4 0.2555702030658722\n",
      "Validation loss: 0.396437687032363 ROC AUC: 0.93652950310559\n",
      "47 3 0.21723151206970215\n",
      "Validation loss: 0.5149982519009534 ROC AUC: 0.9098408385093169\n",
      "48 2 0.05796948820352554\n",
      "Validation loss: 0.4167575672561047 ROC AUC: 0.9264363354037267\n",
      "49 1 0.13950249552726746\n",
      "Validation loss: 0.4455030782549989 ROC AUC: 0.9302212732919255\n",
      "50 0 0.49758514761924744\n",
      "50 50 0.30486515164375305\n",
      "Validation loss: 0.42596947270281177 ROC AUC: 0.9217779503105591\n",
      "51 49 0.5091748833656311\n",
      "Validation loss: 0.44793494425567926 ROC AUC: 0.920516304347826\n",
      "52 48 0.24690811336040497\n",
      "Validation loss: 0.5023420160891963 ROC AUC: 0.9169254658385093\n",
      "53 47 0.27253276109695435\n",
      "Validation loss: 0.46333900619955626 ROC AUC: 0.9114906832298136\n",
      "54 46 0.11654625087976456\n",
      "Validation loss: 0.4275018642930424 ROC AUC: 0.9359472049689441\n",
      "55 45 0.27483078837394714\n",
      "Validation loss: 0.4658609348184922 ROC AUC: 0.921583850931677\n",
      "56 44 0.36094653606414795\n",
      "Validation loss: 0.5688331110366419 ROC AUC: 0.8940217391304349\n",
      "57 43 0.4185951352119446\n",
      "Validation loss: 0.3848322711738886 ROC AUC: 0.9286684782608696\n",
      "58 42 0.22503654658794403\n",
      "Validation loss: 0.6105942866381477 ROC AUC: 0.9006211180124223\n",
      "59 41 0.17860305309295654\n",
      "Validation loss: 0.5021852219805998 ROC AUC: 0.8921777950310558\n",
      "60 40 0.1575649380683899\n",
      "Validation loss: 0.4780911172137541 ROC AUC: 0.9239130434782608\n",
      "61 39 0.07063214480876923\n",
      "Validation loss: 0.4046626541142662 ROC AUC: 0.9337150621118012\n",
      "62 38 0.23496083915233612\n",
      "Validation loss: 0.5312381246510673 ROC AUC: 0.9149844720496894\n",
      "63 37 0.08411511778831482\n",
      "Validation loss: 0.48102835346670714 ROC AUC: 0.9245923913043478\n",
      "64 36 0.147475928068161\n",
      "Validation loss: 0.48495034347562227 ROC AUC: 0.9394409937888197\n",
      "65 35 0.22019758820533752\n",
      "Validation loss: 0.5066690783874661 ROC AUC: 0.8988742236024845\n",
      "66 34 0.23821331560611725\n",
      "Validation loss: 0.676033101829828 ROC AUC: 0.8808229813664596\n",
      "67 33 0.21563516557216644\n",
      "Validation loss: 0.6431433196161308 ROC AUC: 0.8852872670807453\n",
      "68 32 0.28197064995765686\n",
      "Validation loss: 0.4981658086180687 ROC AUC: 0.922263198757764\n",
      "69 31 0.31068238615989685\n",
      "Validation loss: 0.48344884023946877 ROC AUC: 0.9185753105590062\n",
      "70 30 0.1898200660943985\n",
      "Validation loss: 0.649579069778031 ROC AUC: 0.8777173913043478\n",
      "71 29 0.19342729449272156\n",
      "Validation loss: 0.5340960353028541 ROC AUC: 0.9180900621118012\n",
      "72 28 0.25716978311538696\n",
      "Validation loss: 0.5361015527856117 ROC AUC: 0.9235248447204969\n",
      "73 27 0.1788514256477356\n",
      "Validation loss: 0.5348581274350485 ROC AUC: 0.9003299689440994\n",
      "74 26 0.11009643226861954\n",
      "Validation loss: 0.5396475298147575 ROC AUC: 0.9191576086956521\n",
      "75 25 0.14577606320381165\n",
      "Validation loss: 0.6451431816699458 ROC AUC: 0.8960597826086957\n",
      "76 24 0.13804978132247925\n",
      "Validation loss: 0.5431567874609255 ROC AUC: 0.9255628881987576\n",
      "77 23 0.19827915728092194\n",
      "Validation loss: 0.6623415929429671 ROC AUC: 0.905861801242236\n",
      "78 22 0.07309848815202713\n",
      "Validation loss: 0.6917253598278644 ROC AUC: 0.889266304347826\n",
      "79 21 0.1756688356399536\n",
      "Validation loss: 0.6367847618519091 ROC AUC: 0.88965450310559\n",
      "80 20 0.11951533704996109\n",
      "Validation loss: 0.7906883791381237 ROC AUC: 0.8882958074534161\n",
      "81 19 0.11191175878047943\n",
      "Validation loss: 0.6427726850790136 ROC AUC: 0.905764751552795\n",
      "82 18 0.1715509593486786\n",
      "Validation loss: 0.6505568985845528 ROC AUC: 0.9126552795031055\n",
      "83 17 0.26552873849868774\n",
      "Validation loss: 0.7450135274260652 ROC AUC: 0.8774262422360248\n",
      "84 16 0.11566942930221558\n",
      "Validation loss: 0.47576697609003854 ROC AUC: 0.9327445652173912\n",
      "85 15 0.05643538385629654\n",
      "Validation loss: 0.5278802467327491 ROC AUC: 0.9105201863354038\n",
      "86 14 0.4316401183605194\n",
      "Validation loss: 0.7252678123174929 ROC AUC: 0.8991653726708074\n",
      "87 13 0.17855523526668549\n",
      "Validation loss: 0.8530873001790514 ROC AUC: 0.8858695652173914\n",
      "88 12 0.16854076087474823\n",
      "Validation loss: 0.5844116444681206 ROC AUC: 0.9162461180124223\n",
      "89 11 0.3103012442588806\n",
      "Validation loss: 0.6481191866538104 ROC AUC: 0.9040178571428572\n",
      "90 10 0.11365921795368195\n",
      "Validation loss: 0.6559603493295464 ROC AUC: 0.8912072981366459\n",
      "91 9 0.3505631685256958\n",
      "Validation loss: 0.7766206369680517 ROC AUC: 0.8828610248447205\n",
      "92 8 0.1556706428527832\n",
      "Validation loss: 0.601745908166848 ROC AUC: 0.9185753105590062\n",
      "93 7 0.08612679690122604\n",
      "Validation loss: 0.4422541815860599 ROC AUC: 0.9391498447204968\n",
      "94 6 0.19840598106384277\n",
      "Validation loss: 0.5727047990350163 ROC AUC: 0.9139169254658385\n",
      "95 5 0.09279855340719223\n",
      "Validation loss: 0.6899498169328652 ROC AUC: 0.8973214285714286\n",
      "96 4 0.12662449479103088\n",
      "Validation loss: 0.7945005887863683 ROC AUC: 0.9025621118012422\n",
      "97 3 0.2286892682313919\n",
      "Validation loss: 0.6422843188047409 ROC AUC: 0.90625\n",
      "98 2 0.11753471195697784\n",
      "Validation loss: 0.6653415023111829 ROC AUC: 0.9098408385093169\n",
      "99 1 0.1383114606142044\n",
      "Validation loss: 0.6766791588389406 ROC AUC: 0.9096467391304348\n",
      "100 0 0.11114427447319031\n",
      "100 50 0.13488399982452393\n",
      "Validation loss: 0.44653090191822425 ROC AUC: 0.935947204968944\n",
      "101 49 0.1645338237285614\n",
      "Validation loss: 0.5398234605204826 ROC AUC: 0.9303183229813664\n",
      "102 48 0.11269131302833557\n",
      "Validation loss: 0.5307937001480776 ROC AUC: 0.9387616459627329\n",
      "103 47 0.30183348059654236\n",
      "Validation loss: 0.5309373585909021 ROC AUC: 0.9268245341614907\n",
      "104 46 0.22368451952934265\n",
      "Validation loss: 0.7423982240405738 ROC AUC: 0.9087732919254659\n",
      "105 45 0.2520280182361603\n",
      "Validation loss: 1.1094089115367216 ROC AUC: 0.8711180124223603\n",
      "106 44 0.2882710099220276\n",
      "Validation loss: 0.6539205289354512 ROC AUC: 0.9164402173913043\n",
      "107 43 0.08040563017129898\n",
      "Validation loss: 0.7374610784007054 ROC AUC: 0.9029503105590062\n",
      "108 42 0.09378217160701752\n",
      "Validation loss: 0.9817116826991824 ROC AUC: 0.9005240683229814\n",
      "109 41 0.13627365231513977\n",
      "Validation loss: 0.5611005741007188 ROC AUC: 0.9276009316770186\n",
      "110 40 0.1303192526102066\n",
      "Validation loss: 0.6737880075679106 ROC AUC: 0.9292507763975155\n",
      "111 39 0.17477509379386902\n",
      "Validation loss: 0.6368818435014463 ROC AUC: 0.9163431677018633\n",
      "112 38 0.09762071818113327\n",
      "Validation loss: 0.7726886019695038 ROC AUC: 0.921680900621118\n",
      "113 37 0.06646612286567688\n",
      "Validation loss: 0.6645054104281407 ROC AUC: 0.9166343167701864\n",
      "114 36 0.06274396181106567\n",
      "Validation loss: 0.7230110383209061 ROC AUC: 0.9207104037267081\n",
      "115 35 0.19665662944316864\n",
      "Validation loss: 0.6947625399220223 ROC AUC: 0.8913043478260869\n",
      "116 34 0.23764808475971222\n",
      "Validation loss: 0.6666156263912425 ROC AUC: 0.9249805900621118\n",
      "117 33 0.17743439972400665\n",
      "Validation loss: 0.5929951009285801 ROC AUC: 0.9266304347826088\n",
      "118 32 0.10833454132080078\n",
      "Validation loss: 0.8642326336280972 ROC AUC: 0.8998447204968943\n",
      "119 31 0.3024650812149048\n",
      "Validation loss: 0.8621590207604801 ROC AUC: 0.9089673913043479\n",
      "120 30 0.15277236700057983\n",
      "Validation loss: 0.5668324214570662 ROC AUC: 0.922748447204969\n",
      "121 29 0.1487574428319931\n",
      "Validation loss: 0.7633551701026804 ROC AUC: 0.9056677018633541\n",
      "122 28 0.10080312192440033\n",
      "Validation loss: 0.8306808316824483 ROC AUC: 0.9012034161490684\n",
      "123 27 0.1314624845981598\n",
      "Validation loss: 0.7332458147669539 ROC AUC: 0.9185753105590062\n",
      "124 26 0.047043245285749435\n",
      "Validation loss: 0.60561009832457 ROC AUC: 0.92284549689441\n",
      "125 25 0.19739405810832977\n",
      "Validation loss: 0.884507395874928 ROC AUC: 0.9121700310559006\n",
      "126 24 0.18522514402866364\n",
      "Validation loss: 0.7484931525062112 ROC AUC: 0.9245923913043478\n",
      "127 23 0.06591757386922836\n",
      "Validation loss: 1.0456506142429276 ROC AUC: 0.890722049689441\n",
      "128 22 0.0853223204612732\n",
      "Validation loss: 0.7231919715801874 ROC AUC: 0.9260481366459627\n",
      "129 21 0.09140831232070923\n",
      "Validation loss: 0.9239127028222177 ROC AUC: 0.8923718944099379\n",
      "130 20 0.06669293344020844\n",
      "Validation loss: 0.8573753226037119 ROC AUC: 0.9260481366459626\n",
      "131 19 0.06548671424388885\n",
      "Validation loss: 0.7156487596677799 ROC AUC: 0.922263198757764\n",
      "132 18 0.12977726757526398\n",
      "Validation loss: 0.87034624172192 ROC AUC: 0.9175077639751552\n",
      "133 17 0.0390266478061676\n",
      "Validation loss: 0.7224957891831211 ROC AUC: 0.9176048136645962\n",
      "134 16 0.05528058856725693\n",
      "Validation loss: 0.7993732994677973 ROC AUC: 0.9133346273291926\n",
      "135 15 0.1334901601076126\n",
      "Validation loss: 0.7797367794840944 ROC AUC: 0.9013004658385092\n",
      "136 14 0.1077054962515831\n",
      "Validation loss: 0.695140845635358 ROC AUC: 0.9237189440993789\n",
      "137 13 0.07111117243766785\n",
      "Validation loss: 0.8368312611299402 ROC AUC: 0.9106172360248448\n",
      "138 12 0.05855684354901314\n",
      "Validation loss: 0.7635647093548494 ROC AUC: 0.9106172360248447\n",
      "139 11 0.1002209410071373\n",
      "Validation loss: 0.6543747782707214 ROC AUC: 0.9169254658385093\n",
      "140 10 0.14877767860889435\n",
      "Validation loss: 0.761389457273717 ROC AUC: 0.9012034161490683\n",
      "141 9 0.28847736120224\n",
      "Validation loss: 0.8328214959771025 ROC AUC: 0.9138198757763976\n",
      "142 8 0.13153672218322754\n",
      "Validation loss: 0.6466792740073859 ROC AUC: 0.9183812111801242\n",
      "143 7 0.0802362784743309\n",
      "Validation loss: 0.7343214970885539 ROC AUC: 0.9235248447204969\n",
      "144 6 0.055354587733745575\n",
      "Validation loss: 0.7310309122115666 ROC AUC: 0.9266304347826088\n",
      "145 5 0.09440809488296509\n",
      "Validation loss: 0.9428040467056573 ROC AUC: 0.9167313664596273\n",
      "146 4 0.11302658915519714\n",
      "Validation loss: 0.9497047297510446 ROC AUC: 0.888392857142857\n",
      "147 3 0.05819687992334366\n",
      "Validation loss: 0.8433137524361703 ROC AUC: 0.9247864906832298\n",
      "148 2 0.06032129377126694\n",
      "Validation loss: 0.9103728339952581 ROC AUC: 0.9019798136645963\n",
      "149 1 0.09381559491157532\n",
      "Validation loss: 0.7190722262158113 ROC AUC: 0.9168284161490683\n",
      "150 0 0.09943661093711853\n",
      "150 50 0.040373992174863815\n",
      "Validation loss: 0.5931542373317129 ROC AUC: 0.921195652173913\n",
      "151 49 0.07334119826555252\n",
      "Validation loss: 0.7915055611554314 ROC AUC: 0.9092585403726707\n",
      "152 48 0.08968684822320938\n",
      "Validation loss: 0.7718726934171191 ROC AUC: 0.9173136645962733\n",
      "153 47 0.1106812059879303\n",
      "Validation loss: 0.63244082179724 ROC AUC: 0.9329386645962732\n",
      "154 46 0.029205314815044403\n",
      "Validation loss: 0.8135243537379246 ROC AUC: 0.9237189440993789\n",
      "155 45 0.06466993689537048\n",
      "Validation loss: 0.9187257663876403 ROC AUC: 0.9004270186335405\n",
      "156 44 0.14105507731437683\n",
      "Validation loss: 0.8242493368246976 ROC AUC: 0.9245923913043479\n",
      "157 43 0.06608249992132187\n",
      "Validation loss: 0.9732244558194104 ROC AUC: 0.8929541925465839\n",
      "158 42 0.11712682992219925\n",
      "Validation loss: 1.4848461525112975 ROC AUC: 0.8497670807453417\n",
      "159 41 0.1638053059577942\n",
      "Validation loss: 0.6440781313999027 ROC AUC: 0.9025621118012422\n",
      "160 40 0.04620852321386337\n",
      "Validation loss: 0.7173294904185277 ROC AUC: 0.9223602484472051\n",
      "161 39 0.09244274348020554\n",
      "Validation loss: 0.8280238967900183 ROC AUC: 0.8937305900621118\n",
      "162 38 0.17129698395729065\n",
      "Validation loss: 0.9186022901067546 ROC AUC: 0.9126552795031057\n",
      "163 37 0.035572368651628494\n",
      "Validation loss: 1.0021007508039474 ROC AUC: 0.9169254658385092\n",
      "164 36 0.17203177511692047\n",
      "Validation loss: 0.8843159523664736 ROC AUC: 0.9089673913043478\n",
      "165 35 0.11820803582668304\n",
      "Validation loss: 1.0459183290892957 ROC AUC: 0.9061529503105589\n",
      "166 34 0.16924351453781128\n",
      "Validation loss: 0.9056531569975264 ROC AUC: 0.8832492236024845\n",
      "167 33 0.019992241635918617\n",
      "Validation loss: 0.9751677980609968 ROC AUC: 0.9155667701863354\n",
      "168 32 0.1873892992734909\n",
      "Validation loss: 1.0272720982046688 ROC AUC: 0.8956715838509317\n",
      "169 31 0.07246299833059311\n",
      "Validation loss: 0.7923582492980594 ROC AUC: 0.9111024844720497\n",
      "170 30 0.10234391689300537\n",
      "Validation loss: 0.7640067508407667 ROC AUC: 0.9204192546583851\n",
      "171 29 0.1359563171863556\n",
      "Validation loss: 0.815079083629683 ROC AUC: 0.905764751552795\n",
      "172 28 0.04040144383907318\n",
      "Validation loss: 1.1756570549572216 ROC AUC: 0.8847049689440993\n",
      "173 27 0.08794227242469788\n",
      "Validation loss: 0.942469576994578 ROC AUC: 0.921777950310559\n",
      "174 26 0.1346815824508667\n",
      "Validation loss: 0.9358467973914801 ROC AUC: 0.9115877329192547\n",
      "175 25 0.08233002573251724\n",
      "Validation loss: 0.9983251048069374 ROC AUC: 0.9256599378881987\n",
      "176 24 0.12069254368543625\n",
      "Validation loss: 0.9492662082992348 ROC AUC: 0.9151785714285714\n",
      "177 23 0.11182921379804611\n",
      "Validation loss: 0.9451037434970632 ROC AUC: 0.9127523291925466\n",
      "178 22 0.15955990552902222\n",
      "Validation loss: 1.027759968065748 ROC AUC: 0.907705745341615\n",
      "179 21 0.053652770817279816\n",
      "Validation loss: 1.1369056327670228 ROC AUC: 0.9077057453416149\n",
      "180 20 0.040765609592199326\n",
      "Validation loss: 0.675573408019309 ROC AUC: 0.9338121118012422\n",
      "181 19 0.02751457691192627\n",
      "Validation loss: 0.9938552885078916 ROC AUC: 0.9095496894409937\n",
      "182 18 0.01431482844054699\n",
      "Validation loss: 0.7302085841987648 ROC AUC: 0.920807453416149\n",
      "183 17 0.14317895472049713\n",
      "Validation loss: 0.690870040772008 ROC AUC: 0.9325504658385092\n",
      "184 16 0.026877475902438164\n",
      "Validation loss: 1.0828171144513523 ROC AUC: 0.9132375776397517\n",
      "185 15 0.021178267896175385\n",
      "Validation loss: 0.8807350204271429 ROC AUC: 0.9333268633540371\n",
      "186 14 0.01962999254465103\n",
      "Validation loss: 0.8394453462724593 ROC AUC: 0.9257569875776397\n",
      "187 13 0.08261245489120483\n",
      "Validation loss: 0.8357900673633113 ROC AUC: 0.9342973602484471\n",
      "188 12 0.046559352427721024\n",
      "Validation loss: 0.6721728268791648 ROC AUC: 0.921680900621118\n",
      "189 11 0.056697070598602295\n",
      "Validation loss: 0.8391367737569061 ROC AUC: 0.9225543478260869\n",
      "190 10 0.04975252225995064\n",
      "Validation loss: 0.7716781029514238 ROC AUC: 0.921292701863354\n",
      "191 9 0.0425708070397377\n",
      "Validation loss: 0.8895778731972563 ROC AUC: 0.919642857142857\n",
      "192 8 0.10577404499053955\n",
      "Validation loss: 0.9691371380114088 ROC AUC: 0.9203222049689441\n",
      "193 7 0.078302763402462\n",
      "Validation loss: 1.1590750708299524 ROC AUC: 0.9133346273291925\n",
      "194 6 0.008861581794917583\n",
      "Validation loss: 1.3377318711695718 ROC AUC: 0.9071234472049688\n",
      "195 5 0.015425759367644787\n",
      "Validation loss: 0.9604161275075931 ROC AUC: 0.8958656832298136\n",
      "196 4 0.13229092955589294\n",
      "Validation loss: 1.1368139181651322 ROC AUC: 0.9117818322981367\n",
      "197 3 0.036593880504369736\n",
      "Validation loss: 0.8305431955000934 ROC AUC: 0.9032414596273293\n",
      "198 2 0.03469640016555786\n",
      "Validation loss: 0.8649482131004333 ROC AUC: 0.9090644409937888\n",
      "199 1 0.11192413419485092\n",
      "Validation loss: 0.7065536800552817 ROC AUC: 0.9331327639751553\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.4665057694210726 Test ROC AUC: 0.7300317949706138\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bbbp', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'classification', 'data_path': 'data/bbbp/BBBP.csv', 'target': ['p_np']}}\n",
      "Running on: cuda:1\n",
      "2038\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/2038\n",
      "Generating scaffold 1000/2038\n",
      "Generating scaffold 2000/2038\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 8.445286750793457\n",
      "0 50 2.520759344100952\n",
      "Validation loss: 0.9096816895054836 ROC AUC: 0.8605395962732919\n",
      "1 49 1.7455434799194336\n",
      "Validation loss: 0.5259330050618041 ROC AUC: 0.8752911490683231\n",
      "2 48 1.2895418405532837\n",
      "Validation loss: 0.6913485527038574 ROC AUC: 0.8882958074534162\n",
      "3 47 1.1989552974700928\n",
      "Validation loss: 0.54863489316959 ROC AUC: 0.8848990683229814\n",
      "4 46 1.134155511856079\n",
      "Validation loss: 0.417637099238003 ROC AUC: 0.9266304347826086\n",
      "5 45 0.9741756916046143\n",
      "Validation loss: 0.42049826243344474 ROC AUC: 0.9276979813664596\n",
      "6 44 0.7633752822875977\n",
      "Validation loss: 0.36511265647177604 ROC AUC: 0.9289596273291926\n",
      "7 43 0.8136175870895386\n",
      "Validation loss: 0.4997265636920929 ROC AUC: 0.9136257763975155\n",
      "8 42 0.8092542290687561\n",
      "Validation loss: 0.43042241007673976 ROC AUC: 0.9234277950310559\n",
      "9 41 0.6198747754096985\n",
      "Validation loss: 0.4821659104496825 ROC AUC: 0.920225155279503\n",
      "10 40 0.6411440968513489\n",
      "Validation loss: 0.45628295692743037 ROC AUC: 0.9245923913043477\n",
      "11 39 0.512330174446106\n",
      "Validation loss: 0.47696726827644836 ROC AUC: 0.9030473602484472\n",
      "12 38 0.6441763639450073\n",
      "Validation loss: 0.3683618984970392 ROC AUC: 0.9301242236024845\n",
      "13 37 0.5116952657699585\n",
      "Validation loss: 0.4461513968075023 ROC AUC: 0.9326475155279503\n",
      "14 36 0.36779049038887024\n",
      "Validation loss: 0.5451139953790927 ROC AUC: 0.9181871118012422\n",
      "15 35 0.5574238896369934\n",
      "Validation loss: 0.3972400958631553 ROC AUC: 0.9262422360248448\n",
      "16 34 0.3950622081756592\n",
      "Validation loss: 0.47761356596853216 ROC AUC: 0.9285714285714285\n",
      "17 33 0.5118833780288696\n",
      "Validation loss: 0.5802374517216402 ROC AUC: 0.9013004658385093\n",
      "18 32 0.4633103609085083\n",
      "Validation loss: 0.3641144250537835 ROC AUC: 0.9373059006211181\n",
      "19 31 0.3185535669326782\n",
      "Validation loss: 0.4517413132330951 ROC AUC: 0.889945652173913\n",
      "20 30 0.27854055166244507\n",
      "Validation loss: 0.4314868131688997 ROC AUC: 0.9121700310559007\n",
      "21 29 0.25287654995918274\n",
      "Validation loss: 0.36361701961825876 ROC AUC: 0.9309006211180124\n",
      "22 28 0.2800535261631012\n",
      "Validation loss: 0.4012555824775322 ROC AUC: 0.9319681677018633\n",
      "23 27 0.3260195553302765\n",
      "Validation loss: 0.5699181521640104 ROC AUC: 0.8938276397515528\n",
      "24 26 0.33199360966682434\n",
      "Validation loss: 0.3581406795511059 ROC AUC: 0.9421583850931676\n",
      "25 25 0.33381491899490356\n",
      "Validation loss: 0.485258536011565 ROC AUC: 0.9093555900621119\n",
      "26 24 0.24640785157680511\n",
      "Validation loss: 0.4540543703764093 ROC AUC: 0.9127523291925466\n",
      "27 23 0.32461029291152954\n",
      "Validation loss: 0.4128946305490008 ROC AUC: 0.9160520186335404\n",
      "28 22 0.38963040709495544\n",
      "Validation loss: 0.44849420645657706 ROC AUC: 0.9276979813664596\n",
      "29 21 0.3014727532863617\n",
      "Validation loss: 0.4312431625291413 ROC AUC: 0.9122670807453416\n",
      "30 20 0.349044531583786\n",
      "Validation loss: 0.4138909744865754 ROC AUC: 0.920807453416149\n",
      "31 19 0.5836246609687805\n",
      "Validation loss: 0.39346958024829043 ROC AUC: 0.9241071428571427\n",
      "32 18 0.379209041595459\n",
      "Validation loss: 0.4253292722883178 ROC AUC: 0.9295419254658385\n",
      "33 17 0.20215928554534912\n",
      "Validation loss: 0.3944425851691003 ROC AUC: 0.9163431677018634\n",
      "34 16 0.3428749144077301\n",
      "Validation loss: 0.47481565031350825 ROC AUC: 0.9297360248447204\n",
      "35 15 0.2526398003101349\n",
      "Validation loss: 0.5372584193360572 ROC AUC: 0.8875194099378881\n",
      "36 14 0.3844342827796936\n",
      "Validation loss: 0.3904493754985286 ROC AUC: 0.936335403726708\n",
      "37 13 0.24442525207996368\n",
      "Validation loss: 0.4299635983565274 ROC AUC: 0.9176048136645963\n",
      "38 12 0.2492736279964447\n",
      "Validation loss: 0.4113612215892941 ROC AUC: 0.9179930124223603\n",
      "39 11 0.31040483713150024\n",
      "Validation loss: 0.35444500165827136 ROC AUC: 0.9318711180124225\n",
      "40 10 0.18053236603736877\n",
      "Validation loss: 0.499849678254595 ROC AUC: 0.9065411490683231\n",
      "41 9 0.3793567717075348\n",
      "Validation loss: 0.3832838251894596 ROC AUC: 0.9267274844720497\n",
      "42 8 0.3259999752044678\n",
      "Validation loss: 0.4844478281105266 ROC AUC: 0.9302212732919255\n",
      "43 7 0.1868235468864441\n",
      "Validation loss: 0.42981096751549663 ROC AUC: 0.9206133540372671\n",
      "44 6 0.2322491854429245\n",
      "Validation loss: 0.580828323375945 ROC AUC: 0.9145962732919255\n",
      "45 5 0.3734760582447052\n",
      "Validation loss: 0.37874168157577515 ROC AUC: 0.9304153726708074\n",
      "46 4 0.15403985977172852\n",
      "Validation loss: 0.5208046342812332 ROC AUC: 0.9049883540372672\n",
      "47 3 0.3038614094257355\n",
      "Validation loss: 0.5143357789983937 ROC AUC: 0.9123641304347825\n",
      "48 2 0.3056957423686981\n",
      "Validation loss: 0.4725537615663865 ROC AUC: 0.9180900621118012\n",
      "49 1 0.4926261007785797\n",
      "Validation loss: 0.5675810259931228 ROC AUC: 0.8957686335403726\n",
      "50 0 0.34098899364471436\n",
      "50 50 0.20328518748283386\n",
      "Validation loss: 0.4804242487047233 ROC AUC: 0.9118788819875775\n",
      "51 49 0.2102949619293213\n",
      "Validation loss: 0.40675647790525477 ROC AUC: 0.937305900621118\n",
      "52 48 0.4186757802963257\n",
      "Validation loss: 0.42019446281825795 ROC AUC: 0.9286684782608696\n",
      "53 47 0.350109726190567\n",
      "Validation loss: 0.35828716789974885 ROC AUC: 0.9294448757763976\n",
      "54 46 0.14041799306869507\n",
      "Validation loss: 0.4317338513393028 ROC AUC: 0.9255628881987576\n",
      "55 45 0.3475673496723175\n",
      "Validation loss: 0.5712244924084813 ROC AUC: 0.8920807453416149\n",
      "56 44 0.3987615704536438\n",
      "Validation loss: 0.4502740093305999 ROC AUC: 0.9127523291925466\n",
      "57 43 0.205690398812294\n",
      "Validation loss: 0.41418137620477113 ROC AUC: 0.9288625776397514\n",
      "58 42 0.2209639698266983\n",
      "Validation loss: 0.4149948241663914 ROC AUC: 0.921001552795031\n",
      "59 41 0.19754968583583832\n",
      "Validation loss: 0.41488997375263886 ROC AUC: 0.921777950310559\n",
      "60 40 0.17957261204719543\n",
      "Validation loss: 0.536740737802842 ROC AUC: 0.9038237577639752\n",
      "61 39 0.6018600463867188\n",
      "Validation loss: 0.5001204136539908 ROC AUC: 0.9156638198757765\n",
      "62 38 0.1196172833442688\n",
      "Validation loss: 0.5355278721042708 ROC AUC: 0.906152950310559\n",
      "63 37 0.20430271327495575\n",
      "Validation loss: 0.510293744358362 ROC AUC: 0.9260481366459626\n",
      "64 36 0.11125931143760681\n",
      "Validation loss: 0.3963717479331821 ROC AUC: 0.9245923913043479\n",
      "65 35 0.4644368290901184\n",
      "Validation loss: 0.4173205822121863 ROC AUC: 0.9251746894409938\n",
      "66 34 0.19795790314674377\n",
      "Validation loss: 0.5366968457020965 ROC AUC: 0.9051824534161491\n",
      "67 33 0.13294120132923126\n",
      "Validation loss: 0.43546466850766946 ROC AUC: 0.9204192546583851\n",
      "68 32 0.530808687210083\n",
      "Validation loss: 0.47428106209811044 ROC AUC: 0.9120729813664596\n",
      "69 31 0.3546169400215149\n",
      "Validation loss: 0.4183706202927758 ROC AUC: 0.9334239130434783\n",
      "70 30 0.3220808506011963\n",
      "Validation loss: 0.3389722412707759 ROC AUC: 0.938761645962733\n",
      "71 29 0.2078114151954651\n",
      "Validation loss: 0.47539352552563535 ROC AUC: 0.9232336956521738\n",
      "72 28 0.3102402985095978\n",
      "Validation loss: 0.5097687010671578 ROC AUC: 0.9075116459627328\n",
      "73 27 0.21654164791107178\n",
      "Validation loss: 0.45065850486942366 ROC AUC: 0.9237189440993789\n",
      "74 26 0.47271063923835754\n",
      "Validation loss: 0.45063718642089884 ROC AUC: 0.9217779503105591\n",
      "75 25 0.07575571537017822\n",
      "Validation loss: 0.40560877089406927 ROC AUC: 0.9257569875776397\n",
      "76 24 0.5539641976356506\n",
      "Validation loss: 0.486673165770138 ROC AUC: 0.9088703416149069\n",
      "77 23 0.09279462695121765\n",
      "Validation loss: 0.4429812951415193 ROC AUC: 0.9164402173913043\n",
      "78 22 0.16370533406734467\n",
      "Validation loss: 0.41229826723243673 ROC AUC: 0.9313858695652173\n",
      "79 21 0.18876637518405914\n",
      "Validation loss: 0.3804098461188522 ROC AUC: 0.9325504658385093\n",
      "80 20 0.14500577747821808\n",
      "Validation loss: 0.651728118167204 ROC AUC: 0.8804347826086957\n",
      "81 19 0.13623417913913727\n",
      "Validation loss: 0.4268925423715629 ROC AUC: 0.9244953416149069\n",
      "82 18 0.056367553770542145\n",
      "Validation loss: 0.3594416718856961 ROC AUC: 0.9333268633540374\n",
      "83 17 0.17912694811820984\n",
      "Validation loss: 0.48489998668140055 ROC AUC: 0.9176048136645962\n",
      "84 16 0.24032844603061676\n",
      "Validation loss: 0.40583522668948363 ROC AUC: 0.9247864906832297\n",
      "85 15 0.2596008777618408\n",
      "Validation loss: 0.40335562299279604 ROC AUC: 0.9306094720496894\n",
      "86 14 0.15024641156196594\n",
      "Validation loss: 0.5930894915671909 ROC AUC: 0.9083850931677018\n",
      "87 13 0.14393416047096252\n",
      "Validation loss: 0.40675197395623897 ROC AUC: 0.9259510869565217\n",
      "88 12 0.07854533195495605\n",
      "Validation loss: 0.5104588077348822 ROC AUC: 0.8995535714285714\n",
      "89 11 0.36660701036453247\n",
      "Validation loss: 0.4792541838159748 ROC AUC: 0.9145962732919255\n",
      "90 10 0.07794365286827087\n",
      "Validation loss: 0.7260282472068188 ROC AUC: 0.8773291925465838\n",
      "91 9 0.317067414522171\n",
      "Validation loss: 0.5347638095126432 ROC AUC: 0.9309006211180124\n",
      "92 8 0.30242466926574707\n",
      "Validation loss: 0.4802335640963386 ROC AUC: 0.9185753105590062\n",
      "93 7 0.268554151058197\n",
      "Validation loss: 0.407416156547911 ROC AUC: 0.9317740683229814\n",
      "94 6 0.045850660651922226\n",
      "Validation loss: 0.5224726772045388 ROC AUC: 0.9143051242236025\n",
      "95 5 0.2189091444015503\n",
      "Validation loss: 0.4400975727567486 ROC AUC: 0.9353649068322981\n",
      "96 4 0.16416515409946442\n",
      "Validation loss: 0.759757390793632 ROC AUC: 0.8726708074534162\n",
      "97 3 0.0631207749247551\n",
      "Validation loss: 0.5795748759718502 ROC AUC: 0.9204192546583851\n",
      "98 2 0.10763680189847946\n",
      "Validation loss: 0.5561583275888481 ROC AUC: 0.9091614906832297\n",
      "99 1 0.03935025632381439\n",
      "Validation loss: 0.6245637559423259 ROC AUC: 0.9012034161490683\n",
      "100 0 0.13455727696418762\n",
      "100 50 0.1527036726474762\n",
      "Validation loss: 0.5552137494087219 ROC AUC: 0.9080939440993788\n",
      "101 49 0.20862893760204315\n",
      "Validation loss: 0.5494608271355722 ROC AUC: 0.9120729813664596\n"
     ]
    }
   ],
   "source": [
    "datasets = [ 'ESOL', 'Lipo', 'qm7', \"bace\",  \"bbbp\",  'tox21', 'clintox', 'sider']\n",
    "seeds = [777, 778, 779, 780, 781]\n",
    "\n",
    "for dataset in datasets:\n",
    "    for seed in seeds:\n",
    "            if dataset == 'FreeSolv':\n",
    "            # FreeSolv     \n",
    "                !python finetuneReconAlpha2.py \\\n",
    "                --task_name {dataset} \\\n",
    "                --seed {seed} \\\n",
    "                --dropout 0.5 \\\n",
    "                --num_layer 3 \\\n",
    "                --emb_dim 64 \\\n",
    "                --feat_dim 64 \\\n",
    "                --alpha 0.1 \\\n",
    "                --mask_edge 1 \\\n",
    "                --gpu cuda:1 \n",
    "            \n",
    "            elif dataset == 'clintox':\n",
    "                !python finetuneReconAlpha2.py \\\n",
    "                --task_name {dataset} \\\n",
    "                --seed {seed} \\\n",
    "                --dropout 0.3 \\\n",
    "                --num_layer 5 \\\n",
    "                --emb_dim 64 \\\n",
    "                --feat_dim 64 \\\n",
    "                --alpha 0.1 \\\n",
    "                --mask_edge 1 \\\n",
    "                --gpu cuda:1\n",
    "\n",
    "            else:\n",
    "                !python finetuneReconAlpha2.py \\\n",
    "                --task_name {dataset} \\\n",
    "                --seed {seed} \\\n",
    "                --alpha 0.1 \\\n",
    "                --mask_edge 1 \\\n",
    "                --gpu cuda:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b2a46ae-a6b6-4a66-befc-c4e38c83fdb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'freesolv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'target': ['expt']}}\n",
      "Running on: cuda:1\n",
      "641\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/641\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 43.940364837646484\n",
      "Validation loss: 42.32244300842285 RMSE: 6.50557\n",
      "Validation loss: 21.440093994140625 RMSE: 4.630345\n",
      "Validation loss: 10.841592788696289 RMSE: 3.2926574\n",
      "3 2 6.706172466278076\n",
      "Validation loss: 23.540712356567383 RMSE: 4.851877\n",
      "Validation loss: 20.874542236328125 RMSE: 4.568867\n",
      "Validation loss: 33.60826396942139 RMSE: 5.797264\n",
      "6 4 5.004969120025635\n",
      "Validation loss: 24.800201416015625 RMSE: 4.9799795\n",
      "Validation loss: 12.941470623016357 RMSE: 3.5974257\n",
      "Validation loss: 46.32302761077881 RMSE: 6.8061023\n",
      "9 6 3.5921382904052734\n",
      "Validation loss: 13.608193397521973 RMSE: 3.6889281\n",
      "Validation loss: 50.10170936584473 RMSE: 7.0782557\n",
      "Validation loss: 14.371757507324219 RMSE: 3.7910101\n",
      "12 8 2.8508119583129883\n",
      "Validation loss: 41.884695053100586 RMSE: 6.471838\n",
      "Validation loss: 33.49806594848633 RMSE: 5.787752\n",
      "Validation loss: 28.793803215026855 RMSE: 5.3659854\n",
      "15 10 4.201597690582275\n",
      "Validation loss: 29.143244743347168 RMSE: 5.398449\n",
      "Validation loss: 15.453770637512207 RMSE: 3.9311285\n",
      "Validation loss: 17.43252468109131 RMSE: 4.1752276\n",
      "18 12 3.934993267059326\n",
      "Validation loss: 19.095504760742188 RMSE: 4.3698406\n",
      "Validation loss: 23.464874267578125 RMSE: 4.8440557\n",
      "Validation loss: 26.503468990325928 RMSE: 5.148152\n",
      "21 14 1.951054573059082\n",
      "Validation loss: 32.09277534484863 RMSE: 5.665049\n",
      "Validation loss: 20.749094009399414 RMSE: 4.555117\n",
      "Validation loss: 18.359436988830566 RMSE: 4.2847915\n",
      "Validation loss: 35.6076774597168 RMSE: 5.9672174\n",
      "25 0 1.5338808298110962\n",
      "Validation loss: 22.089783668518066 RMSE: 4.699977\n",
      "Validation loss: 28.94654941558838 RMSE: 5.3801994\n",
      "Validation loss: 22.846168518066406 RMSE: 4.779767\n",
      "28 2 2.0698533058166504\n",
      "Validation loss: 28.520034790039062 RMSE: 5.340416\n",
      "Validation loss: 16.156204223632812 RMSE: 4.0194783\n",
      "Validation loss: 49.78097724914551 RMSE: 7.055563\n",
      "31 4 3.898179054260254\n",
      "Validation loss: 30.783087730407715 RMSE: 5.548252\n",
      "Validation loss: 17.29116439819336 RMSE: 4.158264\n",
      "Validation loss: 28.83924102783203 RMSE: 5.370218\n",
      "34 6 0.9548368453979492\n",
      "Validation loss: 23.657459259033203 RMSE: 4.8638935\n",
      "Validation loss: 43.45732307434082 RMSE: 6.592217\n",
      "Validation loss: 23.161791801452637 RMSE: 4.81267\n",
      "37 8 1.326537847518921\n",
      "Validation loss: 46.12671089172363 RMSE: 6.791665\n",
      "Validation loss: 31.29344367980957 RMSE: 5.5940547\n",
      "Validation loss: 30.92775058746338 RMSE: 5.5612726\n",
      "40 10 1.540187954902649\n",
      "Validation loss: 37.219122886657715 RMSE: 6.100747\n",
      "Validation loss: 35.76196765899658 RMSE: 5.980131\n",
      "Validation loss: 19.37586212158203 RMSE: 4.401802\n",
      "43 12 1.687074065208435\n",
      "Validation loss: 44.148216247558594 RMSE: 6.6444125\n",
      "Validation loss: 40.79616165161133 RMSE: 6.387187\n",
      "Validation loss: 43.68540716171265 RMSE: 6.6094937\n",
      "46 14 3.5270884037017822\n",
      "Validation loss: 30.142544746398926 RMSE: 5.4902225\n",
      "Validation loss: 27.025702953338623 RMSE: 5.1986256\n",
      "Validation loss: 25.08691167831421 RMSE: 5.008683\n",
      "Validation loss: 38.792694091796875 RMSE: 6.2283792\n",
      "50 0 1.6777654886245728\n",
      "Validation loss: 25.92780303955078 RMSE: 5.0919347\n",
      "Validation loss: 40.313743591308594 RMSE: 6.349311\n",
      "Validation loss: 16.465715408325195 RMSE: 4.057797\n",
      "53 2 1.0959752798080444\n",
      "Validation loss: 40.15104293823242 RMSE: 6.3364844\n",
      "Validation loss: 15.732288360595703 RMSE: 3.966395\n",
      "Validation loss: 22.1583309173584 RMSE: 4.707264\n",
      "56 4 0.9847248792648315\n",
      "Validation loss: 33.459816455841064 RMSE: 5.7844462\n",
      "Validation loss: 26.887779235839844 RMSE: 5.185343\n",
      "Validation loss: 17.814827919006348 RMSE: 4.2207613\n",
      "59 6 1.1610825061798096\n",
      "Validation loss: 36.295799255371094 RMSE: 6.0245996\n",
      "Validation loss: 24.6641902923584 RMSE: 4.9663057\n",
      "Validation loss: 30.894132614135742 RMSE: 5.558249\n",
      "62 8 1.1201205253601074\n",
      "Validation loss: 19.95857572555542 RMSE: 4.4675016\n",
      "Validation loss: 23.939846992492676 RMSE: 4.8928366\n",
      "Validation loss: 36.3393759727478 RMSE: 6.028215\n",
      "65 10 1.4208240509033203\n",
      "Validation loss: 23.46671485900879 RMSE: 4.8442454\n",
      "Validation loss: 27.260543823242188 RMSE: 5.2211633\n",
      "Validation loss: 36.72369575500488 RMSE: 6.0600076\n",
      "68 12 1.1660168170928955\n",
      "Validation loss: 18.034675121307373 RMSE: 4.246725\n",
      "Validation loss: 32.95794868469238 RMSE: 5.740901\n",
      "Validation loss: 23.49701499938965 RMSE: 4.847372\n",
      "71 14 1.2872482538223267\n",
      "Validation loss: 26.914188385009766 RMSE: 5.1878886\n",
      "Validation loss: 19.462407112121582 RMSE: 4.411622\n",
      "Validation loss: 35.052557945251465 RMSE: 5.920521\n",
      "Validation loss: 32.58866500854492 RMSE: 5.708648\n",
      "75 0 1.5380133390426636\n",
      "Validation loss: 31.570706367492676 RMSE: 5.6187825\n",
      "Validation loss: 32.36310005187988 RMSE: 5.6888576\n",
      "Validation loss: 15.54518985748291 RMSE: 3.9427388\n",
      "78 2 1.7014431953430176\n",
      "Validation loss: 32.86430358886719 RMSE: 5.7327394\n",
      "Validation loss: 27.989460945129395 RMSE: 5.290507\n",
      "Validation loss: 39.44802761077881 RMSE: 6.2807665\n",
      "81 4 2.534358263015747\n",
      "Validation loss: 22.27723979949951 RMSE: 4.719877\n",
      "Validation loss: 24.939462661743164 RMSE: 4.9939427\n",
      "Validation loss: 29.506283283233643 RMSE: 5.4319687\n",
      "84 6 1.1265486478805542\n",
      "Validation loss: 33.06458854675293 RMSE: 5.7501817\n",
      "Validation loss: 21.15886402130127 RMSE: 4.5998764\n",
      "Validation loss: 28.15572214126587 RMSE: 5.3061967\n",
      "87 8 1.0756913423538208\n",
      "Validation loss: 28.65785503387451 RMSE: 5.353302\n",
      "Validation loss: 27.446659088134766 RMSE: 5.238956\n",
      "Validation loss: 30.087430477142334 RMSE: 5.4852014\n",
      "90 10 1.2501800060272217\n",
      "Validation loss: 27.933027267456055 RMSE: 5.2851706\n",
      "Validation loss: 29.521221160888672 RMSE: 5.4333434\n",
      "Validation loss: 38.28559875488281 RMSE: 6.1875353\n",
      "93 12 0.9584264159202576\n",
      "Validation loss: 29.74507236480713 RMSE: 5.4539037\n",
      "Validation loss: 23.98943328857422 RMSE: 4.8979006\n",
      "Validation loss: 32.22280025482178 RMSE: 5.676513\n",
      "96 14 0.6841310262680054\n",
      "Validation loss: 36.43655014038086 RMSE: 6.0362697\n",
      "Validation loss: 21.679585456848145 RMSE: 4.656134\n",
      "Validation loss: 29.26754093170166 RMSE: 5.4099483\n",
      "Validation loss: 35.086212158203125 RMSE: 5.923362\n",
      "100 0 1.1122105121612549\n",
      "Validation loss: 21.044334411621094 RMSE: 4.5874104\n",
      "Validation loss: 54.599098205566406 RMSE: 7.3891206\n",
      "Validation loss: 21.418596267700195 RMSE: 4.628023\n",
      "103 2 0.8369159698486328\n",
      "Validation loss: 25.299837112426758 RMSE: 5.0298944\n",
      "Validation loss: 19.654528617858887 RMSE: 4.433343\n",
      "Validation loss: 26.197529792785645 RMSE: 5.1183524\n",
      "106 4 0.8902868032455444\n",
      "Validation loss: 22.707138061523438 RMSE: 4.7652006\n",
      "Validation loss: 20.988657474517822 RMSE: 4.581338\n",
      "Validation loss: 40.58264636993408 RMSE: 6.3704505\n",
      "109 6 0.9998846054077148\n",
      "Validation loss: 15.694007873535156 RMSE: 3.9615664\n",
      "Validation loss: 39.9713020324707 RMSE: 6.3222857\n",
      "Validation loss: 18.242459297180176 RMSE: 4.271119\n",
      "112 8 1.3147741556167603\n",
      "Validation loss: 41.7417516708374 RMSE: 6.460786\n",
      "Validation loss: 15.873466491699219 RMSE: 3.9841518\n",
      "Validation loss: 21.61344814300537 RMSE: 4.6490264\n",
      "115 10 0.8645281791687012\n",
      "Validation loss: 33.126264572143555 RMSE: 5.755542\n",
      "Validation loss: 23.373915672302246 RMSE: 4.8346577\n",
      "Validation loss: 49.895851135253906 RMSE: 7.0637\n",
      "118 12 1.8586928844451904\n",
      "Validation loss: 30.98334789276123 RMSE: 5.566269\n",
      "Validation loss: 27.394773483276367 RMSE: 5.2340016\n",
      "Validation loss: 35.60900020599365 RMSE: 5.967327\n",
      "121 14 0.7140282988548279\n",
      "Validation loss: 27.44647979736328 RMSE: 5.2389393\n",
      "Validation loss: 23.166841506958008 RMSE: 4.8131943\n",
      "Validation loss: 28.45594882965088 RMSE: 5.3344116\n",
      "Validation loss: 16.76927089691162 RMSE: 4.09503\n",
      "125 0 0.8413404822349548\n",
      "Validation loss: 27.017221450805664 RMSE: 5.197809\n",
      "Validation loss: 27.144786834716797 RMSE: 5.2100654\n",
      "Validation loss: 21.616641521453857 RMSE: 4.64937\n",
      "128 2 0.7550930976867676\n",
      "Validation loss: 33.04435157775879 RMSE: 5.7484217\n",
      "Validation loss: 31.203723907470703 RMSE: 5.5860295\n",
      "Validation loss: 32.50015926361084 RMSE: 5.700891\n",
      "131 4 1.1840019226074219\n",
      "Validation loss: 19.39688730239868 RMSE: 4.4041896\n",
      "Validation loss: 25.271523475646973 RMSE: 5.027079\n",
      "Validation loss: 23.469948768615723 RMSE: 4.8445797\n",
      "134 6 0.5543213486671448\n",
      "Validation loss: 17.322169303894043 RMSE: 4.161991\n",
      "Validation loss: 36.78535842895508 RMSE: 6.0650935\n",
      "Validation loss: 18.567073345184326 RMSE: 4.308953\n",
      "137 8 0.8399605751037598\n",
      "Validation loss: 32.022682189941406 RMSE: 5.658859\n",
      "Validation loss: 28.651212692260742 RMSE: 5.3526835\n",
      "Validation loss: 20.53274631500244 RMSE: 4.531307\n",
      "140 10 0.638956606388092\n",
      "Validation loss: 24.487133979797363 RMSE: 4.9484477\n",
      "Validation loss: 33.90846824645996 RMSE: 5.823098\n",
      "Validation loss: 28.849180221557617 RMSE: 5.3711433\n",
      "143 12 1.4857219457626343\n",
      "Validation loss: 23.399290084838867 RMSE: 4.8372817\n",
      "Validation loss: 23.22765064239502 RMSE: 4.819507\n",
      "Validation loss: 19.811037063598633 RMSE: 4.450959\n",
      "146 14 0.6337209939956665\n",
      "Validation loss: 33.3960542678833 RMSE: 5.7789316\n",
      "Validation loss: 22.6837215423584 RMSE: 4.762743\n",
      "Validation loss: 29.88718605041504 RMSE: 5.466918\n",
      "Validation loss: 26.229236602783203 RMSE: 5.1214485\n",
      "150 0 0.5720570087432861\n",
      "Validation loss: 25.46185302734375 RMSE: 5.045974\n",
      "Validation loss: 30.28592586517334 RMSE: 5.503265\n",
      "Validation loss: 22.158435821533203 RMSE: 4.707275\n",
      "153 2 0.6420388221740723\n",
      "Validation loss: 35.81795310974121 RMSE: 5.98481\n",
      "Validation loss: 17.871554374694824 RMSE: 4.2274756\n",
      "Validation loss: 17.237205028533936 RMSE: 4.1517715\n",
      "156 4 0.6688256859779358\n",
      "Validation loss: 22.33051872253418 RMSE: 4.7255177\n",
      "Validation loss: 27.09532070159912 RMSE: 5.2053165\n",
      "Validation loss: 16.951476573944092 RMSE: 4.117217\n",
      "159 6 0.46845775842666626\n",
      "Validation loss: 36.51816177368164 RMSE: 6.043026\n",
      "Validation loss: 22.39120578765869 RMSE: 4.7319345\n",
      "Validation loss: 20.639533519744873 RMSE: 4.5430756\n",
      "162 8 0.692281186580658\n",
      "Validation loss: 24.787755012512207 RMSE: 4.97873\n",
      "Validation loss: 26.02193832397461 RMSE: 5.101171\n",
      "Validation loss: 39.371957778930664 RMSE: 6.274707\n",
      "165 10 1.1253474950790405\n",
      "Validation loss: 24.135862350463867 RMSE: 4.912826\n",
      "Validation loss: 39.616722106933594 RMSE: 6.294182\n",
      "Validation loss: 21.854948043823242 RMSE: 4.6749277\n",
      "168 12 0.974205732345581\n",
      "Validation loss: 37.35732078552246 RMSE: 6.112064\n",
      "Validation loss: 22.86437225341797 RMSE: 4.7816706\n",
      "Validation loss: 31.84618854522705 RMSE: 5.6432424\n",
      "171 14 0.4115704298019409\n",
      "Validation loss: 17.651689529418945 RMSE: 4.2013917\n",
      "Validation loss: 24.718600273132324 RMSE: 4.9717803\n",
      "Validation loss: 16.34725522994995 RMSE: 4.043174\n",
      "Validation loss: 41.0837287902832 RMSE: 6.4096594\n",
      "175 0 0.6616290807723999\n",
      "Validation loss: 25.043213844299316 RMSE: 5.004319\n",
      "Validation loss: 20.126930236816406 RMSE: 4.4863048\n",
      "Validation loss: 17.38328456878662 RMSE: 4.169327\n",
      "178 2 0.8196763396263123\n",
      "Validation loss: 25.97808265686035 RMSE: 5.09687\n",
      "Validation loss: 16.322157382965088 RMSE: 4.040069\n",
      "Validation loss: 24.31640911102295 RMSE: 4.9311666\n",
      "181 4 0.5658812522888184\n",
      "Validation loss: 15.850765228271484 RMSE: 3.981302\n",
      "Validation loss: 27.9974365234375 RMSE: 5.2912602\n",
      "Validation loss: 33.76990222930908 RMSE: 5.8111877\n",
      "184 6 1.175317406654358\n",
      "Validation loss: 20.111708641052246 RMSE: 4.484608\n",
      "Validation loss: 30.2523250579834 RMSE: 5.5002112\n",
      "Validation loss: 33.62216377258301 RMSE: 5.798463\n",
      "187 8 0.4125159978866577\n",
      "Validation loss: 29.018982887268066 RMSE: 5.386927\n",
      "Validation loss: 22.967495918273926 RMSE: 4.792442\n",
      "Validation loss: 31.200366973876953 RMSE: 5.5857286\n",
      "190 10 0.4761979579925537\n",
      "Validation loss: 23.781325340270996 RMSE: 4.87661\n",
      "Validation loss: 18.784038543701172 RMSE: 4.334056\n",
      "Validation loss: 22.29522132873535 RMSE: 4.7217817\n",
      "193 12 0.6987863183021545\n",
      "Validation loss: 22.843910217285156 RMSE: 4.7795305\n",
      "Validation loss: 22.814270973205566 RMSE: 4.776429\n",
      "Validation loss: 32.63365840911865 RMSE: 5.712588\n",
      "196 14 0.681879997253418\n",
      "Validation loss: 21.216018676757812 RMSE: 4.606085\n",
      "Validation loss: 21.813718795776367 RMSE: 4.670516\n",
      "Validation loss: 19.67827081680298 RMSE: 4.43602\n",
      "Validation loss: 17.43083095550537 RMSE: 4.1750245\n",
      "Loaded trained model with success.\n",
      "Test loss: 13.17285543680191 Test RMSE: 3.6294427\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'freesolv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 778, 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'target': ['expt']}}\n",
      "Running on: cuda:1\n",
      "641\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/641\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 28.371477127075195\n",
      "Validation loss: 45.022361755371094 RMSE: 6.7098703\n",
      "Validation loss: 22.504730224609375 RMSE: 4.743915\n",
      "Validation loss: 12.735766410827637 RMSE: 3.5687206\n",
      "3 2 4.886356353759766\n",
      "Validation loss: 16.81407356262207 RMSE: 4.1004963\n",
      "Validation loss: 32.12990093231201 RMSE: 5.668324\n",
      "Validation loss: 42.15038204193115 RMSE: 6.4923315\n",
      "6 4 3.4879493713378906\n",
      "Validation loss: 16.833858489990234 RMSE: 4.1029077\n",
      "Validation loss: 15.54255485534668 RMSE: 3.9424047\n",
      "Validation loss: 11.206153392791748 RMSE: 3.3475595\n",
      "9 6 4.071750640869141\n",
      "Validation loss: 30.099351406097412 RMSE: 5.4862876\n",
      "Validation loss: 20.27351140975952 RMSE: 4.502612\n",
      "Validation loss: 23.15390110015869 RMSE: 4.81185\n",
      "12 8 2.9122157096862793\n",
      "Validation loss: 30.40470790863037 RMSE: 5.514046\n",
      "Validation loss: 21.972612380981445 RMSE: 4.687495\n",
      "Validation loss: 33.16358947753906 RMSE: 5.758784\n",
      "15 10 2.216106653213501\n",
      "Validation loss: 33.735469818115234 RMSE: 5.808224\n",
      "Validation loss: 69.68951225280762 RMSE: 8.348022\n",
      "Validation loss: 13.359538078308105 RMSE: 3.65507\n",
      "18 12 2.8195760250091553\n",
      "Validation loss: 34.887993812561035 RMSE: 5.9066057\n",
      "Validation loss: 35.379526138305664 RMSE: 5.948069\n",
      "Validation loss: 42.04275703430176 RMSE: 6.4840384\n",
      "21 14 2.132035255432129\n",
      "Validation loss: 25.038978576660156 RMSE: 5.0038958\n",
      "Validation loss: 21.45242214202881 RMSE: 4.6316757\n",
      "Validation loss: 35.48231315612793 RMSE: 5.956703\n",
      "Validation loss: 40.489662647247314 RMSE: 6.3631487\n",
      "25 0 2.3996529579162598\n",
      "Validation loss: 24.65937328338623 RMSE: 4.965821\n",
      "Validation loss: 27.09943389892578 RMSE: 5.205712\n",
      "Validation loss: 18.301095962524414 RMSE: 4.2779784\n",
      "28 2 1.3720693588256836\n",
      "Validation loss: 43.8046875 RMSE: 6.6185102\n",
      "Validation loss: 27.039670944213867 RMSE: 5.1999683\n",
      "Validation loss: 16.56764268875122 RMSE: 4.070337\n",
      "31 4 3.9962267875671387\n",
      "Validation loss: 25.251254558563232 RMSE: 5.0250626\n",
      "Validation loss: 22.2552433013916 RMSE: 4.7175465\n",
      "Validation loss: 21.20309066772461 RMSE: 4.6046815\n",
      "34 6 2.7420969009399414\n",
      "Validation loss: 32.91152048110962 RMSE: 5.736856\n",
      "Validation loss: 31.105649948120117 RMSE: 5.577244\n",
      "Validation loss: 22.526942253112793 RMSE: 4.746256\n",
      "37 8 1.6779202222824097\n",
      "Validation loss: 24.812914848327637 RMSE: 4.981256\n",
      "Validation loss: 50.434688568115234 RMSE: 7.1017385\n",
      "Validation loss: 26.988290786743164 RMSE: 5.195026\n",
      "40 10 1.0407512187957764\n",
      "Validation loss: 24.338624000549316 RMSE: 4.933419\n",
      "Validation loss: 28.28141689300537 RMSE: 5.3180275\n",
      "Validation loss: 34.095083236694336 RMSE: 5.8390994\n",
      "43 12 1.2074782848358154\n",
      "Validation loss: 34.95528984069824 RMSE: 5.9122996\n",
      "Validation loss: 29.384931564331055 RMSE: 5.420787\n",
      "Validation loss: 19.946746826171875 RMSE: 4.466178\n",
      "46 14 1.177135705947876\n",
      "Validation loss: 34.21989631652832 RMSE: 5.8497777\n",
      "Validation loss: 32.779541015625 RMSE: 5.725342\n",
      "Validation loss: 29.799983024597168 RMSE: 5.4589367\n",
      "Validation loss: 28.269301414489746 RMSE: 5.316888\n",
      "50 0 1.7216252088546753\n",
      "Validation loss: 23.148080825805664 RMSE: 4.8112445\n",
      "Validation loss: 38.42976379394531 RMSE: 6.199175\n",
      "Validation loss: 30.902883529663086 RMSE: 5.5590363\n",
      "53 2 1.4486181735992432\n",
      "Validation loss: 30.281545639038086 RMSE: 5.5028677\n",
      "Validation loss: 81.36626434326172 RMSE: 9.020326\n",
      "Validation loss: 42.66093063354492 RMSE: 6.5315332\n",
      "56 4 1.3957165479660034\n",
      "Validation loss: 72.484130859375 RMSE: 8.5137615\n",
      "Validation loss: 16.079651832580566 RMSE: 4.009944\n",
      "Validation loss: 23.034658432006836 RMSE: 4.7994432\n",
      "59 6 1.5507704019546509\n",
      "Validation loss: 30.429875373840332 RMSE: 5.5163274\n",
      "Validation loss: 42.13288116455078 RMSE: 6.4909844\n",
      "Validation loss: 17.931440353393555 RMSE: 4.2345533\n",
      "62 8 1.6345239877700806\n",
      "Validation loss: 40.892385482788086 RMSE: 6.394715\n",
      "Validation loss: 20.415462493896484 RMSE: 4.5183473\n",
      "Validation loss: 49.714120864868164 RMSE: 7.050824\n",
      "65 10 0.8286021947860718\n",
      "Validation loss: 26.23840618133545 RMSE: 5.122344\n",
      "Validation loss: 29.49856185913086 RMSE: 5.431258\n",
      "Validation loss: 25.818769454956055 RMSE: 5.0812173\n",
      "68 12 1.8045461177825928\n",
      "Validation loss: 34.3712854385376 RMSE: 5.8627033\n",
      "Validation loss: 34.338215827941895 RMSE: 5.859882\n",
      "Validation loss: 41.9369478225708 RMSE: 6.4758735\n",
      "71 14 0.629338264465332\n",
      "Validation loss: 29.062259674072266 RMSE: 5.3909426\n",
      "Validation loss: 48.45527267456055 RMSE: 6.960982\n",
      "Validation loss: 24.994874954223633 RMSE: 4.9994874\n",
      "Validation loss: 56.56354331970215 RMSE: 7.520874\n",
      "75 0 1.3428024053573608\n",
      "Validation loss: 34.81671905517578 RMSE: 5.9005694\n",
      "Validation loss: 33.92810249328613 RMSE: 5.824784\n",
      "Validation loss: 21.583965301513672 RMSE: 4.6458545\n",
      "78 2 0.9532259106636047\n",
      "Validation loss: 15.68496322631836 RMSE: 3.9604247\n",
      "Validation loss: 24.761926651000977 RMSE: 4.9761357\n",
      "Validation loss: 30.108016967773438 RMSE: 5.487077\n",
      "81 4 2.0977330207824707\n",
      "Validation loss: 22.218416213989258 RMSE: 4.7136416\n",
      "Validation loss: 24.42306423187256 RMSE: 4.9419694\n",
      "Validation loss: 26.876235961914062 RMSE: 5.1842294\n",
      "84 6 0.603549063205719\n",
      "Validation loss: 20.3633713722229 RMSE: 4.5125794\n",
      "Validation loss: 23.894649982452393 RMSE: 4.8882155\n",
      "Validation loss: 37.382246017456055 RMSE: 6.114102\n",
      "87 8 0.8868691921234131\n",
      "Validation loss: 14.81352949142456 RMSE: 3.848835\n",
      "Validation loss: 27.615415573120117 RMSE: 5.255037\n",
      "Validation loss: 28.641380310058594 RMSE: 5.351764\n",
      "90 10 1.582388997077942\n",
      "Validation loss: 15.357580184936523 RMSE: 3.918875\n",
      "Validation loss: 22.37887144088745 RMSE: 4.7306314\n",
      "Validation loss: 22.79662799835205 RMSE: 4.7745814\n",
      "93 12 1.047317624092102\n",
      "Validation loss: 31.502384185791016 RMSE: 5.612698\n",
      "Validation loss: 32.47849941253662 RMSE: 5.6989913\n",
      "Validation loss: 26.129606246948242 RMSE: 5.111712\n",
      "96 14 0.9606688618659973\n",
      "Validation loss: 28.024312019348145 RMSE: 5.2937994\n",
      "Validation loss: 21.318049430847168 RMSE: 4.6171474\n",
      "Validation loss: 23.26834774017334 RMSE: 4.8237276\n",
      "Validation loss: 19.04976177215576 RMSE: 4.364603\n",
      "100 0 0.7619338035583496\n",
      "Validation loss: 24.22658634185791 RMSE: 4.9220514\n",
      "Validation loss: 48.35553550720215 RMSE: 6.9538145\n",
      "Validation loss: 19.282007217407227 RMSE: 4.391128\n",
      "103 2 1.1893352270126343\n",
      "Validation loss: 34.111077308654785 RMSE: 5.8404684\n",
      "Validation loss: 40.21615505218506 RMSE: 6.3416214\n",
      "Validation loss: 15.688173294067383 RMSE: 3.96083\n",
      "106 4 0.7208517789840698\n",
      "Validation loss: 43.4697322845459 RMSE: 6.5931573\n",
      "Validation loss: 30.528555870056152 RMSE: 5.5252647\n",
      "Validation loss: 22.87278413772583 RMSE: 4.78255\n",
      "109 6 0.6336656808853149\n",
      "Validation loss: 27.30662441253662 RMSE: 5.225574\n",
      "Validation loss: 22.20979881286621 RMSE: 4.7127275\n",
      "Validation loss: 16.08433961868286 RMSE: 4.0105286\n",
      "112 8 0.691126823425293\n",
      "Validation loss: 25.87708282470703 RMSE: 5.086952\n",
      "Validation loss: 20.415374755859375 RMSE: 4.5183377\n",
      "Validation loss: 26.47298288345337 RMSE: 5.1451902\n",
      "115 10 1.3650553226470947\n",
      "Validation loss: 24.55641746520996 RMSE: 4.9554434\n",
      "Validation loss: 19.551281929016113 RMSE: 4.421683\n",
      "Validation loss: 17.80501937866211 RMSE: 4.2195992\n",
      "118 12 0.7525039315223694\n",
      "Validation loss: 23.43698215484619 RMSE: 4.8411756\n",
      "Validation loss: 27.591934204101562 RMSE: 5.2528024\n",
      "Validation loss: 17.109684944152832 RMSE: 4.1363854\n",
      "121 14 0.6762216091156006\n",
      "Validation loss: 15.61060905456543 RMSE: 3.9510264\n",
      "Validation loss: 41.0907883644104 RMSE: 6.410209\n",
      "Validation loss: 14.372148513793945 RMSE: 3.7910619\n",
      "Validation loss: 16.874337196350098 RMSE: 4.107838\n",
      "125 0 0.8863606452941895\n",
      "Validation loss: 33.35531044006348 RMSE: 5.7754054\n",
      "Validation loss: 15.871177196502686 RMSE: 3.9838648\n",
      "Validation loss: 31.15206813812256 RMSE: 5.5814037\n",
      "128 2 0.6234586238861084\n",
      "Validation loss: 15.888954639434814 RMSE: 3.9860954\n",
      "Validation loss: 19.603758811950684 RMSE: 4.4276133\n",
      "Validation loss: 37.3170223236084 RMSE: 6.108766\n",
      "131 4 2.316594362258911\n",
      "Validation loss: 19.399590492248535 RMSE: 4.4044967\n",
      "Validation loss: 18.523215293884277 RMSE: 4.3038607\n",
      "Validation loss: 34.565438747406006 RMSE: 5.8792386\n",
      "134 6 0.8433672189712524\n",
      "Validation loss: 29.566899299621582 RMSE: 5.437545\n",
      "Validation loss: 15.328360557556152 RMSE: 3.915145\n",
      "Validation loss: 18.330846786499023 RMSE: 4.2814536\n",
      "137 8 0.648210346698761\n",
      "Validation loss: 18.374571323394775 RMSE: 4.286557\n",
      "Validation loss: 24.659128189086914 RMSE: 4.965796\n",
      "Validation loss: 16.356431484222412 RMSE: 4.0443087\n",
      "140 10 0.52939772605896\n",
      "Validation loss: 19.50713348388672 RMSE: 4.4166884\n",
      "Validation loss: 15.453788757324219 RMSE: 3.9311306\n",
      "Validation loss: 27.59893035888672 RMSE: 5.253469\n",
      "143 12 0.9043097496032715\n",
      "Validation loss: 18.511096954345703 RMSE: 4.3024526\n",
      "Validation loss: 16.63251495361328 RMSE: 4.078298\n",
      "Validation loss: 19.44728708267212 RMSE: 4.409908\n",
      "146 14 0.6334564089775085\n",
      "Validation loss: 16.616241455078125 RMSE: 4.0763025\n",
      "Validation loss: 19.24424934387207 RMSE: 4.3868265\n",
      "Validation loss: 16.801005363464355 RMSE: 4.098903\n",
      "Validation loss: 23.599618911743164 RMSE: 4.857944\n",
      "150 0 0.3472119867801666\n",
      "Validation loss: 18.30709981918335 RMSE: 4.2786794\n",
      "Validation loss: 25.449223518371582 RMSE: 5.0447226\n",
      "Validation loss: 25.17254638671875 RMSE: 5.017225\n",
      "153 2 2.032163381576538\n",
      "Validation loss: 15.741267204284668 RMSE: 3.9675267\n",
      "Validation loss: 21.743388175964355 RMSE: 4.6629806\n",
      "Validation loss: 21.00211524963379 RMSE: 4.5828066\n",
      "156 4 0.9228641986846924\n",
      "Validation loss: 19.729243278503418 RMSE: 4.4417615\n",
      "Validation loss: 24.1325626373291 RMSE: 4.912491\n",
      "Validation loss: 16.764952659606934 RMSE: 4.0945024\n",
      "159 6 0.7500009536743164\n",
      "Validation loss: 16.00079345703125 RMSE: 4.0000987\n",
      "Validation loss: 15.239729404449463 RMSE: 3.9038095\n",
      "Validation loss: 17.27452278137207 RMSE: 4.156263\n",
      "162 8 0.9024325609207153\n",
      "Validation loss: 19.787291526794434 RMSE: 4.448291\n",
      "Validation loss: 18.851235389709473 RMSE: 4.3418007\n",
      "Validation loss: 22.243691444396973 RMSE: 4.7163215\n",
      "165 10 0.6994761824607849\n",
      "Validation loss: 18.799954414367676 RMSE: 4.3358912\n",
      "Validation loss: 17.565024375915527 RMSE: 4.191065\n",
      "Validation loss: 19.729068756103516 RMSE: 4.4417415\n",
      "168 12 0.8853060603141785\n",
      "Validation loss: 20.957341194152832 RMSE: 4.5779185\n",
      "Validation loss: 16.601707458496094 RMSE: 4.074519\n",
      "Validation loss: 17.478278636932373 RMSE: 4.180703\n",
      "171 14 0.7647068500518799\n",
      "Validation loss: 23.376275062561035 RMSE: 4.834902\n",
      "Validation loss: 20.738204956054688 RMSE: 4.553922\n",
      "Validation loss: 35.873674392700195 RMSE: 5.989464\n",
      "Validation loss: 11.953554153442383 RMSE: 3.4573913\n",
      "175 0 0.6978608965873718\n",
      "Validation loss: 20.02753496170044 RMSE: 4.4752135\n",
      "Validation loss: 16.393423080444336 RMSE: 4.048879\n",
      "Validation loss: 22.008424758911133 RMSE: 4.6913137\n",
      "178 2 0.5037570595741272\n",
      "Validation loss: 14.87468147277832 RMSE: 3.8567708\n",
      "Validation loss: 19.701667308807373 RMSE: 4.438656\n",
      "Validation loss: 18.445781707763672 RMSE: 4.2948556\n",
      "181 4 1.1659772396087646\n",
      "Validation loss: 41.82857131958008 RMSE: 6.4675016\n",
      "Validation loss: 12.589638471603394 RMSE: 3.548188\n",
      "Validation loss: 15.828551530838013 RMSE: 3.978511\n",
      "184 6 0.8582977056503296\n",
      "Validation loss: 19.236032485961914 RMSE: 4.38589\n",
      "Validation loss: 18.661344528198242 RMSE: 4.3198776\n",
      "Validation loss: 26.218220710754395 RMSE: 5.1203732\n",
      "187 8 0.616417646408081\n",
      "Validation loss: 17.222439765930176 RMSE: 4.1499925\n",
      "Validation loss: 19.61612606048584 RMSE: 4.42901\n",
      "Validation loss: 17.919054985046387 RMSE: 4.2330904\n",
      "190 10 0.4610247313976288\n",
      "Validation loss: 18.125909328460693 RMSE: 4.2574534\n",
      "Validation loss: 25.38221025466919 RMSE: 5.0380764\n",
      "Validation loss: 20.073979377746582 RMSE: 4.480399\n",
      "193 12 0.8706808090209961\n",
      "Validation loss: 17.18462324142456 RMSE: 4.145434\n",
      "Validation loss: 18.191229343414307 RMSE: 4.2651176\n",
      "Validation loss: 25.71588706970215 RMSE: 5.071083\n",
      "196 14 0.501807451248169\n",
      "Validation loss: 14.662040710449219 RMSE: 3.8291047\n",
      "Validation loss: 15.600643157958984 RMSE: 3.949765\n",
      "Validation loss: 14.142829895019531 RMSE: 3.7606955\n",
      "Validation loss: 18.49742031097412 RMSE: 4.300863\n",
      "Loaded trained model with success.\n",
      "Test loss: 14.682927175668569 Test RMSE: 3.831831\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'freesolv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 779, 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'target': ['expt']}}\n",
      "Running on: cuda:1\n",
      "641\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/641\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 25.81894874572754\n",
      "Validation loss: 44.310800552368164 RMSE: 6.6566358\n",
      "Validation loss: 31.46853733062744 RMSE: 5.6096826\n",
      "Validation loss: 11.927799224853516 RMSE: 3.4536645\n",
      "3 2 10.502399444580078\n",
      "Validation loss: 19.237688064575195 RMSE: 4.3860793\n",
      "Validation loss: 18.959320068359375 RMSE: 4.35423\n",
      "Validation loss: 37.91876983642578 RMSE: 6.157821\n",
      "6 4 4.377531051635742\n",
      "Validation loss: 34.45046043395996 RMSE: 5.869452\n",
      "Validation loss: 28.108498573303223 RMSE: 5.301745\n",
      "Validation loss: 22.933510780334473 RMSE: 4.7888947\n",
      "9 6 3.670344591140747\n",
      "Validation loss: 49.024864196777344 RMSE: 7.0017757\n",
      "Validation loss: 24.994318962097168 RMSE: 4.999432\n",
      "Validation loss: 19.755334854125977 RMSE: 4.4446974\n",
      "12 8 2.930241107940674\n",
      "Validation loss: 27.301841735839844 RMSE: 5.2251167\n",
      "Validation loss: 34.06199836730957 RMSE: 5.8362656\n",
      "Validation loss: 18.27863597869873 RMSE: 4.275352\n",
      "15 10 2.246896743774414\n",
      "Validation loss: 18.879213333129883 RMSE: 4.3450217\n",
      "Validation loss: 22.368927001953125 RMSE: 4.72958\n",
      "Validation loss: 36.514142990112305 RMSE: 6.0426927\n",
      "18 12 4.906976699829102\n",
      "Validation loss: 45.43302536010742 RMSE: 6.7404017\n",
      "Validation loss: 32.721232414245605 RMSE: 5.7202473\n",
      "Validation loss: 24.046091079711914 RMSE: 4.9036813\n",
      "21 14 1.2166177034378052\n",
      "Validation loss: 22.59965991973877 RMSE: 4.75391\n",
      "Validation loss: 20.933849334716797 RMSE: 4.575352\n",
      "Validation loss: 26.327202796936035 RMSE: 5.1310043\n",
      "Validation loss: 20.301369667053223 RMSE: 4.505704\n",
      "25 0 1.5054658651351929\n",
      "Validation loss: 32.72788143157959 RMSE: 5.720829\n",
      "Validation loss: 27.609882354736328 RMSE: 5.2545104\n",
      "Validation loss: 32.633233070373535 RMSE: 5.7125506\n",
      "28 2 1.4375004768371582\n",
      "Validation loss: 28.088017463684082 RMSE: 5.299813\n",
      "Validation loss: 32.37005138397217 RMSE: 5.6894684\n",
      "Validation loss: 31.019023895263672 RMSE: 5.5694723\n",
      "31 4 1.5670132637023926\n",
      "Validation loss: 25.231700897216797 RMSE: 5.023117\n",
      "Validation loss: 27.219313621520996 RMSE: 5.2172127\n",
      "Validation loss: 34.68218207359314 RMSE: 5.8891582\n",
      "34 6 2.367746353149414\n",
      "Validation loss: 32.05855751037598 RMSE: 5.662028\n",
      "Validation loss: 21.78667449951172 RMSE: 4.6676197\n",
      "Validation loss: 25.62324333190918 RMSE: 5.0619407\n",
      "37 8 2.6597747802734375\n",
      "Validation loss: 81.62689208984375 RMSE: 9.03476\n",
      "Validation loss: 14.917962551116943 RMSE: 3.862378\n",
      "Validation loss: 44.21712112426758 RMSE: 6.6495953\n",
      "40 10 1.6643495559692383\n",
      "Validation loss: 25.93380641937256 RMSE: 5.092524\n",
      "Validation loss: 31.061647415161133 RMSE: 5.5732975\n",
      "Validation loss: 19.436355590820312 RMSE: 4.408668\n",
      "43 12 1.670318603515625\n",
      "Validation loss: 29.9095516204834 RMSE: 5.4689627\n",
      "Validation loss: 34.41671848297119 RMSE: 5.866576\n",
      "Validation loss: 32.84663009643555 RMSE: 5.7311983\n",
      "46 14 3.2056376934051514\n",
      "Validation loss: 49.27058219909668 RMSE: 7.0193005\n",
      "Validation loss: 21.18927001953125 RMSE: 4.6031804\n",
      "Validation loss: 21.38258647918701 RMSE: 4.6241307\n",
      "Validation loss: 44.819825172424316 RMSE: 6.694761\n",
      "50 0 1.5071442127227783\n",
      "Validation loss: 29.988727569580078 RMSE: 5.4761963\n",
      "Validation loss: 40.24658012390137 RMSE: 6.344019\n",
      "Validation loss: 22.411853313446045 RMSE: 4.734116\n",
      "53 2 0.8614268898963928\n",
      "Validation loss: 36.3095645904541 RMSE: 6.0257416\n",
      "Validation loss: 31.74920082092285 RMSE: 5.634643\n",
      "Validation loss: 41.77012634277344 RMSE: 6.462981\n",
      "56 4 1.9488904476165771\n",
      "Validation loss: 19.79082202911377 RMSE: 4.4486876\n",
      "Validation loss: 45.10071563720703 RMSE: 6.7157063\n",
      "Validation loss: 33.49187469482422 RMSE: 5.7872157\n",
      "59 6 5.155215263366699\n",
      "Validation loss: 47.81994438171387 RMSE: 6.9151964\n",
      "Validation loss: 29.185250282287598 RMSE: 5.402337\n",
      "Validation loss: 13.058187484741211 RMSE: 3.6136112\n",
      "62 8 1.804384708404541\n",
      "Validation loss: 18.51985454559326 RMSE: 4.30347\n",
      "Validation loss: 22.65853786468506 RMSE: 4.760099\n",
      "Validation loss: 19.561199188232422 RMSE: 4.4228044\n",
      "65 10 0.8765913248062134\n",
      "Validation loss: 35.732553482055664 RMSE: 5.977671\n",
      "Validation loss: 30.899191856384277 RMSE: 5.558704\n",
      "Validation loss: 37.7678165435791 RMSE: 6.1455526\n",
      "68 12 3.5456082820892334\n",
      "Validation loss: 30.018808841705322 RMSE: 5.4789424\n",
      "Validation loss: 17.52462387084961 RMSE: 4.1862426\n",
      "Validation loss: 30.798810958862305 RMSE: 5.5496674\n",
      "71 14 1.1536699533462524\n",
      "Validation loss: 32.22494029998779 RMSE: 5.676701\n",
      "Validation loss: 19.994030952453613 RMSE: 4.4714684\n",
      "Validation loss: 37.535818099975586 RMSE: 6.1266484\n",
      "Validation loss: 31.20181369781494 RMSE: 5.5858583\n",
      "75 0 1.2398806810379028\n",
      "Validation loss: 28.574466705322266 RMSE: 5.3455086\n",
      "Validation loss: 28.93665599822998 RMSE: 5.3792806\n",
      "Validation loss: 33.13753032684326 RMSE: 5.7565207\n",
      "78 2 1.6026966571807861\n",
      "Validation loss: 49.948551177978516 RMSE: 7.0674286\n",
      "Validation loss: 32.44117736816406 RMSE: 5.6957154\n",
      "Validation loss: 41.75625991821289 RMSE: 6.461908\n",
      "81 4 0.8692946434020996\n",
      "Validation loss: 14.48411512374878 RMSE: 3.8058002\n",
      "Validation loss: 27.022037506103516 RMSE: 5.198272\n",
      "Validation loss: 21.260952949523926 RMSE: 4.61096\n",
      "84 6 0.7357759475708008\n",
      "Validation loss: 31.357308387756348 RMSE: 5.599759\n",
      "Validation loss: 31.987926483154297 RMSE: 5.655787\n",
      "Validation loss: 31.59235382080078 RMSE: 5.620708\n",
      "87 8 0.9571489095687866\n",
      "Validation loss: 32.38975143432617 RMSE: 5.691199\n",
      "Validation loss: 29.810224533081055 RMSE: 5.4598746\n",
      "Validation loss: 41.05127143859863 RMSE: 6.407127\n",
      "90 10 1.0527023077011108\n",
      "Validation loss: 30.671724319458008 RMSE: 5.5382066\n",
      "Validation loss: 34.709089279174805 RMSE: 5.891442\n",
      "Validation loss: 26.75798225402832 RMSE: 5.172812\n",
      "93 12 0.627089262008667\n",
      "Validation loss: 40.79150867462158 RMSE: 6.386823\n",
      "Validation loss: 23.12364959716797 RMSE: 4.8087053\n",
      "Validation loss: 24.56148624420166 RMSE: 4.9559546\n",
      "96 14 0.6407245993614197\n",
      "Validation loss: 20.953102111816406 RMSE: 4.5774555\n",
      "Validation loss: 34.76507377624512 RMSE: 5.896191\n",
      "Validation loss: 29.31906509399414 RMSE: 5.414708\n",
      "Validation loss: 26.019105911254883 RMSE: 5.1008925\n",
      "100 0 2.1144118309020996\n",
      "Validation loss: 44.49559020996094 RMSE: 6.6705017\n",
      "Validation loss: 34.4186897277832 RMSE: 5.866744\n",
      "Validation loss: 24.719552040100098 RMSE: 4.9718766\n",
      "103 2 0.6971141695976257\n",
      "Validation loss: 25.137441635131836 RMSE: 5.0137253\n",
      "Validation loss: 15.861146926879883 RMSE: 3.9826055\n",
      "Validation loss: 23.89535903930664 RMSE: 4.8882875\n",
      "106 4 0.8053596019744873\n",
      "Validation loss: 29.616788864135742 RMSE: 5.442131\n",
      "Validation loss: 19.38942241668701 RMSE: 4.4033422\n",
      "Validation loss: 39.77162742614746 RMSE: 6.306475\n",
      "109 6 0.7034919857978821\n",
      "Validation loss: 26.30656337738037 RMSE: 5.1289926\n",
      "Validation loss: 38.61088180541992 RMSE: 6.213765\n",
      "Validation loss: 31.125600814819336 RMSE: 5.5790324\n",
      "112 8 1.0902842283248901\n",
      "Validation loss: 28.324135780334473 RMSE: 5.322043\n",
      "Validation loss: 21.479820251464844 RMSE: 4.6346326\n",
      "Validation loss: 47.825984954833984 RMSE: 6.915633\n",
      "115 10 1.7305335998535156\n",
      "Validation loss: 17.10702133178711 RMSE: 4.1360636\n",
      "Validation loss: 31.223365306854248 RMSE: 5.587787\n",
      "Validation loss: 23.766304969787598 RMSE: 4.8750696\n",
      "118 12 0.8116703629493713\n",
      "Validation loss: 17.62813377380371 RMSE: 4.198587\n",
      "Validation loss: 20.46285629272461 RMSE: 4.5235887\n",
      "Validation loss: 19.04325532913208 RMSE: 4.3638577\n",
      "121 14 0.8403551578521729\n",
      "Validation loss: 27.887975692749023 RMSE: 5.2809067\n",
      "Validation loss: 26.694518089294434 RMSE: 5.1666737\n",
      "Validation loss: 38.85179615020752 RMSE: 6.233121\n",
      "Validation loss: 30.414857864379883 RMSE: 5.5149665\n",
      "125 0 1.5607558488845825\n",
      "Validation loss: 17.444144248962402 RMSE: 4.176619\n",
      "Validation loss: 28.3382625579834 RMSE: 5.3233695\n",
      "Validation loss: 28.4352445602417 RMSE: 5.3324704\n",
      "128 2 0.7760733366012573\n",
      "Validation loss: 19.082967281341553 RMSE: 4.368406\n",
      "Validation loss: 22.474249839782715 RMSE: 4.7407017\n",
      "Validation loss: 17.645604610443115 RMSE: 4.2006674\n",
      "131 4 1.0886019468307495\n",
      "Validation loss: 19.7612361907959 RMSE: 4.445361\n",
      "Validation loss: 34.41282844543457 RMSE: 5.866245\n",
      "Validation loss: 15.166454315185547 RMSE: 3.8944132\n",
      "134 6 0.9639633297920227\n",
      "Validation loss: 18.138436317443848 RMSE: 4.2589245\n",
      "Validation loss: 17.894704818725586 RMSE: 4.2302136\n",
      "Validation loss: 13.518178939819336 RMSE: 3.6767075\n",
      "137 8 0.623043954372406\n",
      "Validation loss: 20.97849941253662 RMSE: 4.580229\n",
      "Validation loss: 18.85420322418213 RMSE: 4.3421426\n",
      "Validation loss: 19.08543300628662 RMSE: 4.368688\n",
      "140 10 0.5692443251609802\n",
      "Validation loss: 20.871551036834717 RMSE: 4.568539\n",
      "Validation loss: 17.504098892211914 RMSE: 4.18379\n",
      "Validation loss: 26.46184730529785 RMSE: 5.144108\n",
      "143 12 0.5365352034568787\n",
      "Validation loss: 24.01156234741211 RMSE: 4.9001594\n",
      "Validation loss: 19.136631965637207 RMSE: 4.3745437\n",
      "Validation loss: 24.98198699951172 RMSE: 4.9981985\n",
      "146 14 0.39753270149230957\n",
      "Validation loss: 22.069869995117188 RMSE: 4.697858\n",
      "Validation loss: 15.845573425292969 RMSE: 3.9806502\n",
      "Validation loss: 20.338749885559082 RMSE: 4.50985\n",
      "Validation loss: 27.084762573242188 RMSE: 5.2043023\n",
      "150 0 1.4388185739517212\n",
      "Validation loss: 25.280823707580566 RMSE: 5.0280037\n",
      "Validation loss: 14.390850067138672 RMSE: 3.7935276\n",
      "Validation loss: 30.570302963256836 RMSE: 5.5290413\n",
      "153 2 1.5685745477676392\n",
      "Validation loss: 18.605332374572754 RMSE: 4.31339\n",
      "Validation loss: 32.34725761413574 RMSE: 5.6874657\n",
      "Validation loss: 15.22441291809082 RMSE: 3.9018474\n",
      "156 4 1.0202343463897705\n",
      "Validation loss: 19.574654579162598 RMSE: 4.424325\n",
      "Validation loss: 22.177547454833984 RMSE: 4.7093043\n",
      "Validation loss: 17.133159637451172 RMSE: 4.139222\n",
      "159 6 0.5151599049568176\n",
      "Validation loss: 23.5159854888916 RMSE: 4.8493285\n",
      "Validation loss: 17.003262519836426 RMSE: 4.123501\n",
      "Validation loss: 27.282251358032227 RMSE: 5.223242\n",
      "162 8 2.373317241668701\n",
      "Validation loss: 23.981234550476074 RMSE: 4.8970637\n",
      "Validation loss: 26.384194374084473 RMSE: 5.1365542\n",
      "Validation loss: 18.115260124206543 RMSE: 4.2562027\n",
      "165 10 0.708034336566925\n",
      "Validation loss: 19.04619598388672 RMSE: 4.364195\n",
      "Validation loss: 20.384348392486572 RMSE: 4.5149026\n",
      "Validation loss: 18.10733413696289 RMSE: 4.2552714\n",
      "168 12 0.7647408246994019\n",
      "Validation loss: 16.915433883666992 RMSE: 4.1128373\n",
      "Validation loss: 24.34544563293457 RMSE: 4.93411\n",
      "Validation loss: 19.54582643508911 RMSE: 4.4210668\n",
      "171 14 0.5612682700157166\n",
      "Validation loss: 19.969058990478516 RMSE: 4.468675\n",
      "Validation loss: 18.81845474243164 RMSE: 4.3380237\n",
      "Validation loss: 16.96418046951294 RMSE: 4.1187596\n",
      "Validation loss: 21.430224418640137 RMSE: 4.6292787\n",
      "175 0 0.6198965311050415\n",
      "Validation loss: 16.463664054870605 RMSE: 4.057544\n",
      "Validation loss: 14.534022331237793 RMSE: 3.8123515\n",
      "Validation loss: 17.137166500091553 RMSE: 4.139706\n",
      "178 2 0.5243447422981262\n",
      "Validation loss: 18.094025135040283 RMSE: 4.253707\n",
      "Validation loss: 18.612754821777344 RMSE: 4.3142505\n",
      "Validation loss: 14.022584438323975 RMSE: 3.744674\n",
      "181 4 0.9144413471221924\n",
      "Validation loss: 19.096067428588867 RMSE: 4.3699045\n",
      "Validation loss: 14.897643089294434 RMSE: 3.8597467\n",
      "Validation loss: 15.64543104171753 RMSE: 3.9554307\n",
      "184 6 0.3836291432380676\n",
      "Validation loss: 17.694748878479004 RMSE: 4.2065125\n",
      "Validation loss: 18.180572509765625 RMSE: 4.2638683\n",
      "Validation loss: 14.338743209838867 RMSE: 3.7866533\n",
      "187 8 0.8524156212806702\n",
      "Validation loss: 18.027350425720215 RMSE: 4.2458625\n",
      "Validation loss: 16.40739345550537 RMSE: 4.0506043\n",
      "Validation loss: 15.733837127685547 RMSE: 3.9665902\n",
      "190 10 0.3166828155517578\n",
      "Validation loss: 17.3889799118042 RMSE: 4.1700096\n",
      "Validation loss: 18.65633726119995 RMSE: 4.3192983\n",
      "Validation loss: 50.08932971954346 RMSE: 7.077382\n",
      "193 12 0.609563946723938\n",
      "Validation loss: 14.193732738494873 RMSE: 3.767457\n",
      "Validation loss: 31.274942874908447 RMSE: 5.5924\n",
      "Validation loss: 16.192090034484863 RMSE: 4.0239396\n",
      "196 14 1.16828453540802\n",
      "Validation loss: 38.659353256225586 RMSE: 6.217665\n",
      "Validation loss: 13.180630207061768 RMSE: 3.630514\n",
      "Validation loss: 29.192394256591797 RMSE: 5.4029984\n",
      "Validation loss: 19.25449800491333 RMSE: 4.387995\n",
      "Loaded trained model with success.\n",
      "Test loss: 14.532438003099882 Test RMSE: 3.8121433\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'freesolv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 780, 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'target': ['expt']}}\n",
      "Running on: cuda:1\n",
      "641\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/641\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 42.4710807800293\n",
      "Validation loss: 44.04542350769043 RMSE: 6.6366725\n",
      "Validation loss: 26.72987461090088 RMSE: 5.170094\n",
      "Validation loss: 14.337287902832031 RMSE: 3.7864614\n",
      "3 2 5.849494934082031\n",
      "Validation loss: 15.127389430999756 RMSE: 3.8893948\n",
      "Validation loss: 19.777685165405273 RMSE: 4.447211\n",
      "Validation loss: 12.109097480773926 RMSE: 3.4798126\n",
      "6 4 3.936899185180664\n",
      "Validation loss: 20.614853858947754 RMSE: 4.540358\n",
      "Validation loss: 33.46039867401123 RMSE: 5.7844963\n",
      "Validation loss: 26.131467819213867 RMSE: 5.1118946\n",
      "9 6 2.753145694732666\n",
      "Validation loss: 40.60085868835449 RMSE: 6.37188\n",
      "Validation loss: 24.56447696685791 RMSE: 4.9562564\n",
      "Validation loss: 36.11939239501953 RMSE: 6.009941\n",
      "12 8 2.2863516807556152\n",
      "Validation loss: 40.234365463256836 RMSE: 6.3430567\n",
      "Validation loss: 18.405827045440674 RMSE: 4.290201\n",
      "Validation loss: 18.5555362701416 RMSE: 4.307614\n",
      "15 10 1.9351283311843872\n",
      "Validation loss: 47.52661895751953 RMSE: 6.893955\n",
      "Validation loss: 20.09162473678589 RMSE: 4.482368\n",
      "Validation loss: 24.59995126724243 RMSE: 4.959834\n",
      "18 12 1.2560309171676636\n",
      "Validation loss: 19.71382427215576 RMSE: 4.4400253\n",
      "Validation loss: 20.390219688415527 RMSE: 4.515553\n",
      "Validation loss: 26.696585655212402 RMSE: 5.1668735\n",
      "21 14 2.693572521209717\n",
      "Validation loss: 22.411765098571777 RMSE: 4.7341065\n",
      "Validation loss: 22.117281913757324 RMSE: 4.7029014\n",
      "Validation loss: 32.71807289123535 RMSE: 5.719971\n",
      "Validation loss: 31.855438232421875 RMSE: 5.644062\n",
      "25 0 1.7245641946792603\n",
      "Validation loss: 20.492984294891357 RMSE: 4.5269175\n",
      "Validation loss: 23.88139533996582 RMSE: 4.8868594\n",
      "Validation loss: 31.58226776123047 RMSE: 5.6198106\n",
      "28 2 1.4298410415649414\n",
      "Validation loss: 23.984975337982178 RMSE: 4.8974457\n",
      "Validation loss: 27.74933910369873 RMSE: 5.2677646\n",
      "Validation loss: 39.02194881439209 RMSE: 6.2467556\n",
      "31 4 1.5318810939788818\n",
      "Validation loss: 28.187575340270996 RMSE: 5.3091974\n",
      "Validation loss: 28.0399169921875 RMSE: 5.295273\n",
      "Validation loss: 42.65671920776367 RMSE: 6.5312114\n",
      "34 6 2.054919481277466\n",
      "Validation loss: 17.016121864318848 RMSE: 4.12506\n",
      "Validation loss: 18.65144443511963 RMSE: 4.318732\n",
      "Validation loss: 22.88158941268921 RMSE: 4.7834706\n",
      "37 8 5.75998067855835\n",
      "Validation loss: 32.6460657119751 RMSE: 5.7136736\n",
      "Validation loss: 20.05009174346924 RMSE: 4.477733\n",
      "Validation loss: 24.148798942565918 RMSE: 4.9141426\n",
      "40 10 1.9846951961517334\n",
      "Validation loss: 28.768765449523926 RMSE: 5.3636518\n",
      "Validation loss: 26.716367721557617 RMSE: 5.168788\n",
      "Validation loss: 23.527012825012207 RMSE: 4.8504653\n",
      "43 12 1.27190363407135\n",
      "Validation loss: 32.248568534851074 RMSE: 5.678782\n",
      "Validation loss: 30.332134246826172 RMSE: 5.5074615\n",
      "Validation loss: 35.367448806762695 RMSE: 5.9470534\n",
      "46 14 1.253981113433838\n",
      "Validation loss: 16.459886074066162 RMSE: 4.0570784\n",
      "Validation loss: 25.98374366760254 RMSE: 5.097425\n",
      "Validation loss: 29.322230339050293 RMSE: 5.4150004\n",
      "Validation loss: 26.8975887298584 RMSE: 5.1862884\n",
      "50 0 2.970841646194458\n",
      "Validation loss: 30.39116382598877 RMSE: 5.5128183\n",
      "Validation loss: 24.154680728912354 RMSE: 4.9147415\n",
      "Validation loss: 34.27469062805176 RMSE: 5.8544593\n",
      "53 2 2.7908098697662354\n",
      "Validation loss: 24.061720848083496 RMSE: 4.9052744\n",
      "Validation loss: 18.863038063049316 RMSE: 4.34316\n",
      "Validation loss: 25.825716972351074 RMSE: 5.0819006\n",
      "56 4 1.5585665702819824\n",
      "Validation loss: 39.231435775756836 RMSE: 6.2635\n",
      "Validation loss: 19.796571731567383 RMSE: 4.449334\n",
      "Validation loss: 20.67047119140625 RMSE: 4.546479\n",
      "59 6 0.9965580701828003\n",
      "Validation loss: 16.451151847839355 RMSE: 4.056002\n",
      "Validation loss: 15.658820152282715 RMSE: 3.9571228\n",
      "Validation loss: 24.1829776763916 RMSE: 4.917619\n",
      "62 8 1.168286681175232\n",
      "Validation loss: 28.90677785873413 RMSE: 5.376502\n",
      "Validation loss: 27.601916313171387 RMSE: 5.2537527\n",
      "Validation loss: 36.087286949157715 RMSE: 6.0072694\n",
      "65 10 2.070650100708008\n",
      "Validation loss: 13.320792198181152 RMSE: 3.649766\n",
      "Validation loss: 23.051097869873047 RMSE: 4.801156\n",
      "Validation loss: 19.58122444152832 RMSE: 4.425068\n",
      "68 12 1.933751106262207\n",
      "Validation loss: 20.641555786132812 RMSE: 4.543298\n",
      "Validation loss: 25.95037841796875 RMSE: 5.0941515\n",
      "Validation loss: 16.381768703460693 RMSE: 4.04744\n",
      "71 14 1.4102044105529785\n",
      "Validation loss: 24.511436462402344 RMSE: 4.9509025\n",
      "Validation loss: 20.774878978729248 RMSE: 4.5579467\n",
      "Validation loss: 25.935389518737793 RMSE: 5.0926795\n",
      "Validation loss: 30.16254711151123 RMSE: 5.492044\n",
      "75 0 1.1989195346832275\n",
      "Validation loss: 29.151241302490234 RMSE: 5.399189\n",
      "Validation loss: 22.448009490966797 RMSE: 4.7379336\n",
      "Validation loss: 30.56207275390625 RMSE: 5.5282974\n",
      "78 2 1.7243708372116089\n",
      "Validation loss: 18.929040908813477 RMSE: 4.350752\n",
      "Validation loss: 21.641900062561035 RMSE: 4.652086\n",
      "Validation loss: 28.515174865722656 RMSE: 5.33996\n",
      "81 4 1.061529517173767\n",
      "Validation loss: 29.607020378112793 RMSE: 5.4412336\n",
      "Validation loss: 20.626370429992676 RMSE: 4.5416265\n",
      "Validation loss: 15.88471508026123 RMSE: 3.9855633\n",
      "84 6 0.8318337202072144\n",
      "Validation loss: 35.80072021484375 RMSE: 5.983371\n",
      "Validation loss: 16.060816764831543 RMSE: 4.007595\n",
      "Validation loss: 31.730472564697266 RMSE: 5.632981\n",
      "87 8 1.0419549942016602\n",
      "Validation loss: 22.587055206298828 RMSE: 4.752584\n",
      "Validation loss: 25.203269004821777 RMSE: 5.0202856\n",
      "Validation loss: 19.873351573944092 RMSE: 4.457954\n",
      "90 10 0.7757036685943604\n",
      "Validation loss: 34.33676815032959 RMSE: 5.8597584\n",
      "Validation loss: 24.007424354553223 RMSE: 4.899737\n",
      "Validation loss: 20.7011661529541 RMSE: 4.5498533\n",
      "93 12 1.1225603818893433\n",
      "Validation loss: 16.052401065826416 RMSE: 4.0065446\n",
      "Validation loss: 34.063133239746094 RMSE: 5.836363\n",
      "Validation loss: 21.24822998046875 RMSE: 4.6095805\n",
      "96 14 0.6558325886726379\n",
      "Validation loss: 19.740872383117676 RMSE: 4.44307\n",
      "Validation loss: 24.448843955993652 RMSE: 4.9445777\n",
      "Validation loss: 19.169885635375977 RMSE: 4.3783426\n",
      "Validation loss: 33.55595397949219 RMSE: 5.7927504\n",
      "100 0 0.7128636837005615\n",
      "Validation loss: 26.088989734649658 RMSE: 5.107738\n",
      "Validation loss: 21.403651237487793 RMSE: 4.626408\n",
      "Validation loss: 24.0765323638916 RMSE: 4.906784\n",
      "103 2 0.8992339372634888\n",
      "Validation loss: 17.951101303100586 RMSE: 4.2368736\n",
      "Validation loss: 27.87864398956299 RMSE: 5.280023\n",
      "Validation loss: 26.785512924194336 RMSE: 5.1754723\n",
      "106 4 0.719452977180481\n",
      "Validation loss: 29.1654634475708 RMSE: 5.400506\n",
      "Validation loss: 21.932639122009277 RMSE: 4.6832294\n",
      "Validation loss: 27.98775863647461 RMSE: 5.290346\n",
      "109 6 0.8042067289352417\n",
      "Validation loss: 21.763773918151855 RMSE: 4.665166\n",
      "Validation loss: 18.267573356628418 RMSE: 4.274058\n",
      "Validation loss: 19.054548263549805 RMSE: 4.3651514\n",
      "112 8 0.44917118549346924\n",
      "Validation loss: 20.191513061523438 RMSE: 4.493497\n",
      "Validation loss: 16.10551357269287 RMSE: 4.013168\n",
      "Validation loss: 20.699417114257812 RMSE: 4.5496616\n",
      "115 10 0.9500367641448975\n",
      "Validation loss: 18.577617645263672 RMSE: 4.3101764\n",
      "Validation loss: 28.177326202392578 RMSE: 5.3082323\n",
      "Validation loss: 15.6826810836792 RMSE: 3.9601364\n",
      "118 12 0.5739723443984985\n",
      "Validation loss: 25.430842399597168 RMSE: 5.0429006\n",
      "Validation loss: 19.06777000427246 RMSE: 4.366666\n",
      "Validation loss: 22.478293418884277 RMSE: 4.741128\n",
      "121 14 0.8875335454940796\n",
      "Validation loss: 19.438623905181885 RMSE: 4.4089255\n",
      "Validation loss: 19.427026748657227 RMSE: 4.4076104\n",
      "Validation loss: 18.346507787704468 RMSE: 4.2832823\n",
      "Validation loss: 14.657066226005554 RMSE: 3.8284547\n",
      "125 0 1.158645749092102\n",
      "Validation loss: 25.449000358581543 RMSE: 5.0447\n",
      "Validation loss: 21.489755153656006 RMSE: 4.635704\n",
      "Validation loss: 11.569550514221191 RMSE: 3.4014044\n",
      "128 2 0.8718842267990112\n",
      "Validation loss: 22.753369331359863 RMSE: 4.7700496\n",
      "Validation loss: 17.994646549224854 RMSE: 4.2420096\n",
      "Validation loss: 25.964088439941406 RMSE: 5.0954967\n",
      "131 4 0.851547360420227\n",
      "Validation loss: 16.330756187438965 RMSE: 4.041133\n",
      "Validation loss: 17.99370288848877 RMSE: 4.2418985\n",
      "Validation loss: 18.957645893096924 RMSE: 4.354038\n",
      "134 6 1.13675856590271\n",
      "Validation loss: 19.88072681427002 RMSE: 4.458781\n",
      "Validation loss: 19.331613540649414 RMSE: 4.3967733\n",
      "Validation loss: 21.019150733947754 RMSE: 4.584665\n",
      "137 8 1.217555284500122\n",
      "Validation loss: 15.405534744262695 RMSE: 3.9249887\n",
      "Validation loss: 13.921090602874756 RMSE: 3.731098\n",
      "Validation loss: 16.27146577835083 RMSE: 4.0337906\n",
      "140 10 0.8702674508094788\n",
      "Validation loss: 24.461682319641113 RMSE: 4.945875\n",
      "Validation loss: 19.521921157836914 RMSE: 4.4183617\n",
      "Validation loss: 31.398052215576172 RMSE: 5.6033964\n",
      "143 12 0.6682725548744202\n",
      "Validation loss: 16.3604416847229 RMSE: 4.044804\n",
      "Validation loss: 20.471759796142578 RMSE: 4.524573\n",
      "Validation loss: 21.358972549438477 RMSE: 4.621577\n",
      "146 14 0.7874820828437805\n",
      "Validation loss: 15.719793319702148 RMSE: 3.9648194\n",
      "Validation loss: 25.903907775878906 RMSE: 5.089588\n",
      "Validation loss: 20.433908462524414 RMSE: 4.5203876\n",
      "Validation loss: 14.882606029510498 RMSE: 3.8577983\n",
      "150 0 0.4262377917766571\n",
      "Validation loss: 29.414628982543945 RMSE: 5.4235253\n",
      "Validation loss: 13.479362487792969 RMSE: 3.6714253\n",
      "Validation loss: 29.326655387878418 RMSE: 5.4154086\n",
      "153 2 0.627846896648407\n",
      "Validation loss: 16.925512313842773 RMSE: 4.1140623\n",
      "Validation loss: 16.097253799438477 RMSE: 4.0121384\n",
      "Validation loss: 17.359471321105957 RMSE: 4.1664696\n",
      "156 4 0.7789539098739624\n",
      "Validation loss: 21.83187484741211 RMSE: 4.672459\n",
      "Validation loss: 15.11837387084961 RMSE: 3.8882349\n",
      "Validation loss: 18.334249019622803 RMSE: 4.281851\n",
      "159 6 1.0347658395767212\n",
      "Validation loss: 14.24014139175415 RMSE: 3.7736113\n",
      "Validation loss: 22.89311695098877 RMSE: 4.784675\n",
      "Validation loss: 14.95332384109497 RMSE: 3.8669527\n",
      "162 8 0.8053984642028809\n",
      "Validation loss: 16.406773567199707 RMSE: 4.0505276\n",
      "Validation loss: 19.34063744544983 RMSE: 4.397799\n",
      "Validation loss: 16.88857936859131 RMSE: 4.1095715\n",
      "165 10 0.627569854259491\n",
      "Validation loss: 18.28403949737549 RMSE: 4.275984\n",
      "Validation loss: 15.650070190429688 RMSE: 3.9560168\n",
      "Validation loss: 15.918807029724121 RMSE: 3.989838\n",
      "168 12 0.9584507942199707\n",
      "Validation loss: 20.557082176208496 RMSE: 4.533992\n",
      "Validation loss: 13.266512870788574 RMSE: 3.6423225\n",
      "Validation loss: 17.543607711791992 RMSE: 4.188509\n",
      "171 14 0.5574182868003845\n",
      "Validation loss: 22.553373336791992 RMSE: 4.749039\n",
      "Validation loss: 12.547125816345215 RMSE: 3.5421922\n",
      "Validation loss: 12.395238637924194 RMSE: 3.5206873\n",
      "Validation loss: 16.2936429977417 RMSE: 4.0365386\n",
      "175 0 0.6230291128158569\n",
      "Validation loss: 16.57666778564453 RMSE: 4.0714455\n",
      "Validation loss: 17.280269622802734 RMSE: 4.1569543\n",
      "Validation loss: 17.352210998535156 RMSE: 4.1655984\n",
      "178 2 0.3875236511230469\n",
      "Validation loss: 16.426064491271973 RMSE: 4.0529084\n",
      "Validation loss: 20.97643280029297 RMSE: 4.5800037\n",
      "Validation loss: 22.316771984100342 RMSE: 4.724063\n",
      "181 4 0.7051790356636047\n",
      "Validation loss: 13.736549377441406 RMSE: 3.706285\n",
      "Validation loss: 17.713074684143066 RMSE: 4.2086906\n",
      "Validation loss: 19.754828453063965 RMSE: 4.4446406\n",
      "184 6 0.46972596645355225\n",
      "Validation loss: 16.683483600616455 RMSE: 4.084542\n",
      "Validation loss: 19.5999436378479 RMSE: 4.4271827\n",
      "Validation loss: 14.175233840942383 RMSE: 3.7650013\n",
      "187 8 0.35062864422798157\n",
      "Validation loss: 15.545342445373535 RMSE: 3.9427583\n",
      "Validation loss: 19.178382873535156 RMSE: 4.379313\n",
      "Validation loss: 17.801836013793945 RMSE: 4.219222\n",
      "190 10 1.039212942123413\n",
      "Validation loss: 11.833407402038574 RMSE: 3.4399722\n",
      "Validation loss: 18.451897621154785 RMSE: 4.295567\n",
      "Validation loss: 14.637327194213867 RMSE: 3.8258762\n",
      "193 12 0.38712167739868164\n",
      "Validation loss: 14.228255271911621 RMSE: 3.7720363\n",
      "Validation loss: 19.482933044433594 RMSE: 4.4139476\n",
      "Validation loss: 17.613755226135254 RMSE: 4.1968746\n",
      "196 14 0.7455273866653442\n",
      "Validation loss: 13.705286502838135 RMSE: 3.702065\n",
      "Validation loss: 16.568278312683105 RMSE: 4.070415\n",
      "Validation loss: 16.819422721862793 RMSE: 4.1011486\n",
      "Validation loss: 21.60828399658203 RMSE: 4.6484714\n",
      "Loaded trained model with success.\n",
      "Test loss: 8.685058650832909 Test RMSE: 2.9470425\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'freesolv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'target': ['expt']}}\n",
      "Running on: cuda:1\n",
      "641\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/641\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 27.66948699951172\n",
      "Validation loss: 45.19831657409668 RMSE: 6.722969\n",
      "Validation loss: 28.26388645172119 RMSE: 5.316379\n",
      "Validation loss: 20.61287498474121 RMSE: 4.5401406\n",
      "3 2 7.533885955810547\n",
      "Validation loss: 11.852331161499023 RMSE: 3.4427214\n",
      "Validation loss: 30.38568115234375 RMSE: 5.5123205\n",
      "Validation loss: 12.48204517364502 RMSE: 3.532994\n",
      "6 4 3.6897506713867188\n",
      "Validation loss: 32.94576072692871 RMSE: 5.73984\n",
      "Validation loss: 16.662150382995605 RMSE: 4.0819297\n",
      "Validation loss: 32.07618951797485 RMSE: 5.663584\n",
      "9 6 3.3982415199279785\n",
      "Validation loss: 24.952497959136963 RMSE: 4.995248\n",
      "Validation loss: 34.54914665222168 RMSE: 5.877852\n",
      "Validation loss: 14.276770114898682 RMSE: 3.7784612\n",
      "12 8 4.14119291305542\n",
      "Validation loss: 21.834043741226196 RMSE: 4.672691\n",
      "Validation loss: 12.961536407470703 RMSE: 3.600213\n",
      "Validation loss: 32.81834602355957 RMSE: 5.7287297\n",
      "15 10 1.8385905027389526\n",
      "Validation loss: 30.391433715820312 RMSE: 5.5128417\n",
      "Validation loss: 21.162219524383545 RMSE: 4.6002407\n",
      "Validation loss: 29.34179973602295 RMSE: 5.4168077\n",
      "18 12 2.2544357776641846\n",
      "Validation loss: 19.680435180664062 RMSE: 4.436263\n",
      "Validation loss: 39.00375747680664 RMSE: 6.2452984\n",
      "Validation loss: 34.98627710342407 RMSE: 5.9149203\n",
      "21 14 2.2839255332946777\n",
      "Validation loss: 32.63307189941406 RMSE: 5.7125363\n",
      "Validation loss: 27.19224739074707 RMSE: 5.214618\n",
      "Validation loss: 27.354835510253906 RMSE: 5.230185\n",
      "Validation loss: 22.455042362213135 RMSE: 4.738675\n",
      "25 0 1.7191731929779053\n",
      "Validation loss: 28.903276443481445 RMSE: 5.376177\n",
      "Validation loss: 39.581037521362305 RMSE: 6.2913465\n",
      "Validation loss: 26.008134841918945 RMSE: 5.0998173\n",
      "28 2 2.711254835128784\n",
      "Validation loss: 37.587074279785156 RMSE: 6.13083\n",
      "Validation loss: 23.718785285949707 RMSE: 4.870194\n",
      "Validation loss: 32.74789905548096 RMSE: 5.722579\n",
      "31 4 1.287571907043457\n",
      "Validation loss: 25.614938735961914 RMSE: 5.06112\n",
      "Validation loss: 34.80775451660156 RMSE: 5.89981\n",
      "Validation loss: 20.074678897857666 RMSE: 4.480478\n",
      "34 6 1.40042245388031\n",
      "Validation loss: 23.868509769439697 RMSE: 4.885541\n",
      "Validation loss: 18.88656997680664 RMSE: 4.3458686\n",
      "Validation loss: 16.083027124404907 RMSE: 4.010365\n",
      "37 8 1.4760210514068604\n",
      "Validation loss: 21.105295658111572 RMSE: 4.59405\n",
      "Validation loss: 27.319602966308594 RMSE: 5.226815\n",
      "Validation loss: 25.16619873046875 RMSE: 5.0165925\n",
      "40 10 1.5338594913482666\n",
      "Validation loss: 33.41750717163086 RMSE: 5.780788\n",
      "Validation loss: 25.02663516998291 RMSE: 5.0026627\n",
      "Validation loss: 19.58536386489868 RMSE: 4.4255357\n",
      "43 12 1.5205289125442505\n",
      "Validation loss: 28.596184730529785 RMSE: 5.34754\n",
      "Validation loss: 22.830467224121094 RMSE: 4.7781243\n",
      "Validation loss: 35.16274166107178 RMSE: 5.9298177\n",
      "46 14 1.4984132051467896\n",
      "Validation loss: 30.339665412902832 RMSE: 5.5081453\n",
      "Validation loss: 39.458024978637695 RMSE: 6.281563\n",
      "Validation loss: 24.33473491668701 RMSE: 4.933025\n",
      "Validation loss: 31.987550258636475 RMSE: 5.6557536\n",
      "50 0 2.0152626037597656\n",
      "Validation loss: 23.571338653564453 RMSE: 4.8550324\n",
      "Validation loss: 32.052611351013184 RMSE: 5.661503\n",
      "Validation loss: 27.64943218231201 RMSE: 5.2582726\n",
      "53 2 1.852744221687317\n",
      "Validation loss: 19.819339752197266 RMSE: 4.451892\n",
      "Validation loss: 32.94565391540527 RMSE: 5.7398305\n",
      "Validation loss: 27.940667152404785 RMSE: 5.285893\n",
      "56 4 1.4963581562042236\n",
      "Validation loss: 29.940241813659668 RMSE: 5.4717674\n",
      "Validation loss: 32.26158809661865 RMSE: 5.679929\n",
      "Validation loss: 19.254253387451172 RMSE: 4.387967\n",
      "59 6 1.191072702407837\n",
      "Validation loss: 32.953444480895996 RMSE: 5.7405086\n",
      "Validation loss: 14.05589246749878 RMSE: 3.749119\n",
      "Validation loss: 23.481689453125 RMSE: 4.8457904\n",
      "62 8 1.264323353767395\n",
      "Validation loss: 18.69131088256836 RMSE: 4.3233447\n",
      "Validation loss: 21.235952377319336 RMSE: 4.6082487\n",
      "Validation loss: 20.958821296691895 RMSE: 4.5780807\n",
      "65 10 1.1529972553253174\n",
      "Validation loss: 24.4378604888916 RMSE: 4.943466\n",
      "Validation loss: 17.9748592376709 RMSE: 4.239677\n",
      "Validation loss: 63.58621406555176 RMSE: 7.974097\n",
      "68 12 2.699221134185791\n",
      "Validation loss: 45.99924278259277 RMSE: 6.7822742\n",
      "Validation loss: 20.79317569732666 RMSE: 4.5599537\n",
      "Validation loss: 31.439522743225098 RMSE: 5.607096\n",
      "71 14 1.618948221206665\n",
      "Validation loss: 36.36630439758301 RMSE: 6.0304475\n",
      "Validation loss: 27.2453556060791 RMSE: 5.219708\n",
      "Validation loss: 35.13157653808594 RMSE: 5.9271894\n",
      "Validation loss: 48.260549545288086 RMSE: 6.946982\n",
      "75 0 2.4166574478149414\n",
      "Validation loss: 21.888137817382812 RMSE: 4.678476\n",
      "Validation loss: 23.2983341217041 RMSE: 4.8268347\n",
      "Validation loss: 26.04706382751465 RMSE: 5.1036325\n",
      "78 2 1.5296754837036133\n",
      "Validation loss: 28.118446350097656 RMSE: 5.3026834\n",
      "Validation loss: 47.03402900695801 RMSE: 6.8581357\n",
      "Validation loss: 30.124098777770996 RMSE: 5.4885426\n",
      "81 4 0.9801627397537231\n",
      "Validation loss: 27.072616577148438 RMSE: 5.203135\n",
      "Validation loss: 19.83037281036377 RMSE: 4.4531307\n",
      "Validation loss: 33.602688789367676 RMSE: 5.796783\n",
      "84 6 0.9926580190658569\n",
      "Validation loss: 23.812519073486328 RMSE: 4.8798075\n",
      "Validation loss: 28.986988067626953 RMSE: 5.3839564\n",
      "Validation loss: 21.03521203994751 RMSE: 4.586416\n",
      "87 8 1.0263147354125977\n",
      "Validation loss: 16.62031078338623 RMSE: 4.076802\n",
      "Validation loss: 13.64815902709961 RMSE: 3.6943414\n",
      "Validation loss: 21.851717948913574 RMSE: 4.674582\n",
      "90 10 0.6846572160720825\n",
      "Validation loss: 15.946003913879395 RMSE: 3.993245\n",
      "Validation loss: 30.241518020629883 RMSE: 5.499229\n",
      "Validation loss: 26.27779483795166 RMSE: 5.126187\n",
      "93 12 0.8123360276222229\n",
      "Validation loss: 28.32165241241455 RMSE: 5.3218093\n",
      "Validation loss: 18.89797353744507 RMSE: 4.34718\n",
      "Validation loss: 30.64119529724121 RMSE: 5.535449\n",
      "96 14 1.7576245069503784\n",
      "Validation loss: 24.37328338623047 RMSE: 4.9369307\n",
      "Validation loss: 21.257356643676758 RMSE: 4.61057\n",
      "Validation loss: 37.216901779174805 RMSE: 6.1005654\n",
      "Validation loss: 25.7479248046875 RMSE: 5.074241\n",
      "100 0 0.5452078580856323\n",
      "Validation loss: 20.143659591674805 RMSE: 4.4881687\n",
      "Validation loss: 27.41616439819336 RMSE: 5.2360444\n",
      "Validation loss: 29.91280460357666 RMSE: 5.46926\n",
      "103 2 0.9990251064300537\n",
      "Validation loss: 33.37292504310608 RMSE: 5.7769303\n",
      "Validation loss: 25.819052696228027 RMSE: 5.081245\n",
      "Validation loss: 26.075702667236328 RMSE: 5.106437\n",
      "106 4 0.5302952527999878\n",
      "Validation loss: 18.39317798614502 RMSE: 4.288727\n",
      "Validation loss: 29.92786979675293 RMSE: 5.4706373\n",
      "Validation loss: 26.53836441040039 RMSE: 5.15154\n",
      "109 6 0.6899223923683167\n",
      "Validation loss: 16.121809005737305 RMSE: 4.0151973\n",
      "Validation loss: 34.14009666442871 RMSE: 5.8429527\n",
      "Validation loss: 17.096043586730957 RMSE: 4.134736\n",
      "112 8 0.9335352778434753\n",
      "Validation loss: 24.272245407104492 RMSE: 4.9266872\n",
      "Validation loss: 15.341675758361816 RMSE: 3.9168453\n",
      "Validation loss: 24.239988327026367 RMSE: 4.923412\n",
      "115 10 0.7387637495994568\n",
      "Validation loss: 18.550642013549805 RMSE: 4.307046\n",
      "Validation loss: 28.152475357055664 RMSE: 5.30589\n",
      "Validation loss: 36.813724517822266 RMSE: 6.067432\n",
      "118 12 0.6635922789573669\n",
      "Validation loss: 19.01015281677246 RMSE: 4.360063\n",
      "Validation loss: 35.27551555633545 RMSE: 5.9393196\n",
      "Validation loss: 26.229053497314453 RMSE: 5.121431\n",
      "121 14 1.1482043266296387\n",
      "Validation loss: 17.20654582977295 RMSE: 4.1480775\n",
      "Validation loss: 36.27754306793213 RMSE: 6.0230837\n",
      "Validation loss: 18.269309997558594 RMSE: 4.2742615\n",
      "Validation loss: 27.650458335876465 RMSE: 5.2583704\n",
      "125 0 1.0608726739883423\n",
      "Validation loss: 17.344253540039062 RMSE: 4.1646433\n",
      "Validation loss: 26.445013999938965 RMSE: 5.142472\n",
      "Validation loss: 20.304341316223145 RMSE: 4.5060344\n",
      "128 2 2.2635598182678223\n",
      "Validation loss: 23.349648475646973 RMSE: 4.832147\n",
      "Validation loss: 18.70375680923462 RMSE: 4.324784\n",
      "Validation loss: 17.55840539932251 RMSE: 4.190275\n",
      "131 4 0.2843800187110901\n",
      "Validation loss: 17.412936210632324 RMSE: 4.172881\n",
      "Validation loss: 24.6350679397583 RMSE: 4.9633727\n",
      "Validation loss: 23.90162754058838 RMSE: 4.8889294\n",
      "134 6 0.8006866574287415\n",
      "Validation loss: 29.046263694763184 RMSE: 5.389458\n",
      "Validation loss: 17.078619480133057 RMSE: 4.1326284\n",
      "Validation loss: 26.37077236175537 RMSE: 5.1352477\n",
      "137 8 1.0289461612701416\n",
      "Validation loss: 21.651095390319824 RMSE: 4.6530733\n",
      "Validation loss: 21.042123317718506 RMSE: 4.587169\n",
      "Validation loss: 21.378188133239746 RMSE: 4.6236553\n",
      "140 10 0.7124748229980469\n",
      "Validation loss: 20.6542329788208 RMSE: 4.544693\n",
      "Validation loss: 21.92291831970215 RMSE: 4.682192\n",
      "Validation loss: 39.64560317993164 RMSE: 6.296475\n",
      "143 12 0.9367128610610962\n",
      "Validation loss: 21.47034740447998 RMSE: 4.6336107\n",
      "Validation loss: 19.90846347808838 RMSE: 4.46189\n",
      "Validation loss: 19.230887413024902 RMSE: 4.3853035\n",
      "146 14 0.6061428189277649\n",
      "Validation loss: 18.905698776245117 RMSE: 4.3480687\n",
      "Validation loss: 29.2234206199646 RMSE: 5.4058695\n",
      "Validation loss: 18.792753219604492 RMSE: 4.3350606\n",
      "Validation loss: 25.664607048034668 RMSE: 5.066025\n",
      "150 0 0.3901919722557068\n",
      "Validation loss: 22.44788360595703 RMSE: 4.73792\n",
      "Validation loss: 40.75528335571289 RMSE: 6.383987\n",
      "Validation loss: 14.216880798339844 RMSE: 3.7705278\n",
      "153 2 0.7759072780609131\n",
      "Validation loss: 20.536328315734863 RMSE: 4.5317025\n",
      "Validation loss: 17.9813289642334 RMSE: 4.2404394\n",
      "Validation loss: 20.415552139282227 RMSE: 4.518357\n",
      "156 4 0.4815126657485962\n",
      "Validation loss: 21.903862953186035 RMSE: 4.680156\n",
      "Validation loss: 17.23195743560791 RMSE: 4.1511393\n",
      "Validation loss: 20.241076946258545 RMSE: 4.499008\n",
      "159 6 0.5624263286590576\n",
      "Validation loss: 21.97574520111084 RMSE: 4.6878295\n",
      "Validation loss: 37.31646919250488 RMSE: 6.108721\n",
      "Validation loss: 16.39983081817627 RMSE: 4.04967\n",
      "162 8 0.8060392141342163\n",
      "Validation loss: 22.331650733947754 RMSE: 4.725638\n",
      "Validation loss: 19.163835525512695 RMSE: 4.3776517\n",
      "Validation loss: 18.27642822265625 RMSE: 4.2750936\n",
      "165 10 0.615753173828125\n",
      "Validation loss: 18.296586990356445 RMSE: 4.277451\n",
      "Validation loss: 17.38144588470459 RMSE: 4.169106\n",
      "Validation loss: 34.23026943206787 RMSE: 5.8506637\n",
      "168 12 0.4986189007759094\n",
      "Validation loss: 12.679065585136414 RMSE: 3.5607677\n",
      "Validation loss: 16.595397472381592 RMSE: 4.073745\n",
      "Validation loss: 21.77589988708496 RMSE: 4.6664653\n",
      "171 14 0.8759838938713074\n",
      "Validation loss: 22.7084903717041 RMSE: 4.7653427\n",
      "Validation loss: 22.524568557739258 RMSE: 4.7460055\n",
      "Validation loss: 18.548380851745605 RMSE: 4.306783\n",
      "Validation loss: 20.75340175628662 RMSE: 4.55559\n",
      "175 0 1.316979169845581\n",
      "Validation loss: 18.849123001098633 RMSE: 4.3415575\n",
      "Validation loss: 16.98701047897339 RMSE: 4.12153\n",
      "Validation loss: 19.466116428375244 RMSE: 4.412042\n",
      "178 2 0.8715676069259644\n",
      "Validation loss: 13.733234405517578 RMSE: 3.7058377\n",
      "Validation loss: 23.380617141723633 RMSE: 4.835351\n",
      "Validation loss: 14.294921875 RMSE: 3.7808626\n",
      "181 4 0.7552956342697144\n",
      "Validation loss: 21.32118558883667 RMSE: 4.6174865\n",
      "Validation loss: 17.936561584472656 RMSE: 4.2351584\n",
      "Validation loss: 28.422761917114258 RMSE: 5.3313003\n",
      "184 6 0.6182938814163208\n",
      "Validation loss: 16.507582664489746 RMSE: 4.062952\n",
      "Validation loss: 22.980379104614258 RMSE: 4.7937856\n",
      "Validation loss: 17.231016159057617 RMSE: 4.1510262\n",
      "187 8 0.47600769996643066\n",
      "Validation loss: 20.269258499145508 RMSE: 4.502139\n",
      "Validation loss: 23.823555946350098 RMSE: 4.880938\n",
      "Validation loss: 19.04721164703369 RMSE: 4.364311\n",
      "190 10 0.4324260950088501\n",
      "Validation loss: 19.426547050476074 RMSE: 4.4075556\n",
      "Validation loss: 20.77111291885376 RMSE: 4.5575337\n",
      "Validation loss: 17.789047718048096 RMSE: 4.217706\n",
      "193 12 0.6414130330085754\n",
      "Validation loss: 16.960598468780518 RMSE: 4.1183248\n",
      "Validation loss: 19.450127601623535 RMSE: 4.41023\n",
      "Validation loss: 22.547117233276367 RMSE: 4.7483807\n",
      "196 14 0.4666677713394165\n",
      "Validation loss: 22.153614044189453 RMSE: 4.706763\n",
      "Validation loss: 22.051859855651855 RMSE: 4.6959405\n",
      "Validation loss: 17.66187286376953 RMSE: 4.2026033\n",
      "Validation loss: 20.80805206298828 RMSE: 4.5615845\n",
      "Loaded trained model with success.\n",
      "Test loss: 15.497265874422514 Test RMSE: 3.9366567\n"
     ]
    }
   ],
   "source": [
    "seeds = list(range(777,782))\n",
    "# datasets = [\"bace\",  \"bbbp\", \"tox21\", \"toxcast\", \"sider\",  ]\n",
    "datasets = [\"freeSolv\" ]\n",
    "\n",
    "for dataset in datasets:\n",
    "    for seed in seeds: \n",
    "        !python finetuneReconAlpha2.py \\\n",
    "            --task_name {dataset} \\\n",
    "            --splitting scaffold \\\n",
    "            --mask_rate 0.2 \\\n",
    "            --seed {seed} \\\n",
    "            --random_masking 1 \\\n",
    "            --alpha 0.1 \\\n",
    "            --mask_edge 1 \\\n",
    "            --gpu cuda:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6764b07a-c44b-44d3-ab6b-161100c0d53b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 751, 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'target': ['measured log solubility in mols per litre']}}\n",
      "Running on: cuda:0\n",
      "1127\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1127\n",
      "Generating scaffold 1000/1127\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "tensor([[ 0.0806, -0.0410, -0.0872,  ..., -0.0789, -0.0887, -0.1107],\n",
      "        [ 0.0313,  0.0164,  0.1077,  ..., -0.0785,  0.1171,  0.1046],\n",
      "        [-0.0002, -0.0291, -0.0762,  ...,  0.0110,  0.0630,  0.0511],\n",
      "        ...,\n",
      "        [ 0.0313,  0.0164,  0.1077,  ..., -0.0785,  0.1171,  0.1046],\n",
      "        [-0.0175,  0.1190, -0.0096,  ...,  0.0821,  0.0621,  0.0488],\n",
      "        [ 0.0313,  0.0164,  0.1077,  ..., -0.0785,  0.1171,  0.1046]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "0 0 8.955981254577637\n",
      "tensor([[ 0.0312,  0.0165,  0.1078,  ..., -0.0786,  0.1172,  0.1047],\n",
      "        [ 0.0312,  0.0165,  0.1078,  ..., -0.0786,  0.1172,  0.1047],\n",
      "        [ 0.0312,  0.0165,  0.1078,  ..., -0.0786,  0.1172,  0.1047],\n",
      "        ...,\n",
      "        [ 0.0312,  0.0165,  0.1078,  ..., -0.0786,  0.1172,  0.1047],\n",
      "        [ 0.0312,  0.0165,  0.1078,  ..., -0.0786,  0.1172,  0.1047],\n",
      "        [ 0.0312,  0.0165,  0.1078,  ..., -0.0786,  0.1172,  0.1047]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0004, -0.0289, -0.0764,  ...,  0.0108,  0.0629,  0.0509],\n",
      "        [-0.0004, -0.0289, -0.0764,  ...,  0.0108,  0.0629,  0.0509],\n",
      "        [-0.0004, -0.0289, -0.0764,  ...,  0.0108,  0.0629,  0.0509],\n",
      "        ...,\n",
      "        [ 0.0311,  0.0166,  0.1079,  ..., -0.0787,  0.1173,  0.1048],\n",
      "        [ 0.0311,  0.0166,  0.1079,  ..., -0.0787,  0.1173,  0.1048],\n",
      "        [ 0.0311,  0.0166,  0.1079,  ..., -0.0787,  0.1173,  0.1048]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0004, -0.0288, -0.0764,  ...,  0.0108,  0.0629,  0.0509],\n",
      "        [-0.0004, -0.0288, -0.0764,  ...,  0.0108,  0.0629,  0.0509],\n",
      "        [ 0.0311,  0.0167,  0.1079,  ..., -0.0788,  0.1174,  0.1048],\n",
      "        ...,\n",
      "        [ 0.0187, -0.0968, -0.0305,  ...,  0.0381, -0.0655, -0.0279],\n",
      "        [ 0.0311,  0.0167,  0.1079,  ..., -0.0788,  0.1174,  0.1048],\n",
      "        [ 0.0311,  0.0167,  0.1079,  ..., -0.0788,  0.1174,  0.1048]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0310,  0.0168,  0.1079,  ..., -0.0789,  0.1174,  0.1049],\n",
      "        [-0.0003, -0.0287, -0.0764,  ...,  0.0107,  0.0629,  0.0509],\n",
      "        [-0.0003, -0.0287, -0.0764,  ...,  0.0107,  0.0629,  0.0509],\n",
      "        ...,\n",
      "        [ 0.0310,  0.0168,  0.1079,  ..., -0.0789,  0.1174,  0.1049],\n",
      "        [ 0.0310,  0.0168,  0.1079,  ..., -0.0789,  0.1174,  0.1049],\n",
      "        [ 0.0310,  0.0168,  0.1079,  ..., -0.0789,  0.1174,  0.1049]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0309,  0.0168,  0.1080,  ..., -0.0789,  0.1175,  0.1050],\n",
      "        [ 0.0309,  0.0168,  0.1080,  ..., -0.0789,  0.1175,  0.1050],\n",
      "        [-0.0961, -0.0527,  0.0569,  ...,  0.0218, -0.0656,  0.0982],\n",
      "        ...,\n",
      "        [ 0.0309,  0.0168,  0.1080,  ..., -0.0789,  0.1175,  0.1050],\n",
      "        [-0.0961, -0.0527,  0.0569,  ...,  0.0218, -0.0656,  0.0982],\n",
      "        [ 0.0065, -0.1107,  0.0619,  ...,  0.0173,  0.0921, -0.0094]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0065, -0.1107,  0.0619,  ...,  0.0174,  0.0921, -0.0095],\n",
      "        [ 0.0065, -0.1107,  0.0619,  ...,  0.0174,  0.0921, -0.0095],\n",
      "        [ 0.0309,  0.0169,  0.1080,  ..., -0.0790,  0.1176,  0.1050],\n",
      "        ...,\n",
      "        [-0.0961, -0.0528,  0.0569,  ...,  0.0219, -0.0655,  0.0981],\n",
      "        [ 0.0309,  0.0169,  0.1080,  ..., -0.0790,  0.1176,  0.1050],\n",
      "        [ 0.0065, -0.1107,  0.0619,  ...,  0.0174,  0.0921, -0.0095]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0002, -0.0285, -0.0763,  ...,  0.0108,  0.0630,  0.0507],\n",
      "        [-0.0002, -0.0285, -0.0763,  ...,  0.0108,  0.0630,  0.0507],\n",
      "        [ 0.0309,  0.0169,  0.1081,  ..., -0.0791,  0.1177,  0.1051],\n",
      "        ...,\n",
      "        [ 0.0309,  0.0169,  0.1081,  ..., -0.0791,  0.1177,  0.1051],\n",
      "        [ 0.0309,  0.0169,  0.1081,  ..., -0.0791,  0.1177,  0.1051],\n",
      "        [-0.0123,  0.1087, -0.0120,  ...,  0.0790,  0.0517, -0.0861]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0961, -0.0528,  0.0569,  ...,  0.0220, -0.0653,  0.0979],\n",
      "        [-0.0961, -0.0528,  0.0569,  ...,  0.0220, -0.0653,  0.0979],\n",
      "        [ 0.0804, -0.0412, -0.0873,  ..., -0.0789, -0.0891, -0.1105],\n",
      "        ...,\n",
      "        [ 0.0309,  0.0170,  0.1081,  ..., -0.0791,  0.1178,  0.1052],\n",
      "        [ 0.0309,  0.0170,  0.1081,  ..., -0.0791,  0.1178,  0.1052],\n",
      "        [-0.0961, -0.0528,  0.0569,  ...,  0.0220, -0.0653,  0.0979]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0002, -0.0284, -0.0764,  ...,  0.0108,  0.0631,  0.0506],\n",
      "        [-0.0002, -0.0284, -0.0764,  ...,  0.0108,  0.0631,  0.0506],\n",
      "        [ 0.0309,  0.0170,  0.1082,  ..., -0.0792,  0.1179,  0.1052],\n",
      "        ...,\n",
      "        [ 0.0309,  0.0170,  0.1082,  ..., -0.0792,  0.1179,  0.1052],\n",
      "        [ 0.0309,  0.0170,  0.1082,  ..., -0.0792,  0.1179,  0.1052],\n",
      "        [ 0.0309,  0.0170,  0.1082,  ..., -0.0792,  0.1179,  0.1052]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0310,  0.0170,  0.1083,  ..., -0.0792,  0.1179,  0.1053],\n",
      "        [-0.0002, -0.0284, -0.0765,  ...,  0.0108,  0.0631,  0.0505],\n",
      "        [-0.0002, -0.0284, -0.0765,  ...,  0.0108,  0.0631,  0.0505],\n",
      "        ...,\n",
      "        [ 0.0310,  0.0170,  0.1083,  ..., -0.0792,  0.1179,  0.1053],\n",
      "        [ 0.0310,  0.0170,  0.1083,  ..., -0.0792,  0.1179,  0.1053],\n",
      "        [ 0.0310,  0.0170,  0.1083,  ..., -0.0792,  0.1179,  0.1053]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0310,  0.0171,  0.1083,  ..., -0.0793,  0.1179,  0.1054],\n",
      "        [ 0.0070, -0.1110,  0.0617,  ...,  0.0178,  0.0925, -0.0099],\n",
      "        [ 0.0310,  0.0171,  0.1083,  ..., -0.0793,  0.1179,  0.1054],\n",
      "        ...,\n",
      "        [ 0.0310,  0.0171,  0.1083,  ..., -0.0793,  0.1179,  0.1054],\n",
      "        [ 0.0310,  0.0171,  0.1083,  ..., -0.0793,  0.1179,  0.1054],\n",
      "        [-0.0961, -0.0529,  0.0568,  ...,  0.0223, -0.0651,  0.0977]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0309,  0.0171,  0.1084,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1084,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [-0.0961, -0.0529,  0.0568,  ...,  0.0223, -0.0650,  0.0976],\n",
      "        ...,\n",
      "        [ 0.0309,  0.0171,  0.1084,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1084,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1084,  ..., -0.0794,  0.1179,  0.1054]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0961, -0.0529,  0.0568,  ...,  0.0224, -0.0649,  0.0975],\n",
      "        [-0.0003, -0.0284, -0.0766,  ...,  0.0107,  0.0633,  0.0504],\n",
      "        [-0.0003, -0.0284, -0.0766,  ...,  0.0107,  0.0633,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0309,  0.0171,  0.1085,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [ 0.0071, -0.1112,  0.0617,  ...,  0.0179,  0.0926, -0.0100],\n",
      "        [ 0.0309,  0.0171,  0.1085,  ..., -0.0794,  0.1179,  0.1054]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0309,  0.0171,  0.1085,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1085,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1085,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        ...,\n",
      "        [ 0.0071, -0.1112,  0.0616,  ...,  0.0180,  0.0927, -0.0100],\n",
      "        [ 0.0309,  0.0171,  0.1085,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1085,  ..., -0.0794,  0.1179,  0.1054]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0309,  0.0171,  0.1086,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1086,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1086,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        ...,\n",
      "        [ 0.0309,  0.0171,  0.1086,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [-0.0962, -0.0529,  0.0568,  ...,  0.0225, -0.0647,  0.0974],\n",
      "        [-0.0127,  0.1084, -0.0120,  ...,  0.0788,  0.0512, -0.0857]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0309,  0.0171,  0.1087,  ..., -0.0795,  0.1179,  0.1054],\n",
      "        [-0.0002, -0.0284, -0.0766,  ...,  0.0107,  0.0632,  0.0503],\n",
      "        [-0.0002, -0.0284, -0.0766,  ...,  0.0107,  0.0632,  0.0503],\n",
      "        ...,\n",
      "        [ 0.0309,  0.0171,  0.1087,  ..., -0.0795,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1087,  ..., -0.0795,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1087,  ..., -0.0795,  0.1179,  0.1054]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 3.0917e-02,  1.7134e-02,  1.0878e-01,  ..., -7.9471e-02,\n",
      "          1.1795e-01,  1.0532e-01],\n",
      "        [-1.1599e-04, -2.8463e-02, -7.6550e-02,  ...,  1.0742e-02,\n",
      "          6.3165e-02,  5.0226e-02],\n",
      "        [-1.1599e-04, -2.8463e-02, -7.6550e-02,  ...,  1.0742e-02,\n",
      "          6.3165e-02,  5.0226e-02],\n",
      "        ...,\n",
      "        [ 3.0917e-02,  1.7134e-02,  1.0878e-01,  ..., -7.9471e-02,\n",
      "          1.1795e-01,  1.0532e-01],\n",
      "        [ 3.0917e-02,  1.7134e-02,  1.0878e-01,  ..., -7.9471e-02,\n",
      "          1.1795e-01,  1.0532e-01],\n",
      "        [ 3.0917e-02,  1.7134e-02,  1.0878e-01,  ..., -7.9471e-02,\n",
      "          1.1795e-01,  1.0532e-01]], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0309,  0.0172,  0.1088,  ..., -0.0795,  0.1180,  0.1053],\n",
      "        [ 0.0309,  0.0172,  0.1088,  ..., -0.0795,  0.1180,  0.1053],\n",
      "        [ 0.0309,  0.0172,  0.1088,  ..., -0.0795,  0.1180,  0.1053],\n",
      "        ...,\n",
      "        [ 0.0074, -0.1113,  0.0618,  ...,  0.0180,  0.0929, -0.0100],\n",
      "        [ 0.0309,  0.0172,  0.1088,  ..., -0.0795,  0.1180,  0.1053],\n",
      "        [-0.0964, -0.0527,  0.0568,  ...,  0.0224, -0.0647,  0.0975]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-9.6424e-02, -5.2667e-02,  5.6764e-02,  ...,  2.2343e-02,\n",
      "         -6.4659e-02,  9.7490e-02],\n",
      "        [ 3.0807e-02,  1.7243e-02,  1.0880e-01,  ..., -7.9564e-02,\n",
      "          1.1803e-01,  1.0522e-01],\n",
      "        [-1.7022e-05, -2.8596e-02, -7.6470e-02,  ...,  1.0681e-02,\n",
      "          6.3049e-02,  5.0292e-02],\n",
      "        ...,\n",
      "        [ 3.0807e-02,  1.7243e-02,  1.0880e-01,  ..., -7.9564e-02,\n",
      "          1.1803e-01,  1.0522e-01],\n",
      "        [-1.7267e-02,  1.1858e-01, -1.0125e-02,  ...,  8.2536e-02,\n",
      "          6.1876e-02,  4.8307e-02],\n",
      "        [ 3.0807e-02,  1.7243e-02,  1.0880e-01,  ..., -7.9564e-02,\n",
      "          1.1803e-01,  1.0522e-01]], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 3.0753e-02,  1.7299e-02,  1.0883e-01,  ..., -7.9583e-02,\n",
      "          1.1807e-01,  1.0516e-01],\n",
      "        [ 3.0753e-02,  1.7299e-02,  1.0883e-01,  ..., -7.9583e-02,\n",
      "          1.1807e-01,  1.0516e-01],\n",
      "        [ 4.1295e-05, -2.8627e-02, -7.6411e-02,  ...,  1.0639e-02,\n",
      "          6.3006e-02,  5.0348e-02],\n",
      "        ...,\n",
      "        [ 3.0753e-02,  1.7299e-02,  1.0883e-01,  ..., -7.9583e-02,\n",
      "          1.1807e-01,  1.0516e-01],\n",
      "        [-1.2426e-02,  1.0806e-01, -1.2240e-02,  ...,  7.9107e-02,\n",
      "          5.1456e-02, -8.5975e-02],\n",
      "        [ 3.0753e-02,  1.7299e-02,  1.0883e-01,  ..., -7.9583e-02,\n",
      "          1.1807e-01,  1.0516e-01]], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0307,  0.0173,  0.1089,  ..., -0.0796,  0.1181,  0.1051],\n",
      "        [ 0.0307,  0.0173,  0.1089,  ..., -0.0796,  0.1181,  0.1051],\n",
      "        [ 0.0307,  0.0173,  0.1089,  ..., -0.0796,  0.1181,  0.1051],\n",
      "        ...,\n",
      "        [ 0.0076, -0.1114,  0.0619,  ...,  0.0181,  0.0930, -0.0100],\n",
      "        [ 0.0307,  0.0173,  0.1089,  ..., -0.0796,  0.1181,  0.1051],\n",
      "        [ 0.0307,  0.0173,  0.1089,  ..., -0.0796,  0.1181,  0.1051]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0307,  0.0174,  0.1089,  ..., -0.0796,  0.1181,  0.1051],\n",
      "        [ 0.0808, -0.0411, -0.0881,  ..., -0.0790, -0.0893, -0.1108],\n",
      "        [ 0.0076, -0.1113,  0.0619,  ...,  0.0181,  0.0930, -0.0100],\n",
      "        ...,\n",
      "        [ 0.0307,  0.0174,  0.1089,  ..., -0.0796,  0.1181,  0.1051],\n",
      "        [-0.0966, -0.0525,  0.0567,  ...,  0.0222, -0.0646,  0.0975],\n",
      "        [-0.0966, -0.0525,  0.0567,  ...,  0.0222, -0.0646,  0.0975]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0001, -0.0288, -0.0764,  ...,  0.0106,  0.0630,  0.0504],\n",
      "        [ 0.0898,  0.0321,  0.0691,  ...,  0.0426, -0.0070,  0.0773],\n",
      "        [ 0.0001, -0.0288, -0.0764,  ...,  0.0106,  0.0630,  0.0504],\n",
      "        ...,\n",
      "        [-0.0967, -0.0524,  0.0567,  ...,  0.0222, -0.0646,  0.0975],\n",
      "        [ 0.0307,  0.0174,  0.1089,  ..., -0.0797,  0.1182,  0.1051],\n",
      "        [-0.0967, -0.0524,  0.0567,  ...,  0.0222, -0.0646,  0.0975]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0968, -0.0523,  0.0567,  ...,  0.0222, -0.0646,  0.0974],\n",
      "        [ 0.0001, -0.0288, -0.0764,  ...,  0.0106,  0.0630,  0.0504],\n",
      "        [ 0.0001, -0.0288, -0.0764,  ...,  0.0106,  0.0630,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0307,  0.0174,  0.1090,  ..., -0.0797,  0.1182,  0.1052],\n",
      "        [-0.0968, -0.0523,  0.0567,  ...,  0.0222, -0.0646,  0.0974],\n",
      "        [ 0.0307,  0.0174,  0.1090,  ..., -0.0797,  0.1182,  0.1052]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0306,  0.0174,  0.1090,  ..., -0.0798,  0.1182,  0.1052],\n",
      "        [ 0.0001, -0.0289, -0.0764,  ...,  0.0106,  0.0630,  0.0504],\n",
      "        [ 0.0001, -0.0289, -0.0764,  ...,  0.0106,  0.0630,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0306,  0.0174,  0.1090,  ..., -0.0798,  0.1182,  0.1052],\n",
      "        [-0.0968, -0.0523,  0.0566,  ...,  0.0222, -0.0646,  0.0974],\n",
      "        [-0.0122,  0.1078, -0.0123,  ...,  0.0793,  0.0515, -0.0860]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0122,  0.1078, -0.0123,  ...,  0.0793,  0.0516, -0.0860],\n",
      "        [ 0.0306,  0.0174,  0.1091,  ..., -0.0798,  0.1182,  0.1053],\n",
      "        [ 0.0306,  0.0174,  0.1091,  ..., -0.0798,  0.1182,  0.1053],\n",
      "        ...,\n",
      "        [ 0.0306,  0.0174,  0.1091,  ..., -0.0798,  0.1182,  0.1053],\n",
      "        [ 0.0306,  0.0174,  0.1091,  ..., -0.0798,  0.1182,  0.1053],\n",
      "        [ 0.0306,  0.0174,  0.1091,  ..., -0.0798,  0.1182,  0.1053]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0306,  0.0174,  0.1091,  ..., -0.0799,  0.1182,  0.1053],\n",
      "        [-0.0121,  0.1078, -0.0122,  ...,  0.0793,  0.0516, -0.0860],\n",
      "        [ 0.0306,  0.0174,  0.1091,  ..., -0.0799,  0.1182,  0.1053],\n",
      "        ...,\n",
      "        [ 0.0306,  0.0174,  0.1091,  ..., -0.0799,  0.1182,  0.1053],\n",
      "        [ 0.0306,  0.0174,  0.1091,  ..., -0.0799,  0.1182,  0.1053],\n",
      "        [-0.0170,  0.1189, -0.0102,  ...,  0.0827,  0.0622,  0.0487]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0121,  0.1077, -0.0122,  ...,  0.0793,  0.0516, -0.0860],\n",
      "        [ 0.0305,  0.0174,  0.1092,  ..., -0.0799,  0.1182,  0.1053],\n",
      "        [ 0.0305,  0.0174,  0.1092,  ..., -0.0799,  0.1182,  0.1053],\n",
      "        ...,\n",
      "        [ 0.0305,  0.0174,  0.1092,  ..., -0.0799,  0.1182,  0.1053],\n",
      "        [ 0.0001, -0.0291, -0.0765,  ...,  0.0107,  0.0630,  0.0504],\n",
      "        [ 0.0001, -0.0291, -0.0765,  ...,  0.0107,  0.0630,  0.0504]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Validation loss: 2.2496231530619935 RMSE: 1.4998744\n",
      "tensor([[ 0.0305,  0.0174,  0.1092,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [-0.0970, -0.0521,  0.0565,  ...,  0.0224, -0.0646,  0.0973],\n",
      "        [ 0.0001, -0.0292, -0.0766,  ...,  0.0107,  0.0630,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0305,  0.0174,  0.1092,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [ 0.0305,  0.0174,  0.1092,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [ 0.0305,  0.0174,  0.1092,  ..., -0.0800,  0.1182,  0.1054]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0002, -0.0292, -0.0766,  ...,  0.0108,  0.0630,  0.0504],\n",
      "        [ 0.0305,  0.0174,  0.1092,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [ 0.0305,  0.0174,  0.1092,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        ...,\n",
      "        [ 0.0305,  0.0174,  0.1092,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [-0.0971, -0.0521,  0.0565,  ...,  0.0224, -0.0646,  0.0972],\n",
      "        [ 0.0078, -0.1111,  0.0621,  ...,  0.0182,  0.0933, -0.0101]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0971, -0.0521,  0.0565,  ...,  0.0224, -0.0647,  0.0972],\n",
      "        [ 0.0002, -0.0292, -0.0766,  ...,  0.0108,  0.0630,  0.0504],\n",
      "        [ 0.0002, -0.0292, -0.0766,  ...,  0.0108,  0.0630,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0305,  0.0174,  0.1093,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [ 0.0305,  0.0174,  0.1093,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [ 0.0078, -0.1111,  0.0621,  ...,  0.0182,  0.0934, -0.0101]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0304,  0.0174,  0.1093,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [ 0.0304,  0.0174,  0.1093,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [ 0.0002, -0.0293, -0.0766,  ...,  0.0108,  0.0630,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0304,  0.0174,  0.1093,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [ 0.0304,  0.0174,  0.1093,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [ 0.0304,  0.0174,  0.1093,  ..., -0.0800,  0.1182,  0.1054]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [-0.0120,  0.1077, -0.0121,  ...,  0.0793,  0.0515, -0.0860],\n",
      "        ...,\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [ 0.0809, -0.0410, -0.0884,  ..., -0.0791, -0.0894, -0.1111],\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [ 0.0003, -0.0293, -0.0766,  ...,  0.0108,  0.0631,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [-0.0120,  0.1076, -0.0121,  ...,  0.0793,  0.0515, -0.0860]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        ...,\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0304,  0.0174,  0.1095,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        [ 0.0304,  0.0174,  0.1095,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        [ 0.0304,  0.0174,  0.1095,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        ...,\n",
      "        [-0.0974, -0.0521,  0.0564,  ...,  0.0225, -0.0648,  0.0970],\n",
      "        [ 0.0233,  0.0582, -0.1101,  ...,  0.0704,  0.0737,  0.0701],\n",
      "        [-0.0974, -0.0521,  0.0564,  ...,  0.0225, -0.0648,  0.0970]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0303,  0.0174,  0.1095,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        [ 0.0303,  0.0174,  0.1095,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        [ 0.0003, -0.0294, -0.0767,  ...,  0.0108,  0.0631,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0303,  0.0174,  0.1095,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        [ 0.0303,  0.0174,  0.1095,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        [-0.0974, -0.0522,  0.0564,  ...,  0.0225, -0.0649,  0.0970]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0003, -0.0295, -0.0767,  ...,  0.0108,  0.0631,  0.0503],\n",
      "        [ 0.0003, -0.0295, -0.0767,  ...,  0.0108,  0.0631,  0.0503],\n",
      "        [ 0.0303,  0.0174,  0.1096,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        ...,\n",
      "        [ 0.0303,  0.0174,  0.1096,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        [ 0.0303,  0.0174,  0.1096,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        [ 0.0303,  0.0174,  0.1096,  ..., -0.0801,  0.1182,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0303,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1055],\n",
      "        [ 0.0003, -0.0295, -0.0767,  ...,  0.0108,  0.0631,  0.0503],\n",
      "        [ 0.0003, -0.0295, -0.0767,  ...,  0.0108,  0.0631,  0.0503],\n",
      "        ...,\n",
      "        [-0.0167,  0.1191, -0.0102,  ...,  0.0827,  0.0622,  0.0491],\n",
      "        [-0.0167,  0.1191, -0.0102,  ...,  0.0827,  0.0622,  0.0491],\n",
      "        [ 0.0303,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0302,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1055],\n",
      "        [ 0.0004, -0.0296, -0.0768,  ...,  0.0108,  0.0631,  0.0503],\n",
      "        [ 0.0004, -0.0296, -0.0768,  ...,  0.0108,  0.0631,  0.0503],\n",
      "        ...,\n",
      "        [ 0.0302,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1055],\n",
      "        [ 0.0302,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1055],\n",
      "        [ 0.0302,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0079, -0.1110,  0.0623,  ...,  0.0182,  0.0935, -0.0101],\n",
      "        [-0.0976, -0.0523,  0.0563,  ...,  0.0225, -0.0650,  0.0970],\n",
      "        [ 0.0302,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0302,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0302,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0302,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0302,  0.0174,  0.1097,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0302,  0.0174,  0.1097,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0302,  0.0174,  0.1097,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        ...,\n",
      "        [-0.0977, -0.0523,  0.0563,  ...,  0.0225, -0.0649,  0.0970],\n",
      "        [ 0.0302,  0.0174,  0.1097,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0302,  0.0174,  0.1097,  ..., -0.0802,  0.1182,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [-0.0977, -0.0524,  0.0563,  ...,  0.0225, -0.0649,  0.0969],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0118,  0.1075, -0.0120,  ...,  0.0793,  0.0513, -0.0859],\n",
      "        [-0.0118,  0.1075, -0.0120,  ...,  0.0793,  0.0513, -0.0859],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0803,  0.1182,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0803,  0.1182,  0.1056],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0803,  0.1182,  0.1056],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0803,  0.1182,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0003, -0.0297, -0.0768,  ...,  0.0108,  0.0631,  0.0504],\n",
      "        [ 0.0003, -0.0297, -0.0768,  ...,  0.0108,  0.0631,  0.0504],\n",
      "        [ 0.0003, -0.0297, -0.0768,  ...,  0.0108,  0.0631,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0082, -0.1109,  0.0626,  ...,  0.0178,  0.0937, -0.0099],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0803,  0.1181,  0.1056],\n",
      "        [ 0.0813, -0.0407, -0.0882,  ..., -0.0792, -0.0893, -0.1111]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0300,  0.0174,  0.1096,  ..., -0.0804,  0.1181,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0804,  0.1181,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0804,  0.1181,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0804,  0.1181,  0.1056],\n",
      "        [ 0.0082, -0.1109,  0.0626,  ...,  0.0178,  0.0938, -0.0099],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0804,  0.1181,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0002, -0.0298, -0.0769,  ...,  0.0107,  0.0631,  0.0504],\n",
      "        [ 0.0002, -0.0298, -0.0769,  ...,  0.0107,  0.0631,  0.0504],\n",
      "        [ 0.0002, -0.0298, -0.0769,  ...,  0.0107,  0.0631,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0804,  0.1181,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0804,  0.1181,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0804,  0.1181,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0300,  0.0174,  0.1096,  ..., -0.0805,  0.1181,  0.1055],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0805,  0.1181,  0.1055],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0805,  0.1181,  0.1055],\n",
      "        ...,\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0805,  0.1181,  0.1055],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0805,  0.1181,  0.1055],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0805,  0.1181,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0174,  0.1097,  ..., -0.0805,  0.1181,  0.1055],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0805,  0.1181,  0.1055],\n",
      "        [ 0.0001, -0.0298, -0.0769,  ...,  0.0107,  0.0631,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0805,  0.1181,  0.1055],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0805,  0.1181,  0.1055],\n",
      "        [ 0.0900,  0.0317,  0.0689,  ...,  0.0427, -0.0067,  0.0771]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "1 21 1.6086289882659912\n",
      "tensor([[ 0.0299,  0.0174,  0.1097,  ..., -0.0806,  0.1181,  0.1055],\n",
      "        [ 0.0083, -0.1108,  0.0627,  ...,  0.0176,  0.0939, -0.0098],\n",
      "        [ 0.0083, -0.1108,  0.0627,  ...,  0.0176,  0.0939, -0.0098],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0806,  0.1181,  0.1055],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0806,  0.1181,  0.1055],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0806,  0.1181,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0174,  0.1097,  ..., -0.0806,  0.1181,  0.1056],\n",
      "        [-0.0983, -0.0523,  0.0559,  ...,  0.0224, -0.0645,  0.0968],\n",
      "        [-0.0983, -0.0523,  0.0559,  ...,  0.0224, -0.0645,  0.0968],\n",
      "        ...,\n",
      "        [ 0.0083, -0.1107,  0.0627,  ...,  0.0175,  0.0939, -0.0097],\n",
      "        [-0.0983, -0.0523,  0.0559,  ...,  0.0224, -0.0645,  0.0968],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0806,  0.1181,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0174,  0.1097,  ..., -0.0807,  0.1182,  0.1056],\n",
      "        [ 0.0002, -0.0300, -0.0769,  ...,  0.0107,  0.0631,  0.0505],\n",
      "        [ 0.0002, -0.0300, -0.0769,  ...,  0.0107,  0.0631,  0.0505],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0807,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0807,  0.1182,  0.1056],\n",
      "        [ 0.0901,  0.0316,  0.0689,  ...,  0.0427, -0.0068,  0.0770]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0174,  0.1097,  ..., -0.0807,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0807,  0.1182,  0.1056],\n",
      "        [ 0.0003, -0.0300, -0.0769,  ...,  0.0106,  0.0631,  0.0506],\n",
      "        ...,\n",
      "        [ 0.0901,  0.0316,  0.0689,  ...,  0.0427, -0.0069,  0.0771],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0807,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0807,  0.1182,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0174,  0.1097,  ..., -0.0808,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0808,  0.1182,  0.1056],\n",
      "        [-0.0116,  0.1073, -0.0120,  ...,  0.0794,  0.0513, -0.0860],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0808,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0808,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0808,  0.1182,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0986, -0.0523,  0.0560,  ...,  0.0223, -0.0644,  0.0966],\n",
      "        [ 0.0299,  0.0175,  0.1097,  ..., -0.0808,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0175,  0.1097,  ..., -0.0808,  0.1182,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0175,  0.1097,  ..., -0.0808,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0175,  0.1097,  ..., -0.0808,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0175,  0.1097,  ..., -0.0808,  0.1182,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0082, -0.1106,  0.0628,  ...,  0.0174,  0.0939, -0.0098],\n",
      "        [-0.0987, -0.0523,  0.0560,  ...,  0.0223, -0.0644,  0.0966],\n",
      "        [ 0.0004, -0.0301, -0.0769,  ...,  0.0105,  0.0631,  0.0508],\n",
      "        ...,\n",
      "        [ 0.0004, -0.0301, -0.0769,  ...,  0.0105,  0.0631,  0.0508],\n",
      "        [ 0.0004, -0.0301, -0.0769,  ...,  0.0105,  0.0631,  0.0508],\n",
      "        [ 0.0004, -0.0301, -0.0769,  ...,  0.0105,  0.0631,  0.0508]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Validation loss: 17.010034324848547 RMSE: 4.1243224\n",
      "tensor([[ 0.0004, -0.0302, -0.0769,  ...,  0.0105,  0.0631,  0.0508],\n",
      "        [-0.0115,  0.1073, -0.0120,  ...,  0.0794,  0.0512, -0.0860],\n",
      "        [ 0.0299,  0.0175,  0.1096,  ..., -0.0809,  0.1182,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0082, -0.1106,  0.0628,  ...,  0.0174,  0.0939, -0.0097],\n",
      "        [ 0.0299,  0.0175,  0.1096,  ..., -0.0809,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0175,  0.1096,  ..., -0.0809,  0.1182,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0175,  0.1096,  ..., -0.0809,  0.1181,  0.1056],\n",
      "        [ 0.0004, -0.0302, -0.0769,  ...,  0.0105,  0.0631,  0.0508],\n",
      "        [ 0.0004, -0.0302, -0.0769,  ...,  0.0105,  0.0631,  0.0508],\n",
      "        ...,\n",
      "        [-0.0989, -0.0523,  0.0560,  ...,  0.0224, -0.0644,  0.0966],\n",
      "        [ 0.0299,  0.0175,  0.1096,  ..., -0.0809,  0.1181,  0.1056],\n",
      "        [ 0.0299,  0.0175,  0.1096,  ..., -0.0809,  0.1181,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0175,  0.1096,  ..., -0.0810,  0.1181,  0.1056],\n",
      "        [ 0.0004, -0.0302, -0.0769,  ...,  0.0105,  0.0631,  0.0508],\n",
      "        [ 0.0004, -0.0302, -0.0769,  ...,  0.0105,  0.0631,  0.0508],\n",
      "        ...,\n",
      "        [-0.0989, -0.0523,  0.0560,  ...,  0.0225, -0.0644,  0.0966],\n",
      "        [ 0.0299,  0.0175,  0.1096,  ..., -0.0810,  0.1181,  0.1056],\n",
      "        [-0.0115,  0.1073, -0.0119,  ...,  0.0795,  0.0512, -0.0860]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0174,  0.1096,  ..., -0.0810,  0.1181,  0.1056],\n",
      "        [ 0.0004, -0.0303, -0.0770,  ...,  0.0104,  0.0630,  0.0508],\n",
      "        [ 0.0004, -0.0303, -0.0770,  ...,  0.0104,  0.0630,  0.0508],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0810,  0.1181,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0810,  0.1181,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0810,  0.1181,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056],\n",
      "        [-0.0115,  0.1073, -0.0118,  ...,  0.0795,  0.0512, -0.0859],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0300,  0.0174,  0.1096,  ..., -0.0811,  0.1179,  0.1056],\n",
      "        [-0.0993, -0.0524,  0.0558,  ...,  0.0228, -0.0645,  0.0966],\n",
      "        [ 0.0004, -0.0304, -0.0772,  ...,  0.0104,  0.0629,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0811,  0.1179,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0811,  0.1179,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0811,  0.1179,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056],\n",
      "        [-0.0115,  0.1073, -0.0117,  ...,  0.0795,  0.0512, -0.0859],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0994, -0.0524,  0.0558,  ...,  0.0229, -0.0646,  0.0966],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1178,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1178,  0.1056],\n",
      "        [ 0.0003, -0.0305, -0.0773,  ...,  0.0104,  0.0628,  0.0506],\n",
      "        ...,\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1178,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1178,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0995, -0.0524,  0.0558,  ...,  0.0229, -0.0646,  0.0966],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        ...,\n",
      "        [-0.0995, -0.0524,  0.0558,  ...,  0.0229, -0.0646,  0.0966],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0174,  0.1097,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0004, -0.0305, -0.0774,  ...,  0.0104,  0.0628,  0.0506],\n",
      "        [ 0.0004, -0.0305, -0.0774,  ...,  0.0104,  0.0628,  0.0506],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0165,  0.1185, -0.0105,  ...,  0.0828,  0.0629,  0.0487],\n",
      "        [ 0.0299,  0.0174,  0.1098,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0004, -0.0305, -0.0774,  ...,  0.0104,  0.0627,  0.0506],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1098,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1098,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1098,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0115,  0.1073, -0.0117,  ...,  0.0795,  0.0511, -0.0859],\n",
      "        [ 0.0299,  0.0174,  0.1098,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [-0.0997, -0.0524,  0.0558,  ...,  0.0230, -0.0647,  0.0966],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1098,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1098,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1098,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0298,  0.0175,  0.1099,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        ...,\n",
      "        [-0.0998, -0.0524,  0.0558,  ...,  0.0230, -0.0647,  0.0966],\n",
      "        [ 0.0234,  0.0589, -0.1091,  ...,  0.0714,  0.0753,  0.0714],\n",
      "        [ 0.0808, -0.0412, -0.0879,  ..., -0.0785, -0.0889, -0.1103]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0004, -0.0305, -0.0774,  ...,  0.0103,  0.0626,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        ...,\n",
      "        [-0.0998, -0.0524,  0.0558,  ...,  0.0230, -0.0647,  0.0966],\n",
      "        [ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0005, -0.0305, -0.0774,  ...,  0.0103,  0.0626,  0.0507],\n",
      "        [ 0.0005, -0.0305, -0.0774,  ...,  0.0103,  0.0626,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0005, -0.0306, -0.0774,  ...,  0.0102,  0.0626,  0.0507],\n",
      "        [ 0.0005, -0.0306, -0.0774,  ...,  0.0102,  0.0626,  0.0507],\n",
      "        [ 0.0005, -0.0306, -0.0774,  ...,  0.0102,  0.0626,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.1000, -0.0523,  0.0557,  ...,  0.0230, -0.0646,  0.0964],\n",
      "        [ 0.0005, -0.0306, -0.0775,  ...,  0.0103,  0.0625,  0.0507],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0806, -0.0413, -0.0879,  ..., -0.0785, -0.0888, -0.1102],\n",
      "        [-0.1000, -0.0523,  0.0557,  ...,  0.0230, -0.0646,  0.0964],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0005, -0.0305, -0.0775,  ...,  0.0103,  0.0625,  0.0507],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0005, -0.0305, -0.0776,  ...,  0.0103,  0.0625,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [ 0.0005, -0.0305, -0.0776,  ...,  0.0103,  0.0625,  0.0507],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [-0.1001, -0.0524,  0.0557,  ...,  0.0231, -0.0646,  0.0963],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0112,  0.1071, -0.0116,  ...,  0.0795,  0.0511, -0.0860],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [ 0.0087, -0.1107,  0.0631,  ...,  0.0173,  0.0944, -0.0097],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [-0.1001, -0.0524,  0.0557,  ...,  0.0232, -0.0646,  0.0963],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.1001, -0.0524,  0.0556,  ...,  0.0232, -0.0645,  0.0963],\n",
      "        [-0.1001, -0.0524,  0.0556,  ...,  0.0232, -0.0645,  0.0963],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [ 0.0005, -0.0306, -0.0777,  ...,  0.0103,  0.0624,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [-0.1002, -0.0524,  0.0556,  ...,  0.0232, -0.0645,  0.0962],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1177,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.1002, -0.0524,  0.0556,  ...,  0.0233, -0.0645,  0.0962],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1177,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1176,  0.1056],\n",
      "        [ 0.0005, -0.0305, -0.0778,  ...,  0.0104,  0.0624,  0.0506],\n",
      "        [ 0.0089, -0.1107,  0.0631,  ...,  0.0172,  0.0945, -0.0097],\n",
      "        ...,\n",
      "        [-0.1002, -0.0524,  0.0556,  ...,  0.0233, -0.0645,  0.0962],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1176,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Validation loss: 3.044654910543324 RMSE: 1.744894\n",
      "tensor([[ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1176,  0.1056],\n",
      "        ...,\n",
      "        [-0.1002, -0.0523,  0.0556,  ...,  0.0233, -0.0645,  0.0962],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1176,  0.1056],\n",
      "        [ 0.0089, -0.1107,  0.0632,  ...,  0.0171,  0.0946, -0.0098]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0005, -0.0306, -0.0779,  ...,  0.0104,  0.0623,  0.0507],\n",
      "        [ 0.0005, -0.0306, -0.0779,  ...,  0.0104,  0.0623,  0.0507],\n",
      "        [ 0.0297,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0005, -0.0306, -0.0779,  ...,  0.0105,  0.0622,  0.0507],\n",
      "        [ 0.0005, -0.0306, -0.0779,  ...,  0.0105,  0.0622,  0.0507],\n",
      "        [ 0.0005, -0.0306, -0.0779,  ...,  0.0105,  0.0622,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0175,  0.1100,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0175,  0.1100,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0175,  0.1100,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0175,  0.1100,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [-0.1002, -0.0523,  0.0556,  ...,  0.0233, -0.0645,  0.0962],\n",
      "        [ 0.0297,  0.0175,  0.1100,  ..., -0.0811,  0.1176,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0175,  0.1099,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [-0.1002, -0.0523,  0.0556,  ...,  0.0233, -0.0645,  0.0962],\n",
      "        [ 0.0005, -0.0306, -0.0779,  ...,  0.0105,  0.0621,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0811,  0.1176,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0113,  0.1071, -0.0114,  ...,  0.0795,  0.0511, -0.0859],\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0005, -0.0306, -0.0779,  ...,  0.0105,  0.0621,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0005, -0.0306, -0.0779,  ...,  0.0105,  0.0621,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [-0.1003, -0.0524,  0.0556,  ...,  0.0234, -0.0646,  0.0962],\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0909,  0.0324,  0.0702,  ...,  0.0420, -0.0075,  0.0781],\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [-0.1003, -0.0525,  0.0556,  ...,  0.0234, -0.0645,  0.0961],\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0298,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1055],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1055],\n",
      "        [-0.1004, -0.0525,  0.0556,  ...,  0.0234, -0.0645,  0.0961]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.1004, -0.0525,  0.0556,  ...,  0.0234, -0.0645,  0.0961],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1176,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1176,  0.1055],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1176,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1176,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1176,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0005, -0.0305, -0.0779,  ...,  0.0106,  0.0620,  0.0506],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [-0.1004, -0.0525,  0.0556,  ...,  0.0234, -0.0643,  0.0961],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        ...,\n",
      "        [ 0.0088, -0.1103,  0.0630,  ...,  0.0169,  0.0950, -0.0102],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "3 13 1.791797399520874\n",
      "tensor([[ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0239,  0.0583, -0.1088,  ...,  0.0713,  0.0755,  0.0716],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        ...,\n",
      "        [ 0.0089, -0.1103,  0.0630,  ...,  0.0169,  0.0951, -0.0102],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0910,  0.0325,  0.0701,  ...,  0.0420, -0.0072,  0.0780],\n",
      "        [ 0.0005, -0.0306, -0.0780,  ...,  0.0108,  0.0618,  0.0505],\n",
      "        [ 0.0005, -0.0306, -0.0780,  ...,  0.0108,  0.0618,  0.0505],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1054],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1054],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1054]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0111,  0.1072, -0.0113,  ...,  0.0795,  0.0512, -0.0859],\n",
      "        [-0.1005, -0.0524,  0.0556,  ...,  0.0235, -0.0642,  0.0960],\n",
      "        [ 0.0298,  0.0176,  0.1101,  ..., -0.0810,  0.1174,  0.1054],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0176,  0.1101,  ..., -0.0810,  0.1174,  0.1054],\n",
      "        [ 0.0298,  0.0176,  0.1101,  ..., -0.0810,  0.1174,  0.1054],\n",
      "        [ 0.0298,  0.0176,  0.1101,  ..., -0.0810,  0.1174,  0.1054]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1174,  0.1054],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1174,  0.1054],\n",
      "        [ 0.0005, -0.0306, -0.0780,  ...,  0.0108,  0.0617,  0.0505],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1174,  0.1054],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1174,  0.1054],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1174,  0.1054]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "seeds = [range(777,782)]\n",
    "for seed in seeds:\n",
    "    !python finetuneRecon.py \\\n",
    "    --task_name bbbp \\\n",
    "    --splitting scaffold \\\n",
    "    --seed {seed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce4ecd8-eaee-4c19-8a8d-195f56a1af16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c350a18-74eb-42bb-ac32-ea54a4810977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bace', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'classification', 'data_path': 'data/bace/bace.csv', 'target': ['Class']}}\n",
      "Running on: cuda:1\n",
      "1512\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1512\n",
      "Generating scaffold 1000/1512\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 7.4981489181518555\n",
      "Validation loss: 0.7139721508847167 ROC AUC: 0.47909284195605945\n",
      "1 12 2.1420817375183105\n",
      "Validation loss: 0.7306526875653804 ROC AUC: 0.5754783841247342\n",
      "2 24 1.6013022661209106\n",
      "Validation loss: 0.7059317989065158 ROC AUC: 0.5914245216158753\n",
      "3 36 1.2378596067428589\n",
      "Validation loss: 1.1195988710352918 ROC AUC: 0.5611268603827073\n",
      "Validation loss: 1.1868105068901518 ROC AUC: 0.5263997165131112\n",
      "5 10 1.102484941482544\n",
      "Validation loss: 0.7106327525037803 ROC AUC: 0.6015237420269313\n",
      "6 22 1.0403249263763428\n",
      "Validation loss: 0.7793103440707883 ROC AUC: 0.6312898653437279\n",
      "7 34 0.8195744156837463\n",
      "Validation loss: 0.8231810047137027 ROC AUC: 0.6146350106307584\n",
      "Validation loss: 0.7968797008722823 ROC AUC: 0.6061304039688165\n",
      "9 8 0.6828190088272095\n",
      "Validation loss: 0.79995241030952 ROC AUC: 0.6435152374202693\n",
      "10 20 0.719448983669281\n",
      "Validation loss: 0.7647524306316249 ROC AUC: 0.6475903614457831\n",
      "11 32 0.6335601806640625\n",
      "Validation loss: 0.9527782545184458 ROC AUC: 0.6346562721474133\n",
      "Validation loss: 0.7836000449610072 ROC AUC: 0.6102055279943303\n",
      "13 6 0.6211827397346497\n",
      "Validation loss: 1.0777890334855642 ROC AUC: 0.6424521615875266\n",
      "14 18 0.6217907071113586\n",
      "Validation loss: 0.8860967131639947 ROC AUC: 0.6220765414599575\n",
      "15 30 0.6113861799240112\n",
      "Validation loss: 0.7442192557631739 ROC AUC: 0.6279234585400425\n",
      "Validation loss: 0.9523899097316313 ROC AUC: 0.6601700921332387\n",
      "17 4 0.6723071932792664\n",
      "Validation loss: 1.017614884487051 ROC AUC: 0.6674344436569809\n",
      "18 16 0.47430381178855896\n",
      "Validation loss: 0.9529897203508592 ROC AUC: 0.6426293408929837\n",
      "19 28 0.5671438574790955\n",
      "Validation loss: 0.6487332120636441 ROC AUC: 0.6851523742026931\n",
      "Validation loss: 0.9199409354601474 ROC AUC: 0.672041105598866\n",
      "21 2 0.363366961479187\n",
      "Validation loss: 0.9705262136775137 ROC AUC: 0.6328844790928418\n",
      "22 14 0.5697730779647827\n",
      "Validation loss: 0.8092701332458597 ROC AUC: 0.654677533664068\n",
      "23 26 0.2935602068901062\n",
      "Validation loss: 0.9286611845951207 ROC AUC: 0.5830970942593905\n",
      "Validation loss: 0.8596574435170913 ROC AUC: 0.6376683203401843\n",
      "25 0 0.32478252053260803\n",
      "Validation loss: 0.7882244677733112 ROC AUC: 0.6392629340892984\n",
      "26 12 0.4092811346054077\n",
      "Validation loss: 0.9538159512526152 ROC AUC: 0.5933734939759037\n",
      "27 24 0.3896125555038452\n",
      "Validation loss: 0.7879380631131052 ROC AUC: 0.6622962437987242\n",
      "28 36 0.4073028266429901\n",
      "Validation loss: 0.9372482844535878 ROC AUC: 0.6208362863217577\n",
      "Validation loss: 0.7492959021732507 ROC AUC: 0.6638908575478384\n",
      "30 10 0.3960237503051758\n",
      "Validation loss: 0.8032533139582502 ROC AUC: 0.6723954642097802\n",
      "31 22 0.4698207974433899\n",
      "Validation loss: 0.983465489962243 ROC AUC: 0.6451098511693834\n",
      "32 34 0.4966234564781189\n",
      "Validation loss: 0.947194424686053 ROC AUC: 0.6514883061658399\n",
      "Validation loss: 0.9057516293809903 ROC AUC: 0.6366052445074415\n",
      "34 8 0.3890514373779297\n",
      "Validation loss: 1.0738816569183047 ROC AUC: 0.6615875265768959\n",
      "35 20 0.3794173002243042\n",
      "Validation loss: 1.0214880696985105 ROC AUC: 0.669029057406095\n",
      "36 32 0.31377077102661133\n",
      "Validation loss: 1.0866364974849272 ROC AUC: 0.6784195605953225\n",
      "Validation loss: 0.7828253045776822 ROC AUC: 0.6886959603118357\n",
      "38 6 0.5744560360908508\n",
      "Validation loss: 0.9528594380182935 ROC AUC: 0.679305457122608\n",
      "39 18 0.48311376571655273\n",
      "Validation loss: 0.7913618545658541 ROC AUC: 0.6578667611622961\n",
      "40 30 0.3141349256038666\n",
      "Validation loss: 0.8562103723058637 ROC AUC: 0.7023387668320339\n",
      "Validation loss: 0.7886608104832125 ROC AUC: 0.6752303330970942\n",
      "42 4 0.43292227387428284\n",
      "Validation loss: 0.8450155885803778 ROC AUC: 0.6645995747696669\n",
      "43 16 0.549712061882019\n",
      "Validation loss: 0.7967097261883566 ROC AUC: 0.677710843373494\n",
      "44 28 0.4710620939731598\n",
      "Validation loss: 0.8707172081170492 ROC AUC: 0.651665485471297\n",
      "Validation loss: 0.8872696777053227 ROC AUC: 0.6800141743444366\n",
      "46 2 0.4040296673774719\n",
      "Validation loss: 0.818967145799801 ROC AUC: 0.6711552090715804\n",
      "47 14 0.308441698551178\n",
      "Validation loss: 0.7048792089058074 ROC AUC: 0.7057051736357194\n",
      "48 26 0.3498179316520691\n",
      "Validation loss: 0.9952533683240019 ROC AUC: 0.6729270021261516\n",
      "Validation loss: 0.8706090750283753 ROC AUC: 0.6723954642097804\n",
      "50 0 0.3238138258457184\n",
      "Validation loss: 0.8107953103172858 ROC AUC: 0.6514883061658399\n",
      "51 12 0.4634484648704529\n",
      "Validation loss: 0.9919743668164639 ROC AUC: 0.6727498228206945\n",
      "52 24 0.2796283960342407\n",
      "Validation loss: 0.8330094056413663 ROC AUC: 0.684975194897236\n",
      "53 36 0.2333069145679474\n",
      "Validation loss: 0.7826358439117078 ROC AUC: 0.7104890148830616\n",
      "Validation loss: 1.0035257497370638 ROC AUC: 0.6688518781006378\n",
      "55 10 0.4759169816970825\n",
      "Validation loss: 1.1161621011645588 ROC AUC: 0.6529057406094968\n",
      "56 22 0.4835397005081177\n",
      "Validation loss: 0.8774111768267802 ROC AUC: 0.6723954642097804\n",
      "57 34 0.3962599039077759\n",
      "Validation loss: 0.7826319439521688 ROC AUC: 0.6490077958894401\n",
      "Validation loss: 0.788052815869944 ROC AUC: 0.6915308291991494\n",
      "59 8 0.40750378370285034\n",
      "Validation loss: 0.8395951773157183 ROC AUC: 0.7071226080793762\n",
      "60 20 0.40538349747657776\n",
      "Validation loss: 1.0723563160327887 ROC AUC: 0.6635364989369242\n",
      "61 32 0.3066117465496063\n",
      "Validation loss: 0.8259206481327285 ROC AUC: 0.677888022678951\n",
      "Validation loss: 0.9517050010479049 ROC AUC: 0.6702693125442948\n",
      "63 6 0.4023512899875641\n",
      "Validation loss: 1.1350904276828893 ROC AUC: 0.6693834160170093\n",
      "64 18 0.4566039741039276\n",
      "Validation loss: 0.928890534584096 ROC AUC: 0.6665485471296952\n",
      "65 30 0.26656830310821533\n",
      "Validation loss: 0.8947630074639984 ROC AUC: 0.6791282778171508\n",
      "Validation loss: 0.8799507720580954 ROC AUC: 0.6844436569808646\n",
      "67 4 0.29165980219841003\n",
      "Validation loss: 0.9765393402402764 ROC AUC: 0.6612331679659816\n",
      "68 16 0.5139544010162354\n",
      "Validation loss: 1.039672739063667 ROC AUC: 0.7046420978029766\n",
      "69 28 0.3201305568218231\n",
      "Validation loss: 0.9426964008255511 ROC AUC: 0.674698795180723\n",
      "Validation loss: 0.9424548749102662 ROC AUC: 0.6972005669737776\n",
      "71 2 0.3040936291217804\n",
      "Validation loss: 0.7771340667806714 ROC AUC: 0.6812544294826365\n",
      "72 14 0.4106921851634979\n",
      "Validation loss: 0.9750701165357173 ROC AUC: 0.6789510985116938\n",
      "73 26 0.39014121890068054\n",
      "Validation loss: 0.9244414828471 ROC AUC: 0.6874557051736359\n",
      "Validation loss: 0.8681401614321779 ROC AUC: 0.6885187810063784\n",
      "75 0 0.3077901303768158\n",
      "Validation loss: 1.184421738251945 ROC AUC: 0.696491849751949\n",
      "76 12 0.3053998649120331\n",
      "Validation loss: 0.9430398775252286 ROC AUC: 0.6856839121190645\n",
      "77 24 0.27590933442115784\n",
      "Validation loss: 0.8721872777338849 ROC AUC: 0.7117292700212615\n",
      "78 36 0.3238167464733124\n",
      "Validation loss: 1.2225186122174294 ROC AUC: 0.6856839121190645\n",
      "Validation loss: 0.9216558652997806 ROC AUC: 0.7076541459957477\n",
      "80 10 0.49634552001953125\n",
      "Validation loss: 0.9422312161780351 ROC AUC: 0.6826718639262934\n",
      "81 22 0.3422080874443054\n",
      "Validation loss: 0.9044146490412832 ROC AUC: 0.7152728561304039\n",
      "82 34 0.3893662393093109\n",
      "Validation loss: 1.0509937788477006 ROC AUC: 0.6754075124025514\n",
      "Validation loss: 1.0223036720263248 ROC AUC: 0.6552090715804394\n",
      "84 8 0.21724992990493774\n",
      "Validation loss: 1.0226324547995005 ROC AUC: 0.6745216158752658\n",
      "85 20 0.3048151731491089\n",
      "Validation loss: 0.8625938075267716 ROC AUC: 0.7034018426647768\n",
      "86 32 0.4366673231124878\n",
      "Validation loss: 0.8627376023507276 ROC AUC: 0.6860382707299787\n",
      "Validation loss: 0.8725756813358787 ROC AUC: 0.699326718639263\n",
      "88 6 0.3140982687473297\n",
      "Validation loss: 0.9466550993603586 ROC AUC: 0.7030474840538625\n",
      "89 18 0.23090052604675293\n",
      "Validation loss: 0.8835041633504905 ROC AUC: 0.709603118355776\n",
      "90 30 0.29761236906051636\n",
      "Validation loss: 0.9305580218896171 ROC AUC: 0.7181077250177179\n",
      "Validation loss: 0.8728494912583307 ROC AUC: 0.7152728561304039\n",
      "92 4 0.365215003490448\n",
      "Validation loss: 0.9480566662668393 ROC AUC: 0.7048192771084336\n",
      "93 16 0.3616190552711487\n",
      "Validation loss: 0.8276975521978164 ROC AUC: 0.7103118355776045\n",
      "94 28 0.4587516486644745\n",
      "Validation loss: 0.8416091910261192 ROC AUC: 0.7042877391920623\n",
      "Validation loss: 0.9931795573392451 ROC AUC: 0.6973777462792345\n",
      "96 2 0.28745803236961365\n",
      "Validation loss: 0.8596528369859354 ROC AUC: 0.7088944011339476\n",
      "97 14 0.2992555499076843\n",
      "Validation loss: 0.8355479062787744 ROC AUC: 0.711020552799433\n",
      "98 26 0.2575511932373047\n",
      "Validation loss: 0.8550182221741076 ROC AUC: 0.7085400425230334\n",
      "Validation loss: 0.9749058935026459 ROC AUC: 0.6918851878100637\n",
      "100 0 0.3154968023300171\n",
      "Validation loss: 1.0399027139145807 ROC AUC: 0.7007441530829199\n",
      "101 12 0.3105909526348114\n",
      "Validation loss: 0.8446222717398839 ROC AUC: 0.7177533664068037\n",
      "102 24 0.2574571669101715\n",
      "Validation loss: 0.9581043266302702 ROC AUC: 0.7236002834868888\n",
      "103 36 0.3696464002132416\n",
      "Validation loss: 0.8250169734291682 ROC AUC: 0.7232459248759745\n",
      "Validation loss: 0.9229226149865334 ROC AUC: 0.6986180014174344\n",
      "105 10 0.26636651158332825\n",
      "Validation loss: 1.151747524343579 ROC AUC: 0.6989723600283486\n",
      "106 22 0.2742233872413635\n",
      "Validation loss: 0.986290094473504 ROC AUC: 0.7055279943302621\n",
      "107 34 0.23304535448551178\n",
      "Validation loss: 0.9846306012955722 ROC AUC: 0.7085400425230334\n",
      "Validation loss: 1.112052210908852 ROC AUC: 0.6886959603118356\n",
      "109 8 0.29073697328567505\n",
      "Validation loss: 1.1163476271345125 ROC AUC: 0.6768249468462084\n",
      "110 20 0.31690335273742676\n",
      "Validation loss: 1.0123955319259341 ROC AUC: 0.6764705882352942\n",
      "111 32 0.2861561179161072\n",
      "Validation loss: 1.0651339639891062 ROC AUC: 0.7108433734939759\n",
      "Validation loss: 1.024031470942971 ROC AUC: 0.7140326009922041\n",
      "113 6 0.2681407630443573\n",
      "Validation loss: 1.0831556635976627 ROC AUC: 0.6791282778171509\n",
      "114 18 0.14749930799007416\n",
      "Validation loss: 0.9856063466987862 ROC AUC: 0.6998582565556343\n",
      "115 30 0.3753790259361267\n",
      "Validation loss: 1.0146344513293133 ROC AUC: 0.6929482636428066\n",
      "Validation loss: 0.8855832053336087 ROC AUC: 0.6800141743444366\n",
      "117 4 0.3097115755081177\n",
      "Validation loss: 1.0510541480898068 ROC AUC: 0.71243798724309\n",
      "118 16 0.19736361503601074\n",
      "Validation loss: 0.9145176963300894 ROC AUC: 0.7106661941885187\n",
      "119 28 0.3371641933917999\n",
      "Validation loss: 1.1192860224389083 ROC AUC: 0.6869241672572644\n",
      "Validation loss: 0.9840744528549397 ROC AUC: 0.7117292700212614\n",
      "121 2 0.2725587487220764\n",
      "Validation loss: 0.9035413387595423 ROC AUC: 0.7007441530829199\n",
      "122 14 0.1270149201154709\n",
      "Validation loss: 0.935980902602341 ROC AUC: 0.729801559177888\n",
      "123 26 0.24204333126544952\n",
      "Validation loss: 0.9252341559391148 ROC AUC: 0.7205882352941176\n",
      "Validation loss: 0.8552033001223937 ROC AUC: 0.7085400425230334\n",
      "125 0 0.39080384373664856\n",
      "Validation loss: 1.0419098951958663 ROC AUC: 0.7161587526576896\n",
      "126 12 0.29982373118400574\n",
      "Validation loss: 1.1891786558738608 ROC AUC: 0.7007441530829199\n",
      "127 24 0.13586333394050598\n",
      "Validation loss: 1.0493660959976399 ROC AUC: 0.7087172218284904\n",
      "128 36 0.3548916280269623\n",
      "Validation loss: 1.1721345091497661 ROC AUC: 0.6948972360028349\n",
      "Validation loss: 1.02886086337219 ROC AUC: 0.6871013465627215\n",
      "130 10 0.28065136075019836\n",
      "Validation loss: 0.9392879640819222 ROC AUC: 0.7234231041814315\n",
      "131 22 0.2786422073841095\n",
      "Validation loss: 1.068951886221273 ROC AUC: 0.7115520907158044\n",
      "132 34 0.21909473836421967\n",
      "Validation loss: 1.1016711501885723 ROC AUC: 0.6973777462792345\n",
      "Validation loss: 0.9940235689775834 ROC AUC: 0.7064138908575478\n",
      "134 8 0.2498386800289154\n",
      "Validation loss: 1.0663789881775712 ROC AUC: 0.7131467044649185\n",
      "135 20 -2.4061975479125977\n",
      "Validation loss: 0.7790682221090557 ROC AUC: 0.5829199149539334\n",
      "136 32 -56.713741302490234\n",
      "Validation loss: 0.6863608226081394 ROC AUC: 0.621367824238129\n",
      "Validation loss: 0.7342400629788834 ROC AUC: 0.5760099220411056\n",
      "138 6 -116.674072265625\n",
      "Validation loss: 0.7530948069711395 ROC AUC: 0.5322466335931963\n",
      "139 18 -183.2919464111328\n",
      "Validation loss: 0.7322757390161224 ROC AUC: 0.5676824946846208\n",
      "140 30 -258.55609130859375\n",
      "Validation loss: 0.700844471028309 ROC AUC: 0.6410347271438696\n",
      "Validation loss: 0.669670449187424 ROC AUC: 0.5960311835577604\n",
      "142 4 -330.3785400390625\n",
      "Validation loss: 0.6730232140086344 ROC AUC: 0.6187101346562721\n",
      "143 16 -419.27581787109375\n",
      "Validation loss: 0.6862649503133155 ROC AUC: 0.5788447909284196\n",
      "144 28 -501.2515869140625\n",
      "Validation loss: 0.7496475608933051 ROC AUC: 0.5389794472005669\n",
      "Validation loss: 0.7044685044825472 ROC AUC: 0.5892983699503899\n",
      "146 2 -583.0723266601562\n",
      "Validation loss: 0.7108603759317209 ROC AUC: 0.5951452870304749\n",
      "147 14 -680.0121459960938\n",
      "Validation loss: 0.7038794917776096 ROC AUC: 0.614280652019844\n",
      "148 26 -777.8502197265625\n",
      "Validation loss: 0.7132016341417831 ROC AUC: 0.5517363571934797\n",
      "Validation loss: 0.6954568806073523 ROC AUC: 0.5350815024805102\n",
      "150 0 -883.3605346679688\n",
      "Validation loss: 0.7417535446337516 ROC AUC: 0.5834514528703048\n",
      "151 12 -993.4178466796875\n",
      "Validation loss: 0.7362725801815261 ROC AUC: 0.546243798724309\n",
      "152 24 -1091.91259765625\n",
      "Validation loss: 0.7129274736966519 ROC AUC: 0.5986888731396173\n",
      "153 36 -1212.347412109375\n",
      "Validation loss: 0.7301303578528348 ROC AUC: 0.5478384124734231\n",
      "Validation loss: 0.6817090866581493 ROC AUC: 0.5611268603827073\n",
      "155 10 -1314.5140380859375\n",
      "Validation loss: 0.7023000685584466 ROC AUC: 0.5430545712260808\n",
      "156 22 -1408.677734375\n",
      "Validation loss: 0.6973595642885625 ROC AUC: 0.5712260807937632\n",
      "157 34 -1547.7711181640625\n",
      "Validation loss: 0.7318747840969768 ROC AUC: 0.5868178596739901\n",
      "Validation loss: 0.7121219666588385 ROC AUC: 0.5411055988660525\n",
      "159 8 -1676.6878662109375\n",
      "Validation loss: 0.7075272984062599 ROC AUC: 0.582388377037562\n",
      "160 20 -1790.3414306640625\n",
      "Validation loss: 0.7233630702985043 ROC AUC: 0.5836286321757618\n",
      "161 32 -1930.2496337890625\n",
      "Validation loss: 0.7144614927816075 ROC AUC: 0.5923104181431608\n",
      "Validation loss: 0.6985922680785325 ROC AUC: 0.554925584691708\n",
      "163 6 -2038.7974853515625\n",
      "Validation loss: 0.7244792331922922 ROC AUC: 0.5731750531537916\n",
      "164 18 -2228.97216796875\n",
      "Validation loss: 0.7023757052737356 ROC AUC: 0.5536853295535081\n",
      "165 30 -2353.916259765625\n",
      "Validation loss: 0.7081370594485706 ROC AUC: 0.564847625797307\n",
      "Validation loss: 0.7036131592775812 ROC AUC: 0.5442948263642806\n",
      "167 4 -2473.842041015625\n",
      "Validation loss: 0.7004000548495363 ROC AUC: 0.5637845499645642\n",
      "168 16 -2675.0849609375\n",
      "Validation loss: 0.6966642141342163 ROC AUC: 0.5570517363571934\n",
      "169 28 -2772.19677734375\n",
      "Validation loss: 0.6959154436130397 ROC AUC: 0.5605953224663359\n",
      "Validation loss: 0.6964417388107603 ROC AUC: 0.5703401842664776\n",
      "171 2 -2970.356689453125\n",
      "Validation loss: 0.7050035651156444 ROC AUC: 0.5846917080085046\n",
      "172 14 -3064.458984375\n",
      "Validation loss: 0.7108016523304365 ROC AUC: 0.5719347980155918\n",
      "173 26 -3241.525634765625\n",
      "Validation loss: 0.7109950840078443 ROC AUC: 0.5671509567682496\n",
      "Validation loss: 0.7175020484734844 ROC AUC: 0.566442239546421\n",
      "175 0 -3474.0498046875\n",
      "Validation loss: 0.695551270285979 ROC AUC: 0.5554571226080793\n",
      "176 12 -3586.3359375\n",
      "Validation loss: 0.696280208644488 ROC AUC: 0.5834514528703048\n",
      "177 24 -3823.56103515625\n",
      "Validation loss: 0.7051402172505461 ROC AUC: 0.5660878809355068\n",
      "178 36 -3957.802978515625\n",
      "Validation loss: 0.7199416172425479 ROC AUC: 0.5834514528703048\n",
      "Validation loss: 0.6949731786519486 ROC AUC: 0.5768958185683912\n",
      "180 10 -4054.43994140625\n",
      "Validation loss: 0.7033558661574559 ROC AUC: 0.5776045357902198\n",
      "181 22 -4282.3134765625\n",
      "Validation loss: 0.7092304577101145 ROC AUC: 0.57512402551382\n",
      "182 34 -4527.6396484375\n",
      "Validation loss: 0.6920689612824396 ROC AUC: 0.5613040396881644\n",
      "Validation loss: 0.7029705319973018 ROC AUC: 0.5712260807937632\n",
      "184 8 -4675.22802734375\n",
      "Validation loss: 0.6977272061322699 ROC AUC: 0.5667965981573353\n",
      "185 20 -4924.20458984375\n",
      "Validation loss: 0.7013787761429288 ROC AUC: 0.583982990786676\n",
      "186 32 -5071.1904296875\n",
      "Validation loss: 0.7041579105996139 ROC AUC: 0.5885896527285613\n",
      "Validation loss: 0.702332830981703 ROC AUC: 0.5692771084337349\n",
      "188 6 -5260.3515625\n",
      "Validation loss: 0.716500743335446 ROC AUC: 0.601169383416017\n",
      "189 18 -5499.08154296875\n",
      "Validation loss: 0.701479477203445 ROC AUC: 0.573706591070163\n",
      "190 30 -5738.03515625\n",
      "Validation loss: 0.7150309188476461 ROC AUC: 0.5717576187101346\n",
      "Validation loss: 0.7010987823372645 ROC AUC: 0.5701630049610206\n",
      "192 4 -5936.40625\n",
      "Validation loss: 0.700982873802943 ROC AUC: 0.5680368532955351\n",
      "193 16 -6045.0556640625\n",
      "Validation loss: 0.7070788413483575 ROC AUC: 0.5579376328844792\n",
      "194 28 -6365.220703125\n",
      "Validation loss: 0.7104095927137413 ROC AUC: 0.5687455705173635\n",
      "Validation loss: 0.6980386459274798 ROC AUC: 0.5630758327427356\n",
      "196 2 -6567.01904296875\n",
      "Validation loss: 0.7104694010406141 ROC AUC: 0.6057760453579022\n",
      "197 14 -6861.15380859375\n",
      "Validation loss: 0.6977959666031086 ROC AUC: 0.5744153082919915\n",
      "198 26 -7064.39208984375\n",
      "Validation loss: 0.6985676616232916 ROC AUC: 0.5673281360737066\n",
      "Validation loss: 0.7002702390910774 ROC AUC: 0.6006378454996456\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.0206805593089054 Test ROC AUC: 0.7960144927536232\n"
     ]
    }
   ],
   "source": [
    "!python finetuneReconAlpha2.py \\\n",
    "    --task_name freeSolv \\\n",
    "    --splitting scaffold \\\n",
    "    --mask_rate 0.7 \\\n",
    "    --seed 777 \\\n",
    "    --random_masking 1 \\\n",
    "    --alpha 0.01 \\\n",
    "    --mask_edge 1 \\\n",
    "    --gpu cuda:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1537fe0-447a-43d8-90e0-6fa2e27ae65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "483786aa-1d33-4c99-b6a1-dea4f8c5cedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 10\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f834183-27af-4128-9b00-975829c3dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_node = torch.randn(num_nodes, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62d0161b-718c-43a9-b1fb-9331cfee6ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_node_label = torch.randint(0,num_classes, (num_nodes, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3730f1a7-27ac-4dc5-8e9d-3fdddae73954",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, prediced_classes = torch.max(pred_node, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99403bc3-e586-45e0-9721-4e71da0a9c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, prediced_classes = torch.max(pred_node, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89a58134-3106-420b-b4ce-a7f39642f13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4224,  2.0152, -0.8221],\n",
       "        [-0.6797,  0.7852,  0.8896],\n",
       "        [ 1.0098, -0.3531,  0.5847],\n",
       "        [ 0.5771,  0.8337, -0.1788],\n",
       "        [-0.8700,  0.0082,  0.2619],\n",
       "        [-1.1317, -1.1674, -0.2489],\n",
       "        [ 1.7766, -0.0508, -0.0692],\n",
       "        [-0.8634, -1.4741,  1.3934],\n",
       "        [-0.4561,  0.9929, -0.2693],\n",
       "        [ 0.5695, -0.1895, -0.2701]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77c1959b-1126-4984-8209-2c985d3ab49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 0, 1, 2, 2, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediced_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79a78ae8-8ab8-4ef8-8c7b-2d6ae5c5542d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [1],\n",
       "        [2],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_node_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9da51ee-4134-4539-aa70-0fc2226f73cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = (prediced_classes == mask_node_label[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6df2d293-0fe0-4b73-b414-c6cdd567e3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  True, False,  True, False,  True, False, False])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb8e2d38-0355-4198-9035-664ca3a6bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = correct_predictions.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afa8427a-2f8a-466d-a394-1bc7fa1ae53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "335403f7-30fe-4eb3-99ba-d357a825e77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30000001192092896"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414449ac-09e8-4507-8b7f-69ea4ddc818d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
