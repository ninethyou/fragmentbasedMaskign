{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cbc95c-8c82-4b39-9acb-eac3d7dea845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'freesolv', 'model_type': 'gin', 'model': {'num_layer': 3, 'emb_dim': 64, 'feat_dim': 64, 'drop_ratio': 0.5, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'target': ['expt']}}\n",
      "Running on: cuda:1\n",
      "641\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/641\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 22.765607178931294\n",
      "Validation loss: 67.76921653747559 RMSE: 8.232206\n",
      "Validation loss: 61.709373474121094 RMSE: 7.855531\n",
      "Validation loss: 51.4941291809082 RMSE: 7.1759405\n",
      "3 2 12.509482596921353\n",
      "Validation loss: 39.20685386657715 RMSE: 6.2615376\n",
      "Validation loss: 16.26902484893799 RMSE: 4.033488\n",
      "Validation loss: 12.566465854644775 RMSE: 3.5449214\n",
      "6 4 5.772772903667269\n",
      "Validation loss: 13.082480907440186 RMSE: 3.6169713\n",
      "Validation loss: 13.519720554351807 RMSE: 3.6769176\n",
      "Validation loss: 15.478009700775146 RMSE: 3.9342103\n",
      "9 6 5.958229143017753\n",
      "Validation loss: 12.287816524505615 RMSE: 3.5053983\n",
      "Validation loss: 11.594627380371094 RMSE: 3.4050884\n",
      "Validation loss: 12.316524982452393 RMSE: 3.5094907\n",
      "12 8 5.117322246401017\n",
      "Validation loss: 13.506373882293701 RMSE: 3.6751018\n",
      "Validation loss: 13.252665519714355 RMSE: 3.640421\n",
      "Validation loss: 12.783780097961426 RMSE: 3.5754411\n",
      "15 10 3.8057360798912345\n",
      "Validation loss: 15.951221466064453 RMSE: 3.9938982\n",
      "Validation loss: 12.555403232574463 RMSE: 3.5433605\n",
      "Validation loss: 11.315004348754883 RMSE: 3.363778\n",
      "18 12 6.045317882129681\n",
      "Validation loss: 14.227739334106445 RMSE: 3.7719674\n",
      "Validation loss: 10.687952518463135 RMSE: 3.2692435\n",
      "Validation loss: 11.057226181030273 RMSE: 3.3252409\n",
      "21 14 4.720424620992521\n",
      "Validation loss: 9.193670749664307 RMSE: 3.0321066\n",
      "Validation loss: 11.824687480926514 RMSE: 3.438704\n",
      "Validation loss: 11.979208946228027 RMSE: 3.4610996\n",
      "Validation loss: 10.209471702575684 RMSE: 3.1952264\n",
      "25 0 4.093754578863841\n",
      "Validation loss: 11.482805252075195 RMSE: 3.3886287\n",
      "Validation loss: 11.204308986663818 RMSE: 3.3472838\n",
      "Validation loss: 14.357475280761719 RMSE: 3.789126\n",
      "28 2 3.8588079315612243\n",
      "Validation loss: 15.57827091217041 RMSE: 3.9469318\n",
      "Validation loss: 10.432817459106445 RMSE: 3.2299874\n",
      "Validation loss: 8.51735782623291 RMSE: 2.9184513\n",
      "31 4 4.048154680679011\n",
      "Validation loss: 8.63901138305664 RMSE: 2.9392197\n",
      "Validation loss: 10.359402656555176 RMSE: 3.2186027\n",
      "Validation loss: 11.728275299072266 RMSE: 3.4246566\n",
      "34 6 6.088481421578859\n",
      "Validation loss: 7.013579845428467 RMSE: 2.6483166\n",
      "Validation loss: 14.366357326507568 RMSE: 3.7902977\n",
      "Validation loss: 10.205309391021729 RMSE: 3.194575\n",
      "37 8 4.508024053654937\n",
      "Validation loss: 12.960676193237305 RMSE: 3.6000938\n",
      "Validation loss: 10.306894779205322 RMSE: 3.2104354\n",
      "Validation loss: 10.66068696975708 RMSE: 3.2650704\n",
      "40 10 4.735641387248263\n",
      "Validation loss: 10.865391254425049 RMSE: 3.2962692\n",
      "Validation loss: 8.342419624328613 RMSE: 2.888325\n",
      "Validation loss: 7.43037748336792 RMSE: 2.725872\n",
      "43 12 2.7932667098682993\n",
      "Validation loss: 10.680505275726318 RMSE: 3.2681043\n",
      "Validation loss: 9.309075832366943 RMSE: 3.0510778\n",
      "Validation loss: 10.469438076019287 RMSE: 3.2356513\n",
      "46 14 2.797471754597661\n",
      "Validation loss: 9.294254302978516 RMSE: 3.0486479\n",
      "Validation loss: 9.685880184173584 RMSE: 3.1122146\n",
      "Validation loss: 10.068552494049072 RMSE: 3.1730983\n",
      "Validation loss: 9.812148094177246 RMSE: 3.132435\n",
      "50 0 3.6748252553747713\n",
      "Validation loss: 11.332557678222656 RMSE: 3.3663864\n",
      "Validation loss: 8.803518772125244 RMSE: 2.9670722\n",
      "Validation loss: 9.686662673950195 RMSE: 3.1123405\n",
      "53 2 2.779671876574526\n",
      "Validation loss: 9.6893310546875 RMSE: 3.1127691\n",
      "Validation loss: 11.188190937042236 RMSE: 3.3448753\n",
      "Validation loss: 10.53129768371582 RMSE: 3.2451959\n",
      "56 4 2.4695557080227393\n",
      "Validation loss: 10.88099193572998 RMSE: 3.2986348\n",
      "Validation loss: 7.777585506439209 RMSE: 2.7888324\n",
      "Validation loss: 8.43842077255249 RMSE: 2.9048963\n",
      "59 6 2.782057742228361\n",
      "Validation loss: 8.822070598602295 RMSE: 2.9701967\n",
      "Validation loss: 9.632307529449463 RMSE: 3.1035957\n",
      "Validation loss: 9.370177268981934 RMSE: 3.0610747\n",
      "62 8 3.173571073835444\n",
      "Validation loss: 12.760030746459961 RMSE: 3.5721183\n",
      "Validation loss: 11.78060245513916 RMSE: 3.4322882\n",
      "Validation loss: 10.919952392578125 RMSE: 3.3045352\n",
      "65 10 2.297608719398485\n",
      "Validation loss: 11.164002418518066 RMSE: 3.3412578\n",
      "Validation loss: 10.232200145721436 RMSE: 3.198781\n",
      "Validation loss: 9.020076274871826 RMSE: 3.0033445\n",
      "68 12 1.8034797834174938\n",
      "Validation loss: 9.589375495910645 RMSE: 3.0966716\n",
      "Validation loss: 9.5484619140625 RMSE: 3.0900583\n",
      "Validation loss: 9.22443962097168 RMSE: 3.0371764\n",
      "71 14 2.028105630833498\n",
      "Validation loss: 9.283330917358398 RMSE: 3.046856\n",
      "Validation loss: 10.300908327102661 RMSE: 3.209503\n",
      "Validation loss: 6.514897584915161 RMSE: 2.5524297\n",
      "Validation loss: 7.134978294372559 RMSE: 2.6711378\n",
      "75 0 1.4254186354900023\n",
      "Validation loss: 8.48767900466919 RMSE: 2.9133618\n",
      "Validation loss: 11.331507682800293 RMSE: 3.3662305\n",
      "Validation loss: 9.240825653076172 RMSE: 3.0398726\n",
      "78 2 2.4321266350895416\n",
      "Validation loss: 8.173765897750854 RMSE: 2.85898\n",
      "Validation loss: 7.433137655258179 RMSE: 2.7263782\n",
      "Validation loss: 9.467063188552856 RMSE: 3.076859\n",
      "81 4 2.2863959975503048\n",
      "Validation loss: 8.030288219451904 RMSE: 2.8337765\n",
      "Validation loss: 7.603039979934692 RMSE: 2.757361\n",
      "Validation loss: 9.10471510887146 RMSE: 3.017402\n",
      "84 6 2.400139306330709\n",
      "Validation loss: 12.52552604675293 RMSE: 3.539142\n",
      "Validation loss: 13.353384017944336 RMSE: 3.6542282\n",
      "Validation loss: 10.285208225250244 RMSE: 3.207056\n",
      "87 8 1.858647116302172\n",
      "Validation loss: 10.15605354309082 RMSE: 3.1868567\n",
      "Validation loss: 12.231311798095703 RMSE: 3.4973295\n",
      "Validation loss: 10.062100887298584 RMSE: 3.1720815\n",
      "90 10 2.484136402918159\n",
      "Validation loss: 9.059525489807129 RMSE: 3.0099044\n",
      "Validation loss: 10.000834465026855 RMSE: 3.1624095\n",
      "Validation loss: 8.567476272583008 RMSE: 2.9270253\n",
      "93 12 2.2033363916726887\n",
      "Validation loss: 9.458950519561768 RMSE: 3.0755405\n",
      "Validation loss: 8.49746823310852 RMSE: 2.9150417\n",
      "Validation loss: 11.019181251525879 RMSE: 3.319515\n",
      "96 14 2.4275297175452324\n",
      "Validation loss: 11.0784432888031 RMSE: 3.3284295\n",
      "Validation loss: 9.847879886627197 RMSE: 3.138133\n",
      "Validation loss: 9.825986623764038 RMSE: 3.134643\n",
      "Validation loss: 12.062633037567139 RMSE: 3.4731305\n",
      "100 0 2.7621174915578197\n",
      "Validation loss: 12.914677619934082 RMSE: 3.5937\n",
      "Validation loss: 9.864779472351074 RMSE: 3.1408246\n",
      "Validation loss: 9.31113052368164 RMSE: 3.0514145\n",
      "103 2 2.1327901677457546\n",
      "Validation loss: 11.132364273071289 RMSE: 3.3365197\n",
      "Validation loss: 10.896422386169434 RMSE: 3.3009732\n",
      "Validation loss: 9.37177324295044 RMSE: 3.0613353\n",
      "106 4 6.52345669866604\n",
      "Validation loss: 13.347434043884277 RMSE: 3.653414\n",
      "Validation loss: 12.608194351196289 RMSE: 3.5508022\n",
      "Validation loss: 14.832545280456543 RMSE: 3.8513045\n",
      "109 6 2.2730579054355102\n",
      "Validation loss: 12.850907564163208 RMSE: 3.5848165\n",
      "Validation loss: 13.615957260131836 RMSE: 3.689981\n",
      "Validation loss: 13.333288669586182 RMSE: 3.6514778\n",
      "112 8 2.389890819465635\n",
      "Validation loss: 10.246681451797485 RMSE: 3.2010438\n",
      "Validation loss: 10.162731647491455 RMSE: 3.1879036\n",
      "Validation loss: 8.358057022094727 RMSE: 2.8910306\n",
      "115 10 2.634124193686696\n",
      "Validation loss: 9.589375972747803 RMSE: 3.0966709\n",
      "Validation loss: 10.92122507095337 RMSE: 3.3047283\n",
      "Validation loss: 10.523467540740967 RMSE: 3.2439892\n",
      "118 12 3.0635385705177547\n",
      "Validation loss: 10.452991962432861 RMSE: 3.2331088\n",
      "Validation loss: 10.28785753250122 RMSE: 3.207469\n",
      "Validation loss: 13.945233345031738 RMSE: 3.7343316\n",
      "121 14 4.896470048182338\n",
      "Validation loss: 11.373667240142822 RMSE: 3.3724868\n",
      "Validation loss: 13.601068019866943 RMSE: 3.6879625\n",
      "Validation loss: 12.720912456512451 RMSE: 3.5666387\n",
      "Validation loss: 10.793776035308838 RMSE: 3.2853885\n",
      "125 0 2.6759686770629143\n",
      "Validation loss: 12.754858016967773 RMSE: 3.5713947\n",
      "Validation loss: 11.284890174865723 RMSE: 3.359299\n",
      "Validation loss: 9.182456016540527 RMSE: 3.0302565\n",
      "128 2 2.0817340586774638\n",
      "Validation loss: 8.801844596862793 RMSE: 2.9667907\n",
      "Validation loss: 9.27142858505249 RMSE: 3.044902\n",
      "Validation loss: 11.527584075927734 RMSE: 3.3952296\n",
      "131 4 1.7143192813784447\n",
      "Validation loss: 19.308023929595947 RMSE: 4.3940897\n",
      "Validation loss: 10.87408995628357 RMSE: 3.2975886\n",
      "Validation loss: 9.685912132263184 RMSE: 3.1122198\n",
      "134 6 2.135651687470692\n",
      "Validation loss: 11.630506038665771 RMSE: 3.4103527\n",
      "Validation loss: 11.711899042129517 RMSE: 3.422265\n",
      "Validation loss: 15.397577285766602 RMSE: 3.9239745\n",
      "137 8 1.596133970430589\n",
      "Validation loss: 10.592550039291382 RMSE: 3.25462\n",
      "Validation loss: 15.083392143249512 RMSE: 3.8837342\n",
      "Validation loss: 12.081525087356567 RMSE: 3.475849\n",
      "140 10 1.4662003261861611\n",
      "Validation loss: 10.861766338348389 RMSE: 3.2957194\n",
      "Validation loss: 9.052496194839478 RMSE: 3.0087364\n",
      "Validation loss: 11.248417377471924 RMSE: 3.3538659\n",
      "143 12 2.6177802768915117\n",
      "Validation loss: 12.018516063690186 RMSE: 3.4667733\n",
      "Validation loss: 15.807446241378784 RMSE: 3.9758577\n",
      "Validation loss: 14.27371597290039 RMSE: 3.7780576\n",
      "146 14 1.5007219931960698\n",
      "Validation loss: 10.618696689605713 RMSE: 3.258634\n",
      "Validation loss: 11.69706106185913 RMSE: 3.4200966\n",
      "Validation loss: 14.064548015594482 RMSE: 3.7502732\n",
      "Validation loss: 10.0350980758667 RMSE: 3.1678221\n",
      "150 0 1.7766743697581164\n",
      "Validation loss: 12.274126529693604 RMSE: 3.503445\n",
      "Validation loss: 10.925572395324707 RMSE: 3.3053856\n",
      "Validation loss: 11.504686832427979 RMSE: 3.3918562\n",
      "153 2 2.039086731937493\n",
      "Validation loss: 12.492109775543213 RMSE: 3.5344179\n",
      "Validation loss: 18.007052302360535 RMSE: 4.2434716\n",
      "Validation loss: 13.163573741912842 RMSE: 3.628164\n",
      "156 4 1.361480155499875\n",
      "Validation loss: 15.152849435806274 RMSE: 3.8926659\n",
      "Validation loss: 8.433736324310303 RMSE: 2.9040895\n",
      "Validation loss: 13.016988039016724 RMSE: 3.6079063\n",
      "159 6 1.6944576789937285\n",
      "Validation loss: 9.8093900680542 RMSE: 3.1319945\n",
      "Validation loss: 17.72098970413208 RMSE: 4.209631\n",
      "Validation loss: 12.617048263549805 RMSE: 3.5520484\n",
      "162 8 1.204999249472023\n",
      "Validation loss: 9.245559453964233 RMSE: 3.040651\n",
      "Validation loss: 12.14279317855835 RMSE: 3.484651\n",
      "Validation loss: 14.078866004943848 RMSE: 3.7521815\n",
      "165 10 2.6478332357253\n",
      "Validation loss: 14.959249019622803 RMSE: 3.867719\n",
      "Validation loss: 11.71710729598999 RMSE: 3.423026\n",
      "Validation loss: 10.173224449157715 RMSE: 3.1895494\n",
      "168 12 1.7282131903579456\n",
      "Validation loss: 13.222350597381592 RMSE: 3.636255\n",
      "Validation loss: 13.836193084716797 RMSE: 3.7197037\n",
      "Validation loss: 11.623305320739746 RMSE: 3.409297\n",
      "171 14 2.723131385233644\n",
      "Validation loss: 15.268858909606934 RMSE: 3.9075387\n",
      "Validation loss: 12.944479942321777 RMSE: 3.5978436\n",
      "Validation loss: 9.632094383239746 RMSE: 3.1035616\n",
      "Validation loss: 15.297152519226074 RMSE: 3.9111574\n",
      "175 0 1.3131006576985902\n",
      "Validation loss: 11.434115886688232 RMSE: 3.3814368\n",
      "Validation loss: 15.567677021026611 RMSE: 3.9455898\n",
      "Validation loss: 12.553154945373535 RMSE: 3.5430434\n",
      "178 2 1.458857243201605\n",
      "Validation loss: 9.56592082977295 RMSE: 3.0928824\n",
      "Validation loss: 13.98874568939209 RMSE: 3.740153\n",
      "Validation loss: 11.810019969940186 RMSE: 3.4365711\n",
      "181 4 2.116765730327379\n",
      "Validation loss: 12.369636535644531 RMSE: 3.5170498\n",
      "Validation loss: 18.7359561920166 RMSE: 4.328505\n",
      "Validation loss: 13.753865718841553 RMSE: 3.7086205\n",
      "184 6 2.797959683172583\n",
      "Validation loss: 12.395983934402466 RMSE: 3.520793\n",
      "Validation loss: 13.526813507080078 RMSE: 3.6778817\n",
      "Validation loss: 14.991231441497803 RMSE: 3.8718514\n",
      "187 8 1.94131938265385\n",
      "Validation loss: 14.97712230682373 RMSE: 3.870029\n",
      "Validation loss: 10.61416220664978 RMSE: 3.2579381\n",
      "Validation loss: 12.676145076751709 RMSE: 3.5603576\n",
      "190 10 2.385950658819883\n",
      "Validation loss: 11.954972743988037 RMSE: 3.4575963\n",
      "Validation loss: 11.846903800964355 RMSE: 3.4419334\n",
      "Validation loss: 16.830892324447632 RMSE: 4.1025467\n",
      "193 12 2.474786820548857\n",
      "Validation loss: 13.198199272155762 RMSE: 3.6329324\n",
      "Validation loss: 13.874080181121826 RMSE: 3.7247927\n",
      "Validation loss: 15.262353420257568 RMSE: 3.906706\n",
      "196 14 1.3712859188060553\n",
      "Validation loss: 14.790787696838379 RMSE: 3.845879\n",
      "Validation loss: 15.588089942932129 RMSE: 3.9481752\n",
      "Validation loss: 12.744978427886963 RMSE: 3.570011\n",
      "Validation loss: 14.980031490325928 RMSE: 3.8704047\n",
      "Loaded trained model with success.\n",
      "Test loss: 5.809193244347205 Test RMSE: 2.4102268\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'freesolv', 'model_type': 'gin', 'model': {'num_layer': 3, 'emb_dim': 64, 'feat_dim': 64, 'drop_ratio': 0.5, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 778, 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'target': ['expt']}}\n",
      "Running on: cuda:1\n",
      "641\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/641\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 18.8817398644688\n",
      "Validation loss: 63.243974685668945 RMSE: 7.9526086\n",
      "Validation loss: 57.84972381591797 RMSE: 7.605901\n",
      "Validation loss: 50.85210418701172 RMSE: 7.1310663\n",
      "3 2 13.566222068848345\n",
      "Validation loss: 38.248579025268555 RMSE: 6.1845436\n",
      "Validation loss: 23.68028163909912 RMSE: 4.866239\n",
      "Validation loss: 16.18305540084839 RMSE: 4.022817\n",
      "6 4 10.393763263556236\n",
      "Validation loss: 18.256107807159424 RMSE: 4.2727165\n",
      "Validation loss: 13.641751289367676 RMSE: 3.693474\n",
      "Validation loss: 11.512739658355713 RMSE: 3.3930428\n",
      "9 6 4.916807243169125\n",
      "Validation loss: 12.721091270446777 RMSE: 3.566664\n",
      "Validation loss: 10.838859558105469 RMSE: 3.2922423\n",
      "Validation loss: 12.378345489501953 RMSE: 3.5182872\n",
      "12 8 7.566723692734334\n",
      "Validation loss: 11.996391296386719 RMSE: 3.4635806\n",
      "Validation loss: 11.851861000061035 RMSE: 3.442653\n",
      "Validation loss: 11.646575450897217 RMSE: 3.4127078\n",
      "15 10 4.908512623304432\n",
      "Validation loss: 11.77440595626831 RMSE: 3.4313855\n",
      "Validation loss: 12.633318901062012 RMSE: 3.5543377\n",
      "Validation loss: 12.068868637084961 RMSE: 3.4740279\n",
      "18 12 4.326212942828213\n",
      "Validation loss: 12.701020240783691 RMSE: 3.563849\n",
      "Validation loss: 12.89458417892456 RMSE: 3.590903\n",
      "Validation loss: 13.626482486724854 RMSE: 3.6914065\n",
      "21 14 4.038399990463604\n",
      "Validation loss: 12.428351402282715 RMSE: 3.5253868\n",
      "Validation loss: 13.603487014770508 RMSE: 3.6882906\n",
      "Validation loss: 13.255780220031738 RMSE: 3.6408486\n",
      "Validation loss: 13.549164295196533 RMSE: 3.680919\n",
      "25 0 3.4990872428144346\n",
      "Validation loss: 12.996859073638916 RMSE: 3.6051157\n",
      "Validation loss: 13.898856163024902 RMSE: 3.728117\n",
      "Validation loss: 13.597692966461182 RMSE: 3.687505\n",
      "28 2 1.942967770670955\n",
      "Validation loss: 12.964890956878662 RMSE: 3.600679\n",
      "Validation loss: 15.848569393157959 RMSE: 3.9810262\n",
      "Validation loss: 17.082589149475098 RMSE: 4.133109\n",
      "31 4 4.383433323566805\n",
      "Validation loss: 13.79960584640503 RMSE: 3.714782\n",
      "Validation loss: 13.139562129974365 RMSE: 3.6248534\n",
      "Validation loss: 15.84169864654541 RMSE: 3.980163\n",
      "34 6 4.072377103979047\n",
      "Validation loss: 13.279914855957031 RMSE: 3.644162\n",
      "Validation loss: 12.693740844726562 RMSE: 3.5628276\n",
      "Validation loss: 15.878044605255127 RMSE: 3.984727\n",
      "37 8 2.25045786516422\n",
      "Validation loss: 15.046064853668213 RMSE: 3.8789256\n",
      "Validation loss: 13.07996940612793 RMSE: 3.616624\n",
      "Validation loss: 15.334430694580078 RMSE: 3.91592\n",
      "40 10 3.5942590638945053\n",
      "Validation loss: 14.856508255004883 RMSE: 3.8544142\n",
      "Validation loss: 14.477910041809082 RMSE: 3.804985\n",
      "Validation loss: 16.33975601196289 RMSE: 4.0422463\n",
      "43 12 1.870406242149133\n",
      "Validation loss: 14.726670265197754 RMSE: 3.8375344\n",
      "Validation loss: 15.674269199371338 RMSE: 3.9590743\n",
      "Validation loss: 15.31987714767456 RMSE: 3.9140615\n",
      "46 14 3.3195098222487527\n",
      "Validation loss: 16.272942066192627 RMSE: 4.033973\n",
      "Validation loss: 14.281404495239258 RMSE: 3.7790742\n",
      "Validation loss: 14.872797012329102 RMSE: 3.8565264\n",
      "Validation loss: 15.783951759338379 RMSE: 3.972902\n",
      "50 0 2.439460933905769\n",
      "Validation loss: 13.485084056854248 RMSE: 3.672204\n",
      "Validation loss: 13.295758247375488 RMSE: 3.6463351\n",
      "Validation loss: 16.021161556243896 RMSE: 4.0026445\n",
      "53 2 3.1415000559200186\n",
      "Validation loss: 14.675172328948975 RMSE: 3.8308187\n",
      "Validation loss: 19.285223960876465 RMSE: 4.3914948\n",
      "Validation loss: 17.745491981506348 RMSE: 4.2125397\n",
      "56 4 2.378914730540158\n",
      "Validation loss: 16.253989219665527 RMSE: 4.0316234\n",
      "Validation loss: 14.577378273010254 RMSE: 3.8180332\n",
      "Validation loss: 14.46587085723877 RMSE: 3.8034024\n",
      "59 6 1.7961565904552244\n",
      "Validation loss: 16.3946590423584 RMSE: 4.0490317\n",
      "Validation loss: 14.044244289398193 RMSE: 3.7475648\n",
      "Validation loss: 12.811721801757812 RMSE: 3.5793467\n",
      "62 8 2.452923272589357\n",
      "Validation loss: 13.73893690109253 RMSE: 3.7066073\n",
      "Validation loss: 17.688365936279297 RMSE: 4.205754\n",
      "Validation loss: 12.410864353179932 RMSE: 3.5229058\n",
      "65 10 3.7399651831630183\n",
      "Validation loss: 13.112468004226685 RMSE: 3.621114\n",
      "Validation loss: 14.165219783782959 RMSE: 3.7636712\n",
      "Validation loss: 14.480971336364746 RMSE: 3.8053873\n",
      "68 12 2.6199694732189824\n",
      "Validation loss: 18.864388942718506 RMSE: 4.343315\n",
      "Validation loss: 16.456623077392578 RMSE: 4.0566764\n",
      "Validation loss: 13.43267297744751 RMSE: 3.6650615\n",
      "71 14 3.5005228054567543\n",
      "Validation loss: 19.64185905456543 RMSE: 4.431913\n",
      "Validation loss: 15.267786026000977 RMSE: 3.9074013\n",
      "Validation loss: 17.14657211303711 RMSE: 4.140842\n",
      "Validation loss: 13.939061880111694 RMSE: 3.7335052\n",
      "75 0 1.9742665326373743\n",
      "Validation loss: 14.726956367492676 RMSE: 3.8375711\n",
      "Validation loss: 16.42312717437744 RMSE: 4.0525455\n",
      "Validation loss: 17.101683616638184 RMSE: 4.1354184\n",
      "78 2 2.278132086039093\n",
      "Validation loss: 13.786421298980713 RMSE: 3.713007\n",
      "Validation loss: 20.34797954559326 RMSE: 4.5108733\n",
      "Validation loss: 15.97766923904419 RMSE: 3.9972076\n",
      "81 4 4.5055481147595104\n",
      "Validation loss: 21.4099702835083 RMSE: 4.6270914\n",
      "Validation loss: 15.113017082214355 RMSE: 3.8875468\n",
      "Validation loss: 13.72866439819336 RMSE: 3.7052212\n",
      "84 6 1.837943489028735\n",
      "Validation loss: 20.11962127685547 RMSE: 4.48549\n",
      "Validation loss: 19.94027328491211 RMSE: 4.465453\n",
      "Validation loss: 18.789809703826904 RMSE: 4.3347216\n",
      "87 8 2.722719364762245\n",
      "Validation loss: 19.85113525390625 RMSE: 4.4554615\n",
      "Validation loss: 17.201702117919922 RMSE: 4.1474934\n",
      "Validation loss: 16.943710803985596 RMSE: 4.116274\n",
      "90 10 3.4331383984735053\n",
      "Validation loss: 16.486868381500244 RMSE: 4.060403\n",
      "Validation loss: 20.900147438049316 RMSE: 4.5716677\n",
      "Validation loss: 15.794767379760742 RMSE: 3.9742627\n",
      "93 12 1.8412477932858349\n",
      "Validation loss: 19.298462867736816 RMSE: 4.393002\n",
      "Validation loss: 19.620431900024414 RMSE: 4.4294953\n",
      "Validation loss: 18.589570999145508 RMSE: 4.3115625\n",
      "96 14 2.866548473606131\n",
      "Validation loss: 17.683735847473145 RMSE: 4.2052035\n",
      "Validation loss: 19.533150672912598 RMSE: 4.4196324\n",
      "Validation loss: 16.679299354553223 RMSE: 4.0840297\n",
      "Validation loss: 23.528297424316406 RMSE: 4.850598\n",
      "100 0 1.5675167492625621\n",
      "Validation loss: 18.20419454574585 RMSE: 4.2666373\n",
      "Validation loss: 13.67867660522461 RMSE: 3.6984694\n",
      "Validation loss: 13.033641815185547 RMSE: 3.6102135\n",
      "103 2 1.504659917378677\n",
      "Validation loss: 18.39103627204895 RMSE: 4.2884774\n",
      "Validation loss: 18.03111743927002 RMSE: 4.246307\n",
      "Validation loss: 17.527234077453613 RMSE: 4.186554\n",
      "106 4 4.393741067227856\n",
      "Validation loss: 16.95166778564453 RMSE: 4.1172404\n",
      "Validation loss: 16.44734001159668 RMSE: 4.055532\n",
      "Validation loss: 16.629497528076172 RMSE: 4.077928\n",
      "109 6 1.3913676812314124\n",
      "Validation loss: 17.35753870010376 RMSE: 4.1662383\n",
      "Validation loss: 16.396575927734375 RMSE: 4.0492687\n",
      "Validation loss: 13.539706707000732 RMSE: 3.679634\n",
      "112 8 2.0908683991651396\n",
      "Validation loss: 17.09481644630432 RMSE: 4.134588\n",
      "Validation loss: 16.957290172576904 RMSE: 4.1179233\n",
      "Validation loss: 25.16444969177246 RMSE: 5.016418\n",
      "115 10 2.066223982037589\n",
      "Validation loss: 24.700525283813477 RMSE: 4.9699626\n",
      "Validation loss: 16.77223491668701 RMSE: 4.095392\n",
      "Validation loss: 18.188934326171875 RMSE: 4.2648487\n",
      "118 12 2.244836433512121\n",
      "Validation loss: 28.790393829345703 RMSE: 5.365668\n",
      "Validation loss: 19.08493423461914 RMSE: 4.368631\n",
      "Validation loss: 17.106457710266113 RMSE: 4.135996\n",
      "121 14 2.9430837509581402\n",
      "Validation loss: 13.246088981628418 RMSE: 3.6395178\n",
      "Validation loss: 13.462559700012207 RMSE: 3.6691358\n",
      "Validation loss: 16.996039390563965 RMSE: 4.1226254\n",
      "Validation loss: 17.333964824676514 RMSE: 4.163408\n",
      "125 0 1.7141857004659928\n",
      "Validation loss: 16.622358322143555 RMSE: 4.077053\n",
      "Validation loss: 13.771647453308105 RMSE: 3.7110171\n",
      "Validation loss: 15.057926177978516 RMSE: 3.8804543\n",
      "128 2 1.7804750689649913\n",
      "Validation loss: 15.173852920532227 RMSE: 3.8953629\n",
      "Validation loss: 16.145629405975342 RMSE: 4.018163\n",
      "Validation loss: 18.652562618255615 RMSE: 4.318861\n",
      "131 4 1.90916276321393\n",
      "Validation loss: 27.11983585357666 RMSE: 5.2076707\n",
      "Validation loss: 16.015263557434082 RMSE: 4.0019073\n",
      "Validation loss: 13.488112449645996 RMSE: 3.6726162\n",
      "134 6 3.8708062214279972\n",
      "Validation loss: 15.339691638946533 RMSE: 3.916592\n",
      "Validation loss: 23.78861713409424 RMSE: 4.877358\n",
      "Validation loss: 20.726868152618408 RMSE: 4.552677\n",
      "137 8 1.853431139896455\n",
      "Validation loss: 20.367015838623047 RMSE: 4.512983\n",
      "Validation loss: 15.709417819976807 RMSE: 3.963511\n",
      "Validation loss: 16.270849227905273 RMSE: 4.0337143\n",
      "140 10 1.1852106346661448\n",
      "Validation loss: 16.977558135986328 RMSE: 4.1203833\n",
      "Validation loss: 15.991021156311035 RMSE: 3.9988775\n",
      "Validation loss: 24.194799423217773 RMSE: 4.918821\n",
      "143 12 1.8880745179777336\n",
      "Validation loss: 19.43224334716797 RMSE: 4.408202\n",
      "Validation loss: 20.483519077301025 RMSE: 4.5258727\n",
      "Validation loss: 17.29178762435913 RMSE: 4.1583395\n",
      "146 14 1.857445481402892\n",
      "Validation loss: 16.47345280647278 RMSE: 4.05875\n",
      "Validation loss: 14.316602230072021 RMSE: 3.7837286\n",
      "Validation loss: 23.259575843811035 RMSE: 4.822818\n",
      "Validation loss: 25.185380935668945 RMSE: 5.0185037\n",
      "150 0 1.6554159239177335\n",
      "Validation loss: 16.295522689819336 RMSE: 4.0367713\n",
      "Validation loss: 28.006349563598633 RMSE: 5.2921023\n",
      "Validation loss: 20.66896629333496 RMSE: 4.546313\n",
      "153 2 3.3169766775639897\n",
      "Validation loss: 18.617183685302734 RMSE: 4.3147635\n",
      "Validation loss: 21.273362159729004 RMSE: 4.6123056\n",
      "Validation loss: 23.307523727416992 RMSE: 4.8277864\n",
      "156 4 1.528381091870942\n",
      "Validation loss: 30.022205352783203 RMSE: 5.479253\n",
      "Validation loss: 16.29716682434082 RMSE: 4.0369754\n",
      "Validation loss: 13.0829496383667 RMSE: 3.6170359\n",
      "159 6 2.602082825043494\n",
      "Validation loss: 15.150465488433838 RMSE: 3.89236\n",
      "Validation loss: 20.543615341186523 RMSE: 4.5325065\n",
      "Validation loss: 24.738259315490723 RMSE: 4.973757\n",
      "162 8 2.031454707992603\n",
      "Validation loss: 21.496277809143066 RMSE: 4.636408\n",
      "Validation loss: 15.453603744506836 RMSE: 3.9311075\n",
      "Validation loss: 20.034326553344727 RMSE: 4.475972\n",
      "165 10 1.6635679256255915\n",
      "Validation loss: 16.677865982055664 RMSE: 4.083854\n",
      "Validation loss: 18.01866340637207 RMSE: 4.2448397\n",
      "Validation loss: 17.7155122756958 RMSE: 4.20898\n",
      "168 12 1.615022796487886\n",
      "Validation loss: 21.36660408973694 RMSE: 4.622402\n",
      "Validation loss: 14.570233345031738 RMSE: 3.817097\n",
      "Validation loss: 21.368090629577637 RMSE: 4.622563\n",
      "171 14 2.494464821941075\n",
      "Validation loss: 16.40574026107788 RMSE: 4.0504\n",
      "Validation loss: 17.317562103271484 RMSE: 4.1614375\n",
      "Validation loss: 13.354547500610352 RMSE: 3.6543875\n",
      "Validation loss: 16.14739227294922 RMSE: 4.0183816\n",
      "175 0 2.4539919435486635\n",
      "Validation loss: 18.060111045837402 RMSE: 4.249719\n",
      "Validation loss: 19.758112907409668 RMSE: 4.4450107\n",
      "Validation loss: 17.998440742492676 RMSE: 4.242457\n",
      "178 2 2.022840697340516\n",
      "Validation loss: 17.89298391342163 RMSE: 4.2300096\n",
      "Validation loss: 19.955106735229492 RMSE: 4.467114\n",
      "Validation loss: 18.66226291656494 RMSE: 4.3199844\n",
      "181 4 1.3184622136259962\n",
      "Validation loss: 18.367305755615234 RMSE: 4.28571\n",
      "Validation loss: 17.903347969055176 RMSE: 4.2312346\n",
      "Validation loss: 14.368186950683594 RMSE: 3.790539\n",
      "184 6 2.741707986393453\n",
      "Validation loss: 17.82293701171875 RMSE: 4.221722\n",
      "Validation loss: 13.13404369354248 RMSE: 3.624092\n",
      "Validation loss: 20.73547649383545 RMSE: 4.553622\n",
      "187 8 1.92014767549713\n",
      "Validation loss: 19.023788452148438 RMSE: 4.361626\n",
      "Validation loss: 15.592898845672607 RMSE: 3.9487848\n",
      "Validation loss: 16.36764407157898 RMSE: 4.0456944\n",
      "190 10 1.6821798753578208\n",
      "Validation loss: 14.589859962463379 RMSE: 3.8196673\n",
      "Validation loss: 22.50678515434265 RMSE: 4.7441316\n",
      "Validation loss: 18.159679412841797 RMSE: 4.261417\n",
      "193 12 2.4700124217146526\n",
      "Validation loss: 19.003192901611328 RMSE: 4.359266\n",
      "Validation loss: 15.5701904296875 RMSE: 3.9459078\n",
      "Validation loss: 15.245422840118408 RMSE: 3.904539\n",
      "196 14 1.7768633496890185\n",
      "Validation loss: 13.732136726379395 RMSE: 3.7056897\n",
      "Validation loss: 14.366148948669434 RMSE: 3.7902703\n",
      "Validation loss: 17.402101516723633 RMSE: 4.171582\n",
      "Validation loss: 12.382949590682983 RMSE: 3.5189416\n",
      "Loaded trained model with success.\n",
      "Test loss: 8.210954663386712 Test RMSE: 2.8654764\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'freesolv', 'model_type': 'gin', 'model': {'num_layer': 3, 'emb_dim': 64, 'feat_dim': 64, 'drop_ratio': 0.5, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 779, 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'target': ['expt']}}\n",
      "Running on: cuda:1\n",
      "641\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/641\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 25.785404946194255\n",
      "Validation loss: 72.00831604003906 RMSE: 8.485772\n",
      "Validation loss: 66.3345947265625 RMSE: 8.144606\n",
      "Validation loss: 58.95440673828125 RMSE: 7.678177\n",
      "3 2 14.212657018097287\n",
      "Validation loss: 47.38847351074219 RMSE: 6.883929\n",
      "Validation loss: 29.966188430786133 RMSE: 5.474138\n",
      "Validation loss: 14.863654136657715 RMSE: 3.8553407\n",
      "6 4 7.900253256752054\n",
      "Validation loss: 15.960797786712646 RMSE: 3.9950967\n",
      "Validation loss: 14.780740737915039 RMSE: 3.8445725\n",
      "Validation loss: 14.32574462890625 RMSE: 3.7849364\n",
      "9 6 4.731600704117721\n",
      "Validation loss: 14.311692714691162 RMSE: 3.7830799\n",
      "Validation loss: 16.129009246826172 RMSE: 4.016094\n",
      "Validation loss: 14.9542818069458 RMSE: 3.8670769\n",
      "12 8 5.897524166069575\n",
      "Validation loss: 14.33463716506958 RMSE: 3.7861114\n",
      "Validation loss: 13.965157985687256 RMSE: 3.7369986\n",
      "Validation loss: 13.999473094940186 RMSE: 3.741587\n",
      "15 10 4.048144605731138\n",
      "Validation loss: 14.832922458648682 RMSE: 3.8513532\n",
      "Validation loss: 14.991544723510742 RMSE: 3.8718917\n",
      "Validation loss: 17.052412509918213 RMSE: 4.1294565\n",
      "18 12 4.358374658751271\n",
      "Validation loss: 17.032032012939453 RMSE: 4.1269884\n",
      "Validation loss: 19.226855278015137 RMSE: 4.384844\n",
      "Validation loss: 17.62562370300293 RMSE: 4.1982884\n",
      "21 14 5.01785259898924\n",
      "Validation loss: 25.501672744750977 RMSE: 5.049918\n",
      "Validation loss: 22.715542793273926 RMSE: 4.7660823\n",
      "Validation loss: 30.726619720458984 RMSE: 5.54316\n",
      "Validation loss: 19.567035675048828 RMSE: 4.423464\n",
      "25 0 3.3109054842159855\n",
      "Validation loss: 20.34507942199707 RMSE: 4.510552\n",
      "Validation loss: 18.253561973571777 RMSE: 4.272419\n",
      "Validation loss: 20.083102226257324 RMSE: 4.4814177\n",
      "28 2 3.5757351557726604\n",
      "Validation loss: 22.500518798828125 RMSE: 4.743471\n",
      "Validation loss: 20.5617036819458 RMSE: 4.5345016\n",
      "Validation loss: 18.171618938446045 RMSE: 4.2628183\n",
      "31 4 3.695989836084303\n",
      "Validation loss: 17.450818061828613 RMSE: 4.1774173\n",
      "Validation loss: 24.638750076293945 RMSE: 4.9637437\n",
      "Validation loss: 27.857556343078613 RMSE: 5.2780256\n",
      "34 6 2.793172124377395\n",
      "Validation loss: 23.670534133911133 RMSE: 4.865237\n",
      "Validation loss: 20.662909507751465 RMSE: 4.5456476\n",
      "Validation loss: 25.097542762756348 RMSE: 5.0097446\n",
      "37 8 3.3741586999737123\n",
      "Validation loss: 18.316588401794434 RMSE: 4.2797885\n",
      "Validation loss: 19.10029411315918 RMSE: 4.370388\n",
      "Validation loss: 32.70360040664673 RMSE: 5.718706\n",
      "40 10 3.611648000832101\n",
      "Validation loss: 21.283997535705566 RMSE: 4.613458\n",
      "Validation loss: 24.976642608642578 RMSE: 4.9976635\n",
      "Validation loss: 21.162672996520996 RMSE: 4.600291\n",
      "43 12 5.603581938493613\n",
      "Validation loss: 20.821712493896484 RMSE: 4.5630817\n",
      "Validation loss: 21.61233901977539 RMSE: 4.6489077\n",
      "Validation loss: 21.52775478363037 RMSE: 4.639801\n",
      "46 14 2.5421652185951866\n",
      "Validation loss: 22.153403282165527 RMSE: 4.7067404\n",
      "Validation loss: 16.802568435668945 RMSE: 4.099094\n",
      "Validation loss: 19.577054023742676 RMSE: 4.4245963\n",
      "Validation loss: 20.600089073181152 RMSE: 4.538732\n",
      "50 0 3.7270140933972487\n",
      "Validation loss: 26.541839599609375 RMSE: 5.1518774\n",
      "Validation loss: 23.640369415283203 RMSE: 4.8621364\n",
      "Validation loss: 30.454235076904297 RMSE: 5.5185356\n",
      "53 2 1.9710194945932302\n",
      "Validation loss: 26.127775192260742 RMSE: 5.111533\n",
      "Validation loss: 23.55580234527588 RMSE: 4.8534317\n",
      "Validation loss: 14.643638610839844 RMSE: 3.8267004\n",
      "56 4 1.9221390010971775\n",
      "Validation loss: 15.106613636016846 RMSE: 3.8867226\n",
      "Validation loss: 14.912362575531006 RMSE: 3.8616529\n",
      "Validation loss: 14.735955238342285 RMSE: 3.8387442\n",
      "59 6 3.8050149018990593\n",
      "Validation loss: 21.304235458374023 RMSE: 4.615651\n",
      "Validation loss: 21.30091667175293 RMSE: 4.615291\n",
      "Validation loss: 21.049696922302246 RMSE: 4.5879946\n",
      "62 8 3.583734650148173\n",
      "Validation loss: 24.972250938415527 RMSE: 4.997224\n",
      "Validation loss: 22.249201774597168 RMSE: 4.716906\n",
      "Validation loss: 22.869179725646973 RMSE: 4.782173\n",
      "65 10 2.504521013715478\n",
      "Validation loss: 15.859333992004395 RMSE: 3.982378\n",
      "Validation loss: 23.473788261413574 RMSE: 4.8449755\n",
      "Validation loss: 23.473411560058594 RMSE: 4.8449364\n",
      "68 12 2.5476556916192976\n",
      "Validation loss: 17.03765869140625 RMSE: 4.12767\n",
      "Validation loss: 18.167386054992676 RMSE: 4.262322\n",
      "Validation loss: 23.854928016662598 RMSE: 4.8841505\n",
      "71 14 2.6851533110838406\n",
      "Validation loss: 23.156845092773438 RMSE: 4.8121567\n",
      "Validation loss: 17.385347366333008 RMSE: 4.169574\n",
      "Validation loss: 18.11629867553711 RMSE: 4.2563243\n",
      "Validation loss: 19.7274112701416 RMSE: 4.4415555\n",
      "75 0 3.742890866492363\n",
      "Validation loss: 18.991931915283203 RMSE: 4.3579736\n",
      "Validation loss: 16.5885009765625 RMSE: 4.0728984\n",
      "Validation loss: 19.278545379638672 RMSE: 4.390734\n",
      "78 2 4.481165331795929\n",
      "Validation loss: 16.439148426055908 RMSE: 4.0545216\n",
      "Validation loss: 18.202223777770996 RMSE: 4.2664065\n",
      "Validation loss: 16.901037216186523 RMSE: 4.1110873\n",
      "81 4 3.3657067869515735\n",
      "Validation loss: 16.69155979156494 RMSE: 4.0855303\n",
      "Validation loss: 19.36135482788086 RMSE: 4.400154\n",
      "Validation loss: 19.754796981811523 RMSE: 4.444637\n",
      "84 6 3.3256557835871736\n",
      "Validation loss: 22.671765327453613 RMSE: 4.7614875\n",
      "Validation loss: 17.123223781585693 RMSE: 4.1380215\n",
      "Validation loss: 16.494072437286377 RMSE: 4.0612893\n",
      "87 8 2.8205409539006445\n",
      "Validation loss: 17.479628562927246 RMSE: 4.180865\n",
      "Validation loss: 14.775216102600098 RMSE: 3.8438544\n",
      "Validation loss: 14.1810941696167 RMSE: 3.7657795\n",
      "90 10 2.0281106289143667\n",
      "Validation loss: 17.100183486938477 RMSE: 4.1352367\n",
      "Validation loss: 17.008790016174316 RMSE: 4.1241713\n",
      "Validation loss: 21.519141912460327 RMSE: 4.6388726\n",
      "93 12 4.179114828374702\n",
      "Validation loss: 21.185587882995605 RMSE: 4.6027803\n",
      "Validation loss: 22.69757080078125 RMSE: 4.764197\n",
      "Validation loss: 22.053844451904297 RMSE: 4.6961527\n",
      "96 14 1.941346590062248\n",
      "Validation loss: 20.772682189941406 RMSE: 4.557706\n",
      "Validation loss: 19.124675750732422 RMSE: 4.373177\n",
      "Validation loss: 17.12606906890869 RMSE: 4.1383653\n",
      "Validation loss: 15.571229934692383 RMSE: 3.9460397\n",
      "100 0 5.616287370804023\n",
      "Validation loss: 17.12596845626831 RMSE: 4.1383533\n",
      "Validation loss: 19.01064968109131 RMSE: 4.3601203\n",
      "Validation loss: 23.096174240112305 RMSE: 4.805848\n",
      "103 2 3.7407458248631404\n",
      "Validation loss: 19.217244148254395 RMSE: 4.3837476\n",
      "Validation loss: 19.11325454711914 RMSE: 4.371871\n",
      "Validation loss: 18.813562870025635 RMSE: 4.3374605\n",
      "106 4 6.398614182317732\n",
      "Validation loss: 17.86123561859131 RMSE: 4.2262554\n",
      "Validation loss: 21.689599990844727 RMSE: 4.65721\n",
      "Validation loss: 13.849486827850342 RMSE: 3.7214897\n",
      "109 6 2.164640226279503\n",
      "Validation loss: 16.391303539276123 RMSE: 4.0486174\n",
      "Validation loss: 21.309105396270752 RMSE: 4.6161785\n",
      "Validation loss: 16.6826114654541 RMSE: 4.084435\n",
      "112 8 2.2895397242494666\n",
      "Validation loss: 17.676229000091553 RMSE: 4.2043104\n",
      "Validation loss: 31.27588176727295 RMSE: 5.5924845\n",
      "Validation loss: 18.736005783081055 RMSE: 4.3285108\n",
      "115 10 2.0681450824492495\n",
      "Validation loss: 22.306028366088867 RMSE: 4.722926\n",
      "Validation loss: 20.59938144683838 RMSE: 4.5386534\n",
      "Validation loss: 27.103920936584473 RMSE: 5.2061424\n",
      "118 12 1.7719177945253595\n",
      "Validation loss: 21.206789016723633 RMSE: 4.6050825\n",
      "Validation loss: 18.874767303466797 RMSE: 4.3445096\n",
      "Validation loss: 16.560093879699707 RMSE: 4.06941\n",
      "121 14 1.5332915993955925\n",
      "Validation loss: 21.932893753051758 RMSE: 4.6832566\n",
      "Validation loss: 15.458853006362915 RMSE: 3.9317749\n",
      "Validation loss: 19.480606079101562 RMSE: 4.4136834\n",
      "Validation loss: 19.577963829040527 RMSE: 4.4246993\n",
      "125 0 2.4822970134847937\n",
      "Validation loss: 18.738176345825195 RMSE: 4.3287616\n",
      "Validation loss: 17.88851308822632 RMSE: 4.229481\n",
      "Validation loss: 19.579383850097656 RMSE: 4.42486\n",
      "128 2 2.2266824512945744\n",
      "Validation loss: 18.461532592773438 RMSE: 4.296688\n",
      "Validation loss: 17.905852794647217 RMSE: 4.2315307\n",
      "Validation loss: 21.606511116027832 RMSE: 4.64828\n",
      "131 4 3.0863278794564915\n",
      "Validation loss: 26.30638885498047 RMSE: 5.128976\n",
      "Validation loss: 21.184514045715332 RMSE: 4.602664\n",
      "Validation loss: 22.075600624084473 RMSE: 4.6984673\n",
      "134 6 1.346322920050601\n",
      "Validation loss: 18.499172687530518 RMSE: 4.3010664\n",
      "Validation loss: 18.259580612182617 RMSE: 4.2731233\n",
      "Validation loss: 15.816558837890625 RMSE: 3.9770036\n",
      "137 8 5.432031042877583\n",
      "Validation loss: 24.381986141204834 RMSE: 4.9378123\n",
      "Validation loss: 15.713948249816895 RMSE: 3.9640822\n",
      "Validation loss: 22.845796585083008 RMSE: 4.7797275\n",
      "140 10 1.1879697606670172\n",
      "Validation loss: 21.740817070007324 RMSE: 4.6627054\n",
      "Validation loss: 23.068697929382324 RMSE: 4.8029885\n",
      "Validation loss: 31.856005668640137 RMSE: 5.6441126\n",
      "143 12 2.5743980180596164\n",
      "Validation loss: 16.110119819641113 RMSE: 4.0137415\n",
      "Validation loss: 19.843149185180664 RMSE: 4.454565\n",
      "Validation loss: 20.524773120880127 RMSE: 4.530427\n",
      "146 14 2.789503107081729\n",
      "Validation loss: 24.298501014709473 RMSE: 4.929351\n",
      "Validation loss: 22.36738109588623 RMSE: 4.729417\n",
      "Validation loss: 19.015851974487305 RMSE: 4.360717\n",
      "Validation loss: 23.722854614257812 RMSE: 4.8706107\n",
      "150 0 1.9996378401311643\n",
      "Validation loss: 19.180580139160156 RMSE: 4.379564\n",
      "Validation loss: 16.635748863220215 RMSE: 4.0786943\n",
      "Validation loss: 22.517821311950684 RMSE: 4.7452946\n",
      "153 2 2.647548060652571\n",
      "Validation loss: 22.88148021697998 RMSE: 4.7834587\n",
      "Validation loss: 17.116491317749023 RMSE: 4.137208\n",
      "Validation loss: 19.296114921569824 RMSE: 4.3927345\n",
      "156 4 1.1755073209206182\n",
      "Validation loss: 19.82737159729004 RMSE: 4.452794\n",
      "Validation loss: 20.039567947387695 RMSE: 4.4765573\n",
      "Validation loss: 23.96493625640869 RMSE: 4.895399\n",
      "159 6 1.6390998830749433\n",
      "Validation loss: 33.647335052490234 RMSE: 5.800632\n",
      "Validation loss: 18.261515617370605 RMSE: 4.2733493\n",
      "Validation loss: 22.02567195892334 RMSE: 4.6931515\n",
      "162 8 2.354642202982399\n",
      "Validation loss: 18.499072074890137 RMSE: 4.301055\n",
      "Validation loss: 23.79344367980957 RMSE: 4.8778524\n",
      "Validation loss: 20.26748752593994 RMSE: 4.501942\n",
      "165 10 2.724573668626473\n",
      "Validation loss: 20.069541215896606 RMSE: 4.479904\n",
      "Validation loss: 23.75233745574951 RMSE: 4.8736367\n",
      "Validation loss: 21.931504249572754 RMSE: 4.683108\n",
      "168 12 2.584633171407061\n",
      "Validation loss: 28.61622667312622 RMSE: 5.3494134\n",
      "Validation loss: 17.807573318481445 RMSE: 4.219902\n",
      "Validation loss: 15.820661544799805 RMSE: 3.97752\n",
      "171 14 2.226668005991811\n",
      "Validation loss: 20.38853168487549 RMSE: 4.5153666\n",
      "Validation loss: 21.957162857055664 RMSE: 4.685847\n",
      "Validation loss: 21.23041534423828 RMSE: 4.6076474\n",
      "Validation loss: 25.145777702331543 RMSE: 5.014557\n",
      "175 0 1.4664054501428763\n",
      "Validation loss: 22.094724655151367 RMSE: 4.7005024\n",
      "Validation loss: 23.98597240447998 RMSE: 4.897548\n",
      "Validation loss: 18.212915420532227 RMSE: 4.2676597\n",
      "178 2 2.1016494653022075\n",
      "Validation loss: 25.51577854156494 RMSE: 5.0513144\n",
      "Validation loss: 21.958508729934692 RMSE: 4.6859913\n",
      "Validation loss: 19.89297103881836 RMSE: 4.4601536\n",
      "181 4 1.8115010464463237\n",
      "Validation loss: 24.355846881866455 RMSE: 4.9351645\n",
      "Validation loss: 20.186191082000732 RMSE: 4.4929047\n",
      "Validation loss: 26.36897850036621 RMSE: 5.135073\n",
      "184 6 2.0563107487254935\n",
      "Validation loss: 15.258034706115723 RMSE: 3.9061534\n",
      "Validation loss: 28.40216064453125 RMSE: 5.329367\n",
      "Validation loss: 19.315767288208008 RMSE: 4.394971\n",
      "187 8 2.0516600473145354\n",
      "Validation loss: 22.196444511413574 RMSE: 4.7113104\n",
      "Validation loss: 24.588749885559082 RMSE: 4.9587045\n",
      "Validation loss: 22.150461196899414 RMSE: 4.706427\n",
      "190 10 1.7605019724411743\n",
      "Validation loss: 22.017991065979004 RMSE: 4.692333\n",
      "Validation loss: 24.957271575927734 RMSE: 4.995725\n",
      "Validation loss: 22.602478981018066 RMSE: 4.754206\n",
      "193 12 0.8848749095633623\n",
      "Validation loss: 19.444961547851562 RMSE: 4.409644\n",
      "Validation loss: 21.369406700134277 RMSE: 4.6227055\n",
      "Validation loss: 21.032776832580566 RMSE: 4.5861506\n",
      "196 14 3.4218577725096297\n",
      "Validation loss: 23.8311710357666 RMSE: 4.8817177\n",
      "Validation loss: 18.913521766662598 RMSE: 4.3489676\n",
      "Validation loss: 20.459194660186768 RMSE: 4.523184\n",
      "Validation loss: 17.988619804382324 RMSE: 4.2412996\n",
      "Loaded trained model with success.\n",
      "Test loss: 8.857221280611478 Test RMSE: 2.9761083\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'freesolv', 'model_type': 'gin', 'model': {'num_layer': 3, 'emb_dim': 64, 'feat_dim': 64, 'drop_ratio': 0.5, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 780, 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'target': ['expt']}}\n",
      "Running on: cuda:1\n",
      "641\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/641\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 14.55480720236905\n",
      "Validation loss: 68.15350723266602 RMSE: 8.255514\n",
      "Validation loss: 61.728397369384766 RMSE: 7.8567424\n",
      "Validation loss: 53.83870506286621 RMSE: 7.3374867\n",
      "3 2 16.091362961529658\n",
      "Validation loss: 40.317444801330566 RMSE: 6.3496017\n",
      "Validation loss: 20.541828632354736 RMSE: 4.5323095\n",
      "Validation loss: 12.556309223175049 RMSE: 3.5434883\n",
      "6 4 8.158970394228117\n",
      "Validation loss: 15.10108470916748 RMSE: 3.8860114\n",
      "Validation loss: 16.046303749084473 RMSE: 4.0057836\n",
      "Validation loss: 13.222240924835205 RMSE: 3.6362398\n",
      "9 6 13.202222533496775\n",
      "Validation loss: 11.413317680358887 RMSE: 3.37836\n",
      "Validation loss: 12.291213989257812 RMSE: 3.5058827\n",
      "Validation loss: 11.14237117767334 RMSE: 3.338019\n",
      "12 8 4.56644385128515\n",
      "Validation loss: 10.96463918685913 RMSE: 3.3112895\n",
      "Validation loss: 13.006763458251953 RMSE: 3.6064892\n",
      "Validation loss: 10.649600505828857 RMSE: 3.2633724\n",
      "15 10 7.009584599029722\n",
      "Validation loss: 10.878626823425293 RMSE: 3.2982762\n",
      "Validation loss: 11.903934001922607 RMSE: 3.450208\n",
      "Validation loss: 13.496811866760254 RMSE: 3.673801\n",
      "18 12 4.557123560389968\n",
      "Validation loss: 11.946247577667236 RMSE: 3.4563344\n",
      "Validation loss: 11.758760929107666 RMSE: 3.429105\n",
      "Validation loss: 11.91904878616333 RMSE: 3.4523976\n",
      "21 14 5.188959554503335\n",
      "Validation loss: 12.515216827392578 RMSE: 3.5376852\n",
      "Validation loss: 12.551653861999512 RMSE: 3.5428314\n",
      "Validation loss: 17.123894691467285 RMSE: 4.138103\n",
      "Validation loss: 16.629953861236572 RMSE: 4.0779843\n",
      "25 0 3.6021715540803916\n",
      "Validation loss: 14.36980152130127 RMSE: 3.7907522\n",
      "Validation loss: 15.154288291931152 RMSE: 3.892851\n",
      "Validation loss: 20.217406272888184 RMSE: 4.4963765\n",
      "28 2 2.6148663548450717\n",
      "Validation loss: 18.241299152374268 RMSE: 4.270983\n",
      "Validation loss: 16.76656675338745 RMSE: 4.0947003\n",
      "Validation loss: 15.762922286987305 RMSE: 3.9702547\n",
      "31 4 4.032886721484524\n",
      "Validation loss: 13.789748191833496 RMSE: 3.713455\n",
      "Validation loss: 16.802617073059082 RMSE: 4.0990996\n",
      "Validation loss: 19.99875259399414 RMSE: 4.471996\n",
      "34 6 2.9544675719888542\n",
      "Validation loss: 16.238789558410645 RMSE: 4.029738\n",
      "Validation loss: 17.922021865844727 RMSE: 4.2334404\n",
      "Validation loss: 14.504121780395508 RMSE: 3.8084278\n",
      "37 8 4.275726483089015\n",
      "Validation loss: 17.089402198791504 RMSE: 4.133933\n",
      "Validation loss: 14.153400421142578 RMSE: 3.7621005\n",
      "Validation loss: 16.104256629943848 RMSE: 4.013011\n",
      "40 10 3.867476198451591\n",
      "Validation loss: 14.809701442718506 RMSE: 3.8483377\n",
      "Validation loss: 22.66555118560791 RMSE: 4.760835\n",
      "Validation loss: 15.27225637435913 RMSE: 3.9079733\n",
      "43 12 4.258090026217123\n",
      "Validation loss: 17.5709547996521 RMSE: 4.1917725\n",
      "Validation loss: 17.99711799621582 RMSE: 4.242301\n",
      "Validation loss: 19.645767211914062 RMSE: 4.4323545\n",
      "46 14 2.076007960311949\n",
      "Validation loss: 17.127293586730957 RMSE: 4.1385136\n",
      "Validation loss: 18.801735401153564 RMSE: 4.336097\n",
      "Validation loss: 19.834674835205078 RMSE: 4.4536138\n",
      "Validation loss: 18.52170181274414 RMSE: 4.3036847\n",
      "50 0 5.540348108688847\n",
      "Validation loss: 15.05768632888794 RMSE: 3.8804233\n",
      "Validation loss: 16.51906394958496 RMSE: 4.064365\n",
      "Validation loss: 12.019259929656982 RMSE: 3.4668803\n",
      "53 2 4.90201388873501\n",
      "Validation loss: 14.982587337493896 RMSE: 3.8707347\n",
      "Validation loss: 18.07710838317871 RMSE: 4.2517185\n",
      "Validation loss: 19.63300323486328 RMSE: 4.4309144\n",
      "56 4 2.8945595429584996\n",
      "Validation loss: 17.536993980407715 RMSE: 4.187719\n",
      "Validation loss: 18.27323627471924 RMSE: 4.27472\n",
      "Validation loss: 10.948357820510864 RMSE: 3.3088303\n",
      "59 6 2.7432893239113496\n",
      "Validation loss: 15.159666061401367 RMSE: 3.8935418\n",
      "Validation loss: 14.235439777374268 RMSE: 3.7729878\n",
      "Validation loss: 13.526069641113281 RMSE: 3.6777806\n",
      "62 8 3.3338346872304805\n",
      "Validation loss: 14.064034461975098 RMSE: 3.7502046\n",
      "Validation loss: 15.88264274597168 RMSE: 3.9853036\n",
      "Validation loss: 14.604947566986084 RMSE: 3.8216422\n",
      "65 10 4.087005927809798\n",
      "Validation loss: 15.582849502563477 RMSE: 3.9475117\n",
      "Validation loss: 16.238174438476562 RMSE: 4.0296617\n",
      "Validation loss: 16.145288467407227 RMSE: 4.0181203\n",
      "68 12 1.652945508159509\n",
      "Validation loss: 15.752631187438965 RMSE: 3.9689584\n",
      "Validation loss: 15.821518421173096 RMSE: 3.9776273\n",
      "Validation loss: 14.503514766693115 RMSE: 3.808348\n",
      "71 14 2.408563561013656\n",
      "Validation loss: 14.683917045593262 RMSE: 3.83196\n",
      "Validation loss: 21.29902458190918 RMSE: 4.6150866\n",
      "Validation loss: 14.59077262878418 RMSE: 3.8197865\n",
      "Validation loss: 15.054724216461182 RMSE: 3.8800418\n",
      "75 0 2.6831392406083503\n",
      "Validation loss: 15.485316276550293 RMSE: 3.9351387\n",
      "Validation loss: 15.499563217163086 RMSE: 3.9369485\n",
      "Validation loss: 13.030036449432373 RMSE: 3.6097143\n",
      "78 2 2.0585396874065354\n",
      "Validation loss: 13.340407371520996 RMSE: 3.6524522\n",
      "Validation loss: 12.56992483139038 RMSE: 3.545409\n",
      "Validation loss: 15.030197143554688 RMSE: 3.8768797\n",
      "81 4 2.36714288961356\n",
      "Validation loss: 16.3499116897583 RMSE: 4.0435023\n",
      "Validation loss: 14.780416488647461 RMSE: 3.8445306\n",
      "Validation loss: 16.05395269393921 RMSE: 4.0067387\n",
      "84 6 1.4236541817790482\n",
      "Validation loss: 13.533339500427246 RMSE: 3.6787686\n",
      "Validation loss: 20.42689609527588 RMSE: 4.5196123\n",
      "Validation loss: 19.972694396972656 RMSE: 4.469082\n",
      "87 8 3.49929040378714\n",
      "Validation loss: 13.678316354751587 RMSE: 3.6984205\n",
      "Validation loss: 13.996007919311523 RMSE: 3.741124\n",
      "Validation loss: 17.230268955230713 RMSE: 4.1509356\n",
      "90 10 1.8355530945899505\n",
      "Validation loss: 17.872561931610107 RMSE: 4.2275953\n",
      "Validation loss: 16.403544425964355 RMSE: 4.050129\n",
      "Validation loss: 16.750134468078613 RMSE: 4.092693\n",
      "93 12 3.5951001640992777\n",
      "Validation loss: 12.751811504364014 RMSE: 3.5709677\n",
      "Validation loss: 16.866154670715332 RMSE: 4.106843\n",
      "Validation loss: 15.2783522605896 RMSE: 3.9087534\n",
      "96 14 1.5754600512356514\n",
      "Validation loss: 15.250332832336426 RMSE: 3.9051673\n",
      "Validation loss: 15.259899616241455 RMSE: 3.906392\n",
      "Validation loss: 11.729609966278076 RMSE: 3.4248517\n",
      "Validation loss: 11.148589849472046 RMSE: 3.3389504\n",
      "100 0 1.5975268147573107\n",
      "Validation loss: 10.300317764282227 RMSE: 3.209411\n",
      "Validation loss: 14.039482116699219 RMSE: 3.74693\n",
      "Validation loss: 13.490848064422607 RMSE: 3.6729891\n",
      "103 2 1.6788229837606354\n",
      "Validation loss: 10.089036464691162 RMSE: 3.1763244\n",
      "Validation loss: 12.740320205688477 RMSE: 3.5693586\n",
      "Validation loss: 16.8881893157959 RMSE: 4.109524\n",
      "106 4 2.4217421212065546\n",
      "Validation loss: 15.037944316864014 RMSE: 3.877879\n",
      "Validation loss: 13.589835166931152 RMSE: 3.6864393\n",
      "Validation loss: 14.043538093566895 RMSE: 3.747471\n",
      "109 6 2.5792748066330398\n",
      "Validation loss: 17.16520118713379 RMSE: 4.1430907\n",
      "Validation loss: 13.783987045288086 RMSE: 3.7126794\n",
      "Validation loss: 13.39946985244751 RMSE: 3.6605287\n",
      "112 8 1.592031619630325\n",
      "Validation loss: 13.834502220153809 RMSE: 3.719476\n",
      "Validation loss: 14.802643775939941 RMSE: 3.8474202\n",
      "Validation loss: 13.359050273895264 RMSE: 3.6550035\n",
      "115 10 2.1531828580473187\n",
      "Validation loss: 19.80939292907715 RMSE: 4.4507747\n",
      "Validation loss: 15.701417922973633 RMSE: 3.9625013\n",
      "Validation loss: 14.664918899536133 RMSE: 3.8294802\n",
      "118 12 1.5393282350726083\n",
      "Validation loss: 12.073020935058594 RMSE: 3.4746253\n",
      "Validation loss: 14.798234939575195 RMSE: 3.8468475\n",
      "Validation loss: 13.665018081665039 RMSE: 3.6966226\n",
      "121 14 2.180180406859224\n",
      "Validation loss: 15.13510274887085 RMSE: 3.890386\n",
      "Validation loss: 15.2138671875 RMSE: 3.9004958\n",
      "Validation loss: 13.61053466796875 RMSE: 3.6892457\n",
      "Validation loss: 12.750719547271729 RMSE: 3.570815\n",
      "125 0 2.0460757720065454\n",
      "Validation loss: 13.694260120391846 RMSE: 3.7005758\n",
      "Validation loss: 21.207388877868652 RMSE: 4.6051483\n",
      "Validation loss: 13.229564666748047 RMSE: 3.6372468\n",
      "128 2 1.4389070878197212\n",
      "Validation loss: 16.81770610809326 RMSE: 4.1009398\n",
      "Validation loss: 12.04590892791748 RMSE: 3.4707217\n",
      "Validation loss: 12.023269176483154 RMSE: 3.4674587\n",
      "131 4 2.1161910707514995\n",
      "Validation loss: 13.58097767829895 RMSE: 3.685238\n",
      "Validation loss: 16.17135524749756 RMSE: 4.021363\n",
      "Validation loss: 13.179425716400146 RMSE: 3.6303477\n",
      "134 6 2.578566350417482\n",
      "Validation loss: 15.273041725158691 RMSE: 3.9080744\n",
      "Validation loss: 14.278685569763184 RMSE: 3.7787147\n",
      "Validation loss: 15.431522369384766 RMSE: 3.9282978\n",
      "137 8 3.377142563005521\n",
      "Validation loss: 16.377290725708008 RMSE: 4.046887\n",
      "Validation loss: 14.734061241149902 RMSE: 3.838497\n",
      "Validation loss: 20.094964027404785 RMSE: 4.48274\n",
      "140 10 3.4278752199396862\n",
      "Validation loss: 16.854307174682617 RMSE: 4.1054\n",
      "Validation loss: 19.542707443237305 RMSE: 4.4207134\n",
      "Validation loss: 11.955296039581299 RMSE: 3.4576433\n",
      "143 12 1.3045020758172734\n",
      "Validation loss: 11.81597089767456 RMSE: 3.4374368\n",
      "Validation loss: 11.26273250579834 RMSE: 3.3559995\n",
      "Validation loss: 10.818195819854736 RMSE: 3.2891026\n",
      "146 14 1.0679995626844032\n",
      "Validation loss: 10.110723733901978 RMSE: 3.1797364\n",
      "Validation loss: 14.705322265625 RMSE: 3.8347518\n",
      "Validation loss: 17.061665534973145 RMSE: 4.130577\n",
      "Validation loss: 15.391656398773193 RMSE: 3.9232204\n",
      "150 0 0.936590457378983\n",
      "Validation loss: 16.066978454589844 RMSE: 4.0083637\n",
      "Validation loss: 16.99579095840454 RMSE: 4.1225953\n",
      "Validation loss: 18.06527614593506 RMSE: 4.2503266\n",
      "153 2 1.2496492550528933\n",
      "Validation loss: 13.640061855316162 RMSE: 3.6932456\n",
      "Validation loss: 15.999854564666748 RMSE: 3.9999819\n",
      "Validation loss: 15.48363447189331 RMSE: 3.934925\n",
      "156 4 0.8625314720359938\n",
      "Validation loss: 14.221458435058594 RMSE: 3.7711349\n",
      "Validation loss: 15.51236867904663 RMSE: 3.9385743\n",
      "Validation loss: 15.0574369430542 RMSE: 3.8803914\n",
      "159 6 3.6390277774029816\n",
      "Validation loss: 13.93567705154419 RMSE: 3.7330518\n",
      "Validation loss: 13.247373580932617 RMSE: 3.6396942\n",
      "Validation loss: 13.269103527069092 RMSE: 3.6426778\n",
      "162 8 2.5442109682846255\n",
      "Validation loss: 15.221635341644287 RMSE: 3.9014914\n",
      "Validation loss: 15.934871673583984 RMSE: 3.9918509\n",
      "Validation loss: 19.88594913482666 RMSE: 4.4593663\n",
      "165 10 1.8157056936518121\n",
      "Validation loss: 12.232118606567383 RMSE: 3.4974446\n",
      "Validation loss: 13.516359329223633 RMSE: 3.6764603\n",
      "Validation loss: 11.999781608581543 RMSE: 3.4640706\n",
      "168 12 2.0625952080313517\n",
      "Validation loss: 15.732487201690674 RMSE: 3.9664202\n",
      "Validation loss: 12.789873600006104 RMSE: 3.5762932\n",
      "Validation loss: 21.1777925491333 RMSE: 4.6019335\n",
      "171 14 2.301157281674114\n",
      "Validation loss: 13.44776439666748 RMSE: 3.6671193\n",
      "Validation loss: 15.431685447692871 RMSE: 3.9283178\n",
      "Validation loss: 17.490078926086426 RMSE: 4.182114\n",
      "Validation loss: 15.985017776489258 RMSE: 3.998127\n",
      "175 0 3.1290418242968308\n",
      "Validation loss: 11.566003561019897 RMSE: 3.4008827\n",
      "Validation loss: 13.291760444641113 RMSE: 3.6457863\n",
      "Validation loss: 13.0768723487854 RMSE: 3.6161962\n",
      "178 2 2.1251593693710404\n",
      "Validation loss: 14.783228874206543 RMSE: 3.8448963\n",
      "Validation loss: 21.839750289916992 RMSE: 4.6733017\n",
      "Validation loss: 16.790974140167236 RMSE: 4.097679\n",
      "181 4 1.3333057313490486\n",
      "Validation loss: 21.31484317779541 RMSE: 4.6168\n",
      "Validation loss: 19.68967056274414 RMSE: 4.437304\n",
      "Validation loss: 16.322635650634766 RMSE: 4.0401278\n",
      "184 6 1.4927322713978648\n",
      "Validation loss: 17.545649528503418 RMSE: 4.1887527\n",
      "Validation loss: 19.526341438293457 RMSE: 4.418862\n",
      "Validation loss: 12.917657375335693 RMSE: 3.5941143\n",
      "187 8 0.9608971394105078\n",
      "Validation loss: 13.112435340881348 RMSE: 3.6211097\n",
      "Validation loss: 13.43433666229248 RMSE: 3.6652882\n",
      "Validation loss: 18.110103607177734 RMSE: 4.2555966\n",
      "190 10 1.6680986769125783\n",
      "Validation loss: 16.11359214782715 RMSE: 4.0141735\n",
      "Validation loss: 14.838445663452148 RMSE: 3.8520703\n",
      "Validation loss: 15.678771495819092 RMSE: 3.959643\n",
      "193 12 1.6198308463042022\n",
      "Validation loss: 15.854436874389648 RMSE: 3.9817631\n",
      "Validation loss: 20.56886863708496 RMSE: 4.5352917\n",
      "Validation loss: 20.089650630950928 RMSE: 4.482148\n",
      "196 14 1.8120528650799348\n",
      "Validation loss: 13.566434383392334 RMSE: 3.6832643\n",
      "Validation loss: 16.531338691711426 RMSE: 4.0658746\n",
      "Validation loss: 17.951706886291504 RMSE: 4.236945\n",
      "Validation loss: 15.540866374969482 RMSE: 3.9421906\n",
      "Loaded trained model with success.\n",
      "Test loss: 12.636311164269081 Test RMSE: 3.554759\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'freesolv', 'model_type': 'gin', 'model': {'num_layer': 3, 'emb_dim': 64, 'feat_dim': 64, 'drop_ratio': 0.5, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'target': ['expt']}}\n",
      "Running on: cuda:1\n",
      "641\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/641\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 16.673944870740705\n",
      "Validation loss: 63.43796920776367 RMSE: 7.9647956\n",
      "Validation loss: 57.68832778930664 RMSE: 7.595283\n",
      "Validation loss: 51.048095703125 RMSE: 7.1447954\n",
      "3 2 6.3789152464222045\n",
      "Validation loss: 41.43480682373047 RMSE: 6.4369874\n",
      "Validation loss: 29.689329147338867 RMSE: 5.4487915\n",
      "Validation loss: 23.274702072143555 RMSE: 4.824386\n",
      "6 4 3.9993620727051997\n",
      "Validation loss: 20.22820472717285 RMSE: 4.4975777\n",
      "Validation loss: 19.749919891357422 RMSE: 4.444088\n",
      "Validation loss: 16.423447132110596 RMSE: 4.052585\n",
      "9 6 5.93739278471172\n",
      "Validation loss: 18.871278762817383 RMSE: 4.3441086\n",
      "Validation loss: 17.0300235748291 RMSE: 4.1267447\n",
      "Validation loss: 15.114790916442871 RMSE: 3.8877745\n",
      "12 8 5.850670836276594\n",
      "Validation loss: 13.306973934173584 RMSE: 3.6478727\n",
      "Validation loss: 13.841811656951904 RMSE: 3.7204585\n",
      "Validation loss: 13.831957817077637 RMSE: 3.719134\n",
      "15 10 5.560855086838643\n",
      "Validation loss: 16.59335470199585 RMSE: 4.0734944\n",
      "Validation loss: 12.24827527999878 RMSE: 3.4997535\n",
      "Validation loss: 13.125423431396484 RMSE: 3.6229026\n",
      "18 12 4.299991774485509\n",
      "Validation loss: 12.682765007019043 RMSE: 3.5612872\n",
      "Validation loss: 12.90732717514038 RMSE: 3.592677\n",
      "Validation loss: 14.578165054321289 RMSE: 3.818136\n",
      "21 14 4.823851521193862\n",
      "Validation loss: 14.619660377502441 RMSE: 3.8235667\n",
      "Validation loss: 13.908562183380127 RMSE: 3.7294185\n",
      "Validation loss: 11.840769290924072 RMSE: 3.4410417\n",
      "Validation loss: 15.785677909851074 RMSE: 3.9731195\n",
      "25 0 5.438135025249953\n",
      "Validation loss: 10.563013553619385 RMSE: 3.250079\n",
      "Validation loss: 12.562075138092041 RMSE: 3.5443017\n",
      "Validation loss: 11.79625129699707 RMSE: 3.4345672\n",
      "28 2 5.820491244872384\n",
      "Validation loss: 11.634255409240723 RMSE: 3.4109025\n",
      "Validation loss: 13.39975643157959 RMSE: 3.6605678\n",
      "Validation loss: 9.696234226226807 RMSE: 3.1138775\n",
      "31 4 7.335762813809461\n",
      "Validation loss: 17.529484272003174 RMSE: 4.1868224\n",
      "Validation loss: 12.756741046905518 RMSE: 3.5716584\n",
      "Validation loss: 10.88301134109497 RMSE: 3.298941\n",
      "34 6 2.512418264753725\n",
      "Validation loss: 12.326177597045898 RMSE: 3.5108657\n",
      "Validation loss: 16.0741868019104 RMSE: 4.0092626\n",
      "Validation loss: 12.507976531982422 RMSE: 3.5366619\n",
      "37 8 3.9140636592764113\n",
      "Validation loss: 16.344219207763672 RMSE: 4.0427985\n",
      "Validation loss: 12.651564121246338 RMSE: 3.5569038\n",
      "Validation loss: 15.928604125976562 RMSE: 3.9910655\n",
      "40 10 2.3935628940283813\n",
      "Validation loss: 12.552401065826416 RMSE: 3.542937\n",
      "Validation loss: 12.200133800506592 RMSE: 3.4928687\n",
      "Validation loss: 10.48572587966919 RMSE: 3.2381675\n",
      "43 12 5.414624048670617\n",
      "Validation loss: 16.503618240356445 RMSE: 4.0624647\n",
      "Validation loss: 13.949656009674072 RMSE: 3.7349238\n",
      "Validation loss: 16.15709400177002 RMSE: 4.019589\n",
      "46 14 2.5847641043951834\n",
      "Validation loss: 13.412066459655762 RMSE: 3.662249\n",
      "Validation loss: 16.714383125305176 RMSE: 4.0883226\n",
      "Validation loss: 15.059521675109863 RMSE: 3.88066\n",
      "Validation loss: 12.537086009979248 RMSE: 3.540775\n",
      "50 0 3.2984163413401495\n",
      "Validation loss: 12.516271591186523 RMSE: 3.537834\n",
      "Validation loss: 16.692341327667236 RMSE: 4.085626\n",
      "Validation loss: 12.845299243927002 RMSE: 3.5840335\n",
      "53 2 3.142832991254854\n",
      "Validation loss: 12.217985153198242 RMSE: 3.4954238\n",
      "Validation loss: 12.188312292098999 RMSE: 3.4911761\n",
      "Validation loss: 17.561121940612793 RMSE: 4.1905994\n",
      "56 4 4.0177373293389715\n",
      "Validation loss: 13.65430736541748 RMSE: 3.6951737\n",
      "Validation loss: 10.533477306365967 RMSE: 3.2455318\n",
      "Validation loss: 14.964439630508423 RMSE: 3.8683903\n",
      "59 6 3.3127132413042886\n",
      "Validation loss: 18.24397563934326 RMSE: 4.271297\n",
      "Validation loss: 15.974778175354004 RMSE: 3.996846\n",
      "Validation loss: 17.49272632598877 RMSE: 4.1824307\n",
      "62 8 3.4447866024494354\n",
      "Validation loss: 14.000419616699219 RMSE: 3.7417135\n",
      "Validation loss: 13.006101131439209 RMSE: 3.6063972\n",
      "Validation loss: 14.147507667541504 RMSE: 3.7613175\n",
      "65 10 3.3372349888034245\n",
      "Validation loss: 14.41362476348877 RMSE: 3.796528\n",
      "Validation loss: 13.031973838806152 RMSE: 3.6099827\n",
      "Validation loss: 15.340498924255371 RMSE: 3.9166946\n",
      "68 12 1.9758589707911844\n",
      "Validation loss: 12.413951873779297 RMSE: 3.5233438\n",
      "Validation loss: 12.581318378448486 RMSE: 3.5470157\n",
      "Validation loss: 15.300797462463379 RMSE: 3.9116237\n",
      "71 14 2.6627616724247076\n",
      "Validation loss: 14.330921649932861 RMSE: 3.7856202\n",
      "Validation loss: 12.171741485595703 RMSE: 3.4888022\n",
      "Validation loss: 10.580280303955078 RMSE: 3.2527347\n",
      "Validation loss: 12.785462379455566 RMSE: 3.5756767\n",
      "75 0 1.7702949578067861\n",
      "Validation loss: 10.881705284118652 RMSE: 3.298743\n",
      "Validation loss: 13.738312244415283 RMSE: 3.7065237\n",
      "Validation loss: 15.515371799468994 RMSE: 3.9389555\n",
      "78 2 2.5918093962310547\n",
      "Validation loss: 10.758718013763428 RMSE: 3.2800484\n",
      "Validation loss: 11.347649097442627 RMSE: 3.3686273\n",
      "Validation loss: 16.469871759414673 RMSE: 4.0583096\n",
      "81 4 2.4881568729075414\n",
      "Validation loss: 15.604637622833252 RMSE: 3.9502704\n",
      "Validation loss: 10.554934024810791 RMSE: 3.2488358\n",
      "Validation loss: 13.866639614105225 RMSE: 3.7237937\n",
      "84 6 3.2375696014608786\n",
      "Validation loss: 15.969377994537354 RMSE: 3.99617\n",
      "Validation loss: 17.548428058624268 RMSE: 4.189084\n",
      "Validation loss: 14.658681869506836 RMSE: 3.828666\n",
      "87 8 1.5798243769434415\n",
      "Validation loss: 16.79119110107422 RMSE: 4.0977054\n",
      "Validation loss: 20.953015327453613 RMSE: 4.5774465\n",
      "Validation loss: 12.688146591186523 RMSE: 3.5620425\n",
      "90 10 6.345555666048265\n",
      "Validation loss: 13.839783191680908 RMSE: 3.7201858\n",
      "Validation loss: 13.150828838348389 RMSE: 3.626407\n",
      "Validation loss: 13.899780750274658 RMSE: 3.728241\n",
      "93 12 2.241053182546924\n",
      "Validation loss: 13.378042459487915 RMSE: 3.6576006\n",
      "Validation loss: 18.927549362182617 RMSE: 4.3505807\n",
      "Validation loss: 14.044692993164062 RMSE: 3.747625\n",
      "96 14 2.5881153986663468\n",
      "Validation loss: 11.834407329559326 RMSE: 3.4401174\n",
      "Validation loss: 14.410181045532227 RMSE: 3.7960744\n",
      "Validation loss: 13.804487705230713 RMSE: 3.715439\n",
      "Validation loss: 16.606688499450684 RMSE: 4.0751305\n",
      "100 0 3.9364107267097053\n",
      "Validation loss: 14.384477138519287 RMSE: 3.7926872\n",
      "Validation loss: 15.906506538391113 RMSE: 3.988295\n",
      "Validation loss: 16.146438121795654 RMSE: 4.018264\n",
      "103 2 2.107798574711029\n",
      "Validation loss: 14.790483474731445 RMSE: 3.8458397\n",
      "Validation loss: 15.81413221359253 RMSE: 3.9766984\n",
      "Validation loss: 21.562021732330322 RMSE: 4.643492\n",
      "106 4 2.5880696808974295\n",
      "Validation loss: 14.98728322982788 RMSE: 3.871341\n",
      "Validation loss: 16.71954655647278 RMSE: 4.088954\n",
      "Validation loss: 17.873380661010742 RMSE: 4.227692\n",
      "109 6 2.0365772901578936\n",
      "Validation loss: 15.787201881408691 RMSE: 3.9733114\n",
      "Validation loss: 11.928772926330566 RMSE: 3.4538057\n",
      "Validation loss: 15.572981834411621 RMSE: 3.9462621\n",
      "112 8 2.146716702111083\n",
      "Validation loss: 16.55760955810547 RMSE: 4.069104\n",
      "Validation loss: 17.464553833007812 RMSE: 4.1790614\n",
      "Validation loss: 15.047159671783447 RMSE: 3.8790667\n",
      "115 10 3.5327873760500235\n",
      "Validation loss: 16.719799995422363 RMSE: 4.0889854\n",
      "Validation loss: 14.803153991699219 RMSE: 3.8474867\n",
      "Validation loss: 17.29371166229248 RMSE: 4.158571\n",
      "118 12 2.738992044360081\n",
      "Validation loss: 12.603055953979492 RMSE: 3.5500784\n",
      "Validation loss: 16.474364280700684 RMSE: 4.058862\n",
      "Validation loss: 17.728392601013184 RMSE: 4.21051\n",
      "121 14 1.530638665944724\n",
      "Validation loss: 14.728188037872314 RMSE: 3.8377323\n",
      "Validation loss: 11.180837392807007 RMSE: 3.3437765\n",
      "Validation loss: 15.394026756286621 RMSE: 3.9235222\n",
      "Validation loss: 14.70757532119751 RMSE: 3.8350458\n",
      "125 0 2.1927902836940927\n",
      "Validation loss: 21.814719200134277 RMSE: 4.670624\n",
      "Validation loss: 18.36594009399414 RMSE: 4.28555\n",
      "Validation loss: 15.1339111328125 RMSE: 3.8902328\n",
      "128 2 2.502464703760022\n",
      "Validation loss: 15.43854570388794 RMSE: 3.9291914\n",
      "Validation loss: 19.901575088500977 RMSE: 4.461118\n",
      "Validation loss: 13.440241813659668 RMSE: 3.6660933\n",
      "131 4 2.1055744758844126\n",
      "Validation loss: 18.164567947387695 RMSE: 4.261991\n",
      "Validation loss: 12.292864322662354 RMSE: 3.5061183\n",
      "Validation loss: 22.82188129425049 RMSE: 4.777225\n",
      "134 6 2.10514718483863\n",
      "Validation loss: 13.867481708526611 RMSE: 3.723907\n",
      "Validation loss: 13.576762676239014 RMSE: 3.684666\n",
      "Validation loss: 23.446811199188232 RMSE: 4.84219\n",
      "137 8 2.430404128040263\n",
      "Validation loss: 17.141133308410645 RMSE: 4.1401854\n",
      "Validation loss: 15.710576057434082 RMSE: 3.963657\n",
      "Validation loss: 13.946076393127441 RMSE: 3.734445\n",
      "140 10 1.4309656975357488\n",
      "Validation loss: 14.404574632644653 RMSE: 3.7953362\n",
      "Validation loss: 17.209613800048828 RMSE: 4.148447\n",
      "Validation loss: 24.466611862182617 RMSE: 4.946374\n",
      "143 12 2.229945516504704\n",
      "Validation loss: 16.644542455673218 RMSE: 4.0797725\n",
      "Validation loss: 16.072751998901367 RMSE: 4.0090837\n",
      "Validation loss: 11.886214256286621 RMSE: 3.447639\n",
      "146 14 1.5122745295246405\n",
      "Validation loss: 15.289992809295654 RMSE: 3.9102418\n",
      "Validation loss: 19.62725830078125 RMSE: 4.4302664\n",
      "Validation loss: 16.037681102752686 RMSE: 4.0047073\n",
      "Validation loss: 12.428790092468262 RMSE: 3.525449\n",
      "150 0 1.890613105194927\n",
      "Validation loss: 19.18888282775879 RMSE: 4.3805118\n",
      "Validation loss: 14.74489164352417 RMSE: 3.8399076\n",
      "Validation loss: 14.696179389953613 RMSE: 3.8335602\n",
      "153 2 2.183680683701731\n",
      "Validation loss: 14.651443481445312 RMSE: 3.8277204\n",
      "Validation loss: 12.892694473266602 RMSE: 3.5906398\n",
      "Validation loss: 18.485785484313965 RMSE: 4.29951\n",
      "156 4 5.529964400550412\n",
      "Validation loss: 24.94710421562195 RMSE: 4.9947076\n",
      "Validation loss: 16.872076988220215 RMSE: 4.1075635\n",
      "Validation loss: 19.217801094055176 RMSE: 4.383811\n",
      "159 6 2.605256759359191\n",
      "Validation loss: 14.929054021835327 RMSE: 3.8638134\n",
      "Validation loss: 15.227532386779785 RMSE: 3.9022474\n",
      "Validation loss: 18.6037015914917 RMSE: 4.3132014\n",
      "162 8 1.8806409652834288\n",
      "Validation loss: 14.593512535095215 RMSE: 3.8201454\n",
      "Validation loss: 19.482741355895996 RMSE: 4.4139256\n",
      "Validation loss: 22.093843460083008 RMSE: 4.700409\n",
      "165 10 1.7972250134999823\n",
      "Validation loss: 16.46779155731201 RMSE: 4.058053\n",
      "Validation loss: 20.07181167602539 RMSE: 4.480157\n",
      "Validation loss: 14.626607418060303 RMSE: 3.8244746\n",
      "168 12 3.7921212489713274\n",
      "Validation loss: 15.603700637817383 RMSE: 3.950152\n",
      "Validation loss: 27.823996543884277 RMSE: 5.2748456\n",
      "Validation loss: 20.274096488952637 RMSE: 4.502676\n",
      "171 14 1.0734534858630875\n",
      "Validation loss: 16.52777624130249 RMSE: 4.065437\n",
      "Validation loss: 12.418521404266357 RMSE: 3.5239925\n",
      "Validation loss: 22.220046997070312 RMSE: 4.7138143\n",
      "Validation loss: 15.928628921508789 RMSE: 3.9910688\n",
      "175 0 1.3157325014012136\n",
      "Validation loss: 15.315943717956543 RMSE: 3.9135585\n",
      "Validation loss: 19.145516395568848 RMSE: 4.375559\n",
      "Validation loss: 20.66754722595215 RMSE: 4.5461574\n",
      "178 2 1.4218846425983147\n",
      "Validation loss: 15.132352828979492 RMSE: 3.8900325\n",
      "Validation loss: 20.78813362121582 RMSE: 4.5594\n",
      "Validation loss: 16.746193170547485 RMSE: 4.092211\n",
      "181 4 1.998436132795914\n",
      "Validation loss: 15.798957347869873 RMSE: 3.9747906\n",
      "Validation loss: 16.332250595092773 RMSE: 4.041318\n",
      "Validation loss: 11.503119945526123 RMSE: 3.391625\n",
      "184 6 1.5310209514621997\n",
      "Validation loss: 11.522652626037598 RMSE: 3.3945034\n",
      "Validation loss: 14.587524175643921 RMSE: 3.8193617\n",
      "Validation loss: 18.078251361846924 RMSE: 4.251853\n",
      "187 8 2.45308444421514\n",
      "Validation loss: 15.859270095825195 RMSE: 3.98237\n",
      "Validation loss: 19.989529609680176 RMSE: 4.4709654\n",
      "Validation loss: 14.807193279266357 RMSE: 3.8480117\n",
      "190 10 2.542855221138608\n",
      "Validation loss: 18.178107738494873 RMSE: 4.2635794\n",
      "Validation loss: 17.324191570281982 RMSE: 4.162234\n",
      "Validation loss: 19.85576343536377 RMSE: 4.455981\n",
      "193 12 1.1106880147016647\n",
      "Validation loss: 28.26570987701416 RMSE: 5.3165507\n",
      "Validation loss: 15.471928834915161 RMSE: 3.9334373\n",
      "Validation loss: 12.293473720550537 RMSE: 3.5062044\n",
      "196 14 1.715901815712177\n",
      "Validation loss: 12.215518474578857 RMSE: 3.4950705\n",
      "Validation loss: 13.207073211669922 RMSE: 3.6341538\n",
      "Validation loss: 15.636875629425049 RMSE: 3.954349\n",
      "Validation loss: 14.211697578430176 RMSE: 3.769841\n",
      "Loaded trained model with success.\n",
      "Test loss: 16.322858031495258 Test RMSE: 4.0401554\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'target': ['measured log solubility in mols per litre']}}\n",
      "Running on: cuda:1\n",
      "1127\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1127\n",
      "Generating scaffold 1000/1127\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 7.97463922829068\n",
      "Validation loss: 2.6101544051043755 RMSE: 1.6155972\n",
      "1 21 1.7143250333353992\n",
      "Validation loss: 3.099253217730902 RMSE: 1.7604696\n",
      "Validation loss: 2.6012423376066494 RMSE: 1.6128368\n",
      "3 13 1.6811319589453961\n",
      "Validation loss: 2.5725804999866315 RMSE: 1.6039265\n",
      "Validation loss: 2.2170161272572204 RMSE: 1.4889649\n",
      "5 5 1.3408194916064629\n",
      "Validation loss: 3.4899660739223513 RMSE: 1.868145\n",
      "6 26 1.7154782883444604\n",
      "Validation loss: 3.112812468435912 RMSE: 1.7643164\n",
      "Validation loss: 3.351216938643329 RMSE: 1.8306329\n",
      "8 18 1.8107923035196143\n",
      "Validation loss: 2.3515226672180987 RMSE: 1.5334674\n",
      "Validation loss: 1.8067181753901254 RMSE: 1.3441422\n",
      "10 10 1.2466355239786193\n",
      "Validation loss: 1.9368354177052995 RMSE: 1.3917023\n",
      "Validation loss: 2.2089185218895433 RMSE: 1.4862431\n",
      "12 2 0.799511594030158\n",
      "Validation loss: 3.6831224829749725 RMSE: 1.9191463\n",
      "13 23 0.8088706132345523\n",
      "Validation loss: 2.3925949493340686 RMSE: 1.5468014\n",
      "Validation loss: 2.7863261973963374 RMSE: 1.6692293\n",
      "15 15 0.88703815299405\n",
      "Validation loss: 1.9022564044040917 RMSE: 1.3792231\n",
      "Validation loss: 2.2118091794241845 RMSE: 1.4872153\n",
      "17 7 1.54604095283721\n",
      "Validation loss: 1.9602166983933575 RMSE: 1.4000775\n",
      "18 28 1.4138484966424216\n",
      "Validation loss: 2.168259797898014 RMSE: 1.4725012\n",
      "Validation loss: 1.6123109602295191 RMSE: 1.269768\n",
      "20 20 1.4717704132062808\n",
      "Validation loss: 2.3742245193076346 RMSE: 1.540852\n",
      "Validation loss: 1.5815180307995957 RMSE: 1.2575842\n",
      "22 12 0.8460947457808117\n",
      "Validation loss: 1.7084112800328077 RMSE: 1.3070621\n",
      "Validation loss: 2.1660068045675227 RMSE: 1.4717361\n",
      "24 4 0.8782076856923995\n",
      "Validation loss: 2.7883950461328557 RMSE: 1.6698488\n",
      "25 25 0.7296633676039969\n",
      "Validation loss: 1.9625388542107776 RMSE: 1.4009064\n",
      "Validation loss: 2.227283645520168 RMSE: 1.4924086\n",
      "27 17 0.7028261008009047\n",
      "Validation loss: 2.629725629249505 RMSE: 1.621643\n",
      "Validation loss: 2.0502707726132554 RMSE: 1.4318767\n",
      "29 9 0.7959499089427338\n",
      "Validation loss: 1.4863421157398056 RMSE: 1.2191563\n",
      "Validation loss: 3.3693210930950874 RMSE: 1.835571\n",
      "31 1 1.0616785194634017\n",
      "Validation loss: 1.928829503270377 RMSE: 1.3888232\n",
      "32 22 0.8498437951249451\n",
      "Validation loss: 1.9792679516615066 RMSE: 1.4068646\n",
      "Validation loss: 1.9080955465283014 RMSE: 1.3813384\n",
      "34 14 0.961778010241904\n",
      "Validation loss: 1.7744643139628182 RMSE: 1.3320903\n",
      "Validation loss: 1.951448676860438 RMSE: 1.3969426\n",
      "36 6 0.4508404282290982\n",
      "Validation loss: 1.417457162806418 RMSE: 1.1905701\n",
      "37 27 1.2322778837288522\n",
      "Validation loss: 2.364078325507915 RMSE: 1.5375559\n",
      "Validation loss: 2.3032583515200993 RMSE: 1.5176489\n",
      "39 19 0.8186881097032602\n",
      "Validation loss: 2.71385849049661 RMSE: 1.6473793\n",
      "Validation loss: 1.842789008554104 RMSE: 1.3574936\n",
      "41 11 1.2450141267755424\n",
      "Validation loss: 1.8835451908871137 RMSE: 1.372423\n",
      "Validation loss: 2.248748350987392 RMSE: 1.4995828\n",
      "43 3 0.8440209167388975\n",
      "Validation loss: 2.039006941086423 RMSE: 1.427938\n",
      "44 24 1.163579169254218\n",
      "Validation loss: 1.8148239734953484 RMSE: 1.347154\n",
      "Validation loss: 2.166067218358538 RMSE: 1.4717565\n",
      "46 16 0.6519409057574429\n",
      "Validation loss: 2.0411116612696016 RMSE: 1.4286748\n",
      "Validation loss: 1.8085566505921626 RMSE: 1.344826\n",
      "48 8 0.40915075471210444\n",
      "Validation loss: 2.013706863453958 RMSE: 1.4190513\n",
      "Validation loss: 2.117231283567648 RMSE: 1.4550709\n",
      "50 0 0.41307002895042966\n",
      "Validation loss: 2.1213573227941462 RMSE: 1.456488\n",
      "51 21 0.8758531400679521\n",
      "Validation loss: 2.2113820852431574 RMSE: 1.4870718\n",
      "Validation loss: 1.6028504181752163 RMSE: 1.2660373\n",
      "53 13 0.6703860473990877\n",
      "Validation loss: 1.8570583795024231 RMSE: 1.3627393\n",
      "Validation loss: 2.2642484302014374 RMSE: 1.5047419\n",
      "55 5 1.1596782488298907\n",
      "Validation loss: 2.2039480905617235 RMSE: 1.48457\n",
      "56 26 1.4106648426443666\n",
      "Validation loss: 2.0472810416095024 RMSE: 1.4308323\n",
      "Validation loss: 2.254224308824117 RMSE: 1.5014074\n",
      "58 18 0.8464135528775693\n",
      "Validation loss: 1.9282095611622903 RMSE: 1.3885999\n",
      "Validation loss: 1.5947730467382786 RMSE: 1.2628433\n",
      "60 10 0.6201483522866525\n",
      "Validation loss: 1.7498246104316373 RMSE: 1.3228095\n",
      "Validation loss: 2.097788371871003 RMSE: 1.4483744\n",
      "62 2 0.7500003068147986\n",
      "Validation loss: 2.072617549811844 RMSE: 1.4396589\n",
      "63 23 0.4193747279774206\n",
      "Validation loss: 1.6293207501943132 RMSE: 1.2764485\n",
      "Validation loss: 2.096420837714609 RMSE: 1.4479021\n",
      "65 15 0.42929051863319645\n",
      "Validation loss: 1.6484197441455537 RMSE: 1.283908\n",
      "Validation loss: 1.5852649169685566 RMSE: 1.259073\n",
      "67 7 0.5832268435199066\n",
      "Validation loss: 1.6624364388727508 RMSE: 1.289355\n",
      "68 28 3.9723054612423074\n",
      "Validation loss: 1.7082548732251193 RMSE: 1.3070022\n",
      "Validation loss: 2.0523648240924937 RMSE: 1.4326077\n",
      "70 20 0.7954202744936092\n",
      "Validation loss: 1.9658654084247826 RMSE: 1.4020932\n",
      "Validation loss: 1.680900082124018 RMSE: 1.2964953\n",
      "72 12 0.81021075976242\n",
      "Validation loss: 1.9831283556676544 RMSE: 1.4082359\n",
      "Validation loss: 2.2690814427569905 RMSE: 1.5063471\n",
      "74 4 0.9592551618924839\n",
      "Validation loss: 2.042147721864481 RMSE: 1.4290373\n",
      "75 25 0.5950094551501224\n",
      "Validation loss: 1.711565024029892 RMSE: 1.308268\n",
      "Validation loss: 1.6708184628360039 RMSE: 1.2926015\n",
      "77 17 0.7511826568844814\n",
      "Validation loss: 1.6069207623996566 RMSE: 1.2676438\n",
      "Validation loss: 1.6126562114310476 RMSE: 1.269904\n",
      "79 9 0.7096753944322471\n",
      "Validation loss: 2.193992071447119 RMSE: 1.4812131\n",
      "Validation loss: 1.5940714874098787 RMSE: 1.2625655\n",
      "81 1 0.7008783688971651\n",
      "Validation loss: 2.0777598060337845 RMSE: 1.4414436\n",
      "82 22 0.6132670813733115\n",
      "Validation loss: 1.4989837977738507 RMSE: 1.22433\n",
      "Validation loss: 1.4213363438580944 RMSE: 1.192198\n",
      "84 14 0.6986555768314825\n",
      "Validation loss: 1.7527321672017595 RMSE: 1.3239079\n",
      "Validation loss: 1.8439181694942237 RMSE: 1.3579094\n",
      "86 6 0.8435910442956295\n",
      "Validation loss: 1.646508747497491 RMSE: 1.2831635\n",
      "87 27 0.9117423388736744\n",
      "Validation loss: 1.7293415670901273 RMSE: 1.3150443\n",
      "Validation loss: 1.946530093133977 RMSE: 1.395181\n",
      "89 19 0.5264397463754569\n",
      "Validation loss: 1.4971547337759912 RMSE: 1.2235827\n",
      "Validation loss: 2.0101556324325833 RMSE: 1.4177996\n",
      "91 11 0.3974608777100831\n",
      "Validation loss: 1.7762631283397168 RMSE: 1.3327652\n",
      "Validation loss: 2.1024386619044617 RMSE: 1.4499788\n",
      "93 3 0.3959276293600085\n",
      "Validation loss: 1.7738266075606894 RMSE: 1.3318509\n",
      "94 24 0.4238914570416072\n",
      "Validation loss: 1.7785819104287477 RMSE: 1.3336349\n",
      "Validation loss: 2.4996216993416307 RMSE: 1.581019\n",
      "96 16 0.4634024636839554\n",
      "Validation loss: 2.1215292025456387 RMSE: 1.456547\n",
      "Validation loss: 2.324218536900208 RMSE: 1.5245388\n",
      "98 8 0.6353662920417863\n",
      "Validation loss: 2.4240433557898595 RMSE: 1.556934\n",
      "Validation loss: 1.9253206020962876 RMSE: 1.3875592\n",
      "100 0 0.5184461766301979\n",
      "Validation loss: 1.9431357088342178 RMSE: 1.393964\n",
      "101 21 0.42664724062808324\n",
      "Validation loss: 1.7190451284425448 RMSE: 1.3111235\n",
      "Validation loss: 1.8532590127624242 RMSE: 1.3613446\n",
      "103 13 0.6886326273259642\n",
      "Validation loss: 2.0600872978699947 RMSE: 1.4353005\n",
      "Validation loss: 1.6668036205578693 RMSE: 1.2910476\n",
      "105 5 0.7899872339047914\n",
      "Validation loss: 1.9147127766524796 RMSE: 1.3837315\n",
      "106 26 0.5350189610644833\n",
      "Validation loss: 1.5494411751232315 RMSE: 1.2447655\n",
      "Validation loss: 1.805137777750471 RMSE: 1.3435541\n",
      "108 18 0.4143498755444775\n",
      "Validation loss: 1.6920855119165066 RMSE: 1.3008019\n",
      "Validation loss: 1.7722914377145007 RMSE: 1.3312744\n",
      "110 10 1.0933445000481743\n",
      "Validation loss: 1.6723298319673117 RMSE: 1.293186\n",
      "Validation loss: 1.8610505699056439 RMSE: 1.3642032\n",
      "112 2 0.8535186060757917\n",
      "Validation loss: 1.7586110503272672 RMSE: 1.3261263\n",
      "113 23 0.6097971921537877\n",
      "Validation loss: 1.4877330254664463 RMSE: 1.2197266\n",
      "Validation loss: 1.8772902900138788 RMSE: 1.3701425\n",
      "115 15 0.6847109477914893\n",
      "Validation loss: 1.9134753552158321 RMSE: 1.3832843\n",
      "Validation loss: 1.7323863770054504 RMSE: 1.3162014\n",
      "117 7 0.4998094585688921\n",
      "Validation loss: 1.6742810559483756 RMSE: 1.2939401\n",
      "118 28 0.7682156271239995\n",
      "Validation loss: 1.5619057195376507 RMSE: 1.2497622\n",
      "Validation loss: 1.6021349767668058 RMSE: 1.2657547\n",
      "120 20 0.4257579309547409\n",
      "Validation loss: 1.6882340886951548 RMSE: 1.2993207\n",
      "Validation loss: 1.5442495061232981 RMSE: 1.2426783\n",
      "122 12 0.639904742062244\n",
      "Validation loss: 1.7918362469799751 RMSE: 1.3385949\n",
      "Validation loss: 1.7551776983041678 RMSE: 1.3248311\n",
      "124 4 0.7378508496549715\n",
      "Validation loss: 1.8237938089708312 RMSE: 1.350479\n",
      "125 25 0.4278669510394695\n",
      "Validation loss: 1.6157133858815758 RMSE: 1.2711072\n",
      "Validation loss: 2.0301159831274926 RMSE: 1.4248214\n",
      "127 17 0.4434931507969227\n",
      "Validation loss: 1.7309598606244652 RMSE: 1.3156595\n",
      "Validation loss: 2.1422098009987214 RMSE: 1.463629\n",
      "129 9 0.6894751038905527\n",
      "Validation loss: 1.9174564422759335 RMSE: 1.3847225\n",
      "Validation loss: 1.604669857869106 RMSE: 1.2667557\n",
      "131 1 0.6205966076810016\n",
      "Validation loss: 1.5569886000810471 RMSE: 1.2477934\n",
      "132 22 0.4640322845337787\n",
      "Validation loss: 1.6480656419180135 RMSE: 1.28377\n",
      "Validation loss: 1.5751975331686239 RMSE: 1.2550688\n",
      "134 14 0.5333164489096994\n",
      "Validation loss: 1.6861387027048431 RMSE: 1.298514\n",
      "Validation loss: 1.9982083096968388 RMSE: 1.41358\n",
      "136 6 1.0176244484807255\n",
      "Validation loss: 1.7649716560819508 RMSE: 1.3285224\n",
      "137 27 0.25482844376686525\n",
      "Validation loss: 1.721061658542768 RMSE: 1.3118924\n",
      "Validation loss: 1.8142093325083235 RMSE: 1.3469259\n",
      "139 19 0.5540160836712849\n",
      "Validation loss: 2.0850191411718857 RMSE: 1.4439595\n",
      "Validation loss: 1.8657528615630834 RMSE: 1.3659257\n",
      "141 11 0.2360964249209866\n",
      "Validation loss: 1.4198129314236936 RMSE: 1.191559\n",
      "Validation loss: 1.883980368090942 RMSE: 1.3725816\n",
      "143 3 0.4214052099128418\n",
      "Validation loss: 1.7867221473592572 RMSE: 1.3366833\n",
      "144 24 0.6685680235235579\n",
      "Validation loss: 1.5525940203033717 RMSE: 1.2460313\n",
      "Validation loss: 1.7089484297068773 RMSE: 1.3072675\n",
      "146 16 0.7180901550629643\n",
      "Validation loss: 1.3593759230807818 RMSE: 1.1659229\n",
      "Validation loss: 1.9281906527755535 RMSE: 1.3885931\n",
      "148 8 0.9115348489404056\n",
      "Validation loss: 1.388616622021768 RMSE: 1.1783959\n",
      "Validation loss: 1.8536222149840498 RMSE: 1.361478\n",
      "150 0 0.45765473221095815\n",
      "Validation loss: 1.3899215839605417 RMSE: 1.1789492\n",
      "151 21 0.374159185349277\n",
      "Validation loss: 1.7331476158800379 RMSE: 1.3164907\n",
      "Validation loss: 1.559049853181417 RMSE: 1.2486191\n",
      "153 13 0.3186613937562993\n",
      "Validation loss: 1.875048599411956 RMSE: 1.3693242\n",
      "Validation loss: 2.234621774833814 RMSE: 1.4948652\n",
      "155 5 0.3080024650489896\n",
      "Validation loss: 2.00741651100395 RMSE: 1.4168333\n",
      "156 26 0.7822116214485303\n",
      "Validation loss: 1.8760532172380295 RMSE: 1.369691\n",
      "Validation loss: 1.5997515679460712 RMSE: 1.2648128\n",
      "158 18 0.6434420566736911\n",
      "Validation loss: 1.6512264488017665 RMSE: 1.2850006\n",
      "Validation loss: 1.5288851598722746 RMSE: 1.236481\n",
      "160 10 0.31618608020056244\n",
      "Validation loss: 1.6909857882862598 RMSE: 1.300379\n",
      "Validation loss: 1.646744702242117 RMSE: 1.2832556\n",
      "162 2 0.33147964457688295\n",
      "Validation loss: 2.015623822676397 RMSE: 1.4197266\n",
      "163 23 0.25561490848817897\n",
      "Validation loss: 2.0013287626536544 RMSE: 1.4146832\n",
      "Validation loss: 1.6617396014981565 RMSE: 1.2890848\n",
      "165 15 0.33942930845677255\n",
      "Validation loss: 1.8330742521623595 RMSE: 1.3539107\n",
      "Validation loss: 1.8525379822317478 RMSE: 1.3610797\n",
      "167 7 0.3910870695747955\n",
      "Validation loss: 2.0739917501939082 RMSE: 1.440136\n",
      "168 28 0.5653114454606876\n",
      "Validation loss: 1.6415983765526156 RMSE: 1.2812487\n",
      "Validation loss: 1.6115514810106395 RMSE: 1.269469\n",
      "170 20 0.38642169523023634\n",
      "Validation loss: 1.7432108305196847 RMSE: 1.3203071\n",
      "Validation loss: 1.7905857415325874 RMSE: 1.3381276\n",
      "172 12 0.42956076392061354\n",
      "Validation loss: 1.877017753314128 RMSE: 1.3700429\n",
      "Validation loss: 1.8456145424758439 RMSE: 1.358534\n",
      "174 4 0.318159411472499\n",
      "Validation loss: 2.193746503475493 RMSE: 1.4811301\n",
      "175 25 0.39057017673200367\n",
      "Validation loss: 1.8025949971865765 RMSE: 1.3426075\n",
      "Validation loss: 1.7297668087798936 RMSE: 1.3152059\n",
      "177 17 0.46777903441445046\n",
      "Validation loss: 1.6873584110124977 RMSE: 1.2989836\n",
      "Validation loss: 1.939380840917604 RMSE: 1.3926165\n",
      "179 9 0.29682469800524386\n",
      "Validation loss: 1.7518717018903884 RMSE: 1.3235829\n",
      "Validation loss: 1.816254240221682 RMSE: 1.3476847\n",
      "181 1 0.24588995971988498\n",
      "Validation loss: 1.7121463486578612 RMSE: 1.30849\n",
      "182 22 0.5238720975312099\n",
      "Validation loss: 1.4551525590694057 RMSE: 1.206297\n",
      "Validation loss: 1.8671091003755553 RMSE: 1.366422\n",
      "184 14 0.5784415074534577\n",
      "Validation loss: 1.4906239425186563 RMSE: 1.2209111\n",
      "Validation loss: 1.768479560328796 RMSE: 1.329842\n",
      "186 6 0.3272155977804947\n",
      "Validation loss: 1.7077165662714866 RMSE: 1.3067963\n",
      "187 27 0.5424854831606716\n",
      "Validation loss: 1.5411623083384691 RMSE: 1.2414355\n",
      "Validation loss: 1.7136452957592179 RMSE: 1.3090627\n",
      "189 19 0.22754483240120488\n",
      "Validation loss: 1.582467746945609 RMSE: 1.2579618\n",
      "Validation loss: 1.710204261594114 RMSE: 1.3077477\n",
      "191 11 0.24541347811572292\n",
      "Validation loss: 1.4173933067152986 RMSE: 1.1905433\n",
      "Validation loss: 1.6515688695738802 RMSE: 1.2851337\n",
      "193 3 0.27957416173614763\n",
      "Validation loss: 1.8008303420733562 RMSE: 1.3419502\n",
      "194 24 0.2090608343847446\n",
      "Validation loss: 1.8689598636289613 RMSE: 1.367099\n",
      "Validation loss: 1.5911241105172487 RMSE: 1.2613977\n",
      "196 16 0.3722024636146961\n",
      "Validation loss: 2.2773086708203882 RMSE: 1.5090755\n",
      "Validation loss: 2.008969661408821 RMSE: 1.4173813\n",
      "198 8 0.7370580928148047\n",
      "Validation loss: 1.8230032593803067 RMSE: 1.3501863\n",
      "Validation loss: 1.6190372009192948 RMSE: 1.2724138\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.6993086527934116 Test RMSE: 1.3035753\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 778, 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'target': ['measured log solubility in mols per litre']}}\n",
      "Running on: cuda:1\n",
      "1127\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1127\n",
      "Generating scaffold 1000/1127\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 17.172252228945162\n",
      "Validation loss: 2.8996240101029387 RMSE: 1.7028282\n",
      "1 21 3.0185496590955587\n",
      "Validation loss: 3.617505429065333 RMSE: 1.9019741\n",
      "Validation loss: 4.526912959276047 RMSE: 2.1276543\n",
      "3 13 2.165135954520256\n",
      "Validation loss: 11.88338646846535 RMSE: 3.447229\n",
      "Validation loss: 4.2702222102511245 RMSE: 2.0664515\n",
      "5 5 1.1344559914811105\n",
      "Validation loss: 6.20337267048591 RMSE: 2.490657\n",
      "6 26 1.6319404144315022\n",
      "Validation loss: 2.6154968759654897 RMSE: 1.6172497\n",
      "Validation loss: 2.7377063173108396 RMSE: 1.6546015\n",
      "8 18 1.0159126423202238\n",
      "Validation loss: 2.7616999666247746 RMSE: 1.6618363\n",
      "Validation loss: 1.9176601973255123 RMSE: 1.384796\n",
      "10 10 1.0799929714313248\n",
      "Validation loss: 2.3062636419735125 RMSE: 1.518639\n",
      "Validation loss: 3.9502196522940576 RMSE: 1.9875159\n",
      "12 2 1.0498368217278298\n",
      "Validation loss: 2.2366439863643817 RMSE: 1.4955413\n",
      "13 23 0.6655734435856816\n",
      "Validation loss: 4.9651515884737 RMSE: 2.2282622\n",
      "Validation loss: 2.6490527992754913 RMSE: 1.6275913\n",
      "15 15 0.9897794836548748\n",
      "Validation loss: 2.6962314675339556 RMSE: 1.6420206\n",
      "Validation loss: 2.744383588301397 RMSE: 1.656618\n",
      "17 7 1.812803334535849\n",
      "Validation loss: 4.271369195617406 RMSE: 2.066729\n",
      "18 28 0.6976931905933367\n",
      "Validation loss: 1.9472906821596938 RMSE: 1.3954537\n",
      "Validation loss: 2.2809353887507346 RMSE: 1.5102766\n",
      "20 20 0.6154693795693936\n",
      "Validation loss: 1.9105196589917208 RMSE: 1.3822154\n",
      "Validation loss: 2.371963746779788 RMSE: 1.5401182\n",
      "22 12 1.8328933440883084\n",
      "Validation loss: 2.433743679417973 RMSE: 1.5600462\n",
      "Validation loss: 2.6780199434904928 RMSE: 1.6364657\n",
      "24 4 0.8141315284810584\n",
      "Validation loss: 3.1892412278504496 RMSE: 1.7858447\n",
      "25 25 1.617696348034845\n",
      "Validation loss: 2.18408065032115 RMSE: 1.4778636\n",
      "Validation loss: 2.084652667551969 RMSE: 1.4438328\n",
      "27 17 0.9313912015648798\n",
      "Validation loss: 2.612266697714814 RMSE: 1.6162508\n",
      "Validation loss: 1.6780066838306664 RMSE: 1.295379\n",
      "29 9 0.6486853757156981\n",
      "Validation loss: 3.524873919191614 RMSE: 1.8774647\n",
      "Validation loss: 1.8142589225178272 RMSE: 1.3469443\n",
      "31 1 0.6835283634978169\n",
      "Validation loss: 2.1955220952498173 RMSE: 1.4817295\n",
      "32 22 0.9289407382514236\n",
      "Validation loss: 1.824631956826269 RMSE: 1.3507894\n",
      "Validation loss: 2.3115177850807664 RMSE: 1.5203675\n",
      "34 14 0.6113055176194924\n",
      "Validation loss: 2.420260363975457 RMSE: 1.5557185\n",
      "Validation loss: 1.9647268974675542 RMSE: 1.4016871\n",
      "36 6 1.1135043814756374\n",
      "Validation loss: 2.184501791422346 RMSE: 1.478006\n",
      "37 27 0.7487728245798746\n",
      "Validation loss: 2.6164778365498096 RMSE: 1.617553\n",
      "Validation loss: 1.7972283173451382 RMSE: 1.3406074\n",
      "39 19 0.8314195761356339\n",
      "Validation loss: 2.5297349934029367 RMSE: 1.5905141\n",
      "Validation loss: 2.740947358376157 RMSE: 1.6555806\n",
      "41 11 1.5504204910885624\n",
      "Validation loss: 2.824165261952223 RMSE: 1.6805253\n",
      "Validation loss: 2.030458901835754 RMSE: 1.4249418\n",
      "43 3 1.0488587684494362\n",
      "Validation loss: 2.5595263464260944 RMSE: 1.599852\n",
      "44 24 0.6421330162661183\n",
      "Validation loss: 1.9345684019865188 RMSE: 1.3908876\n",
      "Validation loss: 2.1286200538145756 RMSE: 1.458979\n",
      "46 16 0.5723360325900521\n",
      "Validation loss: 2.102188770749928 RMSE: 1.4498926\n",
      "Validation loss: 1.99092840093427 RMSE: 1.4110026\n",
      "48 8 0.702666672452658\n",
      "Validation loss: 1.8687709358941138 RMSE: 1.36703\n",
      "Validation loss: 1.9356017228776374 RMSE: 1.3912591\n",
      "50 0 1.309182647301109\n",
      "Validation loss: 1.9140855949536888 RMSE: 1.3835049\n",
      "51 21 0.47198571126200134\n",
      "Validation loss: 1.9050909818801205 RMSE: 1.3802505\n",
      "Validation loss: 1.8077851607736233 RMSE: 1.344539\n",
      "53 13 0.47104266900640984\n",
      "Validation loss: 2.002400315968336 RMSE: 1.415062\n",
      "Validation loss: 2.137740356732259 RMSE: 1.4621013\n",
      "55 5 1.1461065265736663\n",
      "Validation loss: 2.547039431808269 RMSE: 1.5959448\n",
      "56 26 1.8156422883242296\n",
      "Validation loss: 1.8119816400308524 RMSE: 1.3460988\n",
      "Validation loss: 1.9502256338575246 RMSE: 1.3965048\n",
      "58 18 0.68076977395301\n",
      "Validation loss: 1.787876449855028 RMSE: 1.3371149\n",
      "Validation loss: 1.9107258594141596 RMSE: 1.38229\n",
      "60 10 0.9601939080998233\n",
      "Validation loss: 2.41872503377695 RMSE: 1.5552251\n",
      "Validation loss: 1.8468248675354815 RMSE: 1.3589793\n",
      "62 2 0.6077562194250881\n",
      "Validation loss: 2.0775106533438756 RMSE: 1.4413573\n",
      "63 23 0.5107619390668946\n",
      "Validation loss: 1.913180874512259 RMSE: 1.3831779\n",
      "Validation loss: 1.8690101551798592 RMSE: 1.3671175\n",
      "65 15 1.2024539912542334\n",
      "Validation loss: 2.206548987236698 RMSE: 1.4854457\n",
      "Validation loss: 1.8277704620783308 RMSE: 1.3519505\n",
      "67 7 0.8853535928031863\n",
      "Validation loss: 1.919626841502907 RMSE: 1.385506\n",
      "68 28 2.766120894855141\n",
      "Validation loss: 1.6144805239365163 RMSE: 1.2706221\n",
      "Validation loss: 1.653221303382806 RMSE: 1.2857765\n",
      "70 20 0.7009641143593734\n",
      "Validation loss: 1.856968966205563 RMSE: 1.3627065\n",
      "Validation loss: 1.5385375898496239 RMSE: 1.240378\n",
      "72 12 0.6304969460158704\n",
      "Validation loss: 1.7486964179351268 RMSE: 1.3223829\n",
      "Validation loss: 1.4906583750142461 RMSE: 1.2209252\n",
      "74 4 0.6931952561256245\n",
      "Validation loss: 1.6049929371977274 RMSE: 1.2668831\n",
      "75 25 1.0806244305634813\n",
      "Validation loss: 1.781347815969349 RMSE: 1.3346715\n",
      "Validation loss: 2.019373045558423 RMSE: 1.4210465\n",
      "77 17 0.5666063435237648\n",
      "Validation loss: 1.8078918520328218 RMSE: 1.3445787\n",
      "Validation loss: 1.972713739471098 RMSE: 1.4045333\n",
      "79 9 0.3403841551707678\n",
      "Validation loss: 1.5988763644631985 RMSE: 1.2644668\n",
      "Validation loss: 2.135767670859278 RMSE: 1.4614265\n",
      "81 1 0.5917003097566446\n",
      "Validation loss: 1.7169495304073907 RMSE: 1.3103242\n",
      "82 22 0.9826734539784908\n",
      "Validation loss: 1.7815754835584523 RMSE: 1.3347567\n",
      "Validation loss: 1.794849245949129 RMSE: 1.3397199\n",
      "84 14 0.589154507693127\n",
      "Validation loss: 2.0715049758421635 RMSE: 1.4392724\n",
      "Validation loss: 2.3181842322898123 RMSE: 1.5225585\n",
      "86 6 1.0157493159401771\n",
      "Validation loss: 1.8242653328760536 RMSE: 1.3506536\n",
      "87 27 0.7036825601959477\n",
      "Validation loss: 2.0610275120861763 RMSE: 1.4356279\n",
      "Validation loss: 1.6322221186308734 RMSE: 1.2775846\n",
      "89 19 0.3427250201201221\n",
      "Validation loss: 2.2065247729816266 RMSE: 1.4854376\n",
      "Validation loss: 1.6548358634509872 RMSE: 1.2864043\n",
      "91 11 1.1478021538357195\n",
      "Validation loss: 1.884742055319052 RMSE: 1.3728591\n",
      "Validation loss: 2.58054238716058 RMSE: 1.6064066\n",
      "93 3 0.7607131158400285\n",
      "Validation loss: 2.487661988334318 RMSE: 1.5772324\n",
      "94 24 0.6177143942499664\n",
      "Validation loss: 2.052942934289443 RMSE: 1.4328095\n",
      "Validation loss: 1.7279288241293578 RMSE: 1.3145071\n",
      "96 16 0.5851678568912788\n",
      "Validation loss: 2.1108343485182366 RMSE: 1.4528711\n",
      "Validation loss: 1.9332976726304114 RMSE: 1.3904307\n",
      "98 8 0.5887261289864882\n",
      "Validation loss: 2.202538356316828 RMSE: 1.4840951\n",
      "Validation loss: 1.8945269384215364 RMSE: 1.3764181\n",
      "100 0 0.6555081439679218\n",
      "Validation loss: 2.332748402536443 RMSE: 1.527334\n",
      "101 21 0.6205260880223653\n",
      "Validation loss: 1.7909947380555415 RMSE: 1.3382804\n",
      "Validation loss: 1.9427041226783686 RMSE: 1.3938092\n",
      "103 13 0.6005443303993558\n",
      "Validation loss: 2.02369211205339 RMSE: 1.4225652\n",
      "Validation loss: 1.6508999271730407 RMSE: 1.2848735\n",
      "105 5 0.7377158692351358\n",
      "Validation loss: 1.883072549262933 RMSE: 1.3722509\n",
      "106 26 1.438589165191821\n",
      "Validation loss: 2.1619989608241394 RMSE: 1.4703737\n",
      "Validation loss: 1.5345967069136357 RMSE: 1.2387884\n",
      "108 18 0.17138995061065998\n",
      "Validation loss: 1.7840882914256206 RMSE: 1.3356977\n",
      "Validation loss: 1.7517211679863718 RMSE: 1.323526\n",
      "110 10 0.3516445132713816\n",
      "Validation loss: 3.063294602706369 RMSE: 1.750227\n",
      "Validation loss: 1.7501167407078027 RMSE: 1.3229198\n",
      "112 2 0.4336230291053722\n",
      "Validation loss: 2.203895223879181 RMSE: 1.4845523\n",
      "113 23 0.6232142530832094\n",
      "Validation loss: 1.9283661568059332 RMSE: 1.3886563\n",
      "Validation loss: 1.5016920228975008 RMSE: 1.2254355\n",
      "115 15 0.6323989541157836\n",
      "Validation loss: 2.6321046668871313 RMSE: 1.6223762\n",
      "Validation loss: 2.0653449529040175 RMSE: 1.4371308\n",
      "117 7 0.8738346900070166\n",
      "Validation loss: 1.7180737668434076 RMSE: 1.3107531\n",
      "118 28 0.8364035314270089\n",
      "Validation loss: 1.9514775856406288 RMSE: 1.396953\n",
      "Validation loss: 1.9619936732064307 RMSE: 1.4007119\n",
      "120 20 0.48751674523476224\n",
      "Validation loss: 1.963922186235411 RMSE: 1.4014001\n",
      "Validation loss: 2.046570863343973 RMSE: 1.4305842\n",
      "122 12 0.3552219836877959\n",
      "Validation loss: 2.0152824863923335 RMSE: 1.4196064\n",
      "Validation loss: 1.7063571008960758 RMSE: 1.306276\n",
      "124 4 0.5026102746184209\n",
      "Validation loss: 1.6715347703579253 RMSE: 1.2928785\n",
      "125 25 0.6617990807435116\n",
      "Validation loss: 1.658580823282225 RMSE: 1.287859\n",
      "Validation loss: 1.5700335629218447 RMSE: 1.2530097\n",
      "127 17 0.3912347079289456\n",
      "Validation loss: 1.7129087901748388 RMSE: 1.3087815\n",
      "Validation loss: 1.6251301185219689 RMSE: 1.2748059\n",
      "129 9 0.8321260815520881\n",
      "Validation loss: 1.4823256952572712 RMSE: 1.217508\n",
      "Validation loss: 2.1352114804023135 RMSE: 1.4612364\n",
      "131 1 1.364381775249503\n",
      "Validation loss: 1.8891114534529965 RMSE: 1.3744495\n",
      "132 22 0.7652788908056694\n",
      "Validation loss: 1.7267419954316805 RMSE: 1.3140556\n",
      "Validation loss: 1.7936915834393121 RMSE: 1.3392876\n",
      "134 14 0.824593802867149\n",
      "Validation loss: 1.9445430367393832 RMSE: 1.3944687\n",
      "Validation loss: 1.8114010612521552 RMSE: 1.345883\n",
      "136 6 0.9512884310480285\n",
      "Validation loss: 1.805766842006582 RMSE: 1.3437883\n",
      "137 27 0.8225742941594113\n",
      "Validation loss: 1.839580865032905 RMSE: 1.3563113\n",
      "Validation loss: 1.8218931655968185 RMSE: 1.3497752\n",
      "139 19 0.42659762642735055\n",
      "Validation loss: 1.8874226587008587 RMSE: 1.373835\n",
      "Validation loss: 1.71322402067944 RMSE: 1.3089019\n",
      "141 11 0.3512775301722979\n",
      "Validation loss: 1.8837164798669055 RMSE: 1.3724855\n",
      "Validation loss: 1.661618466925832 RMSE: 1.289038\n",
      "143 3 0.3797362528729666\n",
      "Validation loss: 1.6633615367180479 RMSE: 1.2897137\n",
      "144 24 0.6490699864432788\n",
      "Validation loss: 2.104730650386979 RMSE: 1.450769\n",
      "Validation loss: 1.6824204088312336 RMSE: 1.2970815\n",
      "146 16 0.22271272985823756\n",
      "Validation loss: 1.4670799601394517 RMSE: 1.2112308\n",
      "Validation loss: 2.131702502216913 RMSE: 1.4600351\n",
      "148 8 0.3155910518134253\n",
      "Validation loss: 1.9712429964436895 RMSE: 1.4040097\n",
      "Validation loss: 2.418509702766891 RMSE: 1.5551559\n",
      "150 0 0.29343014581744975\n",
      "Validation loss: 1.9940290630391213 RMSE: 1.4121009\n",
      "151 21 0.7644624271293441\n",
      "Validation loss: 1.8434353022448784 RMSE: 1.3577317\n",
      "Validation loss: 1.6518288966828742 RMSE: 1.2852349\n",
      "153 13 0.24066089043264133\n",
      "Validation loss: 1.8185277544291674 RMSE: 1.348528\n",
      "Validation loss: 1.5470846627665833 RMSE: 1.2438186\n",
      "155 5 0.5024538810219171\n",
      "Validation loss: 1.8906971785874493 RMSE: 1.3750262\n",
      "156 26 0.534347750974469\n",
      "Validation loss: 2.344050749740769 RMSE: 1.5310293\n",
      "Validation loss: 1.6154550134608177 RMSE: 1.2710055\n",
      "158 18 0.452620038573673\n",
      "Validation loss: 1.6848702916001852 RMSE: 1.2980255\n",
      "Validation loss: 1.7459254317579016 RMSE: 1.3213346\n",
      "160 10 0.32344974420745143\n",
      "Validation loss: 1.5337888245034006 RMSE: 1.2384623\n",
      "Validation loss: 1.5562120021971981 RMSE: 1.2474823\n",
      "162 2 0.7780633343333538\n",
      "Validation loss: 2.231652717674728 RMSE: 1.4938717\n",
      "163 23 0.9832129155660337\n",
      "Validation loss: 2.0046310424804688 RMSE: 1.4158498\n",
      "Validation loss: 1.84580679593888 RMSE: 1.3586048\n",
      "165 15 0.5605199872490505\n",
      "Validation loss: 1.9473020017674538 RMSE: 1.3954576\n",
      "Validation loss: 1.6561858137096979 RMSE: 1.2869289\n",
      "167 7 0.44699723154092696\n",
      "Validation loss: 1.7457952995215897 RMSE: 1.3212855\n",
      "168 28 0.223128096256607\n",
      "Validation loss: 1.564469228803584 RMSE: 1.2507875\n",
      "Validation loss: 1.9920134554922053 RMSE: 1.4113871\n",
      "170 20 0.5918397802975285\n",
      "Validation loss: 2.0974627828176042 RMSE: 1.448262\n",
      "Validation loss: 1.8703249017749213 RMSE: 1.3675983\n",
      "172 12 0.3163468309167575\n",
      "Validation loss: 1.8656909296997881 RMSE: 1.3659029\n",
      "Validation loss: 1.681654968092927 RMSE: 1.2967864\n",
      "174 4 0.34392494310731947\n",
      "Validation loss: 1.7777983815269132 RMSE: 1.3333411\n",
      "175 25 0.3734098014882417\n",
      "Validation loss: 1.8229091631627716 RMSE: 1.3501515\n",
      "Validation loss: 2.5502343599775195 RMSE: 1.5969453\n",
      "177 17 0.4322073993177904\n",
      "Validation loss: 2.04680840315017 RMSE: 1.430667\n",
      "Validation loss: 1.7232096849289615 RMSE: 1.3127109\n",
      "179 9 0.42669322711114654\n",
      "Validation loss: 1.8718542672891532 RMSE: 1.3681573\n",
      "Validation loss: 1.9834029189253275 RMSE: 1.4083335\n",
      "181 1 0.6090065720233451\n",
      "Validation loss: 2.0977962871568394 RMSE: 1.4483771\n",
      "182 22 0.8003876990714163\n",
      "Validation loss: 2.7255464001039487 RMSE: 1.6509229\n",
      "Validation loss: 3.3401115552514002 RMSE: 1.827597\n",
      "184 14 0.3660363048738875\n",
      "Validation loss: 2.274820471231916 RMSE: 1.5082507\n",
      "Validation loss: 2.0594731896324494 RMSE: 1.4350865\n",
      "186 6 0.3921416650186725\n",
      "Validation loss: 3.292813317965617 RMSE: 1.8146108\n",
      "187 27 0.31589416062416814\n",
      "Validation loss: 2.1910199464949884 RMSE: 1.4802095\n",
      "Validation loss: 2.5888797688273204 RMSE: 1.6089996\n",
      "189 19 0.49686623831074994\n",
      "Validation loss: 3.121289687874043 RMSE: 1.7667172\n",
      "Validation loss: 1.5869400954879491 RMSE: 1.2597381\n",
      "191 11 0.33242843049635\n",
      "Validation loss: 2.146416491111823 RMSE: 1.4650654\n",
      "Validation loss: 2.4016628455271762 RMSE: 1.54973\n",
      "193 3 0.2098169295023759\n",
      "Validation loss: 2.068834061116244 RMSE: 1.4383442\n",
      "194 24 0.562947816178732\n",
      "Validation loss: 1.9338533498544608 RMSE: 1.3906305\n",
      "Validation loss: 1.6054996557995282 RMSE: 1.2670832\n",
      "196 16 0.27814962187895365\n",
      "Validation loss: 1.9408113576669608 RMSE: 1.3931301\n",
      "Validation loss: 1.5246473740687412 RMSE: 1.2347662\n",
      "198 8 0.5657633627783365\n",
      "Validation loss: 2.162739310644369 RMSE: 1.4706255\n",
      "Validation loss: 2.1545239096194244 RMSE: 1.4678297\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.6159118023593868 Test RMSE: 1.2711852\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 779, 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'target': ['measured log solubility in mols per litre']}}\n",
      "Running on: cuda:1\n",
      "1127\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1127\n",
      "Generating scaffold 1000/1127\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 14.950308226717382\n",
      "Validation loss: 2.4325929046732133 RMSE: 1.5596771\n",
      "1 21 2.303210967645247\n",
      "Validation loss: 2.8102344369466326 RMSE: 1.6763754\n",
      "Validation loss: 4.058462575473617 RMSE: 2.0145626\n",
      "3 13 1.7876409283297758\n",
      "Validation loss: 7.079682493631819 RMSE: 2.6607676\n",
      "Validation loss: 2.78293338708118 RMSE: 1.6682128\n",
      "5 5 1.4093844795969614\n",
      "Validation loss: 2.4594332000850576 RMSE: 1.568258\n",
      "6 26 1.7007925077637445\n",
      "Validation loss: 3.0306147853885075 RMSE: 1.7408661\n",
      "Validation loss: 3.1633053775382254 RMSE: 1.7785683\n",
      "8 18 1.228000622984445\n",
      "Validation loss: 2.605167289750766 RMSE: 1.6140531\n",
      "Validation loss: 3.30023455619812 RMSE: 1.8166548\n",
      "10 10 1.0999376393101967\n",
      "Validation loss: 2.8981913866195 RMSE: 1.7024075\n",
      "Validation loss: 2.377722854107882 RMSE: 1.5419867\n",
      "12 2 1.4160954381994213\n",
      "Validation loss: 1.9369030884936846 RMSE: 1.3917266\n",
      "13 23 0.770640945775682\n",
      "Validation loss: 1.6642379739643198 RMSE: 1.2900536\n",
      "Validation loss: 2.2634014176056447 RMSE: 1.5044606\n",
      "15 15 1.8053286897377276\n",
      "Validation loss: 1.9381997442878454 RMSE: 1.3921925\n",
      "Validation loss: 2.4704042050690775 RMSE: 1.571752\n",
      "17 7 0.826850289269711\n",
      "Validation loss: 2.916534214948131 RMSE: 1.7077863\n",
      "18 28 1.791664492751866\n",
      "Validation loss: 3.552511746904491 RMSE: 1.8848108\n",
      "Validation loss: 4.361081123352051 RMSE: 2.0883203\n",
      "20 20 0.7703263130640572\n",
      "Validation loss: 2.865053778201078 RMSE: 1.692647\n",
      "Validation loss: 3.139268189404918 RMSE: 1.771798\n",
      "22 12 1.8897096462324716\n",
      "Validation loss: 2.54512787603699 RMSE: 1.5953456\n",
      "Validation loss: 5.56360878986595 RMSE: 2.3587306\n",
      "24 4 2.3986738808124217\n",
      "Validation loss: 2.6693547426071844 RMSE: 1.633816\n",
      "25 25 0.7893717098500714\n",
      "Validation loss: 2.090870840359578 RMSE: 1.4459844\n",
      "Validation loss: 2.854845365591809 RMSE: 1.6896287\n",
      "27 17 0.5354916306327654\n",
      "Validation loss: 2.018227994969461 RMSE: 1.4206434\n",
      "Validation loss: 2.4791061414026583 RMSE: 1.5745178\n",
      "29 9 1.143134692848863\n",
      "Validation loss: 1.7684992499056116 RMSE: 1.3298492\n",
      "Validation loss: 3.651405161460944 RMSE: 1.9108651\n",
      "31 1 1.6927468804960353\n",
      "Validation loss: 1.763237873009876 RMSE: 1.3278697\n",
      "32 22 0.6580376518342755\n",
      "Validation loss: 1.8223547418560602 RMSE: 1.3499463\n",
      "Validation loss: 1.9875084657584672 RMSE: 1.4097902\n",
      "34 14 1.4662261766848785\n",
      "Validation loss: 2.4765285496163156 RMSE: 1.5736989\n",
      "Validation loss: 2.0555772454337737 RMSE: 1.4337283\n",
      "36 6 1.112543026181503\n",
      "Validation loss: 2.247733508591103 RMSE: 1.4992442\n",
      "37 27 0.6116513554892148\n",
      "Validation loss: 1.968188853390449 RMSE: 1.4029216\n",
      "Validation loss: 1.8370624801753896 RMSE: 1.3553828\n",
      "39 19 1.1257295844631827\n",
      "Validation loss: 2.108708685478278 RMSE: 1.4521394\n",
      "Validation loss: 2.301590946923315 RMSE: 1.5170995\n",
      "41 11 0.7162937730617825\n",
      "Validation loss: 4.5010007187328505 RMSE: 2.1215563\n",
      "Validation loss: 2.441705935824234 RMSE: 1.5625958\n",
      "43 3 0.6813804655123\n",
      "Validation loss: 2.1129169822794145 RMSE: 1.4535877\n",
      "44 24 0.6146687092629499\n",
      "Validation loss: 1.8321621133162913 RMSE: 1.3535739\n",
      "Validation loss: 3.3761802099447333 RMSE: 1.8374385\n",
      "46 16 1.01673235351194\n",
      "Validation loss: 1.9727293179098484 RMSE: 1.4045389\n",
      "Validation loss: 2.3608682936271737 RMSE: 1.5365117\n",
      "48 8 0.618094034324985\n",
      "Validation loss: 2.8317258758882504 RMSE: 1.6827732\n",
      "Validation loss: 2.1150742426382756 RMSE: 1.4543295\n",
      "50 0 0.546683357663273\n",
      "Validation loss: 1.6634813357243496 RMSE: 1.2897602\n",
      "51 21 0.9226679888552397\n",
      "Validation loss: 2.3430465343779168 RMSE: 1.5307013\n",
      "Validation loss: 2.1218645182331053 RMSE: 1.456662\n",
      "53 13 0.730625050636602\n",
      "Validation loss: 2.0606460170408267 RMSE: 1.435495\n",
      "Validation loss: 2.1473146961853566 RMSE: 1.4653718\n",
      "55 5 0.5820374845435751\n",
      "Validation loss: 2.4170374511617476 RMSE: 1.5546825\n",
      "56 26 1.5765496066790197\n",
      "Validation loss: 2.3748962552146575 RMSE: 1.5410699\n",
      "Validation loss: 2.2569079926583617 RMSE: 1.5023009\n",
      "58 18 0.7096805253080835\n",
      "Validation loss: 2.236154024579884 RMSE: 1.4953775\n",
      "Validation loss: 2.025015090419128 RMSE: 1.4230301\n",
      "60 10 0.9015670096394534\n",
      "Validation loss: 1.7679455649536269 RMSE: 1.3296412\n",
      "Validation loss: 2.5343753637465753 RMSE: 1.5919721\n",
      "62 2 0.49821972402894016\n",
      "Validation loss: 2.900065874631426 RMSE: 1.702958\n",
      "63 23 0.40777705005595516\n",
      "Validation loss: 1.6062985268314327 RMSE: 1.2673984\n",
      "Validation loss: 1.9613404822560538 RMSE: 1.4004787\n",
      "65 15 1.6775897744606514\n",
      "Validation loss: 2.148303390604205 RMSE: 1.4657092\n",
      "Validation loss: 1.8452079422705996 RMSE: 1.3583843\n",
      "67 7 0.3978022861874535\n",
      "Validation loss: 1.9815047842211428 RMSE: 1.4076593\n",
      "68 28 1.733843209869819\n",
      "Validation loss: 1.9509985341434986 RMSE: 1.3967814\n",
      "Validation loss: 1.8319483816096214 RMSE: 1.3534949\n",
      "70 20 0.6280373730246098\n",
      "Validation loss: 1.7895830922422156 RMSE: 1.337753\n",
      "Validation loss: 2.049073533674257 RMSE: 1.4314586\n",
      "72 12 0.4595404782248713\n",
      "Validation loss: 2.2797489261205217 RMSE: 1.5098838\n",
      "Validation loss: 2.1453284753107393 RMSE: 1.464694\n",
      "74 4 0.6580082683538964\n",
      "Validation loss: 1.8464262422207183 RMSE: 1.3588326\n",
      "75 25 0.6438480865322744\n",
      "Validation loss: 1.4204235298443684 RMSE: 1.1918153\n",
      "Validation loss: 1.9389176168272981 RMSE: 1.3924502\n",
      "77 17 1.116479358360728\n",
      "Validation loss: 1.6591212127061017 RMSE: 1.2880688\n",
      "Validation loss: 1.751955558768416 RMSE: 1.3236146\n",
      "79 9 0.6366401357339492\n",
      "Validation loss: 1.560949408902531 RMSE: 1.2493796\n",
      "Validation loss: 1.977957858448535 RMSE: 1.4063989\n",
      "81 1 0.7778824244907817\n",
      "Validation loss: 2.1461142860682663 RMSE: 1.4649622\n",
      "82 22 0.6176382866628972\n",
      "Validation loss: 2.4387885627493393 RMSE: 1.5616621\n",
      "Validation loss: 1.5619791461303172 RMSE: 1.2497916\n",
      "84 14 0.562830020620139\n",
      "Validation loss: 1.7227069804098754 RMSE: 1.3125194\n",
      "Validation loss: 1.6651009173519844 RMSE: 1.290388\n",
      "86 6 1.012198458370709\n",
      "Validation loss: 1.6389300021450077 RMSE: 1.280207\n",
      "87 27 0.7492982348109638\n",
      "Validation loss: 2.046599856520121 RMSE: 1.4305942\n",
      "Validation loss: 2.220648947015273 RMSE: 1.4901842\n",
      "89 19 0.8300290115745765\n",
      "Validation loss: 1.7375583305823064 RMSE: 1.3181647\n",
      "Validation loss: 1.868449884178364 RMSE: 1.3669126\n",
      "91 11 0.8965235752219152\n",
      "Validation loss: 1.5927160102709206 RMSE: 1.2620286\n",
      "Validation loss: 1.678267465228528 RMSE: 1.2954795\n",
      "93 3 0.6127276266097628\n",
      "Validation loss: 1.9003150136069913 RMSE: 1.3785192\n",
      "94 24 0.6511323438662717\n",
      "Validation loss: 2.6180801644789433 RMSE: 1.6180484\n",
      "Validation loss: 1.6583679450296722 RMSE: 1.2877765\n",
      "96 16 0.3964582468572522\n",
      "Validation loss: 1.6258553888945453 RMSE: 1.2750903\n",
      "Validation loss: 2.5222989384051973 RMSE: 1.5881747\n",
      "98 8 0.38694757823161785\n",
      "Validation loss: 1.4814579845529743 RMSE: 1.2171515\n",
      "Validation loss: 1.6436516964330083 RMSE: 1.2820498\n",
      "100 0 0.5783181022059313\n",
      "Validation loss: 1.949610424252738 RMSE: 1.3962845\n",
      "101 21 0.9520649686914359\n",
      "Validation loss: 1.7915526343657908 RMSE: 1.3384889\n",
      "Validation loss: 1.4978820750143675 RMSE: 1.22388\n",
      "103 13 0.41762398884213325\n",
      "Validation loss: 1.955918743547085 RMSE: 1.3985416\n",
      "Validation loss: 1.4477693422705726 RMSE: 1.2032328\n",
      "105 5 0.4222272931388046\n",
      "Validation loss: 2.1640368837170896 RMSE: 1.4710666\n",
      "106 26 0.5792806158420205\n",
      "Validation loss: 1.599247090584409 RMSE: 1.2646135\n",
      "Validation loss: 1.6966236819208196 RMSE: 1.3025451\n",
      "108 18 0.27719398370105336\n",
      "Validation loss: 1.7376053396579438 RMSE: 1.3181826\n",
      "Validation loss: 2.095969966027589 RMSE: 1.4477466\n",
      "110 10 0.5283014452471888\n",
      "Validation loss: 1.8904149110338329 RMSE: 1.3749236\n",
      "Validation loss: 1.376025733694566 RMSE: 1.1730412\n",
      "112 2 0.3578674959063148\n",
      "Validation loss: 1.4981342269256053 RMSE: 1.2239829\n",
      "113 23 0.5750994015716326\n",
      "Validation loss: 1.766225812709437 RMSE: 1.3289943\n",
      "Validation loss: 1.9519538531261207 RMSE: 1.3971235\n",
      "115 15 0.6450756863433049\n",
      "Validation loss: 1.9199742869993226 RMSE: 1.3856313\n",
      "Validation loss: 1.9183747578511197 RMSE: 1.3850541\n",
      "117 7 0.9109874918701465\n",
      "Validation loss: 1.6550098056286837 RMSE: 1.286472\n",
      "118 28 0.8860754611233191\n",
      "Validation loss: 1.9192373436109154 RMSE: 1.3853655\n",
      "Validation loss: 1.6927161016295442 RMSE: 1.3010443\n",
      "120 20 0.4738616266556491\n",
      "Validation loss: 1.8997997984421993 RMSE: 1.3783323\n",
      "Validation loss: 1.690869720636216 RMSE: 1.3003345\n",
      "122 12 0.4123789624804325\n",
      "Validation loss: 1.8714069877050619 RMSE: 1.3679938\n",
      "Validation loss: 1.7749462085487568 RMSE: 1.3322711\n",
      "124 4 0.7617896138096889\n",
      "Validation loss: 1.7077887554084306 RMSE: 1.3068238\n",
      "125 25 0.5469960238233276\n",
      "Validation loss: 1.8192030244168982 RMSE: 1.3487784\n",
      "Validation loss: 1.8542626368261017 RMSE: 1.361713\n",
      "127 17 1.2501755939578794\n",
      "Validation loss: 2.0258974807452312 RMSE: 1.4233403\n",
      "Validation loss: 1.7028240598408522 RMSE: 1.304923\n",
      "129 9 0.37199852633648334\n",
      "Validation loss: 1.8319096902830412 RMSE: 1.3534806\n",
      "Validation loss: 1.4566308112271065 RMSE: 1.2069098\n",
      "131 1 0.6171726291460253\n",
      "Validation loss: 1.838709194048316 RMSE: 1.3559902\n",
      "132 22 0.2992112009718807\n",
      "Validation loss: 1.752695507707849 RMSE: 1.3238941\n",
      "Validation loss: 1.7658103915442407 RMSE: 1.328838\n",
      "134 14 0.45281519431907663\n",
      "Validation loss: 2.1365390477982245 RMSE: 1.4616905\n",
      "Validation loss: 1.3945030374864562 RMSE: 1.1808908\n",
      "136 6 0.41172443533810293\n",
      "Validation loss: 2.1369837965585488 RMSE: 1.4618425\n",
      "137 27 0.29781733177943215\n",
      "Validation loss: 1.8934439009269781 RMSE: 1.3760246\n",
      "Validation loss: 1.6015911629769655 RMSE: 1.2655399\n",
      "139 19 1.4058581735644144\n",
      "Validation loss: 1.7571087622009547 RMSE: 1.3255597\n",
      "Validation loss: 2.5914420596266217 RMSE: 1.6097957\n",
      "141 11 0.6841970125236888\n",
      "Validation loss: 1.9625947074552552 RMSE: 1.4009264\n",
      "Validation loss: 1.6260296159085974 RMSE: 1.2751586\n",
      "143 3 0.348917420679677\n",
      "Validation loss: 1.8461347850023118 RMSE: 1.3587254\n",
      "144 24 0.880059599914768\n",
      "Validation loss: 1.9232122581616966 RMSE: 1.3867993\n",
      "Validation loss: 1.6325283472516896 RMSE: 1.2777044\n",
      "146 16 1.106638159104821\n",
      "Validation loss: 1.6117385193309952 RMSE: 1.2695426\n",
      "Validation loss: 1.8287913060821264 RMSE: 1.3523281\n",
      "148 8 0.4075067215651686\n",
      "Validation loss: 1.8143475129541042 RMSE: 1.3469771\n",
      "Validation loss: 2.041781425476074 RMSE: 1.4289092\n",
      "150 0 0.6626431775186991\n",
      "Validation loss: 1.753068297310213 RMSE: 1.3240348\n",
      "151 21 0.5973672269981923\n",
      "Validation loss: 1.5500285319522418 RMSE: 1.2450014\n",
      "Validation loss: 2.3350531063248625 RMSE: 1.528088\n",
      "153 13 0.5427099840019323\n",
      "Validation loss: 1.7186610118477745 RMSE: 1.3109771\n",
      "Validation loss: 1.7429269467834878 RMSE: 1.3201995\n",
      "155 5 0.36752436998101706\n",
      "Validation loss: 1.7347612897906683 RMSE: 1.3171034\n",
      "156 26 0.6078170331658228\n",
      "Validation loss: 1.403862308611912 RMSE: 1.1848469\n",
      "Validation loss: 1.6470667978303621 RMSE: 1.2833809\n",
      "158 18 0.5400793894503081\n",
      "Validation loss: 1.6506200891680423 RMSE: 1.2847646\n",
      "Validation loss: 1.7882554309558025 RMSE: 1.3372567\n",
      "160 10 0.5672126065634782\n",
      "Validation loss: 1.715159644067815 RMSE: 1.309641\n",
      "Validation loss: 1.912001053843878 RMSE: 1.3827513\n",
      "162 2 0.36245860864553403\n",
      "Validation loss: 1.6065391397054216 RMSE: 1.2674932\n",
      "163 23 0.4020435884903213\n",
      "Validation loss: 1.6496351503692896 RMSE: 1.2843812\n",
      "Validation loss: 1.8745676490057885 RMSE: 1.3691485\n",
      "165 15 0.29375014640675573\n",
      "Validation loss: 1.7065688846385585 RMSE: 1.3063571\n",
      "Validation loss: 1.58315875361451 RMSE: 1.2582364\n",
      "167 7 0.2903882113735468\n",
      "Validation loss: 1.763020834036633 RMSE: 1.3277879\n",
      "168 28 2.2603852478047757\n",
      "Validation loss: 1.8364592168183453 RMSE: 1.3551602\n",
      "Validation loss: 2.1758290160018787 RMSE: 1.4750692\n",
      "170 20 0.31306242090868097\n",
      "Validation loss: 1.5053098544610286 RMSE: 1.2269107\n",
      "Validation loss: 1.4129458813540703 RMSE: 1.1886741\n",
      "172 12 0.6184180683464927\n",
      "Validation loss: 1.6639827890733703 RMSE: 1.2899545\n",
      "Validation loss: 1.9478391197930396 RMSE: 1.3956499\n",
      "174 4 0.4044807916594751\n",
      "Validation loss: 1.9075683745662724 RMSE: 1.3811475\n",
      "175 25 0.29406889498118666\n",
      "Validation loss: 1.7783456217926161 RMSE: 1.3335462\n",
      "Validation loss: 1.5294011736338118 RMSE: 1.2366896\n",
      "177 17 0.36905687606532694\n",
      "Validation loss: 1.6451086333367677 RMSE: 1.2826178\n",
      "Validation loss: 1.6956056430276516 RMSE: 1.3021542\n",
      "179 9 0.7401856704316419\n",
      "Validation loss: 1.6548637974578722 RMSE: 1.2864151\n",
      "Validation loss: 1.7461665710516736 RMSE: 1.3214259\n",
      "181 1 0.25438721029129946\n",
      "Validation loss: 1.6515503320018803 RMSE: 1.2851266\n",
      "182 22 0.43104560574033735\n",
      "Validation loss: 1.8143804537511505 RMSE: 1.3469895\n",
      "Validation loss: 2.0180472546974113 RMSE: 1.4205799\n",
      "184 14 0.3094585772454884\n",
      "Validation loss: 1.8239100607095566 RMSE: 1.350522\n",
      "Validation loss: 1.83354356120118 RMSE: 1.354084\n",
      "186 6 0.6103770482263999\n",
      "Validation loss: 1.6925026568691288 RMSE: 1.3009622\n",
      "187 27 0.37704397410246465\n",
      "Validation loss: 2.0173459696558727 RMSE: 1.420333\n",
      "Validation loss: 2.0328044057947343 RMSE: 1.4257646\n",
      "189 19 0.2494518476983649\n",
      "Validation loss: 1.8875118610078254 RMSE: 1.3738675\n",
      "Validation loss: 1.4912963145602065 RMSE: 1.2211864\n",
      "191 11 0.43073506846445975\n",
      "Validation loss: 1.8100513789506085 RMSE: 1.3453814\n",
      "Validation loss: 1.7054951728972714 RMSE: 1.3059461\n",
      "193 3 0.5720578138616733\n",
      "Validation loss: 1.786016088671389 RMSE: 1.3364191\n",
      "194 24 0.6252694835072066\n",
      "Validation loss: 1.7254714480543558 RMSE: 1.313572\n",
      "Validation loss: 1.6116851747563454 RMSE: 1.2695216\n",
      "196 16 0.22522614470855104\n",
      "Validation loss: 1.916463743268916 RMSE: 1.384364\n",
      "Validation loss: 1.9266572082992148 RMSE: 1.3880408\n",
      "198 8 0.8654382746078767\n",
      "Validation loss: 1.8503609442077906 RMSE: 1.3602798\n",
      "Validation loss: 1.7789602406257021 RMSE: 1.3337767\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.7088948182300128 Test RMSE: 1.307247\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 780, 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'target': ['measured log solubility in mols per litre']}}\n",
      "Running on: cuda:1\n",
      "1127\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1127\n",
      "Generating scaffold 1000/1127\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 17.313997050806652\n",
      "Validation loss: 2.408139874449873 RMSE: 1.5518183\n",
      "1 21 3.100102989848851\n",
      "Validation loss: 4.651013330020736 RMSE: 2.156621\n",
      "Validation loss: 4.017275236349191 RMSE: 2.0043142\n",
      "3 13 1.7128100520628902\n",
      "Validation loss: 5.454199596843888 RMSE: 2.3354225\n",
      "Validation loss: 3.4616125199647074 RMSE: 1.860541\n",
      "5 5 1.4839900768618306\n",
      "Validation loss: 2.89291094889683 RMSE: 1.700856\n",
      "6 26 1.4168792050646046\n",
      "Validation loss: 2.561860335611664 RMSE: 1.6005813\n",
      "Validation loss: 2.2267545788688996 RMSE: 1.4922314\n",
      "8 18 1.3440326373636828\n",
      "Validation loss: 1.9323056609229703 RMSE: 1.3900739\n",
      "Validation loss: 3.3152270654661464 RMSE: 1.8207765\n",
      "10 10 0.8925213816525571\n",
      "Validation loss: 2.8914219784525645 RMSE: 1.7004182\n",
      "Validation loss: 3.257428992111071 RMSE: 1.8048348\n",
      "12 2 0.8868901059206897\n",
      "Validation loss: 2.363462016645786 RMSE: 1.5373555\n",
      "13 23 1.8441350873256959\n",
      "Validation loss: 3.189923102876781 RMSE: 1.7860357\n",
      "Validation loss: 2.471980786956517 RMSE: 1.5722535\n",
      "15 15 1.5036148272783028\n",
      "Validation loss: 2.7751551033121293 RMSE: 1.6658797\n",
      "Validation loss: 2.2557425963140165 RMSE: 1.5019128\n",
      "17 7 0.7072416115024319\n",
      "Validation loss: 4.664912232255514 RMSE: 2.1598408\n",
      "18 28 4.3964910928795184\n",
      "Validation loss: 2.1869155347874734 RMSE: 1.4788224\n",
      "Validation loss: 2.5189377291012653 RMSE: 1.5871161\n",
      "20 20 1.0667836633161158\n",
      "Validation loss: 1.9754360587196012 RMSE: 1.4055021\n",
      "Validation loss: 2.198169404426507 RMSE: 1.4826225\n",
      "22 12 0.8893640536223648\n",
      "Validation loss: 2.5159210567980743 RMSE: 1.5861654\n",
      "Validation loss: 3.2488704149701952 RMSE: 1.8024622\n",
      "24 4 1.0917709694437696\n",
      "Validation loss: 2.57631717635467 RMSE: 1.6050909\n",
      "25 25 0.6454357802823968\n",
      "Validation loss: 2.1980171309108227 RMSE: 1.4825711\n",
      "Validation loss: 1.8102261999012095 RMSE: 1.3454465\n",
      "27 17 0.9988771495341364\n",
      "Validation loss: 2.458159986850435 RMSE: 1.567852\n",
      "Validation loss: 2.6469401068392053 RMSE: 1.626942\n",
      "29 9 0.6776241418646283\n",
      "Validation loss: 1.9906614491369872 RMSE: 1.410908\n",
      "Validation loss: 2.2253033819451797 RMSE: 1.4917451\n",
      "31 1 0.7724808371664061\n",
      "Validation loss: 2.3323320308617785 RMSE: 1.5271975\n",
      "32 22 0.6237924073021345\n",
      "Validation loss: 2.091147835275768 RMSE: 1.4460802\n",
      "Validation loss: 1.8465017101405996 RMSE: 1.3588604\n",
      "34 14 0.7464506927318917\n",
      "Validation loss: 2.019969609986364 RMSE: 1.4212563\n",
      "Validation loss: 1.8837769453504445 RMSE: 1.3725075\n",
      "36 6 0.9802327385862626\n",
      "Validation loss: 1.8930825744055013 RMSE: 1.3758935\n",
      "37 27 1.4796877398136765\n",
      "Validation loss: 1.5444896031269986 RMSE: 1.242775\n",
      "Validation loss: 1.9568623800193314 RMSE: 1.3988789\n",
      "39 19 1.4875294080343913\n",
      "Validation loss: 2.0331743681325323 RMSE: 1.4258943\n",
      "Validation loss: 1.831883884109227 RMSE: 1.353471\n",
      "41 11 0.4465965309251603\n",
      "Validation loss: 2.2297572076848122 RMSE: 1.4932371\n",
      "Validation loss: 2.3078671134678665 RMSE: 1.5191666\n",
      "43 3 0.6303775873021942\n",
      "Validation loss: 2.6611301687966407 RMSE: 1.6312971\n",
      "44 24 0.6249673876218147\n",
      "Validation loss: 1.8497166422616065 RMSE: 1.3600428\n",
      "Validation loss: 1.9959099313854116 RMSE: 1.4127668\n",
      "46 16 0.7973121217266969\n",
      "Validation loss: 2.4894165317569157 RMSE: 1.5777885\n",
      "Validation loss: 1.6083380458629237 RMSE: 1.2682027\n",
      "48 8 0.8323725387862223\n",
      "Validation loss: 1.9619385721409215 RMSE: 1.4006921\n",
      "Validation loss: 2.996553707966762 RMSE: 1.7310557\n",
      "50 0 0.6018628504947408\n",
      "Validation loss: 1.8198125910969962 RMSE: 1.3490043\n",
      "51 21 0.886563715826904\n",
      "Validation loss: 2.1961067113201174 RMSE: 1.4819268\n",
      "Validation loss: 2.629686876735856 RMSE: 1.6216309\n",
      "53 13 0.6599826739991956\n",
      "Validation loss: 1.898208046908927 RMSE: 1.3777547\n",
      "Validation loss: 2.0108846731945476 RMSE: 1.4180567\n",
      "55 5 0.9920829739677965\n",
      "Validation loss: 1.780724853540944 RMSE: 1.3344381\n",
      "56 26 0.424704882140189\n",
      "Validation loss: 1.5717576657776284 RMSE: 1.2536976\n",
      "Validation loss: 1.956181102094397 RMSE: 1.3986355\n",
      "58 18 0.5890024981222665\n",
      "Validation loss: 1.7867091862501296 RMSE: 1.3366784\n",
      "Validation loss: 2.0964339549562574 RMSE: 1.4479067\n",
      "60 10 0.8098000846500413\n",
      "Validation loss: 2.875031994507376 RMSE: 1.695592\n",
      "Validation loss: 1.873459403493763 RMSE: 1.3687437\n",
      "62 2 0.5333261461027848\n",
      "Validation loss: 1.7700767443243381 RMSE: 1.3304423\n",
      "63 23 0.7794673685017549\n",
      "Validation loss: 1.940971620314944 RMSE: 1.3931876\n",
      "Validation loss: 1.752371100197851 RMSE: 1.3237715\n",
      "65 15 0.6679768921116275\n",
      "Validation loss: 2.0003904905994383 RMSE: 1.4143517\n",
      "Validation loss: 2.0481977230679673 RMSE: 1.4311526\n",
      "67 7 0.5687554714351468\n",
      "Validation loss: 2.2238393093632385 RMSE: 1.4912542\n",
      "68 28 2.436463167279547\n",
      "Validation loss: 2.0147182709347886 RMSE: 1.4194076\n",
      "Validation loss: 1.5889947540992129 RMSE: 1.2605534\n",
      "70 20 1.1858647475962505\n",
      "Validation loss: 2.2117442578341056 RMSE: 1.4871935\n",
      "Validation loss: 1.7519182388761403 RMSE: 1.3236005\n",
      "72 12 0.5925142660271993\n",
      "Validation loss: 1.7051216690941196 RMSE: 1.3058031\n",
      "Validation loss: 1.7812020704809544 RMSE: 1.3346168\n",
      "74 4 1.2168602529269876\n",
      "Validation loss: 1.8795278831920792 RMSE: 1.3709587\n",
      "75 25 0.6078128664113771\n",
      "Validation loss: 2.0563784194203603 RMSE: 1.4340078\n",
      "Validation loss: 1.7117783959987944 RMSE: 1.3083495\n",
      "77 17 1.0662492994533395\n",
      "Validation loss: 2.2960644021498418 RMSE: 1.515277\n",
      "Validation loss: 1.9255353212356567 RMSE: 1.3876365\n",
      "79 9 1.289737675742346\n",
      "Validation loss: 1.9172412990468792 RMSE: 1.3846447\n",
      "Validation loss: 1.9657193738802345 RMSE: 1.4020411\n",
      "81 1 0.4960940761692413\n",
      "Validation loss: 2.027467267703166 RMSE: 1.4238915\n",
      "82 22 0.37332231793578396\n",
      "Validation loss: 1.8171406298612072 RMSE: 1.3480135\n",
      "Validation loss: 2.0454261598333847 RMSE: 1.430184\n",
      "84 14 0.2918246050284482\n",
      "Validation loss: 2.083527026978214 RMSE: 1.4434428\n",
      "Validation loss: 1.7178188857779038 RMSE: 1.3106558\n",
      "86 6 0.5043759129774058\n",
      "Validation loss: 1.6956011088548508 RMSE: 1.3021525\n",
      "87 27 0.5234497001000027\n",
      "Validation loss: 1.7938488405362694 RMSE: 1.3393464\n",
      "Validation loss: 1.9786097222724848 RMSE: 1.4066308\n",
      "89 19 0.8768952656037063\n",
      "Validation loss: 1.6618395864436057 RMSE: 1.2891235\n",
      "Validation loss: 2.050252971395982 RMSE: 1.4318705\n",
      "91 11 0.939659010302953\n",
      "Validation loss: 2.4976787250653834 RMSE: 1.5804046\n",
      "Validation loss: 2.881700306867076 RMSE: 1.6975571\n",
      "93 3 0.813389784416186\n",
      "Validation loss: 2.274223650451255 RMSE: 1.508053\n",
      "94 24 0.7376048575558273\n",
      "Validation loss: 2.0646627371290087 RMSE: 1.4368935\n",
      "Validation loss: 1.8332788258527233 RMSE: 1.3539863\n",
      "96 16 0.8650630952881811\n",
      "Validation loss: 1.93752960082704 RMSE: 1.3919517\n",
      "Validation loss: 1.8390763839789197 RMSE: 1.3561256\n",
      "98 8 0.6922503028480115\n",
      "Validation loss: 1.67761756994028 RMSE: 1.2952287\n",
      "Validation loss: 2.5810906802658486 RMSE: 1.6065773\n",
      "100 0 0.30965411245351965\n",
      "Validation loss: 2.050287291011979 RMSE: 1.4318824\n",
      "101 21 1.183654417932301\n",
      "Validation loss: 1.3632658514301335 RMSE: 1.1675898\n",
      "Validation loss: 1.7620578613956417 RMSE: 1.3274252\n",
      "103 13 0.2635161187465045\n",
      "Validation loss: 1.6818520347628974 RMSE: 1.2968624\n",
      "Validation loss: 1.7412750773725256 RMSE: 1.3195739\n",
      "105 5 0.3805913916712778\n",
      "Validation loss: 2.0513180504857966 RMSE: 1.4322423\n",
      "106 26 0.36006386781601296\n",
      "Validation loss: 1.7299301877485966 RMSE: 1.3152682\n",
      "Validation loss: 2.1874320971227323 RMSE: 1.4789969\n",
      "108 18 0.8223703232923876\n",
      "Validation loss: 1.925681319911923 RMSE: 1.3876891\n",
      "Validation loss: 2.1308118083835703 RMSE: 1.45973\n",
      "110 10 0.8871964438693811\n",
      "Validation loss: 1.5022972621748933 RMSE: 1.2256824\n",
      "Validation loss: 1.869263541381971 RMSE: 1.3672101\n",
      "112 2 0.6528493171662371\n",
      "Validation loss: 1.918950743379846 RMSE: 1.385262\n",
      "113 23 0.6266027986164467\n",
      "Validation loss: 1.961200330109723 RMSE: 1.4004288\n",
      "Validation loss: 2.019428065392823 RMSE: 1.4210659\n",
      "115 15 1.1855619628939476\n",
      "Validation loss: 1.5120944006253132 RMSE: 1.2296727\n",
      "Validation loss: 1.6142755567500022 RMSE: 1.2705414\n",
      "117 7 0.3962674059968533\n",
      "Validation loss: 1.7585584157336074 RMSE: 1.3261064\n",
      "118 28 0.9752838846544153\n",
      "Validation loss: 1.8249403607528822 RMSE: 1.3509036\n",
      "Validation loss: 1.7060363282144597 RMSE: 1.3061533\n",
      "120 20 0.29736229816825777\n",
      "Validation loss: 2.0826482287550396 RMSE: 1.4431382\n",
      "Validation loss: 1.4342082359094535 RMSE: 1.1975843\n",
      "122 12 0.6629347070175035\n",
      "Validation loss: 1.750686090604394 RMSE: 1.323135\n",
      "Validation loss: 1.6061185334636048 RMSE: 1.2673274\n",
      "124 4 1.5709610800838623\n",
      "Validation loss: 1.7148804727908784 RMSE: 1.3095344\n",
      "125 25 0.4325991305227244\n",
      "Validation loss: 1.6353585435225901 RMSE: 1.2788113\n",
      "Validation loss: 1.8833173080883194 RMSE: 1.3723401\n",
      "127 17 0.6532313307753119\n",
      "Validation loss: 1.930467708975868 RMSE: 1.3894128\n",
      "Validation loss: 1.6926973688918932 RMSE: 1.301037\n",
      "129 9 0.9692895161274946\n",
      "Validation loss: 1.9767452098627005 RMSE: 1.4059677\n",
      "Validation loss: 1.8700364469426922 RMSE: 1.3674928\n",
      "131 1 0.6050862215806759\n",
      "Validation loss: 1.9445806868308413 RMSE: 1.3944823\n",
      "132 22 0.4891017210557281\n",
      "Validation loss: 1.720960908231482 RMSE: 1.3118541\n",
      "Validation loss: 1.6208070548234788 RMSE: 1.2731092\n",
      "134 14 0.5902302777341297\n",
      "Validation loss: 1.7861148066225305 RMSE: 1.3364561\n",
      "Validation loss: 1.5649192966191114 RMSE: 1.2509673\n",
      "136 6 0.4962048159504811\n",
      "Validation loss: 1.4923834442037396 RMSE: 1.2216315\n",
      "137 27 0.35624721697743944\n",
      "Validation loss: 2.0511534688747033 RMSE: 1.4321848\n",
      "Validation loss: 2.16920457899043 RMSE: 1.4728221\n",
      "139 19 0.8617198388406173\n",
      "Validation loss: 1.9154851077932171 RMSE: 1.3840104\n",
      "Validation loss: 1.8505594097407518 RMSE: 1.3603528\n",
      "141 11 0.5028085579766804\n",
      "Validation loss: 1.6212771877778316 RMSE: 1.2732939\n",
      "Validation loss: 1.577579333718899 RMSE: 1.2560172\n",
      "143 3 0.6969688489946637\n",
      "Validation loss: 1.864070403892382 RMSE: 1.3653096\n",
      "144 24 0.22011489647677293\n",
      "Validation loss: 1.550564523555536 RMSE: 1.2452166\n",
      "Validation loss: 1.6980093970762944 RMSE: 1.3030769\n",
      "146 16 0.3858366073225145\n",
      "Validation loss: 1.755400284201698 RMSE: 1.3249152\n",
      "Validation loss: 1.824244885318047 RMSE: 1.3506461\n",
      "148 8 0.5402380081267618\n",
      "Validation loss: 1.9104289692060081 RMSE: 1.3821826\n",
      "Validation loss: 1.928713516851442 RMSE: 1.3887814\n",
      "150 0 0.4135650200837176\n",
      "Validation loss: 1.8857946406423518 RMSE: 1.3732424\n",
      "151 21 1.656944455503536\n",
      "Validation loss: 1.8165904040885184 RMSE: 1.3478094\n",
      "Validation loss: 1.8246210127805187 RMSE: 1.3507853\n",
      "153 13 0.5797103657435966\n",
      "Validation loss: 1.818037628072553 RMSE: 1.3483464\n",
      "Validation loss: 1.6084692731367802 RMSE: 1.2682544\n",
      "155 5 0.32479083392355707\n",
      "Validation loss: 1.7830838386991383 RMSE: 1.3353217\n",
      "156 26 0.4777344272027238\n",
      "Validation loss: 1.7776520173106574 RMSE: 1.3332862\n",
      "Validation loss: 2.256433508037466 RMSE: 1.5021429\n",
      "158 18 0.21058577669343248\n",
      "Validation loss: 2.054066936526678 RMSE: 1.4332017\n",
      "Validation loss: 2.1057333017872497 RMSE: 1.4511145\n",
      "160 10 1.0650110353017332\n",
      "Validation loss: 1.8536794533771752 RMSE: 1.361499\n",
      "Validation loss: 1.855882020123237 RMSE: 1.3623077\n",
      "162 2 0.9799167532409317\n",
      "Validation loss: 1.680032403068205 RMSE: 1.2961606\n",
      "163 23 0.6685139947786095\n",
      "Validation loss: 1.5546189451639632 RMSE: 1.2468436\n",
      "Validation loss: 1.7287020018670411 RMSE: 1.3148011\n",
      "165 15 0.24392979672854806\n",
      "Validation loss: 1.8699567539502033 RMSE: 1.3674636\n",
      "Validation loss: 1.7564978557350361 RMSE: 1.3253294\n",
      "167 7 0.36970052924678715\n",
      "Validation loss: 1.6000385210577366 RMSE: 1.2649263\n",
      "168 28 0.3560801557713885\n",
      "Validation loss: 2.3397567166691333 RMSE: 1.5296264\n",
      "Validation loss: 1.9712156405491112 RMSE: 1.4039999\n",
      "170 20 0.6190203228993716\n",
      "Validation loss: 2.102771069096253 RMSE: 1.4500935\n",
      "Validation loss: 1.7327023185459913 RMSE: 1.3163215\n",
      "172 12 0.47636774274650207\n",
      "Validation loss: 1.8922599469665933 RMSE: 1.3755944\n",
      "Validation loss: 1.792956042078744 RMSE: 1.3390131\n",
      "174 4 0.4162562219691737\n",
      "Validation loss: 1.6673465376406644 RMSE: 1.2912577\n",
      "175 25 0.601532890443406\n",
      "Validation loss: 1.6884393164541869 RMSE: 1.2993996\n",
      "Validation loss: 1.7591859629723878 RMSE: 1.326343\n",
      "177 17 0.36604730593958773\n",
      "Validation loss: 1.4684879895860115 RMSE: 1.2118118\n",
      "Validation loss: 1.5811014122667566 RMSE: 1.2574185\n",
      "179 9 0.4326338987686002\n",
      "Validation loss: 1.6456599024544776 RMSE: 1.2828327\n",
      "Validation loss: 1.804337343283459 RMSE: 1.3432562\n",
      "181 1 0.42035018111429023\n",
      "Validation loss: 1.698933736412926 RMSE: 1.3034315\n",
      "182 22 0.2916136484563125\n",
      "Validation loss: 1.8181961975266447 RMSE: 1.348405\n",
      "Validation loss: 1.958559781049205 RMSE: 1.3994856\n",
      "184 14 0.6036936005999969\n",
      "Validation loss: 1.7675158439484318 RMSE: 1.3294795\n",
      "Validation loss: 1.541216975819748 RMSE: 1.2414577\n",
      "186 6 0.25201003677775263\n",
      "Validation loss: 2.0555353080276895 RMSE: 1.4337139\n",
      "187 27 0.545082244796061\n",
      "Validation loss: 1.9113202453714557 RMSE: 1.3825049\n",
      "Validation loss: 1.8527925816257442 RMSE: 1.3611732\n",
      "189 19 0.3167779509809586\n",
      "Validation loss: 1.681288873199868 RMSE: 1.2966453\n",
      "Validation loss: 1.625409676965359 RMSE: 1.2749156\n",
      "191 11 0.34483926629409145\n",
      "Validation loss: 1.5642770803080195 RMSE: 1.2507107\n",
      "Validation loss: 1.4927757556459544 RMSE: 1.221792\n",
      "193 3 0.2859735855308961\n",
      "Validation loss: 1.7191495009228193 RMSE: 1.3111635\n",
      "194 24 0.6088992671866856\n",
      "Validation loss: 2.0318913375381875 RMSE: 1.4254442\n",
      "Validation loss: 1.5180698664842454 RMSE: 1.2320997\n",
      "196 16 0.6528791485662535\n",
      "Validation loss: 1.5412599386367123 RMSE: 1.2414749\n",
      "Validation loss: 1.7949341430073291 RMSE: 1.3397516\n",
      "198 8 0.4512663625976004\n",
      "Validation loss: 1.589162836032631 RMSE: 1.2606201\n",
      "Validation loss: 2.3111187019179353 RMSE: 1.5202365\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.6180495224167815 Test RMSE: 1.2720257\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'target': ['measured log solubility in mols per litre']}}\n",
      "Running on: cuda:1\n",
      "1127\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1127\n",
      "Generating scaffold 1000/1127\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 15.065126637856173\n",
      "Validation loss: 3.5296620816256095 RMSE: 1.8787396\n",
      "1 21 2.6451872765085667\n",
      "Validation loss: 5.262190441114712 RMSE: 2.2939465\n",
      "Validation loss: 3.7369707559062317 RMSE: 1.9331245\n",
      "3 13 1.8688295585963526\n",
      "Validation loss: 2.969218629651365 RMSE: 1.723142\n",
      "Validation loss: 2.5369330897795415 RMSE: 1.5927753\n",
      "5 5 1.781856411966682\n",
      "Validation loss: 3.063163679257958 RMSE: 1.7501895\n",
      "6 26 1.3345340799010001\n",
      "Validation loss: 1.6736741551255758 RMSE: 1.2937056\n",
      "Validation loss: 4.54008493170274 RMSE: 2.1307476\n",
      "8 18 1.3807972703736946\n",
      "Validation loss: 3.3621106168865103 RMSE: 1.833606\n",
      "Validation loss: 2.587451095074679 RMSE: 1.6085557\n",
      "10 10 2.284339040876243\n",
      "Validation loss: 2.101886996125753 RMSE: 1.4497887\n",
      "Validation loss: 2.0920959700525334 RMSE: 1.446408\n",
      "12 2 1.9545042981641387\n",
      "Validation loss: 2.94637098143586 RMSE: 1.7164996\n",
      "13 23 1.630795580733227\n",
      "Validation loss: 2.3967903124547636 RMSE: 1.548157\n",
      "Validation loss: 2.017266005541371 RMSE: 1.4203048\n",
      "15 15 1.061483546866536\n",
      "Validation loss: 2.975242437514584 RMSE: 1.724889\n",
      "Validation loss: 2.142435908317566 RMSE: 1.4637063\n",
      "17 7 1.2862791724241536\n",
      "Validation loss: 2.2696862073071236 RMSE: 1.5065478\n",
      "18 28 0.7832245234114664\n",
      "Validation loss: 3.364147473225551 RMSE: 1.8341613\n",
      "Validation loss: 2.3318393029997835 RMSE: 1.5270361\n",
      "20 20 0.9958587551026924\n",
      "Validation loss: 3.0982187553844622 RMSE: 1.7601758\n",
      "Validation loss: 2.1500320307976377 RMSE: 1.4662988\n",
      "22 12 1.1029630318343278\n",
      "Validation loss: 1.8753239718158687 RMSE: 1.3694247\n",
      "Validation loss: 2.140888819652321 RMSE: 1.4631776\n",
      "24 4 0.7836324999676286\n",
      "Validation loss: 2.0380435179820102 RMSE: 1.4276006\n",
      "25 25 0.8001247801062108\n",
      "Validation loss: 2.239653144262533 RMSE: 1.4965471\n",
      "Validation loss: 2.4586027828992996 RMSE: 1.5679934\n",
      "27 17 0.6651324204882744\n",
      "Validation loss: 2.619582925222616 RMSE: 1.6185127\n",
      "Validation loss: 1.9507602252791414 RMSE: 1.3966961\n",
      "29 9 0.6991442986205844\n",
      "Validation loss: 1.910594722865957 RMSE: 1.3822427\n",
      "Validation loss: 1.9541144729715534 RMSE: 1.3978965\n",
      "31 1 0.7460976071392421\n",
      "Validation loss: 2.692202304316833 RMSE: 1.6407931\n",
      "32 22 1.2538195657128155\n",
      "Validation loss: 3.104816681515854 RMSE: 1.762049\n",
      "Validation loss: 3.349903213239349 RMSE: 1.830274\n",
      "34 14 1.0294361890458035\n",
      "Validation loss: 2.2645744560039147 RMSE: 1.5048504\n",
      "Validation loss: 2.435848153797926 RMSE: 1.5607204\n",
      "36 6 0.6925489676680443\n",
      "Validation loss: 2.23435184807904 RMSE: 1.4947748\n",
      "37 27 0.8041304899614892\n",
      "Validation loss: 3.1250804609956995 RMSE: 1.7677897\n",
      "Validation loss: 2.217938796608849 RMSE: 1.4892747\n",
      "39 19 1.1540450103518944\n",
      "Validation loss: 3.099554500748626 RMSE: 1.7605551\n",
      "Validation loss: 2.09023269931827 RMSE: 1.4457637\n",
      "41 11 0.6341216065751153\n",
      "Validation loss: 1.9996165659575336 RMSE: 1.414078\n",
      "Validation loss: 2.1206898604874063 RMSE: 1.4562589\n",
      "43 3 0.6505360285935828\n",
      "Validation loss: 3.024652922047978 RMSE: 1.7391528\n",
      "44 24 0.8165223450688698\n",
      "Validation loss: 1.872594848143316 RMSE: 1.3684279\n",
      "Validation loss: 2.387470106107999 RMSE: 1.5451441\n",
      "46 16 0.8453784816624017\n",
      "Validation loss: 1.7967386593860863 RMSE: 1.3404249\n",
      "Validation loss: 1.9800675063006645 RMSE: 1.4071487\n",
      "48 8 0.8585572622414739\n",
      "Validation loss: 2.5725086589830113 RMSE: 1.6039044\n",
      "Validation loss: 2.1616755671205774 RMSE: 1.4702638\n",
      "50 0 0.6211989373400163\n",
      "Validation loss: 1.941399106937172 RMSE: 1.393341\n",
      "51 21 0.4724602200568412\n",
      "Validation loss: 2.022927493120717 RMSE: 1.4222965\n",
      "Validation loss: 1.7581422128508577 RMSE: 1.3259494\n",
      "53 13 0.6309252550210255\n",
      "Validation loss: 1.721725995561718 RMSE: 1.3121455\n",
      "Validation loss: 1.951348381759846 RMSE: 1.3969067\n",
      "55 5 0.6443988063980299\n",
      "Validation loss: 1.732750111976556 RMSE: 1.3163396\n",
      "56 26 0.7069584080195171\n",
      "Validation loss: 2.6010878465871894 RMSE: 1.6127888\n",
      "Validation loss: 1.9098606415554487 RMSE: 1.3819771\n",
      "58 18 0.3857084810536821\n",
      "Validation loss: 2.292325802608929 RMSE: 1.514043\n",
      "Validation loss: 1.7944758144100155 RMSE: 1.3395804\n",
      "60 10 1.80593339849271\n",
      "Validation loss: 1.8415240059911677 RMSE: 1.3570276\n",
      "Validation loss: 2.0422243449540263 RMSE: 1.4290642\n",
      "62 2 0.8519310703716476\n",
      "Validation loss: 1.9322785835350509 RMSE: 1.3900642\n",
      "63 23 0.46499625487487095\n",
      "Validation loss: 1.644294202855203 RMSE: 1.2823004\n",
      "Validation loss: 1.7057948661061515 RMSE: 1.3060608\n",
      "65 15 0.764535730529185\n",
      "Validation loss: 1.9756950825716542 RMSE: 1.4055942\n",
      "Validation loss: 2.021609909766543 RMSE: 1.4218333\n",
      "67 7 0.736169757123719\n",
      "Validation loss: 2.1252721294892574 RMSE: 1.4578313\n",
      "68 28 2.541251989860698\n",
      "Validation loss: 1.8055856312270713 RMSE: 1.3437208\n",
      "Validation loss: 2.042770404731278 RMSE: 1.4292551\n",
      "70 20 0.934074887778576\n",
      "Validation loss: 1.8410876472439386 RMSE: 1.3568668\n",
      "Validation loss: 1.8444490190100882 RMSE: 1.358105\n",
      "72 12 0.983765837833302\n",
      "Validation loss: 2.0729598577043653 RMSE: 1.4397779\n",
      "Validation loss: 2.1712572363625586 RMSE: 1.4735186\n",
      "74 4 0.8218919640843669\n",
      "Validation loss: 1.840700326767643 RMSE: 1.3567241\n",
      "75 25 0.5960808485435806\n",
      "Validation loss: 1.7983589309506711 RMSE: 1.3410292\n",
      "Validation loss: 2.0186473057333347 RMSE: 1.4207911\n",
      "77 17 0.9044497598272072\n",
      "Validation loss: 2.121749238630312 RMSE: 1.4566225\n",
      "Validation loss: 2.078518793646213 RMSE: 1.4417069\n",
      "79 9 0.6675895815334155\n",
      "Validation loss: 1.7394352486703248 RMSE: 1.3188766\n",
      "Validation loss: 1.991245164280444 RMSE: 1.4111149\n",
      "81 1 0.45709027282744724\n",
      "Validation loss: 1.7698366958483132 RMSE: 1.3303521\n",
      "82 22 0.34995851364545\n",
      "Validation loss: 1.5619229057193857 RMSE: 1.2497691\n",
      "Validation loss: 1.8731485805680266 RMSE: 1.3686302\n",
      "84 14 0.4202506634862107\n",
      "Validation loss: 2.161865107781064 RMSE: 1.4703282\n",
      "Validation loss: 1.6605352411227943 RMSE: 1.2886175\n",
      "86 6 0.8936293460820507\n",
      "Validation loss: 1.5982766341319126 RMSE: 1.2642297\n",
      "87 27 0.6275474844341955\n",
      "Validation loss: 1.994389727052334 RMSE: 1.4122286\n",
      "Validation loss: 2.917723455260285 RMSE: 1.7081345\n",
      "89 19 0.6358698428538235\n",
      "Validation loss: 1.5349419370161748 RMSE: 1.2389277\n",
      "Validation loss: 1.7671744295981078 RMSE: 1.3293512\n",
      "91 11 0.8892287763247377\n",
      "Validation loss: 1.7342141223164786 RMSE: 1.3168956\n",
      "Validation loss: 2.6600418744888983 RMSE: 1.6309636\n",
      "93 3 0.5311383886956541\n",
      "Validation loss: 2.0651538583029687 RMSE: 1.4370643\n",
      "94 24 0.49803681786114506\n",
      "Validation loss: 2.0080450952580544 RMSE: 1.417055\n",
      "Validation loss: 1.7051478898630732 RMSE: 1.3058131\n",
      "96 16 0.7526431358526058\n",
      "Validation loss: 1.6031605838674359 RMSE: 1.2661598\n",
      "Validation loss: 1.6315701450921793 RMSE: 1.2773293\n",
      "98 8 0.5983554907640601\n",
      "Validation loss: 1.5589388176403214 RMSE: 1.2485747\n",
      "Validation loss: 1.7882631373616447 RMSE: 1.3372595\n",
      "100 0 0.8060374787428249\n",
      "Validation loss: 1.6067405759760764 RMSE: 1.2675728\n",
      "101 21 0.5168876172643047\n",
      "Validation loss: 1.685115617988384 RMSE: 1.29812\n",
      "Validation loss: 1.6312113462296207 RMSE: 1.2771889\n",
      "103 13 0.47633545176069275\n",
      "Validation loss: 1.8699124829959026 RMSE: 1.3674475\n",
      "Validation loss: 1.6335201790902467 RMSE: 1.2780923\n",
      "105 5 0.7479526755724615\n",
      "Validation loss: 1.9608914925988796 RMSE: 1.4003184\n",
      "106 26 0.43847609253033454\n",
      "Validation loss: 1.715198290031568 RMSE: 1.3096558\n",
      "Validation loss: 1.7540389879614906 RMSE: 1.3244014\n",
      "108 18 0.5450761739689631\n",
      "Validation loss: 1.7865263909365223 RMSE: 1.33661\n",
      "Validation loss: 1.6565344312549692 RMSE: 1.2870643\n",
      "110 10 0.4315831680528306\n",
      "Validation loss: 1.7748949675433403 RMSE: 1.3322518\n",
      "Validation loss: 2.020696437991826 RMSE: 1.421512\n",
      "112 2 0.7138145949004544\n",
      "Validation loss: 1.6868062589020856 RMSE: 1.298771\n",
      "113 23 0.49589543324614777\n",
      "Validation loss: 1.747190422716394 RMSE: 1.3218133\n",
      "Validation loss: 1.5880460496497366 RMSE: 1.260177\n",
      "115 15 0.4920088848962523\n",
      "Validation loss: 1.7266162707742336 RMSE: 1.3140078\n",
      "Validation loss: 1.6403650952651438 RMSE: 1.2807674\n",
      "117 7 0.6834365936071556\n",
      "Validation loss: 1.8254219525683242 RMSE: 1.3510817\n",
      "118 28 0.28948237106241165\n",
      "Validation loss: 1.7584607453472847 RMSE: 1.3260697\n",
      "Validation loss: 1.7178722947044711 RMSE: 1.3106763\n",
      "120 20 0.3086228179433749\n",
      "Validation loss: 2.1173987372786596 RMSE: 1.4551286\n",
      "Validation loss: 1.8875241522240427 RMSE: 1.373872\n",
      "122 12 0.5650064448197811\n",
      "Validation loss: 1.7632688146776858 RMSE: 1.3278813\n",
      "Validation loss: 1.4009922832514332 RMSE: 1.1836352\n",
      "124 4 0.6263033111366643\n",
      "Validation loss: 1.5242005333436275 RMSE: 1.2345852\n",
      "125 25 0.5562231066533372\n",
      "Validation loss: 1.857426010401903 RMSE: 1.3628742\n",
      "Validation loss: 1.7195747489422823 RMSE: 1.3113256\n",
      "127 17 0.863258242733424\n",
      "Validation loss: 1.7040834764463713 RMSE: 1.3054054\n",
      "Validation loss: 1.8454066219583023 RMSE: 1.3584574\n",
      "129 9 0.3134212903279029\n",
      "Validation loss: 1.6382255564748713 RMSE: 1.2799318\n",
      "Validation loss: 1.6372067337542509 RMSE: 1.2795336\n",
      "131 1 0.28765770104230914\n",
      "Validation loss: 1.7941945696299055 RMSE: 1.3394755\n",
      "132 22 0.5891964645126376\n",
      "Validation loss: 1.8673991323572345 RMSE: 1.3665282\n",
      "Validation loss: 1.922828002313597 RMSE: 1.3866607\n",
      "134 14 0.24458089166824287\n",
      "Validation loss: 2.5591754301459386 RMSE: 1.5997423\n",
      "Validation loss: 1.9730832260266868 RMSE: 1.4046648\n",
      "136 6 0.7287906100980596\n",
      "Validation loss: 1.5944670618107888 RMSE: 1.2627221\n",
      "137 27 0.3852710768841812\n",
      "Validation loss: 1.6507171033757977 RMSE: 1.2848023\n",
      "Validation loss: 1.4711602113943185 RMSE: 1.212914\n",
      "139 19 0.724727499857732\n",
      "Validation loss: 1.5175582914225823 RMSE: 1.2318921\n",
      "Validation loss: 1.4490780229062106 RMSE: 1.2037766\n",
      "141 11 0.42630272190527574\n",
      "Validation loss: 1.7890960305137973 RMSE: 1.3375709\n",
      "Validation loss: 1.813934748151661 RMSE: 1.3468239\n",
      "143 3 0.3847744711980397\n",
      "Validation loss: 1.5306788123814405 RMSE: 1.2372061\n",
      "144 24 0.33968362134310326\n",
      "Validation loss: 1.5083809004420727 RMSE: 1.2281617\n",
      "Validation loss: 1.6692326907562998 RMSE: 1.2919879\n",
      "146 16 0.45028939461938705\n",
      "Validation loss: 1.5586953047102532 RMSE: 1.2484772\n",
      "Validation loss: 1.5503040193456463 RMSE: 1.2451121\n",
      "148 8 0.317702551741586\n",
      "Validation loss: 1.5793743523876225 RMSE: 1.2567316\n",
      "Validation loss: 1.6087001066292281 RMSE: 1.2683454\n",
      "150 0 0.8472004295949355\n",
      "Validation loss: 1.5827450288080536 RMSE: 1.258072\n",
      "151 21 0.6100758550980351\n",
      "Validation loss: 1.4493190060674617 RMSE: 1.2038767\n",
      "Validation loss: 1.6137614355678052 RMSE: 1.2703391\n",
      "153 13 0.7474323071178\n",
      "Validation loss: 1.6372049076367268 RMSE: 1.279533\n",
      "Validation loss: 1.5768932879498574 RMSE: 1.2557441\n",
      "155 5 0.6140383064458027\n",
      "Validation loss: 1.3667178597070475 RMSE: 1.169067\n",
      "156 26 0.4147341835123696\n",
      "Validation loss: 1.3645927811090925 RMSE: 1.1681578\n",
      "Validation loss: 1.4996483895630963 RMSE: 1.2246013\n",
      "158 18 0.6573397949657397\n",
      "Validation loss: 1.4203471240744125 RMSE: 1.1917831\n",
      "Validation loss: 1.5636679619814442 RMSE: 1.2504671\n",
      "160 10 0.5895885783202223\n",
      "Validation loss: 1.7668401730799042 RMSE: 1.3292253\n",
      "Validation loss: 1.6119091130990897 RMSE: 1.2696099\n",
      "162 2 0.6098925571897844\n",
      "Validation loss: 1.6268945204473175 RMSE: 1.2754979\n",
      "163 23 0.7559174803394098\n",
      "Validation loss: 1.5893024923527135 RMSE: 1.2606754\n",
      "Validation loss: 1.4876832445110895 RMSE: 1.2197063\n",
      "165 15 0.8411239350074662\n",
      "Validation loss: 1.5540638613489877 RMSE: 1.246621\n",
      "Validation loss: 1.6865723723858859 RMSE: 1.2986811\n",
      "167 7 0.5203737421019258\n",
      "Validation loss: 1.5870007846207745 RMSE: 1.2597622\n",
      "168 28 0.5272935357046011\n",
      "Validation loss: 1.6848885918085554 RMSE: 1.2980325\n",
      "Validation loss: 1.8040376996572038 RMSE: 1.3431447\n",
      "170 20 0.8399642234979063\n",
      "Validation loss: 1.5022007849364154 RMSE: 1.2256429\n",
      "Validation loss: 1.6676634486797637 RMSE: 1.2913805\n",
      "172 12 0.40379917924814696\n",
      "Validation loss: 1.6027827146833977 RMSE: 1.2660106\n",
      "Validation loss: 1.6947509356304609 RMSE: 1.301826\n",
      "174 4 0.4744688394802593\n",
      "Validation loss: 1.900842815373851 RMSE: 1.3787106\n",
      "175 25 0.3442274332993613\n",
      "Validation loss: 1.3828672138990554 RMSE: 1.1759537\n",
      "Validation loss: 1.3749987087418547 RMSE: 1.1726035\n",
      "177 17 0.6961683336738873\n",
      "Validation loss: 1.6575525640386395 RMSE: 1.2874597\n",
      "Validation loss: 1.5418347289076948 RMSE: 1.2417064\n",
      "179 9 0.388866082669881\n",
      "Validation loss: 1.6367722021794953 RMSE: 1.279364\n",
      "Validation loss: 1.8873644581938211 RMSE: 1.3738139\n",
      "181 1 0.39474515603571086\n",
      "Validation loss: 1.6919930693322578 RMSE: 1.3007663\n",
      "182 22 0.37764448987350685\n",
      "Validation loss: 2.0979808832691833 RMSE: 1.4484409\n",
      "Validation loss: 1.535979226627181 RMSE: 1.2393463\n",
      "184 14 0.5482268575429148\n",
      "Validation loss: 1.6999059240374945 RMSE: 1.3038044\n",
      "Validation loss: 1.373521094564843 RMSE: 1.1719732\n",
      "186 6 0.3275777232727752\n",
      "Validation loss: 1.53217447067784 RMSE: 1.2378104\n",
      "187 27 0.5404176080685144\n",
      "Validation loss: 1.4536517346854758 RMSE: 1.2056748\n",
      "Validation loss: 1.4904534204871254 RMSE: 1.2208413\n",
      "189 19 0.6135101316069801\n",
      "Validation loss: 1.8280834096722898 RMSE: 1.3520664\n",
      "Validation loss: 1.6357071315292764 RMSE: 1.2789477\n",
      "191 11 0.6138887195688715\n",
      "Validation loss: 1.4844940521020804 RMSE: 1.2183982\n",
      "Validation loss: 1.5459458289948185 RMSE: 1.2433608\n",
      "193 3 0.2963977538466173\n",
      "Validation loss: 1.599296064503425 RMSE: 1.2646327\n",
      "194 24 0.46911541830636383\n",
      "Validation loss: 1.4863332182960172 RMSE: 1.2191526\n",
      "Validation loss: 1.4214741149834826 RMSE: 1.192256\n",
      "196 16 0.4594653807619032\n",
      "Validation loss: 1.535926405307466 RMSE: 1.2393249\n",
      "Validation loss: 1.5104031024780948 RMSE: 1.2289846\n",
      "198 8 0.317036357121915\n",
      "Validation loss: 1.752915827573928 RMSE: 1.3239772\n",
      "Validation loss: 1.6170874243288968 RMSE: 1.2716476\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.519554709966204 Test RMSE: 1.2327021\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'target': ['exp']}}\n",
      "Running on: cuda:1\n",
      "4199\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/4199\n",
      "Generating scaffold 1000/4199\n",
      "Generating scaffold 2000/4199\n",
      "Generating scaffold 3000/4199\n",
      "Generating scaffold 4000/4199\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 7.628942227437204\n",
      "0 50 1.327240647870718\n",
      "0 100 1.6702975497374848\n",
      "Validation loss: 1.5034378199350267 RMSE: 1.2261475\n",
      "1 45 1.3095366204611318\n",
      "1 95 0.9106659929819727\n",
      "Validation loss: 0.9929082152389345 RMSE: 0.9964478\n",
      "2 40 0.7079853962164322\n",
      "2 90 0.73105322611891\n",
      "Validation loss: 0.922600269317627 RMSE: 0.96052086\n",
      "3 35 0.8006324470601069\n",
      "3 85 0.7584240304125437\n",
      "Validation loss: 0.8506942550341289 RMSE: 0.92233086\n",
      "4 30 0.6905312733827731\n",
      "4 80 0.7676772793656322\n",
      "Validation loss: 0.834927921635764 RMSE: 0.9137439\n",
      "5 25 0.8878653180235324\n",
      "5 75 0.578547804009687\n",
      "Validation loss: 0.9169703142983573 RMSE: 0.95758563\n",
      "6 20 0.5610478082955871\n",
      "6 70 0.754296713166202\n",
      "Validation loss: 1.001782228833153 RMSE: 1.0008907\n",
      "7 15 0.5439790902662195\n",
      "7 65 0.6352858135514826\n",
      "Validation loss: 0.8597738186518351 RMSE: 0.9272399\n",
      "8 10 1.033621013337224\n",
      "8 60 1.0090467672784451\n",
      "Validation loss: 0.7475045121851421 RMSE: 0.86458343\n",
      "9 5 0.9062740450342348\n",
      "9 55 0.7139258287779829\n",
      "Validation loss: 0.8068322851544335 RMSE: 0.8982384\n",
      "10 0 0.8178521862550373\n",
      "10 50 0.6726708519989669\n",
      "10 100 0.7157589562692104\n",
      "Validation loss: 0.8329947267259871 RMSE: 0.9126854\n",
      "11 45 0.4990525270463937\n",
      "11 95 0.734947148097288\n",
      "Validation loss: 0.8375153621037801 RMSE: 0.9151586\n",
      "12 40 0.6197203957296634\n",
      "12 90 0.8652725977690078\n",
      "Validation loss: 0.9854411409014747 RMSE: 0.9926939\n",
      "13 35 0.5979966136726205\n",
      "13 85 0.7707009103070793\n",
      "Validation loss: 0.8598614647274926 RMSE: 0.9272872\n",
      "14 30 0.7688053218873827\n",
      "14 80 0.752824818965536\n",
      "Validation loss: 0.7752544124921162 RMSE: 0.8804853\n",
      "15 25 0.5670338528623942\n",
      "15 75 0.4151842953287501\n",
      "Validation loss: 0.6940742855980283 RMSE: 0.8331112\n",
      "16 20 0.6157479331843027\n",
      "16 70 0.6299912247281656\n",
      "Validation loss: 0.7260197491872878 RMSE: 0.85206795\n",
      "17 15 1.0443733606126815\n",
      "17 65 0.5202721202457701\n",
      "Validation loss: 0.7308071811993917 RMSE: 0.8548726\n",
      "18 10 0.9531420974282977\n",
      "18 60 0.42426516594191327\n",
      "Validation loss: 0.6875264633269537 RMSE: 0.82917213\n",
      "19 5 0.897896026238233\n",
      "19 55 0.38397320774844135\n",
      "Validation loss: 0.6552109826178778 RMSE: 0.80945104\n",
      "20 0 0.419637273037758\n",
      "20 50 0.7027450527956867\n",
      "20 100 0.650636873014659\n",
      "Validation loss: 0.6963674681527274 RMSE: 0.8344863\n",
      "21 45 0.9254824763806825\n",
      "21 95 0.4414185173465916\n",
      "Validation loss: 0.6864119220347632 RMSE: 0.82849985\n",
      "22 40 0.719688978059079\n",
      "22 90 0.3944320417462617\n",
      "Validation loss: 0.6417476114772614 RMSE: 0.8010915\n",
      "23 35 0.8402339131494349\n",
      "23 85 0.32773720066810386\n",
      "Validation loss: 0.6299653717449734 RMSE: 0.79370356\n",
      "24 30 0.5780531376889457\n",
      "24 80 0.44242936218567097\n",
      "Validation loss: 0.6869627055667695 RMSE: 0.8288321\n",
      "25 25 0.3251697900436321\n",
      "25 75 1.0262455650933293\n",
      "Validation loss: 0.8331711031141735 RMSE: 0.9127821\n",
      "26 20 0.47522780252692937\n",
      "26 70 0.45249070017233123\n",
      "Validation loss: 0.6353050907452901 RMSE: 0.79706025\n",
      "27 15 0.8049978341472661\n",
      "27 65 0.5532507839336095\n",
      "Validation loss: 0.6787347566513788 RMSE: 0.8238536\n",
      "28 10 0.6122980079614918\n",
      "28 60 0.5553215245137187\n",
      "Validation loss: 0.6616422321470011 RMSE: 0.813414\n",
      "29 5 0.6828606014233358\n",
      "29 55 0.6741723043930721\n",
      "Validation loss: 0.6941820190066383 RMSE: 0.83317584\n",
      "30 0 0.5963710388719413\n",
      "30 50 0.7848379480346996\n",
      "30 100 0.5350228674646704\n",
      "Validation loss: 0.6475606410276322 RMSE: 0.8047115\n",
      "31 45 0.6988420114404751\n",
      "31 95 0.5840639236942694\n",
      "Validation loss: 0.5695559942296573 RMSE: 0.75468934\n",
      "32 40 0.47770539236577136\n",
      "32 90 0.4465585689166436\n",
      "Validation loss: 0.675901718934377 RMSE: 0.8221324\n",
      "33 35 0.45684550579746996\n",
      "33 85 0.8313178604094723\n",
      "Validation loss: 0.8344093300047375 RMSE: 0.9134601\n",
      "34 30 0.317852477453019\n",
      "34 80 0.41162293222069474\n",
      "Validation loss: 0.6318332955950783 RMSE: 0.79487944\n",
      "35 25 0.42976374650909127\n",
      "35 75 0.5997036997497212\n",
      "Validation loss: 0.6748020683016096 RMSE: 0.82146335\n",
      "36 20 0.30542592981312777\n",
      "36 70 0.4670986009797245\n",
      "Validation loss: 0.6593386374768757 RMSE: 0.8119967\n",
      "37 15 0.6613987173504734\n",
      "37 65 0.5450642501431241\n",
      "Validation loss: 0.6886866978236608 RMSE: 0.8298715\n",
      "38 10 0.6439505119729942\n",
      "38 60 0.64990257878063\n",
      "Validation loss: 0.6530429034006028 RMSE: 0.8081107\n",
      "39 5 0.30542100719837084\n",
      "39 55 0.855118671431556\n",
      "Validation loss: 0.7210746328035991 RMSE: 0.84916115\n",
      "40 0 0.40758334712023236\n",
      "40 50 0.47710966098410096\n",
      "40 100 0.4284050666428823\n",
      "Validation loss: 0.6030963318688529 RMSE: 0.7765928\n",
      "41 45 0.3474329697526289\n",
      "41 95 0.4915819575270607\n",
      "Validation loss: 0.6263399186588469 RMSE: 0.7914164\n",
      "42 40 0.30741956668370585\n",
      "42 90 0.3204933319042322\n",
      "Validation loss: 0.6040286969570886 RMSE: 0.77719283\n",
      "43 35 0.454019539387324\n",
      "43 85 0.43871360994612646\n",
      "Validation loss: 0.6074487935929072 RMSE: 0.77939\n",
      "44 30 0.490576151776836\n",
      "44 80 0.45984495801538844\n",
      "Validation loss: 0.6173635323842367 RMSE: 0.7857248\n",
      "45 25 0.24605578919427817\n",
      "45 75 0.46925852173900556\n",
      "Validation loss: 0.5938027438663301 RMSE: 0.77058595\n",
      "46 20 0.32263079030430064\n",
      "46 70 0.3479331167080489\n",
      "Validation loss: 0.6304048663093931 RMSE: 0.7939804\n",
      "47 15 0.5671579632490745\n",
      "47 65 0.39568717404773673\n",
      "Validation loss: 0.7106597446259998 RMSE: 0.8430064\n",
      "48 10 0.4743369306873796\n",
      "48 60 0.3197620965150341\n",
      "Validation loss: 0.5714566165492648 RMSE: 0.7559475\n",
      "49 5 0.6007983801960588\n",
      "49 55 0.2658296119370073\n",
      "Validation loss: 0.5975072511604854 RMSE: 0.77298594\n",
      "50 0 0.7177719728429538\n",
      "50 50 0.4034267817179007\n",
      "50 100 0.28966660382829285\n",
      "Validation loss: 0.5653662102563041 RMSE: 0.75190836\n",
      "51 45 0.5804899067650698\n",
      "51 95 0.6106030338298645\n",
      "Validation loss: 0.6192732331298646 RMSE: 0.78693914\n",
      "52 40 0.25786057740622487\n",
      "52 90 0.31827896080608187\n",
      "Validation loss: 0.5911944275810606 RMSE: 0.7688917\n",
      "53 35 0.5439036760848678\n",
      "53 85 0.5255687283887082\n",
      "Validation loss: 0.6353443753151666 RMSE: 0.797085\n",
      "54 30 0.41582080737189236\n",
      "54 80 0.247692401611654\n",
      "Validation loss: 0.5795863029502687 RMSE: 0.7613057\n",
      "55 25 0.3336760329163231\n",
      "55 75 0.4584657585349877\n",
      "Validation loss: 0.5850256812004816 RMSE: 0.76486975\n",
      "56 20 0.28675405826673617\n",
      "56 70 0.3356864825303035\n",
      "Validation loss: 0.592575532481784 RMSE: 0.76978934\n",
      "57 15 0.36507110085859135\n",
      "57 65 0.3682350218485538\n",
      "Validation loss: 0.5742921911534808 RMSE: 0.75782067\n",
      "58 10 0.4308090585259087\n",
      "58 60 0.2720733894957395\n",
      "Validation loss: 0.5982346784500848 RMSE: 0.77345634\n",
      "59 5 0.50680703625993\n",
      "59 55 0.3618138517046939\n",
      "Validation loss: 0.6686587447211856 RMSE: 0.8177156\n",
      "60 0 0.26924734994337346\n",
      "60 50 0.39059842860192173\n",
      "60 100 0.3442845056512129\n",
      "Validation loss: 0.6004124141874767 RMSE: 0.7748628\n",
      "61 45 0.3022008452633952\n",
      "61 95 0.4153558623948968\n",
      "Validation loss: 0.5599789267494565 RMSE: 0.74831736\n",
      "62 40 0.5986095723533886\n",
      "62 90 0.5055629173196593\n",
      "Validation loss: 0.6008902782485599 RMSE: 0.7751711\n",
      "63 35 0.36003488325120897\n",
      "63 85 0.3802917300129756\n",
      "Validation loss: 0.6194924507822309 RMSE: 0.78707844\n",
      "64 30 0.6831209188293855\n",
      "64 80 0.2638342282593886\n",
      "Validation loss: 0.6157302155381157 RMSE: 0.7846848\n",
      "65 25 0.3291034743546226\n",
      "65 75 0.11299470452865387\n",
      "Validation loss: 0.5587527502150763 RMSE: 0.7474977\n",
      "66 20 0.7862078153065702\n",
      "66 70 0.5864796861920828\n",
      "Validation loss: 0.6125415870121547 RMSE: 0.78265035\n",
      "67 15 0.35460980094682226\n",
      "67 65 0.20582113784963774\n",
      "Validation loss: 0.6356905247483935 RMSE: 0.79730207\n",
      "68 10 0.5112917671746948\n",
      "68 60 0.24684857297970253\n",
      "Validation loss: 0.6122983923980168 RMSE: 0.782495\n",
      "69 5 0.2451493443335056\n",
      "69 55 0.41370089745890365\n",
      "Validation loss: 0.58311411965461 RMSE: 0.76361907\n",
      "70 0 0.512381776379547\n",
      "70 50 0.31951615274497613\n",
      "70 100 0.7413770078577677\n",
      "Validation loss: 0.613729282787868 RMSE: 0.78340876\n",
      "71 45 0.4170440574970175\n",
      "71 95 0.35347474697608383\n",
      "Validation loss: 0.6478105306625366 RMSE: 0.8048668\n",
      "72 40 0.39968699526787194\n",
      "72 90 0.5698980535193429\n",
      "Validation loss: 0.693575112024943 RMSE: 0.83281153\n",
      "73 35 0.43152636852614207\n",
      "73 85 0.39412616281335916\n",
      "Validation loss: 0.5523760403196017 RMSE: 0.7432201\n",
      "74 30 0.23109317372235175\n",
      "74 80 0.3006793889398456\n",
      "Validation loss: 0.5859703523772103 RMSE: 0.765487\n",
      "75 25 0.231976600698801\n",
      "75 75 0.6572939013780876\n",
      "Validation loss: 0.5546167675937925 RMSE: 0.74472594\n",
      "76 20 0.1924121549340484\n",
      "76 70 0.2884710635857799\n",
      "Validation loss: 0.5474570912974221 RMSE: 0.73990345\n",
      "77 15 0.3799136576867096\n",
      "77 65 0.48762407120505546\n",
      "Validation loss: 0.5593720316886902 RMSE: 0.74791175\n",
      "78 10 0.5121748027519523\n",
      "78 60 0.21257386659659777\n",
      "Validation loss: 0.5651784601665678 RMSE: 0.7517835\n",
      "79 5 0.49950590933894995\n",
      "79 55 0.19109516652817024\n",
      "Validation loss: 0.533648935953776 RMSE: 0.7305128\n",
      "80 0 0.3659391423411683\n",
      "80 50 0.34409121689539945\n",
      "80 100 0.3117825344132111\n",
      "Validation loss: 0.5360780999774024 RMSE: 0.73217356\n",
      "81 45 0.27602754995483647\n",
      "81 95 0.23541751610562264\n",
      "Validation loss: 0.5334684105146499 RMSE: 0.73038924\n",
      "82 40 0.3123171555384693\n",
      "82 90 0.2651124239164197\n",
      "Validation loss: 0.5849664055165791 RMSE: 0.76483095\n",
      "83 35 0.24641489543708844\n",
      "83 85 0.19980983483477333\n",
      "Validation loss: 0.5705865962164742 RMSE: 0.75537187\n",
      "84 30 0.3045033374272994\n",
      "84 80 0.2720674452351783\n",
      "Validation loss: 0.5603046178817749 RMSE: 0.748535\n",
      "85 25 0.41667694376488695\n",
      "85 75 0.3772885122944917\n",
      "Validation loss: 0.4921849580038162 RMSE: 0.70155895\n",
      "86 20 0.34211213817878977\n",
      "86 70 0.1542080334820373\n",
      "Validation loss: 0.5204198791867211 RMSE: 0.72140133\n",
      "87 15 0.2797320855848278\n",
      "87 65 0.3004760039550039\n",
      "Validation loss: 0.5142365325064886 RMSE: 0.7171029\n",
      "88 10 0.17588116103267912\n",
      "88 60 0.2545667515821149\n",
      "Validation loss: 0.5553523591586522 RMSE: 0.74521965\n",
      "89 5 0.3075767095183013\n",
      "89 55 0.2719145248873767\n",
      "Validation loss: 0.5488506402288165 RMSE: 0.74084455\n",
      "90 0 0.4089499653518576\n",
      "90 50 0.3603198145792371\n",
      "90 100 0.3003823218349019\n",
      "Validation loss: 0.5384781962349301 RMSE: 0.7338107\n",
      "91 45 0.4132565476132927\n",
      "91 95 0.35613738254859756\n",
      "Validation loss: 0.5710645365573112 RMSE: 0.75568813\n",
      "92 40 0.3197337459516358\n",
      "92 90 0.2124319646660002\n",
      "Validation loss: 0.5311979630163738 RMSE: 0.7288333\n",
      "93 35 0.2580717297709185\n",
      "93 85 0.28415443489697545\n",
      "Validation loss: 0.5116879003388541 RMSE: 0.7153237\n",
      "94 30 0.3687042181494951\n",
      "94 80 0.5528261766332994\n",
      "Validation loss: 0.5148840489841643 RMSE: 0.7175542\n",
      "95 25 0.23769264053943415\n",
      "95 75 0.34479276831835515\n",
      "Validation loss: 0.5609354557026001 RMSE: 0.7489562\n",
      "96 20 0.36334951269827725\n",
      "96 70 0.1953469339580683\n",
      "Validation loss: 0.519167674439294 RMSE: 0.7205329\n",
      "97 15 0.20623609110155647\n",
      "97 65 0.17296238606472314\n",
      "Validation loss: 0.5656594072069441 RMSE: 0.7521033\n",
      "98 10 0.4275912140469354\n",
      "98 60 0.18913758074178252\n",
      "Validation loss: 0.5059632732754662 RMSE: 0.7113109\n",
      "99 5 0.40495386411575063\n",
      "99 55 0.35860074857938484\n",
      "Validation loss: 0.546140836534046 RMSE: 0.73901343\n",
      "100 0 0.23760821591828452\n",
      "100 50 0.26955903934439734\n",
      "100 100 0.18449830690883862\n",
      "Validation loss: 0.5323820119812375 RMSE: 0.72964513\n",
      "101 45 0.35232902107579483\n",
      "101 95 0.3306382495857666\n",
      "Validation loss: 0.5343480825424194 RMSE: 0.7309912\n",
      "102 40 0.24696114023784785\n",
      "102 90 0.3282766021912104\n",
      "Validation loss: 0.5237346160979498 RMSE: 0.7236951\n",
      "103 35 0.19276455383907293\n",
      "103 85 0.2300827108792319\n",
      "Validation loss: 0.5319706448486873 RMSE: 0.7293632\n",
      "104 30 0.08143938286286223\n",
      "104 80 0.2253871562867243\n",
      "Validation loss: 0.524424980367933 RMSE: 0.72417194\n",
      "105 25 0.16691501867245848\n",
      "105 75 0.2383308106801014\n",
      "Validation loss: 0.5074954305376326 RMSE: 0.71238714\n",
      "106 20 0.4668565700831392\n",
      "106 70 0.30526861127292626\n",
      "Validation loss: 0.526978828225817 RMSE: 0.7259331\n",
      "107 15 0.35046130832610295\n",
      "107 65 0.21673228655164334\n",
      "Validation loss: 0.5162757579769407 RMSE: 0.7185233\n",
      "108 10 0.2766212542629336\n",
      "108 60 0.3707125382547451\n",
      "Validation loss: 0.52086277675061 RMSE: 0.72170824\n",
      "109 5 0.29652367468443025\n",
      "109 55 0.19229046649770745\n",
      "Validation loss: 0.5146198170525688 RMSE: 0.7173701\n",
      "110 0 0.25325273798087916\n",
      "110 50 0.22741451857843767\n",
      "110 100 0.34610647733849087\n",
      "Validation loss: 0.5293492640767778 RMSE: 0.7275639\n",
      "111 45 0.2765576417169892\n",
      "111 95 0.29343701696331587\n",
      "Validation loss: 0.5669339838482085 RMSE: 0.75295013\n",
      "112 40 0.19718162365715966\n",
      "112 90 0.15753254492001767\n",
      "Validation loss: 0.5421990235646565 RMSE: 0.73634166\n",
      "113 35 0.20511669438306995\n",
      "113 85 0.3694525445928832\n",
      "Validation loss: 0.4857294914977891 RMSE: 0.696943\n",
      "114 30 0.20613122585853225\n",
      "114 80 0.30464462946052706\n",
      "Validation loss: 0.5114341769899641 RMSE: 0.71514624\n",
      "115 25 0.18902301808106933\n",
      "115 75 0.23895751523381337\n",
      "Validation loss: 0.5016958741914659 RMSE: 0.70830494\n",
      "116 20 0.2538857270396375\n",
      "116 70 0.572365987827915\n",
      "Validation loss: 0.5299971557798839 RMSE: 0.72800905\n",
      "117 15 0.22670893746011503\n",
      "117 65 0.3663727590078584\n",
      "Validation loss: 0.5476004600524902 RMSE: 0.7400003\n",
      "118 10 0.27736370952485834\n",
      "118 60 0.1668621455710083\n",
      "Validation loss: 0.555489024803752 RMSE: 0.7453113\n",
      "119 5 0.12270636660215323\n",
      "119 55 0.12875594134925905\n",
      "Validation loss: 0.523027507464091 RMSE: 0.7232064\n",
      "120 0 0.23054545871879364\n",
      "120 50 0.295433007782279\n",
      "120 100 0.2767745373219106\n",
      "Validation loss: 0.512386239142645 RMSE: 0.71581155\n",
      "121 45 0.20106428732492035\n",
      "121 95 0.3001705938816029\n",
      "Validation loss: 0.5508397635959443 RMSE: 0.74218583\n",
      "122 40 0.24119028568175246\n",
      "122 90 0.17391827467064214\n",
      "Validation loss: 0.5153043678828648 RMSE: 0.717847\n",
      "123 35 0.22792799773528896\n",
      "123 85 0.21135544360533884\n",
      "Validation loss: 0.5139308890948693 RMSE: 0.71688974\n",
      "124 30 0.27224237817700775\n",
      "124 80 0.37148852129059284\n",
      "Validation loss: 0.5027091849417914 RMSE: 0.7090199\n",
      "125 25 0.13966014257122794\n",
      "125 75 0.24789809911133076\n",
      "Validation loss: 0.5071154197057088 RMSE: 0.71212035\n",
      "126 20 0.21061476453588296\n",
      "126 70 0.25262135512450684\n",
      "Validation loss: 0.5079281943184989 RMSE: 0.71269083\n",
      "127 15 0.1713703739236422\n",
      "127 65 0.26041884952434824\n",
      "Validation loss: 0.5178674669492812 RMSE: 0.71963006\n",
      "128 10 0.3480477904118565\n",
      "128 60 0.15840140474873465\n",
      "Validation loss: 0.5265834453560058 RMSE: 0.7256607\n",
      "129 5 0.25376814330358705\n",
      "129 55 0.3212994312649428\n",
      "Validation loss: 0.5383143742879232 RMSE: 0.73369914\n",
      "130 0 0.26775280309289046\n",
      "130 50 0.4148074973718082\n",
      "130 100 0.2564821010011441\n",
      "Validation loss: 0.5095869668892452 RMSE: 0.7138536\n",
      "131 45 0.27854653208657665\n",
      "131 95 0.21260252597388832\n",
      "Validation loss: 0.5052001680646624 RMSE: 0.7107743\n",
      "132 40 0.25179010982841016\n",
      "132 90 0.24034348596564814\n",
      "Validation loss: 0.4982064485549927 RMSE: 0.7058374\n",
      "133 35 0.27392455542495187\n",
      "133 85 0.2067640593839763\n",
      "Validation loss: 0.49453412549836295 RMSE: 0.70323116\n",
      "134 30 0.15330658419999293\n",
      "134 80 0.20061805779869832\n",
      "Validation loss: 0.5290748147737412 RMSE: 0.7273753\n",
      "135 25 0.2858957702892152\n",
      "135 75 0.25168994378032156\n",
      "Validation loss: 0.5466929716723306 RMSE: 0.73938686\n",
      "136 20 0.19937822456152338\n",
      "136 70 0.286916141074101\n",
      "Validation loss: 0.5109544030257633 RMSE: 0.7148108\n",
      "137 15 0.19091647129987685\n",
      "137 65 0.2877244829437442\n",
      "Validation loss: 0.5009510407845179 RMSE: 0.70777893\n",
      "138 10 0.2887326219279857\n",
      "138 60 0.19766182312688443\n",
      "Validation loss: 0.4829188389437539 RMSE: 0.69492364\n",
      "139 5 0.15044678015657745\n",
      "139 55 0.3008891578181546\n",
      "Validation loss: 0.49741751948992413 RMSE: 0.70527834\n",
      "140 0 0.18473171413005302\n",
      "140 50 0.2734099960239856\n",
      "140 100 0.1856374977406209\n",
      "Validation loss: 0.536535252275921 RMSE: 0.73248565\n",
      "141 45 0.25439899277236194\n",
      "141 95 0.2545934560848375\n",
      "Validation loss: 0.5284027326674688 RMSE: 0.7269131\n",
      "142 40 0.24025363098572808\n",
      "142 90 0.17254924538362237\n",
      "Validation loss: 0.4771490440482185 RMSE: 0.6907597\n",
      "143 35 0.15015488838059338\n",
      "143 85 0.1367559897469798\n",
      "Validation loss: 0.49455446033250716 RMSE: 0.70324564\n",
      "144 30 0.23236638322947123\n",
      "144 80 0.14975152125719723\n",
      "Validation loss: 0.5559360331013089 RMSE: 0.74561113\n",
      "145 25 0.30384582819230055\n",
      "145 75 0.19075687014760026\n",
      "Validation loss: 0.5251650989055634 RMSE: 0.7246828\n",
      "146 20 0.2783158192950468\n",
      "146 70 0.1800024359040404\n",
      "Validation loss: 0.5482051748605001 RMSE: 0.7404088\n",
      "147 15 0.17286470710341645\n",
      "147 65 0.16591431813791843\n",
      "Validation loss: 0.499044345390229 RMSE: 0.70643073\n",
      "148 10 0.23626766372470626\n",
      "148 60 0.20352237264763032\n",
      "Validation loss: 0.5269964899335589 RMSE: 0.72594523\n",
      "149 5 0.14440408270766383\n",
      "149 55 0.3635244078743924\n",
      "Validation loss: 0.5116883970442272 RMSE: 0.715324\n",
      "150 0 0.16448515429726837\n",
      "150 50 0.2589249157943443\n",
      "150 100 0.41662084437622304\n",
      "Validation loss: 0.5374608448573521 RMSE: 0.73311716\n",
      "151 45 0.1942744261266081\n",
      "151 95 0.18493902338897805\n",
      "Validation loss: 0.517753621510097 RMSE: 0.71955097\n",
      "152 40 0.22123448104994461\n",
      "152 90 0.3282968178938118\n",
      "Validation loss: 0.5005960765339079 RMSE: 0.7075281\n",
      "153 35 0.21402776769718784\n",
      "153 85 0.28965408761644146\n",
      "Validation loss: 0.5119316254343306 RMSE: 0.715494\n",
      "154 30 0.42518768298485043\n",
      "154 80 0.16151840992195793\n",
      "Validation loss: 0.5271191358566284 RMSE: 0.7260297\n",
      "155 25 0.2367215338596485\n",
      "155 75 0.2813550959297851\n",
      "Validation loss: 0.5342538475990295 RMSE: 0.7309267\n",
      "156 20 0.1961311029639979\n",
      "156 70 0.1947956882179308\n",
      "Validation loss: 0.5284724577374401 RMSE: 0.72696114\n",
      "157 15 0.18354411640624949\n",
      "157 65 0.17471244756445733\n",
      "Validation loss: 0.4996884184224265 RMSE: 0.7068864\n",
      "158 10 0.18402746894051392\n",
      "158 60 0.2809477647386637\n",
      "Validation loss: 0.5347370499656314 RMSE: 0.7312572\n",
      "159 5 0.16874578577806923\n",
      "159 55 0.18850020457602404\n",
      "Validation loss: 0.5219784311595417 RMSE: 0.7224808\n",
      "160 0 0.11190840660330004\n",
      "160 50 0.2035691975800139\n",
      "160 100 0.21417937131265505\n",
      "Validation loss: 0.5098343202045985 RMSE: 0.71402687\n",
      "161 45 0.131660362400819\n",
      "161 95 0.1341823087487439\n",
      "Validation loss: 0.5497514872323899 RMSE: 0.7414523\n",
      "162 40 0.23558313537943845\n",
      "162 90 0.2552813068417625\n",
      "Validation loss: 0.5484555153619676 RMSE: 0.7405778\n",
      "163 35 0.20130415862599801\n",
      "163 85 0.12581445666916402\n",
      "Validation loss: 0.5256083836158116 RMSE: 0.7249885\n",
      "164 30 0.15856388766883822\n",
      "164 80 0.19630119863941065\n",
      "Validation loss: 0.5079183315946942 RMSE: 0.7126839\n",
      "165 25 0.16746080708071956\n",
      "165 75 0.2701818593160687\n",
      "Validation loss: 0.560351318404788 RMSE: 0.7485662\n",
      "166 20 0.1362577336345816\n",
      "166 70 0.11382350696398263\n",
      "Validation loss: 0.5498224437236786 RMSE: 0.7415001\n",
      "167 15 0.16453181477910367\n",
      "167 65 0.19662981193860743\n",
      "Validation loss: 0.5360263898259118 RMSE: 0.7321383\n",
      "168 10 0.17129387974181703\n",
      "168 60 0.07209250618471048\n",
      "Validation loss: 0.5167712731020792 RMSE: 0.718868\n",
      "169 5 0.16437204817253662\n",
      "169 55 0.20488207866564745\n",
      "Validation loss: 0.5410051394786154 RMSE: 0.7355305\n",
      "170 0 0.12699674723057622\n",
      "170 50 0.28106321063088696\n",
      "170 100 0.1496669141231748\n",
      "Validation loss: 0.5033563253425416 RMSE: 0.7094761\n",
      "171 45 0.24027938197821655\n",
      "171 95 0.22273697391479905\n",
      "Validation loss: 0.4983244765372503 RMSE: 0.705921\n",
      "172 40 0.19055106771153232\n",
      "172 90 0.2644715886390196\n",
      "Validation loss: 0.5577541341384252 RMSE: 0.7468294\n",
      "173 35 0.15130661104559012\n",
      "173 85 0.1659796494522626\n",
      "Validation loss: 0.5129924075944083 RMSE: 0.7162349\n",
      "174 30 0.21089985017398336\n",
      "174 80 0.3162555561077426\n",
      "Validation loss: 0.5270900164331709 RMSE: 0.72600967\n",
      "175 25 0.19438212268147526\n",
      "175 75 0.5326167271735325\n",
      "Validation loss: 0.5412297568150929 RMSE: 0.7356832\n",
      "176 20 0.14752824112340937\n",
      "176 70 0.17043929718067563\n",
      "Validation loss: 0.525913013163067 RMSE: 0.72519857\n",
      "177 15 0.10277130739800379\n",
      "177 65 0.17853481353935327\n",
      "Validation loss: 0.5340282411802383 RMSE: 0.7307724\n",
      "178 10 0.11461808968580114\n",
      "178 60 0.14488258584707536\n",
      "Validation loss: 0.5190277349381219 RMSE: 0.7204358\n",
      "179 5 0.21216114521601642\n",
      "179 55 0.14693459665823716\n",
      "Validation loss: 0.5213602616673424 RMSE: 0.7220528\n",
      "180 0 0.18602299981561876\n",
      "180 50 0.17285185608814105\n",
      "180 100 0.23849436367614593\n",
      "Validation loss: 0.5669484311626071 RMSE: 0.7529598\n",
      "181 45 0.3104263153713591\n",
      "181 95 0.1293406020080344\n",
      "Validation loss: 0.5200454973039172 RMSE: 0.72114176\n",
      "182 40 0.14889451679803678\n",
      "182 90 0.1934885752672227\n",
      "Validation loss: 0.558677700020018 RMSE: 0.7474475\n",
      "183 35 0.17148663376420709\n",
      "183 85 0.3218309897514646\n",
      "Validation loss: 0.5319365467344012 RMSE: 0.72933984\n",
      "184 30 0.17290755345973471\n",
      "184 80 0.1298507349428552\n",
      "Validation loss: 0.5191373964150746 RMSE: 0.7205119\n",
      "185 25 0.27027681478528304\n",
      "185 75 0.265340064833027\n",
      "Validation loss: 0.4961022615432739 RMSE: 0.7043453\n",
      "186 20 0.09665918263436843\n",
      "186 70 0.1766284750817344\n",
      "Validation loss: 0.5329961168624106 RMSE: 0.7300658\n",
      "187 15 0.27892125329549167\n",
      "187 65 0.21351589479470579\n",
      "Validation loss: 0.5335569278115317 RMSE: 0.7304498\n",
      "188 10 0.08508970464583976\n",
      "188 60 0.21930117656436846\n",
      "Validation loss: 0.5046634806053979 RMSE: 0.71039677\n",
      "189 5 0.14381931102224355\n",
      "189 55 0.1420234230340464\n",
      "Validation loss: 0.4994286811600129 RMSE: 0.70670265\n",
      "190 0 0.29435636322165915\n",
      "190 50 0.27503068278279674\n",
      "190 100 0.1822800328630616\n",
      "Validation loss: 0.571672397000449 RMSE: 0.7560902\n",
      "191 45 0.23988444547776744\n",
      "191 95 0.27844598610848137\n",
      "Validation loss: 0.5360541005929311 RMSE: 0.7321571\n",
      "192 40 0.23339647701723437\n",
      "192 90 0.12295995918208694\n",
      "Validation loss: 0.532615567956652 RMSE: 0.7298052\n",
      "193 35 0.2063616843474739\n",
      "193 85 0.18328898513538866\n",
      "Validation loss: 0.527611913283666 RMSE: 0.72636896\n",
      "194 30 0.1282312975721046\n",
      "194 80 0.09903457707192961\n",
      "Validation loss: 0.5336676315182731 RMSE: 0.73052555\n",
      "195 25 0.1970313943244019\n",
      "195 75 0.12200866337982165\n",
      "Validation loss: 0.5398759421848115 RMSE: 0.7347625\n",
      "196 20 0.23631271509410517\n",
      "196 70 0.2761428637919926\n",
      "Validation loss: 0.5184152588957832 RMSE: 0.7200106\n",
      "197 15 0.2024345615886237\n",
      "197 65 0.18190259472176765\n",
      "Validation loss: 0.5284186442693074 RMSE: 0.72692406\n",
      "198 10 0.2030676017101239\n",
      "198 60 0.08881823617265887\n",
      "Validation loss: 0.5518037710871015 RMSE: 0.7428349\n",
      "199 5 0.21015121173807963\n",
      "199 55 0.1396799598796273\n",
      "Validation loss: 0.5138808125541323 RMSE: 0.7168548\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.5307902722131639 Test RMSE: 0.72855353\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 778, 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'target': ['exp']}}\n",
      "Running on: cuda:1\n",
      "4199\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/4199\n",
      "Generating scaffold 1000/4199\n",
      "Generating scaffold 2000/4199\n",
      "Generating scaffold 3000/4199\n",
      "Generating scaffold 4000/4199\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 7.908167754983337\n",
      "0 50 2.028647090147445\n",
      "0 100 1.5155771213909826\n",
      "Validation loss: 1.122704267501831 RMSE: 1.0595773\n",
      "1 45 0.8684530067821685\n",
      "1 95 0.8290223446951575\n",
      "Validation loss: 1.0747662987027848 RMSE: 1.0367093\n",
      "2 40 0.9620806868988458\n",
      "2 90 0.8987219151852304\n",
      "Validation loss: 1.168768122082665 RMSE: 1.0810958\n",
      "3 35 1.1852370230614642\n",
      "3 85 1.218626206511127\n",
      "Validation loss: 1.203299099490756 RMSE: 1.0969499\n",
      "4 30 0.9289790622243466\n",
      "4 80 1.104212435788771\n",
      "Validation loss: 0.9275103693916684 RMSE: 0.9630733\n",
      "5 25 0.6527802709440733\n",
      "5 75 0.7119892706354841\n",
      "Validation loss: 1.1371527907394228 RMSE: 1.0663737\n",
      "6 20 0.8994999267325589\n",
      "6 70 0.4668262059764163\n",
      "Validation loss: 0.9561872885340736 RMSE: 0.9778483\n",
      "7 15 0.8199516110353421\n",
      "7 65 0.9522399749906116\n",
      "Validation loss: 0.8507378089995611 RMSE: 0.9223545\n",
      "8 10 0.871330251104287\n",
      "8 60 0.6266302181082024\n",
      "Validation loss: 0.9489167883282617 RMSE: 0.97412366\n",
      "9 5 1.3759852758628803\n",
      "9 55 0.5126569631260305\n",
      "Validation loss: 0.8351549761635917 RMSE: 0.9138681\n",
      "10 0 1.0628004281944894\n",
      "10 50 0.4744876523928877\n",
      "10 100 0.5132589461360039\n",
      "Validation loss: 0.7634208672103427 RMSE: 0.87373954\n",
      "11 45 0.8020452698528518\n",
      "11 95 0.472704011311215\n",
      "Validation loss: 0.8118905981381734 RMSE: 0.90104973\n",
      "12 40 0.9272888354411498\n",
      "12 90 1.0114018573568069\n",
      "Validation loss: 0.8383808612823487 RMSE: 0.91563135\n",
      "13 35 0.9242948278053449\n",
      "13 85 1.0862903058255853\n",
      "Validation loss: 0.9244840501319794 RMSE: 0.96150094\n",
      "14 30 0.6377241906397888\n",
      "14 80 0.35247815486515593\n",
      "Validation loss: 0.7477461360749744 RMSE: 0.86472315\n",
      "15 25 0.5074628655049621\n",
      "15 75 0.7195330956841934\n",
      "Validation loss: 0.8322030180976504 RMSE: 0.91225165\n",
      "16 20 0.7855910333565838\n",
      "16 70 0.5802837373588496\n",
      "Validation loss: 0.8176875205267043 RMSE: 0.9042608\n",
      "17 15 0.6653541582467721\n",
      "17 65 0.4285372340242935\n",
      "Validation loss: 0.7060530004047212 RMSE: 0.8402696\n",
      "18 10 0.41675108570559316\n",
      "18 60 0.6088718828040471\n",
      "Validation loss: 0.7725952951681047 RMSE: 0.87897396\n",
      "19 5 0.6090982441970799\n",
      "19 55 0.4096046264844069\n",
      "Validation loss: 0.6948196098918007 RMSE: 0.83355844\n",
      "20 0 0.5535071104840618\n",
      "20 50 0.4479849163802694\n",
      "20 100 0.4305181433244263\n",
      "Validation loss: 0.6674069075357346 RMSE: 0.8169498\n",
      "21 45 0.46963408304884635\n",
      "21 95 0.9602759606131177\n",
      "Validation loss: 0.6667285209610349 RMSE: 0.81653446\n",
      "22 40 0.6869426006342385\n",
      "22 90 0.5976158207230388\n",
      "Validation loss: 0.6768202648276375 RMSE: 0.8226909\n",
      "23 35 0.6264594822382901\n",
      "23 85 0.5633516226033599\n",
      "Validation loss: 0.6462004258519127 RMSE: 0.8038659\n",
      "24 30 0.6460301289988468\n",
      "24 80 0.7325108788305043\n",
      "Validation loss: 0.6860471123740787 RMSE: 0.8282796\n",
      "25 25 0.6309792860137048\n",
      "25 75 0.3650447763916804\n",
      "Validation loss: 0.6947619441009704 RMSE: 0.8335238\n",
      "26 20 0.6186650145301207\n",
      "26 70 0.5644800776795528\n",
      "Validation loss: 0.6332436615512484 RMSE: 0.7957661\n",
      "27 15 0.4573514369430534\n",
      "27 65 0.7663678377721442\n",
      "Validation loss: 0.6661229417437599 RMSE: 0.8161636\n",
      "28 10 0.7801727309293411\n",
      "28 60 0.7107634323962475\n",
      "Validation loss: 0.6500562315895444 RMSE: 0.80626065\n",
      "29 5 0.4864544644253004\n",
      "29 55 1.0016034411034345\n",
      "Validation loss: 0.646082820211138 RMSE: 0.8037927\n",
      "30 0 0.5026790708530832\n",
      "30 50 0.3153389030681306\n",
      "30 100 0.37271361348353127\n",
      "Validation loss: 0.7327651631264459 RMSE: 0.856017\n",
      "31 45 0.45191972177717166\n",
      "31 95 0.6577874994464598\n",
      "Validation loss: 0.6149901639847528 RMSE: 0.78421307\n",
      "32 40 0.45771505479997243\n",
      "32 90 0.48490595780521484\n",
      "Validation loss: 0.7644879003365834 RMSE: 0.87434995\n",
      "33 35 0.6304273155780532\n",
      "33 85 0.8765453601102824\n",
      "Validation loss: 0.7267103217896961 RMSE: 0.8524731\n",
      "34 30 0.4162679884800857\n",
      "34 80 0.7825880904073016\n",
      "Validation loss: 0.6274658186095101 RMSE: 0.79212743\n",
      "35 25 0.6657516815557707\n",
      "35 75 0.44042785650123667\n",
      "Validation loss: 0.6516035238901774 RMSE: 0.80721956\n",
      "36 20 0.5644687892963406\n",
      "36 70 0.7593688744523002\n",
      "Validation loss: 0.6060287935393197 RMSE: 0.7784785\n",
      "37 15 0.5126330997568895\n",
      "37 65 0.3544249273849182\n",
      "Validation loss: 0.6527494680313837 RMSE: 0.80792916\n",
      "38 10 0.42262879453455304\n",
      "38 60 0.40036566895063724\n",
      "Validation loss: 0.6383465732846941 RMSE: 0.79896593\n",
      "39 5 0.4651128385210183\n",
      "39 55 0.3526415394381719\n",
      "Validation loss: 0.5926509689717065 RMSE: 0.7698383\n",
      "40 0 0.36644754696885495\n",
      "40 50 0.38818782135983726\n",
      "40 100 0.17634368675986478\n",
      "Validation loss: 0.6771323915216185 RMSE: 0.8228805\n",
      "41 45 0.37683250232120236\n",
      "41 95 0.49731308205230246\n",
      "Validation loss: 0.6773415434928167 RMSE: 0.82300764\n",
      "42 40 0.42371162731267387\n",
      "42 90 0.3022554092050801\n",
      "Validation loss: 0.6655224050794329 RMSE: 0.81579554\n",
      "43 35 0.5070775249152805\n",
      "43 85 0.3825440150113644\n",
      "Validation loss: 0.7099811894553049 RMSE: 0.8426038\n",
      "44 30 0.5035326085569012\n",
      "44 80 0.3211724533069276\n",
      "Validation loss: 0.7038869528543381 RMSE: 0.8389797\n",
      "45 25 0.17853456775076945\n",
      "45 75 0.32712752991163957\n",
      "Validation loss: 0.6057818778923579 RMSE: 0.7783199\n",
      "46 20 0.6540952564635106\n",
      "46 70 0.5692641960013868\n",
      "Validation loss: 0.6119491616884868 RMSE: 0.78227174\n",
      "47 15 0.5181019078189295\n",
      "47 65 0.4701627474626991\n",
      "Validation loss: 0.6026716425305321 RMSE: 0.77631927\n",
      "48 10 0.38540538915788364\n",
      "48 60 0.3729182240013735\n",
      "Validation loss: 0.6235761188325428 RMSE: 0.7896684\n",
      "49 5 0.5136092258445332\n",
      "49 55 0.34840810678345757\n",
      "Validation loss: 0.5942178510484242 RMSE: 0.77085525\n",
      "50 0 0.233933347130672\n",
      "50 50 0.3939112226706439\n",
      "50 100 0.5073387281388883\n",
      "Validation loss: 0.5953882047108241 RMSE: 0.771614\n",
      "51 45 0.25155141939422226\n",
      "51 95 0.48278524275299817\n",
      "Validation loss: 0.5916587420872279 RMSE: 0.7691936\n",
      "52 40 0.430719675682147\n",
      "52 90 0.4471928807022368\n",
      "Validation loss: 0.5942893482389904 RMSE: 0.7709016\n",
      "53 35 0.23972617209413297\n",
      "53 85 0.4959675182619566\n",
      "Validation loss: 0.5865368286768595 RMSE: 0.7658569\n",
      "54 30 0.5316144867675355\n",
      "54 80 0.34080394840010014\n",
      "Validation loss: 0.5800011282875425 RMSE: 0.761578\n",
      "55 25 0.3620662258909209\n",
      "55 75 0.269472146300728\n",
      "Validation loss: 0.6505353927612305 RMSE: 0.8065577\n",
      "56 20 0.3588367650504213\n",
      "56 70 0.3376852820964103\n",
      "Validation loss: 0.6320557089078994 RMSE: 0.79501927\n",
      "57 15 0.5135588296845047\n",
      "57 65 0.673675017604078\n",
      "Validation loss: 0.6076171409516108 RMSE: 0.779498\n",
      "58 10 0.24038677567883213\n",
      "58 60 0.44669837062659884\n",
      "Validation loss: 0.6165244437399364 RMSE: 0.7851907\n",
      "59 5 0.36811627473056496\n",
      "59 55 0.3808726315491569\n",
      "Validation loss: 0.6352292751982098 RMSE: 0.79701275\n",
      "60 0 0.4210400462579261\n",
      "60 50 0.6355589379890046\n",
      "60 100 0.29648000860696516\n",
      "Validation loss: 0.6155022984459286 RMSE: 0.7845395\n",
      "61 45 0.5243447247428397\n",
      "61 95 0.2807337918964976\n",
      "Validation loss: 0.556765084323429 RMSE: 0.74616694\n",
      "62 40 0.5592119053890847\n",
      "62 90 0.3071092542619654\n",
      "Validation loss: 0.5931331271216983 RMSE: 0.7701513\n",
      "63 35 0.41899162684362057\n",
      "63 85 0.316153150172173\n",
      "Validation loss: 0.5739385661624726 RMSE: 0.7575873\n",
      "64 30 0.5312001238008821\n",
      "64 80 0.3895031099172066\n",
      "Validation loss: 0.5967659904843285 RMSE: 0.7725063\n",
      "65 25 0.34458241360397535\n",
      "65 75 0.2987801130335441\n",
      "Validation loss: 0.6368891704650153 RMSE: 0.7980534\n",
      "66 20 0.22781924001811144\n",
      "66 70 0.535046022620883\n",
      "Validation loss: 0.6365649223327636 RMSE: 0.7978502\n",
      "67 15 0.4451985654448974\n",
      "67 65 0.7221791613006188\n",
      "Validation loss: 0.5799181168987637 RMSE: 0.76152354\n",
      "68 10 0.2687598441764887\n",
      "68 60 0.5766842389036563\n",
      "Validation loss: 0.5676115280105954 RMSE: 0.75339997\n",
      "69 5 0.6430377532817384\n",
      "69 55 0.31039619604307916\n",
      "Validation loss: 0.5631051595721926 RMSE: 0.75040334\n",
      "70 0 0.36575409556785377\n",
      "70 50 0.22654317020207626\n",
      "70 100 0.5952594638968336\n",
      "Validation loss: 0.722083026596478 RMSE: 0.84975463\n",
      "71 45 0.5824504644486724\n",
      "71 95 0.641942388212588\n",
      "Validation loss: 0.5667517412276495 RMSE: 0.7528292\n",
      "72 40 0.22090624759444144\n",
      "72 90 0.23863277486719206\n",
      "Validation loss: 0.547050466423943 RMSE: 0.73962855\n",
      "73 35 0.1744894661006856\n",
      "73 85 0.3622193340502039\n",
      "Validation loss: 0.5884108861287435 RMSE: 0.7670794\n",
      "74 30 0.3266525946678005\n",
      "74 80 0.4806098174671819\n",
      "Validation loss: 0.5766270787942978 RMSE: 0.7593596\n",
      "75 25 0.5181722349431716\n",
      "75 75 0.435289466880726\n",
      "Validation loss: 0.5261481444040934 RMSE: 0.7253607\n",
      "76 20 0.30134085201253147\n",
      "76 70 0.3897003526468905\n",
      "Validation loss: 0.5900841463179816 RMSE: 0.7681694\n",
      "77 15 0.1950503308707366\n",
      "77 65 0.43776974970084764\n",
      "Validation loss: 0.6021552108582996 RMSE: 0.7759866\n",
      "78 10 0.33118694453207603\n",
      "78 60 0.25279693794029334\n",
      "Validation loss: 0.5992189801165035 RMSE: 0.7740923\n",
      "79 5 0.22355517978669096\n",
      "79 55 0.3435102848489582\n",
      "Validation loss: 0.528871994075321 RMSE: 0.72723585\n",
      "80 0 0.35734884885945406\n",
      "80 50 0.2566145286409629\n",
      "80 100 0.2566690843142197\n",
      "Validation loss: 0.5715886178470794 RMSE: 0.7560348\n",
      "81 45 0.21396711997239135\n",
      "81 95 0.28113950778021063\n",
      "Validation loss: 0.5106636456080845 RMSE: 0.7146073\n",
      "82 40 0.2747619851212869\n",
      "82 90 0.23289645408216014\n",
      "Validation loss: 0.576934358051845 RMSE: 0.75956196\n",
      "83 35 0.1686734144283064\n",
      "83 85 0.3171101350943543\n",
      "Validation loss: 0.5553201584588914 RMSE: 0.7451981\n",
      "84 30 0.45384494071735604\n",
      "84 80 0.20158116302707313\n",
      "Validation loss: 0.616243855158488 RMSE: 0.785012\n",
      "85 25 0.20014808623482633\n",
      "85 75 0.23361640025456268\n",
      "Validation loss: 0.5304679087230137 RMSE: 0.7283323\n",
      "86 20 0.6234706070433214\n",
      "86 70 0.22366812893416924\n",
      "Validation loss: 0.5587024013201396 RMSE: 0.74746394\n",
      "87 15 0.40691898690859496\n",
      "87 65 0.3333273409410331\n",
      "Validation loss: 0.5594788083008357 RMSE: 0.74798316\n",
      "88 10 0.2525131812873463\n",
      "88 60 0.17559910103090084\n",
      "Validation loss: 0.5813764103821346 RMSE: 0.76248044\n",
      "89 5 0.5864077141305524\n",
      "89 55 0.2524524163181707\n",
      "Validation loss: 0.5685626535188584 RMSE: 0.75403094\n",
      "90 0 0.31957013717707716\n",
      "90 50 0.37507084528102325\n",
      "90 100 0.24724657591145408\n",
      "Validation loss: 0.5510790983835856 RMSE: 0.742347\n",
      "91 45 0.6399882808325784\n",
      "91 95 0.27786662734285655\n",
      "Validation loss: 0.5238263084774926 RMSE: 0.72375846\n",
      "92 40 0.20716625438865297\n",
      "92 90 0.2838469325290532\n",
      "Validation loss: 0.5168289127803984 RMSE: 0.71890813\n",
      "93 35 0.5102371770156126\n",
      "93 85 0.2351028537347484\n",
      "Validation loss: 0.5359556000857126 RMSE: 0.7320899\n",
      "94 30 0.22191893358621723\n",
      "94 80 0.5928585026443096\n",
      "Validation loss: 0.5600981201444354 RMSE: 0.74839705\n",
      "95 25 0.16015041621682757\n",
      "95 75 0.3275459753192501\n",
      "Validation loss: 0.5343521719887143 RMSE: 0.730994\n",
      "96 20 0.36868034878691053\n",
      "96 70 0.45151210159143956\n",
      "Validation loss: 0.5363770060596011 RMSE: 0.73237765\n",
      "97 15 0.2507872600393394\n",
      "97 65 0.3736931437750603\n",
      "Validation loss: 0.5975725284644535 RMSE: 0.7730282\n",
      "98 10 0.4141049312539672\n",
      "98 60 0.22302535519784947\n",
      "Validation loss: 0.5807888519196284 RMSE: 0.76209503\n",
      "99 5 0.16939301985002758\n",
      "99 55 0.24752991246839906\n",
      "Validation loss: 0.5332062130882627 RMSE: 0.73020965\n",
      "100 0 0.257107238874743\n",
      "100 50 0.2354295011603711\n",
      "100 100 0.2178672535164592\n",
      "Validation loss: 0.527091345900581 RMSE: 0.72601056\n",
      "101 45 0.22055250830890194\n",
      "101 95 0.2790544569841379\n",
      "Validation loss: 0.550235983303615 RMSE: 0.7417789\n",
      "102 40 0.21868911704792648\n",
      "102 90 0.2754753538616039\n",
      "Validation loss: 0.5382409839403062 RMSE: 0.7336491\n",
      "103 35 0.20565097738318153\n",
      "103 85 0.2993039629659514\n",
      "Validation loss: 0.541678220530351 RMSE: 0.7359879\n",
      "104 30 0.23950715846574766\n",
      "104 80 0.21523127501157674\n",
      "Validation loss: 0.5426417980875288 RMSE: 0.73664224\n",
      "105 25 0.17686438425826284\n",
      "105 75 0.28818701152367665\n",
      "Validation loss: 0.5480817967937106 RMSE: 0.74032545\n",
      "106 20 0.2971745507222758\n",
      "106 70 0.2937582935927615\n",
      "Validation loss: 0.5395939980234419 RMSE: 0.7345706\n",
      "107 15 0.20328726133880617\n",
      "107 65 0.3575156103545953\n",
      "Validation loss: 0.5884337561471121 RMSE: 0.7670944\n",
      "108 10 0.2563162791818412\n",
      "108 60 0.2608389385042454\n",
      "Validation loss: 0.5428806394338608 RMSE: 0.73680437\n",
      "109 5 0.3175384507635594\n",
      "109 55 0.24942247532474549\n",
      "Validation loss: 0.4823083806605566 RMSE: 0.69448423\n",
      "110 0 0.2525565221081551\n",
      "110 50 0.30409898936070845\n",
      "110 100 0.3277180538980298\n",
      "Validation loss: 0.5427633658051491 RMSE: 0.73672473\n",
      "111 45 0.24510456420256851\n",
      "111 95 0.2985925328561447\n",
      "Validation loss: 0.5041646168345497 RMSE: 0.71004546\n",
      "112 40 0.31824473412253307\n",
      "112 90 0.48493977319060366\n",
      "Validation loss: 0.5716082802840642 RMSE: 0.7560478\n",
      "113 35 0.32456990868375624\n",
      "113 85 0.29090972671641446\n",
      "Validation loss: 0.5656706009592328 RMSE: 0.7521108\n",
      "114 30 0.26047110562406284\n",
      "114 80 0.3858447898668913\n",
      "Validation loss: 0.5644712871029264 RMSE: 0.75131303\n",
      "115 25 0.29484478617910764\n",
      "115 75 0.24364205117008866\n",
      "Validation loss: 0.5718744834441514 RMSE: 0.7562238\n",
      "116 20 0.16099558595078645\n",
      "116 70 0.2848476938453564\n",
      "Validation loss: 0.5129368146260579 RMSE: 0.71619606\n",
      "117 15 0.38075271746960615\n",
      "117 65 0.17607944211753532\n",
      "Validation loss: 0.5407590707143147 RMSE: 0.73536325\n",
      "118 10 0.26884553226715624\n",
      "118 60 0.22902957745304858\n",
      "Validation loss: 0.5367806077003479 RMSE: 0.73265314\n",
      "119 5 0.18805008064127426\n",
      "119 55 0.2748664156338177\n",
      "Validation loss: 0.5334981055486769 RMSE: 0.73040956\n",
      "120 0 0.2366402151192316\n",
      "120 50 0.2298644312984474\n",
      "120 100 0.19933453499812562\n",
      "Validation loss: 0.523699464684441 RMSE: 0.72367084\n",
      "121 45 0.22152980301440345\n",
      "121 95 0.21288596757329284\n",
      "Validation loss: 0.5101779611337752 RMSE: 0.71426743\n",
      "122 40 0.19181145903824245\n",
      "122 90 0.19638430204476431\n",
      "Validation loss: 0.5615512669086457 RMSE: 0.74936724\n",
      "123 35 0.2233091327628586\n",
      "123 85 0.23090065953742703\n",
      "Validation loss: 0.5417145297640846 RMSE: 0.7360126\n",
      "124 30 0.34019512758883036\n",
      "124 80 0.457810677518814\n",
      "Validation loss: 0.552864564600445 RMSE: 0.74354863\n",
      "125 25 0.26433292230339006\n",
      "125 75 0.3016096758825902\n",
      "Validation loss: 0.5362216124931971 RMSE: 0.73227155\n",
      "126 20 0.1442692505059591\n",
      "126 70 0.2732152716619247\n",
      "Validation loss: 0.5634410653795515 RMSE: 0.7506271\n",
      "127 15 0.17443532009950938\n",
      "127 65 0.1791304652591172\n",
      "Validation loss: 0.5382934888203939 RMSE: 0.73368484\n",
      "128 10 0.18423793188812101\n",
      "128 60 0.15819641696261705\n",
      "Validation loss: 0.5467943060965765 RMSE: 0.73945546\n",
      "129 5 0.16142812205191348\n",
      "129 55 0.09416351921158359\n",
      "Validation loss: 0.5601610898971557 RMSE: 0.7484391\n",
      "130 0 0.2382729696823372\n",
      "130 50 0.18573430362301122\n",
      "130 100 0.17978205362919333\n",
      "Validation loss: 0.5261455762953985 RMSE: 0.7253589\n",
      "131 45 0.3882961942551523\n",
      "131 95 0.21945867784181533\n",
      "Validation loss: 0.5687524091629755 RMSE: 0.75415677\n",
      "132 40 0.18532725274363432\n",
      "132 90 0.1740410832766686\n",
      "Validation loss: 0.5295210940497262 RMSE: 0.727682\n",
      "133 35 0.16716972213453962\n",
      "133 85 0.19240449072771698\n",
      "Validation loss: 0.528061542624519 RMSE: 0.72667843\n",
      "134 30 0.26200232402997564\n",
      "134 80 0.19231572039837386\n",
      "Validation loss: 0.5522839053755715 RMSE: 0.7431581\n",
      "135 25 0.1744014396389911\n",
      "135 75 0.1531117446397366\n",
      "Validation loss: 0.520462965965271 RMSE: 0.7214312\n",
      "136 20 0.3228139729181996\n",
      "136 70 0.18134569791843758\n",
      "Validation loss: 0.5389918814102809 RMSE: 0.73416066\n",
      "137 15 0.29767951408963345\n",
      "137 65 0.19347196048792792\n",
      "Validation loss: 0.5485445340474446 RMSE: 0.7406379\n",
      "138 10 0.26402209912835545\n",
      "138 60 0.23196883012578232\n",
      "Validation loss: 0.5195732786541893 RMSE: 0.7208143\n",
      "139 5 0.22570455964006866\n",
      "139 55 0.15940792177381782\n",
      "Validation loss: 0.519731622437636 RMSE: 0.72092414\n",
      "140 0 0.11557019308330842\n",
      "140 50 0.43799196361333315\n",
      "140 100 0.2885781925427158\n",
      "Validation loss: 0.5261985182762146 RMSE: 0.72539544\n",
      "141 45 0.15941228447049535\n",
      "141 95 0.23016840365173147\n",
      "Validation loss: 0.5659884458496457 RMSE: 0.752322\n",
      "142 40 0.25055522458373797\n",
      "142 90 0.2554274865177972\n",
      "Validation loss: 0.5234773698307219 RMSE: 0.72351736\n",
      "143 35 0.21450987812058261\n",
      "143 85 0.12745425743559471\n",
      "Validation loss: 0.521566039962428 RMSE: 0.72219527\n",
      "144 30 0.20373603040631053\n",
      "144 80 0.1012238823459991\n",
      "Validation loss: 0.5174401609670548 RMSE: 0.7193331\n",
      "145 25 0.25679121694890217\n",
      "145 75 0.26813784755874803\n",
      "Validation loss: 0.5464477390050888 RMSE: 0.739221\n",
      "146 20 0.4959613129218014\n",
      "146 70 0.21944047539633865\n",
      "Validation loss: 0.5532474180062612 RMSE: 0.74380606\n",
      "147 15 0.20533856636542572\n",
      "147 65 0.15353106335482555\n",
      "Validation loss: 0.5316427982988812 RMSE: 0.7291384\n",
      "148 10 0.17193698599854174\n",
      "148 60 0.13778580155597234\n",
      "Validation loss: 0.5374677419662476 RMSE: 0.73312193\n",
      "149 5 0.3785642751665424\n",
      "149 55 0.18906059260817396\n",
      "Validation loss: 0.5428506590071178 RMSE: 0.736784\n",
      "150 0 0.1830766291272966\n",
      "150 50 0.16623271334985665\n",
      "150 100 0.19668936471668555\n",
      "Validation loss: 0.5266972050780342 RMSE: 0.72573906\n",
      "151 45 0.1433881974913703\n",
      "151 95 0.1751717422101166\n",
      "Validation loss: 0.5350580862590245 RMSE: 0.73147666\n",
      "152 40 0.28393767044820956\n",
      "152 90 0.18958971916814996\n",
      "Validation loss: 0.5256174501918611 RMSE: 0.7249948\n",
      "153 35 0.20632311767841965\n",
      "153 85 0.3153884018260072\n",
      "Validation loss: 0.5176206270853678 RMSE: 0.7194586\n",
      "154 30 0.29020189384911954\n",
      "154 80 0.1977309651090449\n",
      "Validation loss: 0.5407506338187626 RMSE: 0.73535746\n",
      "155 25 0.1738252731162321\n",
      "155 75 0.16328038605498013\n",
      "Validation loss: 0.5003112494945526 RMSE: 0.70732677\n",
      "156 20 0.24090885748264765\n",
      "156 70 0.18684270742321551\n",
      "Validation loss: 0.5512908152171544 RMSE: 0.7424896\n",
      "157 15 0.14582512577933587\n",
      "157 65 0.14109410162830183\n",
      "Validation loss: 0.5416055943284716 RMSE: 0.7359386\n",
      "158 10 0.23969921691703444\n",
      "158 60 0.14470054568221952\n",
      "Validation loss: 0.5362581661769322 RMSE: 0.7322965\n",
      "159 5 0.24669167143549167\n",
      "159 55 0.23331849896369575\n",
      "Validation loss: 0.5010762719880967 RMSE: 0.70786744\n",
      "160 0 0.17800137926276405\n",
      "160 50 0.19187050694750407\n",
      "160 100 0.24691499620797516\n",
      "Validation loss: 0.5017447409175692 RMSE: 0.70833945\n",
      "161 45 0.17813114246814735\n",
      "161 95 0.24689231479106902\n",
      "Validation loss: 0.5080317900294349 RMSE: 0.7127635\n",
      "162 40 0.21045935643182268\n",
      "162 90 0.2172088765952736\n",
      "Validation loss: 0.5052544625032516 RMSE: 0.7108125\n",
      "163 35 0.19607086597046391\n",
      "163 85 0.11086138224585643\n",
      "Validation loss: 0.5099722703297933 RMSE: 0.71412337\n",
      "164 30 0.19822791041925303\n",
      "164 80 0.14178099657714524\n",
      "Validation loss: 0.5314895071444057 RMSE: 0.7290333\n",
      "165 25 0.2119630991272291\n",
      "165 75 0.21568813401892648\n",
      "Validation loss: 0.514595498641332 RMSE: 0.7173531\n",
      "166 20 0.07485379562844724\n",
      "166 70 0.15880525993840922\n",
      "Validation loss: 0.5373534557365236 RMSE: 0.73304397\n",
      "167 15 0.1864328697071034\n",
      "167 65 0.2200057839151614\n",
      "Validation loss: 0.5154424775214422 RMSE: 0.71794325\n",
      "168 10 0.15556829147207207\n",
      "168 60 0.1743303187078792\n",
      "Validation loss: 0.6061007823262896 RMSE: 0.77852476\n",
      "169 5 0.11514832457404947\n",
      "169 55 0.21054524449133602\n",
      "Validation loss: 0.562752442132859 RMSE: 0.7501683\n",
      "170 0 0.11632711117107802\n",
      "170 50 0.20882561103465047\n",
      "170 100 0.13913778000249175\n",
      "Validation loss: 0.5128057980821246 RMSE: 0.71610457\n",
      "171 45 0.1683704948463515\n",
      "171 95 0.18522758596641145\n",
      "Validation loss: 0.5260100221350079 RMSE: 0.7252655\n",
      "172 40 0.29717273124267624\n",
      "172 90 0.12995557622376605\n",
      "Validation loss: 0.5357160532758349 RMSE: 0.73192626\n",
      "173 35 0.1569679457349391\n",
      "173 85 0.0961509920582088\n",
      "Validation loss: 0.5562280092920576 RMSE: 0.74580693\n",
      "174 30 0.05787361991760591\n",
      "174 80 0.11381850746548698\n",
      "Validation loss: 0.5659818998404912 RMSE: 0.7523177\n",
      "175 25 0.14901915044285372\n",
      "175 75 0.12398976850559174\n",
      "Validation loss: 0.529491136755262 RMSE: 0.72766143\n",
      "176 20 0.18022178588652507\n",
      "176 70 0.17536601500835286\n",
      "Validation loss: 0.5536178486687796 RMSE: 0.744055\n",
      "177 15 0.15964665578957102\n",
      "177 65 0.15874022365407894\n",
      "Validation loss: 0.552554593483607 RMSE: 0.7433402\n",
      "178 10 0.17062624027631393\n",
      "178 60 0.1411593838234932\n",
      "Validation loss: 0.5280279828678994 RMSE: 0.72665536\n",
      "179 5 0.14654183605539947\n",
      "179 55 0.17406153978043296\n",
      "Validation loss: 0.537480564344497 RMSE: 0.7331307\n",
      "180 0 0.15728748489503866\n",
      "180 50 0.28178212884384485\n",
      "180 100 0.26749997106062084\n",
      "Validation loss: 0.526951098903304 RMSE: 0.725914\n",
      "181 45 0.148564439595659\n",
      "181 95 0.17256280239554248\n",
      "Validation loss: 0.5265051943915231 RMSE: 0.72560674\n",
      "182 40 0.1277313831722223\n",
      "182 90 0.2468736264652114\n",
      "Validation loss: 0.5305445568902152 RMSE: 0.7283849\n",
      "183 35 0.21237290889814625\n",
      "183 85 0.19476644650330643\n",
      "Validation loss: 0.5243676336038681 RMSE: 0.72413236\n",
      "184 30 0.14981379575270082\n",
      "184 80 0.3644624460320191\n",
      "Validation loss: 0.5345190060280618 RMSE: 0.73110807\n",
      "185 25 0.1314737832917382\n",
      "185 75 0.259582587528734\n",
      "Validation loss: 0.5438851793607076 RMSE: 0.7374857\n",
      "186 20 0.1772928028749282\n",
      "186 70 0.17043344513979333\n",
      "Validation loss: 0.503708461352757 RMSE: 0.70972425\n",
      "187 15 0.2787322263255364\n",
      "187 65 0.22106043552804322\n",
      "Validation loss: 0.5662544226362591 RMSE: 0.7524988\n",
      "188 10 0.11636263875159597\n",
      "188 60 0.19920783391357885\n",
      "Validation loss: 0.5909980924356552 RMSE: 0.768764\n",
      "189 5 0.20307815681002614\n",
      "189 55 0.2960662496217535\n",
      "Validation loss: 0.5525456871305193 RMSE: 0.7433342\n",
      "190 0 0.14206402457311337\n",
      "190 50 0.1906103733530504\n",
      "190 100 0.1547135045875238\n",
      "Validation loss: 0.5675128258409954 RMSE: 0.75333446\n",
      "191 45 0.09262747678694312\n",
      "191 95 0.1567669617410932\n",
      "Validation loss: 0.5248727872258141 RMSE: 0.72448105\n",
      "192 40 0.09916969107198856\n",
      "192 90 0.3010191329089652\n",
      "Validation loss: 0.5321761318615504 RMSE: 0.72950405\n",
      "193 35 0.13194964997521358\n",
      "193 85 0.13430625096254348\n",
      "Validation loss: 0.5377539095424471 RMSE: 0.7333171\n",
      "194 30 0.16016228309141342\n",
      "194 80 0.1550692982182805\n",
      "Validation loss: 0.5001116355260213 RMSE: 0.70718575\n",
      "195 25 0.13644280807567438\n",
      "195 75 0.24102825959893928\n",
      "Validation loss: 0.5393770365487962 RMSE: 0.7344229\n",
      "196 20 0.18216078408946423\n",
      "196 70 0.12778868150557487\n",
      "Validation loss: 0.5352722372327532 RMSE: 0.731623\n",
      "197 15 0.10175082519893755\n",
      "197 65 0.1889041838864115\n",
      "Validation loss: 0.5432602502050854 RMSE: 0.7370619\n",
      "198 10 0.19321645256935274\n",
      "198 60 0.21087849948116638\n",
      "Validation loss: 0.5688099009650094 RMSE: 0.7541949\n",
      "199 5 0.1988919185503905\n",
      "199 55 0.13585015671677833\n",
      "Validation loss: 0.5258895939304715 RMSE: 0.7251824\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.5065756489833196 Test RMSE: 0.71174127\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 779, 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'target': ['exp']}}\n",
      "Running on: cuda:1\n",
      "4199\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/4199\n",
      "Generating scaffold 1000/4199\n",
      "Generating scaffold 2000/4199\n",
      "Generating scaffold 3000/4199\n",
      "Generating scaffold 4000/4199\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 5.174460934258073\n",
      "0 50 1.8420979014184744\n",
      "0 100 0.9418767279025936\n",
      "Validation loss: 1.392477890423366 RMSE: 1.180033\n",
      "1 45 0.7746634497432828\n",
      "1 95 1.1183999572142995\n",
      "Validation loss: 1.3174425931203932 RMSE: 1.147799\n",
      "2 40 1.1205904075582382\n",
      "2 90 0.820100074867147\n",
      "Validation loss: 1.053762642542521 RMSE: 1.0265294\n",
      "3 35 0.8232793262860553\n",
      "3 85 1.1457010788561535\n",
      "Validation loss: 1.1526714586076283 RMSE: 1.0736253\n",
      "4 30 1.1093523470863649\n",
      "4 80 0.5415626418009337\n",
      "Validation loss: 0.9801247960045224 RMSE: 0.9900125\n",
      "5 25 0.7331988270412284\n",
      "5 75 0.8168834270583148\n",
      "Validation loss: 0.8916227590470087 RMSE: 0.9442578\n",
      "6 20 0.6156494204752169\n",
      "6 70 0.5983692297803972\n",
      "Validation loss: 0.8357210040092469 RMSE: 0.9141778\n",
      "7 15 0.7607861137597235\n",
      "7 65 0.7589510727999597\n",
      "Validation loss: 0.841390521753402 RMSE: 0.91727346\n",
      "8 10 1.0574701778922388\n",
      "8 60 0.7872225590176534\n",
      "Validation loss: 0.8826787534214201 RMSE: 0.93950987\n",
      "9 5 1.03536047866959\n",
      "9 55 0.9411303273498932\n",
      "Validation loss: 0.7603872432595208 RMSE: 0.8720018\n",
      "10 0 0.5191696530789407\n",
      "10 50 0.7274792871629755\n",
      "10 100 1.0793939523930367\n",
      "Validation loss: 0.8125690375055585 RMSE: 0.9014261\n",
      "11 45 0.7964758133567066\n",
      "11 95 0.6400161691973718\n",
      "Validation loss: 0.7680611366317386 RMSE: 0.87639093\n",
      "12 40 0.5148674075881183\n",
      "12 90 0.6308290995983419\n",
      "Validation loss: 1.0063914673668997 RMSE: 1.0031906\n",
      "13 35 0.5252908140266537\n",
      "13 85 0.6657657782685654\n",
      "Validation loss: 0.7311593359424955 RMSE: 0.8550786\n",
      "14 30 0.712405335275393\n",
      "14 80 0.5317020978193211\n",
      "Validation loss: 0.8042436633791242 RMSE: 0.89679635\n",
      "15 25 0.6960891989219588\n",
      "15 75 0.5273296995492892\n",
      "Validation loss: 0.8304267048835754 RMSE: 0.91127753\n",
      "16 20 0.5770429390989651\n",
      "16 70 0.5512106534176051\n",
      "Validation loss: 0.718738636019684 RMSE: 0.8477846\n",
      "17 15 0.47071446265033434\n",
      "17 65 0.5594941623979927\n",
      "Validation loss: 0.6610023668834142 RMSE: 0.8130206\n",
      "18 10 0.5330550237421384\n",
      "18 60 0.6435817517737839\n",
      "Validation loss: 0.6733998588153294 RMSE: 0.82060945\n",
      "19 5 0.35716765491254066\n",
      "19 55 0.3415328320155314\n",
      "Validation loss: 0.6432461182276408 RMSE: 0.8020263\n",
      "20 0 0.6275347775659018\n",
      "20 50 0.6362251562031677\n",
      "20 100 0.35362137919988523\n",
      "Validation loss: 0.6607682202543531 RMSE: 0.8128765\n",
      "21 45 0.4759481615849241\n",
      "21 95 0.446751899666809\n",
      "Validation loss: 0.6928015628740901 RMSE: 0.832347\n",
      "22 40 0.6541467934527129\n",
      "22 90 0.2140075951020849\n",
      "Validation loss: 0.8378625052315848 RMSE: 0.9153483\n",
      "23 35 0.5648882837318572\n",
      "23 85 0.635128127369991\n",
      "Validation loss: 0.7601755062739054 RMSE: 0.8718804\n",
      "24 30 0.6128370496413674\n",
      "24 80 0.6073266295162096\n",
      "Validation loss: 0.6529354969660441 RMSE: 0.80804425\n",
      "25 25 0.3512107799875044\n",
      "25 75 0.727307805732351\n",
      "Validation loss: 0.6933193890821366 RMSE: 0.83265805\n",
      "26 20 0.2631610647692361\n",
      "26 70 0.3319811998976975\n",
      "Validation loss: 0.6923276015690395 RMSE: 0.83206224\n",
      "27 15 0.4715966290659954\n",
      "27 65 0.6188422734367723\n",
      "Validation loss: 0.6332189645086016 RMSE: 0.7957505\n",
      "28 10 0.5644331093996621\n",
      "28 60 0.42249668006402796\n",
      "Validation loss: 0.6494562149047851 RMSE: 0.8058885\n",
      "29 5 0.41093212013022484\n",
      "29 55 0.44181467878770386\n",
      "Validation loss: 0.6656891050792876 RMSE: 0.81589776\n",
      "30 0 0.4630454623008583\n",
      "30 50 0.3692538829591258\n",
      "30 100 0.7069202280623189\n",
      "Validation loss: 0.6908844706558046 RMSE: 0.8311946\n",
      "31 45 0.4115647021964108\n",
      "31 95 0.40135329533916486\n",
      "Validation loss: 0.646134797164372 RMSE: 0.8038251\n",
      "32 40 0.452312636688288\n",
      "32 90 0.3746510155876691\n",
      "Validation loss: 0.6277254411152431 RMSE: 0.7922913\n",
      "33 35 0.3343626102958222\n",
      "33 85 0.5864100212566333\n",
      "Validation loss: 0.6791952864045189 RMSE: 0.82413304\n",
      "34 30 0.3006322037262459\n",
      "34 80 0.3217095048231658\n",
      "Validation loss: 0.6482157026018415 RMSE: 0.8051184\n",
      "35 25 0.6543391346356437\n",
      "35 75 0.756795985675067\n",
      "Validation loss: 0.6514787056616375 RMSE: 0.80714226\n",
      "36 20 0.5354172455155253\n",
      "36 70 0.4691916620268898\n",
      "Validation loss: 0.6988028594425746 RMSE: 0.8359443\n",
      "37 15 0.5191313983220267\n",
      "37 65 0.48138271090715884\n",
      "Validation loss: 0.6745525087629046 RMSE: 0.8213115\n",
      "38 10 0.48372671943242795\n",
      "38 60 0.363411522517832\n",
      "Validation loss: 0.6412235069842566 RMSE: 0.8007643\n",
      "39 5 0.419211455070413\n",
      "39 55 0.47386403711717273\n",
      "Validation loss: 0.6103016717093331 RMSE: 0.7812181\n",
      "40 0 0.5204185716832352\n",
      "40 50 0.257475985835567\n",
      "40 100 0.43851434239703674\n",
      "Validation loss: 0.6595150039309547 RMSE: 0.8121053\n",
      "41 45 0.5140354221143422\n",
      "41 95 0.35492050072729503\n",
      "Validation loss: 0.5983040764218285 RMSE: 0.77350116\n",
      "42 40 0.25466224193560694\n",
      "42 90 0.4371346693009107\n",
      "Validation loss: 0.6274235129356385 RMSE: 0.7921007\n",
      "43 35 0.45627777602717134\n",
      "43 85 0.7508477417088684\n",
      "Validation loss: 0.5633794969036465 RMSE: 0.7505861\n",
      "44 30 0.2872797304981005\n",
      "44 80 0.42187802205198277\n",
      "Validation loss: 0.6312138304823921 RMSE: 0.7944897\n",
      "45 25 0.4478048024975738\n",
      "45 75 0.5114503417371579\n",
      "Validation loss: 0.5728247370038714 RMSE: 0.7568519\n",
      "46 20 0.5982531265203158\n",
      "46 70 0.3507600979085092\n",
      "Validation loss: 0.5849307673318046 RMSE: 0.7648077\n",
      "47 15 0.738072852719261\n",
      "47 65 0.3400852437194707\n",
      "Validation loss: 0.5927589129833948 RMSE: 0.7699084\n",
      "48 10 0.17600953475807657\n",
      "48 60 0.457796627224456\n",
      "Validation loss: 0.6032108602069673 RMSE: 0.77666646\n",
      "49 5 0.3681237613402093\n",
      "49 55 0.2833973189198903\n",
      "Validation loss: 0.5762514875048683 RMSE: 0.7591123\n",
      "50 0 0.44201270299655526\n",
      "50 50 0.49980101348185635\n",
      "50 100 0.37694526369534587\n",
      "Validation loss: 0.5867120447612945 RMSE: 0.76597136\n",
      "51 45 0.4920719448257841\n",
      "51 95 0.4222666752425564\n",
      "Validation loss: 0.6087986219496954 RMSE: 0.7802555\n",
      "52 40 0.35887053644610883\n",
      "52 90 0.4575266353603849\n",
      "Validation loss: 0.5458000750768752 RMSE: 0.7387828\n",
      "53 35 0.2865852674144798\n",
      "53 85 0.3376897756103378\n",
      "Validation loss: 0.5477589601562136 RMSE: 0.74010736\n",
      "54 30 0.3807777637152173\n",
      "54 80 0.16979060965351056\n",
      "Validation loss: 0.5265079577763875 RMSE: 0.7256087\n",
      "55 25 0.5267564882673138\n",
      "55 75 0.6036039678194963\n",
      "Validation loss: 0.696235800357092 RMSE: 0.83440745\n",
      "56 20 0.44518974282305934\n",
      "56 70 0.35430887024948227\n",
      "Validation loss: 0.5921954597745623 RMSE: 0.7695424\n",
      "57 15 0.4154436518084126\n",
      "57 65 0.4096972911987235\n",
      "Validation loss: 0.5405485158874875 RMSE: 0.73522\n",
      "58 10 0.37451358871401763\n",
      "58 60 0.5198924122412938\n",
      "Validation loss: 0.5892068329311553 RMSE: 0.7675981\n",
      "59 5 0.425411869443329\n",
      "59 55 0.5920058266634641\n",
      "Validation loss: 0.5771791463806516 RMSE: 0.7597231\n",
      "60 0 0.3617619169373589\n",
      "60 50 0.5154906399142087\n",
      "60 100 0.32710644219847695\n",
      "Validation loss: 0.5567231325876145 RMSE: 0.7461389\n",
      "61 45 0.21933883329347265\n",
      "61 95 0.27786998489474246\n",
      "Validation loss: 0.560491685072581 RMSE: 0.74865997\n",
      "62 40 0.2507622892666884\n",
      "62 90 0.4460086492433262\n",
      "Validation loss: 0.5515020391770772 RMSE: 0.74263185\n",
      "63 35 0.1974608278548602\n",
      "63 85 0.5074401645210128\n",
      "Validation loss: 0.6226660001845586 RMSE: 0.7890919\n",
      "64 30 0.5511945644642141\n",
      "64 80 0.30648357989255554\n",
      "Validation loss: 0.5530605368670963 RMSE: 0.7436804\n",
      "65 25 0.3649005973700529\n",
      "65 75 0.43596533759523554\n",
      "Validation loss: 0.5724697703406925 RMSE: 0.7566173\n",
      "66 20 0.24274967374982873\n",
      "66 70 0.21359689315689634\n",
      "Validation loss: 0.5810616907619295 RMSE: 0.762274\n",
      "67 15 0.2141472432852095\n",
      "67 65 0.3441912098162072\n",
      "Validation loss: 0.523867475702649 RMSE: 0.7237869\n",
      "68 10 0.3316043614760815\n",
      "68 60 0.5076057245792318\n",
      "Validation loss: 0.5163560092449189 RMSE: 0.7185792\n",
      "69 5 0.2415250673330839\n",
      "69 55 0.2856104784407673\n",
      "Validation loss: 0.5947904870623634 RMSE: 0.77122664\n",
      "70 0 0.17710977316624052\n",
      "70 50 0.35076326631221505\n",
      "70 100 0.3437999487801719\n",
      "Validation loss: 0.5192359254473732 RMSE: 0.7205803\n",
      "71 45 0.35231577507426326\n",
      "71 95 0.4367851393609528\n",
      "Validation loss: 0.5774945190974644 RMSE: 0.7599306\n",
      "72 40 0.35569718968569186\n",
      "72 90 0.5568183274831549\n",
      "Validation loss: 0.574078190894354 RMSE: 0.75767946\n",
      "73 35 0.42812603726939386\n",
      "73 85 0.1371081094607737\n",
      "Validation loss: 0.5185000118755159 RMSE: 0.72006947\n",
      "74 30 0.2526590595162152\n",
      "74 80 0.2840608184150322\n",
      "Validation loss: 0.5423801876249768 RMSE: 0.7364647\n",
      "75 25 0.7295819176442654\n",
      "75 75 0.34872751825618914\n",
      "Validation loss: 0.5229129155476888 RMSE: 0.72312725\n",
      "76 20 0.2979936610594741\n",
      "76 70 0.4594555431551205\n",
      "Validation loss: 0.594623571350461 RMSE: 0.7711184\n",
      "77 15 0.30559811150015886\n",
      "77 65 0.33862460295231367\n",
      "Validation loss: 0.5249144727275485 RMSE: 0.72450984\n",
      "78 10 0.17700542023122237\n",
      "78 60 0.40080932031902156\n",
      "Validation loss: 0.5242036493761199 RMSE: 0.7240191\n",
      "79 5 0.26132344203014457\n",
      "79 55 0.29192509312553644\n",
      "Validation loss: 0.5354607400440035 RMSE: 0.7317518\n",
      "80 0 0.4369372171595258\n",
      "80 50 0.35435565679246167\n",
      "80 100 0.2126534596449885\n",
      "Validation loss: 0.5177784352075486 RMSE: 0.71956825\n",
      "81 45 0.32166364622276145\n",
      "81 95 0.34298364497512074\n",
      "Validation loss: 0.5062376726241339 RMSE: 0.7115038\n",
      "82 40 0.5155582461041865\n",
      "82 90 0.3186090654048506\n",
      "Validation loss: 0.5289202515568052 RMSE: 0.72726905\n",
      "83 35 0.38787094989536075\n",
      "83 85 0.16107659035071756\n",
      "Validation loss: 0.5804332557178679 RMSE: 0.7618617\n",
      "84 30 0.12442474389729309\n",
      "84 80 0.3367169490752691\n",
      "Validation loss: 0.569336504027957 RMSE: 0.7545439\n",
      "85 25 0.22262542259478252\n",
      "85 75 0.18524975973376198\n",
      "Validation loss: 0.5760642392294747 RMSE: 0.758989\n",
      "86 20 0.3327588422274212\n",
      "86 70 0.3483445934721317\n",
      "Validation loss: 0.5440628065949394 RMSE: 0.7376061\n",
      "87 15 0.5405281117356492\n",
      "87 65 0.37133560345037825\n",
      "Validation loss: 0.5009048172405788 RMSE: 0.70774627\n",
      "88 10 0.25750747921539324\n",
      "88 60 0.3372789881128495\n",
      "Validation loss: 0.5888177996590024 RMSE: 0.76734465\n",
      "89 5 0.22593820475372223\n",
      "89 55 0.46657069351856445\n",
      "Validation loss: 0.5494349865686325 RMSE: 0.7412388\n",
      "90 0 0.3058816291632356\n",
      "90 50 0.21023269016996096\n",
      "90 100 0.2714806879487218\n",
      "Validation loss: 0.49397084258851554 RMSE: 0.7028306\n",
      "91 45 0.36569193337183425\n",
      "91 95 0.4048846665894306\n",
      "Validation loss: 0.5147731578775815 RMSE: 0.7174769\n",
      "92 40 0.33636754149471826\n",
      "92 90 0.171616711003869\n",
      "Validation loss: 0.5199169113522484 RMSE: 0.72105265\n",
      "93 35 0.13647938834313303\n",
      "93 85 0.2719854891836092\n",
      "Validation loss: 0.5265879812694731 RMSE: 0.72566384\n",
      "94 30 0.5449897776670949\n",
      "94 80 0.3248447203427566\n",
      "Validation loss: 0.5467775197256179 RMSE: 0.739444\n",
      "95 25 0.28459672184952384\n",
      "95 75 0.23540510168084466\n",
      "Validation loss: 0.544742781207675 RMSE: 0.738067\n",
      "96 20 0.1850651228862229\n",
      "96 70 0.290683663315206\n",
      "Validation loss: 0.5618583077476138 RMSE: 0.7495721\n",
      "97 15 0.26799007199563113\n",
      "97 65 0.4393837350993301\n",
      "Validation loss: 0.5091857698701677 RMSE: 0.71357256\n",
      "98 10 0.3493239603470653\n",
      "98 60 0.2968675991704118\n",
      "Validation loss: 0.4839874613852728 RMSE: 0.69569206\n",
      "99 5 0.2621101591166358\n",
      "99 55 0.42048217768977525\n",
      "Validation loss: 0.5200115987232753 RMSE: 0.7211183\n",
      "100 0 0.223152356457126\n",
      "100 50 0.14845404162429676\n",
      "100 100 0.12167282460438034\n",
      "Validation loss: 0.532309763399618 RMSE: 0.7295956\n",
      "101 45 0.294025388233769\n",
      "101 95 0.2214401235901609\n",
      "Validation loss: 0.5242925683657328 RMSE: 0.7240805\n",
      "102 40 0.2772959914926612\n",
      "102 90 0.3071362850688672\n",
      "Validation loss: 0.5274288858686175 RMSE: 0.726243\n",
      "103 35 0.4128707595209061\n",
      "103 85 0.24992722089121608\n",
      "Validation loss: 0.5127521741957891 RMSE: 0.71606714\n",
      "104 30 0.22767297919484472\n",
      "104 80 0.2357006807958945\n",
      "Validation loss: 0.54224990436009 RMSE: 0.73637617\n",
      "105 25 0.22274225689807214\n",
      "105 75 0.7050409490517691\n",
      "Validation loss: 0.5047728708812169 RMSE: 0.7104737\n",
      "106 20 0.14574542322305786\n",
      "106 70 0.22762578118766044\n",
      "Validation loss: 0.5609536454791114 RMSE: 0.74896836\n",
      "107 15 0.19438093425391015\n",
      "107 65 0.14546342875637805\n",
      "Validation loss: 0.5257003443581717 RMSE: 0.72505194\n",
      "108 10 0.2141055263015123\n",
      "108 60 0.24033286453121644\n",
      "Validation loss: 0.5036243631726219 RMSE: 0.70966494\n",
      "109 5 0.27346337435264995\n",
      "109 55 0.15525176116588216\n",
      "Validation loss: 0.5155618230501811 RMSE: 0.71802634\n",
      "110 0 0.43259596535002287\n",
      "110 50 0.2992403064317399\n",
      "110 100 0.25769849568933056\n",
      "Validation loss: 0.5123462501026336 RMSE: 0.71578366\n",
      "111 45 0.376468714057497\n",
      "111 95 0.21251351148633246\n",
      "Validation loss: 0.544235945315588 RMSE: 0.73772347\n",
      "112 40 0.31008327857821605\n",
      "112 90 0.23191422211946003\n",
      "Validation loss: 0.5265891131545816 RMSE: 0.7256646\n",
      "113 35 0.3665254842898805\n",
      "113 85 0.1773182196445872\n",
      "Validation loss: 0.5258757337927819 RMSE: 0.72517294\n",
      "114 30 0.18603954565475622\n",
      "114 80 0.21422990504776182\n",
      "Validation loss: 0.5299540110996791 RMSE: 0.7279794\n",
      "115 25 0.42798997451971615\n",
      "115 75 0.20826656579482328\n",
      "Validation loss: 0.5180516782261076 RMSE: 0.7197581\n",
      "116 20 0.1804465242543442\n",
      "116 70 0.5346736628343174\n",
      "Validation loss: 0.5250517589705331 RMSE: 0.72460455\n",
      "117 15 0.17806167163342468\n",
      "117 65 0.2844993529868047\n",
      "Validation loss: 0.5359562980277198 RMSE: 0.73209035\n",
      "118 10 0.14840323883073073\n",
      "118 60 0.24483341825530158\n",
      "Validation loss: 0.5720938432784307 RMSE: 0.7563689\n",
      "119 5 0.14614687424184974\n",
      "119 55 0.3078706173244646\n",
      "Validation loss: 0.5290791801043919 RMSE: 0.72737825\n",
      "120 0 0.2441223239814436\n",
      "120 50 0.42584099780663204\n",
      "120 100 0.17303016311652075\n",
      "Validation loss: 0.5171579701559884 RMSE: 0.71913695\n",
      "121 45 0.1568641761978684\n",
      "121 95 0.19387182642619635\n",
      "Validation loss: 0.5182053495021094 RMSE: 0.7198648\n",
      "122 40 0.21215118661793037\n",
      "122 90 0.37840205244362274\n",
      "Validation loss: 0.5233634454863412 RMSE: 0.7234386\n",
      "123 35 0.3705077906904118\n",
      "123 85 0.20252442248148791\n",
      "Validation loss: 0.5088754900864192 RMSE: 0.71335506\n",
      "124 30 0.26681187902901016\n",
      "124 80 0.25654259406770574\n",
      "Validation loss: 0.5121409541084653 RMSE: 0.71564025\n",
      "125 25 0.16837355516839844\n",
      "125 75 0.20908843147548073\n",
      "Validation loss: 0.5276200450602032 RMSE: 0.72637457\n",
      "126 20 0.24219303904594222\n",
      "126 70 0.12137991644345665\n",
      "Validation loss: 0.5314033045655205 RMSE: 0.72897416\n",
      "127 15 0.21255761858105254\n",
      "127 65 0.300089660791528\n",
      "Validation loss: 0.5291668579691933 RMSE: 0.72743857\n",
      "128 10 0.48483865021703343\n",
      "128 60 0.34687101207867227\n",
      "Validation loss: 0.526344488915943 RMSE: 0.72549605\n",
      "129 5 0.2547411862466891\n",
      "129 55 0.14598931868400397\n",
      "Validation loss: 0.5936229961259024 RMSE: 0.7704693\n",
      "130 0 0.4261769133096802\n",
      "130 50 0.13466537421205269\n",
      "130 100 0.14570980659376537\n",
      "Validation loss: 0.5551483846846081 RMSE: 0.7450828\n",
      "131 45 0.42141513581059775\n",
      "131 95 0.16034330598338078\n",
      "Validation loss: 0.5230962135962077 RMSE: 0.7232539\n",
      "132 40 0.5254259407313512\n",
      "132 90 0.10919459577046661\n",
      "Validation loss: 0.513652673789433 RMSE: 0.71669567\n",
      "133 35 0.1387862377345523\n",
      "133 85 0.1994280265377311\n",
      "Validation loss: 0.5277636641547794 RMSE: 0.72647345\n",
      "134 30 0.24343375353038268\n",
      "134 80 0.28679624315005126\n",
      "Validation loss: 0.513572865440732 RMSE: 0.71664\n",
      "135 25 0.19539200398585913\n",
      "135 75 0.34489600866299275\n",
      "Validation loss: 0.5254577165558225 RMSE: 0.7248846\n",
      "136 20 0.1686904026066995\n",
      "136 70 0.22857377303362672\n",
      "Validation loss: 0.5048832734425862 RMSE: 0.7105514\n",
      "137 15 0.1265956539106978\n",
      "137 65 0.20447788827016047\n",
      "Validation loss: 0.5161901451292492 RMSE: 0.7184638\n",
      "138 10 0.17422939188338776\n",
      "138 60 0.2385430833862558\n",
      "Validation loss: 0.5493568420410156 RMSE: 0.7411861\n",
      "139 5 0.20576411524651445\n",
      "139 55 0.20270203917309285\n",
      "Validation loss: 0.5408606676828294 RMSE: 0.73543227\n",
      "140 0 0.16661843862226475\n",
      "140 50 0.18828578301733478\n",
      "140 100 0.24745102522380943\n",
      "Validation loss: 0.5274073180698213 RMSE: 0.7262282\n",
      "141 45 0.11631261358894493\n",
      "141 95 0.26819286140931675\n",
      "Validation loss: 0.5325035242807298 RMSE: 0.7297284\n",
      "142 40 0.28922969035519475\n",
      "142 90 0.2805674648165694\n",
      "Validation loss: 0.5443461350032262 RMSE: 0.73779815\n",
      "143 35 0.22291959991620616\n",
      "143 85 0.1707988853451995\n",
      "Validation loss: 0.490339073680696 RMSE: 0.70024216\n",
      "144 30 0.2572258441058898\n",
      "144 80 0.2213580668665678\n",
      "Validation loss: 0.5220198952016376 RMSE: 0.72250944\n",
      "145 25 0.33365039115030165\n",
      "145 75 0.20034455549059219\n",
      "Validation loss: 0.49216599691481816 RMSE: 0.7015454\n",
      "146 20 0.07136988841350915\n",
      "146 70 0.25900744815020904\n",
      "Validation loss: 0.5281532978018125 RMSE: 0.72674155\n",
      "147 15 0.09175889738712002\n",
      "147 65 0.21139249798417548\n",
      "Validation loss: 0.5092484939666021 RMSE: 0.7136165\n",
      "148 10 0.19341798592325082\n",
      "148 60 0.24453308712246472\n",
      "Validation loss: 0.5183207423914047 RMSE: 0.71994495\n",
      "149 5 0.1581017594002198\n",
      "149 55 0.10988720308206053\n",
      "Validation loss: 0.5026558816432953 RMSE: 0.7089823\n",
      "150 0 0.22602951548335845\n",
      "150 50 0.10914595560303324\n",
      "150 100 0.26791113296789926\n",
      "Validation loss: 0.519728968824659 RMSE: 0.7209223\n",
      "151 45 0.12721431148919882\n",
      "151 95 0.4088991531342273\n",
      "Validation loss: 0.48550565384683153 RMSE: 0.69678235\n",
      "152 40 0.14878062099848455\n",
      "152 90 0.17209913189706078\n",
      "Validation loss: 0.5113486385061627 RMSE: 0.71508646\n",
      "153 35 0.251056306233692\n",
      "153 85 0.22765042917567302\n",
      "Validation loss: 0.5072135184492383 RMSE: 0.7121892\n",
      "154 30 0.18422648303998518\n",
      "154 80 0.2844672791255506\n",
      "Validation loss: 0.5062235451879955 RMSE: 0.71149385\n",
      "155 25 0.20172482373780837\n",
      "155 75 0.148881831114951\n",
      "Validation loss: 0.5394188390601249 RMSE: 0.73445135\n",
      "156 20 0.11984274200124401\n",
      "156 70 0.16056336811554078\n",
      "Validation loss: 0.525363716625032 RMSE: 0.7248198\n",
      "157 15 0.2299562819302715\n",
      "157 65 0.32722537331958435\n",
      "Validation loss: 0.546481610479809 RMSE: 0.7392439\n",
      "158 10 0.22550886607516593\n",
      "158 60 0.21987834349684734\n",
      "Validation loss: 0.5387685026441301 RMSE: 0.7340085\n",
      "159 5 0.1378987937336003\n",
      "159 55 0.12256263903716204\n",
      "Validation loss: 0.5418933665468579 RMSE: 0.73613405\n",
      "160 0 0.24048899608997082\n",
      "160 50 0.1738838755175941\n",
      "160 100 0.13554555649298317\n",
      "Validation loss: 0.5031890043545337 RMSE: 0.70935816\n",
      "161 45 0.26139330606324795\n",
      "161 95 0.36678033060045667\n",
      "Validation loss: 0.4873623706045605 RMSE: 0.69811344\n",
      "162 40 0.10005783937516112\n",
      "162 90 0.14992506404476044\n",
      "Validation loss: 0.5137807125136966 RMSE: 0.71678495\n",
      "163 35 0.16766035846173583\n",
      "163 85 0.2447298013694173\n",
      "Validation loss: 0.5324019422133763 RMSE: 0.7296588\n",
      "164 30 0.1563165774070787\n",
      "164 80 0.1451280585093745\n",
      "Validation loss: 0.4792453218074072 RMSE: 0.6922754\n",
      "165 25 0.14717598732443637\n",
      "165 75 0.23899354655506994\n",
      "Validation loss: 0.5228221564065842 RMSE: 0.7230644\n",
      "166 20 0.23519056501246252\n",
      "166 70 0.16806757479633294\n",
      "Validation loss: 0.5089758364927202 RMSE: 0.7134254\n",
      "167 15 0.17814230115240282\n",
      "167 65 0.11645674606940243\n",
      "Validation loss: 0.5287590024017153 RMSE: 0.7271582\n",
      "168 10 0.17429421398956946\n",
      "168 60 0.1641602646556804\n",
      "Validation loss: 0.5034224616629737 RMSE: 0.7095227\n",
      "169 5 0.2557339155493197\n",
      "169 55 0.19006137266069442\n",
      "Validation loss: 0.5150433008869489 RMSE: 0.71766514\n",
      "170 0 0.1909060805493524\n",
      "170 50 0.17430633838681106\n",
      "170 100 0.1413249509544388\n",
      "Validation loss: 0.5309322618302845 RMSE: 0.728651\n",
      "171 45 0.12646432817052985\n",
      "171 95 0.12690819510872287\n",
      "Validation loss: 0.542765892687298 RMSE: 0.73672646\n",
      "172 40 0.11498755549981379\n",
      "172 90 0.13252448749679094\n",
      "Validation loss: 0.5405904190880911 RMSE: 0.73524857\n",
      "173 35 0.16118658237292624\n",
      "173 85 0.13021227571164837\n",
      "Validation loss: 0.5152756977648962 RMSE: 0.717827\n",
      "174 30 0.22891315323888223\n",
      "174 80 0.19341474103285597\n",
      "Validation loss: 0.5142362353347597 RMSE: 0.71710265\n",
      "175 25 0.15605585002908223\n",
      "175 75 0.18601460307899273\n",
      "Validation loss: 0.5348163622475806 RMSE: 0.7313114\n",
      "176 20 0.15050588982833576\n",
      "176 70 0.08977127029687909\n",
      "Validation loss: 0.4945984891482762 RMSE: 0.703277\n",
      "177 15 0.16234624565208267\n",
      "177 65 0.37688300516307743\n",
      "Validation loss: 0.5106822008178348 RMSE: 0.7146203\n",
      "178 10 0.13384124547649884\n",
      "178 60 0.24214646923790906\n",
      "Validation loss: 0.4897786015555972 RMSE: 0.6998418\n",
      "179 5 0.16490254473050928\n",
      "179 55 0.10028160353407144\n",
      "Validation loss: 0.5462640455790928 RMSE: 0.73909676\n",
      "180 0 0.18464610941733933\n",
      "180 50 0.13468135604449413\n",
      "180 100 0.16606141092677265\n",
      "Validation loss: 0.513288991366114 RMSE: 0.71644187\n",
      "181 45 0.1270989103974327\n",
      "181 95 0.33789357945835297\n",
      "Validation loss: 0.5050274272759755 RMSE: 0.7106528\n",
      "182 40 0.14482683547518654\n",
      "182 90 0.13748054882498126\n",
      "Validation loss: 0.52053418053048 RMSE: 0.72148055\n",
      "183 35 0.17779480933911362\n",
      "183 85 0.19034206742598725\n",
      "Validation loss: 0.5289060087431044 RMSE: 0.7272592\n",
      "184 30 0.1188229844574758\n",
      "184 80 0.13569873514355768\n",
      "Validation loss: 0.554102593376523 RMSE: 0.74438065\n",
      "185 25 0.1718923915720551\n",
      "185 75 0.16477534283503403\n",
      "Validation loss: 0.5308467007818676 RMSE: 0.7285923\n",
      "186 20 0.11013768586509719\n",
      "186 70 0.14653346809503248\n",
      "Validation loss: 0.5165281783966791 RMSE: 0.718699\n",
      "187 15 0.2345635490957499\n",
      "187 65 0.1771158138640865\n",
      "Validation loss: 0.4944542666276296 RMSE: 0.7031744\n",
      "188 10 0.1199126603381028\n",
      "188 60 0.33467573090243335\n",
      "Validation loss: 0.49459343353907265 RMSE: 0.70327336\n",
      "189 5 0.18601747060216495\n",
      "189 55 0.13310923066094205\n",
      "Validation loss: 0.5544503894590196 RMSE: 0.74461424\n",
      "190 0 0.2334535115012285\n",
      "190 50 0.20657982481906068\n",
      "190 100 0.1912555870282138\n",
      "Validation loss: 0.5152539230528332 RMSE: 0.7178119\n",
      "191 45 0.16040764996818818\n",
      "191 95 0.11153257834656137\n",
      "Validation loss: 0.5082551011017391 RMSE: 0.71292007\n",
      "192 40 0.13519535049595366\n",
      "192 90 0.18441741665198266\n",
      "Validation loss: 0.5205766303198678 RMSE: 0.72150993\n",
      "193 35 0.3312860801510204\n",
      "193 85 0.25692381799070846\n",
      "Validation loss: 0.5480694100970314 RMSE: 0.7403171\n",
      "194 30 0.15843727569265798\n",
      "194 80 0.1287312704161233\n",
      "Validation loss: 0.5118012433960324 RMSE: 0.71540284\n",
      "195 25 0.1752282895882481\n",
      "195 75 0.1177381341037642\n",
      "Validation loss: 0.5070163911297207 RMSE: 0.7120508\n",
      "196 20 0.1409836216532962\n",
      "196 70 0.1170183347924227\n",
      "Validation loss: 0.5284170252936227 RMSE: 0.726923\n",
      "197 15 0.20345731721708882\n",
      "197 65 0.12711823689198617\n",
      "Validation loss: 0.541626905259632 RMSE: 0.7359531\n",
      "198 10 0.13837391973992366\n",
      "198 60 0.13644605732800116\n",
      "Validation loss: 0.5268277003651574 RMSE: 0.72582895\n",
      "199 5 0.14192658788490325\n",
      "199 55 0.17973430897296752\n",
      "Validation loss: 0.5535692288762047 RMSE: 0.7440223\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.5112821403003874 Test RMSE: 0.71503997\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 780, 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'target': ['exp']}}\n",
      "Running on: cuda:1\n",
      "4199\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/4199\n",
      "Generating scaffold 1000/4199\n",
      "Generating scaffold 2000/4199\n",
      "Generating scaffold 3000/4199\n",
      "Generating scaffold 4000/4199\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 5.182457148281626\n",
      "0 50 1.475278183783728\n",
      "0 100 1.320223438177289\n",
      "Validation loss: 1.3295645043963478 RMSE: 1.1530675\n",
      "1 45 1.1854262670587306\n",
      "1 95 1.0317275366970045\n",
      "Validation loss: 1.0039148642903282 RMSE: 1.0019555\n",
      "2 40 1.0122171367448587\n",
      "2 90 0.47284621212402195\n",
      "Validation loss: 1.2503788073857625 RMSE: 1.1182034\n",
      "3 35 0.8385047237979897\n",
      "3 85 0.8082332127120686\n",
      "Validation loss: 1.182796209199088 RMSE: 1.0875643\n",
      "4 30 1.113386446511425\n",
      "4 80 0.6586439837916404\n",
      "Validation loss: 1.0096497717357817 RMSE: 1.0048133\n",
      "5 25 0.5261996432338288\n",
      "5 75 0.7528698387474454\n",
      "Validation loss: 1.038841422398885 RMSE: 1.0192357\n",
      "6 20 0.5872850030332748\n",
      "6 70 0.8395805836729627\n",
      "Validation loss: 0.8797062431062971 RMSE: 0.93792653\n",
      "7 15 0.9326068514005217\n",
      "7 65 0.7345690405092697\n",
      "Validation loss: 0.8417879717690604 RMSE: 0.91749\n",
      "8 10 0.6209426755460304\n",
      "8 60 0.5157602664960971\n",
      "Validation loss: 0.9473182178678967 RMSE: 0.9733028\n",
      "9 5 0.3788034602177036\n",
      "9 55 0.5907730687018187\n",
      "Validation loss: 0.7952401501791818 RMSE: 0.8917624\n",
      "10 0 0.5261165457459287\n",
      "10 50 0.7780739775246168\n",
      "10 100 0.5573046287332984\n",
      "Validation loss: 0.8131616791089376 RMSE: 0.9017548\n",
      "11 45 0.4796819380876315\n",
      "11 95 0.7056531596334096\n",
      "Validation loss: 0.9177183412370228 RMSE: 0.95797616\n",
      "12 40 0.8934255893303633\n",
      "12 90 1.0279686913228834\n",
      "Validation loss: 0.8291651731445676 RMSE: 0.9105851\n",
      "13 35 0.3911880972804036\n",
      "13 85 0.5285898338829116\n",
      "Validation loss: 0.8482057440848577 RMSE: 0.9209808\n",
      "14 30 0.41158260037111954\n",
      "14 80 0.5491593751884094\n",
      "Validation loss: 0.8327942575727191 RMSE: 0.9125756\n",
      "15 25 0.6324165800810833\n",
      "15 75 0.7655298111154685\n",
      "Validation loss: 0.7966992923191616 RMSE: 0.89258015\n",
      "16 20 1.0634930206499402\n",
      "16 70 0.5568290619340913\n",
      "Validation loss: 0.7909509647460211 RMSE: 0.8893542\n",
      "17 15 0.6217447898103441\n",
      "17 65 0.5773752034368412\n",
      "Validation loss: 0.7595566034317016 RMSE: 0.87152547\n",
      "18 10 0.5832770761217266\n",
      "18 60 0.802104834734863\n",
      "Validation loss: 0.7100525245780036 RMSE: 0.8426461\n",
      "19 5 0.48496599161158677\n",
      "19 55 0.7509234392932382\n",
      "Validation loss: 0.6640089310350872 RMSE: 0.81486744\n",
      "20 0 0.5726875990849782\n",
      "20 50 0.42695468727270663\n",
      "20 100 0.5131185580089178\n",
      "Validation loss: 0.7329681683154333 RMSE: 0.8561356\n",
      "21 45 0.3066630130987085\n",
      "21 95 0.4586230640418153\n",
      "Validation loss: 0.6850598284176418 RMSE: 0.82768345\n",
      "22 40 0.4368465185029603\n",
      "22 90 0.5312306610157229\n",
      "Validation loss: 0.7216876450039091 RMSE: 0.84952205\n",
      "23 35 0.5240871899686534\n",
      "23 85 0.4704020816607211\n",
      "Validation loss: 0.7499558925628662 RMSE: 0.866\n",
      "24 30 0.32400310828424117\n",
      "24 80 0.6325177685227685\n",
      "Validation loss: 0.6243528559094383 RMSE: 0.79016\n",
      "25 25 0.3745282434541548\n",
      "25 75 0.35511355111048426\n",
      "Validation loss: 0.6861431553250268 RMSE: 0.8283376\n",
      "26 20 0.794031513262147\n",
      "26 70 0.8331098421543651\n",
      "Validation loss: 0.6753858583314079 RMSE: 0.8218186\n",
      "27 15 0.3487696580728139\n",
      "27 65 0.4922222618104792\n",
      "Validation loss: 0.614058936777569 RMSE: 0.78361905\n",
      "28 10 0.37877038594209217\n",
      "28 60 0.6573328633681076\n",
      "Validation loss: 0.6767449719565255 RMSE: 0.8226451\n",
      "29 5 0.6106661723202337\n",
      "29 55 0.4093582698206794\n",
      "Validation loss: 0.6422035560721443 RMSE: 0.801376\n",
      "30 0 0.7608396891050485\n",
      "30 50 0.7294631503678508\n",
      "30 100 0.6547492941770635\n",
      "Validation loss: 0.5892443861280169 RMSE: 0.76762253\n",
      "31 45 0.37421121733803436\n",
      "31 95 0.7298359078230082\n",
      "Validation loss: 0.6679527125010888 RMSE: 0.81728375\n",
      "32 40 0.5927663778279723\n",
      "32 90 0.6568017006180481\n",
      "Validation loss: 0.6178054105667841 RMSE: 0.786006\n",
      "33 35 0.4694425060000137\n",
      "33 85 0.4842129498697699\n",
      "Validation loss: 0.6363108850660778 RMSE: 0.797691\n",
      "34 30 0.956781474900176\n",
      "34 80 0.5547915236823986\n",
      "Validation loss: 0.6981015665190561 RMSE: 0.8355247\n",
      "35 25 0.5156529581420289\n",
      "35 75 1.0401549515765078\n",
      "Validation loss: 0.6151265564418974 RMSE: 0.7843\n",
      "36 20 0.6466487326681848\n",
      "36 70 0.3834911095896534\n",
      "Validation loss: 0.6644431767009553 RMSE: 0.81513387\n",
      "37 15 0.3713126548099721\n",
      "37 65 0.511358309507678\n",
      "Validation loss: 0.6394629404658363 RMSE: 0.79966426\n",
      "38 10 0.4140379743787687\n",
      "38 60 0.4601503207042786\n",
      "Validation loss: 0.6098744142623175 RMSE: 0.7809446\n",
      "39 5 0.34222064718245787\n",
      "39 55 0.9086596451823226\n",
      "Validation loss: 0.6173797979241326 RMSE: 0.7857352\n",
      "40 0 0.8651553464520652\n",
      "40 50 0.5731080953164723\n",
      "40 100 0.31078237415746024\n",
      "Validation loss: 0.7135719849949791 RMSE: 0.8447319\n",
      "41 45 0.44639451891743553\n",
      "41 95 0.5109229822377241\n",
      "Validation loss: 0.6586557172593617 RMSE: 0.811576\n",
      "42 40 0.5218115424039913\n",
      "42 90 0.27632844491942066\n",
      "Validation loss: 0.600435019958587 RMSE: 0.7748774\n",
      "43 35 0.44610557008681023\n",
      "43 85 0.6031387368858675\n",
      "Validation loss: 0.6025642939976283 RMSE: 0.7762501\n",
      "44 30 0.45699782339618095\n",
      "44 80 0.20178997773162385\n",
      "Validation loss: 0.607034641220456 RMSE: 0.7791243\n",
      "45 25 0.6958803668019613\n",
      "45 75 0.6670238768993323\n",
      "Validation loss: 0.6415043240501768 RMSE: 0.8009397\n",
      "46 20 0.42618960355544677\n",
      "46 70 0.7790349364605387\n",
      "Validation loss: 0.5907713572184244 RMSE: 0.76861656\n",
      "47 15 0.30734978009420577\n",
      "47 65 0.3236586978920282\n",
      "Validation loss: 0.6438539470945086 RMSE: 0.8024051\n",
      "48 10 0.27683264340921837\n",
      "48 60 0.6733444497266601\n",
      "Validation loss: 0.6160462220509847 RMSE: 0.7848862\n",
      "49 5 0.24778408257526205\n",
      "49 55 0.4388096019579205\n",
      "Validation loss: 0.5803694557575952 RMSE: 0.76181984\n",
      "50 0 0.3819804747881725\n",
      "50 50 0.3846883023415033\n",
      "50 100 0.563168130109825\n",
      "Validation loss: 0.5822079102198283 RMSE: 0.7630255\n",
      "51 45 0.3959884089407735\n",
      "51 95 0.35535424633675905\n",
      "Validation loss: 0.6703698010671706 RMSE: 0.8187611\n",
      "52 40 0.2203524026460922\n",
      "52 90 0.5442981432693534\n",
      "Validation loss: 0.5931534945255235 RMSE: 0.7701646\n",
      "53 35 0.43279845556404173\n",
      "53 85 0.4313724720534494\n",
      "Validation loss: 0.5922330055918013 RMSE: 0.7695668\n",
      "54 30 0.4383815239153128\n",
      "54 80 0.4598094669826423\n",
      "Validation loss: 0.5519509837740944 RMSE: 0.74293405\n",
      "55 25 0.17564222026888598\n",
      "55 75 0.3403531219157667\n",
      "Validation loss: 0.6119026229495094 RMSE: 0.78224206\n",
      "56 20 0.5869414823410026\n",
      "56 70 0.3368747654774063\n",
      "Validation loss: 0.598061812491644 RMSE: 0.7733446\n",
      "57 15 0.3439721126100378\n",
      "57 65 0.41750611111264585\n",
      "Validation loss: 0.6046591227962858 RMSE: 0.77759826\n",
      "58 10 0.38823750167456766\n",
      "58 60 0.42550571999273623\n",
      "Validation loss: 0.6142864056995937 RMSE: 0.78376424\n",
      "59 5 0.33799236828093526\n",
      "59 55 0.41147115310018306\n",
      "Validation loss: 0.5666534409636543 RMSE: 0.75276387\n",
      "60 0 0.35681398018575\n",
      "60 50 0.4059197875244781\n",
      "60 100 0.2869217212851242\n",
      "Validation loss: 0.6416717608769734 RMSE: 0.80104417\n",
      "61 45 0.2860149609136898\n",
      "61 95 0.39339762362003217\n",
      "Validation loss: 0.5770678291363376 RMSE: 0.7596498\n",
      "62 40 0.5042792946291933\n",
      "62 90 0.2638080337332814\n",
      "Validation loss: 0.6752959285463606 RMSE: 0.82176393\n",
      "63 35 0.38606093258374347\n",
      "63 85 0.4352154948053054\n",
      "Validation loss: 0.6233015168280829 RMSE: 0.78949445\n",
      "64 30 0.42959893892780393\n",
      "64 80 1.0307778658754485\n",
      "Validation loss: 0.6010766460782005 RMSE: 0.7752913\n",
      "65 25 0.2394239873078797\n",
      "65 75 0.25814703255211374\n",
      "Validation loss: 0.5735234419504801 RMSE: 0.7573133\n",
      "66 20 0.6266157904448224\n",
      "66 70 0.35555489733257584\n",
      "Validation loss: 0.5957223574320475 RMSE: 0.77183056\n",
      "67 15 0.22619680380054843\n",
      "67 65 0.37036057827966024\n",
      "Validation loss: 0.5747532396089463 RMSE: 0.7581248\n",
      "68 10 0.31324167144717846\n",
      "68 60 0.2983134090506944\n",
      "Validation loss: 0.5631855039369492 RMSE: 0.75045687\n",
      "69 5 0.3156586020888385\n",
      "69 55 0.24135466275614276\n",
      "Validation loss: 0.5970756762084507 RMSE: 0.7727067\n",
      "70 0 0.47074471383708405\n",
      "70 50 0.28348862879386133\n",
      "70 100 0.31816423394717447\n",
      "Validation loss: 0.5632772057538941 RMSE: 0.75051796\n",
      "71 45 0.5262780574828316\n",
      "71 95 0.4191799325561053\n",
      "Validation loss: 0.5396595963409969 RMSE: 0.73461527\n",
      "72 40 0.5284945690086057\n",
      "72 90 0.5193850182237477\n",
      "Validation loss: 0.5503377602213905 RMSE: 0.7418476\n",
      "73 35 0.2640279721509278\n",
      "73 85 0.3376343202564028\n",
      "Validation loss: 0.6272071157182966 RMSE: 0.7919641\n",
      "74 30 0.38085526852204826\n",
      "74 80 0.34063241772353836\n",
      "Validation loss: 0.6289239434968857 RMSE: 0.79304725\n",
      "75 25 0.26558808718231897\n",
      "75 75 0.3407517168815605\n",
      "Validation loss: 0.5269708342495418 RMSE: 0.7259276\n",
      "76 20 0.26820766000443447\n",
      "76 70 0.3822216419176156\n",
      "Validation loss: 0.5915444067546299 RMSE: 0.7691192\n",
      "77 15 0.7402162713116479\n",
      "77 65 0.4140919864346986\n",
      "Validation loss: 0.5423273370379493 RMSE: 0.7364288\n",
      "78 10 0.3437706827479513\n",
      "78 60 0.17357011442275275\n",
      "Validation loss: 0.6047027988448029 RMSE: 0.7776264\n",
      "79 5 0.2766317583762762\n",
      "79 55 0.30166669297938487\n",
      "Validation loss: 0.5663528788657416 RMSE: 0.7525642\n",
      "80 0 0.2652382154817173\n",
      "80 50 0.31919153482865054\n",
      "80 100 0.23811294969562094\n",
      "Validation loss: 0.5724582819711594 RMSE: 0.75660974\n",
      "81 45 0.3915663494587572\n",
      "81 95 0.5079035296658915\n",
      "Validation loss: 0.55926395768211 RMSE: 0.7478395\n",
      "82 40 0.3177357640809049\n",
      "82 90 0.4319417295621168\n",
      "Validation loss: 0.5681370468366713 RMSE: 0.75374866\n",
      "83 35 0.4887007603637781\n",
      "83 85 0.43051356766860316\n",
      "Validation loss: 0.6398302679970151 RMSE: 0.7998939\n",
      "84 30 0.2555846847353191\n",
      "84 80 0.29893012145934517\n",
      "Validation loss: 0.6043599196842738 RMSE: 0.7774059\n",
      "85 25 0.33392514703536397\n",
      "85 75 0.29137377282829413\n",
      "Validation loss: 0.619510771547045 RMSE: 0.78709006\n",
      "86 20 0.35178874365002494\n",
      "86 70 0.28725142635627826\n",
      "Validation loss: 0.5262472090267 RMSE: 0.725429\n",
      "87 15 0.4732407725933385\n",
      "87 65 0.15660560847277327\n",
      "Validation loss: 0.6263395041227341 RMSE: 0.7914161\n",
      "88 10 0.20994870489437228\n",
      "88 60 0.328898840383101\n",
      "Validation loss: 0.5331610418501355 RMSE: 0.7301788\n",
      "89 5 0.21044548400661467\n",
      "89 55 0.2608811390341775\n",
      "Validation loss: 0.5495434602101644 RMSE: 0.741312\n",
      "90 0 0.3994299322786532\n",
      "90 50 0.22215046878431138\n",
      "90 100 0.2096238860355895\n",
      "Validation loss: 0.5741696238517762 RMSE: 0.75773984\n",
      "91 45 0.4663536867457639\n",
      "91 95 0.33494856656901\n",
      "Validation loss: 0.5962623502526965 RMSE: 0.77218026\n",
      "92 40 0.31200874098798287\n",
      "92 90 0.28499718416662506\n",
      "Validation loss: 0.5980812887350718 RMSE: 0.77335715\n",
      "93 35 0.49295997888617143\n",
      "93 85 0.3567112705557034\n",
      "Validation loss: 0.5702848933991932 RMSE: 0.7551721\n",
      "94 30 0.19914505976404767\n",
      "94 80 0.24305508262139305\n",
      "Validation loss: 0.5276725803102765 RMSE: 0.7264107\n",
      "95 25 0.13143514130170875\n",
      "95 75 0.3977597983229496\n",
      "Validation loss: 0.5376687367757161 RMSE: 0.733259\n",
      "96 20 0.365432766352349\n",
      "96 70 0.2480242479359307\n",
      "Validation loss: 0.5437367683365232 RMSE: 0.7373851\n",
      "97 15 0.19716676027714275\n",
      "97 65 0.325011465908677\n",
      "Validation loss: 0.5278290328525361 RMSE: 0.7265184\n",
      "98 10 0.24061036204478206\n",
      "98 60 0.3536539537535198\n",
      "Validation loss: 0.533955835160755 RMSE: 0.73072284\n",
      "99 5 0.19501674293727142\n",
      "99 55 0.29820459952827116\n",
      "Validation loss: 0.5325360471560132 RMSE: 0.72975063\n",
      "100 0 0.28809871122257363\n",
      "100 50 0.20917021135415637\n",
      "100 100 0.3013580457249949\n",
      "Validation loss: 0.558261099315825 RMSE: 0.7471687\n",
      "101 45 0.24623117720409338\n",
      "101 95 0.2519424247476529\n",
      "Validation loss: 0.5272052293732052 RMSE: 0.72608894\n",
      "102 40 0.3237938367024402\n",
      "102 90 0.4441229772286538\n",
      "Validation loss: 0.5201372617766971 RMSE: 0.7212054\n",
      "103 35 0.19367121163955578\n",
      "103 85 0.25857562557272795\n",
      "Validation loss: 0.5342527843656995 RMSE: 0.730926\n",
      "104 30 0.2959963855714384\n",
      "104 80 0.36779863649909494\n",
      "Validation loss: 0.5217029514766874 RMSE: 0.7222901\n",
      "105 25 0.28500331192260464\n",
      "105 75 0.22781655055381334\n",
      "Validation loss: 0.5469184177262443 RMSE: 0.7395393\n",
      "106 20 0.2654827418018471\n",
      "106 70 0.33646114194633797\n",
      "Validation loss: 0.5154080765587943 RMSE: 0.7179193\n",
      "107 15 0.2101771657997697\n",
      "107 65 0.28633302979960484\n",
      "Validation loss: 0.5597661489532108 RMSE: 0.7481752\n",
      "108 10 0.2962395166852423\n",
      "108 60 0.2518529534769363\n",
      "Validation loss: 0.5053488527025495 RMSE: 0.7108789\n",
      "109 5 0.24142889044069374\n",
      "109 55 0.2691081188831444\n",
      "Validation loss: 0.5437880967344556 RMSE: 0.7374199\n",
      "110 0 0.1599315168218571\n",
      "110 50 0.16623608939570614\n",
      "110 100 0.2928733553557633\n",
      "Validation loss: 0.5454314563955579 RMSE: 0.7385333\n",
      "111 45 0.19871350970669144\n",
      "111 95 0.48330590854575184\n",
      "Validation loss: 0.5499258912035397 RMSE: 0.7415699\n",
      "112 40 0.26877701295688783\n",
      "112 90 0.19293490945525787\n",
      "Validation loss: 0.5230562706788381 RMSE: 0.7232263\n",
      "113 35 0.2172929786403467\n",
      "113 85 0.2685240337014284\n",
      "Validation loss: 0.5484101482800074 RMSE: 0.74054724\n",
      "114 30 0.23890030636321807\n",
      "114 80 0.193283906302132\n",
      "Validation loss: 0.5209753865287418 RMSE: 0.72178626\n",
      "115 25 0.4681782377095796\n",
      "115 75 0.306811133936542\n",
      "Validation loss: 0.49850923418998716 RMSE: 0.7060519\n",
      "116 20 0.17238175848555576\n",
      "116 70 0.26731395796385626\n",
      "Validation loss: 0.554821698864301 RMSE: 0.74486357\n",
      "117 15 0.28647344927084406\n",
      "117 65 0.3822866058226214\n",
      "Validation loss: 0.5315620453584762 RMSE: 0.729083\n",
      "118 10 0.20825565420487613\n",
      "118 60 0.2716236249414186\n",
      "Validation loss: 0.48859654721759616 RMSE: 0.6989968\n",
      "119 5 0.2522558183922844\n",
      "119 55 0.4018174731783306\n",
      "Validation loss: 0.5276617822192964 RMSE: 0.72640336\n",
      "120 0 0.646391002615973\n",
      "120 50 0.3847125286216007\n",
      "120 100 0.20390122037005204\n",
      "Validation loss: 0.5201670311746143 RMSE: 0.7212261\n",
      "121 45 0.2106951530127625\n",
      "121 95 0.21021363004985608\n",
      "Validation loss: 0.5130271752675374 RMSE: 0.7162591\n",
      "122 40 0.23370042999605828\n",
      "122 90 0.2176859852596076\n",
      "Validation loss: 0.5043741901715596 RMSE: 0.71019304\n",
      "123 35 0.3823928739505802\n",
      "123 85 0.2570287126135853\n",
      "Validation loss: 0.5153563908168248 RMSE: 0.7178832\n",
      "124 30 0.3238253437912174\n",
      "124 80 0.18914635683521613\n",
      "Validation loss: 0.5572745680809021 RMSE: 0.74650824\n",
      "125 25 0.44416858906326906\n",
      "125 75 0.10709434619852636\n",
      "Validation loss: 0.5383450508117675 RMSE: 0.73372\n",
      "126 20 0.1602876476408745\n",
      "126 70 0.21519831676453807\n",
      "Validation loss: 0.49783280406679425 RMSE: 0.70557266\n",
      "127 15 0.1623527932350758\n",
      "127 65 0.47511622996312086\n",
      "Validation loss: 0.5259095770972115 RMSE: 0.7251962\n",
      "128 10 0.21371256995046703\n",
      "128 60 0.2528722919701313\n",
      "Validation loss: 0.5029438529695783 RMSE: 0.70918536\n",
      "129 5 0.1573785570483472\n",
      "129 55 0.33758966228098375\n",
      "Validation loss: 0.5206390840666635 RMSE: 0.7215532\n",
      "130 0 0.324223580811951\n",
      "130 50 0.5225002890015198\n",
      "130 100 0.24698094951846827\n",
      "Validation loss: 0.5148339368048168 RMSE: 0.7175193\n",
      "131 45 0.3158527241998014\n",
      "131 95 0.3058507296874916\n",
      "Validation loss: 0.5078742174875168 RMSE: 0.7126529\n",
      "132 40 0.18684136023711914\n",
      "132 90 0.2233791063204718\n",
      "Validation loss: 0.49559435432865506 RMSE: 0.7039846\n",
      "133 35 0.33234663708878087\n",
      "133 85 0.17430697619139301\n",
      "Validation loss: 0.4833328831763495 RMSE: 0.6952215\n",
      "134 30 0.20533443237229176\n",
      "134 80 0.3051759815132756\n",
      "Validation loss: 0.5003683277538844 RMSE: 0.7073672\n",
      "135 25 0.20619151263593727\n",
      "135 75 0.13464630110867506\n",
      "Validation loss: 0.544925725034305 RMSE: 0.7381909\n",
      "136 20 0.1421446724103178\n",
      "136 70 0.15886532937592548\n",
      "Validation loss: 0.5183120627488409 RMSE: 0.71993893\n",
      "137 15 0.13525997958674854\n",
      "137 65 0.24062543012204535\n",
      "Validation loss: 0.527274819782802 RMSE: 0.7261369\n",
      "138 10 0.3174281577053537\n",
      "138 60 0.20143109305684104\n",
      "Validation loss: 0.5379684246721722 RMSE: 0.7334633\n",
      "139 5 0.1445120325189283\n",
      "139 55 0.33448917382667653\n",
      "Validation loss: 0.507253840139934 RMSE: 0.71221757\n",
      "140 0 0.22291569074520962\n",
      "140 50 0.17875943351980553\n",
      "140 100 0.1747523870889139\n",
      "Validation loss: 0.5247626267728351 RMSE: 0.724405\n",
      "141 45 0.20175805150411252\n",
      "141 95 0.20998790311983218\n",
      "Validation loss: 0.5289288809256895 RMSE: 0.72727495\n",
      "142 40 0.13972831943419808\n",
      "142 90 0.2634165017887856\n",
      "Validation loss: 0.5334762630008516 RMSE: 0.7303946\n",
      "143 35 0.22456979244659356\n",
      "143 85 0.14866647095219446\n",
      "Validation loss: 0.5466655475752694 RMSE: 0.7393683\n",
      "144 30 0.1847901466070679\n",
      "144 80 0.13679705750781446\n",
      "Validation loss: 0.5176048136892772 RMSE: 0.71944755\n",
      "145 25 0.1717626208876414\n",
      "145 75 0.20573140902129095\n",
      "Validation loss: 0.5390754631587438 RMSE: 0.7342176\n",
      "146 20 0.2021612569713058\n",
      "146 70 0.31621459996240775\n",
      "Validation loss: 0.5395203144777388 RMSE: 0.73452044\n",
      "147 15 0.2135623625743466\n",
      "147 65 0.253537878523513\n",
      "Validation loss: 0.5362907500494094 RMSE: 0.7323187\n",
      "148 10 0.19915416570872196\n",
      "148 60 0.1532232430799988\n",
      "Validation loss: 0.4867599714370001 RMSE: 0.69768184\n",
      "149 5 0.1974205229316941\n",
      "149 55 0.2053326727048811\n",
      "Validation loss: 0.5561270455519358 RMSE: 0.7457393\n",
      "150 0 0.1532347826543665\n",
      "150 50 0.19797256818486464\n",
      "150 100 0.23235823680144316\n",
      "Validation loss: 0.5442954597019014 RMSE: 0.7377638\n",
      "151 45 0.1951787363210184\n",
      "151 95 0.15867655920054183\n",
      "Validation loss: 0.5479474186897277 RMSE: 0.7402347\n",
      "152 40 0.18095906883387802\n",
      "152 90 0.2848669654782319\n",
      "Validation loss: 0.4783777814535868 RMSE: 0.6916486\n",
      "153 35 0.17822998838031262\n",
      "153 85 0.21023241990103486\n",
      "Validation loss: 0.5315696057819185 RMSE: 0.7290882\n",
      "154 30 0.23703158438848992\n",
      "154 80 0.159640696596764\n",
      "Validation loss: 0.5295920616104489 RMSE: 0.72773075\n",
      "155 25 0.21956231465239634\n",
      "155 75 0.21763291399688983\n",
      "Validation loss: 0.49860574290865944 RMSE: 0.70612025\n",
      "156 20 0.2312168074673937\n",
      "156 70 0.29343713657402\n",
      "Validation loss: 0.4945199069522676 RMSE: 0.7032211\n",
      "157 15 0.1725522764927988\n",
      "157 65 0.35464128774027953\n",
      "Validation loss: 0.5390335991269066 RMSE: 0.7341891\n",
      "158 10 0.188988111604293\n",
      "158 60 0.22746849891581525\n",
      "Validation loss: 0.5260854352088201 RMSE: 0.7253175\n",
      "159 5 0.1734779672971688\n",
      "159 55 0.20083143100848747\n",
      "Validation loss: 0.5203756091140566 RMSE: 0.72137064\n",
      "160 0 0.13841518500377123\n",
      "160 50 0.27475540330333903\n",
      "160 100 0.15864008419115974\n",
      "Validation loss: 0.5442616729509263 RMSE: 0.73774093\n",
      "161 45 0.19741055378104305\n",
      "161 95 0.3260713443809541\n",
      "Validation loss: 0.5207292448906672 RMSE: 0.72161573\n",
      "162 40 0.14200891765859133\n",
      "162 90 0.23210867096610505\n",
      "Validation loss: 0.5230212115106129 RMSE: 0.72320205\n",
      "163 35 0.1752788093134231\n",
      "163 85 0.1157422869469551\n",
      "Validation loss: 0.5652680573009309 RMSE: 0.7518431\n",
      "164 30 0.12496431126232398\n",
      "164 80 0.3226373441888845\n",
      "Validation loss: 0.49343831042448677 RMSE: 0.70245165\n",
      "165 25 0.27040369539986375\n",
      "165 75 0.20892218555221734\n",
      "Validation loss: 0.5055888959339687 RMSE: 0.7110477\n",
      "166 20 0.18767842015167308\n",
      "166 70 0.1758997702407809\n",
      "Validation loss: 0.5564921150604883 RMSE: 0.745984\n",
      "167 15 0.20475187548125462\n",
      "167 65 0.2378123447789037\n",
      "Validation loss: 0.5323024562426976 RMSE: 0.7295906\n",
      "168 10 0.09816286589465631\n",
      "168 60 0.17668343432325997\n",
      "Validation loss: 0.5123050967852275 RMSE: 0.7157549\n",
      "169 5 0.22431384203059693\n",
      "169 55 0.23804715099477827\n",
      "Validation loss: 0.5229840675989786 RMSE: 0.72317636\n",
      "170 0 0.21453736843840807\n",
      "170 50 0.31599031358542085\n",
      "170 100 0.21784649162218947\n",
      "Validation loss: 0.5011438352721078 RMSE: 0.7079151\n",
      "171 45 0.15510272398552077\n",
      "171 95 0.16532107252323777\n",
      "Validation loss: 0.5438360097862426 RMSE: 0.7374524\n",
      "172 40 0.10438584646761578\n",
      "172 90 0.26441876734353165\n",
      "Validation loss: 0.520611378124782 RMSE: 0.7215341\n",
      "173 35 0.13413562332669338\n",
      "173 85 0.35465420400520203\n",
      "Validation loss: 0.5546664022264026 RMSE: 0.74475926\n",
      "174 30 0.1702816162999762\n",
      "174 80 0.17872502353221162\n",
      "Validation loss: 0.5509344623202369 RMSE: 0.74224955\n",
      "175 25 0.13236173160449827\n",
      "175 75 0.125129350637663\n",
      "Validation loss: 0.5688859542210897 RMSE: 0.7542453\n",
      "176 20 0.1339308032413001\n",
      "176 70 0.20668967289970364\n",
      "Validation loss: 0.5602141618728638 RMSE: 0.74847454\n",
      "177 15 0.15124578626491308\n",
      "177 65 0.15659056787703776\n",
      "Validation loss: 0.516748016788846 RMSE: 0.7188519\n",
      "178 10 0.19872769793881717\n",
      "178 60 0.2078058221523563\n",
      "Validation loss: 0.5308244080770583 RMSE: 0.72857696\n",
      "179 5 0.12916921012852495\n",
      "179 55 0.18938936497881045\n",
      "Validation loss: 0.49564033604803537 RMSE: 0.7040173\n",
      "180 0 0.1574099637355336\n",
      "180 50 0.3160868437782367\n",
      "180 100 0.22048137177421726\n",
      "Validation loss: 0.5327367623647054 RMSE: 0.7298882\n",
      "181 45 0.14488713105511591\n",
      "181 95 0.17934846261487883\n",
      "Validation loss: 0.5409242065889495 RMSE: 0.7354755\n",
      "182 40 0.15482856899198186\n",
      "182 90 0.15700581696930144\n",
      "Validation loss: 0.5077191384065719 RMSE: 0.71254414\n",
      "183 35 0.2604191376495631\n",
      "183 85 0.21079722285794614\n",
      "Validation loss: 0.4876701826140994 RMSE: 0.69833386\n",
      "184 30 0.21275206113152764\n",
      "184 80 0.2404194555769358\n",
      "Validation loss: 0.5123367593401954 RMSE: 0.71577704\n",
      "185 25 0.10800780025800961\n",
      "185 75 0.18483749229978463\n",
      "Validation loss: 0.5099212141264052 RMSE: 0.71408767\n",
      "186 20 0.1652755000702801\n",
      "186 70 0.14385490853468633\n",
      "Validation loss: 0.5542197744051616 RMSE: 0.74445945\n",
      "187 15 0.0903747352054764\n",
      "187 65 0.23735638834339207\n",
      "Validation loss: 0.4865842802183969 RMSE: 0.69755596\n",
      "188 10 0.18084446293831472\n",
      "188 60 0.10844329432478643\n",
      "Validation loss: 0.5027700401487805 RMSE: 0.7090628\n",
      "189 5 0.29115834465737084\n",
      "189 55 0.21330485590840984\n",
      "Validation loss: 0.5351007200422742 RMSE: 0.7315058\n",
      "190 0 0.18694323004648503\n",
      "190 50 0.13678568650247008\n",
      "190 100 0.1114575943164504\n",
      "Validation loss: 0.4979537620430901 RMSE: 0.7056584\n",
      "191 45 0.20008697745211054\n",
      "191 95 0.17983058845296757\n",
      "Validation loss: 0.5318225311381476 RMSE: 0.72926164\n",
      "192 40 0.16060026646831946\n",
      "192 90 0.129395291591771\n",
      "Validation loss: 0.5451978706178211 RMSE: 0.7383752\n",
      "193 35 0.1450335688500699\n",
      "193 85 0.1368008728539757\n",
      "Validation loss: 0.5104939778645833 RMSE: 0.7144886\n",
      "194 30 0.1393943182624197\n",
      "194 80 0.21334263068512102\n",
      "Validation loss: 0.55690576788925 RMSE: 0.7462612\n",
      "195 25 0.16055411460310348\n",
      "195 75 0.25690598948145776\n",
      "Validation loss: 0.5370152382623582 RMSE: 0.73281324\n",
      "196 20 0.17802717811884952\n",
      "196 70 0.08555832804212042\n",
      "Validation loss: 0.5731795268399374 RMSE: 0.7570862\n",
      "197 15 0.1864166247781313\n",
      "197 65 0.17717729955577594\n",
      "Validation loss: 0.5315571489788237 RMSE: 0.72907966\n",
      "198 10 0.1879392102828382\n",
      "198 60 0.19127531038139908\n",
      "Validation loss: 0.5150964907237462 RMSE: 0.7177022\n",
      "199 5 0.1485389946150114\n",
      "199 55 0.14143403059494153\n",
      "Validation loss: 0.5607486702146984 RMSE: 0.74883157\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.5355714054334731 Test RMSE: 0.7318275\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'target': ['exp']}}\n",
      "Running on: cuda:1\n",
      "4199\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/4199\n",
      "Generating scaffold 1000/4199\n",
      "Generating scaffold 2000/4199\n",
      "Generating scaffold 3000/4199\n",
      "Generating scaffold 4000/4199\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 7.066689795973723\n",
      "0 50 1.3671028049836196\n",
      "0 100 1.5875233224178342\n",
      "Validation loss: 1.3477161117962428 RMSE: 1.1609118\n",
      "1 45 0.8514225141874396\n",
      "1 95 0.9018327100799831\n",
      "Validation loss: 1.0693455389567783 RMSE: 1.0340916\n",
      "2 40 0.9521456316002763\n",
      "2 90 1.037136933591164\n",
      "Validation loss: 0.9646894057591756 RMSE: 0.982186\n",
      "3 35 1.8200004455918415\n",
      "3 85 0.7281317360371697\n",
      "Validation loss: 0.9623078192983355 RMSE: 0.98097295\n",
      "4 30 0.6421406242933214\n",
      "4 80 1.0464354442881476\n",
      "Validation loss: 1.0925505887894404 RMSE: 1.0452515\n",
      "5 25 0.7541057837557599\n",
      "5 75 0.5283209997372019\n",
      "Validation loss: 0.9560944023586455 RMSE: 0.9778008\n",
      "6 20 0.801124981204957\n",
      "6 70 0.4910907328942307\n",
      "Validation loss: 0.9134618446940468 RMSE: 0.955752\n",
      "7 15 0.42821699487809395\n",
      "7 65 1.0857605866394415\n",
      "Validation loss: 0.8179464482125782 RMSE: 0.9044039\n",
      "8 10 0.7078363416576552\n",
      "8 60 0.6090518371174347\n",
      "Validation loss: 1.0417033195495606 RMSE: 1.0206387\n",
      "9 5 0.7961276517231116\n",
      "9 55 0.6593520580843683\n",
      "Validation loss: 0.798780333995819 RMSE: 0.8937451\n",
      "10 0 0.4968582850173719\n",
      "10 50 0.6173470894622981\n",
      "10 100 0.7059937152092757\n",
      "Validation loss: 0.8278586745262146 RMSE: 0.90986735\n",
      "11 45 0.8090372001928585\n",
      "11 95 0.5503971727988181\n",
      "Validation loss: 0.8532270526602155 RMSE: 0.9237029\n",
      "12 40 0.4997569847245983\n",
      "12 90 0.5370028319955595\n",
      "Validation loss: 0.6883739420345851 RMSE: 0.82968307\n",
      "13 35 0.5897608683288472\n",
      "13 85 0.7576103069892002\n",
      "Validation loss: 0.763254273505438 RMSE: 0.87364423\n",
      "14 30 0.5724211980121358\n",
      "14 80 0.33984153330572775\n",
      "Validation loss: 0.7498547395070394 RMSE: 0.8659415\n",
      "15 25 0.4288972418115929\n",
      "15 75 1.0460733810741336\n",
      "Validation loss: 0.7283344336918423 RMSE: 0.8534251\n",
      "16 20 0.8034747706311787\n",
      "16 70 0.5174743276850915\n",
      "Validation loss: 0.6622214887823378 RMSE: 0.8137699\n",
      "17 15 0.742593234790702\n",
      "17 65 0.6543128917908807\n",
      "Validation loss: 0.759473230725243 RMSE: 0.8714776\n",
      "18 10 0.693847125489361\n",
      "18 60 0.522352170704053\n",
      "Validation loss: 0.7829127924782889 RMSE: 0.8848236\n",
      "19 5 0.39713369873135257\n",
      "19 55 0.9307916652870534\n",
      "Validation loss: 0.6599964794658479 RMSE: 0.81240165\n",
      "20 0 0.4568871509056561\n",
      "20 50 0.5170307293475702\n",
      "20 100 0.668240663583994\n",
      "Validation loss: 0.7316279303459894 RMSE: 0.85535246\n",
      "21 45 0.621049304716415\n",
      "21 95 0.6726799760281016\n",
      "Validation loss: 0.7771427608671643 RMSE: 0.881557\n",
      "22 40 0.4651121647255555\n",
      "22 90 0.3976054741202745\n",
      "Validation loss: 0.6792059835933504 RMSE: 0.8241396\n",
      "23 35 0.8862156961501171\n",
      "23 85 0.604923906368219\n",
      "Validation loss: 0.7474687167576382 RMSE: 0.86456275\n",
      "24 30 0.3610842131394957\n",
      "24 80 0.48113810221285375\n",
      "Validation loss: 0.8206508835156758 RMSE: 0.90589786\n",
      "25 25 0.5437528227604373\n",
      "25 75 0.6164560496059864\n",
      "Validation loss: 0.6701806366443634 RMSE: 0.81864566\n",
      "26 20 0.501878853431956\n",
      "26 70 1.0587936425734605\n",
      "Validation loss: 0.7346652632667905 RMSE: 0.8571262\n",
      "27 15 0.31092337135837916\n",
      "27 65 0.32244900828690476\n",
      "Validation loss: 0.7255639870961507 RMSE: 0.85180044\n",
      "28 10 0.6646746668693375\n",
      "28 60 0.6467766781735691\n",
      "Validation loss: 0.6616752874283564 RMSE: 0.81343424\n",
      "29 5 0.5034564902978143\n",
      "29 55 0.8042877046302617\n",
      "Validation loss: 0.6465298564661117 RMSE: 0.80407083\n",
      "30 0 0.4838717824769321\n",
      "30 50 0.515192848905579\n",
      "30 100 0.37469015993502464\n",
      "Validation loss: 0.601435733409155 RMSE: 0.7755229\n",
      "31 45 0.5117443136631874\n",
      "31 95 0.613826334506229\n",
      "Validation loss: 0.7924926905404954 RMSE: 0.8902206\n",
      "32 40 0.3433854703789086\n",
      "32 90 0.4739692018759269\n",
      "Validation loss: 0.6215093442371913 RMSE: 0.7883586\n",
      "33 35 0.558272175452124\n",
      "33 85 0.6328146344592754\n",
      "Validation loss: 0.6420468546095348 RMSE: 0.80127823\n",
      "34 30 0.7397512213375945\n",
      "34 80 0.5350340765115839\n",
      "Validation loss: 0.6664925126802353 RMSE: 0.8163899\n",
      "35 25 0.5428776241989101\n",
      "35 75 0.3978019838019387\n",
      "Validation loss: 0.6246505825292497 RMSE: 0.7903484\n",
      "36 20 0.41603778523796886\n",
      "36 70 0.6542201788730552\n",
      "Validation loss: 0.5920822237219129 RMSE: 0.7694688\n",
      "37 15 0.5984384590104822\n",
      "37 65 0.34466363776850023\n",
      "Validation loss: 0.6676772662571498 RMSE: 0.8171152\n",
      "38 10 0.41797912403082504\n",
      "38 60 0.4465237798283158\n",
      "Validation loss: 0.7160478557859148 RMSE: 0.8461961\n",
      "39 5 0.25885270002673755\n",
      "39 55 0.413290567127754\n",
      "Validation loss: 0.6075619697570801 RMSE: 0.7794626\n",
      "40 0 0.29846335769295274\n",
      "40 50 0.2943184467626603\n",
      "40 100 0.4290814735359209\n",
      "Validation loss: 0.7281968184879848 RMSE: 0.8533445\n",
      "41 45 0.44300068937198916\n",
      "41 95 0.25515949068714694\n",
      "Validation loss: 0.6114684976282574 RMSE: 0.7819645\n",
      "42 40 0.47853685395533085\n",
      "42 90 0.23046267879317253\n",
      "Validation loss: 0.5987101702463059 RMSE: 0.77376366\n",
      "43 35 0.443221515884661\n",
      "43 85 0.3826925618240186\n",
      "Validation loss: 0.5970898639588129 RMSE: 0.7727159\n",
      "44 30 0.5212111065009642\n",
      "44 80 0.36926261871976107\n",
      "Validation loss: 0.6465333206312996 RMSE: 0.804073\n",
      "45 25 0.4699147017098769\n",
      "45 75 0.4901286245626111\n",
      "Validation loss: 0.5964645561717805 RMSE: 0.77231115\n",
      "46 20 0.8100871964354619\n",
      "46 70 0.4985687515512296\n",
      "Validation loss: 0.5987364140294847 RMSE: 0.7737806\n",
      "47 15 0.44384086940495576\n",
      "47 65 0.3297098852039776\n",
      "Validation loss: 0.6817380118937719 RMSE: 0.8256743\n",
      "48 10 0.43224122790122727\n",
      "48 60 0.43201471028847416\n",
      "Validation loss: 0.5676433411382493 RMSE: 0.75342107\n",
      "49 5 0.7075785150272044\n",
      "49 55 0.20742730746740315\n",
      "Validation loss: 0.5581869891711644 RMSE: 0.7471191\n",
      "50 0 0.6057972495080503\n",
      "50 50 0.30286424716029947\n",
      "50 100 0.37107883638839817\n",
      "Validation loss: 0.6141385047208695 RMSE: 0.7836699\n",
      "51 45 0.4735696798371417\n",
      "51 95 0.7018732051859793\n",
      "Validation loss: 0.5950104338782174 RMSE: 0.7713692\n",
      "52 40 0.39746430737835814\n",
      "52 90 0.37582968983155907\n",
      "Validation loss: 0.5789152065912883 RMSE: 0.7608648\n",
      "53 35 0.32450980261654083\n",
      "53 85 0.2700630197770873\n",
      "Validation loss: 0.5752438125156221 RMSE: 0.75844824\n",
      "54 30 0.32206107518582733\n",
      "54 80 0.44018710546073714\n",
      "Validation loss: 0.6320934251660393 RMSE: 0.79504305\n",
      "55 25 0.48043992663490154\n",
      "55 75 0.3753009809016288\n",
      "Validation loss: 0.6325404076349168 RMSE: 0.7953241\n",
      "56 20 0.3848431983121832\n",
      "56 70 0.3191914373655758\n",
      "Validation loss: 0.5858739086559841 RMSE: 0.765424\n",
      "57 15 0.5873471077383803\n",
      "57 65 0.40270357011137425\n",
      "Validation loss: 0.5918554527418954 RMSE: 0.76932144\n",
      "58 10 0.3293322563111608\n",
      "58 60 0.29276138423234066\n",
      "Validation loss: 0.5185518576985314 RMSE: 0.7201054\n",
      "59 5 0.3776508379378357\n",
      "59 55 0.3226767539733904\n",
      "Validation loss: 0.5987089405457179 RMSE: 0.7737629\n",
      "60 0 0.33140550882053976\n",
      "60 50 0.3336576425451386\n",
      "60 100 0.3680201863752313\n",
      "Validation loss: 0.5522397685618627 RMSE: 0.74312836\n",
      "61 45 0.4418104091554037\n",
      "61 95 0.21150278124797958\n",
      "Validation loss: 0.5689462346690042 RMSE: 0.7542853\n",
      "62 40 0.3456990147252268\n",
      "62 90 0.2950234289261018\n",
      "Validation loss: 0.5910202446438018 RMSE: 0.76877844\n",
      "63 35 0.187326021247396\n",
      "63 85 0.2880562682622651\n",
      "Validation loss: 0.5536245050884429 RMSE: 0.7440595\n",
      "64 30 0.3061536599316051\n",
      "64 80 0.7242137721216103\n",
      "Validation loss: 0.5701041732515607 RMSE: 0.75505245\n",
      "65 25 0.33381912937062547\n",
      "65 75 0.2619851753829169\n",
      "Validation loss: 0.5514879924910409 RMSE: 0.7426224\n",
      "66 20 0.2692317805023857\n",
      "66 70 0.42189811872781324\n",
      "Validation loss: 0.5916044859659104 RMSE: 0.7691583\n",
      "67 15 0.3405659042516768\n",
      "67 65 0.449437266550834\n",
      "Validation loss: 0.4956136697814578 RMSE: 0.7039984\n",
      "68 10 0.25641000510101\n",
      "68 60 0.4328354457288944\n",
      "Validation loss: 0.5291697683788481 RMSE: 0.7274406\n",
      "69 5 0.2963692930172349\n",
      "69 55 0.4807588627570398\n",
      "Validation loss: 0.5357471244675772 RMSE: 0.7319475\n",
      "70 0 0.30093545949228945\n",
      "70 50 0.5878765127699582\n",
      "70 100 0.4023924829842751\n",
      "Validation loss: 0.5592533384050642 RMSE: 0.7478325\n",
      "71 45 0.33952652572177494\n",
      "71 95 0.4817361139087613\n",
      "Validation loss: 0.527055697781699 RMSE: 0.72598606\n",
      "72 40 0.5227326257816259\n",
      "72 90 0.344837153578207\n",
      "Validation loss: 0.5159205817040943 RMSE: 0.71827614\n",
      "73 35 0.3241593664230348\n",
      "73 85 0.27189171770140597\n",
      "Validation loss: 0.543730389220374 RMSE: 0.73738074\n",
      "74 30 0.2800019097274413\n",
      "74 80 0.25970995448986217\n",
      "Validation loss: 0.5191647382009597 RMSE: 0.72053087\n",
      "75 25 0.27462142400034784\n",
      "75 75 0.25499754230436816\n",
      "Validation loss: 0.550681015423366 RMSE: 0.74207884\n",
      "76 20 0.2878503916397257\n",
      "76 70 0.25878070083634097\n",
      "Validation loss: 0.5358682175477346 RMSE: 0.7320302\n",
      "77 15 0.4414765391735178\n",
      "77 65 0.2929518807567329\n",
      "Validation loss: 0.5424685376031059 RMSE: 0.7365246\n",
      "78 10 0.4584302457966555\n",
      "78 60 0.4286751672810883\n",
      "Validation loss: 0.5103293827601841 RMSE: 0.71437335\n",
      "79 5 0.5265464179211007\n",
      "79 55 0.39733154267505266\n",
      "Validation loss: 0.5313997942776907 RMSE: 0.7289718\n",
      "80 0 0.3340444309757239\n",
      "80 50 0.24422195648475561\n",
      "80 100 0.23947819965046183\n",
      "Validation loss: 0.521737323488508 RMSE: 0.7223139\n",
      "81 45 0.2803400723679201\n",
      "81 95 0.287739628412731\n",
      "Validation loss: 0.5799176233155386 RMSE: 0.7615232\n",
      "82 40 0.2658749763676482\n",
      "82 90 0.2711231233206538\n",
      "Validation loss: 0.5593107910383315 RMSE: 0.74787086\n",
      "83 35 0.3031473069474519\n",
      "83 85 0.22345624079366788\n",
      "Validation loss: 0.5788824993939626 RMSE: 0.7608433\n",
      "84 30 0.26224881589841\n",
      "84 80 0.31530293333781595\n",
      "Validation loss: 0.5722140049650556 RMSE: 0.75644827\n",
      "85 25 0.3650848937248927\n",
      "85 75 0.191932781936279\n",
      "Validation loss: 0.5186287215777806 RMSE: 0.7201588\n",
      "86 20 0.20119983127494198\n",
      "86 70 0.34536308330028315\n",
      "Validation loss: 0.5192478668122065 RMSE: 0.72058856\n",
      "87 15 0.2549606382839926\n",
      "87 65 0.2163667701769783\n",
      "Validation loss: 0.4997208527156285 RMSE: 0.70690936\n",
      "88 10 0.2227233954779692\n",
      "88 60 0.41751768876824774\n",
      "Validation loss: 0.5340957051231747 RMSE: 0.7308185\n",
      "89 5 0.16938286933110241\n",
      "89 55 0.24132992099894457\n",
      "Validation loss: 0.5157666081473941 RMSE: 0.7181689\n",
      "90 0 0.18274994144040116\n",
      "90 50 0.37673468680616623\n",
      "90 100 0.18540155692632654\n",
      "Validation loss: 0.5456074944564274 RMSE: 0.73865247\n",
      "91 45 0.17520428991861833\n",
      "91 95 0.29368594498822953\n",
      "Validation loss: 0.5674953860895974 RMSE: 0.75332296\n",
      "92 40 0.25275380785119417\n",
      "92 90 0.23303929432084428\n",
      "Validation loss: 0.5161657926582155 RMSE: 0.71844685\n",
      "93 35 0.25347568454697295\n",
      "93 85 0.2620399418559129\n",
      "Validation loss: 0.5160193817956107 RMSE: 0.71834487\n",
      "94 30 0.27506183281941465\n",
      "94 80 0.23772622804171728\n",
      "Validation loss: 0.515839546918869 RMSE: 0.71821976\n",
      "95 25 0.4308589140210263\n",
      "95 75 0.2052848357926883\n",
      "Validation loss: 0.5557280716441927 RMSE: 0.7454717\n",
      "96 20 0.24865003345879924\n",
      "96 70 0.21585275500788587\n",
      "Validation loss: 0.5250533621935617 RMSE: 0.7246057\n",
      "97 15 0.3359982294033186\n",
      "97 65 0.4153855497098064\n",
      "Validation loss: 0.5544640279951549 RMSE: 0.7446234\n",
      "98 10 0.16504965471978147\n",
      "98 60 0.2914015916971185\n",
      "Validation loss: 0.5273950213477725 RMSE: 0.72621965\n",
      "99 5 0.18201934118925817\n",
      "99 55 0.20271075471447503\n",
      "Validation loss: 0.526348849989119 RMSE: 0.72549903\n",
      "100 0 0.26314041160535423\n",
      "100 50 0.2668690533113916\n",
      "100 100 0.6266288106321333\n",
      "Validation loss: 0.5247147395497277 RMSE: 0.72437197\n",
      "101 45 0.4302192252948622\n",
      "101 95 0.3022110746275006\n",
      "Validation loss: 0.5090781384990328 RMSE: 0.7134971\n",
      "102 40 0.5145473068863226\n",
      "102 90 0.28503624811388406\n",
      "Validation loss: 0.5483996215320769 RMSE: 0.7405401\n",
      "103 35 0.18438097732233852\n",
      "103 85 0.2570035109147327\n",
      "Validation loss: 0.5690011924221402 RMSE: 0.7543217\n",
      "104 30 0.27823820287581674\n",
      "104 80 0.36699219282595297\n",
      "Validation loss: 0.5420888352961767 RMSE: 0.7362668\n",
      "105 25 0.45408023612069065\n",
      "105 75 0.3288138983073297\n",
      "Validation loss: 0.5678986735996746 RMSE: 0.7535905\n",
      "106 20 0.2772202836093576\n",
      "106 70 0.42922443809994837\n",
      "Validation loss: 0.5008107310249692 RMSE: 0.7076798\n",
      "107 15 0.19344069767876507\n",
      "107 65 0.3173183404132717\n",
      "Validation loss: 0.5158657494045439 RMSE: 0.71823794\n",
      "108 10 0.4877814664882099\n",
      "108 60 0.19400587851810933\n",
      "Validation loss: 0.5863246446564084 RMSE: 0.7657184\n",
      "109 5 0.1684135531983409\n",
      "109 55 0.21485281572628778\n",
      "Validation loss: 0.5349087709472293 RMSE: 0.7313746\n",
      "110 0 0.1908484931267308\n",
      "110 50 0.16192783802710115\n",
      "110 100 0.33603232842460157\n",
      "Validation loss: 0.5241688711302621 RMSE: 0.7239951\n",
      "111 45 0.24633235140977897\n",
      "111 95 0.2392300974843297\n",
      "Validation loss: 0.5319455328441801 RMSE: 0.729346\n",
      "112 40 0.18507157298512922\n",
      "112 90 0.3914086386936799\n",
      "Validation loss: 0.5774855922375407 RMSE: 0.7599247\n",
      "113 35 0.318160512783611\n",
      "113 85 0.22654214334240014\n",
      "Validation loss: 0.5574131420680455 RMSE: 0.74660105\n",
      "114 30 0.3327762373214718\n",
      "114 80 0.2764830608588576\n",
      "Validation loss: 0.5218126291320437 RMSE: 0.72236603\n",
      "115 25 0.20193989389406108\n",
      "115 75 0.21928256709893254\n",
      "Validation loss: 0.5358149471737089 RMSE: 0.7319938\n",
      "116 20 0.3140133754412021\n",
      "116 70 0.1973532348249494\n",
      "Validation loss: 0.5591207806553159 RMSE: 0.7477438\n",
      "117 15 0.1371361051738709\n",
      "117 65 0.2790926785934633\n",
      "Validation loss: 0.5534948672567095 RMSE: 0.74397236\n",
      "118 10 0.3064547140015342\n",
      "118 60 0.27053094727779753\n",
      "Validation loss: 0.5497209943476178 RMSE: 0.7414317\n",
      "119 5 0.14226853304075954\n",
      "119 55 0.28232457430388086\n",
      "Validation loss: 0.56323748032252 RMSE: 0.75049156\n",
      "120 0 0.22740265565432677\n",
      "120 50 0.2773484004720045\n",
      "120 100 0.25629319898304526\n",
      "Validation loss: 0.5438248293740409 RMSE: 0.7374448\n",
      "121 45 0.24741048384782216\n",
      "121 95 0.2292876346508576\n",
      "Validation loss: 0.5170345476695469 RMSE: 0.7190511\n",
      "122 40 0.3046088335044199\n",
      "122 90 0.3590518221688521\n",
      "Validation loss: 0.5700961220832098 RMSE: 0.75504714\n",
      "123 35 0.19610571675051242\n",
      "123 85 0.5921891136282497\n",
      "Validation loss: 0.551712201322828 RMSE: 0.74277335\n",
      "124 30 0.19320997157898903\n",
      "124 80 0.24342427398297664\n",
      "Validation loss: 0.5388485136486235 RMSE: 0.734063\n",
      "125 25 0.3145127977674648\n",
      "125 75 0.25097366871675625\n",
      "Validation loss: 0.5454462254331225 RMSE: 0.73854333\n",
      "126 20 0.286207640175848\n",
      "126 70 0.26816029775387445\n",
      "Validation loss: 0.5100133234546298 RMSE: 0.71415216\n",
      "127 15 0.2551650992372127\n",
      "127 65 0.43425159011669084\n",
      "Validation loss: 0.5319260651866595 RMSE: 0.7293326\n",
      "128 10 0.2681680879669124\n",
      "128 60 0.15523949877943086\n",
      "Validation loss: 0.5749413899012974 RMSE: 0.75824887\n",
      "129 5 0.2271944016833523\n",
      "129 55 0.2675197533100589\n",
      "Validation loss: 0.5344895933355603 RMSE: 0.7310879\n",
      "130 0 0.27287997505349804\n",
      "130 50 0.2595978623457612\n",
      "130 100 0.22152624199952914\n",
      "Validation loss: 0.5559009614444914 RMSE: 0.7455877\n",
      "131 45 0.19610192546804914\n",
      "131 95 0.3348285448978409\n",
      "Validation loss: 0.5727789126691364 RMSE: 0.7568216\n",
      "132 40 0.1803575957782413\n",
      "132 90 0.2533303888323645\n",
      "Validation loss: 0.5710629429136004 RMSE: 0.75568706\n",
      "133 35 0.2660477365926779\n",
      "133 85 0.2451885283794633\n",
      "Validation loss: 0.5412886528741746 RMSE: 0.73572326\n",
      "134 30 0.2361304333190269\n",
      "134 80 0.19064757644933678\n",
      "Validation loss: 0.5479773579608826 RMSE: 0.7402549\n",
      "135 25 0.23614364626901865\n",
      "135 75 0.3231803907381791\n",
      "Validation loss: 0.538867978254954 RMSE: 0.73407626\n",
      "136 20 0.22522239356160462\n",
      "136 70 0.15705753495208893\n",
      "Validation loss: 0.5609704908870515 RMSE: 0.7489796\n",
      "137 15 0.2362902963686198\n",
      "137 65 0.4282734814405432\n",
      "Validation loss: 0.5547285307021368 RMSE: 0.74480104\n",
      "138 10 0.21755441221754684\n",
      "138 60 0.18371533852960317\n",
      "Validation loss: 0.523822063491458 RMSE: 0.7237555\n",
      "139 5 0.2402817425452949\n",
      "139 55 0.25054164512318533\n",
      "Validation loss: 0.509246513957069 RMSE: 0.7136151\n",
      "140 0 0.2305462672821901\n",
      "140 50 0.1464622448578533\n",
      "140 100 0.18341988133054743\n",
      "Validation loss: 0.5479446853910174 RMSE: 0.7402329\n",
      "141 45 0.1926822911053999\n",
      "141 95 0.16918221031769862\n",
      "Validation loss: 0.4965609238261268 RMSE: 0.7046708\n",
      "142 40 0.24224663706078536\n",
      "142 90 0.21368163396414444\n",
      "Validation loss: 0.5181164128439767 RMSE: 0.71980304\n",
      "143 35 0.13497175615064988\n",
      "143 85 0.24845663132570878\n",
      "Validation loss: 0.5445491688592093 RMSE: 0.7379358\n",
      "144 30 0.16429966422297368\n",
      "144 80 0.23835239096718058\n",
      "Validation loss: 0.5410799213818142 RMSE: 0.73558134\n",
      "145 25 0.16254218717265406\n",
      "145 75 0.13730995105095214\n",
      "Validation loss: 0.551070307691892 RMSE: 0.7423411\n",
      "146 20 0.14860778880012807\n",
      "146 70 0.2979548967557666\n",
      "Validation loss: 0.5464089082110496 RMSE: 0.73919475\n",
      "147 15 0.16379022791072995\n",
      "147 65 0.12240079990794872\n",
      "Validation loss: 0.5405146366073972 RMSE: 0.735197\n",
      "148 10 0.2805047635776498\n",
      "148 60 0.3221644084409214\n",
      "Validation loss: 0.5511421893324171 RMSE: 0.74238956\n",
      "149 5 0.20293190616414045\n",
      "149 55 0.16309595425428217\n",
      "Validation loss: 0.5492554289954049 RMSE: 0.7411177\n",
      "150 0 0.18279704144370582\n",
      "150 50 0.3424036638224778\n",
      "150 100 0.20177633912998624\n",
      "Validation loss: 0.504518513452439 RMSE: 0.71029466\n",
      "151 45 0.1290771015621256\n",
      "151 95 0.17454237242594084\n",
      "Validation loss: 0.5416830281416575 RMSE: 0.7359912\n",
      "152 40 0.18701842079975675\n",
      "152 90 0.12505032495958313\n",
      "Validation loss: 0.58272972263041 RMSE: 0.76336735\n",
      "153 35 0.31151550234848296\n",
      "153 85 0.34248557178479094\n",
      "Validation loss: 0.5866393849963234 RMSE: 0.76592386\n",
      "154 30 0.24925370369260763\n",
      "154 80 0.21977873903358658\n",
      "Validation loss: 0.5305383778753735 RMSE: 0.7283807\n",
      "155 25 0.2985671110960265\n",
      "155 75 0.1576714334690639\n",
      "Validation loss: 0.5275859001136961 RMSE: 0.7263511\n",
      "156 20 0.17955838455969358\n",
      "156 70 0.1326924175422867\n",
      "Validation loss: 0.5135908277261825 RMSE: 0.7166525\n",
      "157 15 0.3421852876803043\n",
      "157 65 0.2922430270069986\n",
      "Validation loss: 0.5521244281814212 RMSE: 0.74305075\n",
      "158 10 0.17983731600265979\n",
      "158 60 0.2114968216739197\n",
      "Validation loss: 0.5428302943706512 RMSE: 0.73677015\n",
      "159 5 0.19980639333369235\n",
      "159 55 0.1435239888366086\n",
      "Validation loss: 0.5967463254928589 RMSE: 0.7724936\n",
      "160 0 0.18319755014221487\n",
      "160 50 0.12221573996139842\n",
      "160 100 0.45293393973551005\n",
      "Validation loss: 0.5724012442997524 RMSE: 0.756572\n",
      "161 45 0.15995956630690386\n",
      "161 95 0.22975696325818223\n",
      "Validation loss: 0.5219930671510242 RMSE: 0.7224909\n",
      "162 40 0.2767554328468904\n",
      "162 90 0.29638219185651354\n",
      "Validation loss: 0.5364948289734977 RMSE: 0.73245806\n",
      "163 35 0.17923427451365126\n",
      "163 85 0.32985219363327745\n",
      "Validation loss: 0.5328363639967783 RMSE: 0.7299564\n",
      "164 30 0.2305125454980232\n",
      "164 80 0.17523104792365307\n",
      "Validation loss: 0.5582163844789777 RMSE: 0.7471388\n",
      "165 25 0.14869443167686383\n",
      "165 75 0.21609827327429393\n",
      "Validation loss: 0.5622467415673392 RMSE: 0.7498312\n",
      "166 20 0.189414179859323\n",
      "166 70 0.18082840409937304\n",
      "Validation loss: 0.5594193702652341 RMSE: 0.7479434\n",
      "167 15 0.1587262587783599\n",
      "167 65 0.20154108141475724\n",
      "Validation loss: 0.5781350039300465 RMSE: 0.7603519\n",
      "168 10 0.15265333578550414\n",
      "168 60 0.34625729340640354\n",
      "Validation loss: 0.5336121986309688 RMSE: 0.73048764\n",
      "169 5 0.47243489727934396\n",
      "169 55 0.16557220488700475\n",
      "Validation loss: 0.5751166298275903 RMSE: 0.75836444\n",
      "170 0 0.4807496261118039\n",
      "170 50 0.15790508920454224\n",
      "170 100 0.14617711897802974\n",
      "Validation loss: 0.5448063112440563 RMSE: 0.7381099\n",
      "171 45 0.11297909206808285\n",
      "171 95 0.12205081829835951\n",
      "Validation loss: 0.5146748071625119 RMSE: 0.7174084\n",
      "172 40 0.29323368205857153\n",
      "172 90 0.2043090333031134\n",
      "Validation loss: 0.5137699308849516 RMSE: 0.71677744\n",
      "173 35 0.18472945384627104\n",
      "173 85 0.1479419411387174\n",
      "Validation loss: 0.5120904945191883 RMSE: 0.715605\n",
      "174 30 0.18106905020525474\n",
      "174 80 0.1488022900079526\n",
      "Validation loss: 0.5219666231246222 RMSE: 0.7224726\n",
      "175 25 0.12282741892135762\n",
      "175 75 0.10516763083188956\n",
      "Validation loss: 0.49613000665392193 RMSE: 0.70436496\n",
      "176 20 0.2240851643424196\n",
      "176 70 0.27881294498003795\n",
      "Validation loss: 0.5234866585050311 RMSE: 0.7235238\n",
      "177 15 0.12147278716116786\n",
      "177 65 0.14037611838750805\n",
      "Validation loss: 0.49919958540371484 RMSE: 0.7065406\n",
      "178 10 0.27169759111432806\n",
      "178 60 0.2182832993416531\n",
      "Validation loss: 0.5124457935492198 RMSE: 0.7158532\n",
      "179 5 0.2637994501478862\n",
      "179 55 0.18400304331706463\n",
      "Validation loss: 0.5122724785691216 RMSE: 0.7157321\n",
      "180 0 0.1612831139499834\n",
      "180 50 0.1446576825204278\n",
      "180 100 0.1471422386379646\n",
      "Validation loss: 0.495365309715271 RMSE: 0.70382196\n",
      "181 45 0.20246685104664416\n",
      "181 95 0.15796283063017677\n",
      "Validation loss: 0.5354371666908264 RMSE: 0.7317357\n",
      "182 40 0.16487968338003348\n",
      "182 90 0.30927245899476147\n",
      "Validation loss: 0.5302326395398095 RMSE: 0.72817075\n",
      "183 35 0.15445429356727866\n",
      "183 85 0.16628213818787452\n",
      "Validation loss: 0.5335054485570817 RMSE: 0.7304146\n",
      "184 30 0.2084637997637508\n",
      "184 80 0.22853285233738366\n",
      "Validation loss: 0.5400651069624084 RMSE: 0.7348912\n",
      "185 25 0.1426734244951528\n",
      "185 75 0.20635919861883292\n",
      "Validation loss: 0.5006940762201945 RMSE: 0.70759743\n",
      "186 20 0.2307492868162693\n",
      "186 70 0.17863467624219337\n",
      "Validation loss: 0.5301965094747998 RMSE: 0.7281459\n",
      "187 15 0.18340498656031134\n",
      "187 65 0.1534679030943653\n",
      "Validation loss: 0.5158191411268144 RMSE: 0.7182055\n",
      "188 10 0.20334505915936785\n",
      "188 60 0.16025235353695547\n",
      "Validation loss: 0.5442947620437258 RMSE: 0.73776335\n",
      "189 5 0.1620550606848434\n",
      "189 55 0.15092390962317703\n",
      "Validation loss: 0.5147936324278514 RMSE: 0.7174912\n",
      "190 0 0.23882873754289138\n",
      "190 50 0.3081842321302022\n",
      "190 100 0.13270862997576593\n",
      "Validation loss: 0.5205257200059437 RMSE: 0.7214747\n",
      "191 45 0.16538208523233\n",
      "191 95 0.16674486004097716\n",
      "Validation loss: 0.5365974491550809 RMSE: 0.7325281\n",
      "192 40 0.28627702285792594\n",
      "192 90 0.08770998179960773\n",
      "Validation loss: 0.517775619597662 RMSE: 0.7195662\n",
      "193 35 0.1918880315481633\n",
      "193 85 0.16332765348285966\n",
      "Validation loss: 0.5249081813863345 RMSE: 0.7245055\n",
      "194 30 0.16021875002524935\n",
      "194 80 0.12725348526525598\n",
      "Validation loss: 0.5266163292385283 RMSE: 0.72568333\n",
      "195 25 0.14035929709307438\n",
      "195 75 0.15798468893926151\n",
      "Validation loss: 0.5008135290372939 RMSE: 0.7076818\n",
      "196 20 0.19567596660964148\n",
      "196 70 0.19810904503479698\n",
      "Validation loss: 0.5216838155473982 RMSE: 0.7222768\n",
      "197 15 0.15094586658521167\n",
      "197 65 0.18159492537723537\n",
      "Validation loss: 0.5122854743685041 RMSE: 0.7157412\n",
      "198 10 0.1620502860427244\n",
      "198 60 0.22851836014462515\n",
      "Validation loss: 0.5454958745411465 RMSE: 0.73857695\n",
      "199 5 0.17529674597675868\n",
      "199 55 0.14985099118894044\n",
      "Validation loss: 0.5318344894974004 RMSE: 0.7292698\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.5776914011864435 Test RMSE: 0.76006013\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'qm7', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'regression', 'data_path': 'data/qm7/qm7.csv', 'target': ['u0_atom']}}\n",
      "Running on: cuda:1\n",
      "6833\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/6833\n",
      "Generating scaffold 1000/6833\n",
      "Generating scaffold 2000/6833\n",
      "Generating scaffold 3000/6833\n",
      "Generating scaffold 4000/6833\n",
      "Generating scaffold 5000/6833\n",
      "Generating scaffold 6000/6833\n",
      "About to sort in scaffold sets\n",
      "tensor(-1553.3462) tensor(228.3718) torch.Size([5466, 1])\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.753540924411236\n",
      "0 50 0.7574056733729059\n",
      "0 100 0.5528260608136844\n",
      "0 150 0.5607236966093148\n",
      "Validation loss: 0.5470705089861887 MAE: 124.93547\n",
      "1 29 0.6311887151389824\n",
      "1 79 0.5555169949263054\n",
      "1 129 0.7365590252208318\n",
      "Validation loss: 0.468782020939721 MAE: 107.05659\n",
      "2 8 0.5085792960770786\n",
      "2 58 0.6700412785031977\n",
      "2 108 0.28262373938141006\n",
      "2 158 0.5850375749147791\n",
      "Validation loss: 0.6413686184855233 MAE: 146.47049\n",
      "3 37 0.617834636229858\n",
      "3 87 0.4414937807820236\n",
      "3 137 0.4278634654239263\n",
      "Validation loss: 0.4166311494439666 MAE: 95.14679\n",
      "4 16 0.4071777332519987\n",
      "4 66 0.5075777223668885\n",
      "4 116 0.42545810048079846\n",
      "4 166 0.8008442389677787\n",
      "Validation loss: 0.48516097229126603 MAE: 110.79708\n",
      "5 45 0.5289463663981779\n",
      "5 95 0.4478043819836944\n",
      "5 145 0.6311687828438148\n",
      "Validation loss: 0.4401827792675174 MAE: 100.52532\n",
      "6 24 0.5436843711074888\n",
      "6 74 0.7854736905950631\n",
      "6 124 0.45172220882210545\n",
      "Validation loss: 0.4490815819355479 MAE: 102.557556\n",
      "7 3 0.45568025868578105\n",
      "7 53 0.5367161565037625\n",
      "7 103 0.6629292434579039\n",
      "7 153 0.3689502720186043\n",
      "Validation loss: 0.470053065589994 MAE: 107.346855\n",
      "8 32 0.4553513914447729\n",
      "8 82 0.5207426086209288\n",
      "8 132 0.5827012379191862\n",
      "Validation loss: 0.4104209413305361 MAE: 93.72855\n",
      "9 11 0.5351377892219308\n",
      "9 61 0.5115507838927814\n",
      "9 111 0.48590402100319396\n",
      "9 161 0.7046101148565689\n",
      "Validation loss: 0.4390747874800922 MAE: 100.272285\n",
      "10 40 0.5709110577055287\n",
      "10 90 0.5438205607007831\n",
      "10 140 0.5511212302553072\n",
      "Validation loss: 0.39713695174769353 MAE: 90.69487\n",
      "11 19 0.6634503065197234\n",
      "11 69 0.5755189173460296\n",
      "11 119 0.3703771804138082\n",
      "11 169 0.5030654916070318\n",
      "Validation loss: 0.4576565232890391 MAE: 104.51583\n",
      "12 48 0.48484156560747244\n",
      "12 98 0.48254454034942107\n",
      "12 148 0.5018554776983786\n",
      "Validation loss: 0.5010143603846343 MAE: 114.41755\n",
      "13 27 0.5119471263694494\n",
      "13 77 0.5524439698773652\n",
      "13 127 0.4542368257275196\n",
      "Validation loss: 0.458580781318988 MAE: 104.726906\n",
      "14 6 0.5249039694134598\n",
      "14 56 0.6148345037453931\n",
      "14 106 0.5825542112284996\n",
      "14 156 0.309175231834074\n",
      "Validation loss: 0.4575026429187485 MAE: 104.48068\n",
      "15 35 0.5849147289012061\n",
      "15 85 0.6367213351142673\n",
      "15 135 0.5909599203050927\n",
      "Validation loss: 0.4329961824138262 MAE: 98.884094\n",
      "16 14 0.5592315281821478\n",
      "16 64 0.3982609442842076\n",
      "16 114 0.37841093002070114\n",
      "16 164 0.35347607122973673\n",
      "Validation loss: 0.418520886995639 MAE: 95.578354\n",
      "17 43 0.3479766139870139\n",
      "17 93 0.4261924701382836\n",
      "17 143 0.4161832675081464\n",
      "Validation loss: 0.4373850142746641 MAE: 99.88639\n",
      "18 22 0.44736333857869404\n",
      "18 72 0.412066256826838\n",
      "18 122 0.5603271173912903\n",
      "Validation loss: 0.4177014175911396 MAE: 95.391205\n",
      "19 1 0.727553887972005\n",
      "19 51 0.46339025605766304\n",
      "19 101 0.43219548923457934\n",
      "19 151 0.4022384205207853\n",
      "Validation loss: 0.46057904184910287 MAE: 105.18325\n",
      "20 30 0.44011105802618017\n",
      "20 80 0.40257419900044833\n",
      "20 130 0.4055761602303758\n",
      "Validation loss: 0.4838040516390438 MAE: 110.48718\n",
      "21 9 0.4113103419198801\n",
      "21 59 0.29249588955619216\n",
      "21 109 0.574221774184297\n",
      "21 159 0.38088620900872777\n",
      "Validation loss: 0.4543819755141498 MAE: 103.76801\n",
      "22 38 0.36498294215035776\n",
      "22 88 0.41369176159920973\n",
      "22 138 0.44650159185726557\n",
      "Validation loss: 0.489571062619226 MAE: 111.80421\n",
      "23 17 0.4678937662451833\n",
      "23 67 0.42108920238449893\n",
      "23 117 0.5347807767296009\n",
      "23 167 0.30935756423099664\n",
      "Validation loss: 0.46115249639366107 MAE: 105.31422\n",
      "24 46 0.4691559920778846\n",
      "24 96 0.5310747827771464\n",
      "24 146 0.3786864968412431\n",
      "Validation loss: 0.5593814515230948 MAE: 127.74694\n",
      "25 25 0.4867560642521242\n",
      "25 75 0.4909570698620162\n",
      "25 125 0.42852295995794065\n",
      "Validation loss: 0.5053461807513098 MAE: 115.4068\n",
      "26 4 0.3738224904510406\n",
      "26 54 0.4949148111597272\n",
      "26 104 0.32964962474674364\n",
      "26 154 0.3377808236416327\n",
      "Validation loss: 0.4406537692449246 MAE: 100.63288\n",
      "27 33 0.30998308346107795\n",
      "27 83 0.31849604689041416\n",
      "27 133 0.39420808931319895\n",
      "Validation loss: 0.48671961004971065 MAE: 111.153015\n",
      "28 12 0.44999058832683636\n",
      "28 62 0.4047439948024572\n",
      "28 112 0.3250391960540554\n",
      "28 162 0.4200404032630371\n",
      "Validation loss: 0.4308522531860753 MAE: 98.394485\n",
      "29 41 0.5329371821096753\n",
      "29 91 0.37907325503635037\n",
      "29 141 0.3138327354395645\n",
      "Validation loss: 0.5669191329799897 MAE: 129.46832\n",
      "30 20 0.3269297575848892\n",
      "30 70 0.5452155922696628\n",
      "30 120 0.5092716005822894\n",
      "30 170 0.3760431790363402\n",
      "Validation loss: 0.5817857283597802 MAE: 132.86343\n",
      "31 49 0.3656614241925382\n",
      "31 99 0.4259989360967767\n",
      "31 149 0.4923053946804203\n",
      "Validation loss: 0.4555041375215988 MAE: 104.02429\n",
      "32 28 0.25862110727869747\n",
      "32 78 0.3972411428051626\n",
      "32 128 0.39672831970504574\n",
      "Validation loss: 0.45979805159987064 MAE: 105.0049\n",
      "33 7 0.39116054470915385\n",
      "33 57 0.39147836488757226\n",
      "33 107 0.42609686956496207\n",
      "33 157 0.2883929387352295\n",
      "Validation loss: 0.540174763105069 MAE: 123.36068\n",
      "34 36 0.28255888651601974\n",
      "34 86 0.5031907088681308\n",
      "34 136 0.5814348669451339\n",
      "Validation loss: 0.5089339688856002 MAE: 116.22615\n",
      "35 15 0.4168850498311909\n",
      "35 65 0.3687284027378363\n",
      "35 115 0.3536351278416736\n",
      "35 165 0.2445967857536906\n",
      "Validation loss: 0.4970987909718564 MAE: 113.52334\n",
      "36 44 0.26075124140681294\n",
      "36 94 0.33238293919571177\n",
      "36 144 0.3614360037324968\n",
      "Validation loss: 0.526974976759905 MAE: 120.34621\n",
      "37 23 0.25839773046889647\n",
      "37 73 0.22506387581885656\n",
      "37 123 0.5054292222374898\n",
      "Validation loss: 0.5204596836664523 MAE: 118.85829\n",
      "38 2 0.26131616855986095\n",
      "38 52 0.42708692133404735\n",
      "38 102 0.70184899310179\n",
      "38 152 0.5400306997082159\n",
      "Validation loss: 0.4881909864339215 MAE: 111.48904\n",
      "39 31 0.49431744593140753\n",
      "39 81 0.3960884091538319\n",
      "39 131 0.30881887348949283\n",
      "Validation loss: 0.4343464327485938 MAE: 99.19246\n",
      "40 10 0.491029321934639\n",
      "40 60 0.254894843758701\n",
      "40 110 0.40648434475774925\n",
      "40 160 0.43401557469723606\n",
      "Validation loss: 0.49365138240724976 MAE: 112.73603\n",
      "41 39 0.3947377056118005\n",
      "41 89 0.37713354906900476\n",
      "41 139 0.3512456400037084\n",
      "Validation loss: 0.4249586738341036 MAE: 97.04857\n",
      "42 18 0.35666421237182055\n",
      "42 68 0.405201889596554\n",
      "42 118 0.4355012906874469\n",
      "42 168 0.5008798104511162\n",
      "Validation loss: 0.6337437019710652 MAE: 144.72919\n",
      "43 47 0.42060819491924606\n",
      "43 97 0.3945833940263608\n",
      "43 147 0.4534647004417463\n",
      "Validation loss: 0.4307917600486711 MAE: 98.38068\n",
      "44 26 0.3038076998279545\n",
      "44 76 0.30490495572194365\n",
      "44 126 0.42229960790259596\n",
      "Validation loss: 0.4895780410682946 MAE: 111.80581\n",
      "45 5 0.5029589498210996\n",
      "45 55 0.26865196148716874\n",
      "45 105 0.4115522265935055\n",
      "45 155 0.5061669811116624\n",
      "Validation loss: 0.5404759689032683 MAE: 123.42946\n",
      "46 34 0.3215836876933519\n",
      "46 84 0.4976577957328283\n",
      "46 134 0.32606645926200295\n",
      "Validation loss: 0.452837428154304 MAE: 103.4153\n",
      "47 13 0.5266350224533582\n",
      "47 63 0.3883006085475183\n",
      "47 113 0.2834463798610264\n",
      "47 163 0.30714489589285227\n",
      "Validation loss: 0.6048868608753584 MAE: 138.13908\n",
      "48 42 0.42804508773120675\n",
      "48 92 0.3926128866352534\n",
      "48 142 0.48545979491194824\n",
      "Validation loss: 0.4630508548335025 MAE: 105.74775\n",
      "49 21 0.28852235185040637\n",
      "49 71 0.411816869801986\n",
      "49 121 0.3325027292618294\n",
      "Validation loss: 0.5414472605749877 MAE: 123.65127\n",
      "50 0 0.3368986497998425\n",
      "50 50 0.27544744213920114\n",
      "50 100 0.3303250268662924\n",
      "50 150 0.44412898502665693\n",
      "Validation loss: 0.4636346335299531 MAE: 105.881065\n",
      "51 29 0.36314156598222064\n",
      "51 79 0.3514861458777141\n",
      "51 129 0.3344385047383535\n",
      "Validation loss: 0.5782059835411651 MAE: 132.04593\n",
      "52 8 0.3629772291014302\n",
      "52 58 0.5929065158752553\n",
      "52 108 0.33840641600382987\n",
      "52 158 0.2583343601954507\n",
      "Validation loss: 0.49051577619641845 MAE: 112.019966\n",
      "53 37 0.2663970023737487\n",
      "53 87 0.402752680163258\n",
      "53 137 0.24642567955473035\n",
      "Validation loss: 0.4544716184599358 MAE: 103.78848\n",
      "54 16 0.5676597612844542\n",
      "54 66 0.39763298562709387\n",
      "54 116 0.379528865591174\n",
      "54 166 0.5791119254579177\n",
      "Validation loss: 0.80050963442228 MAE: 182.8138\n",
      "55 45 0.4720169245129523\n",
      "55 95 0.4058134956074782\n",
      "55 145 0.3421169496432861\n",
      "Validation loss: 0.5099066712005794 MAE: 116.44828\n",
      "56 24 0.3218837540185372\n",
      "56 74 0.4778515947972364\n",
      "56 124 0.2954802883735811\n",
      "Validation loss: 0.48715325824001376 MAE: 111.25205\n",
      "57 3 0.42873349608075456\n",
      "57 53 0.2581186529750043\n",
      "57 103 0.4332734888736856\n",
      "57 153 0.2772405828378991\n",
      "Validation loss: 0.5629498603051168 MAE: 128.56186\n",
      "58 32 0.46480951968623824\n",
      "58 82 0.3002110958879871\n",
      "58 132 0.3922250000678736\n",
      "Validation loss: 0.4913527360785077 MAE: 112.2111\n",
      "59 11 0.33800289349679075\n",
      "59 61 0.24123982934597285\n",
      "59 111 0.518903991770885\n",
      "59 161 0.4883599473676622\n",
      "Validation loss: 0.40442456993443227 MAE: 92.35916\n",
      "60 40 0.3929490948108031\n",
      "60 90 0.3503108406137073\n",
      "60 140 0.25186021147784793\n",
      "Validation loss: 0.6098997809036434 MAE: 139.28389\n",
      "61 19 0.39706925756265155\n",
      "61 69 0.3138931702411882\n",
      "61 119 0.3125505648091626\n",
      "61 169 0.41641212704881214\n",
      "Validation loss: 0.4428102217222515 MAE: 101.12535\n",
      "62 48 0.2578115857879838\n",
      "62 98 0.34533064612136466\n",
      "62 148 0.24045224902318044\n",
      "Validation loss: 0.5035268754986991 MAE: 114.99132\n",
      "63 27 0.3894659968262632\n",
      "63 77 0.43033594555974125\n",
      "63 127 0.2697813466242023\n",
      "Validation loss: 0.5182878016031276 MAE: 118.3623\n",
      "64 6 0.2925633245297445\n",
      "64 56 0.3669027211785741\n",
      "64 106 0.46725063108191783\n",
      "64 156 0.4078204193976089\n",
      "Validation loss: 0.5393607923161914 MAE: 123.17479\n",
      "65 35 0.36755068752765035\n",
      "65 85 0.41519680075915527\n",
      "65 135 0.4052695820131169\n",
      "Validation loss: 0.49884694570686383 MAE: 113.92256\n",
      "66 14 0.348850701413246\n",
      "66 64 0.287768775877417\n",
      "66 114 0.37302537370523114\n",
      "66 164 0.3944622209265962\n",
      "Validation loss: 0.562583609631187 MAE: 128.47823\n",
      "67 43 0.39698383252555075\n",
      "67 93 0.28125685609676965\n",
      "67 143 0.5282572237159233\n",
      "Validation loss: 0.5722813334381371 MAE: 130.69289\n",
      "68 22 0.19585312612437125\n",
      "68 72 0.35922932491990867\n",
      "68 122 0.4251974185318507\n",
      "Validation loss: 0.41993915564135503 MAE: 95.90225\n",
      "69 1 0.2943429502347073\n",
      "69 51 0.360896657211606\n",
      "69 101 0.2701870849714978\n",
      "69 151 0.3520786920198797\n",
      "Validation loss: 0.4318002756924657 MAE: 98.611\n",
      "70 30 0.4986567353091661\n",
      "70 80 0.5203571378034548\n",
      "70 130 0.3693197917960261\n",
      "Validation loss: 0.6595057147985314 MAE: 150.61249\n",
      "71 9 0.187928327079687\n",
      "71 59 0.312818269019028\n",
      "71 109 0.2348619984499276\n",
      "71 159 0.40518186385726507\n",
      "Validation loss: 0.5793086868977686 MAE: 132.29776\n",
      "72 38 0.21503702882037842\n",
      "72 88 0.25999092911692506\n",
      "72 138 0.36033901990557227\n",
      "Validation loss: 0.6389019757683514 MAE: 145.90718\n",
      "73 17 0.3016915958337314\n",
      "73 67 0.39154879948787985\n",
      "73 117 0.2193725370908268\n",
      "73 167 0.3075973690752338\n",
      "Validation loss: 0.5195785755651039 MAE: 118.657074\n",
      "74 46 0.2925256113106124\n",
      "74 96 0.3809520550409745\n",
      "74 146 0.2471436324684382\n",
      "Validation loss: 0.5179884848538895 MAE: 118.29395\n",
      "75 25 0.3329752396455887\n",
      "75 75 0.36922170239455226\n",
      "75 125 0.356348615195217\n",
      "Validation loss: 0.559852111060717 MAE: 127.85441\n",
      "76 4 0.3842332278165286\n",
      "76 54 0.28316868488147307\n",
      "76 104 0.4012010446405516\n",
      "76 154 0.40213726837432523\n",
      "Validation loss: 0.6009927716171533 MAE: 137.24979\n",
      "77 33 0.27906777241705766\n",
      "77 83 0.2510954075340453\n",
      "77 133 0.332341320276461\n",
      "Validation loss: 0.7161685399144714 MAE: 163.55269\n",
      "78 12 0.4881126929858008\n",
      "78 62 0.36869649833819335\n",
      "78 112 0.5796072276130286\n",
      "78 162 0.40040178329339626\n",
      "Validation loss: 0.4344347415611758 MAE: 99.21263\n",
      "79 41 0.3022317766207648\n",
      "79 91 0.3206705040996316\n",
      "79 141 0.18600434961199522\n",
      "Validation loss: 0.4618688047977916 MAE: 105.4778\n",
      "80 20 0.41990131129010666\n",
      "80 70 0.29286626492887996\n",
      "80 120 0.2293319471190811\n",
      "80 170 0.3539056501920011\n",
      "Validation loss: 0.4726267976370471 MAE: 107.93462\n",
      "81 49 0.39109963657240976\n",
      "81 99 0.34250908307560535\n",
      "81 149 0.3194400529961621\n",
      "Validation loss: 0.4748335177438301 MAE: 108.438576\n",
      "82 28 0.30391936053208374\n",
      "82 78 0.19952195016157329\n",
      "82 128 0.3127224078671812\n",
      "Validation loss: 0.6664476771103708 MAE: 152.19783\n",
      "83 7 0.33276131438205714\n",
      "83 57 0.5108832696271445\n",
      "83 107 0.43029167749739555\n",
      "83 157 0.41031945551267873\n",
      "Validation loss: 0.7922505621324506 MAE: 180.92767\n",
      "84 36 0.4215740540361782\n",
      "84 86 0.3947656499325192\n",
      "84 136 0.41103999576789124\n",
      "Validation loss: 0.6131100828884638 MAE: 140.01704\n",
      "85 15 0.2618446792136887\n",
      "85 65 0.25866373792961816\n",
      "85 115 0.20527677331380162\n",
      "85 165 0.2936047382029218\n",
      "Validation loss: 0.5240949831510845 MAE: 119.68851\n",
      "86 44 0.354374939281956\n",
      "86 94 0.5667067118243289\n",
      "86 144 0.46029061583138603\n",
      "Validation loss: 0.5121660772819965 MAE: 116.96427\n",
      "87 23 0.2972413270246111\n",
      "87 73 0.3612500592280992\n",
      "87 123 0.36520494503160905\n",
      "Validation loss: 0.6043971435368409 MAE: 138.02725\n",
      "88 2 0.3434805569986701\n",
      "88 52 0.2513100315042256\n",
      "88 102 0.28254751239173603\n",
      "88 152 0.24831447537990017\n",
      "Validation loss: 0.5158414687329566 MAE: 117.803635\n",
      "89 31 0.3631893524856113\n",
      "89 81 0.4331134275477819\n",
      "89 131 0.39073424848460603\n",
      "Validation loss: 0.5697097527353387 MAE: 130.10562\n",
      "90 10 0.2609780352210614\n",
      "90 60 0.3240950846998782\n",
      "90 110 0.275897625455297\n",
      "90 160 0.3292498358366418\n",
      "Validation loss: 0.43341565933841014 MAE: 98.9799\n",
      "91 39 0.30767450093428717\n",
      "91 89 0.35360182402457285\n",
      "91 139 0.3760601261806196\n",
      "Validation loss: 0.6125918640727885 MAE: 139.89868\n",
      "92 18 0.37074670075219857\n",
      "92 68 0.35773606118737145\n",
      "92 118 0.20129715281590832\n",
      "92 168 0.3531542183802841\n",
      "Validation loss: 0.7395992641560516 MAE: 168.9036\n",
      "93 47 0.21735153131317142\n",
      "93 97 0.5180899051672692\n",
      "93 147 0.19862280915676817\n",
      "Validation loss: 0.5519086091141951 MAE: 126.040344\n",
      "94 26 0.3828410663065198\n",
      "94 76 0.3255782629515063\n",
      "94 126 0.2966441578354084\n",
      "Validation loss: 0.5855080781624331 MAE: 133.71352\n",
      "95 5 0.32041530629309084\n",
      "95 55 0.25753708747074994\n",
      "95 105 0.349083738896694\n",
      "95 155 0.33031222980100405\n",
      "Validation loss: 0.6130770437898692 MAE: 140.00949\n",
      "96 34 0.3984012634071631\n",
      "96 84 0.4210093921614029\n",
      "96 134 0.312893447752783\n",
      "Validation loss: 0.6000453939563349 MAE: 137.03343\n",
      "97 13 0.29643006121798454\n",
      "97 63 0.3645134177410219\n",
      "97 113 0.35921189033317125\n",
      "97 163 0.4767678427745083\n",
      "Validation loss: 0.5066112879424067 MAE: 115.695724\n",
      "98 42 0.2832251821974503\n",
      "98 92 0.3176872488780183\n",
      "98 142 0.3778487350933937\n",
      "Validation loss: 0.5448592287755152 MAE: 124.430466\n",
      "99 21 0.2911672849829517\n",
      "99 71 0.3568606913156411\n",
      "99 121 0.25934575691785106\n",
      "Validation loss: 0.5999724600050185 MAE: 137.01678\n",
      "100 0 0.2791309150407051\n",
      "100 50 0.5385033809846711\n",
      "100 100 0.2705846720058522\n",
      "100 150 0.2249925333652194\n",
      "Validation loss: 0.4647067035847937 MAE: 106.12589\n",
      "101 29 0.26345942825174545\n",
      "101 79 0.3536886564322522\n",
      "101 129 0.24865675684400762\n",
      "Validation loss: 0.6717059378735504 MAE: 153.39867\n",
      "102 8 0.4632080724145173\n",
      "102 58 0.2891159661979856\n",
      "102 108 0.45502648758884684\n",
      "102 158 0.4324842699636983\n",
      "Validation loss: 0.6027346242938125 MAE: 137.64758\n",
      "103 37 0.29388245239526795\n",
      "103 87 0.2915720218423655\n",
      "103 137 0.17500632517694822\n",
      "Validation loss: 0.5878794364064758 MAE: 134.25507\n",
      "104 16 0.334148695200364\n",
      "104 66 0.27629209668781063\n",
      "104 116 0.4009933543694878\n",
      "104 166 0.3742775016968078\n",
      "Validation loss: 0.5354717980351364 MAE: 122.28665\n",
      "105 45 0.2545619316115126\n",
      "105 95 0.21747303113992425\n",
      "105 145 0.3325289634795721\n",
      "Validation loss: 0.5848178912324515 MAE: 133.5559\n",
      "106 24 0.26769019813629086\n",
      "106 74 0.23645569347143314\n",
      "106 124 0.20406201066020838\n",
      "Validation loss: 0.5884752765036466 MAE: 134.39114\n",
      "107 3 0.3989299390155265\n",
      "107 53 0.3814910987694555\n",
      "107 103 0.31604307048312885\n",
      "107 153 0.3599180359744657\n",
      "Validation loss: 0.7210728334404571 MAE: 164.67268\n",
      "108 32 0.18906905576800537\n",
      "108 82 0.31724801994447127\n",
      "108 132 0.3636278069913224\n",
      "Validation loss: 0.6070403188292743 MAE: 138.63087\n",
      "109 11 0.3090176294735187\n",
      "109 61 0.4226407847409918\n",
      "109 111 0.23001261849954696\n",
      "109 161 0.25288999522956424\n",
      "Validation loss: 0.5997904985271699 MAE: 136.97522\n",
      "110 40 0.3631586411902219\n",
      "110 90 0.30173393847179675\n",
      "110 140 0.28471634968707193\n",
      "Validation loss: 0.7223364686408238 MAE: 164.96126\n",
      "111 19 0.3034404582344119\n",
      "111 69 0.4355347438754743\n",
      "111 119 0.2990127645496464\n",
      "111 169 0.2559467405054793\n",
      "Validation loss: 0.6527302394136351 MAE: 149.06517\n",
      "112 48 0.26281010607132077\n",
      "112 98 0.18932424022263825\n",
      "112 148 0.17652680719452035\n",
      "Validation loss: 0.5690973613694398 MAE: 129.96577\n",
      "113 27 0.2089415079015917\n",
      "113 77 0.4921845026781347\n",
      "113 127 0.20219310100164326\n",
      "Validation loss: 0.5000919434759352 MAE: 114.206894\n",
      "114 6 0.2546007058526697\n",
      "114 56 0.3136410389815526\n",
      "114 106 0.37836575858264865\n",
      "114 156 0.5244795033451533\n",
      "Validation loss: 0.5530459295239365 MAE: 126.30009\n",
      "115 35 0.295364454369351\n",
      "115 85 0.2832482453458215\n",
      "115 135 0.34541391622665035\n",
      "Validation loss: 0.5178415973981222 MAE: 118.260414\n",
      "116 14 0.29946459033572986\n",
      "116 64 0.30243361418202697\n",
      "116 114 0.23774842996153805\n",
      "116 164 0.3684011567329476\n",
      "Validation loss: 0.5598908495484737 MAE: 127.86326\n",
      "117 43 0.36880776964507445\n",
      "117 93 0.45136998743606044\n",
      "117 143 0.4968173868158536\n",
      "Validation loss: 0.6396180527252063 MAE: 146.07071\n",
      "118 22 0.22052859907936073\n",
      "118 72 0.40293492525992824\n",
      "118 122 0.30339671107368055\n",
      "Validation loss: 0.5152899786742807 MAE: 117.67769\n",
      "119 1 0.2512314335842198\n",
      "119 51 0.26045476687328706\n",
      "119 101 0.3004224880832478\n",
      "119 151 0.33258716796819293\n",
      "Validation loss: 0.5972710417376624 MAE: 136.39986\n",
      "120 30 0.27074144810935374\n",
      "120 80 0.29873746819174135\n",
      "120 130 0.21338845344390284\n",
      "Validation loss: 0.5905048878569352 MAE: 134.85466\n",
      "121 9 0.418064057637266\n",
      "121 59 0.33232416612343735\n",
      "121 109 0.38478088378450687\n",
      "121 159 0.30956228697149435\n",
      "Validation loss: 0.6444630100016009 MAE: 147.17717\n",
      "122 38 0.34503649691028654\n",
      "122 88 0.30439486723863174\n",
      "122 138 0.33242127176643493\n",
      "Validation loss: 0.6392380375611154 MAE: 145.98392\n",
      "123 17 0.29694434784575063\n",
      "123 67 0.20562370321220283\n",
      "123 117 0.34049630360160416\n",
      "123 167 0.19948899970276754\n",
      "Validation loss: 0.599711889760536 MAE: 136.95726\n",
      "124 46 0.26119611138838217\n",
      "124 96 0.3785031967464475\n",
      "124 146 0.3972526425872425\n",
      "Validation loss: 0.5780670763107768 MAE: 132.0142\n",
      "125 25 0.30626192865085256\n",
      "125 75 0.3458312162524217\n",
      "125 125 0.2835056547081581\n",
      "Validation loss: 0.5274873341036121 MAE: 120.46321\n",
      "126 4 0.2715281708269364\n",
      "126 54 0.3225160098093998\n",
      "126 104 0.37281601363544037\n",
      "126 154 0.3338663143402302\n",
      "Validation loss: 0.5975105961163839 MAE: 136.45456\n",
      "127 33 0.43545323379714385\n",
      "127 83 0.25427694561751557\n",
      "127 133 0.3092596865233251\n",
      "Validation loss: 0.48810890979237026 MAE: 111.47029\n",
      "128 12 0.29121640038228813\n",
      "128 62 0.46739952279313457\n",
      "128 112 0.2346799936305416\n",
      "128 162 0.3888987688292399\n",
      "Validation loss: 0.6348277999643694 MAE: 144.97676\n",
      "129 41 0.27971802401345297\n",
      "129 91 0.22523119347096637\n",
      "129 141 0.14265316266929165\n",
      "Validation loss: 0.6190021553931878 MAE: 141.36263\n",
      "130 20 0.3274668398340123\n",
      "130 70 0.2539984211444143\n",
      "130 120 0.17735795034812754\n",
      "130 170 0.2953673762747766\n",
      "Validation loss: 0.6087236930752358 MAE: 139.0153\n",
      "131 49 0.36224768191240403\n",
      "131 99 0.2405594444378545\n",
      "131 149 0.4047777099062763\n",
      "Validation loss: 0.4739765455151162 MAE: 108.24285\n",
      "132 28 0.5966049783509557\n",
      "132 78 0.33919471634740744\n",
      "132 128 0.37242020947585625\n",
      "Validation loss: 0.6559975272730777 MAE: 149.81133\n",
      "133 7 0.25136205836255743\n",
      "133 57 0.28221580019619696\n",
      "133 107 0.18850137794212107\n",
      "133 157 0.25504964814073483\n",
      "Validation loss: 0.5449882174095912 MAE: 124.45993\n",
      "134 36 0.31029697901247044\n",
      "134 86 0.2822743589554918\n",
      "134 136 0.24340642926815556\n",
      "Validation loss: 0.725849285460355 MAE: 165.7635\n",
      "135 15 0.35255091844440234\n",
      "135 65 0.2229020565497375\n",
      "135 115 0.22900067528391532\n",
      "135 165 0.4867269811147629\n",
      "Validation loss: 0.5853930617633619 MAE: 133.68726\n",
      "136 44 0.4785779857875587\n",
      "136 94 0.16947916811450767\n",
      "136 144 0.18033124288365462\n",
      "Validation loss: 0.587488689966369 MAE: 134.16583\n",
      "137 23 0.521351817953904\n",
      "137 73 0.3735468351053418\n",
      "137 123 0.3713334194351427\n",
      "Validation loss: 0.5727255441989118 MAE: 130.79434\n",
      "138 2 0.48043933898681684\n",
      "138 52 0.43018986711329105\n",
      "138 102 0.43107006294845895\n",
      "138 152 0.2659644356383753\n",
      "Validation loss: 0.6413155306152433 MAE: 146.45836\n",
      "139 31 0.36821422063349013\n",
      "139 81 0.4026340670191992\n",
      "139 131 0.23137129653813152\n",
      "Validation loss: 0.5738278257916545 MAE: 131.04608\n",
      "140 10 0.21776929338721085\n",
      "140 60 0.2902376826168072\n",
      "140 110 0.177585414028881\n",
      "140 160 0.31542229830992574\n",
      "Validation loss: 0.6322885026708681 MAE: 144.39685\n",
      "141 39 0.2539624989411351\n",
      "141 89 0.26116605910911783\n",
      "141 139 0.27063043877882786\n",
      "Validation loss: 0.6478770270682218 MAE: 147.95683\n",
      "142 18 0.29805167037241076\n",
      "142 68 0.29776703525889003\n",
      "142 118 0.382165518910939\n",
      "142 168 0.33280174384581995\n",
      "Validation loss: 0.554283749290377 MAE: 126.58276\n",
      "143 47 0.24801638153011585\n",
      "143 97 0.2590074059143003\n",
      "143 147 0.29573349924434\n",
      "Validation loss: 0.5263085215412385 MAE: 120.19401\n",
      "144 26 0.37250177904575166\n",
      "144 76 0.40919508005711597\n",
      "144 126 0.4255909646385322\n",
      "Validation loss: 0.6001219414828116 MAE: 137.0509\n",
      "145 5 0.3422266210874432\n",
      "145 55 0.26518401439422906\n",
      "145 105 0.29792871364073636\n",
      "145 155 0.2840632097364657\n",
      "Validation loss: 0.5775023719720673 MAE: 131.88524\n",
      "146 34 0.28492742645646874\n",
      "146 84 0.21771946460923702\n",
      "146 134 0.28187328083490043\n",
      "Validation loss: 0.614961796685269 MAE: 140.43993\n",
      "147 13 0.32473239420289673\n",
      "147 63 0.23611485206062952\n",
      "147 113 0.3293281400656535\n",
      "147 163 0.2923276599044221\n",
      "Validation loss: 0.6288658809243587 MAE: 143.61522\n",
      "148 42 0.2626800291604372\n",
      "148 92 0.37804422662084525\n",
      "148 142 0.3033017483036898\n",
      "Validation loss: 0.6140358273745977 MAE: 140.22845\n",
      "149 21 0.27295196140414096\n",
      "149 71 0.4034464219667481\n",
      "149 121 0.25864017635598174\n",
      "Validation loss: 0.534811384148068 MAE: 122.135826\n",
      "150 0 0.2632599711621355\n",
      "150 50 0.1895687577572651\n",
      "150 100 0.2239077817865255\n",
      "150 150 0.3365265801464097\n",
      "Validation loss: 0.5744718996404904 MAE: 131.19316\n",
      "151 29 0.16574234620434883\n",
      "151 79 0.1953897163233831\n",
      "151 129 0.2609006149826423\n",
      "Validation loss: 0.6696454260432929 MAE: 152.92812\n",
      "152 8 0.27831358128396677\n",
      "152 58 0.1160644050675742\n",
      "152 108 0.25181572713989575\n",
      "152 158 0.24654130070620178\n",
      "Validation loss: 0.6063449884715834 MAE: 138.47209\n",
      "153 37 0.26772079346083405\n",
      "153 87 0.42760334516167664\n",
      "153 137 0.29666767947425293\n",
      "Validation loss: 0.5615750143402501 MAE: 128.24788\n",
      "154 16 0.32132038276621816\n",
      "154 66 0.33305460324051966\n",
      "154 116 0.322187585385325\n",
      "154 166 0.1435452825011981\n",
      "Validation loss: 0.5923511243005942 MAE: 135.27629\n",
      "155 45 0.3624614456348324\n",
      "155 95 0.46196554884123936\n",
      "155 145 0.23840412815559708\n",
      "Validation loss: 0.49886105283659105 MAE: 113.92578\n",
      "156 24 0.28406987026236247\n",
      "156 74 0.37789936440847305\n",
      "156 124 0.35433773489376674\n",
      "Validation loss: 0.5884717106819153 MAE: 134.39034\n",
      "157 3 0.35896211664397776\n",
      "157 53 0.3968275314934146\n",
      "157 103 0.37098879934572304\n",
      "157 153 0.34163295361753565\n",
      "Validation loss: 0.685544060336219 MAE: 156.55891\n",
      "158 32 0.3113705950658734\n",
      "158 82 0.21265425858550993\n",
      "158 132 0.3080423437052646\n",
      "Validation loss: 0.653162168654782 MAE: 149.16382\n",
      "159 11 0.3254514830797307\n",
      "159 61 0.4112927967736073\n",
      "159 111 0.19924344568920596\n",
      "159 161 0.18632335255481444\n",
      "Validation loss: 0.5904056252094737 MAE: 134.83199\n",
      "160 40 0.24332508206696704\n",
      "160 90 0.28064149989551146\n",
      "160 140 0.35788475332387903\n",
      "Validation loss: 0.6448033601917021 MAE: 147.25488\n",
      "161 19 0.18306611888186478\n",
      "161 69 0.42009447948279427\n",
      "161 119 0.3378212344670835\n",
      "161 169 0.26529854115998125\n",
      "Validation loss: 0.6624363270419383 MAE: 151.28175\n",
      "162 48 0.36585613965871366\n",
      "162 98 0.38204379735062854\n",
      "162 148 0.3528974030680236\n",
      "Validation loss: 0.6155355661584619 MAE: 140.57095\n",
      "163 27 0.25868757687935584\n",
      "163 77 0.30901972385145526\n",
      "163 127 0.26017676204431245\n",
      "Validation loss: 0.5826472918889676 MAE: 133.0602\n",
      "164 6 0.5170761041790914\n",
      "164 56 0.2800951978288776\n",
      "164 106 0.3580461910601431\n",
      "164 156 0.29967105798664734\n",
      "Validation loss: 0.7039791746446263 MAE: 160.76898\n",
      "165 35 0.2234945432000717\n",
      "165 85 0.19197972838338928\n",
      "165 135 0.20431126895447238\n",
      "Validation loss: 0.5667637816646642 MAE: 129.43285\n",
      "166 14 0.18086009778650838\n",
      "166 64 0.2529894372732285\n",
      "166 114 0.2861569865496398\n",
      "166 164 0.3982214939742388\n",
      "Validation loss: 0.6227744995502004 MAE: 142.22412\n",
      "167 43 0.2922230791148491\n",
      "167 93 0.3126177871896341\n",
      "167 143 0.33874895837413177\n",
      "Validation loss: 0.6789932630912602 MAE: 155.06288\n",
      "168 22 0.29937334433500185\n",
      "168 72 0.21412662926231515\n",
      "168 122 0.27009454861060295\n",
      "Validation loss: 0.5733652986281099 MAE: 130.94044\n",
      "169 1 0.23317078155669663\n",
      "169 51 0.45678616208183564\n",
      "169 101 0.2314474122614913\n",
      "169 151 0.19664765600053086\n",
      "Validation loss: 0.5208492362708376 MAE: 118.947266\n",
      "170 30 0.30629308348625633\n",
      "170 80 0.28313846406295134\n",
      "170 130 0.31200777560339243\n",
      "Validation loss: 0.636329442088367 MAE: 145.31969\n",
      "171 9 0.3931534230756054\n",
      "171 59 0.2682914137758331\n",
      "171 109 0.21663016773509183\n",
      "171 159 0.26016186395483026\n",
      "Validation loss: 0.6020564036062587 MAE: 137.49269\n",
      "172 38 0.2671084334105913\n",
      "172 88 0.3529985746055887\n",
      "172 138 0.24703990560964031\n",
      "Validation loss: 0.5159448630977095 MAE: 117.82723\n",
      "173 17 0.1960280067622573\n",
      "173 67 0.3494394572264133\n",
      "173 117 0.21987131501914634\n",
      "173 167 0.21958173311185814\n",
      "Validation loss: 0.653047281747673 MAE: 149.13756\n",
      "174 46 0.44177573889528043\n",
      "174 96 0.20515475053207657\n",
      "174 146 0.32810950117790383\n",
      "Validation loss: 0.5585081009139792 MAE: 127.54749\n",
      "175 25 0.20771050909951616\n",
      "175 75 0.21036427597098906\n",
      "175 125 0.3289323698989041\n",
      "Validation loss: 0.642312562953659 MAE: 146.68607\n",
      "176 4 0.1415848430727178\n",
      "176 54 0.3403903261267191\n",
      "176 104 0.276361896151797\n",
      "176 154 0.2769819530979075\n",
      "Validation loss: 0.6113679077890184 MAE: 139.61917\n",
      "177 33 0.26341081568509905\n",
      "177 83 0.4210523821755991\n",
      "177 133 0.3987934505268099\n",
      "Validation loss: 0.7381017347525435 MAE: 168.56161\n",
      "178 12 0.2943588275591982\n",
      "178 62 0.1524499540789152\n",
      "178 112 0.18629990992092674\n",
      "178 162 0.2669172012163543\n",
      "Validation loss: 0.6822496983740065 MAE: 155.80658\n",
      "179 41 0.2919814539886632\n",
      "179 91 0.26177677643980435\n",
      "179 141 0.5377506288167745\n",
      "Validation loss: 0.6851313898437902 MAE: 156.46468\n",
      "180 20 0.23903508028346\n",
      "180 70 0.26768834002870506\n",
      "180 120 0.15064367756567687\n",
      "180 170 0.2622405623082531\n",
      "Validation loss: 0.5949945324345639 MAE: 135.87996\n",
      "181 49 0.30968271827723387\n",
      "181 99 0.438070830055727\n",
      "181 149 0.20997371000697942\n",
      "Validation loss: 0.562654261352026 MAE: 128.49435\n",
      "182 28 0.3098676607362992\n",
      "182 78 0.3074429379665417\n",
      "182 128 0.34262978053607257\n",
      "Validation loss: 0.6007601967331959 MAE: 137.19666\n",
      "183 7 0.5236477664822453\n",
      "183 57 0.24883358396977995\n",
      "183 107 0.23670542400493405\n",
      "183 157 0.43251617246290297\n",
      "Validation loss: 0.7023689516803675 MAE: 160.40125\n",
      "184 36 0.16207988844011179\n",
      "184 86 0.23021858583484905\n",
      "184 136 0.16060852453594873\n",
      "Validation loss: 0.6725523306263818 MAE: 153.59196\n",
      "185 15 0.35461358829015444\n",
      "185 65 0.2505759662300509\n",
      "185 115 0.2656936502103715\n",
      "185 165 0.39132949059404804\n",
      "Validation loss: 0.5789360477213275 MAE: 132.21265\n",
      "186 44 0.3668002804869654\n",
      "186 94 0.46060054679984475\n",
      "186 144 0.36239521796543517\n",
      "Validation loss: 0.6030696152943616 MAE: 137.72408\n",
      "187 23 0.3074284909341336\n",
      "187 73 0.4022710803265413\n",
      "187 123 0.18044797925202755\n",
      "Validation loss: 0.69416209027084 MAE: 158.52704\n",
      "188 2 0.41384391582553937\n",
      "188 52 0.20980705877897254\n",
      "188 102 0.35459095850438066\n",
      "188 152 0.3026922057018758\n",
      "Validation loss: 0.5915966846092403 MAE: 135.10399\n",
      "189 31 0.2759381069172607\n",
      "189 81 0.24334146907637882\n",
      "189 131 0.24596126454180786\n",
      "Validation loss: 0.5872789279759278 MAE: 134.11794\n",
      "190 10 0.23756004232214087\n",
      "190 60 0.19695062231539154\n",
      "190 110 0.358399832954257\n",
      "190 160 0.30752965363698365\n",
      "Validation loss: 0.5889912045489974 MAE: 134.50897\n",
      "191 39 0.24416699372507664\n",
      "191 89 0.3483077372556296\n",
      "191 139 0.3198096372422068\n",
      "Validation loss: 0.5647175904603032 MAE: 128.96555\n",
      "192 18 0.4767793300521785\n",
      "192 68 0.21470780389040833\n",
      "192 118 0.2545034557847201\n",
      "192 168 0.3655617285217373\n",
      "Validation loss: 0.6148483216413978 MAE: 140.414\n",
      "193 47 0.27415608317423823\n",
      "193 97 0.18511238820253617\n",
      "193 147 0.20283719705691192\n",
      "Validation loss: 0.6812822268023129 MAE: 155.58565\n",
      "194 26 0.2692733025644589\n",
      "194 76 0.22437988952377713\n",
      "194 126 0.20673832594437874\n",
      "Validation loss: 0.5374679405089707 MAE: 122.74251\n",
      "195 5 0.23148889014146154\n",
      "195 55 0.19775561111718423\n",
      "195 105 0.28296561011078214\n",
      "195 155 0.24907322088532063\n",
      "Validation loss: 0.6746316994839942 MAE: 154.06683\n",
      "196 34 0.3431978007762635\n",
      "196 84 0.2098715218983086\n",
      "196 134 0.2683143867770648\n",
      "Validation loss: 0.7773016035905358 MAE: 177.51375\n",
      "197 13 0.17341770510430937\n",
      "197 63 0.18773469212183647\n",
      "197 113 0.2521052562783911\n",
      "197 163 0.5583928393727784\n",
      "Validation loss: 0.5575854722519367 MAE: 127.336784\n",
      "198 42 0.23608688040992654\n",
      "198 92 0.21919149111137495\n",
      "198 142 0.25985191148381986\n",
      "Validation loss: 0.6327876371946949 MAE: 144.51083\n",
      "199 21 0.18786882192091803\n",
      "199 71 0.3802669474328893\n",
      "199 121 0.28460113319682057\n",
      "Validation loss: 0.5618691946330824 MAE: 128.31506\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.32430146364045176 Test MAE: 74.0613\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'qm7', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 778, 'task': 'regression', 'data_path': 'data/qm7/qm7.csv', 'target': ['u0_atom']}}\n",
      "Running on: cuda:1\n",
      "6833\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/6833\n",
      "Generating scaffold 1000/6833\n",
      "Generating scaffold 2000/6833\n",
      "Generating scaffold 3000/6833\n",
      "Generating scaffold 4000/6833\n",
      "Generating scaffold 5000/6833\n",
      "Generating scaffold 6000/6833\n",
      "About to sort in scaffold sets\n",
      "tensor(-1553.3462) tensor(228.3718) torch.Size([5466, 1])\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.3906914500269514\n",
      "0 50 0.8186344527752228\n",
      "0 100 0.8079843548600388\n",
      "0 150 0.5169511154422485\n",
      "Validation loss: 0.48679236658135355 MAE: 111.16964\n",
      "1 29 0.6131604304141489\n",
      "1 79 0.5252547113388656\n",
      "1 129 0.5707319264459036\n",
      "Validation loss: 0.6897013640543174 MAE: 157.50833\n",
      "2 8 0.45165590101864866\n",
      "2 58 0.3833061024601334\n",
      "2 108 0.6192064452474029\n",
      "2 158 0.6426610981683021\n",
      "Validation loss: 0.42440607498960886 MAE: 96.92236\n",
      "3 37 0.48006823952509675\n",
      "3 87 0.5847736222326233\n",
      "3 137 0.5276704919213349\n",
      "Validation loss: 0.428209260193228 MAE: 97.7909\n",
      "4 16 0.39841774010218567\n",
      "4 66 0.48830881305863877\n",
      "4 116 0.40755121959504637\n",
      "4 166 0.6100432268063968\n",
      "Validation loss: 0.4788438461677373 MAE: 109.354416\n",
      "5 45 0.5016221786095401\n",
      "5 95 0.47972548333063864\n",
      "5 145 0.557440851787179\n",
      "Validation loss: 0.4641988699199163 MAE: 106.009926\n",
      "6 24 0.48482423241385925\n",
      "6 74 0.5492710525023825\n",
      "6 124 0.6223039174965593\n",
      "Validation loss: 0.48110083669249776 MAE: 109.86985\n",
      "7 3 0.40238222919786515\n",
      "7 53 0.5455409799479816\n",
      "7 103 0.6771138743129463\n",
      "7 153 0.6007709969738089\n",
      "Validation loss: 0.40251664738906057 MAE: 91.92344\n",
      "8 32 0.7284530636391695\n",
      "8 82 0.2506347612467938\n",
      "8 132 0.554636727066332\n",
      "Validation loss: 0.4888543531908626 MAE: 111.64053\n",
      "9 11 0.5098312957436402\n",
      "9 61 0.4585914926591148\n",
      "9 111 0.6407070300318268\n",
      "9 161 0.5687222191278725\n",
      "Validation loss: 0.40515800351985015 MAE: 92.52664\n",
      "10 40 0.5303461054807898\n",
      "10 90 0.5310104870342865\n",
      "10 140 0.6737866149466979\n",
      "Validation loss: 0.4640749187497368 MAE: 105.98161\n",
      "11 19 0.3331920432268249\n",
      "11 69 0.4191273225187666\n",
      "11 119 0.34251922879037\n",
      "11 169 0.5334290554910885\n",
      "Validation loss: 0.4563201108174017 MAE: 104.21063\n",
      "12 48 0.675097736137752\n",
      "12 98 0.527276087527571\n",
      "12 148 0.3438017633731948\n",
      "Validation loss: 0.3986872027666248 MAE: 91.048904\n",
      "13 27 0.6230591838677797\n",
      "13 77 0.4806001894656989\n",
      "13 127 0.4290425263659144\n",
      "Validation loss: 0.3737471908853765 MAE: 85.35331\n",
      "14 6 0.49452083016843096\n",
      "14 56 0.675802359625265\n",
      "14 106 0.5962152985247537\n",
      "14 156 0.5741158993881154\n",
      "Validation loss: 0.430475770381459 MAE: 98.30852\n",
      "15 35 0.40818800194598887\n",
      "15 85 0.24560983319474747\n",
      "15 135 0.38490524739094883\n",
      "Validation loss: 0.45778663256014995 MAE: 104.54554\n",
      "16 14 0.4555920985378772\n",
      "16 64 0.5973713048579122\n",
      "16 114 0.5092502710028229\n",
      "16 164 0.4040957956690099\n",
      "Validation loss: 0.39367780281089204 MAE: 89.9049\n",
      "17 43 0.2814574776931793\n",
      "17 93 0.6363522443982885\n",
      "17 143 0.33129675778077083\n",
      "Validation loss: 0.433235971725475 MAE: 98.93886\n",
      "18 22 0.6243454818166261\n",
      "18 72 0.4311337038947694\n",
      "18 122 0.532907141798175\n",
      "Validation loss: 0.4280057692388345 MAE: 97.74444\n",
      "19 1 0.45037652677569306\n",
      "19 51 0.5496818868958853\n",
      "19 101 0.6201844535455472\n",
      "19 151 0.5309513882976769\n",
      "Validation loss: 0.40260059303707546 MAE: 91.942604\n",
      "20 30 0.6821918020021311\n",
      "20 80 0.43847096031233823\n",
      "20 130 0.5440879640056366\n",
      "Validation loss: 0.41762828565480414 MAE: 95.37451\n",
      "21 9 0.5464710243138435\n",
      "21 59 0.40256350347995934\n",
      "21 109 0.4721056627865887\n",
      "21 159 0.5479431973300526\n",
      "Validation loss: 0.404270336990468 MAE: 92.32393\n",
      "22 38 0.37281370694600363\n",
      "22 88 0.2945527055772018\n",
      "22 138 0.3820359374141847\n",
      "Validation loss: 0.4066837700138315 MAE: 92.87509\n",
      "23 17 0.4205380093646864\n",
      "23 67 0.4580472086486701\n",
      "23 117 0.45471307627830254\n",
      "23 167 0.4161272530546063\n",
      "Validation loss: 0.4603874861148366 MAE: 105.1395\n",
      "24 46 0.4264169886212364\n",
      "24 96 0.3094406374418391\n",
      "24 146 0.4808145529106331\n",
      "Validation loss: 0.4702242747036337 MAE: 107.38594\n",
      "25 25 0.30652167514528256\n",
      "25 75 0.387851103918383\n",
      "25 125 0.3345174444850872\n",
      "Validation loss: 0.433551393754301 MAE: 99.010895\n",
      "26 4 0.341762032488203\n",
      "26 54 0.28293677302893555\n",
      "26 104 0.46152225541055364\n",
      "26 154 0.2640570470076818\n",
      "Validation loss: 0.4130414222416125 MAE: 94.326996\n",
      "27 33 0.36539969803948064\n",
      "27 83 0.3371411794975333\n",
      "27 133 0.5617786422597638\n",
      "Validation loss: 0.45012185587520487 MAE: 102.79513\n",
      "28 12 0.4908076025175438\n",
      "28 62 0.36398162754894897\n",
      "28 112 0.6372909411369241\n",
      "28 162 0.417022349728581\n",
      "Validation loss: 0.44537868154676336 MAE: 101.71191\n",
      "29 41 0.32876926531497797\n",
      "29 91 0.36826579632927015\n",
      "29 141 0.39345672000408305\n",
      "Validation loss: 0.6182735921346654 MAE: 141.19624\n",
      "30 20 0.4322954102654759\n",
      "30 70 0.45827469221577855\n",
      "30 120 0.39200066372499587\n",
      "30 170 0.2670819376734205\n",
      "Validation loss: 0.5285264103733308 MAE: 120.70051\n",
      "31 49 0.5315503922334905\n",
      "31 99 0.44528943322282893\n",
      "31 149 0.25689724856673096\n",
      "Validation loss: 0.5201461848459745 MAE: 118.78671\n",
      "32 28 0.45699906227259957\n",
      "32 78 0.5051829007939507\n",
      "32 128 0.4799275564110489\n",
      "Validation loss: 0.5307253925075308 MAE: 121.20269\n",
      "33 7 0.36600411429589946\n",
      "33 57 0.26388090991678115\n",
      "33 107 0.3290630010481332\n",
      "33 157 0.35367373263766216\n",
      "Validation loss: 0.4423271001082415 MAE: 101.01503\n",
      "34 36 0.3840306904250577\n",
      "34 86 0.29854291578414527\n",
      "34 136 0.24069615869856648\n",
      "Validation loss: 0.46756009626806827 MAE: 106.77753\n",
      "35 15 0.35565405912640263\n",
      "35 65 0.2737403096885046\n",
      "35 115 0.3353872299528792\n",
      "35 165 0.5578694326322182\n",
      "Validation loss: 0.660104719518918 MAE: 150.7493\n",
      "36 44 0.3692874418693203\n",
      "36 94 0.3692965919323016\n",
      "36 144 0.4615039440951328\n",
      "Validation loss: 0.4727848064132601 MAE: 107.9707\n",
      "37 23 0.31966738200084127\n",
      "37 73 0.28479637439429045\n",
      "37 123 0.3603730688154166\n",
      "Validation loss: 0.4070425837012062 MAE: 92.95703\n",
      "38 2 0.46146545916782516\n",
      "38 52 0.3856185802969372\n",
      "38 102 0.2579559777141892\n",
      "38 152 0.3052544449231446\n",
      "Validation loss: 0.48462731134124665 MAE: 110.6752\n",
      "39 31 0.4445321984692771\n",
      "39 81 0.437138073598575\n",
      "39 131 0.5018100860169961\n",
      "Validation loss: 0.5068426484252975 MAE: 115.74856\n",
      "40 10 0.3195359873858662\n",
      "40 60 0.3361932200991406\n",
      "40 110 0.4588504802929574\n",
      "40 160 0.2741807970956379\n",
      "Validation loss: 0.6039090466778181 MAE: 137.91577\n",
      "41 39 0.3462963833698264\n",
      "41 89 0.44217197185863627\n",
      "41 139 0.43493359561378947\n",
      "Validation loss: 0.5127147397799798 MAE: 117.08957\n",
      "42 18 0.3117087206298875\n",
      "42 68 0.4494471378253684\n",
      "42 118 0.3593904313855769\n",
      "42 168 0.38057586622096673\n",
      "Validation loss: 0.46008333755515474 MAE: 105.07005\n",
      "43 47 0.2973849922477804\n",
      "43 97 0.25084380790148814\n",
      "43 147 0.4010539248588979\n",
      "Validation loss: 0.5378553804598356 MAE: 122.83098\n",
      "44 26 0.2264091826429352\n",
      "44 76 0.34575300773238965\n",
      "44 126 0.2781730562334623\n",
      "Validation loss: 0.5233740527727451 MAE: 119.52385\n",
      "45 5 0.3381694956429686\n",
      "45 55 0.402585470927086\n",
      "45 105 0.403088952278885\n",
      "45 155 0.3116793903061097\n",
      "Validation loss: 0.5286064081721835 MAE: 120.71877\n",
      "46 34 0.47447147672333934\n",
      "46 84 0.3721407082767443\n",
      "46 134 0.3241522481606424\n",
      "Validation loss: 0.4756250994944433 MAE: 108.61933\n",
      "47 13 0.3686394043935795\n",
      "47 63 0.3717642097076875\n",
      "47 113 0.39719514576776516\n",
      "47 163 0.3349570276585153\n",
      "Validation loss: 0.46942790750174496 MAE: 107.20409\n",
      "48 42 0.44015737803089056\n",
      "48 92 0.439241169388589\n",
      "48 142 0.33554721726590797\n",
      "Validation loss: 0.491259683642471 MAE: 112.18984\n",
      "49 21 0.33304422813355006\n",
      "49 71 0.4462810849290552\n",
      "49 121 0.4118429508991965\n",
      "Validation loss: 0.5871741444046734 MAE: 134.094\n",
      "50 0 0.3321418553220205\n",
      "50 50 0.35968789233870413\n",
      "50 100 0.2700056317750943\n",
      "50 150 0.3789602806529946\n",
      "Validation loss: 0.5215614817992985 MAE: 119.10991\n",
      "51 29 0.4091837014032797\n",
      "51 79 0.2587573189747043\n",
      "51 129 0.2847054688397084\n",
      "Validation loss: 0.45468762813255803 MAE: 103.837814\n",
      "52 8 0.29430853494472914\n",
      "52 58 0.44333707081264656\n",
      "52 108 0.38398197782224147\n",
      "52 158 0.3288365983481095\n",
      "Validation loss: 0.40500476921510975 MAE: 92.49165\n",
      "53 37 0.3781174368442712\n",
      "53 87 0.3740822727995992\n",
      "53 137 0.26406569421468606\n",
      "Validation loss: 0.5310415942766513 MAE: 121.27491\n",
      "54 16 0.4626560934575834\n",
      "54 66 0.3709089843441246\n",
      "54 116 0.3374497739864041\n",
      "54 166 0.2821544842102067\n",
      "Validation loss: 0.6144739173309147 MAE: 140.3285\n",
      "55 45 0.4074888128943053\n",
      "55 95 0.3366637881258318\n",
      "55 145 0.41344607343664774\n",
      "Validation loss: 0.5203082031673856 MAE: 118.82371\n",
      "56 24 0.31644710567637124\n",
      "56 74 0.33939708431770665\n",
      "56 124 0.4164933300327788\n",
      "Validation loss: 0.598254104106747 MAE: 136.62434\n",
      "57 3 0.4452200998069003\n",
      "57 53 0.27874025760016324\n",
      "57 103 0.38397830923112763\n",
      "57 153 0.33692881436040495\n",
      "Validation loss: 0.6433972339881094 MAE: 146.93376\n",
      "58 32 0.42612394125470293\n",
      "58 82 0.37160684824218226\n",
      "58 132 0.3233481247004111\n",
      "Validation loss: 0.6035211708462029 MAE: 137.8272\n",
      "59 11 0.5294728562823215\n",
      "59 61 0.38405668556912076\n",
      "59 111 0.35061273499344514\n",
      "59 161 0.32458433546885285\n",
      "Validation loss: 0.5312043843213577 MAE: 121.31209\n",
      "60 40 0.26029473268844927\n",
      "60 90 0.30865687760354493\n",
      "60 140 0.20418723138641873\n",
      "Validation loss: 0.4623283400521641 MAE: 105.58274\n",
      "61 19 0.40393451997219454\n",
      "61 69 0.45553164370174604\n",
      "61 119 0.3054680747136567\n",
      "61 169 0.45232293196364326\n",
      "Validation loss: 0.4569196728935019 MAE: 104.347565\n",
      "62 48 0.4058702557026764\n",
      "62 98 0.27651829329012956\n",
      "62 148 0.47368690771859684\n",
      "Validation loss: 0.5396879168978909 MAE: 123.24949\n",
      "63 27 0.42242482106977974\n",
      "63 77 0.34902105973048053\n",
      "63 127 0.29766560597980274\n",
      "Validation loss: 0.43856853386114913 MAE: 100.15666\n",
      "64 6 0.35023208977364834\n",
      "64 56 0.4794902797058807\n",
      "64 106 0.3663499132825347\n",
      "64 156 0.26051104634109323\n",
      "Validation loss: 0.6207156489815628 MAE: 141.75392\n",
      "65 35 0.3430675648136357\n",
      "65 85 0.37869380236682393\n",
      "65 135 0.5324025037527378\n",
      "Validation loss: 0.5183774945680161 MAE: 118.38279\n",
      "66 14 0.359463476134029\n",
      "66 64 0.3763258637234091\n",
      "66 114 0.3685457913731097\n",
      "66 164 0.248886090674976\n",
      "Validation loss: 0.5424683595958509 MAE: 123.88446\n",
      "67 43 0.4916669304182854\n",
      "67 93 0.3972977657058022\n",
      "67 143 0.3943808473113596\n",
      "Validation loss: 0.5501420402038865 MAE: 125.6369\n",
      "68 22 0.20020097747167878\n",
      "68 72 0.42923613033584845\n",
      "68 122 0.40676970223173176\n",
      "Validation loss: 0.5107599772207918 MAE: 116.64317\n",
      "69 1 0.4459528883113424\n",
      "69 51 0.45549186921210943\n",
      "69 101 0.4349032929054899\n",
      "69 151 0.31356818955080296\n",
      "Validation loss: 0.5097053688869142 MAE: 116.40232\n",
      "70 30 0.3918443561433342\n",
      "70 80 0.35119364805856984\n",
      "70 130 0.24333219860763014\n",
      "Validation loss: 0.5497573586235269 MAE: 125.549065\n",
      "71 9 0.357525784890067\n",
      "71 59 0.34791505473525125\n",
      "71 109 0.376122145917183\n",
      "71 159 0.6114697314514572\n",
      "Validation loss: 0.4611087723782188 MAE: 105.30423\n",
      "72 38 0.44840018674797655\n",
      "72 88 0.3485552636808663\n",
      "72 138 0.22274098508640106\n",
      "Validation loss: 0.4870235648071557 MAE: 111.22243\n",
      "73 17 0.30294367220010343\n",
      "73 67 0.4180632858223324\n",
      "73 117 0.5291473931622097\n",
      "73 167 0.46708105405837874\n",
      "Validation loss: 0.5649548653970685 MAE: 129.01974\n",
      "74 46 0.34959665255591665\n",
      "74 96 0.4121500249912136\n",
      "74 146 0.2594910904639378\n",
      "Validation loss: 0.5460248732427407 MAE: 124.69667\n",
      "75 25 0.2604965513871015\n",
      "75 75 0.37994406424976135\n",
      "75 125 0.4137354388445885\n",
      "Validation loss: 0.4219776925287749 MAE: 96.36778\n",
      "76 4 0.47363543371278993\n",
      "76 54 0.3467437815752489\n",
      "76 104 0.24077944734922332\n",
      "76 154 0.5119546353645579\n",
      "Validation loss: 0.6436366860629522 MAE: 146.98845\n",
      "77 33 0.4139556008393614\n",
      "77 83 0.3058044220037089\n",
      "77 133 0.2708385648202477\n",
      "Validation loss: 0.5290836817339847 MAE: 120.82778\n",
      "78 12 0.24100243766037127\n",
      "78 62 0.2136888059289971\n",
      "78 112 0.31178094603148016\n",
      "78 162 0.44715757204632767\n",
      "Validation loss: 0.5321296016026659 MAE: 121.52337\n",
      "79 41 0.29230045610668776\n",
      "79 91 0.43076343210945395\n",
      "79 141 0.20697042966773138\n",
      "Validation loss: 0.4426995449595981 MAE: 101.100075\n",
      "80 20 0.4362848024722883\n",
      "80 70 0.33471551956011325\n",
      "80 120 0.46624244326991104\n",
      "80 170 0.2828726594426709\n",
      "Validation loss: 0.5146177571419387 MAE: 117.52417\n",
      "81 49 0.4167811718192289\n",
      "81 99 0.37709146669581833\n",
      "81 149 0.42220883487256633\n",
      "Validation loss: 0.6089346332159656 MAE: 139.06348\n",
      "82 28 0.46172184179014936\n",
      "82 78 0.33406486065611213\n",
      "82 128 0.309315663627022\n",
      "Validation loss: 0.6116586256096934 MAE: 139.68556\n",
      "83 7 0.33188171421627893\n",
      "83 57 0.3557051952069495\n",
      "83 107 0.26480380045470964\n",
      "83 157 0.30971500203195834\n",
      "Validation loss: 0.5509591649847421 MAE: 125.823524\n",
      "84 36 0.3549342239019622\n",
      "84 86 0.41885421731549294\n",
      "84 136 0.3495297398850523\n",
      "Validation loss: 0.49993888066526043 MAE: 114.17193\n",
      "85 15 0.29194736874936433\n",
      "85 65 0.4830782208427583\n",
      "85 115 0.41909416137065447\n",
      "85 165 0.27377945986638685\n",
      "Validation loss: 0.6159927238497818 MAE: 140.67535\n",
      "86 44 0.29002913602171354\n",
      "86 94 0.39832603427932495\n",
      "86 144 0.2460848931941592\n",
      "Validation loss: 0.5111765206208703 MAE: 116.73829\n",
      "87 23 0.2963045283364323\n",
      "87 73 0.4018782820058215\n",
      "87 123 0.34537782652181037\n",
      "Validation loss: 0.5526577854714199 MAE: 126.21144\n",
      "88 2 0.3248193811016847\n",
      "88 52 0.3653199605941918\n",
      "88 102 0.6425258717891164\n",
      "88 152 0.29299184646494386\n",
      "Validation loss: 0.6053029413808856 MAE: 138.2341\n",
      "89 31 0.44894930198152244\n",
      "89 81 0.37633065746977845\n",
      "89 131 0.2891952156901315\n",
      "Validation loss: 0.4892844723330604 MAE: 111.73876\n",
      "90 10 0.34948057368465174\n",
      "90 60 0.2638570585136382\n",
      "90 110 0.3050561478679768\n",
      "90 160 0.23301451584597063\n",
      "Validation loss: 0.5105262252322414 MAE: 116.589775\n",
      "91 39 0.26507776956315415\n",
      "91 89 0.3327017881860334\n",
      "91 139 0.414225187832833\n",
      "Validation loss: 0.49621105908650404 MAE: 113.32061\n",
      "92 18 0.3488761637018002\n",
      "92 68 0.23624232785024668\n",
      "92 118 0.3547371340989207\n",
      "92 168 0.25138492336746354\n",
      "Validation loss: 0.5370616229654056 MAE: 122.64972\n",
      "93 47 0.27346646910530054\n",
      "93 97 0.3606901669983541\n",
      "93 147 0.2442032899454186\n",
      "Validation loss: 0.6214840969844171 MAE: 141.92943\n",
      "94 26 0.30764648258976063\n",
      "94 76 0.2711663420565822\n",
      "94 126 0.2515941494075993\n",
      "Validation loss: 0.573440435511327 MAE: 130.95761\n",
      "95 5 0.25129647212297324\n",
      "95 55 0.4319185749822346\n",
      "95 105 0.39860230872800956\n",
      "95 155 0.3989787754686706\n",
      "Validation loss: 0.4563972322564376 MAE: 104.22824\n",
      "96 34 0.4011853413880318\n",
      "96 84 0.24284246663278541\n",
      "96 134 0.25897286244766105\n",
      "Validation loss: 0.40645378200631394 MAE: 92.82257\n",
      "97 13 0.29944968901409197\n",
      "97 63 0.3047663993231776\n",
      "97 113 0.2563329526624686\n",
      "97 163 0.2832063280816976\n",
      "Validation loss: 0.600111676935564 MAE: 137.04858\n",
      "98 42 0.3143504528081405\n",
      "98 92 0.357732475963846\n",
      "98 142 0.30807678014215706\n",
      "Validation loss: 0.5876097762793825 MAE: 134.19348\n",
      "99 21 0.40430021813627137\n",
      "99 71 0.16521294661108613\n",
      "99 121 0.36261080992842254\n",
      "Validation loss: 0.6445018084425675 MAE: 147.18602\n",
      "100 0 0.3645496845033341\n",
      "100 50 0.3618632541634249\n",
      "100 100 0.345390885655698\n",
      "100 150 0.3706502110598515\n",
      "Validation loss: 0.8593668059298867 MAE: 196.25514\n",
      "101 29 0.3381558729739779\n",
      "101 79 0.3966815174142807\n",
      "101 129 0.4458519076364325\n",
      "Validation loss: 0.45372000493501363 MAE: 103.616844\n",
      "102 8 0.2784209087531482\n",
      "102 58 0.3313993649814194\n",
      "102 108 0.2813671472808211\n",
      "102 158 0.269921919785415\n",
      "Validation loss: 0.5322830091442978 MAE: 121.55841\n",
      "103 37 0.419509790012224\n",
      "103 87 0.38354304867386496\n",
      "103 137 0.3600209177991981\n",
      "Validation loss: 0.5725570798617358 MAE: 130.75587\n",
      "104 16 0.1998113159883972\n",
      "104 66 0.41498072961043575\n",
      "104 116 0.3045500171462979\n",
      "104 166 0.28659017110387447\n",
      "Validation loss: 0.5302042992491471 MAE: 121.08369\n",
      "105 45 0.3662151620646342\n",
      "105 95 0.36728386896892923\n",
      "105 145 0.38568976933631616\n",
      "Validation loss: 0.48146134928653117 MAE: 109.95219\n",
      "106 24 0.3405833577782858\n",
      "106 74 0.27016881132856724\n",
      "106 124 0.3088879833639959\n",
      "Validation loss: 0.55814818750348 MAE: 127.46529\n",
      "107 3 0.35443863317879987\n",
      "107 53 0.32063049964464707\n",
      "107 103 0.21684121977822782\n",
      "107 153 0.20200373925579754\n",
      "Validation loss: 0.5865072831075792 MAE: 133.9417\n",
      "108 32 0.2339801944107173\n",
      "108 82 0.37984853595123325\n",
      "108 132 0.3220930925958148\n",
      "Validation loss: 0.5362324920314098 MAE: 122.460365\n",
      "109 11 0.3722632016064269\n",
      "109 61 0.25553659675578927\n",
      "109 111 0.4006073880482723\n",
      "109 161 0.28933368015244393\n",
      "Validation loss: 0.5947415779905709 MAE: 135.82219\n",
      "110 40 0.21006561484046635\n",
      "110 90 0.34993538720394424\n",
      "110 140 0.26735752374233274\n",
      "Validation loss: 0.6142139222189696 MAE: 140.26912\n",
      "111 19 0.3438299716955206\n",
      "111 69 0.4205357011148543\n",
      "111 119 0.3000228405502785\n",
      "111 169 0.30830315671554737\n",
      "Validation loss: 0.5954116819894801 MAE: 135.97522\n",
      "112 48 0.4528929918410751\n",
      "112 98 0.42352552414578926\n",
      "112 148 0.451330024122296\n",
      "Validation loss: 0.6030940427417644 MAE: 137.72968\n",
      "113 27 0.21199508589633723\n",
      "113 77 0.42009137337973557\n",
      "113 127 0.29273723137046725\n",
      "Validation loss: 0.5132080539625291 MAE: 117.20223\n",
      "114 6 0.3091703894833761\n",
      "114 56 0.26356978722415075\n",
      "114 106 0.24977445059577683\n",
      "114 156 0.35747730347143203\n",
      "Validation loss: 0.5863295901588529 MAE: 133.90114\n",
      "115 35 0.2956365484391585\n",
      "115 85 0.2529458443391159\n",
      "115 135 0.3530186651754457\n",
      "Validation loss: 0.5875783377920675 MAE: 134.18631\n",
      "116 14 0.29663475058542293\n",
      "116 64 0.31850605200159726\n",
      "116 114 0.36274929506003434\n",
      "116 164 0.331722069176528\n",
      "Validation loss: 0.5579639220098306 MAE: 127.42321\n",
      "117 43 0.33970915136561786\n",
      "117 93 0.43000297035463825\n",
      "117 143 0.3446558059677442\n",
      "Validation loss: 0.6081894057535986 MAE: 138.89328\n",
      "118 22 0.38772682554518\n",
      "118 72 0.3621082215250608\n",
      "118 122 0.32904392619007483\n",
      "Validation loss: 0.5060903182503773 MAE: 115.57673\n",
      "119 1 0.21251935630057295\n",
      "119 51 0.26029651148167243\n",
      "119 101 0.4200890264752758\n",
      "119 151 0.23948967192755022\n",
      "Validation loss: 0.6542786527098271 MAE: 149.41878\n",
      "120 30 0.2792757743679845\n",
      "120 80 0.3040222785211495\n",
      "120 130 0.335164732617496\n",
      "Validation loss: 0.5615528794059976 MAE: 128.24283\n",
      "121 9 0.17927733966321616\n",
      "121 59 0.33454885286772895\n",
      "121 109 0.3848272202927771\n",
      "121 159 0.27567579790697194\n",
      "Validation loss: 0.62597776365559 MAE: 142.95566\n",
      "122 38 0.18280808564450454\n",
      "122 88 0.219905819373506\n",
      "122 138 0.2345405646442018\n",
      "Validation loss: 0.6978165336519654 MAE: 159.3616\n",
      "123 17 0.2809882775323327\n",
      "123 67 0.4138146448353354\n",
      "123 117 0.4366177578625729\n",
      "123 167 0.29202285311923937\n",
      "Validation loss: 0.6525253203877232 MAE: 149.01837\n",
      "124 46 0.4159740327369997\n",
      "124 96 0.3558682991220699\n",
      "124 146 0.5105814526153927\n",
      "Validation loss: 0.6830834659219486 MAE: 155.99698\n",
      "125 25 0.46763732103643096\n",
      "125 75 0.49827078061048247\n",
      "125 125 0.2446952607031194\n",
      "Validation loss: 0.5296685894330343 MAE: 120.96135\n",
      "126 4 0.36976071199195676\n",
      "126 54 0.2743254472140401\n",
      "126 104 0.2655390956222846\n",
      "126 154 0.2874453394033296\n",
      "Validation loss: 0.5920092161984472 MAE: 135.1982\n",
      "127 33 0.2090546321875518\n",
      "127 83 0.25797066575360456\n",
      "127 133 0.32347330973892235\n",
      "Validation loss: 0.6235126689163565 MAE: 142.3927\n",
      "128 12 0.5288149500363544\n",
      "128 62 0.3853681630004883\n",
      "128 112 0.3080971184004765\n",
      "128 162 0.4358021630088358\n",
      "Validation loss: 0.4992601505497046 MAE: 114.016914\n",
      "129 41 0.3330736862201979\n",
      "129 91 0.28981637116355424\n",
      "129 141 0.2956332637147253\n",
      "Validation loss: 0.6708291897996824 MAE: 153.19846\n",
      "130 20 0.26245284131628227\n",
      "130 70 0.2515366126421676\n",
      "130 120 0.28329479823452164\n",
      "130 170 0.3000343835591246\n",
      "Validation loss: 0.4941537638156735 MAE: 112.85076\n",
      "131 49 0.34101781890870614\n",
      "131 99 0.24341943885657397\n",
      "131 149 0.3085759064979004\n",
      "Validation loss: 0.5579434166177671 MAE: 127.418526\n",
      "132 28 0.2651303943771169\n",
      "132 78 0.3532411533202095\n",
      "132 128 0.21339357680653143\n",
      "Validation loss: 0.5712751833318966 MAE: 130.46313\n",
      "133 7 0.39874041468646276\n",
      "133 57 0.3128537821376417\n",
      "133 107 0.2581556020301289\n",
      "133 157 0.20477839512602092\n",
      "Validation loss: 0.509645836743695 MAE: 116.388725\n",
      "134 36 0.2597574658546959\n",
      "134 86 0.29137865908421906\n",
      "134 136 0.2728977617068053\n",
      "Validation loss: 0.6343944689683747 MAE: 144.87779\n",
      "135 15 0.24588593529753905\n",
      "135 65 0.25477710569927003\n",
      "135 115 0.3587707413257623\n",
      "135 165 0.20008680425046435\n",
      "Validation loss: 0.5641075379667226 MAE: 128.82625\n",
      "136 44 0.4346324987041621\n",
      "136 94 0.2652878573562661\n",
      "136 144 0.36288604095427607\n",
      "Validation loss: 0.6321723218898327 MAE: 144.37032\n",
      "137 23 0.29097200095222536\n",
      "137 73 0.4237448776479498\n",
      "137 123 0.4282457414896818\n",
      "Validation loss: 0.6641402188797443 MAE: 151.67088\n",
      "138 2 0.23794526750462608\n",
      "138 52 0.31003628573508013\n",
      "138 102 0.17263793034231822\n",
      "138 152 0.2615666082550947\n",
      "Validation loss: 0.6019524747168111 MAE: 137.46895\n",
      "139 31 0.2438229784995234\n",
      "139 81 0.5215650821777916\n",
      "139 131 0.28850225662424156\n",
      "Validation loss: 0.5456128770496413 MAE: 124.60258\n",
      "140 10 0.2910924754813082\n",
      "140 60 0.3343743779358701\n",
      "140 110 0.18779149177374893\n",
      "140 160 0.3074902876124225\n",
      "Validation loss: 0.4826603653835274 MAE: 110.226006\n",
      "141 39 0.25663627340490736\n",
      "141 89 0.40632745612578924\n",
      "141 139 0.24677341547612858\n",
      "Validation loss: 0.5983572787011576 MAE: 136.64792\n",
      "142 18 0.3087875733475505\n",
      "142 68 0.3445692500247602\n",
      "142 118 0.3873803791030412\n",
      "142 168 0.3633694638111215\n",
      "Validation loss: 0.586715847428082 MAE: 133.98933\n",
      "143 47 0.40574854253944864\n",
      "143 97 0.3277717194409277\n",
      "143 147 0.3444532440031078\n",
      "Validation loss: 0.5972076814774184 MAE: 136.38538\n",
      "144 26 0.3757906111778021\n",
      "144 76 0.35354256271947143\n",
      "144 126 0.35273041441311315\n",
      "Validation loss: 0.5568513884181865 MAE: 127.169136\n",
      "145 5 0.35330625199401106\n",
      "145 55 0.2619309573729835\n",
      "145 105 0.2348566706659306\n",
      "145 155 0.3868916751797785\n",
      "Validation loss: 0.4880918844750053 MAE: 111.46641\n",
      "146 34 0.29791240987643186\n",
      "146 84 0.3029587980945811\n",
      "146 134 0.19626198034090894\n",
      "Validation loss: 0.5659200643238268 MAE: 129.24017\n",
      "147 13 0.3587520780452817\n",
      "147 63 0.4399911606806891\n",
      "147 113 0.28634241922200737\n",
      "147 163 0.3045018512774802\n",
      "Validation loss: 0.6652362541845668 MAE: 151.92117\n",
      "148 42 0.3267626915084063\n",
      "148 92 0.37839881558339783\n",
      "148 142 0.16786726827139203\n",
      "Validation loss: 0.5253770239869057 MAE: 119.98128\n",
      "149 21 0.3087607662970234\n",
      "149 71 0.15529605078402686\n",
      "149 121 0.4113258204753694\n",
      "Validation loss: 0.5785981353960539 MAE: 132.13548\n",
      "150 0 0.39990408160288443\n",
      "150 50 0.20588169815990648\n",
      "150 100 0.45135580244168594\n",
      "150 150 0.31051106357513797\n",
      "Validation loss: 0.5048579413291306 MAE: 115.295296\n",
      "151 29 0.22732816026856467\n",
      "151 79 0.1737294467781976\n",
      "151 129 0.18549831667718045\n",
      "Validation loss: 0.5818758856134805 MAE: 132.88402\n",
      "152 8 0.3229789024233662\n",
      "152 58 0.1985303978399558\n",
      "152 108 0.2810458864005859\n",
      "152 158 0.22007258860372247\n",
      "Validation loss: 0.632891561552795 MAE: 144.53458\n",
      "153 37 0.2651389492007946\n",
      "153 87 0.3170394108436603\n",
      "153 137 0.2865892595988204\n",
      "Validation loss: 0.5943732066461217 MAE: 135.73805\n",
      "154 16 0.3259365477193526\n",
      "154 66 0.16600617988880959\n",
      "154 116 0.1800430952883415\n",
      "154 166 0.30314012350598973\n",
      "Validation loss: 0.6489036438757914 MAE: 148.19127\n",
      "155 45 0.21042248758286047\n",
      "155 95 0.22705256319738454\n",
      "155 145 0.3532926762694655\n",
      "Validation loss: 0.6144560554571319 MAE: 140.32442\n",
      "156 24 0.34435119953812515\n",
      "156 74 0.19925753979456035\n",
      "156 124 0.38190503850759866\n",
      "Validation loss: 0.6176729383524399 MAE: 141.05907\n",
      "157 3 0.2509956200118955\n",
      "157 53 0.27643963348334716\n",
      "157 103 0.24350964082099597\n",
      "157 153 0.2756829017188521\n",
      "Validation loss: 0.7591721122724968 MAE: 173.37347\n",
      "158 32 0.25793557199350514\n",
      "158 82 0.22230365496216423\n",
      "158 132 0.299675104900065\n",
      "Validation loss: 0.6118481702971876 MAE: 139.72885\n",
      "159 11 0.24941400709981917\n",
      "159 61 0.39150226994821763\n",
      "159 111 0.26340593525064593\n",
      "159 161 0.31838555905601074\n",
      "Validation loss: 0.6444486038029542 MAE: 147.17389\n",
      "160 40 0.44479049039581875\n",
      "160 90 0.35713591986791143\n",
      "160 140 0.2692596979463902\n",
      "Validation loss: 0.5927923792286923 MAE: 135.37704\n",
      "161 19 0.18119202559742723\n",
      "161 69 0.38944672047333934\n",
      "161 119 0.34008995748020726\n",
      "161 169 0.41476909257360756\n",
      "Validation loss: 0.640598021752653 MAE: 146.2945\n",
      "162 48 0.24255614940222658\n",
      "162 98 0.3514957537494466\n",
      "162 148 0.34253865315630877\n",
      "Validation loss: 0.6124786413901033 MAE: 139.87283\n",
      "163 27 0.22478152184222588\n",
      "163 77 0.218990353205585\n",
      "163 127 0.202317570576467\n",
      "Validation loss: 0.6033897225619756 MAE: 137.7972\n",
      "164 6 0.3857030497793264\n",
      "164 56 0.17485621449543795\n",
      "164 106 0.3919367296226697\n",
      "164 156 0.43404096767133576\n",
      "Validation loss: 0.6349998363974498 MAE: 145.01604\n",
      "165 35 0.2722929031028283\n",
      "165 85 0.4224769979289352\n",
      "165 135 0.29342500495110985\n",
      "Validation loss: 0.5757639394168965 MAE: 131.48824\n",
      "166 14 0.3768477702684914\n",
      "166 64 0.21105468232134572\n",
      "166 114 0.32192334372527975\n",
      "166 164 0.2979492150122608\n",
      "Validation loss: 0.5133695323564853 MAE: 117.239105\n",
      "167 43 0.19522134852033582\n",
      "167 93 0.19339211542019105\n",
      "167 143 0.3952693644806535\n",
      "Validation loss: 0.613879728735539 MAE: 140.1928\n",
      "168 22 0.33920526574020626\n",
      "168 72 0.41193003654391064\n",
      "168 122 0.30322636615507115\n",
      "Validation loss: 0.6621052458969473 MAE: 151.20615\n",
      "169 1 0.3094321425329836\n",
      "169 51 0.2000095843740605\n",
      "169 101 0.1602853601643053\n",
      "169 151 0.2833904665093972\n",
      "Validation loss: 0.5659323325979779 MAE: 129.24297\n",
      "170 30 0.17508163129562113\n",
      "170 80 0.2342622313277093\n",
      "170 130 0.1962359263623623\n",
      "Validation loss: 0.5509231704020361 MAE: 125.81531\n",
      "171 9 0.3949209953128858\n",
      "171 59 0.1877848034932593\n",
      "171 109 0.20737118055555626\n",
      "171 159 0.43929961691043257\n",
      "Validation loss: 0.6365153859233299 MAE: 145.36215\n",
      "172 38 0.4057879716718228\n",
      "172 88 0.30658517262270574\n",
      "172 138 0.269210037683488\n",
      "Validation loss: 0.6808672515969527 MAE: 155.49086\n",
      "173 17 0.20204583806867957\n",
      "173 67 0.29248280349040795\n",
      "173 117 0.2823887697396902\n",
      "173 167 0.3459848273964334\n",
      "Validation loss: 0.5895509970815558 MAE: 134.63681\n",
      "174 46 0.31789075636473413\n",
      "174 96 0.22709626538248653\n",
      "174 146 0.36873419635039745\n",
      "Validation loss: 0.7609060640223542 MAE: 173.76947\n",
      "175 25 0.29148360354813907\n",
      "175 75 0.3253783122574774\n",
      "175 125 0.31705562205344606\n",
      "Validation loss: 0.5296886706212808 MAE: 120.96594\n",
      "176 4 0.2259365888801878\n",
      "176 54 0.22452287365259183\n",
      "176 104 0.4102226837802191\n",
      "176 154 0.5186457891709291\n",
      "Validation loss: 0.5584959307609246 MAE: 127.54471\n",
      "177 33 0.20414182734501668\n",
      "177 83 0.26156406359897577\n",
      "177 133 0.41154924824737654\n",
      "Validation loss: 0.5998729657359988 MAE: 136.99406\n",
      "178 12 0.2820220082363595\n",
      "178 62 0.3956150583670429\n",
      "178 112 0.3187499908576689\n",
      "178 162 0.3117286903041425\n",
      "Validation loss: 0.5978007654697575 MAE: 136.52083\n",
      "179 41 0.278672634241563\n",
      "179 91 0.3245382528884075\n",
      "179 141 0.3012584716258954\n",
      "Validation loss: 0.5765692589924349 MAE: 131.67215\n",
      "180 20 0.29791458740881366\n",
      "180 70 0.22553789463286045\n",
      "180 120 0.3729255848330067\n",
      "180 170 0.3765318998420825\n",
      "Validation loss: 0.6181726553286725 MAE: 141.17317\n",
      "181 49 0.36190152425475636\n",
      "181 99 0.18197131288806057\n",
      "181 149 0.25290113886615595\n",
      "Validation loss: 0.5528413946168464 MAE: 126.25336\n",
      "182 28 0.2470179749941993\n",
      "182 78 0.30584574116331553\n",
      "182 128 0.1662905258779214\n",
      "Validation loss: 0.559328127674192 MAE: 127.73475\n",
      "183 7 0.25434345440006295\n",
      "183 57 0.22661290468779527\n",
      "183 107 0.44696988343612987\n",
      "183 157 0.3029230659107085\n",
      "Validation loss: 0.6054567753920082 MAE: 138.26924\n",
      "184 36 0.2718633231206969\n",
      "184 86 0.2331667567996757\n",
      "184 136 0.22868363229084918\n",
      "Validation loss: 0.6291666592073719 MAE: 143.68391\n",
      "185 15 0.2595886389338398\n",
      "185 65 0.12615163064703488\n",
      "185 115 0.25756345038105843\n",
      "185 165 0.32231275609060905\n",
      "Validation loss: 0.6359005887605991 MAE: 145.22176\n",
      "186 44 0.36207932475163934\n",
      "186 94 0.22388492716703795\n",
      "186 144 0.2892466959461544\n",
      "Validation loss: 0.6080375909805298 MAE: 138.85863\n",
      "187 23 0.2382899994962858\n",
      "187 73 0.26782891083687776\n",
      "187 123 0.23402567924388287\n",
      "Validation loss: 0.6569034413636079 MAE: 150.0182\n",
      "188 2 0.17726825531098886\n",
      "188 52 0.3996307500893942\n",
      "188 102 0.5176085959857089\n",
      "188 152 0.3118502599447457\n",
      "Validation loss: 0.6226620409223769 MAE: 142.19843\n",
      "189 31 0.25471788560719605\n",
      "189 81 0.34912837839296507\n",
      "189 131 0.5046241142431991\n",
      "Validation loss: 0.4945083138538383 MAE: 112.93174\n",
      "190 10 0.3737578157749596\n",
      "190 60 0.16535344855469927\n",
      "190 110 0.42769292670112136\n",
      "190 160 0.3322851281566979\n",
      "Validation loss: 0.5177303632797553 MAE: 118.235\n",
      "191 39 0.4202638021733058\n",
      "191 89 0.20506917189413518\n",
      "191 139 0.27550389066457165\n",
      "Validation loss: 0.6065083553916529 MAE: 138.50938\n",
      "192 18 0.3195660637748378\n",
      "192 68 0.1884919278242289\n",
      "192 118 0.3343240738149112\n",
      "192 168 0.22928391163049336\n",
      "Validation loss: 0.6274285832343743 MAE: 143.28699\n",
      "193 47 0.34870205275186755\n",
      "193 97 0.33926092613006237\n",
      "193 147 0.21807136551412115\n",
      "Validation loss: 0.5199735663090533 MAE: 118.747284\n",
      "194 26 0.22718044353538316\n",
      "194 76 0.29044493208662875\n",
      "194 126 0.2831672813589069\n",
      "Validation loss: 0.6145437631690711 MAE: 140.34445\n",
      "195 5 0.2537375530251064\n",
      "195 55 0.16647308529443583\n",
      "195 105 0.3511358947498377\n",
      "195 155 0.28225321050359314\n",
      "Validation loss: 0.5293356106992353 MAE: 120.8853\n",
      "196 34 0.23262092888583302\n",
      "196 84 0.18243994557803828\n",
      "196 134 0.39263675744564036\n",
      "Validation loss: 0.5150227961484451 MAE: 117.61666\n",
      "197 13 0.23187914556960434\n",
      "197 63 0.24081433222704973\n",
      "197 113 0.281185836026771\n",
      "197 163 0.4288011129754762\n",
      "Validation loss: 0.5400063991546631 MAE: 123.32222\n",
      "198 42 0.2297279586647223\n",
      "198 92 0.25699078446178003\n",
      "198 142 0.31205035507579504\n",
      "Validation loss: 0.5450477202733358 MAE: 124.47351\n",
      "199 21 0.3230390814966436\n",
      "199 71 0.30212424628981194\n",
      "199 121 0.449623695355715\n",
      "Validation loss: 0.5808590828326711 MAE: 132.65182\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.31666550470044286 Test MAE: 72.31746\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'qm7', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 779, 'task': 'regression', 'data_path': 'data/qm7/qm7.csv', 'target': ['u0_atom']}}\n",
      "Running on: cuda:1\n",
      "6833\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/6833\n",
      "Generating scaffold 1000/6833\n",
      "Generating scaffold 2000/6833\n",
      "Generating scaffold 3000/6833\n",
      "Generating scaffold 4000/6833\n",
      "Generating scaffold 5000/6833\n",
      "Generating scaffold 6000/6833\n",
      "About to sort in scaffold sets\n",
      "tensor(-1553.3462) tensor(228.3718) torch.Size([5466, 1])\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.3918563658240468\n",
      "0 50 0.6907995886842021\n",
      "0 100 0.7229374215696073\n",
      "0 150 0.7978455060502909\n",
      "Validation loss: 0.4355159658089019 MAE: 99.45954\n",
      "1 29 0.5846941348884337\n",
      "1 79 0.6348907997771209\n",
      "1 129 0.5231024078746814\n",
      "Validation loss: 0.5136099199802555 MAE: 117.29401\n",
      "2 8 0.47967341216469406\n",
      "2 58 0.7895793419851711\n",
      "2 108 0.7520098921603324\n",
      "2 158 0.3807302334165373\n",
      "Validation loss: 0.541389266649882 MAE: 123.63802\n",
      "3 37 0.7044915862572698\n",
      "3 87 0.4406297504091482\n",
      "3 137 0.619947295349863\n",
      "Validation loss: 0.49766007013488234 MAE: 113.65152\n",
      "4 16 0.40183967446895613\n",
      "4 66 0.5031869017755322\n",
      "4 116 0.46399127973799337\n",
      "4 166 0.584137568518253\n",
      "Validation loss: 0.42679270073684333 MAE: 97.4674\n",
      "5 45 0.48688431461432435\n",
      "5 95 0.6059760341820207\n",
      "5 145 0.5944136927995566\n",
      "Validation loss: 0.4304137599398518 MAE: 98.29435\n",
      "6 24 0.6210096515532112\n",
      "6 74 0.6443690287122628\n",
      "6 124 0.4729201019620734\n",
      "Validation loss: 0.4372829414947688 MAE: 99.863075\n",
      "7 3 0.6774101025174879\n",
      "7 53 0.4455900535329137\n",
      "7 103 0.6302572657139318\n",
      "7 153 0.37156848647542773\n",
      "Validation loss: 0.39008871661989314 MAE: 89.08525\n",
      "8 32 0.47116174454937126\n",
      "8 82 0.6638727996427835\n",
      "8 132 0.4315975175511467\n",
      "Validation loss: 0.3951607036311724 MAE: 90.243546\n",
      "9 11 0.7329750433640386\n",
      "9 61 0.5610108760563745\n",
      "9 111 0.5211982620388286\n",
      "9 161 0.5211675026351299\n",
      "Validation loss: 0.3770842639326352 MAE: 86.115395\n",
      "10 40 0.3891642741420921\n",
      "10 90 0.4394045078330247\n",
      "10 140 0.5579637272417727\n",
      "Validation loss: 0.567728998803953 MAE: 129.65327\n",
      "11 19 0.5086491267158005\n",
      "11 69 0.4964980300418031\n",
      "11 119 0.4603058637077304\n",
      "11 169 0.3623797920413523\n",
      "Validation loss: 0.4498252152350911 MAE: 102.72739\n",
      "12 48 0.32402441306361107\n",
      "12 98 0.440876065579196\n",
      "12 148 0.6459893182350585\n",
      "Validation loss: 0.4635991563922481 MAE: 105.87297\n",
      "13 27 0.5618940923639941\n",
      "13 77 0.35405564886943025\n",
      "13 127 0.40512637400535706\n",
      "Validation loss: 0.45626488449977853 MAE: 104.19803\n",
      "14 6 0.4789610223671532\n",
      "14 56 0.3775700292609992\n",
      "14 106 0.5715105664438961\n",
      "14 156 0.4611545261581085\n",
      "Validation loss: 0.4452580670167131 MAE: 101.68437\n",
      "15 35 0.5051831924881843\n",
      "15 85 0.5946215008052577\n",
      "15 135 0.3307495988974184\n",
      "Validation loss: 0.43491365320501274 MAE: 99.32201\n",
      "16 14 0.6055724683366744\n",
      "16 64 0.47341454264263816\n",
      "16 114 0.500149875902737\n",
      "16 164 0.48024463400732637\n",
      "Validation loss: 0.4993868756015398 MAE: 114.04587\n",
      "17 43 0.5732710665675977\n",
      "17 93 0.47001999231527325\n",
      "17 143 0.5904422003114969\n",
      "Validation loss: 0.42705975080791275 MAE: 97.5284\n",
      "18 22 0.5112043969556859\n",
      "18 72 0.561682911371218\n",
      "18 122 0.5208870796890477\n",
      "Validation loss: 0.42800755249826533 MAE: 97.744835\n",
      "19 1 0.5479670883530793\n",
      "19 51 0.4094205434717389\n",
      "19 101 0.37972013256908016\n",
      "19 151 0.39580572606971953\n",
      "Validation loss: 0.4542685660005313 MAE: 103.74212\n",
      "20 30 0.33649914706267114\n",
      "20 80 0.4572462566146077\n",
      "20 130 0.370294765336099\n",
      "Validation loss: 0.37173572688074835 MAE: 84.89395\n",
      "21 9 0.32746742411467716\n",
      "21 59 0.41651379528567173\n",
      "21 109 0.47944993318707985\n",
      "21 159 0.38343970815942235\n",
      "Validation loss: 0.4053496938002737 MAE: 92.57043\n",
      "22 38 0.4060356367338176\n",
      "22 88 0.5356189218045823\n",
      "22 138 0.7205365158158025\n",
      "Validation loss: 0.4267524205453215 MAE: 97.4582\n",
      "23 17 0.5390422025489914\n",
      "23 67 0.531616207318462\n",
      "23 117 0.4661324079401601\n",
      "23 167 0.403729755903936\n",
      "Validation loss: 0.43309997536285577 MAE: 98.90781\n",
      "24 46 0.4523634559229634\n",
      "24 96 0.46439660746377626\n",
      "24 146 0.2723371231559993\n",
      "Validation loss: 0.5605274665425395 MAE: 128.00865\n",
      "25 25 0.41381625711179\n",
      "25 75 0.2749902924724047\n",
      "25 125 0.3482179549517551\n",
      "Validation loss: 0.3785829802877025 MAE: 86.457664\n",
      "26 4 0.2774570075616421\n",
      "26 54 0.34281489020287975\n",
      "26 104 0.3191550173315734\n",
      "26 154 0.5283407417414726\n",
      "Validation loss: 0.39032529948050515 MAE: 89.139275\n",
      "27 33 0.37005646111199175\n",
      "27 83 0.5508951998136545\n",
      "27 133 0.4724559746548413\n",
      "Validation loss: 0.4549097749922011 MAE: 103.88855\n",
      "28 12 0.44318966861691234\n",
      "28 62 0.43854981994011355\n",
      "28 112 0.3242556028939306\n",
      "28 162 0.5505801710505259\n",
      "Validation loss: 0.5137954071948403 MAE: 117.33637\n",
      "29 41 0.2874802731096044\n",
      "29 91 0.3905771054886795\n",
      "29 141 0.32290165985454344\n",
      "Validation loss: 0.46753864295301384 MAE: 106.77261\n",
      "30 20 0.3729358951572693\n",
      "30 70 0.4241660013842012\n",
      "30 120 0.22503619319074672\n",
      "30 170 0.5499530770189514\n",
      "Validation loss: 0.4273118683469226 MAE: 97.58596\n",
      "31 49 0.4621383737413138\n",
      "31 99 0.39237980834917713\n",
      "31 149 0.3370664610657351\n",
      "Validation loss: 0.513768950749559 MAE: 117.33033\n",
      "32 28 0.28310759354901904\n",
      "32 78 0.31073257038774915\n",
      "32 128 0.4811122383137869\n",
      "Validation loss: 0.44292930291410076 MAE: 101.15255\n",
      "33 7 0.3254314930949233\n",
      "33 57 0.30316995796292096\n",
      "33 107 0.36252550501035913\n",
      "33 157 0.5213338411331557\n",
      "Validation loss: 0.407110039253681 MAE: 92.97244\n",
      "34 36 0.4420581251672883\n",
      "34 86 0.2616715817361358\n",
      "34 136 0.2601316696976942\n",
      "Validation loss: 0.4753342457333503 MAE: 108.552925\n",
      "35 15 0.47385242322738375\n",
      "35 65 0.502405678692085\n",
      "35 115 0.3533757881192559\n",
      "35 165 0.5294244766549215\n",
      "Validation loss: 0.4625653610592 MAE: 105.63688\n",
      "36 44 0.4343263066997161\n",
      "36 94 0.30127366545745415\n",
      "36 144 0.311046787186901\n",
      "Validation loss: 0.5034967962412806 MAE: 114.98445\n",
      "37 23 0.38133266943232275\n",
      "37 73 0.4383491188574694\n",
      "37 123 0.21046229733771873\n",
      "Validation loss: 0.4450659183730856 MAE: 101.64049\n",
      "38 2 0.22623396940267967\n",
      "38 52 0.3945198269596836\n",
      "38 102 0.4453290747048505\n",
      "38 152 0.35667920324242575\n",
      "Validation loss: 0.4278688216418551 MAE: 97.713165\n",
      "39 31 0.46021023896817354\n",
      "39 81 0.36536076154041686\n",
      "39 131 0.3715044526842356\n",
      "Validation loss: 0.5936990352401956 MAE: 135.5841\n",
      "40 10 0.2674966245846655\n",
      "40 60 0.27059540115729225\n",
      "40 110 0.5228928836481026\n",
      "40 160 0.35029006913218336\n",
      "Validation loss: 0.5440369070621959 MAE: 124.24267\n",
      "41 39 0.35121803176716554\n",
      "41 89 0.4050073072352606\n",
      "41 139 0.3404891991199082\n",
      "Validation loss: 0.5808872706011722 MAE: 132.65826\n",
      "42 18 0.28485178171427983\n",
      "42 68 0.2867651734998996\n",
      "42 118 0.36564948143238973\n",
      "42 168 0.4463695617325805\n",
      "Validation loss: 0.39880588546133877 MAE: 91.076004\n",
      "43 47 0.3672876744096927\n",
      "43 97 0.3190548001305718\n",
      "43 147 0.338653876887927\n",
      "Validation loss: 0.4579382622451113 MAE: 104.58017\n",
      "44 26 0.2693742203748389\n",
      "44 76 0.6693833760041645\n",
      "44 126 0.6178823136349082\n",
      "Validation loss: 0.5716142319796378 MAE: 130.54056\n",
      "45 5 0.5122442044079163\n",
      "45 55 0.33863473866138144\n",
      "45 105 0.335624075898068\n",
      "45 155 0.2986362403761393\n",
      "Validation loss: 0.7285915146097105 MAE: 166.38976\n",
      "46 34 0.2181723294456582\n",
      "46 84 0.352355646028655\n",
      "46 134 0.312927271628667\n",
      "Validation loss: 0.5557950219215705 MAE: 126.927895\n",
      "47 13 0.4096363498871205\n",
      "47 63 0.4936410771510101\n",
      "47 113 0.43526260579133874\n",
      "47 163 0.5983914870038055\n",
      "Validation loss: 0.5935760813149792 MAE: 135.55603\n",
      "48 42 0.4717117604372896\n",
      "48 92 0.2873793705512101\n",
      "48 142 0.4272290478403649\n",
      "Validation loss: 0.48186160702454417 MAE: 110.04359\n",
      "49 21 0.44799827977621426\n",
      "49 71 0.39258765675506313\n",
      "49 121 0.48326417358135676\n",
      "Validation loss: 0.5314263687496297 MAE: 121.36278\n",
      "50 0 0.6759768542681209\n",
      "50 50 0.41114018511216427\n",
      "50 100 0.45743898375191083\n",
      "50 150 0.28034902945039425\n",
      "Validation loss: 0.5319477717081705 MAE: 121.48185\n",
      "51 29 0.4903542796944721\n",
      "51 79 0.3015879615881955\n",
      "51 129 0.27380401757752065\n",
      "Validation loss: 0.5317247647639604 MAE: 121.43092\n",
      "52 8 0.33899075951207175\n",
      "52 58 0.40936694963657677\n",
      "52 108 0.31682980621583645\n",
      "52 158 0.2858796281418639\n",
      "Validation loss: 0.548808717588235 MAE: 125.33242\n",
      "53 37 0.3333381721572501\n",
      "53 87 0.3884919488211102\n",
      "53 137 0.2954244047014846\n",
      "Validation loss: 0.48465665320903933 MAE: 110.6819\n",
      "54 16 0.3462483602943668\n",
      "54 66 0.47953493054450436\n",
      "54 116 0.383199440294453\n",
      "54 166 0.39886312039264493\n",
      "Validation loss: 0.3944025710660812 MAE: 90.07041\n",
      "55 45 0.43852096222552833\n",
      "55 95 0.5145361612285441\n",
      "55 145 0.5205301055635245\n",
      "Validation loss: 0.5234514621266148 MAE: 119.54153\n",
      "56 24 0.1554934020382724\n",
      "56 74 0.40493615090365337\n",
      "56 124 0.4741619551015312\n",
      "Validation loss: 0.5340190298027463 MAE: 121.954865\n",
      "57 3 0.4317394587091521\n",
      "57 53 0.3173125869152287\n",
      "57 103 0.5582892903347693\n",
      "57 153 0.368782087932484\n",
      "Validation loss: 0.5215149354516414 MAE: 119.099304\n",
      "58 32 0.32049200669871153\n",
      "58 82 0.38169262204840626\n",
      "58 132 0.5169282179105156\n",
      "Validation loss: 0.5969268941042716 MAE: 136.32124\n",
      "59 11 0.49183683366365333\n",
      "59 61 0.4333608805770542\n",
      "59 111 0.21216549249424996\n",
      "59 161 0.4491519818060627\n",
      "Validation loss: 0.47243459984573005 MAE: 107.890724\n",
      "60 40 0.30815148840997114\n",
      "60 90 0.289869032021588\n",
      "60 140 0.3075940249213267\n",
      "Validation loss: 0.53761529225355 MAE: 122.77615\n",
      "61 19 0.4391696146121252\n",
      "61 69 0.31534120113755776\n",
      "61 119 0.31717213078834766\n",
      "61 169 0.4116255740742454\n",
      "Validation loss: 0.5617408602558381 MAE: 128.28575\n",
      "62 48 0.28959066443184756\n",
      "62 98 0.2993940046768042\n",
      "62 148 0.36066894980651387\n",
      "Validation loss: 0.601330318297559 MAE: 137.32687\n",
      "63 27 0.3300348352159273\n",
      "63 77 0.34824258675029973\n",
      "63 127 0.38084831788590756\n",
      "Validation loss: 0.48320307159981535 MAE: 110.34994\n",
      "64 6 0.316618374658244\n",
      "64 56 0.4406070068744689\n",
      "64 106 0.549990436806985\n",
      "64 156 0.3179760503406927\n",
      "Validation loss: 0.46198858015718514 MAE: 105.50515\n",
      "65 35 0.2565569741548358\n",
      "65 85 0.44831985221811627\n",
      "65 135 0.36034705669699935\n",
      "Validation loss: 0.5821179336274577 MAE: 132.9393\n",
      "66 14 0.29509225164485114\n",
      "66 64 0.2754615551477699\n",
      "66 114 0.31693054493593625\n",
      "66 164 0.2860439529207833\n",
      "Validation loss: 0.4749225805028837 MAE: 108.45891\n",
      "67 43 0.398669066574508\n",
      "67 93 0.3049956178645266\n",
      "67 143 0.25171591674425264\n",
      "Validation loss: 0.4615119012475711 MAE: 105.39629\n",
      "68 22 0.43820960423371075\n",
      "68 72 0.3009458938865279\n",
      "68 122 0.3631250981299283\n",
      "Validation loss: 0.6541339043985334 MAE: 149.38573\n",
      "69 1 0.32818278707164117\n",
      "69 51 0.2333623594232348\n",
      "69 101 0.4672655458276962\n",
      "69 151 0.2782992088939896\n",
      "Validation loss: 0.5780762650116146 MAE: 132.0163\n",
      "70 30 0.3923394662780482\n",
      "70 80 0.35847287115539006\n",
      "70 130 0.22768380818246178\n",
      "Validation loss: 0.4124148003539147 MAE: 94.1839\n",
      "71 9 0.4157839255332539\n",
      "71 59 0.42243883502917523\n",
      "71 109 0.38570224124357094\n",
      "71 159 0.2278060288696563\n",
      "Validation loss: 0.6349823607338799 MAE: 145.01205\n",
      "72 38 0.3630934822556212\n",
      "72 88 0.3345222040337926\n",
      "72 138 0.4141545584182009\n",
      "Validation loss: 0.5620328447623559 MAE: 128.35243\n",
      "73 17 0.4537918655665204\n",
      "73 67 0.3865411072545982\n",
      "73 117 0.4405347740134668\n",
      "73 167 0.3921382841671957\n",
      "Validation loss: 0.5782383445062136 MAE: 132.05331\n",
      "74 46 0.2862961772032591\n",
      "74 96 0.492233564727321\n",
      "74 146 0.30309765258372096\n",
      "Validation loss: 0.5533538621071487 MAE: 126.3704\n",
      "75 25 0.41465078256844845\n",
      "75 75 0.3043338980036274\n",
      "75 125 0.4631111689294065\n",
      "Validation loss: 0.5661146239927638 MAE: 129.2846\n",
      "76 4 0.3931899951181397\n",
      "76 54 0.3476909118375388\n",
      "76 104 0.27365868476434063\n",
      "76 154 0.41956706630109214\n",
      "Validation loss: 0.4058539490950735 MAE: 92.68558\n",
      "77 33 0.5316435647585143\n",
      "77 83 0.3640654984765889\n",
      "77 133 0.3249937549949853\n",
      "Validation loss: 0.5194326095413744 MAE: 118.62374\n",
      "78 12 0.34254203743575634\n",
      "78 62 0.2831016941723177\n",
      "78 112 0.28386644914795295\n",
      "78 162 0.44289256329698395\n",
      "Validation loss: 0.5867954729593288 MAE: 134.00752\n",
      "79 41 0.6470047922348992\n",
      "79 91 0.3097732601935395\n",
      "79 141 0.3368143329213913\n",
      "Validation loss: 0.5028761064099987 MAE: 114.8427\n",
      "80 20 0.34163463068119443\n",
      "80 70 0.36738891270513224\n",
      "80 120 0.2780261939492211\n",
      "80 170 0.42779415291537093\n",
      "Validation loss: 0.48911907519513403 MAE: 111.70099\n",
      "81 49 0.39867525974515566\n",
      "81 99 0.28766359547440895\n",
      "81 149 0.35157855986750836\n",
      "Validation loss: 0.5140304694398802 MAE: 117.39005\n",
      "82 28 0.23726956945406982\n",
      "82 78 0.46560744343473615\n",
      "82 128 0.24983307803930943\n",
      "Validation loss: 0.5459656690993504 MAE: 124.68315\n",
      "83 7 0.28298398905460387\n",
      "83 57 0.29979178240295723\n",
      "83 107 0.36545225492600514\n",
      "83 157 0.24007741807265556\n",
      "Validation loss: 0.529949308487407 MAE: 121.02547\n",
      "84 36 0.4037749425311677\n",
      "84 86 0.5125754235999798\n",
      "84 136 0.3215081825920478\n",
      "Validation loss: 0.5109208285459998 MAE: 116.67989\n",
      "85 15 0.3680779147706812\n",
      "85 65 0.2567008014134885\n",
      "85 115 0.2935267957195757\n",
      "85 165 0.3996683120667476\n",
      "Validation loss: 0.58426875189731 MAE: 133.4305\n",
      "86 44 0.18707408451726393\n",
      "86 94 0.202316142720036\n",
      "86 144 0.27522502648326236\n",
      "Validation loss: 0.6349769970129805 MAE: 145.01083\n",
      "87 23 0.38021051851044313\n",
      "87 73 0.4363507893170909\n",
      "87 123 0.3448073092602664\n",
      "Validation loss: 0.5133736747050146 MAE: 117.24007\n",
      "88 2 0.21490366308048056\n",
      "88 52 0.48530770628205033\n",
      "88 102 0.39753225797649777\n",
      "88 152 0.2791064833198853\n",
      "Validation loss: 0.5428823382533782 MAE: 123.979004\n",
      "89 31 0.3571255968627684\n",
      "89 81 0.20988683106126133\n",
      "89 131 0.25610659122088886\n",
      "Validation loss: 0.6596508461829514 MAE: 150.64563\n",
      "90 10 0.5862468509006412\n",
      "90 60 0.2604932975518221\n",
      "90 110 0.3599983672271233\n",
      "90 160 0.2954375923783858\n",
      "Validation loss: 0.635254917089005 MAE: 145.07428\n",
      "91 39 0.2857524214174501\n",
      "91 89 0.28510958356940114\n",
      "91 139 0.45321901897568717\n",
      "Validation loss: 0.6351065332429451 MAE: 145.0404\n",
      "92 18 0.3173356241873741\n",
      "92 68 0.39765368015070407\n",
      "92 118 0.3260576185175545\n",
      "92 168 0.29501506275676176\n",
      "Validation loss: 0.5723734501509639 MAE: 130.71394\n",
      "93 47 0.327728270681029\n",
      "93 97 0.35885535731304136\n",
      "93 147 0.34473304338164545\n",
      "Validation loss: 0.6248104391042252 MAE: 142.68907\n",
      "94 26 0.3749324965954267\n",
      "94 76 0.38034140558320884\n",
      "94 126 0.2998470175160143\n",
      "Validation loss: 0.7132142527758727 MAE: 162.87799\n",
      "95 5 0.28326816920339853\n",
      "95 55 0.23230093021086284\n",
      "95 105 0.5234465205932267\n",
      "95 155 0.27668121122691935\n",
      "Validation loss: 0.5987152279469005 MAE: 136.72968\n",
      "96 34 0.21341195299306542\n",
      "96 84 0.3157122634607048\n",
      "96 134 0.19787593645743703\n",
      "Validation loss: 0.49102768842239825 MAE: 112.13686\n",
      "97 13 0.30737568023846745\n",
      "97 63 0.2718244481462569\n",
      "97 113 0.32947278682991693\n",
      "97 163 0.28255746362885825\n",
      "Validation loss: 0.5321758589897937 MAE: 121.533936\n",
      "98 42 0.29898227247061254\n",
      "98 92 0.3968617423667431\n",
      "98 142 0.1830109094911545\n",
      "Validation loss: 0.49634618264192726 MAE: 113.35146\n",
      "99 21 0.30650268235972733\n",
      "99 71 0.3175964105656583\n",
      "99 121 0.4287551536241088\n",
      "Validation loss: 0.5142188828591018 MAE: 117.43308\n",
      "100 0 0.3558831664467044\n",
      "100 50 0.32389685921514233\n",
      "100 100 0.3493709344092974\n",
      "100 150 0.32244944568546463\n",
      "Validation loss: 0.5035044359184845 MAE: 114.986206\n",
      "101 29 0.613561045299288\n",
      "101 79 0.20458255896593397\n",
      "101 129 0.42732444955939825\n",
      "Validation loss: 0.5380581948492262 MAE: 122.877304\n",
      "102 8 0.265183074967984\n",
      "102 58 0.3206877306884763\n",
      "102 108 0.404044879621338\n",
      "102 158 0.31324271051433444\n",
      "Validation loss: 0.5659908753389503 MAE: 129.25633\n",
      "103 37 0.3529519735891035\n",
      "103 87 0.3320544437188754\n",
      "103 137 0.2718270789516304\n",
      "Validation loss: 0.6010342608069816 MAE: 137.25925\n",
      "104 16 0.35229641924399774\n",
      "104 66 0.22973420304917394\n",
      "104 116 0.23671604665625803\n",
      "104 166 0.2859623553958281\n",
      "Validation loss: 0.4590404274170859 MAE: 104.83189\n",
      "105 45 0.5843581672369491\n",
      "105 95 0.2810035555255365\n",
      "105 145 0.3189304990230565\n",
      "Validation loss: 0.5827307376945228 MAE: 133.07927\n",
      "106 24 0.25118989825751425\n",
      "106 74 0.41958923944483095\n",
      "106 124 0.21203191327740373\n",
      "Validation loss: 0.7188032391475655 MAE: 164.15437\n",
      "107 3 0.29027471792782544\n",
      "107 53 0.2941454629981318\n",
      "107 103 0.25277046529559694\n",
      "107 153 0.4171500373249179\n",
      "Validation loss: 0.5826032147770039 MAE: 133.05013\n",
      "108 32 0.4332677551534657\n",
      "108 82 0.2938950997802042\n",
      "108 132 0.29388950311827805\n",
      "Validation loss: 0.6281141248362804 MAE: 143.44354\n",
      "109 11 0.30963128562469217\n",
      "109 61 0.3803162174989727\n",
      "109 111 0.24214103439976176\n",
      "109 161 0.267808097633412\n",
      "Validation loss: 0.5568423734770881 MAE: 127.167076\n",
      "110 40 0.19740969387008858\n",
      "110 90 0.4654485475675581\n",
      "110 140 0.4033891393314178\n",
      "Validation loss: 0.5684793922636244 MAE: 129.82465\n",
      "111 19 0.3810767788629615\n",
      "111 69 0.3817226848798595\n",
      "111 119 0.2241137180431588\n",
      "111 169 0.18639521001130127\n",
      "Validation loss: 0.6695579025480483 MAE: 152.90813\n",
      "112 48 0.3219862846781087\n",
      "112 98 0.17644266500440242\n",
      "112 148 0.3630055331776722\n",
      "Validation loss: 0.5070748512159314 MAE: 115.80158\n",
      "113 27 0.24777515639854414\n",
      "113 77 0.36598369243408807\n",
      "113 127 0.49259688198775686\n",
      "Validation loss: 0.6096124879100866 MAE: 139.21829\n",
      "114 6 0.4094997832468059\n",
      "114 56 0.2464872332443841\n",
      "114 106 0.25010283323726107\n",
      "114 156 0.28906395957397685\n",
      "Validation loss: 0.4880726309547647 MAE: 111.46201\n",
      "115 35 0.3346297748783567\n",
      "115 85 0.22283641249563463\n",
      "115 135 0.22630701334121947\n",
      "Validation loss: 0.5419482153061538 MAE: 123.76567\n",
      "116 14 0.5560586324113315\n",
      "116 64 0.19179644666074794\n",
      "116 114 0.2949345839759039\n",
      "116 164 0.2292047256877\n",
      "Validation loss: 0.7405937819453011 MAE: 169.13072\n",
      "117 43 0.3627003933851026\n",
      "117 93 0.33090719986045614\n",
      "117 143 0.25164941580747846\n",
      "Validation loss: 0.6643385078474792 MAE: 151.71617\n",
      "118 22 0.4466012652452941\n",
      "118 72 0.2811331260059873\n",
      "118 122 0.3438305889520297\n",
      "Validation loss: 0.5081918633472152 MAE: 116.05667\n",
      "119 1 0.28748373025974744\n",
      "119 51 0.37704991774134866\n",
      "119 101 0.28507068585649875\n",
      "119 151 0.3415843446343684\n",
      "Validation loss: 0.7137023510291562 MAE: 162.98947\n",
      "120 30 0.294490779504191\n",
      "120 80 0.3157730023235287\n",
      "120 130 0.28880047173276246\n",
      "Validation loss: 0.6241731936471504 MAE: 142.54353\n",
      "121 9 0.2778392084893208\n",
      "121 59 0.33029391034314315\n",
      "121 109 0.28049372875825335\n",
      "121 159 0.2612808245176275\n",
      "Validation loss: 0.6069355891113393 MAE: 138.60695\n",
      "122 38 0.32776046670817877\n",
      "122 88 0.3666493747402891\n",
      "122 138 0.5378322878216141\n",
      "Validation loss: 0.5925699360886513 MAE: 135.32625\n",
      "123 17 0.18339300156100571\n",
      "123 67 0.2966931915733531\n",
      "123 117 0.24634311894633348\n",
      "123 167 0.38959622396722104\n",
      "Validation loss: 0.582147751286713 MAE: 132.9461\n",
      "124 46 0.4185305065636179\n",
      "124 96 0.31941394154496644\n",
      "124 146 0.35895162902329236\n",
      "Validation loss: 0.4891852220596626 MAE: 111.7161\n",
      "125 25 0.298437654229982\n",
      "125 75 0.2637155679951103\n",
      "125 125 0.3556475577711963\n",
      "Validation loss: 0.5931985688488386 MAE: 135.4698\n",
      "126 4 0.20797498217412336\n",
      "126 54 0.31725505465555537\n",
      "126 104 0.42218100182070184\n",
      "126 154 0.28091992375764385\n",
      "Validation loss: 0.6798271937677037 MAE: 155.25334\n",
      "127 33 0.1478524426705456\n",
      "127 83 0.2480863785024677\n",
      "127 133 0.32861693108422146\n",
      "Validation loss: 0.6230794536439996 MAE: 142.29376\n",
      "128 12 0.3216038862194825\n",
      "128 62 0.3508185391231476\n",
      "128 112 0.39942475771644176\n",
      "128 162 0.39031853105127845\n",
      "Validation loss: 0.6123720891991554 MAE: 139.8485\n",
      "129 41 0.2621894020237041\n",
      "129 91 0.37314480274203904\n",
      "129 141 0.22104449909175514\n",
      "Validation loss: 0.5880109528351946 MAE: 134.2851\n",
      "130 20 0.3794525246235259\n",
      "130 70 0.31058213312768845\n",
      "130 120 0.3575318254748979\n",
      "130 170 0.18979175146346125\n",
      "Validation loss: 0.5437463574242174 MAE: 124.17631\n",
      "131 49 0.25593492996148304\n",
      "131 99 0.3944105221604745\n",
      "131 149 0.4301626084164377\n",
      "Validation loss: 0.5702189764781305 MAE: 130.22192\n",
      "132 28 0.2723600206228767\n",
      "132 78 0.31750490013456234\n",
      "132 128 0.2698663781327117\n",
      "Validation loss: 0.5528638613851447 MAE: 126.2585\n",
      "133 7 0.3005178552629874\n",
      "133 57 0.3969674402380517\n",
      "133 107 0.24525844436986574\n",
      "133 157 0.4479980625708136\n",
      "Validation loss: 0.65761495333666 MAE: 150.1807\n",
      "134 36 0.28903741073901773\n",
      "134 86 0.25261512150227455\n",
      "134 136 0.27060338729558636\n",
      "Validation loss: 0.5030820671229335 MAE: 114.88975\n",
      "135 15 0.3119710245612538\n",
      "135 65 0.13397432069683973\n",
      "135 115 0.38420763843798544\n",
      "135 165 0.2216586463121756\n",
      "Validation loss: 0.5765721442406637 MAE: 131.6728\n",
      "136 44 0.4239583171888314\n",
      "136 94 0.3186270032609553\n",
      "136 144 0.30441404759219687\n",
      "Validation loss: 0.5706443190574646 MAE: 130.31906\n",
      "137 23 0.18235005790133768\n",
      "137 73 0.28750907919182983\n",
      "137 123 0.35137038598799697\n",
      "Validation loss: 0.5588348957530239 MAE: 127.62212\n",
      "138 2 0.24497026155577536\n",
      "138 52 0.4068121030555812\n",
      "138 102 0.3574931280773018\n",
      "138 152 0.41288856883560554\n",
      "Validation loss: 0.5454157249272218 MAE: 124.55756\n",
      "139 31 0.2458627776549656\n",
      "139 81 0.20126225163603717\n",
      "139 131 0.25651681613086375\n",
      "Validation loss: 0.6361436815986856 MAE: 145.27728\n",
      "140 10 0.29198332003765554\n",
      "140 60 0.2639559672598555\n",
      "140 110 0.28905447263190326\n",
      "140 160 0.3713336808576445\n",
      "Validation loss: 0.663025947342142 MAE: 151.41641\n",
      "141 39 0.24125191036105215\n",
      "141 89 0.29597367888902865\n",
      "141 139 0.3469569603680637\n",
      "Validation loss: 0.6768081704078363 MAE: 154.56389\n",
      "142 18 0.2983121123467013\n",
      "142 68 0.4699036974171688\n",
      "142 118 0.2695493182105799\n",
      "142 168 0.24530298971849707\n",
      "Validation loss: 0.6136604150136312 MAE: 140.14272\n",
      "143 47 0.23392400803009988\n",
      "143 97 0.33067368365973\n",
      "143 147 0.3140385834032633\n",
      "Validation loss: 0.48823337596759464 MAE: 111.49872\n",
      "144 26 0.312613702980332\n",
      "144 76 0.2826246821461408\n",
      "144 126 0.253723222565264\n",
      "Validation loss: 0.5606729105899209 MAE: 128.04187\n",
      "145 5 0.2992868981647773\n",
      "145 55 0.2110510181337824\n",
      "145 105 0.22335428259672718\n",
      "145 155 0.4103312042317008\n",
      "Validation loss: 0.6578472389115227 MAE: 150.23373\n",
      "146 34 0.2937490759128823\n",
      "146 84 0.23045910949313703\n",
      "146 134 0.24193273417048256\n",
      "Validation loss: 0.539134430955028 MAE: 123.12308\n",
      "147 13 0.22898442494639423\n",
      "147 63 0.41676863864382424\n",
      "147 113 0.27448360423834606\n",
      "147 163 0.18256555522264814\n",
      "Validation loss: 0.5799263729686626 MAE: 132.43881\n",
      "148 42 0.2649725068760589\n",
      "148 92 0.3482552102880879\n",
      "148 142 0.17480014521704065\n",
      "Validation loss: 0.6274556277091043 MAE: 143.29315\n",
      "149 21 0.2732607039383388\n",
      "149 71 0.33200904722426167\n",
      "149 121 0.2318612059206289\n",
      "Validation loss: 0.6909501782634802 MAE: 157.79352\n",
      "150 0 0.27413018230072195\n",
      "150 50 0.47588162247644866\n",
      "150 100 0.28692519534904415\n",
      "150 150 0.21338726749088885\n",
      "Validation loss: 0.6359247722123799 MAE: 145.22726\n",
      "151 29 0.25593981024131496\n",
      "151 79 0.4580806128902985\n",
      "151 129 0.2809971191175441\n",
      "Validation loss: 0.6362150886602569 MAE: 145.29356\n",
      "152 8 0.2824626497503875\n",
      "152 58 0.5262680396084394\n",
      "152 108 0.3628352930371388\n",
      "152 158 0.3065919333372137\n",
      "Validation loss: 0.7355537777058563 MAE: 167.97972\n",
      "153 37 0.28839928889568095\n",
      "153 87 0.2503864159800796\n",
      "153 137 0.327370535507218\n",
      "Validation loss: 0.6285181707806058 MAE: 143.53581\n",
      "154 16 0.3034322744359951\n",
      "154 66 0.2618703057823898\n",
      "154 116 0.3586769544352288\n",
      "154 166 0.20513252405472787\n",
      "Validation loss: 0.6131655291507119 MAE: 140.0297\n",
      "155 45 0.47284071624193463\n",
      "155 95 0.2641359454829681\n",
      "155 145 0.26937854781011306\n",
      "Validation loss: 0.6575107797544603 MAE: 150.1569\n",
      "156 24 0.39085727149397753\n",
      "156 74 0.32194246434603385\n",
      "156 124 0.3217958755970993\n",
      "Validation loss: 0.5806900789166054 MAE: 132.61322\n",
      "157 3 0.28985026096228034\n",
      "157 53 0.44416294140425594\n",
      "157 103 0.2721534020353879\n",
      "157 153 0.15289625911189408\n",
      "Validation loss: 0.5238331467436071 MAE: 119.6287\n",
      "158 32 0.3242786194665336\n",
      "158 82 0.2022240342619582\n",
      "158 132 0.3422914823482373\n",
      "Validation loss: 0.5505500608368924 MAE: 125.73008\n",
      "159 11 0.49227751111948914\n",
      "159 61 0.28915286352557945\n",
      "159 111 0.28358937835786724\n",
      "159 161 0.33759722942002285\n",
      "Validation loss: 0.5857556298462271 MAE: 133.77005\n",
      "160 40 0.3062443980700375\n",
      "160 90 0.3163510003221354\n",
      "160 140 0.22950674184402\n",
      "Validation loss: 0.5736478448611254 MAE: 131.00497\n",
      "161 19 0.38843038670922264\n",
      "161 69 0.30425036864117566\n",
      "161 119 0.24868849130516432\n",
      "161 169 0.24375977187192352\n",
      "Validation loss: 0.590124173471105 MAE: 134.7677\n",
      "162 48 0.33130519798021263\n",
      "162 98 0.22673066540857306\n",
      "162 148 0.31895256702751507\n",
      "Validation loss: 0.5865889752817433 MAE: 133.96037\n",
      "163 27 0.17064819701422076\n",
      "163 77 0.2644568020673466\n",
      "163 127 0.24885427409891608\n",
      "Validation loss: 0.6138722910518535 MAE: 140.19112\n",
      "164 6 0.28639890743090346\n",
      "164 56 0.3075996054744369\n",
      "164 106 0.48641955661977915\n",
      "164 156 0.3636262561014913\n",
      "Validation loss: 0.5345227392444833 MAE: 122.0699\n",
      "165 35 0.3467204689231509\n",
      "165 85 0.42577284958898015\n",
      "165 135 0.29697006068781995\n",
      "Validation loss: 0.6044356448259968 MAE: 138.03604\n",
      "166 14 0.20491129822423507\n",
      "166 64 0.3167193780284394\n",
      "166 114 0.1381934831240487\n",
      "166 164 0.2103081170167075\n",
      "Validation loss: 0.6867955665142216 MAE: 156.84473\n",
      "167 43 0.17240522357256693\n",
      "167 93 0.3385527912156529\n",
      "167 143 0.3371160377812847\n",
      "Validation loss: 0.5907907726471884 MAE: 134.91994\n",
      "168 22 0.23580808643458304\n",
      "168 72 0.2629064238934943\n",
      "168 122 0.28228685761843225\n",
      "Validation loss: 0.664564695971751 MAE: 151.76782\n",
      "169 1 0.320201946853066\n",
      "169 51 0.32350370042297616\n",
      "169 101 0.2739653518689452\n",
      "169 151 0.42609011211211056\n",
      "Validation loss: 0.5740931396595916 MAE: 131.10667\n",
      "170 30 0.14252769411184288\n",
      "170 80 0.31493001674949767\n",
      "170 130 0.27588005067267557\n",
      "Validation loss: 0.6151287667235436 MAE: 140.47804\n",
      "171 9 0.35721160060019613\n",
      "171 59 0.35512422943186917\n",
      "171 109 0.15601366764155244\n",
      "171 159 0.35536083903538884\n",
      "Validation loss: 0.5754699110984802 MAE: 131.42108\n",
      "172 38 0.2565375937074648\n",
      "172 88 0.2530757810605162\n",
      "172 138 0.26274761364464155\n",
      "Validation loss: 0.6751181249730072 MAE: 154.17793\n",
      "173 17 0.3121175492621471\n",
      "173 67 0.23528884930242644\n",
      "173 117 0.17534878477558563\n",
      "173 167 0.4085467926616179\n",
      "Validation loss: 0.7102332533451549 MAE: 162.19724\n",
      "174 46 0.3887289912949685\n",
      "174 96 0.31647314309036456\n",
      "174 146 0.3822186630125298\n",
      "Validation loss: 0.5183504725757399 MAE: 118.376625\n",
      "175 25 0.2184591671422132\n",
      "175 75 0.3087221672448751\n",
      "175 125 0.16099346566513698\n",
      "Validation loss: 0.6195675423967908 MAE: 141.49176\n",
      "176 4 0.2860464007874181\n",
      "176 54 0.27076646101781277\n",
      "176 104 0.2232398335881627\n",
      "176 154 0.3550222379845247\n",
      "Validation loss: 0.4907017276998152 MAE: 112.06242\n",
      "177 33 0.2604042184443961\n",
      "177 83 0.29361957597945115\n",
      "177 133 0.3646564918954781\n",
      "Validation loss: 0.5990893143659447 MAE: 136.81508\n",
      "178 12 0.3300329473679135\n",
      "178 62 0.330344382201755\n",
      "178 112 0.36334402595936227\n",
      "178 162 0.23153635642637652\n",
      "Validation loss: 0.5542711347167255 MAE: 126.57989\n",
      "179 41 0.3015107786922594\n",
      "179 91 0.2517664801890078\n",
      "179 141 0.26255085126048805\n",
      "Validation loss: 0.46018355631688884 MAE: 105.092926\n",
      "180 20 0.30828239303576677\n",
      "180 70 0.3492385749665636\n",
      "180 120 0.25899331144056853\n",
      "180 170 0.2970901865795119\n",
      "Validation loss: 0.567218308734615 MAE: 129.53665\n",
      "181 49 0.26574122829438357\n",
      "181 99 0.2863854427326438\n",
      "181 149 0.2151698350758222\n",
      "Validation loss: 0.5141424846928022 MAE: 117.41564\n",
      "182 28 0.2971288885792828\n",
      "182 78 0.2931183631522606\n",
      "182 128 0.2556323639260438\n",
      "Validation loss: 0.5920849174086811 MAE: 135.21548\n",
      "183 7 0.39371947072145513\n",
      "183 57 0.39956715852849983\n",
      "183 107 0.24811510563360706\n",
      "183 157 0.39690924021803947\n",
      "Validation loss: 0.5845937986820064 MAE: 133.50473\n",
      "184 36 0.25315116780311225\n",
      "184 86 0.2221485523693139\n",
      "184 136 0.22934417914410404\n",
      "Validation loss: 0.5720780979820163 MAE: 130.64648\n",
      "185 15 0.2677406706978847\n",
      "185 65 0.31177467428833194\n",
      "185 115 0.3134586317014477\n",
      "185 165 0.39970028230196497\n",
      "Validation loss: 0.5173063281683894 MAE: 118.13816\n",
      "186 44 0.2696237136925372\n",
      "186 94 0.3478986893338793\n",
      "186 144 0.16886291333978395\n",
      "Validation loss: 0.5629096996714498 MAE: 128.5527\n",
      "187 23 0.32561249456498725\n",
      "187 73 0.4322992931252039\n",
      "187 123 0.4067386496255159\n",
      "Validation loss: 0.5768641198587696 MAE: 131.73947\n",
      "188 2 0.26060966508435685\n",
      "188 52 0.32382452819791246\n",
      "188 102 0.36539095829983453\n",
      "188 152 0.39228942133760786\n",
      "Validation loss: 0.5982961536150927 MAE: 136.63396\n",
      "189 31 0.28522176780682085\n",
      "189 81 0.23848085451043913\n",
      "189 131 0.24251579238332382\n",
      "Validation loss: 0.5085793740568105 MAE: 116.14517\n",
      "190 10 0.2599583853579333\n",
      "190 60 0.2924680542825518\n",
      "190 110 0.10850334921393645\n",
      "190 160 0.20498930382987296\n",
      "Validation loss: 0.6516188308160905 MAE: 148.81134\n",
      "191 39 0.216343880542547\n",
      "191 89 0.35530830733829843\n",
      "191 139 0.2459849314241569\n",
      "Validation loss: 0.5954576068454318 MAE: 135.98572\n",
      "192 18 0.32147928141487114\n",
      "192 68 0.4206561500359668\n",
      "192 118 0.221308862453323\n",
      "192 168 0.3846260120701718\n",
      "Validation loss: 0.6354486750580414 MAE: 145.11855\n",
      "193 47 0.2563549641782704\n",
      "193 97 0.1906883602098898\n",
      "193 147 0.2891802870548102\n",
      "Validation loss: 0.5725151338772467 MAE: 130.74629\n",
      "194 26 0.408067731809631\n",
      "194 76 0.2189202931963633\n",
      "194 126 0.26308232886178606\n",
      "Validation loss: 0.6197513885665358 MAE: 141.53372\n",
      "195 5 0.23018081189545944\n",
      "195 55 0.2829244616406615\n",
      "195 105 0.21070858251172273\n",
      "195 155 0.15007649332772893\n",
      "Validation loss: 0.7341295114734716 MAE: 167.65445\n",
      "196 34 0.3234359744449658\n",
      "196 84 0.23412218989253922\n",
      "196 134 0.3725361395566109\n",
      "Validation loss: 0.5272558021266558 MAE: 120.41034\n",
      "197 13 0.17449657856732934\n",
      "197 63 0.48044167011353917\n",
      "197 113 0.2340627450287644\n",
      "197 163 0.21097665891168046\n",
      "Validation loss: 0.6773106009639495 MAE: 154.67862\n",
      "198 42 0.2176394098824449\n",
      "198 92 0.2291031845779901\n",
      "198 142 0.23030576906229502\n",
      "Validation loss: 0.6551280342347441 MAE: 149.61276\n",
      "199 21 0.332309119930917\n",
      "199 71 0.33545595928120386\n",
      "199 121 0.1611610104135205\n",
      "Validation loss: 0.5617331886849208 MAE: 128.284\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.33268263770231915 Test MAE: 75.97533\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'qm7', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 780, 'task': 'regression', 'data_path': 'data/qm7/qm7.csv', 'target': ['u0_atom']}}\n",
      "Running on: cuda:1\n",
      "6833\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/6833\n",
      "Generating scaffold 1000/6833\n",
      "Generating scaffold 2000/6833\n",
      "Generating scaffold 3000/6833\n",
      "Generating scaffold 4000/6833\n",
      "Generating scaffold 5000/6833\n",
      "Generating scaffold 6000/6833\n",
      "About to sort in scaffold sets\n",
      "tensor(-1553.3462) tensor(228.3718) torch.Size([5466, 1])\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.6310558941498918\n",
      "0 50 0.7878320833691226\n",
      "0 100 0.6621311083617122\n",
      "0 150 0.5446775520844366\n",
      "Validation loss: 0.4940183873762164 MAE: 112.819855\n",
      "1 29 0.6461117921579637\n",
      "1 79 0.7202439493454358\n",
      "1 129 0.5191189234328905\n",
      "Validation loss: 0.4275628002414926 MAE: 97.64327\n",
      "2 8 0.6210420876334459\n",
      "2 58 0.5945092739477436\n",
      "2 108 0.5691539503484866\n",
      "2 158 0.5145395768619105\n",
      "Validation loss: 0.4395685349291528 MAE: 100.38504\n",
      "3 37 0.6037856396433404\n",
      "3 87 0.7400972689151272\n",
      "3 137 0.5927240126091775\n",
      "Validation loss: 0.39302724320986115 MAE: 89.756325\n",
      "4 16 0.5941307640106341\n",
      "4 66 0.5717687075571802\n",
      "4 116 0.7309945933831018\n",
      "4 166 0.6164853477812203\n",
      "Validation loss: 0.5257533783452553 MAE: 120.06724\n",
      "5 45 0.43800383023825773\n",
      "5 95 0.7435920995584454\n",
      "5 145 0.40419068900843663\n",
      "Validation loss: 0.3976743137627317 MAE: 90.81759\n",
      "6 24 0.5839637238211173\n",
      "6 74 0.5095324744979833\n",
      "6 124 0.6367238311969288\n",
      "Validation loss: 0.4158017666716325 MAE: 94.95738\n",
      "7 3 0.5417185336905628\n",
      "7 53 0.430047190343523\n",
      "7 103 0.5890219983368757\n",
      "7 153 0.5901341810586631\n",
      "Validation loss: 0.3774288887517494 MAE: 86.1941\n",
      "8 32 0.5910897690752919\n",
      "8 82 0.5669702951657325\n",
      "8 132 0.3704762355013777\n",
      "Validation loss: 0.4054042320502432 MAE: 92.582886\n",
      "9 11 0.374654962287691\n",
      "9 61 0.5930882054138444\n",
      "9 111 0.3439825828732624\n",
      "9 161 0.6382480802577915\n",
      "Validation loss: 0.4112099747211612 MAE: 93.908745\n",
      "10 40 0.5084700820379179\n",
      "10 90 0.7138010175478536\n",
      "10 140 0.39763265857976793\n",
      "Validation loss: 0.37169386385477077 MAE: 84.884384\n",
      "11 19 0.47688712249226184\n",
      "11 69 0.680804921369151\n",
      "11 119 0.47149039469155973\n",
      "11 169 0.5272690935631055\n",
      "Validation loss: 0.37518176140143855 MAE: 85.68092\n",
      "12 48 0.5926438801229146\n",
      "12 98 0.7150193206787223\n",
      "12 148 0.4472496443795529\n",
      "Validation loss: 0.4009466810881743 MAE: 91.564896\n",
      "13 27 0.5928662597476932\n",
      "13 77 0.5171071628275153\n",
      "13 127 0.4878221028987419\n",
      "Validation loss: 0.3767331463900226 MAE: 86.03521\n",
      "14 6 0.36836836161038394\n",
      "14 56 0.517524106359724\n",
      "14 106 0.4747900031594715\n",
      "14 156 0.571775825603978\n",
      "Validation loss: 0.502960617430726 MAE: 114.862015\n",
      "15 35 0.6252228265874231\n",
      "15 85 0.5318642977395996\n",
      "15 135 0.5391234476993937\n",
      "Validation loss: 0.4891277272798862 MAE: 111.702965\n",
      "16 14 0.5587718173788828\n",
      "16 64 0.38991958471152877\n",
      "16 114 0.5563712582287342\n",
      "16 164 0.42498613806953967\n",
      "Validation loss: 0.3938168395332426 MAE: 89.936646\n",
      "17 43 0.500228965214604\n",
      "17 93 0.4178263737228948\n",
      "17 143 0.34116440892690664\n",
      "Validation loss: 0.40677911356875773 MAE: 92.89686\n",
      "18 22 0.37664030848541113\n",
      "18 72 0.3339422861995516\n",
      "18 122 0.4957968345792184\n",
      "Validation loss: 0.48618060106422467 MAE: 111.02992\n",
      "19 1 0.5165380375131279\n",
      "19 51 0.3373779245712415\n",
      "19 101 0.6407536048972966\n",
      "19 151 0.31709320239140876\n",
      "Validation loss: 0.3924813211312768 MAE: 89.631645\n",
      "20 30 0.37228005790343505\n",
      "20 80 0.5513336122940583\n",
      "20 130 0.38321528886388334\n",
      "Validation loss: 0.42438162871968677 MAE: 96.91678\n",
      "21 9 0.4499916408406789\n",
      "21 59 0.29497281830446365\n",
      "21 109 0.3500234175854614\n",
      "21 159 0.39712576646918074\n",
      "Validation loss: 0.49258998994938813 MAE: 112.49365\n",
      "22 38 0.47843714032087403\n",
      "22 88 0.6010835413296813\n",
      "22 138 0.6425646875192961\n",
      "Validation loss: 0.4384469229575486 MAE: 100.12891\n",
      "23 17 0.38069453279969173\n",
      "23 67 0.45356144113989516\n",
      "23 117 0.4514482107858898\n",
      "23 167 0.6606767350318073\n",
      "Validation loss: 0.4128712649233857 MAE: 94.28814\n",
      "24 46 0.6036891260552683\n",
      "24 96 0.4044634295476027\n",
      "24 146 0.43953438744655793\n",
      "Validation loss: 0.45532638252827157 MAE: 103.98369\n",
      "25 25 0.4219250158097284\n",
      "25 75 0.41897719760116825\n",
      "25 125 0.38580533515228227\n",
      "Validation loss: 0.4257331483545359 MAE: 97.22543\n",
      "26 4 0.5006614942514811\n",
      "26 54 0.31987886373358454\n",
      "26 104 0.40919911864330194\n",
      "26 154 0.3777894968742862\n",
      "Validation loss: 0.4344625821587635 MAE: 99.21898\n",
      "27 33 0.6181589616867041\n",
      "27 83 0.4039313568050184\n",
      "27 133 0.4014580023694029\n",
      "Validation loss: 0.4719031338106122 MAE: 107.76935\n",
      "28 12 0.48504234066136553\n",
      "28 62 0.36508425997964616\n",
      "28 112 0.4963829594912753\n",
      "28 162 0.41367721707137717\n",
      "Validation loss: 0.4668600859000669 MAE: 106.61767\n",
      "29 41 0.3565458311173186\n",
      "29 91 0.2648592590477275\n",
      "29 141 0.47263944937090085\n",
      "Validation loss: 0.5904904583044219 MAE: 134.85136\n",
      "30 20 0.2552149924824649\n",
      "30 70 0.649934967404538\n",
      "30 120 0.3661255563490525\n",
      "30 170 0.2647212915189986\n",
      "Validation loss: 0.40216736974771955 MAE: 91.84367\n",
      "31 49 0.46416697267762536\n",
      "31 99 0.31546513076553906\n",
      "31 149 0.5205761913864938\n",
      "Validation loss: 0.41549882623884415 MAE: 94.8882\n",
      "32 28 0.33126854054309585\n",
      "32 78 0.5055859070744056\n",
      "32 128 0.36287292486214967\n",
      "Validation loss: 0.3854334927790346 MAE: 88.022125\n",
      "33 7 0.5876240015698245\n",
      "33 57 0.41686554700297757\n",
      "33 107 0.31303763810944907\n",
      "33 157 0.2834531632533905\n",
      "Validation loss: 0.6493418038937083 MAE: 148.29135\n",
      "34 36 0.2774122536061736\n",
      "34 86 0.6992732227041324\n",
      "34 136 0.47320407443377877\n",
      "Validation loss: 0.43215125502898677 MAE: 98.691154\n",
      "35 15 0.3771676207701777\n",
      "35 65 0.4889609591559262\n",
      "35 115 0.38948915193114514\n",
      "35 165 0.4214124793577339\n",
      "Validation loss: 0.5054254437747755 MAE: 115.42491\n",
      "36 44 0.4807464692345212\n",
      "36 94 0.35689978910422465\n",
      "36 144 0.4592801248482317\n",
      "Validation loss: 0.6171899884067781 MAE: 140.94879\n",
      "37 23 0.3684225522135997\n",
      "37 73 0.29040701235780636\n",
      "37 123 0.4165853125689536\n",
      "Validation loss: 0.6028961563668056 MAE: 137.68446\n",
      "38 2 0.2617264553859937\n",
      "38 52 0.5222663918173689\n",
      "38 102 0.42033396103279413\n",
      "38 152 0.42405390762272255\n",
      "Validation loss: 0.5111800135924802 MAE: 116.73908\n",
      "39 31 0.3672840772795998\n",
      "39 81 0.3852919900399274\n",
      "39 131 0.3635744880429621\n",
      "Validation loss: 0.7074129051632352 MAE: 161.55313\n",
      "40 10 0.36496291652286283\n",
      "40 60 0.3297632400830753\n",
      "40 110 0.5017556801741901\n",
      "40 160 0.47353604303459823\n",
      "Validation loss: 0.5299527401115462 MAE: 121.026245\n",
      "41 39 0.2490352276359922\n",
      "41 89 0.4259418965972399\n",
      "41 139 0.34817325609762156\n",
      "Validation loss: 0.5330585321487739 MAE: 121.73552\n",
      "42 18 0.5286865268609106\n",
      "42 68 0.4613403442085017\n",
      "42 118 0.27893038104667883\n",
      "42 168 0.38190340754619423\n",
      "Validation loss: 0.4620961977375878 MAE: 105.52972\n",
      "43 47 0.3150063349541214\n",
      "43 97 0.4570263067221289\n",
      "43 147 0.4632962828247917\n",
      "Validation loss: 0.5005572298813982 MAE: 114.31314\n",
      "44 26 0.508620850183838\n",
      "44 76 0.3809286631257702\n",
      "44 126 0.39963602493059036\n",
      "Validation loss: 0.4930216492268077 MAE: 112.59222\n",
      "45 5 0.44207447682916423\n",
      "45 55 0.46045625117245226\n",
      "45 105 0.5041730562896969\n",
      "45 155 0.5477188666206938\n",
      "Validation loss: 0.48501864476510653 MAE: 110.764565\n",
      "46 34 0.30781353548247065\n",
      "46 84 0.36528630100424886\n",
      "46 134 0.5263638336445254\n",
      "Validation loss: 0.3846335198447021 MAE: 87.83943\n",
      "47 13 0.39277914342110515\n",
      "47 63 0.4164913379746811\n",
      "47 113 0.29435006926179835\n",
      "47 163 0.3640271100764197\n",
      "Validation loss: 0.5329432299262599 MAE: 121.70919\n",
      "48 42 0.3376888081458439\n",
      "48 92 0.3430433329350593\n",
      "48 142 0.49010469316738686\n",
      "Validation loss: 0.514821549953773 MAE: 117.5707\n",
      "49 21 0.4442694351530664\n",
      "49 71 0.4653868308418069\n",
      "49 121 0.3312736876900873\n",
      "Validation loss: 0.425571557548311 MAE: 97.18853\n",
      "50 0 0.374553055858517\n",
      "50 50 0.45534870450928133\n",
      "50 100 0.21548216604460396\n",
      "50 150 0.34797819085755977\n",
      "Validation loss: 0.49669907525268914 MAE: 113.43204\n",
      "51 29 0.32595664557864806\n",
      "51 79 0.3703152876576044\n",
      "51 129 0.4686129906538864\n",
      "Validation loss: 0.6892958816729093 MAE: 157.41573\n",
      "52 8 0.29423919360849976\n",
      "52 58 0.39016014123118725\n",
      "52 108 0.39320473412061246\n",
      "52 158 0.4359858530019557\n",
      "Validation loss: 0.5303002707442345 MAE: 121.10561\n",
      "53 37 0.4233030186951429\n",
      "53 87 0.3201531444606923\n",
      "53 137 0.45322421332136703\n",
      "Validation loss: 0.4669990562207518 MAE: 106.6494\n",
      "54 16 0.5749633362316209\n",
      "54 66 0.26909146497380093\n",
      "54 116 0.47237850558335226\n",
      "54 166 0.3686327583475252\n",
      "Validation loss: 0.5117135284936916 MAE: 116.86093\n",
      "55 45 0.2906851860045609\n",
      "55 95 0.5289855244616205\n",
      "55 145 0.303325163739985\n",
      "Validation loss: 0.5892795167471233 MAE: 134.5748\n",
      "56 24 0.37863084152986604\n",
      "56 74 0.45745890630666014\n",
      "56 124 0.29497871968371236\n",
      "Validation loss: 0.5419725263327883 MAE: 123.77123\n",
      "57 3 0.36485714916408873\n",
      "57 53 0.4119735758237538\n",
      "57 103 0.34515295570577803\n",
      "57 153 0.4951713878231207\n",
      "Validation loss: 0.5110714860826905 MAE: 116.714294\n",
      "58 32 0.39721609979943384\n",
      "58 82 0.4430098418659011\n",
      "58 132 0.4282069876880256\n",
      "Validation loss: 0.43362339546805934 MAE: 99.02734\n",
      "59 11 0.34463457240394335\n",
      "59 61 0.3134693625382286\n",
      "59 111 0.42424553025204104\n",
      "59 161 0.3870151519988097\n",
      "Validation loss: 0.4896381279529884 MAE: 111.81953\n",
      "60 40 0.3902864236987599\n",
      "60 90 0.3962970051699658\n",
      "60 140 0.1955068144966544\n",
      "Validation loss: 0.5156968859901205 MAE: 117.77061\n",
      "61 19 0.2750861597108234\n",
      "61 69 0.35047234553739004\n",
      "61 119 0.3413319821506645\n",
      "61 169 0.30076148138329184\n",
      "Validation loss: 0.6676718108138145 MAE: 152.4774\n",
      "62 48 0.5244867118786172\n",
      "62 98 0.5053545907539128\n",
      "62 148 0.3749143521719605\n",
      "Validation loss: 0.41871107408874914 MAE: 95.62179\n",
      "63 27 0.48076329515329286\n",
      "63 77 0.49491402619626035\n",
      "63 127 0.3261669929581437\n",
      "Validation loss: 0.5115741369319938 MAE: 116.82909\n",
      "64 6 0.32428923963487966\n",
      "64 56 0.24873491158685615\n",
      "64 106 0.3616957143900715\n",
      "64 156 0.2789942386522825\n",
      "Validation loss: 0.7361282925856741 MAE: 168.11093\n",
      "65 35 0.30842693827535034\n",
      "65 85 0.2931144981556725\n",
      "65 135 0.30127224757738164\n",
      "Validation loss: 0.5918578829681664 MAE: 135.16364\n",
      "66 14 0.37554893867864586\n",
      "66 64 0.2763227211680061\n",
      "66 114 0.358879797630621\n",
      "66 164 0.35705990280765937\n",
      "Validation loss: 0.4452277435893901 MAE: 101.67745\n",
      "67 43 0.5712405950424256\n",
      "67 93 0.2922471356853281\n",
      "67 143 0.3103200374607881\n",
      "Validation loss: 0.46410353978474933 MAE: 105.988144\n",
      "68 22 0.4333599181652673\n",
      "68 72 0.34508918978042574\n",
      "68 122 0.2895630849700835\n",
      "Validation loss: 0.49497311052523163 MAE: 113.03789\n",
      "69 1 0.2721057605881475\n",
      "69 51 0.3427047142772472\n",
      "69 101 0.2765345317031643\n",
      "69 151 0.3918813765181637\n",
      "Validation loss: 0.47210907866383156 MAE: 107.81638\n",
      "70 30 0.533997313060731\n",
      "70 80 0.3941891791958434\n",
      "70 130 0.2846598750116811\n",
      "Validation loss: 0.4775637001322027 MAE: 109.062065\n",
      "71 9 0.37201194587469033\n",
      "71 59 0.3676464905588594\n",
      "71 109 0.47228873478384525\n",
      "71 159 0.226909880490999\n",
      "Validation loss: 0.5188098403445461 MAE: 118.48152\n",
      "72 38 0.37563807380487046\n",
      "72 88 0.2855310618285894\n",
      "72 138 0.35568941629800327\n",
      "Validation loss: 0.43881795455140676 MAE: 100.21363\n",
      "73 17 0.25856251631164345\n",
      "73 67 0.35374614855552594\n",
      "73 117 0.418513710748867\n",
      "73 167 0.3745484522837158\n",
      "Validation loss: 0.5673525629684939 MAE: 129.56732\n",
      "74 46 0.30363348731578066\n",
      "74 96 0.33506724469548027\n",
      "74 146 0.5399590907028945\n",
      "Validation loss: 0.4989689574604146 MAE: 113.95043\n",
      "75 25 0.27294692640570173\n",
      "75 75 0.2901349231592782\n",
      "75 125 0.3572161321032193\n",
      "Validation loss: 0.4897328043541713 MAE: 111.84115\n",
      "76 4 0.5581492864051267\n",
      "76 54 0.5067867362203224\n",
      "76 104 0.1999256049789113\n",
      "76 154 0.34920450032651523\n",
      "Validation loss: 0.6251194647878234 MAE: 142.75964\n",
      "77 33 0.37294653256493254\n",
      "77 83 0.20056787046325025\n",
      "77 133 0.36027471849753995\n",
      "Validation loss: 0.5541011576066938 MAE: 126.54106\n",
      "78 12 0.21161426958762947\n",
      "78 62 0.3670351565055659\n",
      "78 112 0.2249548582089341\n",
      "78 162 0.35039938931229275\n",
      "Validation loss: 0.6982860244505587 MAE: 159.46881\n",
      "79 41 0.35926786626794627\n",
      "79 91 0.2593187694998011\n",
      "79 141 0.5282699253568116\n",
      "Validation loss: 0.6364659844783315 MAE: 145.35088\n",
      "80 20 0.3583850308770726\n",
      "80 70 0.3589704886859619\n",
      "80 120 0.3507662638101028\n",
      "80 170 0.36573683530377776\n",
      "Validation loss: 0.5226806564289227 MAE: 119.36551\n",
      "81 49 0.2504092830589637\n",
      "81 99 0.40649614971485515\n",
      "81 149 0.3868381001303386\n",
      "Validation loss: 0.4957233343208045 MAE: 113.20922\n",
      "82 28 0.2917702264135537\n",
      "82 78 0.3897053071264077\n",
      "82 128 0.39990117863620317\n",
      "Validation loss: 0.49472875134986743 MAE: 112.98208\n",
      "83 7 0.35685777101924127\n",
      "83 57 0.5584041769929793\n",
      "83 107 0.24670317690739682\n",
      "83 157 0.4529651880769173\n",
      "Validation loss: 0.5362672324766192 MAE: 122.46829\n",
      "84 36 0.28732229380530444\n",
      "84 86 0.336616563347637\n",
      "84 136 0.5016608033587568\n",
      "Validation loss: 0.6236384537136346 MAE: 142.42142\n",
      "85 15 0.409545300089562\n",
      "85 65 0.4094330851266948\n",
      "85 115 0.3502284818370632\n",
      "85 165 0.2399671955363621\n",
      "Validation loss: 0.7106142204407363 MAE: 162.28423\n",
      "86 44 0.3201648498534235\n",
      "86 94 0.3581381430185302\n",
      "86 144 0.30200999914037774\n",
      "Validation loss: 0.6717245829732794 MAE: 153.40292\n",
      "87 23 0.3421106985843328\n",
      "87 73 0.339169862508842\n",
      "87 123 0.37779856895969643\n",
      "Validation loss: 0.537380123696132 MAE: 122.72245\n",
      "88 2 0.34475562172995805\n",
      "88 52 0.37114397066846005\n",
      "88 102 0.29623662594631667\n",
      "88 152 0.2536662708256966\n",
      "Validation loss: 0.6142127472057677 MAE: 140.26886\n",
      "89 31 0.29869600415701575\n",
      "89 81 0.2672374464564292\n",
      "89 131 0.3390820636125531\n",
      "Validation loss: 0.4234567650577478 MAE: 96.70557\n",
      "90 10 0.3161814576916089\n",
      "90 60 0.23529606185732002\n",
      "90 110 0.24027038908211368\n",
      "90 160 0.2737140749014898\n",
      "Validation loss: 0.5501337849605851 MAE: 125.635025\n",
      "91 39 0.34725741508739805\n",
      "91 89 0.31035806207617533\n",
      "91 139 0.27038330674471484\n",
      "Validation loss: 0.5682573778587475 MAE: 129.77396\n",
      "92 18 0.2951886992112122\n",
      "92 68 0.3674835335451679\n",
      "92 118 0.4220963518899232\n",
      "92 168 0.30726718512296497\n",
      "Validation loss: 0.5610998952597902 MAE: 128.13937\n",
      "93 47 0.3163140553100285\n",
      "93 97 0.261761278015314\n",
      "93 147 0.46428337841205364\n",
      "Validation loss: 0.6574760041041681 MAE: 150.14896\n",
      "94 26 0.42530854464678813\n",
      "94 76 0.4007621002813691\n",
      "94 126 0.5020329996275814\n",
      "Validation loss: 0.46915757934949553 MAE: 107.14234\n",
      "95 5 0.4108121006079759\n",
      "95 55 0.2109045730869949\n",
      "95 105 0.3528504743215028\n",
      "95 155 0.20166664709997484\n",
      "Validation loss: 0.5140831805112069 MAE: 117.40209\n",
      "96 34 0.3988654682817217\n",
      "96 84 0.17092738037422717\n",
      "96 134 0.3717109548321879\n",
      "Validation loss: 0.5716785157633106 MAE: 130.55524\n",
      "97 13 0.3915704840105115\n",
      "97 63 0.5134807214924683\n",
      "97 113 0.2944089596324495\n",
      "97 163 0.32429418545338734\n",
      "Validation loss: 0.6125169685709546 MAE: 139.88159\n",
      "98 42 0.32274166719307135\n",
      "98 92 0.3201023870146346\n",
      "98 142 0.2750018728675315\n",
      "Validation loss: 0.4941793945100572 MAE: 112.85662\n",
      "99 21 0.5475241700310569\n",
      "99 71 0.18966079418137893\n",
      "99 121 0.24265255948763007\n",
      "Validation loss: 0.5807378286855263 MAE: 132.62413\n",
      "100 0 0.30824628310066876\n",
      "100 50 0.3706685025389143\n",
      "100 100 0.3356390674560257\n",
      "100 150 0.4333444961223724\n",
      "Validation loss: 0.6056984513126619 MAE: 138.32442\n",
      "101 29 0.28243156417337756\n",
      "101 79 0.28443243294105314\n",
      "101 129 0.396880422320104\n",
      "Validation loss: 0.6386962898990565 MAE: 145.86021\n",
      "102 8 0.19637932745587874\n",
      "102 58 0.3278225114180108\n",
      "102 108 0.23832105392550215\n",
      "102 158 0.3775533347649788\n",
      "Validation loss: 0.568556040699719 MAE: 129.84215\n",
      "103 37 0.40568489300879146\n",
      "103 87 0.306610835482378\n",
      "103 137 0.39983919757346487\n",
      "Validation loss: 0.6281715586171512 MAE: 143.45665\n",
      "104 16 0.2694640109799246\n",
      "104 66 0.38212491589137143\n",
      "104 116 0.3795731945382766\n",
      "104 166 0.35228961230706474\n",
      "Validation loss: 0.5329939949582194 MAE: 121.72078\n",
      "105 45 0.482778352928119\n",
      "105 95 0.38454114837495645\n",
      "105 145 0.35536868922576453\n",
      "Validation loss: 0.6139314809040717 MAE: 140.20464\n",
      "106 24 0.3039206319992613\n",
      "106 74 0.23624302188947716\n",
      "106 124 0.22009985674599963\n",
      "Validation loss: 0.43269688100145576 MAE: 98.81576\n",
      "107 3 0.3753817246042854\n",
      "107 53 0.35493154464361965\n",
      "107 103 0.18630263263966781\n",
      "107 153 0.36711652979313925\n",
      "Validation loss: 0.5642821283368339 MAE: 128.86612\n",
      "108 32 0.3671556379350975\n",
      "108 82 0.45433688571756436\n",
      "108 132 0.2655026825271878\n",
      "Validation loss: 0.4705058437341835 MAE: 107.45025\n",
      "109 11 0.40379719914694895\n",
      "109 61 0.32062608218830463\n",
      "109 111 0.3914311832523007\n",
      "109 161 0.2323371905910765\n",
      "Validation loss: 0.6680001877901847 MAE: 152.55238\n",
      "110 40 0.23760632561668815\n",
      "110 90 0.289793841468876\n",
      "110 140 0.44299843353575136\n",
      "Validation loss: 0.5361229613510489 MAE: 122.43536\n",
      "111 19 0.4331583519565216\n",
      "111 69 0.4079280994748496\n",
      "111 119 0.40598363341158444\n",
      "111 169 0.34695193594505463\n",
      "Validation loss: 0.5352369898941085 MAE: 122.23302\n",
      "112 48 0.2994665766711158\n",
      "112 98 0.30302697897009095\n",
      "112 148 0.24870916443161006\n",
      "Validation loss: 0.6421070478812992 MAE: 146.63913\n",
      "113 27 0.4811617749641222\n",
      "113 77 0.25006295545991886\n",
      "113 127 0.2485366441546576\n",
      "Validation loss: 0.68143439850612 MAE: 155.62039\n",
      "114 6 0.4331380208495949\n",
      "114 56 0.2394298665135916\n",
      "114 106 0.27582581692434593\n",
      "114 156 0.4732148125794974\n",
      "Validation loss: 0.5412566252270637 MAE: 123.60773\n",
      "115 35 0.2754799126742961\n",
      "115 85 0.42640062257402084\n",
      "115 135 0.2782035506377104\n",
      "Validation loss: 0.604059984809474 MAE: 137.95024\n",
      "116 14 0.3821347880399803\n",
      "116 64 0.29581028774278634\n",
      "116 114 0.4094080990550685\n",
      "116 164 0.3664938197575912\n",
      "Validation loss: 0.6020537823961493 MAE: 137.4921\n",
      "117 43 0.2153844532012537\n",
      "117 93 0.4243019824680231\n",
      "117 143 0.3550173308063396\n",
      "Validation loss: 0.5407048313938386 MAE: 123.48173\n",
      "118 22 0.4249395884148311\n",
      "118 72 0.1874104371391432\n",
      "118 122 0.4745809474114576\n",
      "Validation loss: 0.635039770812319 MAE: 145.02516\n",
      "119 1 0.29468044954019385\n",
      "119 51 0.2213874697513423\n",
      "119 101 0.31729095151404973\n",
      "119 151 0.5492197961417673\n",
      "Validation loss: 0.6740624765206499 MAE: 153.93684\n",
      "120 30 0.3666780951942703\n",
      "120 80 0.2961057118733938\n",
      "120 130 0.37293702220797637\n",
      "Validation loss: 0.6669512227264761 MAE: 152.31284\n",
      "121 9 0.2777891790055924\n",
      "121 59 0.40889641607516375\n",
      "121 109 0.3995830362772692\n",
      "121 159 0.3089595698254188\n",
      "Validation loss: 0.7016547458213672 MAE: 160.23813\n",
      "122 38 0.31236748212502297\n",
      "122 88 0.2726338147055346\n",
      "122 138 0.3423383079675636\n",
      "Validation loss: 0.5946094886949885 MAE: 135.79202\n",
      "123 17 0.19550831653113102\n",
      "123 67 0.2145729802135946\n",
      "123 117 0.19856409705381572\n",
      "123 167 0.21922937358249114\n",
      "Validation loss: 0.5827225455415179 MAE: 133.07738\n",
      "124 46 0.32149019146799396\n",
      "124 96 0.4668489673226421\n",
      "124 146 0.24429893413647685\n",
      "Validation loss: 0.5807500234124257 MAE: 132.62692\n",
      "125 25 0.3921823449514787\n",
      "125 75 0.3771986799687389\n",
      "125 125 0.28065857498972985\n",
      "Validation loss: 0.6332976957510786 MAE: 144.62732\n",
      "126 4 0.24226631006899157\n",
      "126 54 0.40879733208124736\n",
      "126 104 0.4668394483448225\n",
      "126 154 0.39578100873557664\n",
      "Validation loss: 0.5768786578150521 MAE: 131.7428\n",
      "127 33 0.37975716204581744\n",
      "127 83 0.32371704532440126\n",
      "127 133 0.2736891953179019\n",
      "Validation loss: 0.5561988766778979 MAE: 127.02013\n",
      "128 12 0.37382884517241494\n",
      "128 62 0.23422595289321468\n",
      "128 112 0.504301167497986\n",
      "128 162 0.3634968647545908\n",
      "Validation loss: 0.49977154445927047 MAE: 114.13371\n",
      "129 41 0.2843980052009799\n",
      "129 91 0.20011444322296204\n",
      "129 141 0.3052101332437239\n",
      "Validation loss: 0.685932995980246 MAE: 156.64774\n",
      "130 20 0.2832382167686878\n",
      "130 70 0.2960957774407168\n",
      "130 120 0.3962205477110596\n",
      "130 170 0.432445990646427\n",
      "Validation loss: 0.5725082270583214 MAE: 130.74472\n",
      "131 49 0.5092109737116954\n",
      "131 99 0.34217316594922487\n",
      "131 149 0.26534599906414347\n",
      "Validation loss: 0.5422800998938712 MAE: 123.84147\n",
      "132 28 0.45533347934511864\n",
      "132 78 0.3220072641844471\n",
      "132 128 0.4519737693479795\n",
      "Validation loss: 0.5754158559598421 MAE: 131.40874\n",
      "133 7 0.29124139676451066\n",
      "133 57 0.3597629951220738\n",
      "133 107 0.3967893028484718\n",
      "133 157 0.330941863040906\n",
      "Validation loss: 0.5649970421317028 MAE: 129.02937\n",
      "134 36 0.1875834165336515\n",
      "134 86 0.4564942067087964\n",
      "134 136 0.30147689929414706\n",
      "Validation loss: 0.5288948590992487 MAE: 120.78465\n",
      "135 15 0.4820594867894473\n",
      "135 65 0.21719514118710856\n",
      "135 115 0.30105173896109994\n",
      "135 165 0.2302667325667215\n",
      "Validation loss: 0.5220977855704682 MAE: 119.23239\n",
      "136 44 0.3059168146666429\n",
      "136 94 0.37453146816388977\n",
      "136 144 0.4171870138958013\n",
      "Validation loss: 0.6082962019401684 MAE: 138.91768\n",
      "137 23 0.26290711644050146\n",
      "137 73 0.2739715738930923\n",
      "137 123 0.3201285906000411\n",
      "Validation loss: 0.6157074089635882 MAE: 140.6102\n",
      "138 2 0.34004663611223085\n",
      "138 52 0.3820029964514037\n",
      "138 102 0.28893637737410705\n",
      "138 152 0.3177535853732055\n",
      "Validation loss: 0.4948889456297222 MAE: 113.01866\n",
      "139 31 0.29956899812372406\n",
      "139 81 0.38358643776140516\n",
      "139 131 0.25453213307129646\n",
      "Validation loss: 0.6855229878286172 MAE: 156.55411\n",
      "140 10 0.2907223014700302\n",
      "140 60 0.31136755364359026\n",
      "140 110 0.47451404813811143\n",
      "140 160 0.377865978306397\n",
      "Validation loss: 0.5573095719368137 MAE: 127.273766\n",
      "141 39 0.3722662453314195\n",
      "141 89 0.2102913842978931\n",
      "141 139 0.1628341182658703\n",
      "Validation loss: 0.5773893671426159 MAE: 131.85944\n",
      "142 18 0.31832003542730375\n",
      "142 68 0.3316250942657942\n",
      "142 118 0.31610965987423384\n",
      "142 168 0.21127616578749267\n",
      "Validation loss: 0.6171148332238895 MAE: 140.93161\n",
      "143 47 0.37937136076832007\n",
      "143 97 0.1886335214401124\n",
      "143 147 0.3105134106047923\n",
      "Validation loss: 0.5453576163241738 MAE: 124.5443\n",
      "144 26 0.24597181342356417\n",
      "144 76 0.22973987757306633\n",
      "144 126 0.1974439495644215\n",
      "Validation loss: 0.6320273778591937 MAE: 144.33722\n",
      "145 5 0.33182495290809516\n",
      "145 55 0.2399442998780751\n",
      "145 105 0.40670619786002205\n",
      "145 155 0.30650982663887577\n",
      "Validation loss: 0.47296356126578926 MAE: 108.011536\n",
      "146 34 0.2904126255601558\n",
      "146 84 0.38432953544728893\n",
      "146 134 0.35588303072139754\n",
      "Validation loss: 0.525552727674183 MAE: 120.02141\n",
      "147 13 0.30505470535210377\n",
      "147 63 0.31342129710627986\n",
      "147 113 0.26228023481214735\n",
      "147 163 0.2796038251349037\n",
      "Validation loss: 0.48528866879424154 MAE: 110.826225\n",
      "148 42 0.25750844519907323\n",
      "148 92 0.28596648109685396\n",
      "148 142 0.1558889102520572\n",
      "Validation loss: 0.5400098987490113 MAE: 123.323006\n",
      "149 21 0.3004863163741562\n",
      "149 71 0.2523997358563727\n",
      "149 121 0.19490547658782104\n",
      "Validation loss: 0.5968665651410644 MAE: 136.30748\n",
      "150 0 0.47439071295308655\n",
      "150 50 0.3338035654006909\n",
      "150 100 0.38163605906381376\n",
      "150 150 0.30360312617123875\n",
      "Validation loss: 0.5689559150160405 MAE: 129.93349\n",
      "151 29 0.23539947154698357\n",
      "151 79 0.5175459945305209\n",
      "151 129 0.3150174602453784\n",
      "Validation loss: 0.511678437740482 MAE: 116.85291\n",
      "152 8 0.37393570900483475\n",
      "152 58 0.13499020053394253\n",
      "152 108 0.33337735533075025\n",
      "152 158 0.3487129522804874\n",
      "Validation loss: 0.5038818295239008 MAE: 115.07239\n",
      "153 37 0.2883104405596547\n",
      "153 87 0.23175778036167355\n",
      "153 137 0.26900444119082195\n",
      "Validation loss: 0.6601748131869132 MAE: 150.76529\n",
      "154 16 0.2745117112492891\n",
      "154 66 0.2712544832899272\n",
      "154 116 0.25481143138138573\n",
      "154 166 0.3409938373740521\n",
      "Validation loss: 0.6036331113318951 MAE: 137.85277\n",
      "155 45 0.17981483984517047\n",
      "155 95 0.3575432314703372\n",
      "155 145 0.33419356324109156\n",
      "Validation loss: 0.515551221300984 MAE: 117.73734\n",
      "156 24 0.30417321711795536\n",
      "156 74 0.24876435740316566\n",
      "156 124 0.25775982088146127\n",
      "Validation loss: 0.5903122871242769 MAE: 134.81067\n",
      "157 3 0.22066522709561606\n",
      "157 53 0.2730368264371602\n",
      "157 103 0.1951119620552838\n",
      "157 153 0.2147761760232108\n",
      "Validation loss: 0.6295294629202949 MAE: 143.76675\n",
      "158 32 0.2103083048154645\n",
      "158 82 0.19279164753067593\n",
      "158 132 0.3167306906670199\n",
      "Validation loss: 0.5584260507633811 MAE: 127.52875\n",
      "159 11 0.27693386126731295\n",
      "159 61 0.2443252962206857\n",
      "159 111 0.205942654922567\n",
      "159 161 0.33779221509386226\n",
      "Validation loss: 0.5224314295409018 MAE: 119.30859\n",
      "160 40 0.2663743925654452\n",
      "160 90 0.24096339283096255\n",
      "160 140 0.29410014916749533\n",
      "Validation loss: 0.6605367329385545 MAE: 150.84795\n",
      "161 19 0.44598722138880487\n",
      "161 69 0.2357443333951453\n",
      "161 119 0.28557627113818246\n",
      "161 169 0.27522080215792294\n",
      "Validation loss: 0.5411461558606889 MAE: 123.58251\n",
      "162 48 0.2647540838178459\n",
      "162 98 0.3616165663223567\n",
      "162 148 0.2399747003679403\n",
      "Validation loss: 0.6439413076255753 MAE: 147.05803\n",
      "163 27 0.26237881934429774\n",
      "163 77 0.45801600184213076\n",
      "163 127 0.24981732750232907\n",
      "Validation loss: 0.5825299875080934 MAE: 133.0334\n",
      "164 6 0.1841264650064582\n",
      "164 56 0.3805649954620607\n",
      "164 106 0.26961902578636576\n",
      "164 156 0.31069713269241817\n",
      "Validation loss: 0.5263735676369472 MAE: 120.20886\n",
      "165 35 0.23684515031908374\n",
      "165 85 0.4215068829764694\n",
      "165 135 0.3203640986451913\n",
      "Validation loss: 0.573967677110817 MAE: 131.07802\n",
      "166 14 0.2718941967795952\n",
      "166 64 0.28047504230762116\n",
      "166 114 0.36880105842697686\n",
      "166 164 0.43596484870157515\n",
      "Validation loss: 0.6180698648530837 MAE: 141.14972\n",
      "167 43 0.352788501862043\n",
      "167 93 0.32657607561165375\n",
      "167 143 0.29559801771722843\n",
      "Validation loss: 0.5655401742946334 MAE: 129.15341\n",
      "168 22 0.44959390524653653\n",
      "168 72 0.3022725583237079\n",
      "168 122 0.37724758026463706\n",
      "Validation loss: 0.5650641299479189 MAE: 129.04468\n",
      "169 1 0.27961061537418475\n",
      "169 51 0.4609091578222439\n",
      "169 101 0.27059773251460034\n",
      "169 151 0.3323789883787309\n",
      "Validation loss: 0.6495800157736616 MAE: 148.34573\n",
      "170 30 0.26992974582097784\n",
      "170 80 0.33615383751492867\n",
      "170 130 0.20296738641617157\n",
      "Validation loss: 0.5738554213479249 MAE: 131.05238\n",
      "171 9 0.28430288470358617\n",
      "171 59 0.35107915675728435\n",
      "171 109 0.3778156954232106\n",
      "171 159 0.22495722507375338\n",
      "Validation loss: 0.4718927448255974 MAE: 107.766975\n",
      "172 38 0.416289612556361\n",
      "172 88 0.28483933546684603\n",
      "172 138 0.27249520528774895\n",
      "Validation loss: 0.6848144133885702 MAE: 156.39227\n",
      "173 17 0.43243687552558835\n",
      "173 67 0.4874002328570439\n",
      "173 117 0.3647541996160593\n",
      "173 167 0.3225434202874461\n",
      "Validation loss: 0.5193234396259687 MAE: 118.59881\n",
      "174 46 0.34530690769120936\n",
      "174 96 0.22757708807387614\n",
      "174 146 0.27055504228770344\n",
      "Validation loss: 0.5023724394932128 MAE: 114.727684\n",
      "175 25 0.3289452569042365\n",
      "175 75 0.25528204034811436\n",
      "175 125 0.4199183383441041\n",
      "Validation loss: 0.5465503610365572 MAE: 124.816666\n",
      "176 4 0.23780023975778622\n",
      "176 54 0.34172219513475216\n",
      "176 104 0.31463801463324703\n",
      "176 154 0.28361226119722194\n",
      "Validation loss: 0.7517686740696778 MAE: 171.68274\n",
      "177 33 0.31626742731269175\n",
      "177 83 0.21565776665696282\n",
      "177 133 0.20547888407072357\n",
      "Validation loss: 0.5132931401157936 MAE: 117.221664\n",
      "178 12 0.23902135831221705\n",
      "178 62 0.37427359230294077\n",
      "178 112 0.2941468747979417\n",
      "178 162 0.2631150052836116\n",
      "Validation loss: 0.5664065466289632 MAE: 129.35127\n",
      "179 41 0.4035675515460735\n",
      "179 91 0.2551214090845559\n",
      "179 141 0.311443540230055\n",
      "Validation loss: 0.5158976086399012 MAE: 117.81645\n",
      "180 20 0.4428309693818123\n",
      "180 70 0.27083296931146683\n",
      "180 120 0.3078575934723316\n",
      "180 170 0.407861323857994\n",
      "Validation loss: 0.5017093193461324 MAE: 114.57625\n",
      "181 49 0.27484821729600695\n",
      "181 99 0.22386535907220964\n",
      "181 149 0.33793979240200955\n",
      "Validation loss: 0.5944800544203374 MAE: 135.76247\n",
      "182 28 0.29682554507691666\n",
      "182 78 0.24512753165385257\n",
      "182 128 0.2798217214209313\n",
      "Validation loss: 0.591939764064655 MAE: 135.18234\n",
      "183 7 0.21274918169640292\n",
      "183 57 0.19180680796325605\n",
      "183 107 0.21747538787416726\n",
      "183 157 0.27749782056907213\n",
      "Validation loss: 0.5331112449629265 MAE: 121.74756\n",
      "184 36 0.4560745523200758\n",
      "184 86 0.37178751930207643\n",
      "184 136 0.24799148682570576\n",
      "Validation loss: 0.6578857194610507 MAE: 150.24252\n",
      "185 15 0.24469847414176796\n",
      "185 65 0.38268661309858787\n",
      "185 115 0.45806162001432016\n",
      "185 165 0.28385721114720974\n",
      "Validation loss: 0.584429539086526 MAE: 133.46722\n",
      "186 44 0.16875438805065487\n",
      "186 94 0.37661362996594827\n",
      "186 144 0.21155188197612446\n",
      "Validation loss: 0.6165914444895516 MAE: 140.81207\n",
      "187 23 0.19325362109655908\n",
      "187 73 0.327438434917337\n",
      "187 123 0.3586832029269393\n",
      "Validation loss: 0.6886459240439342 MAE: 157.26729\n",
      "188 2 0.2620736557432373\n",
      "188 52 0.3403035915599316\n",
      "188 102 0.31507921396133176\n",
      "188 152 0.29499532447717586\n",
      "Validation loss: 0.5914963051589609 MAE: 135.08105\n",
      "189 31 0.2885647105906035\n",
      "189 81 0.19113804498503045\n",
      "189 131 0.21919558979098544\n",
      "Validation loss: 0.7080957248196964 MAE: 161.70909\n",
      "190 10 0.3888860830513829\n",
      "190 60 0.3769099744713303\n",
      "190 110 0.21217055996085257\n",
      "190 160 0.1611548812880886\n",
      "Validation loss: 0.6400423447291056 MAE: 146.1676\n",
      "191 39 0.2587721718645245\n",
      "191 89 0.2734010947454108\n",
      "191 139 0.34572775162919245\n",
      "Validation loss: 0.5172795486031917 MAE: 118.13206\n",
      "192 18 0.3234973101147107\n",
      "192 68 0.20726170734295965\n",
      "192 118 0.30927200732974897\n",
      "192 168 0.21828346511473273\n",
      "Validation loss: 0.5769018691185622 MAE: 131.74811\n",
      "193 47 0.3519715369130879\n",
      "193 97 0.4031830482160409\n",
      "193 147 0.29152228447478323\n",
      "Validation loss: 0.49845002269187166 MAE: 113.83192\n",
      "194 26 0.33945294097630563\n",
      "194 76 0.21166729221554173\n",
      "194 126 0.31180433280989645\n",
      "Validation loss: 0.6325765300912467 MAE: 144.4626\n",
      "195 5 0.27878591428382843\n",
      "195 55 0.29431990055265406\n",
      "195 105 0.3584791652555111\n",
      "195 155 0.2090573685818405\n",
      "Validation loss: 0.504518541327694 MAE: 115.21779\n",
      "196 34 0.42704018611576827\n",
      "196 84 0.24873841291076773\n",
      "196 134 0.17382775506352613\n",
      "Validation loss: 0.6230893131585149 MAE: 142.296\n",
      "197 13 0.22645733970324272\n",
      "197 63 0.1945294305884038\n",
      "197 113 0.25869118844486716\n",
      "197 163 0.1985657227995193\n",
      "Validation loss: 0.6286184285816393 MAE: 143.5587\n",
      "198 42 0.3781147619980198\n",
      "198 92 0.28526484318152334\n",
      "198 142 0.2674987032445092\n",
      "Validation loss: 0.5176269115760312 MAE: 118.21137\n",
      "199 21 0.27934153836819714\n",
      "199 71 0.25698439718345445\n",
      "199 121 0.24659520980520966\n",
      "Validation loss: 0.5394261416636015 MAE: 123.189705\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.3255675264891908 Test MAE: 74.35043\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'qm7', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'regression', 'data_path': 'data/qm7/qm7.csv', 'target': ['u0_atom']}}\n",
      "Running on: cuda:1\n",
      "6833\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/6833\n",
      "Generating scaffold 1000/6833\n",
      "Generating scaffold 2000/6833\n",
      "Generating scaffold 3000/6833\n",
      "Generating scaffold 4000/6833\n",
      "Generating scaffold 5000/6833\n",
      "Generating scaffold 6000/6833\n",
      "About to sort in scaffold sets\n",
      "tensor(-1553.3463) tensor(228.3718) torch.Size([5466, 1])\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.4576707841782146\n",
      "0 50 0.7509258230842351\n",
      "0 100 0.768068378793885\n",
      "0 150 0.653039774936864\n",
      "Validation loss: 0.5588841649175388 MAE: 127.63337\n",
      "1 29 0.6357302833892655\n",
      "1 79 0.7404266586517307\n",
      "1 129 0.6397976825879838\n",
      "Validation loss: 0.4569201364851834 MAE: 104.34766\n",
      "2 8 0.6482698100814224\n",
      "2 58 0.44469780430750916\n",
      "2 108 0.47811641734309207\n",
      "2 158 0.7123881410038352\n",
      "Validation loss: 0.711190030240176 MAE: 162.41574\n",
      "3 37 0.650742061041325\n",
      "3 87 0.40154054921814675\n",
      "3 137 0.5722468604294995\n",
      "Validation loss: 0.5580819789429157 MAE: 127.45018\n",
      "4 16 0.6742055441123431\n",
      "4 66 0.6713468985617917\n",
      "4 116 0.4407198046294422\n",
      "4 166 0.42907552450991027\n",
      "Validation loss: 0.4793190398411444 MAE: 109.46294\n",
      "5 45 0.4531593931213568\n",
      "5 95 0.5163881635564374\n",
      "5 145 0.5646819546348152\n",
      "Validation loss: 0.512919789169267 MAE: 117.1364\n",
      "6 24 0.6926111120100829\n",
      "6 74 0.48538457258234396\n",
      "6 124 0.5807700684002827\n",
      "Validation loss: 0.3983695416422615 MAE: 90.97636\n",
      "7 3 0.47280977315810074\n",
      "7 53 0.5767515001703049\n",
      "7 103 0.5671714822294303\n",
      "7 153 0.51964207349488\n",
      "Validation loss: 0.5402103188442208 MAE: 123.36879\n",
      "8 32 0.6400827934145856\n",
      "8 82 0.6414683014079587\n",
      "8 132 0.6110220395566249\n",
      "Validation loss: 0.4470181527890657 MAE: 102.08633\n",
      "9 11 0.4028323853587793\n",
      "9 61 0.5558842115275928\n",
      "9 111 0.5249278141842234\n",
      "9 161 0.3497728978663905\n",
      "Validation loss: 0.6062236696655987 MAE: 138.44438\n",
      "10 40 0.47733137916091334\n",
      "10 90 0.7004901998243134\n",
      "10 140 0.5207367936561431\n",
      "Validation loss: 0.37388641653005145 MAE: 85.38511\n",
      "11 19 0.7555045238043672\n",
      "11 69 0.6803732198205754\n",
      "11 119 0.5442246343182924\n",
      "11 169 0.6255135290853947\n",
      "Validation loss: 0.4095933752798895 MAE: 93.539566\n",
      "12 48 0.613420915938242\n",
      "12 98 0.5191522529841556\n",
      "12 148 0.43424561505314596\n",
      "Validation loss: 0.44997459231761466 MAE: 102.76149\n",
      "13 27 0.5451565549310814\n",
      "13 77 0.7188779091012282\n",
      "13 127 0.5608397852340993\n",
      "Validation loss: 0.39954778883192277 MAE: 91.24543\n",
      "14 6 0.5495717285853284\n",
      "14 56 0.5147264574873864\n",
      "14 106 0.4209771025270408\n",
      "14 156 0.4119330732172589\n",
      "Validation loss: 0.4599253699096323 MAE: 105.033966\n",
      "15 35 0.6361908157135014\n",
      "15 85 0.5412356567199238\n",
      "15 135 0.4151582526858408\n",
      "Validation loss: 0.4299872939349615 MAE: 98.19696\n",
      "16 14 0.5856372276496395\n",
      "16 64 0.5725206033171204\n",
      "16 114 0.5058013897039495\n",
      "16 164 0.48936465273211854\n",
      "Validation loss: 0.466210467076441 MAE: 106.46931\n",
      "17 43 0.46660410257540147\n",
      "17 93 0.6196963209354045\n",
      "17 143 0.5966335460280869\n",
      "Validation loss: 0.3850025381261145 MAE: 87.923706\n",
      "18 22 0.450873492012511\n",
      "18 72 0.47142330278047667\n",
      "18 122 0.4101573629138257\n",
      "Validation loss: 0.3937847816456131 MAE: 89.92933\n",
      "19 1 0.31836766891326806\n",
      "19 51 0.35181709038588055\n",
      "19 101 0.5951530964877657\n",
      "19 151 0.5320950386791251\n",
      "Validation loss: 0.43178896736680417 MAE: 98.60841\n",
      "20 30 0.3758535909091504\n",
      "20 80 0.5181923764978736\n",
      "20 130 0.3948782093173316\n",
      "Validation loss: 0.44683814501901814 MAE: 102.04522\n",
      "21 9 0.6961131754077873\n",
      "21 59 0.3214315734743571\n",
      "21 109 0.3170012416698549\n",
      "21 159 0.3839028432473324\n",
      "Validation loss: 0.4498584368075544 MAE: 102.73497\n",
      "22 38 0.5700740499055992\n",
      "22 88 0.35151620660800004\n",
      "22 138 0.7104890129125891\n",
      "Validation loss: 0.42498607210248535 MAE: 97.054825\n",
      "23 17 0.38478710254485876\n",
      "23 67 0.6043624049431664\n",
      "23 117 0.5815792285571646\n",
      "23 167 0.46607388678838285\n",
      "Validation loss: 0.4741672531903139 MAE: 108.286415\n",
      "24 46 0.48686973009017404\n",
      "24 96 0.49319195951992456\n",
      "24 146 0.3894870395824852\n",
      "Validation loss: 0.4377811024760642 MAE: 99.976845\n",
      "25 25 0.4147517412545588\n",
      "25 75 0.3509618789398786\n",
      "25 125 0.42179751961763456\n",
      "Validation loss: 0.42974912945987187 MAE: 98.14257\n",
      "26 4 0.5056330813300154\n",
      "26 54 0.2974842528137761\n",
      "26 104 0.5279366330171203\n",
      "26 154 0.34643286779574967\n",
      "Validation loss: 0.4764271493543658 MAE: 108.80252\n",
      "27 33 0.4028053838146269\n",
      "27 83 0.5974823393999559\n",
      "27 133 0.4066016536901368\n",
      "Validation loss: 0.4452451495399252 MAE: 101.68143\n",
      "28 12 0.5951798834508568\n",
      "28 62 0.3656872009601422\n",
      "28 112 0.443461151231466\n",
      "28 162 0.33883778036967255\n",
      "Validation loss: 0.39920586347579956 MAE: 91.16734\n",
      "29 41 0.3857638874305931\n",
      "29 91 0.3343357220776448\n",
      "29 141 0.41908937307479266\n",
      "Validation loss: 0.4483652400691607 MAE: 102.393974\n",
      "30 20 0.30539679051901003\n",
      "30 70 0.42761847193597996\n",
      "30 120 0.35985670804801945\n",
      "30 170 0.34560588542051596\n",
      "Validation loss: 0.5355615580988209 MAE: 122.30715\n",
      "31 49 0.25452568784586593\n",
      "31 99 0.5170004176935888\n",
      "31 149 0.6786155118681807\n",
      "Validation loss: 0.4700210840381377 MAE: 107.33955\n",
      "32 28 0.32631811962282076\n",
      "32 78 0.4244596278054072\n",
      "32 128 0.3973103134990707\n",
      "Validation loss: 0.4631494850094555 MAE: 105.77026\n",
      "33 7 0.5468820554474915\n",
      "33 57 0.44654198859860367\n",
      "33 107 0.38926381226187706\n",
      "33 157 0.4329723658891418\n",
      "Validation loss: 0.5938027394793884 MAE: 135.60779\n",
      "34 36 0.489846353590718\n",
      "34 86 0.3987659366120213\n",
      "34 136 0.2007059539790789\n",
      "Validation loss: 0.432505336421275 MAE: 98.77202\n",
      "35 15 0.33368822648206553\n",
      "35 65 0.5480205290405965\n",
      "35 115 0.47597440036215666\n",
      "35 165 0.3725905860082706\n",
      "Validation loss: 0.40395976367749664 MAE: 92.253006\n",
      "36 44 0.25275153119415994\n",
      "36 94 0.295774800678275\n",
      "36 144 0.6047851961699263\n",
      "Validation loss: 0.44504806469058433 MAE: 101.63642\n",
      "37 23 0.3896986179260841\n",
      "37 73 0.3741772954881372\n",
      "37 123 0.46219956498284603\n",
      "Validation loss: 0.46311873023272954 MAE: 105.76325\n",
      "38 2 0.29107846238007\n",
      "38 52 0.3273235927888514\n",
      "38 102 0.4379080831842537\n",
      "38 152 0.40702274025066004\n",
      "Validation loss: 0.5799216568818566 MAE: 132.43774\n",
      "39 31 0.24165281117233656\n",
      "39 81 0.41732142035284636\n",
      "39 131 0.3930723998932385\n",
      "Validation loss: 0.5657297540129277 MAE: 129.1967\n",
      "40 10 0.5342971442053289\n",
      "40 60 0.3080308207628342\n",
      "40 110 0.24612745716981946\n",
      "40 160 0.4993521651407165\n",
      "Validation loss: 0.4539885970584133 MAE: 103.67818\n",
      "41 39 0.4707423103146657\n",
      "41 89 0.28510079129298543\n",
      "41 139 0.534780393182034\n",
      "Validation loss: 0.44112331720820647 MAE: 100.74011\n",
      "42 18 0.34768798440353726\n",
      "42 68 0.29107807390002294\n",
      "42 118 0.42419961530150646\n",
      "42 168 0.3260058948280528\n",
      "Validation loss: 0.5668958727030726 MAE: 129.46301\n",
      "43 47 0.44297903791476656\n",
      "43 97 0.43896164706914603\n",
      "43 147 0.359433530334775\n",
      "Validation loss: 0.5067007904164276 MAE: 115.71617\n",
      "44 26 0.39014357290950524\n",
      "44 76 0.25750075506238074\n",
      "44 126 0.5463866747711719\n",
      "Validation loss: 0.5558732744545964 MAE: 126.94577\n",
      "45 5 0.30443248350826574\n",
      "45 55 0.3849233063873202\n",
      "45 105 0.36520170588609635\n",
      "45 155 0.31884998756416694\n",
      "Validation loss: 0.7105890052360401 MAE: 162.27849\n",
      "46 34 0.36976765846722404\n",
      "46 84 0.33117111108292446\n",
      "46 134 0.33780063242941505\n",
      "Validation loss: 0.5839541901273337 MAE: 133.35864\n",
      "47 13 0.301492571937063\n",
      "47 63 0.37118194025105444\n",
      "47 113 0.3331503905596723\n",
      "47 163 0.4263417088747709\n",
      "Validation loss: 0.550160347021114 MAE: 125.64108\n",
      "48 42 0.3810432139706846\n",
      "48 92 0.33923481883466305\n",
      "48 142 0.3942044592937805\n",
      "Validation loss: 0.5180204277150116 MAE: 118.30124\n",
      "49 21 0.4650720734412722\n",
      "49 71 0.5082116474539763\n",
      "49 121 0.35096207826149217\n",
      "Validation loss: 0.45893993660023336 MAE: 104.808914\n",
      "50 0 0.24227688403464695\n",
      "50 50 0.23490312946959854\n",
      "50 100 0.25577971382553283\n",
      "50 150 0.4058653037361836\n",
      "Validation loss: 0.3926373821252968 MAE: 89.6673\n",
      "51 29 0.3447952707894209\n",
      "51 79 0.3652905656290095\n",
      "51 129 0.3369221651932512\n",
      "Validation loss: 0.5420924243871231 MAE: 123.7986\n",
      "52 8 0.3505511238666247\n",
      "52 58 0.33362691786156073\n",
      "52 108 0.1824502550711802\n",
      "52 158 0.407911524143634\n",
      "Validation loss: 0.38616802695898983 MAE: 88.18987\n",
      "53 37 0.47147122221663945\n",
      "53 87 0.36551267218528777\n",
      "53 137 0.5017890849345567\n",
      "Validation loss: 0.46829441625472396 MAE: 106.94522\n",
      "54 16 0.26491630714034226\n",
      "54 66 0.37985931372620246\n",
      "54 116 0.5722746720455204\n",
      "54 166 0.46033144561225847\n",
      "Validation loss: 0.5213365485096535 MAE: 119.05855\n",
      "55 45 0.349226739571217\n",
      "55 95 0.42978836938424714\n",
      "55 145 0.5115693651807418\n",
      "Validation loss: 0.5019070720463469 MAE: 114.6214\n",
      "56 24 0.37331194338500645\n",
      "56 74 0.4945731908905826\n",
      "56 124 0.38461336312605277\n",
      "Validation loss: 0.4625025088326973 MAE: 105.62251\n",
      "57 3 0.5116017512367624\n",
      "57 53 0.2862315247836319\n",
      "57 103 0.3808671523499724\n",
      "57 153 0.41625682399339214\n",
      "Validation loss: 0.46636061640510784 MAE: 106.50361\n",
      "58 32 0.36219494485620396\n",
      "58 82 0.35286554530049147\n",
      "58 132 0.4391607089706425\n",
      "Validation loss: 0.4824378839013172 MAE: 110.175186\n",
      "59 11 0.31997448594171923\n",
      "59 61 0.36693226857470546\n",
      "59 111 0.4562963029775497\n",
      "59 161 0.3705609911708676\n",
      "Validation loss: 0.607807159075263 MAE: 138.806\n",
      "60 40 0.25383805975223106\n",
      "60 90 0.2993856819804398\n",
      "60 140 0.27300525837281786\n",
      "Validation loss: 0.5964269083842897 MAE: 136.20706\n",
      "61 19 0.4210794428990763\n",
      "61 69 0.37957622275051656\n",
      "61 119 0.2647991887647166\n",
      "61 169 0.3351835740415744\n",
      "Validation loss: 0.5665493328668918 MAE: 129.38388\n",
      "62 48 0.24181587470335414\n",
      "62 98 0.4810746394229425\n",
      "62 148 0.4151335811839577\n",
      "Validation loss: 0.5468887195252535 MAE: 124.893936\n",
      "63 27 0.464992478503929\n",
      "63 77 0.41925282876405756\n",
      "63 127 0.26003356509456926\n",
      "Validation loss: 0.6701165319186205 MAE: 153.0357\n",
      "64 6 0.346070341643325\n",
      "64 56 0.3926335185077652\n",
      "64 106 0.38006766252713664\n",
      "64 156 0.34268214034247535\n",
      "Validation loss: 0.6042118030681944 MAE: 137.98492\n",
      "65 35 0.4909275806027703\n",
      "65 85 0.42213416335621057\n",
      "65 135 0.32638893972341415\n",
      "Validation loss: 0.65333884919596 MAE: 149.20415\n",
      "66 14 0.25271083624174856\n",
      "66 64 0.43956888856562926\n",
      "66 114 0.26860610882706554\n",
      "66 164 0.4064259434580114\n",
      "Validation loss: 0.5201866072520875 MAE: 118.79594\n",
      "67 43 0.42509841201923004\n",
      "67 93 0.535757314233684\n",
      "67 143 0.4177020060457379\n",
      "Validation loss: 0.4137529908565053 MAE: 94.4895\n",
      "68 22 0.3822530487459318\n",
      "68 72 0.3213816237134305\n",
      "68 122 0.32564444493238354\n",
      "Validation loss: 0.49908460301962515 MAE: 113.97684\n",
      "69 1 0.3268484041023789\n",
      "69 51 0.32308030345924393\n",
      "69 101 0.30489205569198913\n",
      "69 151 0.32023902762286927\n",
      "Validation loss: 0.4823649773123669 MAE: 110.158554\n",
      "70 30 0.2875567567311712\n",
      "70 80 0.3519954917798417\n",
      "70 130 0.2501949817163295\n",
      "Validation loss: 0.4012543194823795 MAE: 91.63516\n",
      "71 9 0.3302699693937126\n",
      "71 59 0.3536782762721014\n",
      "71 109 0.23240006907158964\n",
      "71 159 0.2673468297839841\n",
      "Validation loss: 0.6440902244277865 MAE: 147.09204\n",
      "72 38 0.3812442236584919\n",
      "72 88 0.47874806556603133\n",
      "72 138 0.25916870259543534\n",
      "Validation loss: 0.3966501380442179 MAE: 90.5837\n",
      "73 17 0.4375783241020501\n",
      "73 67 0.43812991556342806\n",
      "73 117 0.22501062794345889\n",
      "73 167 0.40855210798169034\n",
      "Validation loss: 0.5824162320435395 MAE: 133.00743\n",
      "74 46 0.4409792591569412\n",
      "74 96 0.3362469482578251\n",
      "74 146 0.30756488699889367\n",
      "Validation loss: 0.5946919360356024 MAE: 135.81085\n",
      "75 25 0.4728225715608002\n",
      "75 75 0.43536130038388493\n",
      "75 125 0.3925018942461823\n",
      "Validation loss: 0.44712009137136893 MAE: 102.109604\n",
      "76 4 0.33591258516353484\n",
      "76 54 0.3724987701591762\n",
      "76 104 0.26652820403196725\n",
      "76 154 0.21466088294194247\n",
      "Validation loss: 0.5465982666141108 MAE: 124.82762\n",
      "77 33 0.295918748713669\n",
      "77 83 0.36776617417750723\n",
      "77 133 0.24436304749313367\n",
      "Validation loss: 0.4874510033088818 MAE: 111.32006\n",
      "78 12 0.31484346188054146\n",
      "78 62 0.4661368967558707\n",
      "78 112 0.2574257584983159\n",
      "78 162 0.5960113817615686\n",
      "Validation loss: 0.6413916635234453 MAE: 146.47575\n",
      "79 41 0.5268123191349623\n",
      "79 91 0.29056014935690583\n",
      "79 141 0.31271794515191675\n",
      "Validation loss: 0.6233609749211205 MAE: 142.35805\n",
      "80 20 0.4506034235758908\n",
      "80 70 0.25192075746977305\n",
      "80 120 0.3874776362737876\n",
      "80 170 0.40360022616698715\n",
      "Validation loss: 0.5917323127127531 MAE: 135.13496\n",
      "81 49 0.3864741518783353\n",
      "81 99 0.2883883037376453\n",
      "81 149 0.4286318378990455\n",
      "Validation loss: 0.5711440635703461 MAE: 130.43318\n",
      "82 28 0.2928065394519236\n",
      "82 78 0.27550424015299446\n",
      "82 128 0.41513350812669964\n",
      "Validation loss: 0.8170974932567417 MAE: 186.60199\n",
      "83 7 0.2940203664482678\n",
      "83 57 0.551159408760677\n",
      "83 107 0.3306097684165644\n",
      "83 157 0.24854246134834607\n",
      "Validation loss: 0.6583334855866014 MAE: 150.34477\n",
      "84 36 0.35325472100909944\n",
      "84 86 0.45408431480422146\n",
      "84 136 0.2298470283532129\n",
      "Validation loss: 0.5884878318212186 MAE: 134.39401\n",
      "85 15 0.20496700976135246\n",
      "85 65 0.42013569597172595\n",
      "85 115 0.24654598278630255\n",
      "85 165 0.3398953429562385\n",
      "Validation loss: 0.6431635987688924 MAE: 146.88042\n",
      "86 44 0.22991335638820298\n",
      "86 94 0.48073217684010705\n",
      "86 144 0.3722011207164847\n",
      "Validation loss: 0.5054384103992529 MAE: 115.42786\n",
      "87 23 0.21967576255725546\n",
      "87 73 0.285101513733706\n",
      "87 123 0.3779403846595688\n",
      "Validation loss: 0.5183457359235887 MAE: 118.37553\n",
      "88 2 0.3635003763442376\n",
      "88 52 0.40959795261700227\n",
      "88 102 0.32617736284331883\n",
      "88 152 0.35431868752269147\n",
      "Validation loss: 0.466564643104174 MAE: 106.550186\n",
      "89 31 0.17046457100554518\n",
      "89 81 0.19528531927243037\n",
      "89 131 0.3762297503791378\n",
      "Validation loss: 0.5207081916388016 MAE: 118.91505\n",
      "90 10 0.2723664991623063\n",
      "90 60 0.29227213545140635\n",
      "90 110 0.4636733224268735\n",
      "90 160 0.3786317518315151\n",
      "Validation loss: 0.6276656361351236 MAE: 143.34113\n",
      "91 39 0.36088550802385455\n",
      "91 89 0.33492943071088616\n",
      "91 139 0.5436972570730326\n",
      "Validation loss: 0.4982051343945732 MAE: 113.775986\n",
      "92 18 0.30011762044563284\n",
      "92 68 0.27927833739203534\n",
      "92 118 0.28700546243803937\n",
      "92 168 0.37506917980107674\n",
      "Validation loss: 0.5650550067773339 MAE: 129.04263\n",
      "93 47 0.3813668705066966\n",
      "93 97 0.22993243325967325\n",
      "93 147 0.4310196194026671\n",
      "Validation loss: 0.5398659601546171 MAE: 123.290146\n",
      "94 26 0.3591212736838901\n",
      "94 76 0.28843908579923055\n",
      "94 126 0.4350352448467672\n",
      "Validation loss: 0.5912775669181556 MAE: 135.03111\n",
      "95 5 0.3311306884948359\n",
      "95 55 0.3299774734025368\n",
      "95 105 0.31883683696517\n",
      "95 155 0.3717515463429682\n",
      "Validation loss: 0.7312225807479947 MAE: 166.9906\n",
      "96 34 0.2565888272370794\n",
      "96 84 0.324892653017332\n",
      "96 134 0.3596169458930792\n",
      "Validation loss: 0.6859454495167872 MAE: 156.65059\n",
      "97 13 0.24200598418095795\n",
      "97 63 0.4120245590404933\n",
      "97 113 0.32994751244190756\n",
      "97 163 0.3526119418505479\n",
      "Validation loss: 0.5704263054836564 MAE: 130.26926\n",
      "98 42 0.27748057543830157\n",
      "98 92 0.2931293605424057\n",
      "98 142 0.20525377691049568\n",
      "Validation loss: 0.5495180442319278 MAE: 125.4944\n",
      "99 21 0.4660379369046232\n",
      "99 71 0.39446460059786653\n",
      "99 121 0.3033081332508823\n",
      "Validation loss: 0.5727237065633138 MAE: 130.79393\n",
      "100 0 0.29810977280913675\n",
      "100 50 0.28366820610193455\n",
      "100 100 0.353702524545314\n",
      "100 150 0.3897361813461675\n",
      "Validation loss: 0.5454255084545292 MAE: 124.559784\n",
      "101 29 0.26470199125051164\n",
      "101 79 0.3554008907179787\n",
      "101 129 0.31196132093233797\n",
      "Validation loss: 0.5725720514330948 MAE: 130.7593\n",
      "102 8 0.33648000139336864\n",
      "102 58 0.2967262967577751\n",
      "102 108 0.3851395597135098\n",
      "102 158 0.37888067997757297\n",
      "Validation loss: 0.6513770923279879 MAE: 148.75615\n",
      "103 37 0.213500579456116\n",
      "103 87 0.48415444451020073\n",
      "103 137 0.38304351625040695\n",
      "Validation loss: 0.5184026339597869 MAE: 118.38853\n",
      "104 16 0.4245633635342563\n",
      "104 66 0.2602211588070635\n",
      "104 116 0.2845738412346035\n",
      "104 166 0.30933871947834846\n",
      "Validation loss: 0.6455864383463275 MAE: 147.43372\n",
      "105 45 0.29797722595100845\n",
      "105 95 0.3150574327841176\n",
      "105 145 0.3538207476325565\n",
      "Validation loss: 0.7075140775992856 MAE: 161.57623\n",
      "106 24 0.3200417791770519\n",
      "106 74 0.2918431797026586\n",
      "106 124 0.2832314069876523\n",
      "Validation loss: 0.6663398296512358 MAE: 152.17322\n",
      "107 3 0.2992263413374279\n",
      "107 53 0.23522944213774474\n",
      "107 103 0.3823918895131257\n",
      "107 153 0.24423635823782744\n",
      "Validation loss: 0.5750144246028878 MAE: 131.31706\n",
      "108 32 0.2687369432604776\n",
      "108 82 0.34088031156961884\n",
      "108 132 0.30061954727642726\n",
      "Validation loss: 0.5034339652772535 MAE: 114.97011\n",
      "109 11 0.33188132465140596\n",
      "109 61 0.2598471821662342\n",
      "109 111 0.24703721893804045\n",
      "109 161 0.40644399605284837\n",
      "Validation loss: 0.5947694989324314 MAE: 135.82855\n",
      "110 40 0.36590534611632863\n",
      "110 90 0.22231009004912522\n",
      "110 140 0.44166197906692967\n",
      "Validation loss: 0.5926434366326583 MAE: 135.34305\n",
      "111 19 0.5135299580553315\n",
      "111 69 0.3233969228797758\n",
      "111 119 0.37465322535500073\n",
      "111 169 0.27965676717495985\n",
      "Validation loss: 0.702421822743109 MAE: 160.41331\n",
      "112 48 0.38646863021619465\n",
      "112 98 0.3161393571121567\n",
      "112 148 0.21224816989173545\n",
      "Validation loss: 0.5063214117323446 MAE: 115.629524\n",
      "113 27 0.3935624413193425\n",
      "113 77 0.40300358648867207\n",
      "113 127 0.25404938461748616\n",
      "Validation loss: 0.6669571894651268 MAE: 152.31421\n",
      "114 6 0.2872320603637914\n",
      "114 56 0.24524018476862836\n",
      "114 106 0.37979917231670424\n",
      "114 156 0.35200220941036947\n",
      "Validation loss: 0.5815361316441096 MAE: 132.80644\n",
      "115 35 0.3691351694418184\n",
      "115 85 0.3345888918985119\n",
      "115 135 0.36001618871163366\n",
      "Validation loss: 0.5549014899117207 MAE: 126.72385\n",
      "116 14 0.24470239811211086\n",
      "116 64 0.2709802586555924\n",
      "116 114 0.29384893335785817\n",
      "116 164 0.29809616364088276\n",
      "Validation loss: 0.7628949413522642 MAE: 174.22368\n",
      "117 43 0.27899969464938\n",
      "117 93 0.3690130965025602\n",
      "117 143 0.24938831049568042\n",
      "Validation loss: 0.6825478481270416 MAE: 155.87466\n",
      "118 22 0.3389581075309215\n",
      "118 72 0.386638326179644\n",
      "118 122 0.2262928697515496\n",
      "Validation loss: 0.44624825475508706 MAE: 101.9105\n",
      "119 1 0.27483204841999576\n",
      "119 51 0.266756712861586\n",
      "119 101 0.36180407751981875\n",
      "119 151 0.2243583258306713\n",
      "Validation loss: 0.689214435237193 MAE: 157.39713\n",
      "120 30 0.2750391057569702\n",
      "120 80 0.2681188822005263\n",
      "120 130 0.17855612128002274\n",
      "Validation loss: 0.5004839311566269 MAE: 114.29641\n",
      "121 9 0.2705178812745157\n",
      "121 59 0.20911100372919203\n",
      "121 109 0.38146605748159657\n",
      "121 159 0.3181666949478324\n",
      "Validation loss: 0.5660442221931546 MAE: 129.26852\n",
      "122 38 0.429426481916006\n",
      "122 88 0.37338870815270225\n",
      "122 138 0.2534620346647559\n",
      "Validation loss: 0.5299717989581371 MAE: 121.03059\n",
      "123 17 0.3202780766774427\n",
      "123 67 0.3743622469362521\n",
      "123 117 0.3383785669118801\n",
      "123 167 0.2818370698271364\n",
      "Validation loss: 0.5721587026328371 MAE: 130.6649\n",
      "124 46 0.4070172214145493\n",
      "124 96 0.36634681264351066\n",
      "124 146 0.3789186173991703\n",
      "Validation loss: 0.553041586750432 MAE: 126.29909\n",
      "125 25 0.28979282382759347\n",
      "125 75 0.37919455470839475\n",
      "125 125 0.35460875154664945\n",
      "Validation loss: 0.6016789571932185 MAE: 137.4065\n",
      "126 4 0.19262769994841503\n",
      "126 54 0.2685016151294952\n",
      "126 104 0.22357757685463087\n",
      "126 154 0.20877438656359593\n",
      "Validation loss: 0.5882625123213606 MAE: 134.34256\n",
      "127 33 0.3966673369283973\n",
      "127 83 0.32071588427835607\n",
      "127 133 0.27673081188668264\n",
      "Validation loss: 0.5728188627644589 MAE: 130.81566\n",
      "128 12 0.3726531112512659\n",
      "128 62 0.34472206016850326\n",
      "128 112 0.34892911704453256\n",
      "128 162 0.19315000681475802\n",
      "Validation loss: 0.6656215138602675 MAE: 152.00916\n",
      "129 41 0.3250338543442534\n",
      "129 91 0.2322845329361254\n",
      "129 141 0.1551896244061352\n",
      "Validation loss: 0.6009896191937184 MAE: 137.24907\n",
      "130 20 0.329074561239061\n",
      "130 70 0.4268117446997656\n",
      "130 120 0.41772819865352306\n",
      "130 170 0.302652043736008\n",
      "Validation loss: 0.6702745814769588 MAE: 153.0718\n",
      "131 49 0.28114333190176233\n",
      "131 99 0.26602604597512497\n",
      "131 149 0.2901491338573865\n",
      "Validation loss: 0.6478434309624789 MAE: 147.94916\n",
      "132 28 0.20598151435494771\n",
      "132 78 0.3268898875761622\n",
      "132 128 0.2901714774263744\n",
      "Validation loss: 0.625386775585643 MAE: 142.82068\n",
      "133 7 0.3162482430343796\n",
      "133 57 0.32058731153517733\n",
      "133 107 0.29501580552331996\n",
      "133 157 0.22228750398780456\n",
      "Validation loss: 0.5179429270370662 MAE: 118.28355\n",
      "134 36 0.32373889625546803\n",
      "134 86 0.4593859755355965\n",
      "134 136 0.345976841366448\n",
      "Validation loss: 0.5616743902713932 MAE: 128.27057\n",
      "135 15 0.26701583011266256\n",
      "135 65 0.31251300077483235\n",
      "135 115 0.35424147602629574\n",
      "135 165 0.28432243707240556\n",
      "Validation loss: 0.7426452218440541 MAE: 169.59921\n",
      "136 44 0.3105946657029187\n",
      "136 94 0.37092090606350864\n",
      "136 144 0.24542256111529712\n",
      "Validation loss: 0.5359116773507748 MAE: 122.38711\n",
      "137 23 0.4133985743658644\n",
      "137 73 0.2644942600058252\n",
      "137 123 0.3048181264772749\n",
      "Validation loss: 0.5669602891157942 MAE: 129.47772\n",
      "138 2 0.3700439599153054\n",
      "138 52 0.2885874811320735\n",
      "138 102 0.241543264170204\n",
      "138 152 0.2163482771971598\n",
      "Validation loss: 0.6570050538631907 MAE: 150.04141\n",
      "139 31 0.29950474123749093\n",
      "139 81 0.29587013919387595\n",
      "139 131 0.32789888220346153\n",
      "Validation loss: 0.5500533877060427 MAE: 125.61666\n",
      "140 10 0.2627837071064638\n",
      "140 60 0.2731392370139588\n",
      "140 110 0.17210871761639746\n",
      "140 160 0.39881550922950676\n",
      "Validation loss: 0.6047679053412544 MAE: 138.11192\n",
      "141 39 0.3226366225725401\n",
      "141 89 0.48822546217313323\n",
      "141 139 0.4138297018801955\n",
      "Validation loss: 0.6550662914911906 MAE: 149.59866\n",
      "142 18 0.2611289737858136\n",
      "142 68 0.5457781649493452\n",
      "142 118 0.4639422034155215\n",
      "142 168 0.38963245724863677\n",
      "Validation loss: 0.637303096160554 MAE: 145.54204\n",
      "143 47 0.22711808562364674\n",
      "143 97 0.3371771577119206\n",
      "143 147 0.34423834315669344\n",
      "Validation loss: 0.5451194696259081 MAE: 124.48991\n",
      "144 26 0.22503633045119387\n",
      "144 76 0.2256981407718648\n",
      "144 126 0.31160213981146706\n",
      "Validation loss: 0.594152647849412 MAE: 135.6877\n",
      "145 5 0.17665224992892245\n",
      "145 55 0.2988489492855552\n",
      "145 105 0.36487891807186235\n",
      "145 155 0.32778411049521583\n",
      "Validation loss: 0.6339208828775507 MAE: 144.76964\n",
      "146 34 0.24894076872706036\n",
      "146 84 0.20577137216755878\n",
      "146 134 0.4684790091930435\n",
      "Validation loss: 0.5640971409647089 MAE: 128.82387\n",
      "147 13 0.23173100398461027\n",
      "147 63 0.37905192270749233\n",
      "147 113 0.2634452163837329\n",
      "147 163 0.40456889870548196\n",
      "Validation loss: 0.601979226135371 MAE: 137.47508\n",
      "148 42 0.24978494254123443\n",
      "148 92 0.2791842409150133\n",
      "148 142 0.3414996207788449\n",
      "Validation loss: 0.5731891024182414 MAE: 130.90022\n",
      "149 21 0.21891867552680716\n",
      "149 71 0.2566539480419165\n",
      "149 121 0.260915909574247\n",
      "Validation loss: 0.6017352478546009 MAE: 137.41934\n",
      "150 0 0.5158342304658662\n",
      "150 50 0.2316707299760153\n",
      "150 100 0.19609984841080577\n",
      "150 150 0.3939364052101663\n",
      "Validation loss: 0.5796986783457081 MAE: 132.38681\n",
      "151 29 0.2623521521312939\n",
      "151 79 0.3493355381236573\n",
      "151 129 0.2831927131928185\n",
      "Validation loss: 0.5547896435386256 MAE: 126.698296\n",
      "152 8 0.22744062465809714\n",
      "152 58 0.22680199733918507\n",
      "152 108 0.397278649689148\n",
      "152 158 0.224787143604194\n",
      "Validation loss: 0.6173187016743665 MAE: 140.97816\n",
      "153 37 0.18255631646187662\n",
      "153 87 0.2504779620947115\n",
      "153 137 0.15512399185198036\n",
      "Validation loss: 0.5917619926887646 MAE: 135.14174\n",
      "154 16 0.2955294547614802\n",
      "154 66 0.2607086831783386\n",
      "154 116 0.441322218662288\n",
      "154 166 0.3164286153480463\n",
      "Validation loss: 0.5052810788851733 MAE: 115.39193\n",
      "155 45 0.3827448508146704\n",
      "155 95 0.22848404009176446\n",
      "155 145 0.2590647280383502\n",
      "Validation loss: 0.6217857972223159 MAE: 141.99834\n",
      "156 24 0.2566483151121634\n",
      "156 74 0.2369683443627985\n",
      "156 124 0.20677117590624103\n",
      "Validation loss: 0.5460544896056081 MAE: 124.70343\n",
      "157 3 0.2565690423530775\n",
      "157 53 0.2412721759484045\n",
      "157 103 0.19076582997247804\n",
      "157 153 0.32774385023492425\n",
      "Validation loss: 0.5168136051523755 MAE: 118.02564\n",
      "158 32 0.2482933309180261\n",
      "158 82 0.4107412931411303\n",
      "158 132 0.35177427342605505\n",
      "Validation loss: 0.5931061178620098 MAE: 135.4487\n",
      "159 11 0.44757162880835\n",
      "159 61 0.12825209130551704\n",
      "159 111 0.46996451711191894\n",
      "159 161 0.18746378600038363\n",
      "Validation loss: 0.5846562894464237 MAE: 133.51901\n",
      "160 40 0.41114783325889925\n",
      "160 90 0.2790243554754431\n",
      "160 140 0.13697173500071408\n",
      "Validation loss: 0.6585081073275784 MAE: 150.38466\n",
      "161 19 0.526754897022336\n",
      "161 69 0.22920668393713373\n",
      "161 119 0.2975965068991307\n",
      "161 169 0.18039169448330708\n",
      "Validation loss: 0.5147937696579604 MAE: 117.56438\n",
      "162 48 0.2768288567465353\n",
      "162 98 0.3476367452989992\n",
      "162 148 0.2417195313417074\n",
      "Validation loss: 0.543410861701296 MAE: 124.0997\n",
      "163 27 0.18635020120138543\n",
      "163 77 0.42937636462780626\n",
      "163 127 0.3402926223062683\n",
      "Validation loss: 0.5831325339992144 MAE: 133.17102\n",
      "164 6 0.34505268477135037\n",
      "164 56 0.23291549816330803\n",
      "164 106 0.2783279785165364\n",
      "164 156 0.206924913327842\n",
      "Validation loss: 0.5954509872442101 MAE: 135.98419\n",
      "165 35 0.24498454268911327\n",
      "165 85 0.30260913093744013\n",
      "165 135 0.23675705819743934\n",
      "Validation loss: 0.5820042658270451 MAE: 132.91335\n",
      "166 14 0.3387195198811743\n",
      "166 64 0.24510165260757136\n",
      "166 114 0.3709967683718302\n",
      "166 164 0.2855100746290214\n",
      "Validation loss: 0.650020558583109 MAE: 148.44633\n",
      "167 43 0.37682565496396825\n",
      "167 93 0.4436216858343457\n",
      "167 143 0.32034804684098467\n",
      "Validation loss: 0.552861912208691 MAE: 126.25805\n",
      "168 22 0.2659165071419362\n",
      "168 72 0.33794298275276496\n",
      "168 122 0.3671870642651892\n",
      "Validation loss: 0.5537567365239238 MAE: 126.46241\n",
      "169 1 0.3983698603969082\n",
      "169 51 0.2130167453182683\n",
      "169 101 0.21021615488653375\n",
      "169 151 0.43968945609417764\n",
      "Validation loss: 0.6221217687366999 MAE: 142.07506\n",
      "170 30 0.29026075136741764\n",
      "170 80 0.5441448184233846\n",
      "170 130 0.27081220707281883\n",
      "Validation loss: 0.696289194606201 MAE: 159.0128\n",
      "171 9 0.2950976513034448\n",
      "171 59 0.3197948152618272\n",
      "171 109 0.351559164540469\n",
      "171 159 0.19656500957779327\n",
      "Validation loss: 0.5477984871780663 MAE: 125.1017\n",
      "172 38 0.25901499470037315\n",
      "172 88 0.20184285243171524\n",
      "172 138 0.3256050819795675\n",
      "Validation loss: 0.6786234408442737 MAE: 154.97844\n",
      "173 17 0.3307836846206876\n",
      "173 67 0.33389354909575286\n",
      "173 117 0.2875985557930418\n",
      "173 167 0.44099964287865395\n",
      "Validation loss: 0.6114171384370815 MAE: 139.63042\n",
      "174 46 0.4632668642925386\n",
      "174 96 0.23117684561068225\n",
      "174 146 0.3447125506797345\n",
      "Validation loss: 0.49761134630058246 MAE: 113.640396\n",
      "175 25 0.26227994461969095\n",
      "175 75 0.3638281785829905\n",
      "175 125 0.35282985951182494\n",
      "Validation loss: 0.5455332717351746 MAE: 124.584404\n",
      "176 4 0.18727130180511814\n",
      "176 54 0.4144650605576184\n",
      "176 104 0.3687440511824665\n",
      "176 154 0.24726247937329754\n",
      "Validation loss: 0.6196523130985728 MAE: 141.5111\n",
      "177 33 0.3327367635456556\n",
      "177 83 0.27286688036558854\n",
      "177 133 0.3535276823808037\n",
      "Validation loss: 0.5121044307424311 MAE: 116.9502\n",
      "178 12 0.2813243182748597\n",
      "178 62 0.3009397647756891\n",
      "178 112 0.2956912606926021\n",
      "178 162 0.3872300793258713\n",
      "Validation loss: 0.523955770403321 MAE: 119.65671\n",
      "179 41 0.34784510885277115\n",
      "179 91 0.32297547480621375\n",
      "179 141 0.3225882731628811\n",
      "Validation loss: 0.5036813024191829 MAE: 115.0266\n",
      "180 20 0.21523146499327334\n",
      "180 70 0.2908950321678998\n",
      "180 120 0.2422382863339979\n",
      "180 170 0.2591658641496207\n",
      "Validation loss: 0.5905493246881586 MAE: 134.86479\n",
      "181 49 0.26054139623942424\n",
      "181 99 0.28630076873789895\n",
      "181 149 0.1773200517468752\n",
      "Validation loss: 0.5194594745050397 MAE: 118.629875\n",
      "182 28 0.3042089556248942\n",
      "182 78 0.4106455826475247\n",
      "182 128 0.278560902570216\n",
      "Validation loss: 0.5157785514990488 MAE: 117.78927\n",
      "183 7 0.316458959428192\n",
      "183 57 0.3306630521186322\n",
      "183 107 0.2952463576180861\n",
      "183 157 0.20141321941762405\n",
      "Validation loss: 0.5861501484586481 MAE: 133.86015\n",
      "184 36 0.2720090486018821\n",
      "184 86 0.41669198265846874\n",
      "184 136 0.19271368205405287\n",
      "Validation loss: 0.5656150955902902 MAE: 129.17053\n",
      "185 15 0.24141981744697974\n",
      "185 65 0.2800152434066439\n",
      "185 115 0.29992579788374885\n",
      "185 165 0.33485774891169057\n",
      "Validation loss: 0.4993125705691109 MAE: 114.0289\n",
      "186 44 0.4644269012852604\n",
      "186 94 0.27713378483466816\n",
      "186 144 0.3415985681645452\n",
      "Validation loss: 0.6126702023528473 MAE: 139.91658\n",
      "187 23 0.24992077993208375\n",
      "187 73 0.236992363608053\n",
      "187 123 0.247510343371134\n",
      "Validation loss: 0.5442588573310807 MAE: 124.29336\n",
      "188 2 0.25580010557229127\n",
      "188 52 0.23740149062249383\n",
      "188 102 0.3012404954904156\n",
      "188 152 0.17291191331554545\n",
      "Validation loss: 0.5523343731088248 MAE: 126.13757\n",
      "189 31 0.3111795165753961\n",
      "189 81 0.2097509275408545\n",
      "189 131 0.23155835929352772\n",
      "Validation loss: 0.5990437053100407 MAE: 136.80467\n",
      "190 10 0.4368807751856886\n",
      "190 60 0.30253312739333516\n",
      "190 110 0.19564275750593368\n",
      "190 160 0.3265771446676661\n",
      "Validation loss: 0.5740582099434925 MAE: 131.09871\n",
      "191 39 0.2753146260699771\n",
      "191 89 0.21015803147191245\n",
      "191 139 0.3569194943930675\n",
      "Validation loss: 0.5244285601970048 MAE: 119.76469\n",
      "192 18 0.4428332114278363\n",
      "192 68 0.3493693192754787\n",
      "192 118 0.284253112559179\n",
      "192 168 0.3727935669119094\n",
      "Validation loss: 0.5704142266546773 MAE: 130.26651\n",
      "193 47 0.3513606246695716\n",
      "193 97 0.2179468939986739\n",
      "193 147 0.3591512550533413\n",
      "Validation loss: 0.5228281286027696 MAE: 119.39918\n",
      "194 26 0.22844276386436116\n",
      "194 76 0.23957501135296486\n",
      "194 126 0.22509612011052763\n",
      "Validation loss: 0.6177618503570557 MAE: 141.07938\n",
      "195 5 0.21696369445988772\n",
      "195 55 0.31809817835468\n",
      "195 105 0.17394125963336032\n",
      "195 155 0.2560148229017768\n",
      "Validation loss: 0.6227823213527077 MAE: 142.2259\n",
      "196 34 0.3893069561999058\n",
      "196 84 0.2797524828093086\n",
      "196 134 0.2509301907612711\n",
      "Validation loss: 0.633229058388381 MAE: 144.61165\n",
      "197 13 0.15003840367125473\n",
      "197 63 0.2587257045822289\n",
      "197 113 0.3443027283977079\n",
      "197 163 0.2455699679946616\n",
      "Validation loss: 0.583641741359443 MAE: 133.2873\n",
      "198 42 0.26831722964596705\n",
      "198 92 0.2183605755516763\n",
      "198 142 0.24643283467995017\n",
      "Validation loss: 0.5448517841205263 MAE: 124.428764\n",
      "199 21 0.1611961349855011\n",
      "199 71 0.19168342769280505\n",
      "199 121 0.20519907990845143\n",
      "Validation loss: 0.6563227811054877 MAE: 149.8856\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.31744223252746057 Test MAE: 72.49484\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bace', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'classification', 'data_path': 'data/bace/bace.csv', 'target': ['Class']}}\n",
      "Running on: cuda:1\n",
      "1512\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1512\n",
      "Generating scaffold 1000/1512\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.3803974167990387\n",
      "Validation loss: 0.7120405028987404 ROC AUC: 0.5225017717930545\n",
      "1 12 0.8399840622082845\n",
      "Validation loss: 0.8816932660854415 ROC AUC: 0.5120481927710844\n",
      "2 24 0.6918727423644533\n",
      "Validation loss: 1.6489440802706787 ROC AUC: 0.6100283486888732\n",
      "3 36 0.744710188170015\n",
      "Validation loss: 0.7070345112819545 ROC AUC: 0.5981573352232459\n",
      "Validation loss: 1.081127960160868 ROC AUC: 0.5581148121899362\n",
      "5 10 0.7062379784127016\n",
      "Validation loss: 0.842183460068229 ROC AUC: 0.5745924875974486\n",
      "6 22 0.5647326262036669\n",
      "Validation loss: 0.6907010346848443 ROC AUC: 0.6413890857547838\n",
      "7 34 0.5468735561056858\n",
      "Validation loss: 0.7241872734581398 ROC AUC: 0.6190644932671865\n",
      "Validation loss: 0.6989543643218792 ROC AUC: 0.635896527285613\n",
      "9 8 0.5750326398445507\n",
      "Validation loss: 0.7574351500991164 ROC AUC: 0.670623671155209\n",
      "10 20 0.546414785535502\n",
      "Validation loss: 0.6738034640716402 ROC AUC: 0.6665485471296952\n",
      "11 32 0.40982875336954094\n",
      "Validation loss: 0.7456860210721856 ROC AUC: 0.6509567682494684\n",
      "Validation loss: 0.8162550286741446 ROC AUC: 0.6041814316087881\n",
      "13 6 0.4873938432643044\n",
      "Validation loss: 1.0711712892481824 ROC AUC: 0.6389085754783841\n",
      "14 18 0.5329999531852405\n",
      "Validation loss: 0.8312794266157593 ROC AUC: 0.6210134656272147\n",
      "15 30 0.45555655002633305\n",
      "Validation loss: 0.7470387678272676 ROC AUC: 0.6442239546420977\n",
      "Validation loss: 0.8150834989863516 ROC AUC: 0.6798369950389794\n",
      "17 4 0.506852423296714\n",
      "Validation loss: 1.1247509812677143 ROC AUC: 0.6775336640680367\n",
      "18 16 0.4467057046191621\n",
      "Validation loss: 1.0668144123443704 ROC AUC: 0.6672572643515237\n",
      "19 28 0.4298389768739789\n",
      "Validation loss: 0.7048966118831508 ROC AUC: 0.6738128986534373\n",
      "Validation loss: 0.7170783541849907 ROC AUC: 0.6816087880935505\n",
      "21 2 0.34191475518691866\n",
      "Validation loss: 0.8903106064196454 ROC AUC: 0.6482990786676116\n",
      "22 14 0.5806941852081834\n",
      "Validation loss: 0.9000805975585584 ROC AUC: 0.6869241672572644\n",
      "23 26 0.28093130039301467\n",
      "Validation loss: 0.9203498616123831 ROC AUC: 0.6119773210489015\n",
      "Validation loss: 0.8010505757584477 ROC AUC: 0.6699149539333806\n",
      "25 0 0.2933668447327896\n",
      "Validation loss: 1.0098415747383573 ROC AUC: 0.6532600992204111\n",
      "26 12 0.363412719212055\n",
      "Validation loss: 0.8005590407264154 ROC AUC: 0.6654854712969525\n",
      "27 24 0.4053822555508668\n",
      "Validation loss: 0.801833383689653 ROC AUC: 0.6669029057406095\n",
      "28 36 0.4420308734818554\n",
      "Validation loss: 0.8825990573459903 ROC AUC: 0.6284549964564139\n",
      "Validation loss: 0.7017367442712089 ROC AUC: 0.6856839121190644\n",
      "30 10 0.41830226152459493\n",
      "Validation loss: 0.7459613440052563 ROC AUC: 0.6789510985116939\n",
      "31 22 0.3799736266078446\n",
      "Validation loss: 0.8392707125240604 ROC AUC: 0.651842664776754\n",
      "32 34 0.35978946015708846\n",
      "Validation loss: 1.0516809161925158 ROC AUC: 0.6807228915662651\n",
      "Validation loss: 0.8703100953670527 ROC AUC: 0.6583982990786676\n",
      "34 8 0.3341258736180994\n",
      "Validation loss: 0.9700872637578194 ROC AUC: 0.6729270021261516\n",
      "35 20 0.42912291792388685\n",
      "Validation loss: 0.892328425353726 ROC AUC: 0.6587526576895818\n",
      "36 32 0.24515279357251282\n",
      "Validation loss: 0.9257588970740109 ROC AUC: 0.6679659815733522\n",
      "Validation loss: 0.7949915078302093 ROC AUC: 0.7074769666902905\n",
      "38 6 0.49173155566007937\n",
      "Validation loss: 0.8375386457569551 ROC AUC: 0.7099574769666903\n",
      "39 18 0.3312192446177689\n",
      "Validation loss: 0.7594402629808085 ROC AUC: 0.6461729270021261\n",
      "40 30 0.24683961101444551\n",
      "Validation loss: 0.8454099806728742 ROC AUC: 0.7051736357193479\n",
      "Validation loss: 0.9160155136853654 ROC AUC: 0.689404677533664\n",
      "42 4 0.38120378073104433\n",
      "Validation loss: 1.0732762142522445 ROC AUC: 0.6465272856130404\n",
      "43 16 0.429726972726819\n",
      "Validation loss: 0.7975103480136947 ROC AUC: 0.695074415308292\n",
      "44 28 0.4057455150047934\n",
      "Validation loss: 0.8133632359125756 ROC AUC: 0.58681785967399\n",
      "Validation loss: 0.9810092283400479 ROC AUC: 0.68656980864635\n",
      "46 2 0.339896067976699\n",
      "Validation loss: 0.7967047197929281 ROC AUC: 0.6984408221119773\n",
      "47 14 0.38630905823972156\n",
      "Validation loss: 0.7866685631259388 ROC AUC: 0.6973777462792347\n",
      "48 26 0.3246757880698098\n",
      "Validation loss: 0.9946555625523953 ROC AUC: 0.7016300496102055\n",
      "Validation loss: 0.6969591391007632 ROC AUC: 0.6940113394755492\n",
      "50 0 0.330489380020277\n",
      "Validation loss: 0.7550028669123618 ROC AUC: 0.6665485471296952\n",
      "51 12 0.3150512319383589\n",
      "Validation loss: 0.8862786194346598 ROC AUC: 0.7262579730687456\n",
      "71 2 0.41542994226615215\n",
      "Validation loss: 0.880628295292128 ROC AUC: 0.6731041814316088\n",
      "72 14 0.29225650921647356\n",
      "Validation loss: 0.8156458743360658 ROC AUC: 0.670623671155209\n",
      "73 26 0.4683324878115126\n",
      "Validation loss: 0.9285685187143995 ROC AUC: 0.6972005669737774\n",
      "Validation loss: 0.8520086964234611 ROC AUC: 0.7044649184975195\n",
      "75 0 0.24431837613049512\n",
      "Validation loss: 1.031579733684363 ROC AUC: 0.7168674698795181\n",
      "76 12 0.285915799452931\n",
      "Validation loss: 0.867863460092355 ROC AUC: 0.7468107725017717\n",
      "77 24 0.3207518905433156\n",
      "Validation loss: 0.8331256402249367 ROC AUC: 0.6867469879518072\n",
      "78 36 0.4077172613812171\n",
      "Validation loss: 0.8669488587916292 ROC AUC: 0.705173635719348\n",
      "Validation loss: 0.9487667585050823 ROC AUC: 0.6977321048901488\n",
      "80 10 0.4100357503317664\n",
      "Validation loss: 0.982363291134108 ROC AUC: 0.7119064493267186\n",
      "81 22 0.33025622602362675\n",
      "Validation loss: 0.7607387387199908 ROC AUC: 0.711020552799433\n",
      "82 34 0.2732464266102615\n",
      "Validation loss: 0.8787988333512615 ROC AUC: 0.6851523742026931\n",
      "Validation loss: 0.91563613012137 ROC AUC: 0.6819631467044649\n",
      "84 8 0.2202093902524494\n",
      "Validation loss: 0.936140175292034 ROC AUC: 0.6656626506024097\n",
      "85 20 0.21919617619887005\n",
      "Validation loss: 0.868731237799916 ROC AUC: 0.680545712260808\n",
      "86 32 0.44800422768147735\n",
      "Validation loss: 0.8768207742678409 ROC AUC: 0.6706236711552092\n",
      "Validation loss: 0.8816173597676864 ROC AUC: 0.6752303330970942\n",
      "88 6 0.22203518650012993\n",
      "Validation loss: 0.9511669005779241 ROC AUC: 0.6963146704464919\n",
      "89 18 0.2170185341166011\n",
      "Validation loss: 0.9022969350909555 ROC AUC: 0.7197023387668321\n",
      "90 30 0.2561537942138006\n",
      "Validation loss: 0.9357575797876775 ROC AUC: 0.7032246633593195\n",
      "Validation loss: 0.9152654488355119 ROC AUC: 0.7120836286321758\n",
      "92 4 0.2631748790031268\n",
      "Validation loss: 0.7823569561472002 ROC AUC: 0.7092487597448618\n",
      "93 16 0.33852721516886236\n",
      "Validation loss: 1.025187182900132 ROC AUC: 0.6982636428065203\n",
      "94 28 0.3818656316234589\n",
      "Validation loss: 0.870615888115586 ROC AUC: 0.7120836286321758\n",
      "Validation loss: 1.1082436470006476 ROC AUC: 0.679305457122608\n",
      "96 2 0.24560867339771505\n",
      "Validation loss: 0.8806400200389078 ROC AUC: 0.6920623671155209\n",
      "97 14 0.3524756920933067\n",
      "Validation loss: 0.8338291199002045 ROC AUC: 0.7150956768249469\n",
      "98 26 0.22273369447777927\n",
      "Validation loss: 0.9209342243655628 ROC AUC: 0.7119064493267185\n",
      "Validation loss: 0.9550979401891595 ROC AUC: 0.6945428773919206\n",
      "100 0 0.3442062654190377\n",
      "Validation loss: 1.0400530320919112 ROC AUC: 0.6915308291991495\n",
      "101 12 0.2756248599165616\n",
      "Validation loss: 0.8275693710276623 ROC AUC: 0.6975549255846917\n",
      "102 24 0.29002122258985696\n",
      "Validation loss: 0.9605585664313361 ROC AUC: 0.7402551381998582\n",
      "103 36 0.3013748727122813\n",
      "Validation loss: 0.9130508528639939 ROC AUC: 0.6941885187810064\n",
      "Validation loss: 0.9509597933845014 ROC AUC: 0.7092487597448617\n",
      "105 10 0.23716131463585344\n",
      "Validation loss: 1.0833196320281124 ROC AUC: 0.6768249468462084\n",
      "106 22 0.18059195754854224\n",
      "Validation loss: 0.957723684658278 ROC AUC: 0.7197023387668321\n",
      "107 34 0.16816978141782282\n",
      "Validation loss: 1.0182093322671801 ROC AUC: 0.708185683912119\n",
      "Validation loss: 1.229088934841535 ROC AUC: 0.7010985116938341\n",
      "109 8 0.2389573255188302\n",
      "Validation loss: 0.8972067927682637 ROC AUC: 0.7060595322466335\n",
      "110 20 0.26273663535128994\n",
      "Validation loss: 0.8798963242019249 ROC AUC: 0.7048192771084337\n",
      "111 32 0.28147009240548654\n",
      "Validation loss: 1.079158454541339 ROC AUC: 0.6909992912827781\n",
      "Validation loss: 1.0400527774892896 ROC AUC: 0.7101346562721473\n",
      "113 6 0.2727383452132688\n",
      "Validation loss: 0.9488321412478061 ROC AUC: 0.7111977321048901\n",
      "114 18 0.2367238103109797\n",
      "Validation loss: 0.9483389475487716 ROC AUC: 0.7303330970942594\n",
      "115 30 0.39902385777467503\n",
      "Validation loss: 0.9992272313067455 ROC AUC: 0.7478738483345146\n",
      "Validation loss: 0.9012130163363273 ROC AUC: 0.690822111977321\n",
      "117 4 0.32251020969441524\n",
      "Validation loss: 1.1704830622041462 ROC AUC: 0.7083628632175762\n",
      "118 16 0.2202291535692088\n",
      "Validation loss: 0.9852730541039776 ROC AUC: 0.7308646350106308\n",
      "119 28 0.2852269694544132\n",
      "Validation loss: 1.0489392430577058 ROC AUC: 0.677533664068037\n",
      "Validation loss: 0.9779897320349484 ROC AUC: 0.6911764705882354\n",
      "121 2 0.22904253245752162\n",
      "Validation loss: 1.1999347719135662 ROC AUC: 0.6823175053153792\n",
      "122 14 0.143252436553181\n",
      "Validation loss: 1.0269926798264712 ROC AUC: 0.7149184975194897\n",
      "123 26 0.15507545538068995\n",
      "Validation loss: 0.8464729718814622 ROC AUC: 0.7145641389085755\n",
      "Validation loss: 0.9564908936323709 ROC AUC: 0.7156272147413182\n",
      "125 0 0.31352656575533655\n",
      "Validation loss: 1.0882169568775506 ROC AUC: 0.7034018426647768\n",
      "126 12 0.24368608709326392\n",
      "Validation loss: 1.2743914214191059 ROC AUC: 0.698086463501063\n",
      "127 24 0.13858780226380668\n",
      "Validation loss: 1.1092819978069786 ROC AUC: 0.6989723600283487\n",
      "128 36 0.27409815952832856\n",
      "Validation loss: 1.3497319939910182 ROC AUC: 0.6858610914245216\n",
      "Validation loss: 1.0805464968183973 ROC AUC: 0.7285613040396881\n",
      "130 10 0.25299052312608983\n",
      "Validation loss: 1.1366017764767273 ROC AUC: 0.7028703047484054\n",
      "131 22 0.1644899108550015\n",
      "Validation loss: 1.131945115051522 ROC AUC: 0.7145641389085755\n",
      "132 34 0.2186608787414659\n",
      "Validation loss: 1.00239308740919 ROC AUC: 0.6961374911410347\n",
      "Validation loss: 1.1297036156749094 ROC AUC: 0.7032246633593197\n",
      "134 8 0.21168769614358518\n",
      "Validation loss: 0.9994120084686785 ROC AUC: 0.7032246633593197\n",
      "135 20 0.29919599873396663\n",
      "Validation loss: 1.1938449349624431 ROC AUC: 0.7010985116938342\n",
      "136 32 0.36433758908691305\n",
      "Validation loss: 1.0206166292657914 ROC AUC: 0.6708008504606662\n",
      "Validation loss: 1.2683914591934506 ROC AUC: 0.699326718639263\n",
      "138 6 0.37011701329508834\n",
      "Validation loss: 1.0189379343133889 ROC AUC: 0.6947200566973777\n",
      "139 18 0.257902914712633\n",
      "Validation loss: 1.1703873438550936 ROC AUC: 0.7285613040396881\n",
      "140 30 0.22755572004165392\n",
      "Validation loss: 1.1985528216456736 ROC AUC: 0.6847980155917789\n",
      "Validation loss: 1.2372831935124682 ROC AUC: 0.6610559886605244\n",
      "142 4 0.23873159034913444\n",
      "Validation loss: 1.0562908203396577 ROC AUC: 0.7149184975194897\n",
      "143 16 0.38956081537636633\n",
      "Validation loss: 1.0931990880839872 ROC AUC: 0.6941885187810064\n",
      "144 28 0.23055538215324986\n",
      "Validation loss: 1.3635129557540084 ROC AUC: 0.6762934089298369\n",
      "Validation loss: 0.9755497160336829 ROC AUC: 0.7306874557051737\n",
      "146 2 0.3572791158046135\n",
      "Validation loss: 1.1633910572291999 ROC AUC: 0.6957831325301205\n",
      "147 14 0.25739105047347466\n",
      "Validation loss: 1.357903817631551 ROC AUC: 0.6667257264351524\n",
      "148 26 0.20774320221633003\n",
      "Validation loss: 1.4157477585685174 ROC AUC: 0.6755846917080085\n",
      "Validation loss: 1.1370790912615543 ROC AUC: 0.7028703047484054\n",
      "150 0 0.14690773781441768\n",
      "Validation loss: 1.0641768957605424 ROC AUC: 0.6941885187810064\n",
      "151 12 0.19755900680312408\n",
      "Validation loss: 1.3107725906845749 ROC AUC: 0.7074769666902906\n",
      "152 24 0.46496417849294214\n",
      "Validation loss: 1.2487674169982506 ROC AUC: 0.667611622962438\n",
      "153 36 0.2568948352975759\n",
      "Validation loss: 1.0224108111779422 ROC AUC: 0.7097802976612332\n",
      "Validation loss: 1.1686730100619083 ROC AUC: 0.6996810772501771\n",
      "155 10 0.20504816834830633\n",
      "Validation loss: 1.3253622955044373 ROC AUC: 0.7088944011339476\n",
      "156 22 0.26570480988296485\n",
      "Validation loss: 1.1927250134234397 ROC AUC: 0.7243090007087172\n",
      "157 34 0.2392706391765319\n",
      "Validation loss: 1.2329245253114511 ROC AUC: 0.721296952515946\n",
      "Validation loss: 0.971287923932865 ROC AUC: 0.703756201275691\n",
      "159 8 0.3103180447229269\n",
      "Validation loss: 1.1917629451151714 ROC AUC: 0.7264351523742028\n",
      "160 20 0.1976770944510863\n",
      "Validation loss: 1.20131159065575 ROC AUC: 0.7239546420978029\n",
      "161 32 0.3795894521966919\n",
      "Validation loss: 1.1283080258116818 ROC AUC: 0.7127923458540042\n",
      "Validation loss: 1.0740010359429366 ROC AUC: 0.72537207654146\n",
      "163 6 0.2955662207483439\n",
      "Validation loss: 1.1312260683009168 ROC AUC: 0.6980864635010631\n",
      "164 18 0.16760185387192408\n",
      "Validation loss: 1.3489767470896639 ROC AUC: 0.7234231041814316\n",
      "165 30 0.3493628097433135\n",
      "Validation loss: 0.8812758717315876 ROC AUC: 0.7397236002834869\n",
      "Validation loss: 1.2258810973325311 ROC AUC: 0.7126151665485472\n",
      "167 4 0.1878764864425976\n",
      "Validation loss: 1.4268579206719303 ROC AUC: 0.7110205527994331\n",
      "168 16 0.34400356054287\n",
      "Validation loss: 1.2121939548593483 ROC AUC: 0.7106661941885188\n",
      "169 28 0.16384710781682135\n",
      "Validation loss: 1.168955776865119 ROC AUC: 0.6924167257264351\n",
      "Validation loss: 1.2266838396621855 ROC AUC: 0.7007441530829199\n",
      "171 2 0.11650290844494822\n",
      "Validation loss: 1.212316133328621 ROC AUC: 0.7138554216867471\n",
      "172 14 0.2729088774943709\n",
      "Validation loss: 1.3238731401645585 ROC AUC: 0.7119064493267188\n",
      "173 26 0.32557081973491103\n",
      "Validation loss: 1.485341269448893 ROC AUC: 0.7003897944720057\n",
      "Validation loss: 1.3810591966111139 ROC AUC: 0.7058823529411765\n",
      "175 0 0.1711951758927298\n",
      "Validation loss: 1.1938850508620407 ROC AUC: 0.7081856839121191\n",
      "176 12 0.27743219678025716\n",
      "Validation loss: 1.529041374756011 ROC AUC: 0.7002126151665485\n",
      "177 24 0.2971757177959623\n",
      "Validation loss: 1.1238368654882671 ROC AUC: 0.7301559177888023\n",
      "178 36 0.34581477854820564\n",
      "Validation loss: 1.5102159337492178 ROC AUC: 0.7026931254429483\n",
      "Validation loss: 1.3863814650781896 ROC AUC: 0.7124379872430899\n",
      "180 10 0.2397336114051895\n",
      "Validation loss: 1.336071488083593 ROC AUC: 0.6991495393338057\n",
      "181 22 0.17543007285346301\n",
      "Validation loss: 0.9560986157284667 ROC AUC: 0.7251948972360028\n",
      "182 34 0.22699103216732064\n",
      "Validation loss: 1.093939002775988 ROC AUC: 0.7379518072289156\n",
      "Validation loss: 0.9753946638265193 ROC AUC: 0.7535435861091424\n",
      "184 8 0.13656586507422977\n",
      "Validation loss: 1.2804701229594402 ROC AUC: 0.6957831325301205\n",
      "185 20 0.29736847038662273\n",
      "Validation loss: 1.1931924239689151 ROC AUC: 0.7232459248759745\n",
      "186 32 0.34663729652153774\n",
      "Validation loss: 1.0240204981620737 ROC AUC: 0.719702338766832\n",
      "Validation loss: 1.376361869028862 ROC AUC: 0.7055279943302623\n",
      "188 6 0.27214040114087\n",
      "Validation loss: 1.346073044056924 ROC AUC: 0.7142097802976612\n",
      "189 18 0.34228933435068865\n",
      "Validation loss: 1.5061083392591665 ROC AUC: 0.6913536498936925\n",
      "190 30 0.11655866861282797\n",
      "Validation loss: 1.2647625796052793 ROC AUC: 0.7317505315379164\n",
      "Validation loss: 1.5551210661597599 ROC AUC: 0.6934798015591779\n",
      "192 4 0.09998428451953995\n",
      "Validation loss: 1.3434226702380654 ROC AUC: 0.7057051736357193\n",
      "193 16 0.12826590083451114\n",
      "Validation loss: 1.3014684102393144 ROC AUC: 0.7170446491849752\n",
      "194 28 0.22603618709254128\n",
      "Validation loss: 1.3325241788333615 ROC AUC: 0.7227143869596031\n",
      "Validation loss: 1.7191586889178547 ROC AUC: 0.6991495393338059\n",
      "196 2 0.14764148500924576\n",
      "Validation loss: 1.5877242925151294 ROC AUC: 0.7005669737774628\n",
      "197 14 0.3263369905096722\n",
      "Validation loss: 1.1469475425631794 ROC AUC: 0.7110205527994331\n",
      "198 26 0.222168572005441\n",
      "Validation loss: 1.7470927720038307 ROC AUC: 0.6977321048901488\n",
      "Validation loss: 1.4525272877800544 ROC AUC: 0.6915308291991495\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.0157925706160695 Test ROC AUC: 0.8128623188405798\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bace', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 778, 'task': 'classification', 'data_path': 'data/bace/bace.csv', 'target': ['Class']}}\n",
      "Running on: cuda:1\n",
      "1512\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1512\n",
      "Generating scaffold 1000/1512\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.3974952728363232\n",
      "Validation loss: 0.7386035567877308 ROC AUC: 0.5953224663359319\n",
      "1 12 0.8616197577638911\n",
      "Validation loss: 0.6948257384710754 ROC AUC: 0.5742381289865344\n",
      "2 24 0.6806874810294533\n",
      "Validation loss: 0.850688458673212 ROC AUC: 0.49681077250177175\n",
      "3 36 0.6911769796996243\n",
      "Validation loss: 1.0118286641228278 ROC AUC: 0.5864635010630758\n",
      "Validation loss: 0.7181114672825036 ROC AUC: 0.6149893692416725\n",
      "5 10 0.5941681175376214\n",
      "Validation loss: 0.6851438497075971 ROC AUC: 0.5949681077250177\n",
      "6 22 0.5650859124528439\n",
      "Validation loss: 0.8238588883387332 ROC AUC: 0.5400425230333097\n",
      "7 34 0.6131764083916327\n",
      "Validation loss: 0.7056000599797988 ROC AUC: 0.5892983699503899\n",
      "Validation loss: 0.9612355401973851 ROC AUC: 0.640326009922041\n",
      "9 8 0.594046112960368\n",
      "Validation loss: 0.8322954596273157 ROC AUC: 0.630049610205528\n",
      "10 20 0.6713298952793773\n",
      "Validation loss: 0.7206907434179294 ROC AUC: 0.6521970233876684\n",
      "11 32 0.5901602006805234\n",
      "Validation loss: 0.680016784478497 ROC AUC: 0.6688518781006377\n",
      "Validation loss: 0.691399125468652 ROC AUC: 0.6513111268603827\n",
      "13 6 0.8146231856682706\n",
      "Validation loss: 0.6980018209147927 ROC AUC: 0.6692062367115521\n",
      "14 18 0.8083566338922843\n",
      "Validation loss: 0.8187082058546559 ROC AUC: 0.6692062367115521\n",
      "15 30 0.5071963993554048\n",
      "Validation loss: 0.9403831062727417 ROC AUC: 0.6479447200566973\n",
      "Validation loss: 1.0231158753104557 ROC AUC: 0.5916017009213324\n",
      "17 4 0.4494933161613746\n",
      "Validation loss: 0.6302445647337579 ROC AUC: 0.6904677533664068\n",
      "18 16 0.4817553870567528\n",
      "Validation loss: 0.6677372629279332 ROC AUC: 0.6493621545003543\n",
      "19 28 0.568617986351095\n",
      "Validation loss: 0.7841963475903139 ROC AUC: 0.7014528703047485\n",
      "Validation loss: 0.7897550100522326 ROC AUC: 0.6814316087880935\n",
      "21 2 0.3097498915892697\n",
      "Validation loss: 1.064144177152621 ROC AUC: 0.6644223954642097\n",
      "22 14 0.5893790446319173\n",
      "Validation loss: 0.7356076962900477 ROC AUC: 0.6782423812898654\n",
      "23 26 0.4065650189973596\n",
      "Validation loss: 0.8819688230950311 ROC AUC: 0.6587526576895819\n",
      "Validation loss: 0.8725318679746413 ROC AUC: 0.6709780297661233\n",
      "25 0 0.5534547822662791\n",
      "Validation loss: 0.677177740643356 ROC AUC: 0.679128277817151\n",
      "26 12 0.4298814540444127\n",
      "Validation loss: 1.2945368416261989 ROC AUC: 0.6594613749114103\n",
      "27 24 0.501964500033171\n",
      "Validation loss: 0.8620618842295463 ROC AUC: 0.617115520907158\n",
      "28 36 0.4253090370332722\n",
      "Validation loss: 0.9858857298528911 ROC AUC: 0.6488306165839829\n",
      "Validation loss: 0.7964626645410298 ROC AUC: 0.6557406094968108\n",
      "30 10 0.4168429327987364\n",
      "Validation loss: 0.6611883103452771 ROC AUC: 0.7092487597448618\n",
      "31 22 0.36877428057328243\n",
      "Validation loss: 0.7780647147570224 ROC AUC: 0.6800141743444366\n",
      "32 34 0.4045706848059072\n",
      "Validation loss: 0.7426846477369599 ROC AUC: 0.6973777462792345\n",
      "Validation loss: 0.8174270087520018 ROC AUC: 0.661764705882353\n",
      "34 8 0.46475932411004633\n",
      "Validation loss: 0.8017179168612751 ROC AUC: 0.6807228915662651\n",
      "35 20 0.3786871472927204\n",
      "Validation loss: 0.8062180505683091 ROC AUC: 0.6826718639262933\n",
      "36 32 0.3021230798855778\n",
      "Validation loss: 0.7299504686665061 ROC AUC: 0.6890503189227497\n",
      "Validation loss: 0.7249064950753521 ROC AUC: 0.6941885187810063\n",
      "38 6 0.31973200821828296\n",
      "Validation loss: 0.7760618826411417 ROC AUC: 0.6954287739192062\n",
      "39 18 0.3044548268066726\n",
      "Validation loss: 0.7442898233205277 ROC AUC: 0.6523742026931254\n",
      "40 30 0.20097792973029072\n",
      "Validation loss: 0.7320330679811389 ROC AUC: 0.6922395464209781\n",
      "Validation loss: 0.7028680925337684 ROC AUC: 0.706591070163005\n",
      "42 4 0.37524562794583494\n",
      "Validation loss: 0.8346857700916316 ROC AUC: 0.6878100637845499\n",
      "43 16 0.26004789545100315\n",
      "Validation loss: 0.8500900505394335 ROC AUC: 0.6295180722891566\n",
      "44 28 0.3361701137715605\n",
      "Validation loss: 0.7274744108023233 ROC AUC: 0.7150956768249469\n",
      "Validation loss: 1.0647819085626413 ROC AUC: 0.6420978029766123\n",
      "46 2 0.30434240315213823\n",
      "Validation loss: 0.9887233269925149 ROC AUC: 0.6871013465627215\n",
      "47 14 0.2878740565887329\n",
      "Validation loss: 0.8716161199752858 ROC AUC: 0.6846208362863218\n",
      "48 26 0.2714605561562676\n",
      "Validation loss: 0.955375020867152 ROC AUC: 0.7034018426647768\n",
      "Validation loss: 0.6868564754921869 ROC AUC: 0.7446846208362863\n",
      "50 0 0.33710163803447557\n",
      "Validation loss: 0.7918490459587401 ROC AUC: 0.6918851878100638\n",
      "51 12 0.5452019310915287\n",
      "Validation loss: 0.7889959081908725 ROC AUC: 0.7172218284904324\n",
      "52 24 0.37785313880290194\n",
      "Validation loss: 1.0315329949587386 ROC AUC: 0.6642452161587526\n",
      "53 36 0.43206428970158783\n",
      "Validation loss: 0.8872356924000165 ROC AUC: 0.6653082919914954\n",
      "Validation loss: 0.7652413217437188 ROC AUC: 0.689227498228207\n",
      "55 10 0.35778040872712047\n",
      "Validation loss: 0.9669665524501674 ROC AUC: 0.6828490432317504\n",
      "56 22 0.3563693823867654\n",
      "Validation loss: 0.7922830021144539 ROC AUC: 0.68781006378455\n",
      "57 34 0.3155190871304735\n",
      "Validation loss: 0.9500677569812497 ROC AUC: 0.6718639262934089\n",
      "Validation loss: 0.7227272746578747 ROC AUC: 0.719702338766832\n",
      "59 8 0.21964817514446783\n",
      "Validation loss: 0.8803312912682034 ROC AUC: 0.6972005669737775\n",
      "60 20 0.37020692870225735\n",
      "Validation loss: 0.7427162433302166 ROC AUC: 0.690822111977321\n",
      "61 32 0.37880483566302847\n",
      "Validation loss: 1.0290631026226953 ROC AUC: 0.706591070163005\n",
      "Validation loss: 0.8116781308950968 ROC AUC: 0.7002126151665485\n",
      "63 6 0.2781409346453221\n",
      "Validation loss: 0.7192642487437519 ROC AUC: 0.7383061658398299\n",
      "64 18 0.29364337578121263\n",
      "Validation loss: 0.8399277589968498 ROC AUC: 0.7271438695960312\n",
      "65 30 0.28305054403564656\n",
      "Validation loss: 0.8601500285382302 ROC AUC: 0.716690290574061\n",
      "Validation loss: 0.8524714455699289 ROC AUC: 0.6989723600283486\n",
      "67 4 0.3285061915837399\n",
      "Validation loss: 0.8448736225532381 ROC AUC: 0.6909992912827781\n",
      "68 16 0.23093896090812108\n",
      "Validation loss: 0.7805125737032353 ROC AUC: 0.7250177179305458\n",
      "69 28 0.2548775056942691\n",
      "Validation loss: 0.866679031722593 ROC AUC: 0.734053862508859\n",
      "Validation loss: 0.8959005336887789 ROC AUC: 0.7156272147413182\n",
      "71 2 0.26926248597797736\n",
      "Validation loss: 0.8228997228950854 ROC AUC: 0.7058823529411765\n",
      "72 14 0.1952244325632583\n",
      "Validation loss: 0.8741457825464918 ROC AUC: 0.6794826364280652\n",
      "73 26 0.2263914688706652\n",
      "Validation loss: 0.9379078789262583 ROC AUC: 0.6746987951807228\n",
      "Validation loss: 0.9706829186306883 ROC AUC: 0.7168674698795181\n",
      "75 0 0.29208433229979053\n",
      "Validation loss: 0.8782137221847939 ROC AUC: 0.6869241672572644\n",
      "76 12 0.2848517514909113\n",
      "Validation loss: 0.9909971087973639 ROC AUC: 0.72413182140326\n",
      "77 24 0.24136715488541394\n",
      "Validation loss: 0.9086471803930422 ROC AUC: 0.7106661941885188\n",
      "78 36 0.521324602898762\n",
      "Validation loss: 0.8176650744400277 ROC AUC: 0.6989723600283487\n",
      "Validation loss: 0.8694066586873389 ROC AUC: 0.6931254429482636\n",
      "80 10 0.2583244756527648\n",
      "Validation loss: 0.8076827076097198 ROC AUC: 0.7397236002834868\n",
      "81 22 0.20703177154323227\n",
      "Validation loss: 0.9448212894382856 ROC AUC: 0.6727498228206945\n",
      "82 34 0.3019552713042996\n",
      "Validation loss: 0.8644412838860064 ROC AUC: 0.68781006378455\n",
      "Validation loss: 0.9426194532028097 ROC AUC: 0.6725726435152375\n",
      "84 8 0.5357858374901916\n",
      "Validation loss: 0.9486023365267066 ROC AUC: 0.7042877391920623\n",
      "85 20 0.3134566823648421\n",
      "Validation loss: 0.8257181632597714 ROC AUC: 0.6894046775336641\n",
      "86 32 0.22771607368261618\n",
      "Validation loss: 0.8979484442843507 ROC AUC: 0.7538979447200567\n",
      "Validation loss: 0.9654276939417352 ROC AUC: 0.7085400425230333\n",
      "88 6 0.19990029341523452\n",
      "Validation loss: 0.8985876587053009 ROC AUC: 0.7170446491849751\n",
      "89 18 0.36773877811839817\n",
      "Validation loss: 0.9612159160588751 ROC AUC: 0.7074769666902906\n",
      "90 30 0.3913483505175268\n",
      "Validation loss: 1.0675107019626542 ROC AUC: 0.6488306165839829\n",
      "Validation loss: 0.9259465632849182 ROC AUC: 0.7342310418143161\n",
      "92 4 0.6532941058692876\n",
      "Validation loss: 1.035401753637175 ROC AUC: 0.71243798724309\n",
      "93 16 0.44800917886491726\n",
      "Validation loss: 0.9932276531560531 ROC AUC: 0.6918851878100638\n",
      "94 28 0.43206190355990887\n",
      "Validation loss: 0.9468642031120149 ROC AUC: 0.7234231041814316\n",
      "Validation loss: 1.0644680443189003 ROC AUC: 0.6757618710134656\n",
      "96 2 0.22987074159597135\n",
      "Validation loss: 0.8974340009373545 ROC AUC: 0.6945428773919207\n",
      "97 14 0.20048613659754727\n",
      "Validation loss: 1.0635868776712987 ROC AUC: 0.7292700212615166\n",
      "98 26 0.3027757461101405\n",
      "Validation loss: 0.9143589973844439 ROC AUC: 0.7289156626506024\n",
      "Validation loss: 0.9797943672597014 ROC AUC: 0.7189936215450035\n",
      "100 0 0.2937496471385426\n",
      "Validation loss: 0.9011625071235051 ROC AUC: 0.7069454287739192\n",
      "101 12 0.29137202479081836\n",
      "Validation loss: 0.9161404339682977 ROC AUC: 0.7292700212615166\n",
      "102 24 0.29748101962476226\n",
      "Validation loss: 0.9573319649064778 ROC AUC: 0.7216513111268603\n",
      "103 36 0.2001780628750562\n",
      "Validation loss: 0.9109371442668486 ROC AUC: 0.7014528703047485\n",
      "Validation loss: 1.0959543147623934 ROC AUC: 0.6940113394755493\n",
      "105 10 0.4614625116014288\n",
      "Validation loss: 0.9963695884540381 ROC AUC: 0.6840892983699504\n",
      "106 22 0.25327050480944496\n",
      "Validation loss: 0.9850855963119608 ROC AUC: 0.7087172218284904\n",
      "107 34 0.19741208720726658\n",
      "Validation loss: 1.1625151018433224 ROC AUC: 0.6940113394755493\n",
      "Validation loss: 1.071177926284588 ROC AUC: 0.7244861800141743\n",
      "109 8 0.4388740580341405\n",
      "Validation loss: 0.989568424145907 ROC AUC: 0.729624379872431\n",
      "110 20 0.19644240544069533\n",
      "Validation loss: 1.0073147546376613 ROC AUC: 0.7122608079376329\n",
      "111 32 0.2846965772608118\n",
      "Validation loss: 1.0146914136330814 ROC AUC: 0.7058823529411765\n",
      "Validation loss: 1.0304906684041812 ROC AUC: 0.7042877391920623\n",
      "113 6 0.16950523504257783\n",
      "Validation loss: 0.9340723847711323 ROC AUC: 0.7083628632175762\n",
      "114 18 0.3466710405037973\n",
      "Validation loss: 1.0506950601047238 ROC AUC: 0.69950389794472\n",
      "115 30 0.37907092281386234\n",
      "Validation loss: 0.9971020083553743 ROC AUC: 0.6550318922749824\n",
      "Validation loss: 1.0609994720149514 ROC AUC: 0.716867469879518\n",
      "117 4 0.21525443058766883\n",
      "Validation loss: 1.0659891872216534 ROC AUC: 0.6823175053153792\n",
      "118 16 0.3551138025943144\n",
      "Validation loss: 1.0161072943384284 ROC AUC: 0.718284904323175\n",
      "119 28 0.2960045703244118\n",
      "Validation loss: 1.020764560494202 ROC AUC: 0.6846208362863218\n",
      "Validation loss: 0.9233937381908593 ROC AUC: 0.7186392629340893\n",
      "121 2 0.2468245362116079\n",
      "Validation loss: 0.961487515083212 ROC AUC: 0.6987951807228916\n",
      "122 14 0.21180717158260007\n",
      "Validation loss: 1.045977094315535 ROC AUC: 0.7319277108433735\n",
      "123 26 0.2383350609514359\n",
      "Validation loss: 0.9705406956325303 ROC AUC: 0.7099574769666903\n",
      "Validation loss: 1.3408480069495194 ROC AUC: 0.6871013465627215\n",
      "125 0 0.13737736469532644\n",
      "Validation loss: 1.1156800053767022 ROC AUC: 0.7104890148830616\n",
      "126 12 0.16236277835125879\n",
      "Validation loss: 1.232527642455322 ROC AUC: 0.6991495393338059\n",
      "127 24 0.24497996305340342\n",
      "Validation loss: 1.0271085027037867 ROC AUC: 0.7104890148830617\n",
      "128 36 0.35713137544884593\n",
      "Validation loss: 1.1945523402548783 ROC AUC: 0.6917080085046066\n",
      "Validation loss: 0.9381870599771966 ROC AUC: 0.6940113394755493\n",
      "130 10 0.21856650073660644\n",
      "Validation loss: 0.9317618142690091 ROC AUC: 0.7085400425230333\n",
      "131 22 0.17311565641091578\n",
      "Validation loss: 0.984450918949203 ROC AUC: 0.6909992912827783\n",
      "132 34 0.18597223458699802\n",
      "Validation loss: 1.077666166602381 ROC AUC: 0.664776754075124\n",
      "Validation loss: 1.0623181766232117 ROC AUC: 0.7149184975194897\n",
      "134 8 0.21868843033407384\n",
      "Validation loss: 1.0755458868891987 ROC AUC: 0.7228915662650602\n",
      "135 20 0.13785925062907267\n",
      "Validation loss: 1.3189244104536952 ROC AUC: 0.6651311126860383\n",
      "136 32 0.32361325394544155\n",
      "Validation loss: 1.0412354619297761 ROC AUC: 0.6902905740609496\n",
      "Validation loss: 1.0783734230805706 ROC AUC: 0.7246633593196314\n",
      "138 6 0.16430727477056767\n",
      "Validation loss: 1.1637488007545471 ROC AUC: 0.7354712969525159\n",
      "139 18 0.22813699924142136\n",
      "Validation loss: 1.2719197131150606 ROC AUC: 0.6876328844790929\n",
      "140 30 0.25739242236160104\n",
      "Validation loss: 1.046526877295892 ROC AUC: 0.7065910701630049\n",
      "Validation loss: 1.117763811389342 ROC AUC: 0.703756201275691\n",
      "142 4 0.35335686526468374\n",
      "Validation loss: 1.2232784427554402 ROC AUC: 0.7122608079376329\n",
      "143 16 0.10756911790238793\n",
      "Validation loss: 1.3151537045737764 ROC AUC: 0.7041105598866053\n",
      "144 28 0.2722013237565318\n",
      "Validation loss: 1.2917300833771561 ROC AUC: 0.6727498228206945\n",
      "Validation loss: 1.0687150110472117 ROC AUC: 0.6986180014174344\n",
      "146 2 0.20962741883396593\n",
      "Validation loss: 1.101615311294202 ROC AUC: 0.6968462083628633\n",
      "147 14 0.12466765387011167\n",
      "Validation loss: 1.3691343345389462 ROC AUC: 0.6782423812898654\n",
      "148 26 0.16802496262633532\n",
      "Validation loss: 1.248865934397211 ROC AUC: 0.716867469879518\n",
      "Validation loss: 1.2100191811062642 ROC AUC: 0.6975549255846917\n",
      "150 0 0.24359998319880893\n",
      "Validation loss: 1.4302155395217289 ROC AUC: 0.7035790219702339\n",
      "151 12 0.28909703994842467\n",
      "Validation loss: 1.429660439491272 ROC AUC: 0.7113749114103473\n",
      "152 24 0.23282629574720404\n",
      "Validation loss: 1.3082168694363525 ROC AUC: 0.7090715804394047\n",
      "153 36 0.3145254816688998\n",
      "Validation loss: 1.2308059768960966 ROC AUC: 0.7025159461374911\n",
      "Validation loss: 1.5164090655497369 ROC AUC: 0.7057051736357193\n",
      "155 10 0.2225915149788463\n",
      "Validation loss: 1.4261131491882122 ROC AUC: 0.6973777462792345\n",
      "156 22 0.0771843000637074\n",
      "Validation loss: 1.35726540925487 ROC AUC: 0.6948972360028349\n",
      "157 34 0.33673590123778263\n",
      "Validation loss: 1.3785063912536923 ROC AUC: 0.71243798724309\n",
      "Validation loss: 1.3154158442225676 ROC AUC: 0.6844436569808646\n",
      "159 8 0.08174786955120908\n",
      "Validation loss: 1.1287699195722871 ROC AUC: 0.6991495393338057\n",
      "160 20 0.20861354405016108\n",
      "Validation loss: 1.4365618063124599 ROC AUC: 0.7159815733522324\n",
      "161 32 0.3085551118258429\n",
      "Validation loss: 1.281574941628816 ROC AUC: 0.6872785258681786\n",
      "Validation loss: 1.2753934126026583 ROC AUC: 0.6856839121190644\n",
      "163 6 0.23831677123376874\n",
      "Validation loss: 1.294034537100634 ROC AUC: 0.7115520907158044\n",
      "164 18 0.2134966585425559\n",
      "Validation loss: 1.2972486840178634 ROC AUC: 0.6957831325301205\n",
      "165 30 0.11947796471553128\n",
      "Validation loss: 1.431258111600055 ROC AUC: 0.6890503189227498\n",
      "Validation loss: 1.2167362874706849 ROC AUC: 0.7067682494684621\n",
      "167 4 0.26485291105895603\n",
      "Validation loss: 1.1498228043120429 ROC AUC: 0.7306874557051736\n",
      "168 16 0.1986940071543391\n",
      "Validation loss: 1.2083122035525493 ROC AUC: 0.7099574769666902\n",
      "169 28 0.1774582400669535\n",
      "Validation loss: 1.4766175439026181 ROC AUC: 0.6789510985116938\n",
      "Validation loss: 1.6841661393247693 ROC AUC: 0.6578667611622963\n",
      "171 2 0.1191951538116695\n",
      "Validation loss: 1.3228577312254748 ROC AUC: 0.7019844082211196\n",
      "172 14 0.19508725016116754\n",
      "Validation loss: 1.2340704755277823 ROC AUC: 0.7028703047484054\n",
      "173 26 0.537546269396217\n",
      "Validation loss: 1.331086079805892 ROC AUC: 0.7007441530829199\n",
      "Validation loss: 1.2840853313736569 ROC AUC: 0.7069454287739192\n",
      "175 0 0.13427065395289922\n",
      "Validation loss: 1.550091171896221 ROC AUC: 0.7078313253012049\n",
      "176 12 0.3028828544125904\n",
      "Validation loss: 1.3653648262781812 ROC AUC: 0.7172218284904324\n",
      "177 24 0.16887687549857874\n",
      "Validation loss: 1.5225407508824835 ROC AUC: 0.7104890148830616\n",
      "178 36 0.13059226455117143\n",
      "Validation loss: 1.101794133123183 ROC AUC: 0.6672572643515238\n",
      "Validation loss: 1.3972207363078137 ROC AUC: 0.7152728561304039\n",
      "180 10 0.22205743665586894\n",
      "Validation loss: 1.4450682974019586 ROC AUC: 0.7237774627923458\n",
      "181 22 0.2425958655773052\n",
      "Validation loss: 1.325027018982843 ROC AUC: 0.7094259390503188\n",
      "182 34 0.1765482842915722\n",
      "Validation loss: 1.344303961621215 ROC AUC: 0.7260807937632885\n",
      "Validation loss: 1.3785748533065745 ROC AUC: 0.7298015591778879\n",
      "184 8 0.2464158277342639\n",
      "Validation loss: 1.3867430900106368 ROC AUC: 0.7019844082211197\n",
      "185 20 0.29598787251137304\n",
      "Validation loss: 1.2420481056567059 ROC AUC: 0.7423812898653437\n",
      "186 32 0.14477707849800187\n",
      "Validation loss: 1.548501336811394 ROC AUC: 0.7188164422395464\n",
      "Validation loss: 1.4207181409494767 ROC AUC: 0.7009213323883771\n",
      "188 6 0.19839663935967455\n",
      "Validation loss: 1.5910988154000794 ROC AUC: 0.7048192771084337\n",
      "189 18 0.256526944998028\n",
      "Validation loss: 1.25868394201165 ROC AUC: 0.7108433734939759\n",
      "190 30 0.1961251814502635\n",
      "Validation loss: 1.4463589459855035 ROC AUC: 0.7377746279234586\n",
      "Validation loss: 1.240398503297212 ROC AUC: 0.703756201275691\n",
      "192 4 0.19361483868298113\n",
      "Validation loss: 1.4075214097041957 ROC AUC: 0.7021615875265769\n",
      "193 16 0.19360758611950912\n",
      "Validation loss: 1.7103752418859115 ROC AUC: 0.6812544294826365\n",
      "194 28 0.2491824766652483\n",
      "Validation loss: 1.2042769817327033 ROC AUC: 0.703756201275691\n",
      "Validation loss: 1.44618682040284 ROC AUC: 0.7067682494684621\n",
      "196 2 0.3414927570592077\n",
      "Validation loss: 1.3094706456392806 ROC AUC: 0.7230687455705174\n",
      "197 14 0.25110644061904913\n",
      "Validation loss: 1.6252900969903201 ROC AUC: 0.6948972360028348\n",
      "198 26 0.2773531120166986\n",
      "Validation loss: 1.402074194112361 ROC AUC: 0.7060595322466336\n",
      "Validation loss: 1.4987325589388412 ROC AUC: 0.6759390503189228\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.1278109330880015 Test ROC AUC: 0.7998188405797102\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bace', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 779, 'task': 'classification', 'data_path': 'data/bace/bace.csv', 'target': ['Class']}}\n",
      "Running on: cuda:1\n",
      "1512\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1512\n",
      "Generating scaffold 1000/1512\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.3823324461191109\n",
      "Validation loss: 0.6857899680042898 ROC AUC: 0.5993975903614458\n",
      "1 12 0.8530136474270816\n",
      "Validation loss: 0.8144890642324031 ROC AUC: 0.5850460666194188\n",
      "2 24 0.8503199132863075\n",
      "Validation loss: 1.0692686497770398 ROC AUC: 0.5196669029057406\n",
      "3 36 0.7816880301243437\n",
      "Validation loss: 0.808626065585787 ROC AUC: 0.641566265060241\n",
      "Validation loss: 0.7567927493954336 ROC AUC: 0.6227852586817859\n",
      "5 10 0.4325357634294217\n",
      "Validation loss: 0.6774662563342921 ROC AUC: 0.6532600992204111\n",
      "6 22 0.47277017413563066\n",
      "Validation loss: 1.1940054909282962 ROC AUC: 0.677710843373494\n",
      "7 34 0.49962387164700217\n",
      "Validation loss: 0.7569600323967586 ROC AUC: 0.6863926293408928\n",
      "Validation loss: 1.5408694602006319 ROC AUC: 0.6031183557760454\n",
      "9 8 0.5059511422197743\n",
      "Validation loss: 0.9869624478927511 ROC AUC: 0.5921332388377037\n",
      "10 20 0.6258604431446516\n",
      "Validation loss: 1.40376864995388 ROC AUC: 0.6332388377037562\n",
      "11 32 0.6858263366839181\n",
      "Validation loss: 0.7288119682413063 ROC AUC: 0.6605244507441531\n",
      "Validation loss: 1.2976351013246752 ROC AUC: 0.6840892983699502\n",
      "13 6 0.3054966848065223\n",
      "Validation loss: 1.1077235471333888 ROC AUC: 0.6351878100637846\n",
      "14 18 0.3942520782669368\n",
      "Validation loss: 1.2055420307134161 ROC AUC: 0.6605244507441531\n",
      "15 30 0.3846259577371736\n",
      "Validation loss: 1.194364206680399 ROC AUC: 0.6580439404677534\n",
      "Validation loss: 0.9463086072972279 ROC AUC: 0.6970233876683202\n",
      "17 4 0.3920190388239663\n",
      "Validation loss: 0.8903341865697444 ROC AUC: 0.6548547129695252\n",
      "18 16 0.38201068913612357\n",
      "Validation loss: 0.811781451402121 ROC AUC: 0.6929482636428065\n",
      "19 28 0.5239281621371834\n",
      "Validation loss: 0.9098571969183865 ROC AUC: 0.6711552090715803\n",
      "Validation loss: 0.8564604552376349 ROC AUC: 0.6688518781006378\n",
      "21 2 0.41875382416480267\n",
      "Validation loss: 0.7387476073985069 ROC AUC: 0.7035790219702337\n",
      "22 14 0.414444818603539\n",
      "Validation loss: 0.9485294510986632 ROC AUC: 0.6226080793763288\n",
      "23 26 0.2803645497245215\n",
      "Validation loss: 0.6868209191505482 ROC AUC: 0.6996810772501773\n",
      "Validation loss: 0.9652989021200218 ROC AUC: 0.6727498228206945\n",
      "25 0 0.2872576229257519\n",
      "Validation loss: 0.8738204777635485 ROC AUC: 0.6832034018426647\n",
      "26 12 0.37493379600297916\n",
      "Validation loss: 0.7993633723416865 ROC AUC: 0.6653082919914954\n",
      "27 24 0.3069517040941434\n",
      "Validation loss: 1.0763323828084579 ROC AUC: 0.669029057406095\n",
      "28 36 0.37371352912863864\n",
      "Validation loss: 0.819950023629018 ROC AUC: 0.6571580439404678\n",
      "Validation loss: 0.8124614227686496 ROC AUC: 0.6506024096385543\n",
      "30 10 0.5072882252776585\n",
      "Validation loss: 0.8915497621163627 ROC AUC: 0.6761162296243799\n",
      "31 22 0.30188515688906586\n",
      "Validation loss: 0.8729216570885766 ROC AUC: 0.699326718639263\n",
      "32 34 0.40755739503145405\n",
      "Validation loss: 0.9526620945393645 ROC AUC: 0.6546775336640681\n",
      "Validation loss: 0.7009028954221713 ROC AUC: 0.6598157335223245\n",
      "34 8 0.27165512882124765\n",
      "Validation loss: 0.9308783684345271 ROC AUC: 0.6809000708717221\n",
      "35 20 0.48789892758712755\n",
      "Validation loss: 0.917757512717847 ROC AUC: 0.7071226080793762\n",
      "36 32 0.5357476402758794\n",
      "Validation loss: 1.317658399904011 ROC AUC: 0.6670800850460665\n",
      "Validation loss: 0.7162330663756818 ROC AUC: 0.6773564847625797\n",
      "38 6 0.43380559303028265\n",
      "Validation loss: 0.8119454948317926 ROC AUC: 0.6931254429482636\n",
      "39 18 0.43423122891419075\n",
      "Validation loss: 0.8535970488920906 ROC AUC: 0.7064138908575479\n",
      "40 30 0.2915570417509828\n",
      "Validation loss: 0.7998674125071393 ROC AUC: 0.6890503189227498\n",
      "Validation loss: 0.7387422370594858 ROC AUC: 0.7046420978029766\n",
      "42 4 0.5063477181079739\n",
      "Validation loss: 0.9108376297729694 ROC AUC: 0.6840892983699504\n",
      "43 16 0.3191624653790606\n",
      "Validation loss: 0.7805626451574414 ROC AUC: 0.7094259390503189\n",
      "44 28 0.24762602376187862\n",
      "Validation loss: 0.874022498825528 ROC AUC: 0.6642452161587525\n",
      "Validation loss: 0.7224815448388359 ROC AUC: 0.7090715804394048\n",
      "46 2 0.5532687786405255\n",
      "Validation loss: 0.7095684298616372 ROC AUC: 0.7030474840538625\n",
      "47 14 0.3966911785987299\n",
      "Validation loss: 0.8716520406552498 ROC AUC: 0.6798369950389794\n",
      "48 26 0.3300250959836701\n",
      "Validation loss: 0.8954839769578138 ROC AUC: 0.6867469879518071\n",
      "Validation loss: 0.9043756462880318 ROC AUC: 0.692239546420978\n",
      "50 0 0.27177600691507303\n",
      "Validation loss: 0.9009121364315614 ROC AUC: 0.6548547129695251\n",
      "51 12 0.43502378366104233\n",
      "Validation loss: 0.9185510376431295 ROC AUC: 0.682140326009922\n",
      "52 24 0.2923177945346538\n",
      "Validation loss: 0.8964573851484336 ROC AUC: 0.7143869596031184\n",
      "53 36 0.2732952530254001\n",
      "Validation loss: 0.6963808583897471 ROC AUC: 0.6998582565556343\n",
      "Validation loss: 0.8919097698287458 ROC AUC: 0.7048192771084337\n",
      "55 10 0.5147488723649232\n",
      "Validation loss: 0.7794201520105072 ROC AUC: 0.708008504606662\n",
      "56 22 0.2664365215687484\n",
      "Validation loss: 0.8006323615446785 ROC AUC: 0.6911764705882353\n",
      "57 34 0.3597452367227543\n",
      "Validation loss: 0.9266551275126982 ROC AUC: 0.683380581148122\n",
      "Validation loss: 0.7224872653058033 ROC AUC: 0.7149184975194898\n",
      "59 8 0.2856940828499021\n",
      "Validation loss: 1.0931990217688858 ROC AUC: 0.7221828490432318\n",
      "60 20 0.22996592726099668\n",
      "Validation loss: 0.9938217385715207 ROC AUC: 0.7094259390503189\n",
      "61 32 0.4642623366961026\n",
      "Validation loss: 0.906945780807773 ROC AUC: 0.6481218993621545\n",
      "Validation loss: 0.9016611177400248 ROC AUC: 0.667611622962438\n",
      "63 6 0.2195977017537287\n",
      "Validation loss: 0.8345122033397093 ROC AUC: 0.7067682494684621\n",
      "64 18 0.43326620208023137\n",
      "Validation loss: 0.8108179687664209 ROC AUC: 0.7260807937632885\n",
      "65 30 0.3249867065813418\n",
      "Validation loss: 0.8606858435056067 ROC AUC: 0.7094259390503189\n",
      "Validation loss: 0.8072916202197801 ROC AUC: 0.7021615875265769\n",
      "67 4 0.3610399171776937\n",
      "Validation loss: 0.9805512680912649 ROC AUC: 0.6929482636428065\n",
      "68 16 0.4675918405979492\n",
      "Validation loss: 0.8462955995111276 ROC AUC: 0.7076541459957477\n",
      "69 28 0.31424560640444216\n",
      "Validation loss: 0.8708341780877271 ROC AUC: 0.722537207654146\n",
      "Validation loss: 0.861649973108279 ROC AUC: 0.705173635719348\n",
      "71 2 0.30350545914328253\n",
      "Validation loss: 0.8340018040297047 ROC AUC: 0.718284904323175\n",
      "72 14 0.19719431447984812\n",
      "Validation loss: 0.8974777617991365 ROC AUC: 0.6782423812898654\n",
      "73 26 0.4116063499410379\n",
      "Validation loss: 0.8356837693429151 ROC AUC: 0.7276754075124026\n",
      "Validation loss: 0.8159105406691697 ROC AUC: 0.72537207654146\n",
      "75 0 0.3496269913914073\n",
      "Validation loss: 1.0379314154189154 ROC AUC: 0.6867469879518072\n",
      "76 12 0.31570433566534145\n",
      "Validation loss: 0.7779634350182995 ROC AUC: 0.6785967399007796\n",
      "77 24 0.32154641368765957\n",
      "Validation loss: 0.7420985075022211 ROC AUC: 0.7329907866761163\n",
      "78 36 0.42864768527997293\n",
      "Validation loss: 1.0356816621805658 ROC AUC: 0.7088944011339476\n",
      "Validation loss: 0.967022121347339 ROC AUC: 0.682140326009922\n",
      "80 10 0.3674407150018737\n",
      "Validation loss: 0.8249185416872138 ROC AUC: 0.7457476966690291\n",
      "81 22 0.31832950658070863\n",
      "Validation loss: 0.8363694057164602 ROC AUC: 0.7416725726435152\n",
      "82 34 0.4768993999976808\n",
      "Validation loss: 0.8646402449797321 ROC AUC: 0.6711552090715804\n",
      "Validation loss: 1.0316055334166976 ROC AUC: 0.654677533664068\n",
      "84 8 0.46054547254168\n",
      "Validation loss: 0.8570868499231654 ROC AUC: 0.7161587526576896\n",
      "85 20 0.34997990334808954\n",
      "Validation loss: 0.9086473359177444 ROC AUC: 0.687987243090007\n",
      "86 32 0.24695027090604232\n",
      "Validation loss: 0.8663860906828318 ROC AUC: 0.708008504606662\n",
      "Validation loss: 0.9922346089849409 ROC AUC: 0.7010985116938342\n",
      "88 6 0.3742747662731916\n",
      "Validation loss: 1.0005637857298189 ROC AUC: 0.6791282778171509\n",
      "89 18 0.23043908596088514\n",
      "Validation loss: 0.963052954105352 ROC AUC: 0.7126151665485471\n",
      "90 30 0.4307207275274792\n",
      "Validation loss: 0.997232317135034 ROC AUC: 0.6468816442239547\n",
      "Validation loss: 0.8619089813421894 ROC AUC: 0.683380581148122\n",
      "92 4 0.3046736541215944\n",
      "Validation loss: 0.8539769171878991 ROC AUC: 0.7069454287739192\n",
      "93 16 0.3827739659245249\n",
      "Validation loss: 0.9144090445625861 ROC AUC: 0.6715095676824947\n",
      "94 28 0.3172744335737996\n",
      "Validation loss: 0.8872366385744107 ROC AUC: 0.7122608079376329\n",
      "Validation loss: 1.124783417246989 ROC AUC: 0.6798369950389794\n",
      "96 2 0.4231720646620308\n",
      "Validation loss: 0.964072426028599 ROC AUC: 0.6679659815733522\n",
      "97 14 0.2702657574737848\n",
      "Validation loss: 0.8825525787492462 ROC AUC: 0.6704464918497519\n",
      "98 26 0.42146889254466113\n",
      "Validation loss: 0.8946413796469076 ROC AUC: 0.7149184975194898\n",
      "Validation loss: 0.9124847686053902 ROC AUC: 0.7035790219702339\n",
      "100 0 0.39649278878228195\n",
      "Validation loss: 0.8458633525482077 ROC AUC: 0.7188164422395464\n",
      "101 12 0.3066250242632114\n",
      "Validation loss: 1.0611195682689845 ROC AUC: 0.7065910701630049\n",
      "102 24 0.26791973285290527\n",
      "Validation loss: 0.8718397017346312 ROC AUC: 0.7446846208362863\n",
      "103 36 0.36633021429358514\n",
      "Validation loss: 0.9959478299349349 ROC AUC: 0.7030474840538625\n",
      "Validation loss: 0.8682496137176918 ROC AUC: 0.7090715804394048\n",
      "105 10 0.2718473107208746\n",
      "Validation loss: 0.9961530341217849 ROC AUC: 0.6770021261516654\n",
      "106 22 0.2135401307589157\n",
      "Validation loss: 0.9854117987171703 ROC AUC: 0.684975194897236\n",
      "107 34 0.3718358789741383\n",
      "Validation loss: 0.9079939186178296 ROC AUC: 0.6862154500354358\n",
      "Validation loss: 0.8147651592627266 ROC AUC: 0.6862154500354359\n",
      "109 8 0.2862881398924617\n",
      "Validation loss: 1.0025551895432125 ROC AUC: 0.7014528703047483\n",
      "110 20 0.23126909486354114\n",
      "Validation loss: 1.1583261481973508 ROC AUC: 0.6750531537916372\n",
      "111 32 0.31677332852203727\n",
      "Validation loss: 1.0257111712796798 ROC AUC: 0.6902905740609497\n",
      "Validation loss: 0.9922060279656719 ROC AUC: 0.7172218284904324\n",
      "113 6 0.4363970634918859\n",
      "Validation loss: 0.8931616955245567 ROC AUC: 0.7120836286321758\n",
      "114 18 0.3507651039977808\n",
      "Validation loss: 1.0939486389918043 ROC AUC: 0.680722891566265\n",
      "115 30 0.15848112134373415\n",
      "Validation loss: 0.9590721489577894 ROC AUC: 0.709603118355776\n",
      "Validation loss: 0.8823227377127338 ROC AUC: 0.7108433734939759\n",
      "117 4 0.20732306502158696\n",
      "Validation loss: 0.8971988981133265 ROC AUC: 0.7462792345854005\n",
      "118 16 0.28775636748970745\n",
      "Validation loss: 1.2364285221163012 ROC AUC: 0.6708008504606662\n",
      "119 28 0.390056022931528\n",
      "Validation loss: 0.845151104674434 ROC AUC: 0.6890503189227498\n",
      "Validation loss: 0.8605622262354718 ROC AUC: 0.7267895109851169\n",
      "121 2 0.2812346948662325\n",
      "Validation loss: 0.9270432283546751 ROC AUC: 0.7150956768249469\n",
      "122 14 0.1616315847438681\n",
      "Validation loss: 0.844534292915799 ROC AUC: 0.7386605244507441\n",
      "123 26 0.4186738237409927\n",
      "Validation loss: 1.0857827923945245 ROC AUC: 0.6863926293408928\n",
      "Validation loss: 0.8820788986635524 ROC AUC: 0.7049964564138909\n",
      "125 0 0.30841419971837886\n",
      "Validation loss: 1.0292335026311559 ROC AUC: 0.6849751948972359\n",
      "126 12 0.23514834686848773\n",
      "Validation loss: 0.9842066816146801 ROC AUC: 0.6856839121190645\n",
      "127 24 0.2734279812423429\n",
      "Validation loss: 1.0150412167144927 ROC AUC: 0.7071226080793763\n",
      "128 36 0.16644097610718944\n",
      "Validation loss: 1.025437945561693 ROC AUC: 0.6989723600283487\n",
      "Validation loss: 0.9451705304202654 ROC AUC: 0.7181077250177179\n",
      "130 10 0.2555707233232271\n",
      "Validation loss: 1.1248890323354708 ROC AUC: 0.6947200566973778\n",
      "131 22 0.24470035641254073\n",
      "Validation loss: 0.9235594580505068 ROC AUC: 0.6855067328136074\n",
      "132 34 0.46046336095273754\n",
      "Validation loss: 0.9851963247684453 ROC AUC: 0.7133238837703756\n",
      "Validation loss: 0.8341216322602025 ROC AUC: 0.6924167257264352\n",
      "134 8 0.2732182539594357\n",
      "Validation loss: 1.153302782418712 ROC AUC: 0.6722182849043232\n",
      "135 20 0.20748481288896298\n",
      "Validation loss: 0.9896787945797901 ROC AUC: 0.7014528703047483\n",
      "136 32 0.19536284061423106\n",
      "Validation loss: 1.1525011800772307 ROC AUC: 0.7216513111268604\n",
      "Validation loss: 1.1544211443686327 ROC AUC: 0.6615875265768958\n",
      "138 6 0.2243578009066844\n",
      "Validation loss: 1.016019413013332 ROC AUC: 0.6890503189227498\n",
      "139 18 0.14875122244380845\n",
      "Validation loss: 1.111785447360664 ROC AUC: 0.6754075124025514\n",
      "140 30 0.15122421124288662\n",
      "Validation loss: 1.089974239172525 ROC AUC: 0.7090715804394047\n",
      "Validation loss: 1.0100056896146559 ROC AUC: 0.714032600992204\n",
      "142 4 0.22127945171809793\n",
      "Validation loss: 1.112935124051492 ROC AUC: 0.7064138908575479\n",
      "143 16 0.21450630523298544\n",
      "Validation loss: 1.1073611145777418 ROC AUC: 0.6920623671155209\n",
      "144 28 0.2584751756875864\n",
      "Validation loss: 0.9038889029168136 ROC AUC: 0.7393692416725727\n",
      "Validation loss: 0.8656843091478411 ROC AUC: 0.7216513111268604\n",
      "146 2 0.30709518240148953\n",
      "Validation loss: 1.0637807703965547 ROC AUC: 0.6791282778171509\n",
      "147 14 0.18247708244025582\n",
      "Validation loss: 1.0213492098233559 ROC AUC: 0.711020552799433\n",
      "148 26 0.313321482697459\n",
      "Validation loss: 1.291491983742114 ROC AUC: 0.634479092841956\n",
      "Validation loss: 1.1457711821360304 ROC AUC: 0.695074415308292\n",
      "150 0 0.10202349962732449\n",
      "Validation loss: 1.011126726668402 ROC AUC: 0.7294472005669738\n",
      "151 12 0.3113335709109678\n",
      "Validation loss: 0.9278913748185367 ROC AUC: 0.7212969525159462\n",
      "152 24 0.2721969762343612\n",
      "Validation loss: 1.0556325691425248 ROC AUC: 0.6984408221119773\n",
      "153 36 0.10450041892251496\n",
      "Validation loss: 1.1373634638375794 ROC AUC: 0.6684975194897236\n",
      "Validation loss: 1.1836411866131207 ROC AUC: 0.7012756909992913\n",
      "155 10 0.19229141162629781\n",
      "Validation loss: 1.1347954762692483 ROC AUC: 0.6925939050318923\n",
      "156 22 0.1522643608276141\n",
      "Validation loss: 0.9483180669759284 ROC AUC: 0.7352941176470589\n",
      "157 34 0.20324914237652977\n",
      "Validation loss: 0.9840686226522686 ROC AUC: 0.7049964564138909\n",
      "Validation loss: 1.0561474474850079 ROC AUC: 0.7026931254429483\n",
      "159 8 0.1867857476466079\n",
      "Validation loss: 1.0039108036369677 ROC AUC: 0.6552090715804395\n",
      "160 20 0.20070565765785675\n",
      "Validation loss: 0.9128024807039475 ROC AUC: 0.6917080085046067\n",
      "161 32 0.2534205312651655\n",
      "Validation loss: 0.9650780258589233 ROC AUC: 0.6929482636428066\n",
      "Validation loss: 0.9794657652741237 ROC AUC: 0.710843373493976\n",
      "163 6 0.36150240523613153\n",
      "Validation loss: 1.1037711149809377 ROC AUC: 0.693656980864635\n",
      "164 18 0.2040239421112174\n",
      "Validation loss: 1.1033275869508452 ROC AUC: 0.7220056697377746\n",
      "165 30 0.24151765728458946\n",
      "Validation loss: 0.9941656992135458 ROC AUC: 0.7003897944720057\n",
      "Validation loss: 1.099054145497202 ROC AUC: 0.6869241672572644\n",
      "167 4 0.21126582894914187\n",
      "Validation loss: 1.1854128786270193 ROC AUC: 0.7025159461374911\n",
      "168 16 0.22001778761156213\n",
      "Validation loss: 1.11877818770756 ROC AUC: 0.7002126151665484\n",
      "169 28 0.1988639591310048\n",
      "Validation loss: 1.1217377051612398 ROC AUC: 0.715272856130404\n",
      "Validation loss: 1.0872464247097242 ROC AUC: 0.6984408221119773\n",
      "171 2 0.06250067655883017\n",
      "Validation loss: 1.2581040551330869 ROC AUC: 0.6667257264351524\n",
      "172 14 0.37692632074255233\n",
      "Validation loss: 1.0695126218511568 ROC AUC: 0.7228915662650602\n",
      "173 26 0.18283497288566966\n",
      "Validation loss: 1.0738068605890336 ROC AUC: 0.6871013465627216\n",
      "Validation loss: 1.1784875653437432 ROC AUC: 0.7223600283486888\n",
      "175 0 0.12614251203958385\n",
      "Validation loss: 1.293160478800338 ROC AUC: 0.7018072289156626\n",
      "176 12 0.213319085909466\n",
      "Validation loss: 1.1842659640785873 ROC AUC: 0.7030474840538625\n",
      "177 24 0.4984502508394045\n",
      "Validation loss: 1.0576168875031124 ROC AUC: 0.731041814316088\n",
      "178 36 0.202642541281943\n",
      "Validation loss: 1.2169640916862234 ROC AUC: 0.7127923458540043\n",
      "Validation loss: 1.372824469938973 ROC AUC: 0.6897590361445783\n",
      "180 10 0.1668962917811437\n",
      "Validation loss: 1.2410268641465547 ROC AUC: 0.6973777462792345\n",
      "181 22 0.30565730876801356\n",
      "Validation loss: 1.3170268938241416 ROC AUC: 0.6791282778171509\n",
      "182 34 0.2832646380236819\n",
      "Validation loss: 1.359755632893139 ROC AUC: 0.7078313253012049\n",
      "Validation loss: 1.2106200377672713 ROC AUC: 0.7039333805811481\n",
      "184 8 0.13908246115812575\n",
      "Validation loss: 1.1912579911434098 ROC AUC: 0.6771793054571226\n",
      "185 20 0.17785446556330844\n",
      "Validation loss: 1.1706493042952177 ROC AUC: 0.7078313253012049\n",
      "186 32 0.24449860323369976\n",
      "Validation loss: 1.197816506916324 ROC AUC: 0.7140326009922041\n",
      "Validation loss: 1.3458331625982625 ROC AUC: 0.7092487597448618\n",
      "188 6 0.15752187098417048\n",
      "Validation loss: 1.5292168247778684 ROC AUC: 0.683557760453579\n",
      "189 18 0.06679235585196383\n",
      "Validation loss: 1.290916249057315 ROC AUC: 0.6837349397590362\n",
      "190 30 0.11007034021973144\n",
      "Validation loss: 1.2625077639194513 ROC AUC: 0.7184620836286321\n",
      "Validation loss: 1.2982467152424995 ROC AUC: 0.7205882352941175\n",
      "192 4 0.27750466850136357\n",
      "Validation loss: 1.3172084172040421 ROC AUC: 0.6938341601700921\n",
      "193 16 0.0976334483203259\n",
      "Validation loss: 1.2474488059416513 ROC AUC: 0.6837349397590362\n",
      "194 28 0.13025254921558022\n",
      "Validation loss: 1.1211808146230433 ROC AUC: 0.716690290574061\n",
      "Validation loss: 1.2896316177797633 ROC AUC: 0.7119064493267186\n",
      "196 2 0.08971216594338606\n",
      "Validation loss: 1.1606872689645023 ROC AUC: 0.703756201275691\n",
      "197 14 0.23051037604741964\n",
      "Validation loss: 1.294357202305699 ROC AUC: 0.7046420978029766\n",
      "198 26 0.196275829292693\n",
      "Validation loss: 1.164790822180691 ROC AUC: 0.715450035435861\n",
      "Validation loss: 1.2571200140264651 ROC AUC: 0.7119064493267186\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.8701805425317664 Test ROC AUC: 0.8389492753623189\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bace', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 780, 'task': 'classification', 'data_path': 'data/bace/bace.csv', 'target': ['Class']}}\n",
      "Running on: cuda:1\n",
      "1512\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1512\n",
      "Generating scaffold 1000/1512\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.443893577766541\n",
      "Validation loss: 0.7135687565171955 ROC AUC: 0.5368532955350815\n",
      "1 12 0.8713358533812638\n",
      "Validation loss: 0.8143170843061233 ROC AUC: 0.5053153791637137\n",
      "2 24 0.6449084294058007\n",
      "Validation loss: 0.9348500899921189 ROC AUC: 0.5388022678951099\n",
      "3 36 0.6405166766153143\n",
      "Validation loss: 0.7465642591975382 ROC AUC: 0.5620127569099929\n",
      "Validation loss: 0.9596262878140077 ROC AUC: 0.5499645641389086\n",
      "5 10 0.5943155374265815\n",
      "Validation loss: 0.767338383276731 ROC AUC: 0.632884479092842\n",
      "6 22 0.44073064540433216\n",
      "Validation loss: 0.8875886351856964 ROC AUC: 0.6079021970233878\n",
      "7 34 0.5283033199974932\n",
      "Validation loss: 0.7142950912185063 ROC AUC: 0.6210134656272146\n",
      "Validation loss: 0.6770903515499949 ROC AUC: 0.6911764705882353\n",
      "9 8 0.536523799578861\n",
      "Validation loss: 0.9961128984855501 ROC AUC: 0.6240255138199858\n",
      "10 20 0.3342995178463162\n",
      "Validation loss: 0.8073003394714254 ROC AUC: 0.5800850460666194\n",
      "11 32 0.39645270165225943\n",
      "Validation loss: 0.7606367235941602 ROC AUC: 0.6534372785258682\n",
      "Validation loss: 0.82219949700185 ROC AUC: 0.6001063075832742\n",
      "13 6 0.36217037652970296\n",
      "Validation loss: 0.666769963226571 ROC AUC: 0.6991495393338059\n",
      "14 18 0.6264553206602945\n",
      "Validation loss: 0.6966851085227057 ROC AUC: 0.6511339475549256\n",
      "15 30 0.5216924194991007\n",
      "Validation loss: 1.3244915679590592 ROC AUC: 0.5914245216158753\n",
      "Validation loss: 0.948060243729724 ROC AUC: 0.6144578313253012\n",
      "17 4 0.5103453879589862\n",
      "Validation loss: 1.2670590301223148 ROC AUC: 0.6192416725726436\n",
      "18 16 0.3803460606956869\n",
      "Validation loss: 0.859592862871309 ROC AUC: 0.677710843373494\n",
      "19 28 0.45595551841464776\n",
      "Validation loss: 0.8797212448341167 ROC AUC: 0.6233167965981573\n",
      "Validation loss: 0.9679236775202467 ROC AUC: 0.648830616583983\n",
      "21 2 0.4840703960421141\n",
      "Validation loss: 0.9686647116743177 ROC AUC: 0.6895818568391212\n",
      "22 14 0.4312360725470906\n",
      "Validation loss: 0.857906661680992 ROC AUC: 0.6746987951807228\n",
      "23 26 0.43797266581735256\n",
      "Validation loss: 0.742880204260744 ROC AUC: 0.670623671155209\n",
      "Validation loss: 0.7253576134214338 ROC AUC: 0.6800141743444366\n",
      "25 0 0.5047122972363721\n",
      "Validation loss: 0.8461610899855759 ROC AUC: 0.6855067328136073\n",
      "26 12 0.4110995028334061\n",
      "Validation loss: 0.8953691539385461 ROC AUC: 0.6715095676824947\n",
      "27 24 0.2716064542041627\n",
      "Validation loss: 0.7742563067682532 ROC AUC: 0.6824946846208362\n",
      "28 36 0.42094990074574623\n",
      "Validation loss: 0.7795837963653716 ROC AUC: 0.679305457122608\n",
      "Validation loss: 0.7065546816547975 ROC AUC: 0.6580439404677533\n",
      "30 10 0.3931988673589079\n",
      "Validation loss: 0.7099145339024777 ROC AUC: 0.6934798015591779\n",
      "31 22 0.39357620481291683\n",
      "Validation loss: 0.9136141972826016 ROC AUC: 0.6814316087880935\n",
      "32 34 0.4432927054639752\n",
      "Validation loss: 0.6659028320912493 ROC AUC: 0.6964918497519489\n",
      "Validation loss: 0.9061075516094436 ROC AUC: 0.6745216158752657\n",
      "34 8 0.2827876595571467\n",
      "Validation loss: 0.9271624901436812 ROC AUC: 0.7014528703047483\n",
      "35 20 0.48225999557692945\n",
      "Validation loss: 0.8280350988274379 ROC AUC: 0.6860382707299787\n",
      "36 32 0.5933325308634212\n",
      "Validation loss: 0.7903694549933175 ROC AUC: 0.6759390503189228\n",
      "Validation loss: 0.9661441907187961 ROC AUC: 0.7014528703047485\n",
      "38 6 0.22938847514316676\n",
      "Validation loss: 0.7899438383563465 ROC AUC: 0.6757618710134657\n",
      "39 18 0.5431761787146646\n",
      "Validation loss: 0.814231932952704 ROC AUC: 0.6587526576895819\n",
      "40 30 0.5076978670691036\n",
      "Validation loss: 0.9374319421534507 ROC AUC: 0.7005669737774627\n",
      "Validation loss: 0.7557453003940203 ROC AUC: 0.6885187810063784\n",
      "42 4 0.41519514492894466\n",
      "Validation loss: 0.7563062104957783 ROC AUC: 0.6885187810063784\n",
      "43 16 0.38064673688016815\n",
      "Validation loss: 0.8982851797381773 ROC AUC: 0.6933026222537209\n",
      "44 28 0.40133888348350616\n",
      "Validation loss: 0.7149303283122991 ROC AUC: 0.7163359319631467\n",
      "Validation loss: 0.8701949297197608 ROC AUC: 0.6901133947554926\n",
      "46 2 0.49582344447785937\n",
      "Validation loss: 0.74891970804985 ROC AUC: 0.7014528703047483\n",
      "47 14 0.40969739360978685\n",
      "Validation loss: 0.9184109675173728 ROC AUC: 0.6856839121190645\n",
      "48 26 0.32433619616622433\n",
      "Validation loss: 0.820597019416607 ROC AUC: 0.6708008504606662\n",
      "Validation loss: 0.8212416700969468 ROC AUC: 0.7030474840538625\n",
      "50 0 0.3433092624043427\n",
      "Validation loss: 0.8525062720507186 ROC AUC: 0.7094259390503189\n",
      "51 12 0.34165255443499176\n",
      "Validation loss: 0.8324771744525985 ROC AUC: 0.71367824238129\n",
      "52 24 0.4387902032036933\n",
      "Validation loss: 0.7458189745612492 ROC AUC: 0.6948972360028348\n",
      "53 36 0.40167621756809224\n",
      "Validation loss: 0.861209633334583 ROC AUC: 0.7028703047484053\n",
      "Validation loss: 0.8970807092079264 ROC AUC: 0.6481218993621545\n",
      "55 10 0.2885941664295344\n",
      "Validation loss: 0.8536031625128739 ROC AUC: 0.6697377746279234\n",
      "56 22 0.4265984032508451\n",
      "Validation loss: 0.9911284198034678 ROC AUC: 0.677710843373494\n",
      "57 34 0.39376272587299094\n",
      "Validation loss: 0.9624599115738016 ROC AUC: 0.6677888022678952\n",
      "Validation loss: 0.9022338169300004 ROC AUC: 0.6729270021261516\n",
      "59 8 0.551803092819751\n",
      "Validation loss: 0.8231954791687972 ROC AUC: 0.7034018426647768\n",
      "60 20 0.3177207554853194\n",
      "Validation loss: 0.8399897557220711 ROC AUC: 0.7048192771084337\n",
      "61 32 0.436016479837489\n",
      "Validation loss: 0.7467045034004363 ROC AUC: 0.6968462083628632\n",
      "Validation loss: 0.8372158033168868 ROC AUC: 0.7335223245924876\n",
      "63 6 0.3010791694929685\n",
      "Validation loss: 0.8352796506408035 ROC AUC: 0.6989723600283487\n",
      "64 18 0.45645910420958014\n",
      "Validation loss: 0.7863816682076612 ROC AUC: 0.7241318214032602\n",
      "65 30 0.4327147378197315\n",
      "Validation loss: 0.8334752755449307 ROC AUC: 0.681963146704465\n",
      "Validation loss: 0.9475135965063083 ROC AUC: 0.7085400425230334\n",
      "67 4 0.27885861577873566\n",
      "Validation loss: 0.9222703074777363 ROC AUC: 0.6722182849043233\n",
      "68 16 0.366872399422599\n",
      "Validation loss: 1.1539865463774726 ROC AUC: 0.689227498228207\n",
      "69 28 0.3362290258954962\n",
      "Validation loss: 0.7584007781072958 ROC AUC: 0.7232459248759744\n",
      "Validation loss: 0.91045803581642 ROC AUC: 0.6775336640680368\n",
      "71 2 0.36311646708717743\n",
      "Validation loss: 1.0423763295672588 ROC AUC: 0.6895818568391211\n",
      "72 14 0.244241163832046\n",
      "Validation loss: 0.9003805601044207 ROC AUC: 0.6713323883770377\n",
      "73 26 0.2870636894712104\n",
      "Validation loss: 0.9156932357131251 ROC AUC: 0.6527285613040397\n",
      "Validation loss: 0.9434483082878669 ROC AUC: 0.6830262225372076\n",
      "75 0 0.2302890767343379\n",
      "Validation loss: 0.9572168872845883 ROC AUC: 0.6881644223954642\n",
      "76 12 0.24329134243565687\n",
      "Validation loss: 0.9393123329080493 ROC AUC: 0.6959603118355776\n",
      "77 24 0.40947703068207864\n",
      "Validation loss: 0.8542561010019669 ROC AUC: 0.725549255846917\n",
      "78 36 0.29840712028636635\n",
      "Validation loss: 0.8651416116202904 ROC AUC: 0.6925939050318923\n",
      "Validation loss: 0.8184815558376691 ROC AUC: 0.7216513111268603\n",
      "80 10 0.3100962156785904\n",
      "Validation loss: 0.8840593541694792 ROC AUC: 0.6872785258681786\n",
      "81 22 0.2641771583260962\n",
      "Validation loss: 0.997354641655423 ROC AUC: 0.7069454287739192\n",
      "82 34 0.2893446986082589\n",
      "Validation loss: 1.210690632166452 ROC AUC: 0.6436924167257265\n",
      "Validation loss: 0.9065331670622162 ROC AUC: 0.684975194897236\n",
      "84 8 0.411135697994943\n",
      "Validation loss: 1.0927642757529454 ROC AUC: 0.6810772501771792\n",
      "85 20 0.3445614461307999\n",
      "Validation loss: 0.8369579161239775 ROC AUC: 0.7108433734939757\n",
      "86 32 0.36359445162414794\n",
      "Validation loss: 1.06398010648639 ROC AUC: 0.7156272147413182\n",
      "Validation loss: 0.8304629175868256 ROC AUC: 0.6948972360028349\n",
      "88 6 0.30810506488435907\n",
      "Validation loss: 0.972488224901111 ROC AUC: 0.6839121190644932\n",
      "89 18 0.37771196168437654\n",
      "Validation loss: 1.1304310726014195 ROC AUC: 0.69950389794472\n",
      "90 30 0.34214775233479255\n",
      "Validation loss: 1.1620872458874785 ROC AUC: 0.672041105598866\n",
      "Validation loss: 1.1257462746260183 ROC AUC: 0.664776754075124\n",
      "92 4 0.27867434359412924\n",
      "Validation loss: 0.8174738947129407 ROC AUC: 0.7186392629340893\n",
      "93 16 0.150336441888477\n",
      "Validation loss: 0.9123243630327136 ROC AUC: 0.7097802976612332\n",
      "94 28 0.2459654003996214\n",
      "Validation loss: 0.9234117095833583 ROC AUC: 0.709603118355776\n",
      "Validation loss: 0.900444373389743 ROC AUC: 0.7065910701630049\n",
      "96 2 0.23209304845408352\n",
      "Validation loss: 0.913412750556769 ROC AUC: 0.6966690290574061\n",
      "97 14 0.3505119401013418\n",
      "Validation loss: 0.8753564997224619 ROC AUC: 0.6918851878100638\n",
      "98 26 0.32329950921972445\n",
      "Validation loss: 0.9562473316855779 ROC AUC: 0.7028703047484054\n",
      "Validation loss: 0.9301346090455719 ROC AUC: 0.6963146704464919\n",
      "100 0 0.20159096552055372\n",
      "Validation loss: 0.9131150506190117 ROC AUC: 0.6915308291991495\n",
      "101 12 0.2890420398940165\n",
      "Validation loss: 0.9480603207026096 ROC AUC: 0.7212969525159462\n",
      "102 24 0.36560026756597275\n",
      "Validation loss: 0.9629722699424289 ROC AUC: 0.7182849043231752\n",
      "103 36 0.19720964162584625\n",
      "Validation loss: 0.9281279109171684 ROC AUC: 0.6867469879518072\n",
      "Validation loss: 0.9005898391174165 ROC AUC: 0.7193479801559177\n",
      "105 10 0.2042246933428684\n",
      "Validation loss: 0.8922974127807365 ROC AUC: 0.6869241672572644\n",
      "106 22 0.3819341788855985\n",
      "Validation loss: 0.9446602491353522 ROC AUC: 0.7168674698795181\n",
      "107 34 0.2053797227585702\n",
      "Validation loss: 0.9538892629920253 ROC AUC: 0.689404677533664\n",
      "Validation loss: 0.9957852383323064 ROC AUC: 0.7016300496102055\n",
      "109 8 0.2551352309815652\n",
      "Validation loss: 0.9721565349212545 ROC AUC: 0.7039333805811481\n",
      "110 20 0.3229796802714074\n",
      "Validation loss: 0.8908486563638346 ROC AUC: 0.6977321048901489\n",
      "111 32 0.38690948394703406\n",
      "Validation loss: 1.0896856054564974 ROC AUC: 0.7042877391920623\n",
      "Validation loss: 0.8970002322796954 ROC AUC: 0.6973777462792345\n",
      "113 6 0.25126286567471245\n",
      "Validation loss: 1.0122816823176202 ROC AUC: 0.6835577604535791\n",
      "114 18 0.339440239142808\n",
      "Validation loss: 0.7978483754278018 ROC AUC: 0.7212969525159462\n",
      "115 30 0.28526597634374945\n",
      "Validation loss: 0.872996331050696 ROC AUC: 0.7135010630758327\n",
      "Validation loss: 1.1417396131730237 ROC AUC: 0.7119064493267186\n",
      "117 4 0.2553054119893143\n",
      "Validation loss: 0.9012134485686851 ROC AUC: 0.7028703047484054\n",
      "118 16 0.400919793535713\n",
      "Validation loss: 0.9809282599695471 ROC AUC: 0.6957831325301205\n",
      "119 28 0.1014835621744984\n",
      "Validation loss: 0.9423009694017321 ROC AUC: 0.6972005669737774\n",
      "Validation loss: 0.9954329413294003 ROC AUC: 0.6757618710134655\n",
      "121 2 0.19452055473329702\n",
      "Validation loss: 1.0701964288357868 ROC AUC: 0.7016300496102056\n",
      "122 14 0.30718578299554444\n",
      "Validation loss: 0.910801053441913 ROC AUC: 0.7032246633593197\n",
      "123 26 0.38392825979652995\n",
      "Validation loss: 1.0173045823116176 ROC AUC: 0.7197023387668321\n",
      "Validation loss: 0.8539369662865898 ROC AUC: 0.7156272147413182\n",
      "125 0 0.2813742169467131\n",
      "Validation loss: 0.9626855151542765 ROC AUC: 0.7016300496102056\n",
      "126 12 0.4462519926255498\n",
      "Validation loss: 0.9263853576799103 ROC AUC: 0.7344082211197732\n",
      "127 24 0.3450279311208199\n",
      "Validation loss: 1.0036558279927992 ROC AUC: 0.7067682494684621\n",
      "128 36 0.3181734343593985\n",
      "Validation loss: 0.9626959834667231 ROC AUC: 0.7126151665485471\n",
      "Validation loss: 1.0851093846441104 ROC AUC: 0.6801913536498937\n",
      "130 10 0.3047904420535676\n",
      "Validation loss: 1.061463846276138 ROC AUC: 0.693834160170092\n",
      "131 22 0.1712805592139663\n",
      "Validation loss: 0.9499554586726309 ROC AUC: 0.7002126151665485\n",
      "132 34 0.3445024626238304\n",
      "Validation loss: 1.016134944972613 ROC AUC: 0.6948972360028348\n",
      "Validation loss: 1.0980181240088103 ROC AUC: 0.7147413182140326\n",
      "134 8 0.21584904727742044\n",
      "Validation loss: 0.9718665543770948 ROC AUC: 0.6904677533664068\n",
      "135 20 0.3022939666434525\n",
      "Validation loss: 1.0175440370641797 ROC AUC: 0.6862154500354358\n",
      "136 32 0.3010303812662169\n",
      "Validation loss: 0.9503867436718467 ROC AUC: 0.7168674698795181\n",
      "Validation loss: 0.8373076678901319 ROC AUC: 0.6980864635010631\n",
      "138 6 0.41321248413667394\n",
      "Validation loss: 1.1174062293096882 ROC AUC: 0.6993267186392629\n",
      "139 18 0.26248306074485694\n",
      "Validation loss: 1.111781541480134 ROC AUC: 0.7057051736357193\n",
      "140 30 0.33767525589116254\n",
      "Validation loss: 1.0903410272093008 ROC AUC: 0.7067682494684621\n",
      "Validation loss: 1.148691077895512 ROC AUC: 0.7170446491849752\n",
      "142 4 0.17811454931786572\n",
      "Validation loss: 0.8771667409416856 ROC AUC: 0.719525159461375\n",
      "143 16 0.2718138427657507\n",
      "Validation loss: 0.9849388717815576 ROC AUC: 0.718107725017718\n",
      "144 28 0.20151986161001686\n",
      "Validation loss: 1.0070358641100245 ROC AUC: 0.7365343727852586\n",
      "Validation loss: 1.0637337537790765 ROC AUC: 0.6785967399007796\n",
      "146 2 0.1971419935839778\n",
      "Validation loss: 1.1862713678783139 ROC AUC: 0.7126151665485472\n",
      "147 14 0.21531844966146885\n",
      "Validation loss: 1.3112359907453424 ROC AUC: 0.7083628632175761\n",
      "148 26 0.3981850981737315\n",
      "Validation loss: 0.90436025684243 ROC AUC: 0.7136782423812899\n",
      "Validation loss: 0.9453397270859472 ROC AUC: 0.7188164422395464\n",
      "150 0 0.25729542841936887\n",
      "Validation loss: 1.1262393739839263 ROC AUC: 0.7122608079376329\n",
      "151 12 0.15824126805866126\n",
      "Validation loss: 1.2868466914094836 ROC AUC: 0.7111977321048901\n",
      "152 24 0.24426139235394667\n",
      "Validation loss: 1.0908181130491346 ROC AUC: 0.7278525868178597\n",
      "153 36 0.14998195811548765\n",
      "Validation loss: 0.9655515744986124 ROC AUC: 0.699326718639263\n",
      "Validation loss: 1.026787376166969 ROC AUC: 0.7127923458540042\n",
      "155 10 0.18513919952442218\n",
      "Validation loss: 1.1467576903223202 ROC AUC: 0.7388377037562013\n",
      "156 22 0.25831200255602627\n",
      "Validation loss: 1.1117711446143144 ROC AUC: 0.6952515946137492\n",
      "157 34 0.2690969476949244\n",
      "Validation loss: 1.1565277505394638 ROC AUC: 0.7289156626506024\n",
      "Validation loss: 1.1859218120969683 ROC AUC: 0.7161587526576897\n",
      "159 8 0.19008739054362936\n",
      "Validation loss: 1.2948188868579487 ROC AUC: 0.7193479801559178\n",
      "160 20 0.2658341930643901\n",
      "Validation loss: 1.2645674517612584 ROC AUC: 0.6885187810063784\n",
      "161 32 0.14920362264559595\n",
      "Validation loss: 1.2274641864347142 ROC AUC: 0.7237774627923459\n",
      "Validation loss: 1.1083300942616747 ROC AUC: 0.702338766832034\n",
      "163 6 0.2133292222140616\n",
      "Validation loss: 1.3388411130336737 ROC AUC: 0.6987951807228915\n",
      "164 18 0.21332914415999227\n",
      "Validation loss: 1.1627498415132231 ROC AUC: 0.721119773210489\n",
      "165 30 0.3988229673617552\n",
      "Validation loss: 1.3229423358740395 ROC AUC: 0.7133238837703756\n",
      "Validation loss: 1.2973994908743347 ROC AUC: 0.7317505315379164\n",
      "167 4 0.18085308773117414\n",
      "Validation loss: 1.2588380713336516 ROC AUC: 0.7173990077958894\n",
      "168 16 0.17156747201326422\n",
      "Validation loss: 1.3247750093605344 ROC AUC: 0.7115520907158044\n",
      "169 28 0.13927352759923392\n",
      "Validation loss: 1.4398321686991002 ROC AUC: 0.705173635719348\n",
      "Validation loss: 1.3538095295823962 ROC AUC: 0.7032246633593197\n",
      "171 2 0.3223143893725319\n",
      "Validation loss: 1.3889231950241998 ROC AUC: 0.7173990077958894\n",
      "172 14 0.16622186546005235\n",
      "Validation loss: 1.1243535753906957 ROC AUC: 0.7329907866761162\n",
      "173 26 0.1581904709907485\n",
      "Validation loss: 1.4594098874275259 ROC AUC: 0.6909992912827783\n",
      "Validation loss: 1.298111803484279 ROC AUC: 0.7340538625088588\n",
      "175 0 0.22911381152111251\n",
      "Validation loss: 1.1194542527988256 ROC AUC: 0.7168674698795181\n",
      "176 12 0.12163525276265633\n",
      "Validation loss: 1.2064229869684637 ROC AUC: 0.7147413182140325\n",
      "177 24 0.1878852658643309\n",
      "Validation loss: 1.3126879788392427 ROC AUC: 0.7143869596031184\n",
      "178 36 0.16028796216376706\n",
      "Validation loss: 1.315990499313304 ROC AUC: 0.7250177179305457\n",
      "Validation loss: 1.4067777371564447 ROC AUC: 0.7296243798724308\n",
      "180 10 0.5390360785940762\n",
      "Validation loss: 1.1090930881879189 ROC AUC: 0.7237774627923458\n",
      "181 22 0.16066726256889272\n",
      "Validation loss: 1.326961454176745 ROC AUC: 0.6913536498936925\n",
      "182 34 0.34024453497627155\n",
      "Validation loss: 0.9760681828915678 ROC AUC: 0.7372430900070872\n",
      "Validation loss: 1.1897897846651393 ROC AUC: 0.7259036144578314\n",
      "184 8 0.23875630806192832\n",
      "Validation loss: 1.376487945089277 ROC AUC: 0.7260807937632885\n",
      "185 20 0.1792695747916544\n",
      "Validation loss: 1.5207852784371534 ROC AUC: 0.6847980155917789\n",
      "186 32 0.1812849897381182\n",
      "Validation loss: 1.3539096985431696 ROC AUC: 0.6886959603118356\n",
      "Validation loss: 1.7565828676255333 ROC AUC: 0.7161587526576896\n",
      "188 6 0.17649134737729147\n",
      "Validation loss: 1.7631321884938422 ROC AUC: 0.690644932671864\n",
      "189 18 0.11913730977976662\n",
      "Validation loss: 1.4642176486009004 ROC AUC: 0.7042877391920623\n",
      "190 30 0.12985943700530814\n",
      "Validation loss: 1.3839535144780646 ROC AUC: 0.686392629340893\n",
      "Validation loss: 1.196411627017899 ROC AUC: 0.7322820694542878\n",
      "192 4 0.1502387205509851\n",
      "Validation loss: 1.2170114596158463 ROC AUC: 0.6957831325301205\n",
      "193 16 0.20751963127257916\n",
      "Validation loss: 1.4338851582925052 ROC AUC: 0.7012756909992913\n",
      "194 28 0.30555439186181066\n",
      "Validation loss: 1.0874516395543585 ROC AUC: 0.7168674698795181\n",
      "Validation loss: 1.3431681149842722 ROC AUC: 0.7007441530829199\n",
      "196 2 0.2629976192686458\n",
      "Validation loss: 1.4711492306349294 ROC AUC: 0.6972005669737774\n",
      "197 14 0.20767547263270103\n",
      "Validation loss: 1.5770367081986358 ROC AUC: 0.7228915662650602\n",
      "198 26 0.15692063196936162\n",
      "Validation loss: 1.6336820812414814 ROC AUC: 0.7142097802976612\n",
      "Validation loss: 1.261980329917756 ROC AUC: 0.7145641389085755\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.431906326820976 Test ROC AUC: 0.7726449275362318\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bace', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'classification', 'data_path': 'data/bace/bace.csv', 'target': ['Class']}}\n",
      "Running on: cuda:1\n",
      "1512\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1512\n",
      "Generating scaffold 1000/1512\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.3996271287041415\n",
      "Validation loss: 0.7661332274904314 ROC AUC: 0.5501417434443656\n",
      "1 12 0.8911216875663313\n",
      "Validation loss: 1.127804387878898 ROC AUC: 0.5021261516654855\n",
      "2 24 0.9204627254207784\n",
      "Validation loss: 0.853724033627289 ROC AUC: 0.5751240255138199\n",
      "3 36 0.6151259523107768\n",
      "Validation loss: 0.7287181588198175 ROC AUC: 0.635719347980156\n",
      "Validation loss: 1.543471356890849 ROC AUC: 0.609851169383416\n",
      "5 10 0.5517866664850402\n",
      "Validation loss: 1.4688002992150009 ROC AUC: 0.6491849751948972\n",
      "6 22 0.5090916332711081\n",
      "Validation loss: 0.7604137524863742 ROC AUC: 0.5740609496810773\n",
      "7 34 0.652543891294806\n",
      "Validation loss: 0.7548673500288401 ROC AUC: 0.5846917080085046\n",
      "Validation loss: 0.730885575149233 ROC AUC: 0.6234939759036144\n",
      "9 8 0.6486819502770629\n",
      "Validation loss: 0.8007433698666806 ROC AUC: 0.5919560595322466\n",
      "10 20 0.4426092108515443\n",
      "Validation loss: 0.8247758126416743 ROC AUC: 0.6263288447909284\n",
      "11 32 0.5433918870936533\n",
      "Validation loss: 1.1203390644086118 ROC AUC: 0.6789510985116939\n",
      "Validation loss: 0.9152320694449722 ROC AUC: 0.6296952515946138\n",
      "13 6 0.4885942494147204\n",
      "Validation loss: 0.8113428717417432 ROC AUC: 0.641743444365698\n",
      "14 18 0.48629376524235307\n",
      "Validation loss: 0.7805884804157232 ROC AUC: 0.6362508858965273\n",
      "15 30 0.3583600161812452\n",
      "Validation loss: 1.031494784828843 ROC AUC: 0.6284549964564139\n",
      "Validation loss: 0.8545717435167325 ROC AUC: 0.6713323883770376\n",
      "17 4 0.4714755500385794\n",
      "Validation loss: 0.8132300578205791 ROC AUC: 0.6645995747696668\n",
      "18 16 0.46137993978165587\n",
      "Validation loss: 0.9400306391400217 ROC AUC: 0.6293408929836996\n",
      "19 28 0.3438096054666896\n",
      "Validation loss: 0.65150442857616 ROC AUC: 0.6929482636428066\n",
      "Validation loss: 0.9065116505749178 ROC AUC: 0.7087172218284904\n",
      "21 2 0.3670782721448921\n",
      "Validation loss: 0.7058216459703761 ROC AUC: 0.6824946846208363\n",
      "22 14 0.6147350342099949\n",
      "Validation loss: 0.9562995879855377 ROC AUC: 0.6475903614457831\n",
      "23 26 0.3293759314896476\n",
      "Validation loss: 1.2129536993456203 ROC AUC: 0.6665485471296952\n",
      "Validation loss: 1.0865597274919219 ROC AUC: 0.6624734231041813\n",
      "25 0 0.44825449983197946\n",
      "Validation loss: 0.756021161347825 ROC AUC: 0.7058823529411764\n",
      "26 12 0.4064128044509506\n",
      "Validation loss: 0.7931242648339429 ROC AUC: 0.6408575478384124\n",
      "27 24 0.481983708834946\n",
      "Validation loss: 0.6660692364174798 ROC AUC: 0.7329907866761163\n",
      "28 36 0.404635959587266\n",
      "Validation loss: 1.1923477941790954 ROC AUC: 0.6640680368532955\n",
      "Validation loss: 1.0098324875957918 ROC AUC: 0.6371367824238129\n",
      "30 10 0.44512070919342545\n",
      "Validation loss: 0.7188038474676625 ROC AUC: 0.6913536498936924\n",
      "31 22 0.5051961723853281\n",
      "Validation loss: 0.7151914943527702 ROC AUC: 0.6775336640680368\n",
      "32 34 0.41377701198667344\n",
      "Validation loss: 0.9712702876684681 ROC AUC: 0.708185683912119\n",
      "Validation loss: 1.0032228120904885 ROC AUC: 0.6812544294826365\n",
      "34 8 0.303190718477571\n",
      "Validation loss: 0.782210395430887 ROC AUC: 0.6840892983699504\n",
      "35 20 0.4768148614734197\n",
      "Validation loss: 0.8492357036135844 ROC AUC: 0.6559177888022679\n",
      "36 32 0.31797795925051897\n",
      "Validation loss: 1.183701566513011 ROC AUC: 0.6436924167257264\n",
      "Validation loss: 0.7888091119709394 ROC AUC: 0.6674344436569808\n",
      "38 6 0.3496337849113745\n",
      "Validation loss: 0.8800360816993461 ROC AUC: 0.6392629340892984\n",
      "39 18 0.46876370551281094\n",
      "Validation loss: 0.73189438139366 ROC AUC: 0.6920623671155209\n",
      "40 30 0.2484348837681022\n",
      "Validation loss: 0.7431934148270563 ROC AUC: 0.6909992912827781\n",
      "Validation loss: 0.8814447699793128 ROC AUC: 0.6906449326718639\n",
      "42 4 0.32716246043364994\n",
      "Validation loss: 0.736334998481321 ROC AUC: 0.7055279943302621\n",
      "43 16 0.306739560650394\n",
      "Validation loss: 0.7399612834911473 ROC AUC: 0.738483345145287\n",
      "44 28 0.39043213789782044\n",
      "Validation loss: 0.919236474479271 ROC AUC: 0.6933026222537207\n",
      "Validation loss: 0.8691990959723264 ROC AUC: 0.6989723600283487\n",
      "46 2 0.3784346786073505\n",
      "Validation loss: 0.8022915866990753 ROC AUC: 0.6989723600283486\n",
      "47 14 0.34618171779145007\n",
      "Validation loss: 0.8572602331243604 ROC AUC: 0.6803685329553508\n",
      "48 26 0.32833847260883803\n",
      "Validation loss: 0.8445693459731853 ROC AUC: 0.7065910701630049\n",
      "Validation loss: 0.8852660158612081 ROC AUC: 0.7142097802976611\n",
      "50 0 0.34909747974634775\n",
      "Validation loss: 1.0527413637432832 ROC AUC: 0.7058823529411764\n",
      "51 12 0.20273945259734993\n",
      "Validation loss: 0.8535579814026687 ROC AUC: 0.7007441530829199\n",
      "52 24 0.33760295269771834\n",
      "Validation loss: 0.8339639238963853 ROC AUC: 0.6833805811481218\n",
      "53 36 0.4503880570684576\n",
      "Validation loss: 0.7934509251291388 ROC AUC: 0.7016300496102055\n",
      "Validation loss: 0.8759322174337526 ROC AUC: 0.6713323883770376\n",
      "55 10 0.41969335423714543\n",
      "Validation loss: 0.8497887198498707 ROC AUC: 0.6915308291991495\n",
      "56 22 0.3786003216071564\n",
      "Validation loss: 0.8394544570651276 ROC AUC: 0.7044649184975196\n",
      "57 34 0.33466295901532894\n",
      "Validation loss: 0.7949311496406202 ROC AUC: 0.7202338766832034\n",
      "Validation loss: 0.8077219922021525 ROC AUC: 0.676293408929837\n",
      "59 8 0.33854158762548103\n",
      "Validation loss: 0.7983731118259051 ROC AUC: 0.7152728561304039\n",
      "60 20 0.20987723743851858\n",
      "Validation loss: 0.8913339313292346 ROC AUC: 0.6396172927002126\n",
      "61 32 0.23705643755083192\n",
      "Validation loss: 0.780793483683605 ROC AUC: 0.7106661941885187\n",
      "Validation loss: 0.8657838220627893 ROC AUC: 0.7216513111268604\n",
      "63 6 0.3443797173409692\n",
      "Validation loss: 0.9071691525692971 ROC AUC: 0.6814316087880936\n",
      "64 18 0.4096548329976257\n",
      "Validation loss: 0.8814418142205043 ROC AUC: 0.6837349397590362\n",
      "65 30 0.28333391274287745\n",
      "Validation loss: 0.8908127262102847 ROC AUC: 0.6904677533664068\n",
      "Validation loss: 0.9666943850106751 ROC AUC: 0.672041105598866\n",
      "67 4 0.28601443547223804\n",
      "Validation loss: 0.8469646257280514 ROC AUC: 0.6998582565556343\n",
      "68 16 0.6855019823565255\n",
      "Validation loss: 0.8665098082150845 ROC AUC: 0.7090715804394047\n",
      "69 28 0.2757037223141698\n",
      "Validation loss: 0.7721775229403515 ROC AUC: 0.7076541459957476\n",
      "Validation loss: 0.8584578929357971 ROC AUC: 0.7207654145995747\n",
      "71 2 0.27003047647404604\n",
      "Validation loss: 0.9056743304461043 ROC AUC: 0.7140326009922041\n",
      "72 14 0.35455150387651796\n",
      "Validation loss: 0.9869990826442542 ROC AUC: 0.6947200566973778\n",
      "73 26 0.2518689824721319\n",
      "Validation loss: 0.9243775404841694 ROC AUC: 0.6927710843373495\n",
      "Validation loss: 0.8478044828042289 ROC AUC: 0.6697377746279235\n",
      "75 0 0.29002285575408254\n",
      "Validation loss: 1.025212404743725 ROC AUC: 0.7326364280652019\n",
      "76 12 0.32525670564783615\n",
      "Validation loss: 0.8066591979652051 ROC AUC: 0.6952515946137491\n",
      "77 24 0.28195059575596804\n",
      "Validation loss: 0.8712532141350753 ROC AUC: 0.6973777462792345\n",
      "78 36 0.36880086874173457\n",
      "Validation loss: 1.1854425692400397 ROC AUC: 0.719702338766832\n",
      "Validation loss: 0.8635825652949858 ROC AUC: 0.6752303330970942\n",
      "80 10 0.3200632412094456\n",
      "Validation loss: 1.0310404332268317 ROC AUC: 0.6991495393338059\n",
      "81 22 0.3872991063539585\n",
      "Validation loss: 0.8599902126962775 ROC AUC: 0.7074769666902906\n",
      "82 34 0.461601818448475\n",
      "Validation loss: 0.9254312953412138 ROC AUC: 0.7005669737774628\n",
      "Validation loss: 0.8777403448591169 ROC AUC: 0.7322820694542878\n",
      "84 8 0.2982495047965557\n",
      "Validation loss: 0.8794240738382403 ROC AUC: 0.6865698086463502\n",
      "85 20 0.2297410373521325\n",
      "Validation loss: 0.7637954512179292 ROC AUC: 0.7122608079376329\n",
      "86 32 0.5929473594035807\n",
      "Validation loss: 0.8171252031989445 ROC AUC: 0.6996810772501771\n",
      "Validation loss: 0.954859349901313 ROC AUC: 0.6656626506024097\n",
      "88 6 0.21484037074981283\n",
      "Validation loss: 1.1332562088176905 ROC AUC: 0.693656980864635\n",
      "89 18 0.264862588070496\n",
      "Validation loss: 0.8877453464545951 ROC AUC: 0.7083628632175762\n",
      "90 30 0.5859985570671842\n",
      "Validation loss: 0.8837470384623041 ROC AUC: 0.7124379872430899\n",
      "Validation loss: 0.8668175769957486 ROC AUC: 0.722537207654146\n",
      "92 4 0.21952875711346545\n",
      "Validation loss: 0.9804062120961827 ROC AUC: 0.7165131112686038\n",
      "93 16 0.2884496302325406\n",
      "Validation loss: 1.0495053975787383 ROC AUC: 0.6711552090715804\n",
      "94 28 0.4913452836075593\n",
      "Validation loss: 0.9327703832790551 ROC AUC: 0.7317505315379164\n",
      "Validation loss: 0.9345749387677932 ROC AUC: 0.6762934089298369\n",
      "96 2 0.31141975283671297\n",
      "Validation loss: 0.8463386269594659 ROC AUC: 0.6816087880935507\n",
      "97 14 0.2871323788074881\n",
      "Validation loss: 0.8329265176855176 ROC AUC: 0.7234231041814316\n",
      "98 26 0.22413368319302185\n",
      "Validation loss: 1.154581960463366 ROC AUC: 0.7468107725017719\n",
      "Validation loss: 1.0282043972552217 ROC AUC: 0.7103118355776046\n",
      "100 0 0.2028612363316405\n",
      "Validation loss: 0.9468778134971265 ROC AUC: 0.7407866761162295\n",
      "101 12 0.19736135818737682\n",
      "Validation loss: 0.9404355449392306 ROC AUC: 0.6952515946137491\n",
      "102 24 0.28161056658793887\n",
      "Validation loss: 1.1534220651285538 ROC AUC: 0.6894046775336641\n",
      "103 36 0.3377659169365052\n",
      "Validation loss: 0.9013917106666313 ROC AUC: 0.7402551381998582\n",
      "Validation loss: 0.9673895906928359 ROC AUC: 0.6809000708717221\n",
      "105 10 0.26942507677826494\n",
      "Validation loss: 0.9594067240392925 ROC AUC: 0.7097802976612331\n",
      "106 22 0.226863542272887\n",
      "Validation loss: 0.9259901192804046 ROC AUC: 0.7315733522324592\n",
      "107 34 0.15983576808114683\n",
      "Validation loss: 0.935680578678649 ROC AUC: 0.6886959603118356\n",
      "Validation loss: 1.0052181687576092 ROC AUC: 0.734053862508859\n",
      "109 8 0.18803107388914894\n",
      "Validation loss: 1.1584854386500176 ROC AUC: 0.7143869596031184\n",
      "110 20 0.34139027868627436\n",
      "Validation loss: 0.9173243855009016 ROC AUC: 0.6809000708717222\n",
      "111 32 0.366060353417933\n",
      "Validation loss: 0.8485642000539413 ROC AUC: 0.6642452161587526\n",
      "Validation loss: 1.022931640511317 ROC AUC: 0.7205882352941176\n",
      "113 6 0.12987850507631943\n",
      "Validation loss: 1.0336954779182839 ROC AUC: 0.7227143869596031\n",
      "114 18 0.1666485361962653\n",
      "Validation loss: 0.9991490422495154 ROC AUC: 0.6996810772501773\n",
      "115 30 0.30030663794713\n",
      "Validation loss: 0.8534417393191761 ROC AUC: 0.7354712969525159\n",
      "Validation loss: 1.1944861593625404 ROC AUC: 0.7244861800141742\n",
      "117 4 0.20944591105778138\n",
      "Validation loss: 0.9048832883897996 ROC AUC: 0.7236002834868887\n",
      "118 16 0.13500718441410625\n",
      "Validation loss: 1.1208630885114732 ROC AUC: 0.6980864635010631\n",
      "119 28 0.5838832087341036\n",
      "Validation loss: 0.8405417638109219 ROC AUC: 0.705350815024805\n",
      "Validation loss: 1.225500302598966 ROC AUC: 0.7264351523742028\n",
      "121 2 0.3853814241809546\n",
      "Validation loss: 1.0033745702528796 ROC AUC: 0.7042877391920623\n",
      "122 14 0.2658161249860829\n",
      "Validation loss: 0.9838860457306666 ROC AUC: 0.7289156626506024\n",
      "123 26 0.26289605617075695\n",
      "Validation loss: 0.9473331748255042 ROC AUC: 0.7062367115520907\n",
      "Validation loss: 1.0665352206356478 ROC AUC: 0.6876328844790928\n",
      "125 0 0.21828609867454105\n",
      "Validation loss: 1.0117009680792195 ROC AUC: 0.7296243798724309\n",
      "126 12 0.18513520075632453\n",
      "Validation loss: 1.111506602622026 ROC AUC: 0.7165131112686038\n",
      "127 24 0.2259980233089614\n",
      "Validation loss: 0.9951896367483581 ROC AUC: 0.7170446491849752\n",
      "128 36 0.3332497959849813\n",
      "Validation loss: 0.98957975415994 ROC AUC: 0.6855067328136074\n",
      "Validation loss: 1.219222751674273 ROC AUC: 0.6842664776754075\n",
      "130 10 0.33560003310748443\n",
      "Validation loss: 1.0560125412530457 ROC AUC: 0.7060595322466335\n",
      "131 22 0.45208974961018783\n",
      "Validation loss: 0.9953864812850952 ROC AUC: 0.7172218284904324\n",
      "132 34 0.2544414931016197\n",
      "Validation loss: 1.113126259963244 ROC AUC: 0.6899362154500355\n",
      "Validation loss: 0.9674793004200158 ROC AUC: 0.709603118355776\n",
      "134 8 0.13426062489662777\n",
      "Validation loss: 1.2104218621917118 ROC AUC: 0.7218284904323176\n",
      "135 20 0.28339530332100765\n",
      "Validation loss: 1.0347572632183302 ROC AUC: 0.7067682494684621\n",
      "136 32 0.3669797605053625\n",
      "Validation loss: 1.2602757152342638 ROC AUC: 0.7379518072289156\n",
      "Validation loss: 0.9417004103692163 ROC AUC: 0.6993267186392629\n",
      "138 6 0.10154959703383566\n",
      "Validation loss: 1.1955090753290036 ROC AUC: 0.7090715804394047\n",
      "139 18 0.23512998720042377\n",
      "Validation loss: 1.0149019992114692 ROC AUC: 0.7391920623671155\n",
      "140 30 0.549215579092286\n",
      "Validation loss: 1.067395822101871 ROC AUC: 0.7262579730687456\n",
      "Validation loss: 1.0375032503873307 ROC AUC: 0.7165131112686038\n",
      "142 4 0.27562706360572464\n",
      "Validation loss: 0.9048265625309471 ROC AUC: 0.7379518072289156\n",
      "143 16 0.2141524667608711\n",
      "Validation loss: 1.0341271379136092 ROC AUC: 0.684975194897236\n",
      "144 28 0.18864383489854714\n",
      "Validation loss: 1.074090101071541 ROC AUC: 0.7181077250177179\n",
      "Validation loss: 1.0677626811905412 ROC AUC: 0.7358256555634302\n",
      "146 2 0.33210698365317054\n",
      "Validation loss: 1.2715339579724318 ROC AUC: 0.7081856839121191\n",
      "147 14 0.17930942288036528\n",
      "Validation loss: 1.2653076806605257 ROC AUC: 0.7042877391920623\n",
      "148 26 0.16485211977033373\n",
      "Validation loss: 1.4090736989943398 ROC AUC: 0.6527285613040397\n",
      "Validation loss: 0.9394354599201127 ROC AUC: 0.7143869596031184\n",
      "150 0 0.35113204059615744\n",
      "Validation loss: 1.200899537035961 ROC AUC: 0.7315733522324592\n",
      "151 12 0.25570175151398505\n",
      "Validation loss: 1.2944093468962916 ROC AUC: 0.7198795180722892\n",
      "152 24 0.14238070583677825\n",
      "Validation loss: 1.2735912531416937 ROC AUC: 0.7009213323883771\n",
      "153 36 0.25110848306323397\n",
      "Validation loss: 1.3278102292525058 ROC AUC: 0.6989723600283486\n",
      "Validation loss: 1.0095369618460042 ROC AUC: 0.7283841247342311\n",
      "155 10 0.12081193289744255\n",
      "Validation loss: 1.417010582835469 ROC AUC: 0.7246633593196314\n",
      "156 22 0.325046714678419\n",
      "Validation loss: 0.9992547224689003 ROC AUC: 0.729801559177888\n",
      "157 34 0.27537893547749387\n",
      "Validation loss: 1.2665364679121813 ROC AUC: 0.7051736357193479\n",
      "Validation loss: 1.1584559315877245 ROC AUC: 0.7170446491849752\n",
      "159 8 0.2924063284546612\n",
      "Validation loss: 1.2964460328714738 ROC AUC: 0.7069454287739192\n",
      "160 20 0.14830672031132225\n",
      "Validation loss: 1.1736015223509428 ROC AUC: 0.7459248759744862\n",
      "161 32 0.3485224514319229\n",
      "Validation loss: 1.2105700393386234 ROC AUC: 0.674698795180723\n",
      "Validation loss: 1.0890815763284039 ROC AUC: 0.7143869596031183\n",
      "163 6 0.12302573007904541\n",
      "Validation loss: 1.0527387746911965 ROC AUC: 0.6770021261516654\n",
      "164 18 0.1363936029206236\n",
      "Validation loss: 1.0356383221038918 ROC AUC: 0.7223600283486888\n",
      "165 30 0.21640052688669853\n",
      "Validation loss: 1.1268027239287925 ROC AUC: 0.6865698086463501\n",
      "Validation loss: 1.1048094381559763 ROC AUC: 0.7358256555634302\n",
      "167 4 0.23744035034171598\n",
      "Validation loss: 1.2920201116839782 ROC AUC: 0.6881644223954643\n",
      "168 16 0.1382323300103253\n",
      "Validation loss: 1.2299151712695495 ROC AUC: 0.7184620836286322\n",
      "169 28 0.13881557601151265\n",
      "Validation loss: 1.1350732497032114 ROC AUC: 0.7087172218284905\n",
      "Validation loss: 1.0948764583132915 ROC AUC: 0.6922395464209781\n",
      "171 2 0.09493902480181486\n",
      "Validation loss: 1.2190582910120882 ROC AUC: 0.7005669737774628\n",
      "172 14 0.25966876797800625\n",
      "Validation loss: 1.378185406425931 ROC AUC: 0.7126151665485472\n",
      "173 26 0.3428685595184664\n",
      "Validation loss: 1.1470782764700076 ROC AUC: 0.7205882352941176\n",
      "Validation loss: 1.1533301942395848 ROC AUC: 0.7234231041814315\n",
      "175 0 0.06923108752768391\n",
      "Validation loss: 1.2070216252314334 ROC AUC: 0.7236002834868888\n",
      "176 12 0.2858979277518705\n",
      "Validation loss: 1.1597602935816278 ROC AUC: 0.7305102763997167\n",
      "177 24 0.13391171793387596\n",
      "Validation loss: 1.3480420736287604 ROC AUC: 0.709603118355776\n",
      "178 36 0.41325287210134287\n",
      "Validation loss: 1.1324678335758234 ROC AUC: 0.7367115520907157\n",
      "Validation loss: 1.1817929847350974 ROC AUC: 0.684975194897236\n",
      "180 10 0.25230505195359476\n",
      "Validation loss: 1.1781744230661961 ROC AUC: 0.7074769666902906\n",
      "181 22 0.1455499064220946\n",
      "Validation loss: 1.0995418149114444 ROC AUC: 0.6922395464209781\n",
      "182 34 0.12413137986180443\n",
      "Validation loss: 1.476999685464316 ROC AUC: 0.6901133947554926\n",
      "Validation loss: 1.3792000132680728 ROC AUC: 0.7218284904323174\n",
      "184 8 0.16902561664437288\n",
      "Validation loss: 1.3247346885946414 ROC AUC: 0.7149184975194897\n",
      "185 20 0.14681227923333592\n",
      "Validation loss: 1.3471615780268285 ROC AUC: 0.7018072289156626\n",
      "186 32 0.3609768757387935\n",
      "Validation loss: 1.3347987576036264 ROC AUC: 0.6920623671155208\n",
      "Validation loss: 1.0856962203979492 ROC AUC: 0.7209425939050319\n",
      "188 6 0.2545971080832051\n",
      "Validation loss: 0.9703280302072992 ROC AUC: 0.7184620836286322\n",
      "189 18 0.26632331797736886\n",
      "Validation loss: 1.172947629398068 ROC AUC: 0.7165131112686037\n",
      "190 30 0.27819947796516903\n",
      "Validation loss: 1.2283581416338485 ROC AUC: 0.7237774627923459\n",
      "Validation loss: 1.4896634643441005 ROC AUC: 0.6979092841956058\n",
      "192 4 0.1668961115060431\n",
      "Validation loss: 1.189901547518787 ROC AUC: 0.7478738483345145\n",
      "193 16 0.12053256114509268\n",
      "Validation loss: 1.2284774669748268 ROC AUC: 0.7363571934798016\n",
      "194 28 0.2049515197558275\n",
      "Validation loss: 1.2218787235929476 ROC AUC: 0.7244861800141744\n",
      "Validation loss: 1.205710619095935 ROC AUC: 0.7064138908575478\n",
      "196 2 0.1362071550028372\n",
      "Validation loss: 1.2744039529996203 ROC AUC: 0.7122608079376328\n",
      "197 14 0.15124450945489695\n",
      "Validation loss: 1.2117075683265333 ROC AUC: 0.6991495393338057\n",
      "198 26 0.1368850466392372\n",
      "Validation loss: 1.1642323677113513 ROC AUC: 0.7264351523742028\n",
      "Validation loss: 1.0642036625881068 ROC AUC: 0.7154500354358612\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.661199921055844 Test ROC AUC: 0.7983695652173913\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bbbp', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'classification', 'data_path': 'data/bbbp/BBBP.csv', 'target': ['p_np']}}\n",
      "Running on: cuda:1\n",
      "2038\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/2038\n",
      "Generating scaffold 1000/2038\n",
      "Generating scaffold 2000/2038\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.4393632571783357\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2e40b2f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2e40b2f80>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2e40b2f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2e40b2f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Validation loss: 0.7754972892649034 ROC AUC: 0.8918866459627329\n",
      "1 5 0.5264197785342931\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2e40b2f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2e40b2f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2e40b2f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2e40b2f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Validation loss: 0.5171794412182826 ROC AUC: 0.8627717391304348\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2e40b2f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2e40b2f80>\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2e40b2f80>\n",
      "    if w.is_alive():\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2e40b2f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Validation loss: 0.9501960499613893 ROC AUC: 0.8471467391304347\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2e40b2f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2e40b2f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2e40b2f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2e40b2f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/MolCLR-master - copy2/finetuneReconSubGraphFrag.py\", line 665, in <module>\n",
      "    result = main(config)\n",
      "  File \"/tf/MolCLR-master - copy2/finetuneReconSubGraphFrag.py\", line 585, in main\n",
      "    fine_tune.train()\n",
      "  File \"/tf/MolCLR-master - copy2/finetuneReconSubGraphFrag.py\", line 396, in train\n",
      "    valid_loss, valid_cls = self._validate(model_list, valid_loader)\n",
      "  File \"/tf/MolCLR-master - copy2/finetuneReconSubGraphFrag.py\", line 474, in _validate\n",
      "    valid_loss /= num_data\n",
      "ZeroDivisionError: float division by zero\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bbbp', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 778, 'task': 'classification', 'data_path': 'data/bbbp/BBBP.csv', 'target': ['p_np']}}\n",
      "Running on: cuda:1\n",
      "2038\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/2038\n",
      "Generating scaffold 1000/2038\n",
      "Generating scaffold 2000/2038\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.3506221605466031\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Validation loss: 0.9208734456230613 ROC AUC: 0.624611801242236\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Validation loss: 0.8174222602563745 ROC AUC: 0.8276397515527949\n",
      "2 20 0.7358890177886765\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Validation loss: 0.5834794453546113 ROC AUC: 0.9047942546583851\n",
      "3 49 0.5668807693871586\n",
      "Validation loss: 0.477125624815623 ROC AUC: 0.9027562111801243\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Validation loss: 0.5321797311306 ROC AUC: 0.8312382149591451\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Validation loss: 0.7648039869233674 ROC AUC: 0.8662655279503105\n",
      "6 20 0.41926435932851064\n",
      "Validation loss: 0.4143919050693512 ROC AUC: 0.98828125\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    self._shutdown_workers()\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "AssertionError: can only test a child process\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Validation loss: 0.49206089505962297 ROC AUC: 0.9085791925465838\n",
      "8 15 0.41578301279105734\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Validation loss: 0.4075467481332667 ROC AUC: 0.9002329192546584\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    self._shutdown_workers()\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    if w.is_alive():\n",
      "AssertionError: can only test a child process\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Validation loss: 0.4366542866417006 ROC AUC: 0.8839285714285714\n",
      "10 4 0.34696582494188255\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Validation loss: 0.42944830247000154 ROC AUC: 0.9053765527950309\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Validation loss: 0.4522425555715374 ROC AUC: 0.9004270186335404\n",
      "12 4 0.5220148286645502\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe8c5616f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n"
     ]
    }
   ],
   "source": [
    "datasets = ['FreeSolv', 'ESOL', 'Lipo', 'qm7', \"bace\",  \"bbbp\",  'tox21', 'clintox', 'sider']\n",
    "seeds = [777, 778, 779, 780, 781]\n",
    "\n",
    "for dataset in datasets:\n",
    "    for seed in seeds:\n",
    "            if dataset == 'FreeSolv':\n",
    "            # FreeSolv 데이터셋에 대한 특정 옵션을 적용\n",
    "                !python finetuneReconSubGraphFrag.py \\\n",
    "                --task_name {dataset} \\\n",
    "                --seed {seed} \\\n",
    "                --dropout 0.5 \\\n",
    "                --num_layer 3 \\\n",
    "                --emb_dim 64 \\\n",
    "                --feat_dim 64 \\\n",
    "                --alpha 0.1 \\\n",
    "                --mask_edge 1 \\\n",
    "                --gpu cuda:1 \n",
    "            \n",
    "            elif dataset == 'clintox':\n",
    "                !python finetuneReconSubGraphFrag.py \\\n",
    "                --task_name {dataset} \\\n",
    "                --seed {seed} \\\n",
    "                --dropout 0.3 \\\n",
    "                --num_layer 5 \\\n",
    "                --emb_dim 64 \\\n",
    "                --feat_dim 64 \\\n",
    "                --alpha 0.1 \\\n",
    "                --mask_edge 1 \\\n",
    "                --gpu cuda:1\n",
    "\n",
    "            else:\n",
    "                !python finetuneReconSubGraphFrag.py \\\n",
    "                --task_name {dataset} \\\n",
    "                --seed {seed} \\\n",
    "                --alpha 0.1 \\\n",
    "                --mask_edge 1 \\\n",
    "                --gpu cuda:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2a46ae-a6b6-4a66-befc-c4e38c83fdb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bbbp', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 0, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'classification', 'data_path': 'data/bbbp/BBBP.csv', 'target': ['p_np']}}\n",
      "Running on: cuda:1\n",
      "2038\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/2038\n",
      "Generating scaffold 1000/2038\n",
      "Generating scaffold 2000/2038\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]0 0 1.4286695103477922\n",
      " 24%|██████████                                 | 12/51 [00:03<00:10,  3.56it/s]\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]Batch number: 0, Data size: (2002, 2002)\n",
      " 14%|██████▍                                      | 1/7 [00:00<00:01,  5.24it/s]Batch number: 1, Data size: (2042, 2042)\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:01,  4.98it/s]Batch number: 2, Data size: (1880, 1880)\n",
      " 43%|███████████████████▎                         | 3/7 [00:00<00:00,  5.13it/s]Batch number: 3, Data size: (1909, 1909)\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  5.19it/s]Batch number: 4, Data size: (2067, 2067)\n",
      " 71%|████████████████████████████████▏            | 5/7 [00:00<00:00,  4.97it/s]Batch number: 5, Data size: (1527, 1527)\n",
      " 86%|██████████████████████████████████████▌      | 6/7 [00:01<00:00,  5.38it/s]Batch number: 6, Data size: (709, 709)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  5.73it/s]\n",
      "Validation loss: 0.9430275828230614 ROC AUC: 0.7280667701863354\n",
      " 14%|██████                                      | 7/51 [00:01<00:10,  4.36it/s]\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]Batch number: 0, Data size: (1855, 1855)\n",
      " 14%|██████▍                                      | 1/7 [00:00<00:01,  5.55it/s]Batch number: 1, Data size: (2438, 2438)\n",
      " 29%|████████████▊                                | 2/7 [00:00<00:01,  4.58it/s]Batch number: 2, Data size: (1684, 1684)\n",
      " 43%|███████████████████▎                         | 3/7 [00:00<00:00,  5.16it/s]Batch number: 3, Data size: (1585, 1585)\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:00<00:00,  5.57it/s]Batch number: 4, Data size: (1756, 1756)\n",
      " 71%|████████████████████████████████▏            | 5/7 [00:00<00:00,  5.63it/s]Batch number: 5, Data size: (2042, 2042)\n",
      " 86%|██████████████████████████████████████▌      | 6/7 [00:01<00:00,  5.45it/s]Batch number: 6, Data size: (776, 776)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  5.86it/s]\n",
      "Validation loss: 0.942590122129403 ROC AUC: 0.8211374223602484\n",
      " 31%|█████████████▍                             | 16/51 [00:03<00:07,  4.63it/s]"
     ]
    }
   ],
   "source": [
    "seeds = list(range(777,782))\n",
    "# datasets = [\"bace\",  \"bbbp\", \"tox21\", \"toxcast\", \"sider\",  ]\n",
    "datasets = [  \"bbbp\",  \"sider\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "    for seed in seeds: \n",
    "                !python finetuneReconSubGraphFrag.py \\\n",
    "                --task_name {dataset} \\\n",
    "                --seed {seed} \\\n",
    "                --alpha 0.1 \\\n",
    "                --mask_edge 1 \\\n",
    "                --gpu cuda:1 \\\n",
    "                --num_workers 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6764b07a-c44b-44d3-ab6b-161100c0d53b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: Syntax error: \"(\" unexpected\n"
     ]
    }
   ],
   "source": [
    "seeds = [range(777,782)]\n",
    "for seed in seeds:\n",
    "                !python finetuneReconSubGraphFrag.py \\\n",
    "                --task_name bbbp\\\n",
    "                --seed {seed} \\\n",
    "                --alpha 0.1 \\\n",
    "                --mask_edge 1 \\\n",
    "                --gpu cuda:1 \\\n",
    "                --num_workers 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88842242-2a03-49af-8f54-331e76eba2d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'bbbp', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 0, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'classification', 'data_path': 'data/bbbp/BBBP.csv', 'target': ['p_np']}}\n",
      "Running on: cuda:1\n",
      "2038\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/2038\n",
      "Generating scaffold 1000/2038\n",
      "Generating scaffold 2000/2038\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "[[0, 1, 2, 3, 4, 5, 14, 16], [18, 20, 6, 7, 8, 10, 11], [12], [9], [13], [15], [17], [19], [21], [22], [23], [24]]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/MolCLR-master - copy2/finetuneReconSubGraphFrag.py\", line 677, in <module>\n",
      "    result = main(config)\n",
      "  File \"/tf/MolCLR-master - copy2/finetuneReconSubGraphFrag.py\", line 594, in main\n",
      "    fine_tune.train()\n",
      "  File \"/tf/MolCLR-master - copy2/finetuneReconSubGraphFrag.py\", line 397, in train\n",
      "    valid_loss, valid_cls = self._validate(model_list, valid_loader)\n",
      "  File \"/tf/MolCLR-master - copy2/finetuneReconSubGraphFrag.py\", line 450, in _validate\n",
      "    for bn, data in enumerate(valid_loader):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 628, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 671, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/tf/MolCLR-master - copy2/dataset/dataset_test_subgraphFrag.py\", line 198, in __getitem__\n",
      "    curr_idx = np.array(list(idx)) + curr_num\n",
      "TypeError: 'int' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "!python finetuneReconSubGraphFrag.py \\\n",
    "--task_name bbbp\\\n",
    "--seed 777 \\\n",
    "--alpha 0.1 \\\n",
    "--mask_edge 1 \\\n",
    "--gpu cuda:1 \\\n",
    "--num_workers 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d532f3f-df2e-49ed-a344-e90899cc8f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 10, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'bbbp', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 750, 'task': 'classification', 'data_path': 'data/bbbp/BBBP.csv', 'target': ['p_np']}}\n",
      "Running on: cuda:0\n",
      "2038\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/2038\n",
      "Generating scaffold 1000/2038\n",
      "Generating scaffold 2000/2038\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 5.518152713775635\n",
      "0 50 0.8474320769309998\n",
      "Validation loss: 1.8594437042872112 ROC AUC: 0.8788819875776397\n"
     ]
    }
   ],
   "source": [
    "!python finetuneReconFrag.py \\\n",
    "--task_name bbbp \\\n",
    "--splitting scaffold \\\n",
    "--seed 750 \\\n",
    "--random_masking 1 \\\n",
    "--epochs 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066714a4-1761-414e-8f25-d0e70cd9a597",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'bbbp', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 42, 'task': 'classification', 'data_path': 'data/bbbp/BBBP.csv', 'target': ['p_np']}}\n",
      "Running on: cuda:0\n",
      "2038\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/2038\n",
      "Generating scaffold 1000/2038\n",
      "Generating scaffold 2000/2038\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0, 50, 0.6508. loss_end: 0.5064, loss_recon_node: 1.4437, loss_recon_edge: 0.0000,acc_node: 0.6057, acc_edge: 0.0000\n",
      "Validation loss: 0.6123627009345036 ROC AUC: 0.8914013975155279 edge acc: 0 node acc: 0.5994507670402527\n",
      "1, 50, 0.5110. loss_end: 0.4019, loss_recon_node: 1.0917, loss_recon_edge: 0.0000,acc_node: 0.6564, acc_edge: 0.0000\n",
      "Validation loss: 0.5601444174261654 ROC AUC: 0.9093555900621118 edge acc: 0 node acc: 0.6123970150947571\n",
      "2, 50, 0.4235. loss_end: 0.3237, loss_recon_node: 0.9980, loss_recon_edge: 0.0000,acc_node: 0.7260, acc_edge: 0.0000\n",
      "Validation loss: 0.5747032633014754 ROC AUC: 0.9165372670807453 edge acc: 0 node acc: 0.6065123677253723\n",
      "3, 50, 0.3800. loss_end: 0.2763, loss_recon_node: 1.0366, loss_recon_edge: 0.0000,acc_node: 0.7353, acc_edge: 0.0000\n",
      "Validation loss: 0.4720950944750917 ROC AUC: 0.9329386645962733 edge acc: 0 node acc: 0.565712034702301\n",
      "4, 50, 0.3952. loss_end: 0.2987, loss_recon_node: 0.9658, loss_recon_edge: 0.0000,acc_node: 0.7054, acc_edge: 0.0000\n",
      "Validation loss: 0.7411106614505544 ROC AUC: 0.8560753105590062 edge acc: 0 node acc: 0.626912534236908\n",
      "5, 50, 0.4545. loss_end: 0.3377, loss_recon_node: 1.1680, loss_recon_edge: 0.0000,acc_node: 0.6393, acc_edge: 0.0000\n",
      "Validation loss: 0.5623083991162917 ROC AUC: 0.8974184782608696 edge acc: 0 node acc: 0.6155354976654053\n",
      "6, 50, 0.5241. loss_end: 0.4296, loss_recon_node: 0.9446, loss_recon_edge: 0.0000,acc_node: 0.6985, acc_edge: 0.0000\n",
      "Validation loss: 0.6311870112138636 ROC AUC: 0.9288625776397514 edge acc: 0 node acc: 0.6116123795509338\n",
      "7, 50, 0.4766. loss_end: 0.3768, loss_recon_node: 0.9979, loss_recon_edge: 0.0000,acc_node: 0.7057, acc_edge: 0.0000\n",
      "Validation loss: 0.6229800196254954 ROC AUC: 0.9109083850931676 edge acc: 0 node acc: 0.6367202997207642\n",
      "8, 50, 0.5288. loss_end: 0.4234, loss_recon_node: 1.0541, loss_recon_edge: 0.0000,acc_node: 0.6981, acc_edge: 0.0000\n",
      "Validation loss: 0.5331168350051431 ROC AUC: 0.921001552795031 edge acc: 0 node acc: 0.6210278272628784\n",
      "9, 50, 0.3497. loss_end: 0.2325, loss_recon_node: 1.1725, loss_recon_edge: 0.0000,acc_node: 0.5932, acc_edge: 0.0000\n",
      "Validation loss: 0.6741983978187337 ROC AUC: 0.921486801242236 edge acc: 0 node acc: 0.6120046973228455\n",
      "10, 50, 0.3763. loss_end: 0.2822, loss_recon_node: 0.9410, loss_recon_edge: 0.0000,acc_node: 0.7113, acc_edge: 0.0000\n",
      "Validation loss: 0.5395644277918572 ROC AUC: 0.9137228260869564 edge acc: 0 node acc: 0.6390741467475891\n",
      "11, 50, 0.3005. loss_end: 0.1896, loss_recon_node: 1.1093, loss_recon_edge: 0.0000,acc_node: 0.6484, acc_edge: 0.0000\n",
      "Validation loss: 0.5174975190676895 ROC AUC: 0.9087732919254659 edge acc: 0 node acc: 0.5943507552146912\n",
      "12, 50, 0.4794. loss_end: 0.3792, loss_recon_node: 1.0014, loss_recon_edge: 0.0000,acc_node: 0.6186, acc_edge: 0.0000\n",
      "Validation loss: 0.6363750783836141 ROC AUC: 0.890527950310559 edge acc: 0 node acc: 0.6053354144096375\n",
      "13, 50, 0.3213. loss_end: 0.2431, loss_recon_node: 0.7822, loss_recon_edge: 0.0000,acc_node: 0.7674, acc_edge: 0.0000\n",
      "Validation loss: 0.5691380699475607 ROC AUC: 0.9171195652173912 edge acc: 0 node acc: 0.5633581876754761\n",
      "14, 50, 0.3339. loss_end: 0.2487, loss_recon_node: 0.8526, loss_recon_edge: 0.0000,acc_node: 0.7768, acc_edge: 0.0000\n",
      "Validation loss: 0.4897971936300689 ROC AUC: 0.9297360248447204 edge acc: 0 node acc: 0.6018046140670776\n",
      "15, 50, 0.3358. loss_end: 0.2182, loss_recon_node: 1.1761, loss_recon_edge: 0.0000,acc_node: 0.5035, acc_edge: 0.0000\n",
      "Validation loss: 0.48366082649604947 ROC AUC: 0.9209045031055899 edge acc: 0 node acc: 0.5955276489257812\n",
      "16, 50, 0.2748. loss_end: 0.1791, loss_recon_node: 0.9565, loss_recon_edge: 0.0000,acc_node: 0.6974, acc_edge: 0.0000\n",
      "Validation loss: 0.4943995195276597 ROC AUC: 0.9172166149068323 edge acc: 0 node acc: 0.5963122844696045\n",
      "17, 50, 0.3823. loss_end: 0.2754, loss_recon_node: 1.0684, loss_recon_edge: 0.0000,acc_node: 0.6321, acc_edge: 0.0000\n",
      "Validation loss: 0.6541186945111144 ROC AUC: 0.8990683229813664 edge acc: 0 node acc: 0.6273048520088196\n",
      "18, 50, 0.2349. loss_end: 0.1337, loss_recon_node: 1.0120, loss_recon_edge: 0.0000,acc_node: 0.6163, acc_edge: 0.0000\n",
      "Validation loss: 0.5771905324038338 ROC AUC: 0.9189635093167702 edge acc: 0 node acc: 0.6163201332092285\n",
      "19, 50, 0.3705. loss_end: 0.2783, loss_recon_node: 0.9216, loss_recon_edge: 0.0000,acc_node: 0.7437, acc_edge: 0.0000\n",
      "Validation loss: 0.513230163677066 ROC AUC: 0.9164402173913041 edge acc: 0 node acc: 0.5833660364151001\n",
      "20, 50, 0.4740. loss_end: 0.3870, loss_recon_node: 0.8705, loss_recon_edge: 0.0000,acc_node: 0.7128, acc_edge: 0.0000\n",
      "Validation loss: 0.6267784740410599 ROC AUC: 0.905376552795031 edge acc: 0 node acc: 0.6190662980079651\n",
      "21, 50, 0.3102. loss_end: 0.2205, loss_recon_node: 0.8974, loss_recon_edge: 0.0000,acc_node: 0.7809, acc_edge: 0.0000\n",
      "Validation loss: 0.995858021810943 ROC AUC: 0.844623447204969 edge acc: 0 node acc: 0.6171047687530518\n",
      "22, 50, 0.3361. loss_end: 0.2192, loss_recon_node: 1.1682, loss_recon_edge: 0.0000,acc_node: 0.5839, acc_edge: 0.0000\n",
      "Validation loss: 0.4686806412304149 ROC AUC: 0.9354619565217391 edge acc: 0 node acc: 0.6088662147521973\n",
      "23, 50, 0.3266. loss_end: 0.2174, loss_recon_node: 1.0917, loss_recon_edge: 0.0000,acc_node: 0.6385, acc_edge: 0.0000\n",
      "Validation loss: 0.43543330916002687 ROC AUC: 0.9355590062111802 edge acc: 0 node acc: 0.6186739802360535\n",
      "24, 50, 0.3427. loss_end: 0.2327, loss_recon_node: 1.1002, loss_recon_edge: 0.0000,acc_node: 0.5663, acc_edge: 0.0000\n",
      "Validation loss: 0.5761144114475624 ROC AUC: 0.9041149068322981 edge acc: 0 node acc: 0.5959199666976929\n",
      "25, 50, 0.4682. loss_end: 0.3650, loss_recon_node: 1.0325, loss_recon_edge: 0.0000,acc_node: 0.6053, acc_edge: 0.0000\n",
      "Validation loss: 0.6098231614804736 ROC AUC: 0.906444099378882 edge acc: 0 node acc: 0.5927814841270447\n",
      "26, 50, 0.3123. loss_end: 0.2175, loss_recon_node: 0.9485, loss_recon_edge: 0.0000,acc_node: 0.6691, acc_edge: 0.0000\n",
      "Validation loss: 0.6228040468459036 ROC AUC: 0.9019798136645963 edge acc: 0 node acc: 0.565712034702301\n",
      "27, 50, 0.2605. loss_end: 0.1897, loss_recon_node: 0.7073, loss_recon_edge: 0.0000,acc_node: 0.7841, acc_edge: 0.0000\n",
      "Validation loss: 0.5434950525854149 ROC AUC: 0.9233307453416149 edge acc: 0 node acc: 0.6394664645195007\n",
      "28, 50, 0.2936. loss_end: 0.1899, loss_recon_node: 1.0366, loss_recon_edge: 0.0000,acc_node: 0.7004, acc_edge: 0.0000\n",
      "Validation loss: 0.5246568795512704 ROC AUC: 0.9199340062111802 edge acc: 0 node acc: 0.5951353311538696\n",
      "29, 50, 0.1860. loss_end: 0.1117, loss_recon_node: 0.7432, loss_recon_edge: 0.0000,acc_node: 0.8127, acc_edge: 0.0000\n",
      "Validation loss: 0.5603807907478482 ROC AUC: 0.9141110248447204 edge acc: 0 node acc: 0.6120046973228455\n",
      "30, 50, 0.4624. loss_end: 0.3608, loss_recon_node: 1.0161, loss_recon_edge: 0.0000,acc_node: 0.6895, acc_edge: 0.0000\n",
      "Validation loss: 0.583322687476289 ROC AUC: 0.9136257763975155 edge acc: 0 node acc: 0.5692428350448608\n",
      "31, 50, 0.3341. loss_end: 0.2462, loss_recon_node: 0.8786, loss_recon_edge: 0.0000,acc_node: 0.7581, acc_edge: 0.0000\n",
      "Validation loss: 0.9263888200124105 ROC AUC: 0.8481172360248448 edge acc: 0 node acc: 0.6331894993782043\n",
      "32, 50, 0.2570. loss_end: 0.1635, loss_recon_node: 0.9357, loss_recon_edge: 0.0000,acc_node: 0.7131, acc_edge: 0.0000\n",
      "Validation loss: 0.6549738762425441 ROC AUC: 0.9139169254658386 edge acc: 0 node acc: 0.6390741467475891\n",
      "33, 50, 0.4215. loss_end: 0.3305, loss_recon_node: 0.9104, loss_recon_edge: 0.0000,acc_node: 0.7055, acc_edge: 0.0000\n",
      "Validation loss: 0.6216741829526191 ROC AUC: 0.9125582298136645 edge acc: 0 node acc: 0.6053354144096375\n",
      "34, 50, 0.3315. loss_end: 0.2546, loss_recon_node: 0.7697, loss_recon_edge: 0.0000,acc_node: 0.8368, acc_edge: 0.0000\n",
      "Validation loss: 0.4890051250364266 ROC AUC: 0.9373059006211181 edge acc: 0 node acc: 0.6414279937744141\n",
      "35, 50, 0.2440. loss_end: 0.1495, loss_recon_node: 0.9452, loss_recon_edge: 0.0000,acc_node: 0.7148, acc_edge: 0.0000\n",
      "Validation loss: 0.4884268325917861 ROC AUC: 0.93555900621118 edge acc: 0 node acc: 0.6465280652046204\n",
      "36, 50, 0.3183. loss_end: 0.2167, loss_recon_node: 1.0163, loss_recon_edge: 0.0000,acc_node: 0.6800, acc_edge: 0.0000\n",
      "Validation loss: 0.696781664502387 ROC AUC: 0.8885869565217391 edge acc: 0 node acc: 0.601412296295166\n",
      "37, 50, 0.4720. loss_end: 0.3804, loss_recon_node: 0.9168, loss_recon_edge: 0.0000,acc_node: 0.7222, acc_edge: 0.0000\n",
      "Validation loss: 0.49920040369033813 ROC AUC: 0.9106172360248447 edge acc: 0 node acc: 0.6790898442268372\n",
      "38, 50, 0.2584. loss_end: 0.1629, loss_recon_node: 0.9556, loss_recon_edge: 0.0000,acc_node: 0.6957, acc_edge: 0.0000\n",
      "Validation loss: 0.767104865289202 ROC AUC: 0.8907220496894411 edge acc: 0 node acc: 0.5919968485832214\n",
      "39, 50, 0.3226. loss_end: 0.2559, loss_recon_node: 0.6677, loss_recon_edge: 0.0000,acc_node: 0.8027, acc_edge: 0.0000\n",
      "Validation loss: 0.5333119607439228 ROC AUC: 0.9247864906832297 edge acc: 0 node acc: 0.6371126174926758\n",
      "40, 50, 0.3951. loss_end: 0.2822, loss_recon_node: 1.1293, loss_recon_edge: 0.0000,acc_node: 0.5483, acc_edge: 0.0000\n",
      "Validation loss: 0.5773715517100166 ROC AUC: 0.9108113354037267 edge acc: 0 node acc: 0.6563358306884766\n",
      "41, 50, 0.2272. loss_end: 0.1363, loss_recon_node: 0.9087, loss_recon_edge: 0.0000,acc_node: 0.6923, acc_edge: 0.0000\n",
      "Validation loss: 0.5844002897832908 ROC AUC: 0.9257569875776398 edge acc: 0 node acc: 0.6061200499534607\n",
      "42, 50, 0.3909. loss_end: 0.3005, loss_recon_node: 0.9041, loss_recon_edge: 0.0000,acc_node: 0.7065, acc_edge: 0.0000\n",
      "Validation loss: 0.5864166740108939 ROC AUC: 0.921001552795031 edge acc: 0 node acc: 0.5649273991584778\n",
      "43, 50, 0.2328. loss_end: 0.1207, loss_recon_node: 1.1212, loss_recon_edge: 0.0000,acc_node: 0.5945, acc_edge: 0.0000\n",
      "Validation loss: 0.5207061288403529 ROC AUC: 0.9143051242236023 edge acc: 0 node acc: 0.6351510286331177\n",
      "44, 50, 0.5477. loss_end: 0.4673, loss_recon_node: 0.8043, loss_recon_edge: 0.0000,acc_node: 0.7618, acc_edge: 0.0000\n",
      "Validation loss: 0.48358294776841704 ROC AUC: 0.9387616459627329 edge acc: 0 node acc: 0.6394664645195007\n",
      "45, 50, 0.3651. loss_end: 0.2768, loss_recon_node: 0.8830, loss_recon_edge: 0.0000,acc_node: 0.7576, acc_edge: 0.0000\n",
      "Validation loss: 0.5867213840578117 ROC AUC: 0.9001358695652174 edge acc: 0 node acc: 0.62142014503479\n",
      "46, 50, 0.5312. loss_end: 0.4402, loss_recon_node: 0.9105, loss_recon_edge: 0.0000,acc_node: 0.7564, acc_edge: 0.0000\n",
      "Validation loss: 0.4790079850776523 ROC AUC: 0.9390527950310559 edge acc: 0 node acc: 0.608081579208374\n",
      "47, 50, 0.2349. loss_end: 0.1257, loss_recon_node: 1.0925, loss_recon_edge: 0.0000,acc_node: 0.6391, acc_edge: 0.0000\n",
      "Validation loss: 0.5223567287127177 ROC AUC: 0.9255628881987578 edge acc: 0 node acc: 0.6422126293182373\n",
      "48, 50, 0.2066. loss_end: 0.1039, loss_recon_node: 1.0278, loss_recon_edge: 0.0000,acc_node: 0.6100, acc_edge: 0.0000\n",
      "Validation loss: 0.5501385249343573 ROC AUC: 0.9193517080745341 edge acc: 0 node acc: 0.65358966588974\n",
      "49, 50, 0.2847. loss_end: 0.1843, loss_recon_node: 1.0038, loss_recon_edge: 0.0000,acc_node: 0.6519, acc_edge: 0.0000\n",
      "Validation loss: 0.5572179339680017 ROC AUC: 0.9241071428571429 edge acc: 0 node acc: 0.662612795829773\n",
      "50, 50, 0.1808. loss_end: 0.1071, loss_recon_node: 0.7367, loss_recon_edge: 0.0000,acc_node: 0.7857, acc_edge: 0.0000\n",
      "Validation loss: 0.5021655162175497 ROC AUC: 0.9321622670807453 edge acc: 0 node acc: 0.6210278272628784\n",
      "51, 50, 0.2511. loss_end: 0.1523, loss_recon_node: 0.9883, loss_recon_edge: 0.0000,acc_node: 0.6237, acc_edge: 0.0000\n",
      "Validation loss: 0.570815760715335 ROC AUC: 0.9091614906832299 edge acc: 0 node acc: 0.626912534236908\n",
      "52, 50, 0.2554. loss_end: 0.1412, loss_recon_node: 1.1423, loss_recon_edge: 0.0000,acc_node: 0.5125, acc_edge: 0.0000\n",
      "Validation loss: 0.4577048946829403 ROC AUC: 0.9383734472049688 edge acc: 0 node acc: 0.6492742300033569\n",
      "53, 50, 0.3170. loss_end: 0.2292, loss_recon_node: 0.8774, loss_recon_edge: 0.0000,acc_node: 0.6869, acc_edge: 0.0000\n",
      "Validation loss: 0.4775390026031756 ROC AUC: 0.921777950310559 edge acc: 0 node acc: 0.6739897727966309\n",
      "54, 50, 0.5022. loss_end: 0.4290, loss_recon_node: 0.7319, loss_recon_edge: 0.0000,acc_node: 0.7798, acc_edge: 0.0000\n",
      "Validation loss: 0.6065728345922395 ROC AUC: 0.9191576086956522 edge acc: 0 node acc: 0.6582973599433899\n",
      "55, 50, 0.2983. loss_end: 0.1934, loss_recon_node: 1.0490, loss_recon_edge: 0.0000,acc_node: 0.6021, acc_edge: 0.0000\n",
      "Validation loss: 0.5957157015800476 ROC AUC: 0.9319681677018634 edge acc: 0 node acc: 0.6159278154373169\n",
      "56, 50, 0.2495. loss_end: 0.1563, loss_recon_node: 0.9321, loss_recon_edge: 0.0000,acc_node: 0.6692, acc_edge: 0.0000\n",
      "Validation loss: 0.6563133398691813 ROC AUC: 0.9160520186335404 edge acc: 0 node acc: 0.634758710861206\n",
      "57, 50, 0.2949. loss_end: 0.2057, loss_recon_node: 0.8919, loss_recon_edge: 0.0000,acc_node: 0.6726, acc_edge: 0.0000\n",
      "Validation loss: 0.6308981299984688 ROC AUC: 0.9288625776397516 edge acc: 0 node acc: 0.5802275538444519\n",
      "58, 50, 0.1490. loss_end: 0.0653, loss_recon_node: 0.8372, loss_recon_edge: 0.0000,acc_node: 0.6800, acc_edge: 0.0000\n",
      "Validation loss: 0.6897283184762094 ROC AUC: 0.9200310559006211 edge acc: 0 node acc: 0.6414279937744141\n",
      "59, 50, 0.3675. loss_end: 0.2580, loss_recon_node: 1.0943, loss_recon_edge: 0.0000,acc_node: 0.5980, acc_edge: 0.0000\n",
      "Validation loss: 0.547771205796915 ROC AUC: 0.9322593167701863 edge acc: 0 node acc: 0.6202432513237\n",
      "60, 50, 0.4265. loss_end: 0.3564, loss_recon_node: 0.7006, loss_recon_edge: 0.0000,acc_node: 0.7950, acc_edge: 0.0000\n",
      "Validation loss: 0.6077941147720113 ROC AUC: 0.9150815217391304 edge acc: 0 node acc: 0.6210278272628784\n",
      "61, 50, 0.2266. loss_end: 0.1395, loss_recon_node: 0.8709, loss_recon_edge: 0.0000,acc_node: 0.7553, acc_edge: 0.0000\n",
      "Validation loss: 0.522267173318302 ROC AUC: 0.9297360248447204 edge acc: 0 node acc: 0.6484895944595337\n",
      "62, 50, 0.2396. loss_end: 0.1521, loss_recon_node: 0.8752, loss_recon_edge: 0.0000,acc_node: 0.7535, acc_edge: 0.0000\n",
      "Validation loss: 0.5063883773252076 ROC AUC: 0.9380822981366459 edge acc: 0 node acc: 0.6194586157798767\n",
      "63, 50, 0.4102. loss_end: 0.3088, loss_recon_node: 1.0136, loss_recon_edge: 0.0000,acc_node: 0.6854, acc_edge: 0.0000\n",
      "Validation loss: 0.5494406690784529 ROC AUC: 0.9249805900621116 edge acc: 0 node acc: 0.6312279105186462\n",
      "64, 50, 0.3475. loss_end: 0.2564, loss_recon_node: 0.9109, loss_recon_edge: 0.0000,acc_node: 0.7119, acc_edge: 0.0000\n",
      "Validation loss: 0.6539247503467635 ROC AUC: 0.8954774844720497 edge acc: 0 node acc: 0.6167124509811401\n",
      "65, 50, 0.3806. loss_end: 0.2977, loss_recon_node: 0.8293, loss_recon_edge: 0.0000,acc_node: 0.7508, acc_edge: 0.0000\n",
      "Validation loss: 0.6032992426086875 ROC AUC: 0.9290566770186336 edge acc: 0 node acc: 0.6551588773727417\n",
      "66, 50, 0.2165. loss_end: 0.1225, loss_recon_node: 0.9396, loss_recon_edge: 0.0000,acc_node: 0.7295, acc_edge: 0.0000\n",
      "Validation loss: 0.6684600962143318 ROC AUC: 0.9093555900621118 edge acc: 0 node acc: 0.5994507670402527\n",
      "67, 50, 0.3365. loss_end: 0.1999, loss_recon_node: 1.3654, loss_recon_edge: 0.0000,acc_node: 0.5121, acc_edge: 0.0000\n",
      "Validation loss: 0.7515415111008812 ROC AUC: 0.90625 edge acc: 0 node acc: 0.6182816624641418\n",
      "68, 50, 0.3622. loss_end: 0.2631, loss_recon_node: 0.9907, loss_recon_edge: 0.0000,acc_node: 0.7491, acc_edge: 0.0000\n",
      "Validation loss: 0.5394594207698223 ROC AUC: 0.9338121118012421 edge acc: 0 node acc: 0.6363279819488525\n",
      "69, 50, 0.1499. loss_end: 0.0631, loss_recon_node: 0.8684, loss_recon_edge: 0.0000,acc_node: 0.7466, acc_edge: 0.0000\n",
      "Validation loss: 0.693296843884038 ROC AUC: 0.9242041925465838 edge acc: 0 node acc: 0.6202432513237\n",
      "70, 50, 0.2641. loss_end: 0.1812, loss_recon_node: 0.8288, loss_recon_edge: 0.0000,acc_node: 0.7617, acc_edge: 0.0000\n",
      "Validation loss: 0.4942276010326311 ROC AUC: 0.935753105590062 edge acc: 0 node acc: 0.6783052086830139\n",
      "71, 50, 0.4230. loss_end: 0.3363, loss_recon_node: 0.8676, loss_recon_edge: 0.0000,acc_node: 0.7288, acc_edge: 0.0000\n",
      "Validation loss: 0.7373733590630924 ROC AUC: 0.8981948757763975 edge acc: 0 node acc: 0.640251100063324\n",
      "72, 50, 0.3123. loss_end: 0.2267, loss_recon_node: 0.8565, loss_recon_edge: 0.0000,acc_node: 0.7057, acc_edge: 0.0000\n",
      "Validation loss: 0.4636356479981366 ROC AUC: 0.9428377329192547 edge acc: 0 node acc: 0.6739897727966309\n",
      "73, 50, 0.1837. loss_end: 0.0864, loss_recon_node: 0.9737, loss_recon_edge: 0.0000,acc_node: 0.5825, acc_edge: 0.0000\n",
      "Validation loss: 0.6308414562075746 ROC AUC: 0.9170225155279503 edge acc: 0 node acc: 0.6441741585731506\n",
      "74, 50, 0.2358. loss_end: 0.1449, loss_recon_node: 0.9091, loss_recon_edge: 0.0000,acc_node: 0.7004, acc_edge: 0.0000\n",
      "Validation loss: 0.7609839042027792 ROC AUC: 0.9140139751552796 edge acc: 0 node acc: 0.6096508502960205\n",
      "75, 50, 0.2002. loss_end: 0.1132, loss_recon_node: 0.8698, loss_recon_edge: 0.0000,acc_node: 0.6848, acc_edge: 0.0000\n",
      "Validation loss: 0.5827517544522005 ROC AUC: 0.9328416149068324 edge acc: 0 node acc: 0.5912122130393982\n",
      "76, 50, 0.3207. loss_end: 0.2322, loss_recon_node: 0.8855, loss_recon_edge: 0.0000,acc_node: 0.7552, acc_edge: 0.0000\n",
      "Validation loss: 0.6376764745104546 ROC AUC: 0.9050854037267081 edge acc: 0 node acc: 0.5994507670402527\n",
      "77, 50, 0.1155. loss_end: 0.0287, loss_recon_node: 0.8682, loss_recon_edge: 0.0000,acc_node: 0.7377, acc_edge: 0.0000\n",
      "Validation loss: 0.6399613817532858 ROC AUC: 0.9171195652173914 edge acc: 0 node acc: 0.6375048756599426\n",
      "78, 50, 0.2005. loss_end: 0.1071, loss_recon_node: 0.9334, loss_recon_edge: 0.0000,acc_node: 0.7253, acc_edge: 0.0000\n",
      "Validation loss: 0.588525790794223 ROC AUC: 0.9233307453416149 edge acc: 0 node acc: 0.6284817457199097\n",
      "79, 50, 0.3097. loss_end: 0.2186, loss_recon_node: 0.9108, loss_recon_edge: 0.0000,acc_node: 0.7059, acc_edge: 0.0000\n",
      "Validation loss: 0.6276788594675999 ROC AUC: 0.9164402173913044 edge acc: 0 node acc: 0.6563358306884766\n",
      "80, 50, 0.6528. loss_end: 0.5581, loss_recon_node: 0.9472, loss_recon_edge: 0.0000,acc_node: 0.6970, acc_edge: 0.0000\n",
      "Validation loss: 0.6486910388750189 ROC AUC: 0.9119759316770185 edge acc: 0 node acc: 0.6563358306884766\n",
      "81, 50, 0.2956. loss_end: 0.1949, loss_recon_node: 1.0069, loss_recon_edge: 0.0000,acc_node: 0.6073, acc_edge: 0.0000\n",
      "Validation loss: 0.6665412094078812 ROC AUC: 0.9006211180124223 edge acc: 0 node acc: 0.6127893328666687\n",
      "82, 50, 0.1550. loss_end: 0.0633, loss_recon_node: 0.9167, loss_recon_edge: 0.0000,acc_node: 0.6795, acc_edge: 0.0000\n",
      "Validation loss: 0.5631202491475087 ROC AUC: 0.9106172360248448 edge acc: 0 node acc: 0.6359356641769409\n",
      "83, 50, 0.5012. loss_end: 0.3903, loss_recon_node: 1.1090, loss_recon_edge: 0.0000,acc_node: 0.6409, acc_edge: 0.0000\n",
      "Validation loss: 0.6972800516614727 ROC AUC: 0.9126552795031055 edge acc: 0 node acc: 0.662612795829773\n",
      "84, 50, 0.1467. loss_end: 0.0571, loss_recon_node: 0.8956, loss_recon_edge: 0.0000,acc_node: 0.7692, acc_edge: 0.0000\n",
      "Validation loss: 0.7742394980262307 ROC AUC: 0.9034355590062111 edge acc: 0 node acc: 0.6108278036117554\n",
      "85, 50, 0.2355. loss_end: 0.1438, loss_recon_node: 0.9172, loss_recon_edge: 0.0000,acc_node: 0.6748, acc_edge: 0.0000\n",
      "Validation loss: 0.6574229013686087 ROC AUC: 0.9242041925465838 edge acc: 0 node acc: 0.6276971101760864\n",
      "86, 50, 0.4692. loss_end: 0.3742, loss_recon_node: 0.9497, loss_recon_edge: 0.0000,acc_node: 0.7000, acc_edge: 0.0000\n",
      "Validation loss: 0.5240987930812088 ROC AUC: 0.9348796583850931 edge acc: 0 node acc: 0.6229894161224365\n",
      "87, 50, 0.2338. loss_end: 0.1478, loss_recon_node: 0.8603, loss_recon_edge: 0.0000,acc_node: 0.7326, acc_edge: 0.0000\n",
      "Validation loss: 0.7350164488250134 ROC AUC: 0.9098408385093169 edge acc: 0 node acc: 0.6029815673828125\n",
      "88, 50, 0.1336. loss_end: 0.0462, loss_recon_node: 0.8733, loss_recon_edge: 0.0000,acc_node: 0.6917, acc_edge: 0.0000\n",
      "Validation loss: 0.6699834349108678 ROC AUC: 0.9113936335403727 edge acc: 0 node acc: 0.6265202164649963\n",
      "89, 50, 0.2372. loss_end: 0.1404, loss_recon_node: 0.9679, loss_recon_edge: 0.0000,acc_node: 0.6786, acc_edge: 0.0000\n",
      "Validation loss: 0.643589212029588 ROC AUC: 0.9096467391304347 edge acc: 0 node acc: 0.6673204898834229\n",
      "90, 50, 0.2675. loss_end: 0.1551, loss_recon_node: 1.1247, loss_recon_edge: 0.0000,acc_node: 0.6376, acc_edge: 0.0000\n",
      "Validation loss: 0.6166974411291235 ROC AUC: 0.9318711180124224 edge acc: 0 node acc: 0.6551588773727417\n",
      "91, 50, 0.1839. loss_end: 0.1002, loss_recon_node: 0.8368, loss_recon_edge: 0.0000,acc_node: 0.7447, acc_edge: 0.0000\n",
      "Validation loss: 0.730679383464888 ROC AUC: 0.9034355590062112 edge acc: 0 node acc: 0.633581817150116\n",
      "92, 50, 0.1925. loss_end: 0.0844, loss_recon_node: 1.0813, loss_recon_edge: 0.0000,acc_node: 0.5728, acc_edge: 0.0000\n",
      "Validation loss: 0.7016437170552272 ROC AUC: 0.9084821428571428 edge acc: 0 node acc: 0.6139662861824036\n",
      "93, 50, 0.1650. loss_end: 0.0778, loss_recon_node: 0.8726, loss_recon_edge: 0.0000,acc_node: 0.7292, acc_edge: 0.0000\n",
      "Validation loss: 0.7068293643932716 ROC AUC: 0.9086762422360247 edge acc: 0 node acc: 0.5712043642997742\n",
      "94, 50, 0.1669. loss_end: 0.0751, loss_recon_node: 0.9183, loss_recon_edge: 0.0000,acc_node: 0.7324, acc_edge: 0.0000\n",
      "Validation loss: 0.6349655804680843 ROC AUC: 0.9205163043478262 edge acc: 0 node acc: 0.594743013381958\n",
      "95, 50, 0.1346. loss_end: 0.0332, loss_recon_node: 1.0139, loss_recon_edge: 0.0000,acc_node: 0.6793, acc_edge: 0.0000\n",
      "Validation loss: 0.7509495136784572 ROC AUC: 0.9139169254658386 edge acc: 0 node acc: 0.6182816624641418\n",
      "96, 50, 0.2158. loss_end: 0.1193, loss_recon_node: 0.9650, loss_recon_edge: 0.0000,acc_node: 0.6462, acc_edge: 0.0000\n",
      "Validation loss: 0.6806046004388847 ROC AUC: 0.9175077639751552 edge acc: 0 node acc: 0.6394664645195007\n",
      "97, 50, 0.2229. loss_end: 0.1366, loss_recon_node: 0.8627, loss_recon_edge: 0.0000,acc_node: 0.6930, acc_edge: 0.0000\n",
      "Validation loss: 0.6508869587206373 ROC AUC: 0.9061529503105589 edge acc: 0 node acc: 0.6834052801132202\n",
      "98, 50, 0.3319. loss_end: 0.2351, loss_recon_node: 0.9674, loss_recon_edge: 0.0000,acc_node: 0.6859, acc_edge: 0.0000\n",
      "Validation loss: 0.9152166621357787 ROC AUC: 0.8990683229813664 edge acc: 0 node acc: 0.6331894993782043\n",
      "99, 50, 0.1791. loss_end: 0.0984, loss_recon_node: 0.8068, loss_recon_edge: 0.0000,acc_node: 0.6743, acc_edge: 0.0000\n",
      "Validation loss: 0.6428490929743823 ROC AUC: 0.92090450310559 edge acc: 0 node acc: 0.6437819004058838\n",
      "100, 50, 0.2852. loss_end: 0.1960, loss_recon_node: 0.8918, loss_recon_edge: 0.0000,acc_node: 0.7336, acc_edge: 0.0000\n",
      "Validation loss: 0.8830337524414062 ROC AUC: 0.9088703416149069 edge acc: 0 node acc: 0.5617889165878296\n",
      "101, 50, 0.2737. loss_end: 0.1819, loss_recon_node: 0.9181, loss_recon_edge: 0.0000,acc_node: 0.7172, acc_edge: 0.0000\n",
      "Validation loss: 0.7260038642322316 ROC AUC: 0.907123447204969 edge acc: 0 node acc: 0.5845429301261902\n",
      "102, 50, 0.1686. loss_end: 0.0877, loss_recon_node: 0.8084, loss_recon_edge: 0.0000,acc_node: 0.7293, acc_edge: 0.0000\n",
      "Validation loss: 0.5942970596107782 ROC AUC: 0.9267274844720497 edge acc: 0 node acc: 0.6171047687530518\n",
      "103, 50, 0.3254. loss_end: 0.2375, loss_recon_node: 0.8783, loss_recon_edge: 0.0000,acc_node: 0.7365, acc_edge: 0.0000\n",
      "Validation loss: 0.8733486451354682 ROC AUC: 0.8882958074534161 edge acc: 0 node acc: 0.6155354976654053\n",
      "104, 50, 0.1609. loss_end: 0.0685, loss_recon_node: 0.9236, loss_recon_edge: 0.0000,acc_node: 0.7432, acc_edge: 0.0000\n",
      "Validation loss: 0.6939075168441323 ROC AUC: 0.9161490683229813 edge acc: 0 node acc: 0.633581817150116\n",
      "105, 50, 0.1564. loss_end: 0.0662, loss_recon_node: 0.9027, loss_recon_edge: 0.0000,acc_node: 0.7617, acc_edge: 0.0000\n",
      "Validation loss: 0.7419344443900913 ROC AUC: 0.9177018633540373 edge acc: 0 node acc: 0.6524127125740051\n",
      "106, 50, 0.2110. loss_end: 0.1125, loss_recon_node: 0.9849, loss_recon_edge: 0.0000,acc_node: 0.6519, acc_edge: 0.0000\n",
      "Validation loss: 0.747606401349984 ROC AUC: 0.9023680124223602 edge acc: 0 node acc: 0.6167124509811401\n",
      "107, 50, 0.1183. loss_end: 0.0242, loss_recon_node: 0.9408, loss_recon_edge: 0.0000,acc_node: 0.6900, acc_edge: 0.0000\n",
      "Validation loss: 0.611433288045958 ROC AUC: 0.922554347826087 edge acc: 0 node acc: 0.5841506719589233\n",
      "108, 50, 0.1749. loss_end: 0.0887, loss_recon_node: 0.8619, loss_recon_edge: 0.0000,acc_node: 0.7266, acc_edge: 0.0000\n",
      "Validation loss: 0.8191525573823967 ROC AUC: 0.8956715838509317 edge acc: 0 node acc: 0.6076892614364624\n",
      "109, 50, 0.1356. loss_end: 0.0402, loss_recon_node: 0.9542, loss_recon_edge: 0.0000,acc_node: 0.6294, acc_edge: 0.0000\n",
      "Validation loss: 0.6622219225939583 ROC AUC: 0.9254658385093169 edge acc: 0 node acc: 0.6684974431991577\n",
      "110, 50, 0.2742. loss_end: 0.1699, loss_recon_node: 1.0427, loss_recon_edge: 0.0000,acc_node: 0.6043, acc_edge: 0.0000\n",
      "Validation loss: 0.7610092373455272 ROC AUC: 0.9152756211180123 edge acc: 0 node acc: 0.6010199785232544\n",
      "111, 50, 0.1570. loss_end: 0.0750, loss_recon_node: 0.8199, loss_recon_edge: 0.0000,acc_node: 0.7607, acc_edge: 0.0000\n",
      "Validation loss: 0.6664082746879727 ROC AUC: 0.9299301242236024 edge acc: 0 node acc: 0.6688897609710693\n",
      "112, 50, 0.2214. loss_end: 0.1444, loss_recon_node: 0.7694, loss_recon_edge: 0.0000,acc_node: 0.7819, acc_edge: 0.0000\n",
      "Validation loss: 0.7777473248687445 ROC AUC: 0.9126552795031055 edge acc: 0 node acc: 0.6504511833190918\n",
      "113, 50, 0.2526. loss_end: 0.1569, loss_recon_node: 0.9574, loss_recon_edge: 0.0000,acc_node: 0.6858, acc_edge: 0.0000\n",
      "Validation loss: 0.9946840329497468 ROC AUC: 0.8935364906832298 edge acc: 0 node acc: 0.6343663930892944\n",
      "114, 50, 0.1881. loss_end: 0.1096, loss_recon_node: 0.7845, loss_recon_edge: 0.0000,acc_node: 0.7519, acc_edge: 0.0000\n",
      "Validation loss: 0.7534687273642596 ROC AUC: 0.9008152173913044 edge acc: 0 node acc: 0.6492742300033569\n",
      "115, 50, 0.3003. loss_end: 0.1934, loss_recon_node: 1.0688, loss_recon_edge: 0.0000,acc_node: 0.6691, acc_edge: 0.0000\n",
      "Validation loss: 0.7352855602900187 ROC AUC: 0.9044060559006211 edge acc: 0 node acc: 0.6359356641769409\n",
      "116, 50, 0.2337. loss_end: 0.1493, loss_recon_node: 0.8441, loss_recon_edge: 0.0000,acc_node: 0.6859, acc_edge: 0.0000\n",
      "Validation loss: 0.8086421548151502 ROC AUC: 0.9042119565217391 edge acc: 0 node acc: 0.6543742418289185\n",
      "117, 50, 0.3356. loss_end: 0.2602, loss_recon_node: 0.7539, loss_recon_edge: 0.0000,acc_node: 0.7909, acc_edge: 0.0000\n",
      "Validation loss: 0.7451171547758813 ROC AUC: 0.8979037267080745 edge acc: 0 node acc: 0.6206355690956116\n",
      "118, 50, 0.2024. loss_end: 0.1157, loss_recon_node: 0.8662, loss_recon_edge: 0.0000,acc_node: 0.7435, acc_edge: 0.0000\n",
      "Validation loss: 0.6954907342499378 ROC AUC: 0.9191576086956522 edge acc: 0 node acc: 0.6288740634918213\n",
      "119, 50, 0.2435. loss_end: 0.1390, loss_recon_node: 1.0449, loss_recon_edge: 0.0000,acc_node: 0.5936, acc_edge: 0.0000\n",
      "Validation loss: 0.6671218801947201 ROC AUC: 0.9176048136645962 edge acc: 0 node acc: 0.6653589606285095\n",
      "120, 50, 0.2141. loss_end: 0.0966, loss_recon_node: 1.1746, loss_recon_edge: 0.0000,acc_node: 0.5312, acc_edge: 0.0000\n",
      "Validation loss: 0.6791508758769316 ROC AUC: 0.9177989130434784 edge acc: 0 node acc: 0.5951353311538696\n",
      "121, 50, 0.1208. loss_end: 0.0286, loss_recon_node: 0.9219, loss_recon_edge: 0.0000,acc_node: 0.7535, acc_edge: 0.0000\n",
      "Validation loss: 0.7158602300812217 ROC AUC: 0.9177989130434784 edge acc: 0 node acc: 0.673597514629364\n",
      "122, 50, 0.2049. loss_end: 0.1048, loss_recon_node: 1.0017, loss_recon_edge: 0.0000,acc_node: 0.6777, acc_edge: 0.0000\n",
      "Validation loss: 0.9949469168980917 ROC AUC: 0.8815023291925466 edge acc: 0 node acc: 0.6069046854972839\n",
      "123, 50, 0.2728. loss_end: 0.1731, loss_recon_node: 0.9972, loss_recon_edge: 0.0000,acc_node: 0.6989, acc_edge: 0.0000\n",
      "Validation loss: 0.7667458478142234 ROC AUC: 0.8974184782608696 edge acc: 0 node acc: 0.6547665596008301\n",
      "124, 50, 0.2542. loss_end: 0.1232, loss_recon_node: 1.3105, loss_recon_edge: 0.0000,acc_node: 0.5021, acc_edge: 0.0000\n",
      "Validation loss: 0.7606784350731793 ROC AUC: 0.904600155279503 edge acc: 0 node acc: 0.6743820905685425\n",
      "125, 50, 0.2333. loss_end: 0.1561, loss_recon_node: 0.7721, loss_recon_edge: 0.0000,acc_node: 0.7770, acc_edge: 0.0000\n",
      "Validation loss: 0.6200990045771879 ROC AUC: 0.9280861801242235 edge acc: 0 node acc: 0.660258948802948\n",
      "126, 50, 0.3169. loss_end: 0.2311, loss_recon_node: 0.8578, loss_recon_edge: 0.0000,acc_node: 0.7711, acc_edge: 0.0000\n",
      "Validation loss: 0.7928930556072908 ROC AUC: 0.9120729813664596 edge acc: 0 node acc: 0.6653589606285095\n",
      "127, 50, 0.1579. loss_end: 0.0661, loss_recon_node: 0.9177, loss_recon_edge: 0.0000,acc_node: 0.6667, acc_edge: 0.0000\n",
      "Validation loss: 0.6904517739426856 ROC AUC: 0.9116847826086957 edge acc: 0 node acc: 0.6363279819488525\n",
      "128, 50, 0.1745. loss_end: 0.0857, loss_recon_node: 0.8877, loss_recon_edge: 0.0000,acc_node: 0.7085, acc_edge: 0.0000\n",
      "Validation loss: 1.0052295946607404 ROC AUC: 0.8806288819875776 edge acc: 0 node acc: 0.5908199548721313\n",
      "129, 50, 0.1442. loss_end: 0.0722, loss_recon_node: 0.7195, loss_recon_edge: 0.0000,acc_node: 0.8007, acc_edge: 0.0000\n",
      "Validation loss: 0.7891998372825921 ROC AUC: 0.9054736024844721 edge acc: 0 node acc: 0.568065881729126\n",
      "130, 50, 0.5639. loss_end: 0.4776, loss_recon_node: 0.8626, loss_recon_edge: 0.0000,acc_node: 0.7528, acc_edge: 0.0000\n",
      "Validation loss: 0.761964259778752 ROC AUC: 0.9152756211180125 edge acc: 0 node acc: 0.6461357474327087\n",
      "131, 50, 0.1863. loss_end: 0.1022, loss_recon_node: 0.8410, loss_recon_edge: 0.0000,acc_node: 0.7509, acc_edge: 0.0000\n",
      "Validation loss: 0.9101803372888004 ROC AUC: 0.8935364906832298 edge acc: 0 node acc: 0.6167124509811401\n",
      "132, 50, 0.1500. loss_end: 0.0581, loss_recon_node: 0.9193, loss_recon_edge: 0.0000,acc_node: 0.7297, acc_edge: 0.0000\n",
      "Validation loss: 0.7711516548605526 ROC AUC: 0.9159549689440993 edge acc: 0 node acc: 0.6406434178352356\n",
      "133, 50, 0.1763. loss_end: 0.0724, loss_recon_node: 1.0395, loss_recon_edge: 0.0000,acc_node: 0.6138, acc_edge: 0.0000\n",
      "Validation loss: 0.9198282156504837 ROC AUC: 0.9025621118012424 edge acc: 0 node acc: 0.5562965869903564\n",
      "134, 50, 0.1143. loss_end: 0.0264, loss_recon_node: 0.8793, loss_recon_edge: 0.0000,acc_node: 0.7627, acc_edge: 0.0000\n",
      "Validation loss: 0.7228241498563804 ROC AUC: 0.9177018633540374 edge acc: 0 node acc: 0.6108278036117554\n",
      "135, 50, 0.1981. loss_end: 0.0990, loss_recon_node: 0.9910, loss_recon_edge: 0.0000,acc_node: 0.7199, acc_edge: 0.0000\n",
      "Validation loss: 0.72480460358601 ROC AUC: 0.9151785714285714 edge acc: 0 node acc: 0.6579050421714783\n",
      "136, 50, 0.3046. loss_end: 0.1671, loss_recon_node: 1.3753, loss_recon_edge: 0.0000,acc_node: 0.4414, acc_edge: 0.0000\n",
      "Validation loss: 0.92049586539175 ROC AUC: 0.9138198757763976 edge acc: 0 node acc: 0.5939584374427795\n",
      "137, 50, 0.1448. loss_end: 0.0301, loss_recon_node: 1.1468, loss_recon_edge: 0.0000,acc_node: 0.5804, acc_edge: 0.0000\n",
      "Validation loss: 0.8009829778297275 ROC AUC: 0.90722049689441 edge acc: 0 node acc: 0.6210278272628784\n",
      "138, 50, 0.1394. loss_end: 0.0687, loss_recon_node: 0.7065, loss_recon_edge: 0.0000,acc_node: 0.8084, acc_edge: 0.0000\n",
      "Validation loss: 0.7185534811487385 ROC AUC: 0.9056677018633541 edge acc: 0 node acc: 0.6265202164649963\n",
      "139, 50, 0.1017. loss_end: 0.0230, loss_recon_node: 0.7868, loss_recon_edge: 0.0000,acc_node: 0.7774, acc_edge: 0.0000\n",
      "Validation loss: 0.655145759676017 ROC AUC: 0.936723602484472 edge acc: 0 node acc: 0.6700667142868042\n",
      "140, 50, 0.4069. loss_end: 0.2833, loss_recon_node: 1.2361, loss_recon_edge: 0.0000,acc_node: 0.6343, acc_edge: 0.0000\n",
      "Validation loss: 0.7137209597755881 ROC AUC: 0.9249805900621119 edge acc: 0 node acc: 0.6167124509811401\n",
      "141, 50, 0.2338. loss_end: 0.1370, loss_recon_node: 0.9678, loss_recon_edge: 0.0000,acc_node: 0.7203, acc_edge: 0.0000\n",
      "Validation loss: 0.6739994567983291 ROC AUC: 0.9405085403726708 edge acc: 0 node acc: 0.6139662861824036\n",
      "142, 50, 0.1095. loss_end: 0.0223, loss_recon_node: 0.8721, loss_recon_edge: 0.0000,acc_node: 0.6700, acc_edge: 0.0000\n",
      "Validation loss: 0.6789375730589324 ROC AUC: 0.9284743788819876 edge acc: 0 node acc: 0.6092585325241089\n",
      "143, 50, 0.1319. loss_end: 0.0244, loss_recon_node: 1.0754, loss_recon_edge: 0.0000,acc_node: 0.5219, acc_edge: 0.0000\n",
      "Validation loss: 0.653293717141245 ROC AUC: 0.9169254658385093 edge acc: 0 node acc: 0.6422126293182373\n",
      "144, 50, 0.1809. loss_end: 0.0996, loss_recon_node: 0.8135, loss_recon_edge: 0.0000,acc_node: 0.7129, acc_edge: 0.0000\n",
      "Validation loss: 0.7736973108029833 ROC AUC: 0.9225543478260869 edge acc: 0 node acc: 0.6783052086830139\n",
      "145, 50, 0.2305. loss_end: 0.1511, loss_recon_node: 0.7940, loss_recon_edge: 0.0000,acc_node: 0.7593, acc_edge: 0.0000\n",
      "Validation loss: 0.9531927599626429 ROC AUC: 0.9020768633540371 edge acc: 0 node acc: 0.6273048520088196\n",
      "146, 50, 0.1390. loss_end: 0.0335, loss_recon_node: 1.0554, loss_recon_edge: 0.0000,acc_node: 0.5985, acc_edge: 0.0000\n",
      "Validation loss: 0.8882130174075856 ROC AUC: 0.9093555900621119 edge acc: 0 node acc: 0.6025892496109009\n",
      "147, 50, 0.1227. loss_end: 0.0303, loss_recon_node: 0.9236, loss_recon_edge: 0.0000,acc_node: 0.6714, acc_edge: 0.0000\n",
      "Validation loss: 0.8238763435214174 ROC AUC: 0.9023680124223603 edge acc: 0 node acc: 0.6630051136016846\n",
      "148, 50, 0.1097. loss_end: 0.0243, loss_recon_node: 0.8538, loss_recon_edge: 0.0000,acc_node: 0.7700, acc_edge: 0.0000\n",
      "Validation loss: 0.8285723176656985 ROC AUC: 0.9247864906832298 edge acc: 0 node acc: 0.5684581995010376\n",
      "149, 50, 0.1528. loss_end: 0.0322, loss_recon_node: 1.2062, loss_recon_edge: 0.0000,acc_node: 0.5321, acc_edge: 0.0000\n",
      "Validation loss: 0.5700017064809799 ROC AUC: 0.9285714285714285 edge acc: 0 node acc: 0.6700667142868042\n",
      "150, 50, 0.1249. loss_end: 0.0454, loss_recon_node: 0.7948, loss_recon_edge: 0.0000,acc_node: 0.7402, acc_edge: 0.0000\n",
      "Validation loss: 0.7557270655445024 ROC AUC: 0.9135287267080745 edge acc: 0 node acc: 0.6237740516662598\n",
      "151, 50, 0.2362. loss_end: 0.1442, loss_recon_node: 0.9199, loss_recon_edge: 0.0000,acc_node: 0.7517, acc_edge: 0.0000\n",
      "Validation loss: 0.8077340301345376 ROC AUC: 0.9113936335403726 edge acc: 0 node acc: 0.6630051136016846\n",
      "152, 50, 0.1974. loss_end: 0.1062, loss_recon_node: 0.9116, loss_recon_edge: 0.0000,acc_node: 0.7305, acc_edge: 0.0000\n",
      "Validation loss: 0.7105660345040116 ROC AUC: 0.9120729813664596 edge acc: 0 node acc: 0.5868968367576599\n",
      "153, 50, 0.1030. loss_end: 0.0231, loss_recon_node: 0.7985, loss_recon_edge: 0.0000,acc_node: 0.7701, acc_edge: 0.0000\n",
      "Validation loss: 0.754339199440152 ROC AUC: 0.9323563664596273 edge acc: 0 node acc: 0.6586896777153015\n",
      "154, 50, 0.1367. loss_end: 0.0441, loss_recon_node: 0.9253, loss_recon_edge: 0.0000,acc_node: 0.7279, acc_edge: 0.0000\n",
      "Validation loss: 0.7872672934158176 ROC AUC: 0.9236218944099379 edge acc: 0 node acc: 0.6100431680679321\n",
      "155, 50, 0.1198. loss_end: 0.0250, loss_recon_node: 0.9474, loss_recon_edge: 0.0000,acc_node: 0.7088, acc_edge: 0.0000\n",
      "Validation loss: 0.7180806819130393 ROC AUC: 0.9232336956521738 edge acc: 0 node acc: 0.6343663930892944\n",
      "156, 50, 0.1691. loss_end: 0.0845, loss_recon_node: 0.8457, loss_recon_edge: 0.0000,acc_node: 0.6667, acc_edge: 0.0000\n",
      "Validation loss: 0.668417818406049 ROC AUC: 0.9234277950310558 edge acc: 0 node acc: 0.6343663930892944\n",
      "157, 50, 0.2315. loss_end: 0.1425, loss_recon_node: 0.8897, loss_recon_edge: 0.0000,acc_node: 0.7153, acc_edge: 0.0000\n",
      "Validation loss: 0.7049303148307052 ROC AUC: 0.9203222049689441 edge acc: 0 node acc: 0.6457434296607971\n",
      "158, 50, 0.2036. loss_end: 0.0948, loss_recon_node: 1.0883, loss_recon_edge: 0.0000,acc_node: 0.6610, acc_edge: 0.0000\n",
      "Validation loss: 0.6674195165727653 ROC AUC: 0.9263392857142857 edge acc: 0 node acc: 0.579050600528717\n",
      "159, 50, 0.1736. loss_end: 0.0940, loss_recon_node: 0.7968, loss_recon_edge: 0.0000,acc_node: 0.7476, acc_edge: 0.0000\n",
      "Validation loss: 0.7258344082271352 ROC AUC: 0.9206133540372671 edge acc: 0 node acc: 0.6661435961723328\n",
      "160, 50, 0.1885. loss_end: 0.1134, loss_recon_node: 0.7508, loss_recon_edge: 0.0000,acc_node: 0.7900, acc_edge: 0.0000\n",
      "Validation loss: 0.8364178520791671 ROC AUC: 0.9176048136645962 edge acc: 0 node acc: 0.6304433345794678\n",
      "161, 50, 0.1080. loss_end: 0.0191, loss_recon_node: 0.8890, loss_recon_edge: 0.0000,acc_node: 0.7238, acc_edge: 0.0000\n",
      "Validation loss: 0.84639519219305 ROC AUC: 0.9148874223602484 edge acc: 0 node acc: 0.6273048520088196\n",
      "162, 50, 0.3775. loss_end: 0.2785, loss_recon_node: 0.9892, loss_recon_edge: 0.0000,acc_node: 0.6901, acc_edge: 0.0000\n",
      "Validation loss: 1.0464476253472121 ROC AUC: 0.9030473602484472 edge acc: 0 node acc: 0.6551588773727417\n",
      "163, 50, 0.1392. loss_end: 0.0438, loss_recon_node: 0.9538, loss_recon_edge: 0.0000,acc_node: 0.7049, acc_edge: 0.0000\n",
      "Validation loss: 0.7612426596529344 ROC AUC: 0.8987771739130435 edge acc: 0 node acc: 0.6837975382804871\n",
      "164, 50, 0.0935. loss_end: 0.0108, loss_recon_node: 0.8266, loss_recon_edge: 0.0000,acc_node: 0.7645, acc_edge: 0.0000\n",
      "Validation loss: 0.6620777740198023 ROC AUC: 0.9172166149068323 edge acc: 0 node acc: 0.6445664763450623\n",
      "165, 50, 0.1400. loss_end: 0.0388, loss_recon_node: 1.0119, loss_recon_edge: 0.0000,acc_node: 0.6786, acc_edge: 0.0000\n",
      "Validation loss: 0.8969318504426994 ROC AUC: 0.9115877329192547 edge acc: 0 node acc: 0.594743013381958\n",
      "166, 50, 0.1287. loss_end: 0.0299, loss_recon_node: 0.9888, loss_recon_edge: 0.0000,acc_node: 0.6835, acc_edge: 0.0000\n",
      "Validation loss: 0.8353362749604618 ROC AUC: 0.9118788819875776 edge acc: 0 node acc: 0.6284817457199097\n",
      "167, 50, 0.1686. loss_end: 0.0786, loss_recon_node: 0.9000, loss_recon_edge: 0.0000,acc_node: 0.7446, acc_edge: 0.0000\n",
      "Validation loss: 0.6707426309585571 ROC AUC: 0.9367236024844721 edge acc: 0 node acc: 0.640251100063324\n",
      "168, 50, 0.1615. loss_end: 0.0702, loss_recon_node: 0.9136, loss_recon_edge: 0.0000,acc_node: 0.7612, acc_edge: 0.0000\n",
      "Validation loss: 1.2969559314204198 ROC AUC: 0.8876164596273293 edge acc: 0 node acc: 0.6390741467475891\n",
      "169, 50, 0.1606. loss_end: 0.0569, loss_recon_node: 1.0368, loss_recon_edge: 0.0000,acc_node: 0.6460, acc_edge: 0.0000\n",
      "Validation loss: 0.8716239601958031 ROC AUC: 0.9134316770186336 edge acc: 0 node acc: 0.6198509335517883\n",
      "170, 50, 0.2046. loss_end: 0.0847, loss_recon_node: 1.1995, loss_recon_edge: 0.0000,acc_node: 0.5887, acc_edge: 0.0000\n",
      "Validation loss: 0.6833090069247227 ROC AUC: 0.9261451863354037 edge acc: 0 node acc: 0.6241663694381714\n",
      "171, 50, 0.1092. loss_end: 0.0190, loss_recon_node: 0.9023, loss_recon_edge: 0.0000,acc_node: 0.7119, acc_edge: 0.0000\n",
      "Validation loss: 0.9547078609466553 ROC AUC: 0.9165372670807452 edge acc: 0 node acc: 0.6343663930892944\n",
      "172, 50, 0.1010. loss_end: 0.0239, loss_recon_node: 0.7713, loss_recon_edge: 0.0000,acc_node: 0.7472, acc_edge: 0.0000\n",
      "Validation loss: 0.7273184113642749 ROC AUC: 0.9367236024844721 edge acc: 0 node acc: 0.6190662980079651\n",
      "173, 50, 0.1212. loss_end: 0.0340, loss_recon_node: 0.8716, loss_recon_edge: 0.0000,acc_node: 0.7801, acc_edge: 0.0000\n",
      "Validation loss: 1.0165816124747782 ROC AUC: 0.906444099378882 edge acc: 0 node acc: 0.6520203948020935\n",
      "174, 50, 0.2111. loss_end: 0.1131, loss_recon_node: 0.9806, loss_recon_edge: 0.0000,acc_node: 0.6077, acc_edge: 0.0000\n",
      "Validation loss: 0.6712850846496283 ROC AUC: 0.9254658385093167 edge acc: 0 node acc: 0.6316202282905579\n",
      "175, 50, 0.0953. loss_end: 0.0134, loss_recon_node: 0.8193, loss_recon_edge: 0.0000,acc_node: 0.7681, acc_edge: 0.0000\n",
      "Validation loss: 0.8216802629770017 ROC AUC: 0.9187694099378882 edge acc: 0 node acc: 0.6304433345794678\n",
      "176, 50, 0.1314. loss_end: 0.0545, loss_recon_node: 0.7687, loss_recon_edge: 0.0000,acc_node: 0.8108, acc_edge: 0.0000\n",
      "Validation loss: 0.898348001872792 ROC AUC: 0.9162461180124224 edge acc: 0 node acc: 0.5951353311538696\n",
      "177, 50, 0.1090. loss_end: 0.0243, loss_recon_node: 0.8467, loss_recon_edge: 0.0000,acc_node: 0.7266, acc_edge: 0.0000\n",
      "Validation loss: 0.9743280761382159 ROC AUC: 0.9165372670807452 edge acc: 0 node acc: 0.6261278986930847\n",
      "178, 50, 0.1648. loss_end: 0.0848, loss_recon_node: 0.8002, loss_recon_edge: 0.0000,acc_node: 0.6655, acc_edge: 0.0000\n",
      "Validation loss: 0.6630461286096012 ROC AUC: 0.9307065217391305 edge acc: 0 node acc: 0.6261278986930847\n",
      "179, 50, 0.1453. loss_end: 0.0584, loss_recon_node: 0.8695, loss_recon_edge: 0.0000,acc_node: 0.7509, acc_edge: 0.0000\n",
      "Validation loss: 0.7595692405513689 ROC AUC: 0.937985248447205 edge acc: 0 node acc: 0.6002354025840759\n",
      "180, 50, 0.0874. loss_end: 0.0036, loss_recon_node: 0.8384, loss_recon_edge: 0.0000,acc_node: 0.7703, acc_edge: 0.0000\n",
      "Validation loss: 0.7927605305232254 ROC AUC: 0.9262422360248447 edge acc: 0 node acc: 0.628089427947998\n",
      "181, 50, 0.1377. loss_end: 0.0119, loss_recon_node: 1.2580, loss_recon_edge: 0.0000,acc_node: 0.5036, acc_edge: 0.0000\n",
      "Validation loss: 1.0098375046954435 ROC AUC: 0.9186723602484472 edge acc: 0 node acc: 0.5919968485832214\n",
      "182, 50, 0.2624. loss_end: 0.1742, loss_recon_node: 0.8824, loss_recon_edge: 0.0000,acc_node: 0.7245, acc_edge: 0.0000\n",
      "Validation loss: 1.010137167631411 ROC AUC: 0.922748447204969 edge acc: 0 node acc: 0.6123970150947571\n",
      "183, 50, 0.2844. loss_end: 0.1862, loss_recon_node: 0.9824, loss_recon_edge: 0.0000,acc_node: 0.6818, acc_edge: 0.0000\n",
      "Validation loss: 0.6877198569914874 ROC AUC: 0.9352678571428572 edge acc: 0 node acc: 0.673597514629364\n",
      "184, 50, 0.1436. loss_end: 0.0633, loss_recon_node: 0.8032, loss_recon_edge: 0.0000,acc_node: 0.7825, acc_edge: 0.0000\n",
      "Validation loss: 0.6695528848498475 ROC AUC: 0.9346855590062112 edge acc: 0 node acc: 0.6563358306884766\n",
      "185, 50, 0.1606. loss_end: 0.0767, loss_recon_node: 0.8391, loss_recon_edge: 0.0000,acc_node: 0.7559, acc_edge: 0.0000\n",
      "Validation loss: 0.813231606547739 ROC AUC: 0.9301242236024845 edge acc: 0 node acc: 0.5912122130393982\n",
      "186, 50, 0.1146. loss_end: 0.0184, loss_recon_node: 0.9623, loss_recon_edge: 0.0000,acc_node: 0.6840, acc_edge: 0.0000\n",
      "Validation loss: 0.6626120443437614 ROC AUC: 0.937888198757764 edge acc: 0 node acc: 0.6586896777153015\n",
      "187, 50, 0.1320. loss_end: 0.0397, loss_recon_node: 0.9228, loss_recon_edge: 0.0000,acc_node: 0.6807, acc_edge: 0.0000\n",
      "Validation loss: 0.8075133830893273 ROC AUC: 0.9187694099378882 edge acc: 0 node acc: 0.608081579208374\n",
      "188, 50, 0.2582. loss_end: 0.1744, loss_recon_node: 0.8371, loss_recon_edge: 0.0000,acc_node: 0.7206, acc_edge: 0.0000\n",
      "Validation loss: 0.7731022975024056 ROC AUC: 0.9378881987577639 edge acc: 0 node acc: 0.6222047805786133\n",
      "189, 50, 0.1749. loss_end: 0.0970, loss_recon_node: 0.7794, loss_recon_edge: 0.0000,acc_node: 0.7556, acc_edge: 0.0000\n",
      "Validation loss: 0.6887024383918912 ROC AUC: 0.9258540372670807 edge acc: 0 node acc: 0.6426049470901489\n",
      "190, 50, 0.1943. loss_end: 0.1107, loss_recon_node: 0.8359, loss_recon_edge: 0.0000,acc_node: 0.7492, acc_edge: 0.0000\n",
      "Validation loss: 0.8781653058295157 ROC AUC: 0.9196428571428572 edge acc: 0 node acc: 0.5535504221916199\n",
      "191, 50, 0.2515. loss_end: 0.1748, loss_recon_node: 0.7668, loss_recon_edge: 0.0000,acc_node: 0.7759, acc_edge: 0.0000\n",
      "Validation loss: 0.8135487855065102 ROC AUC: 0.9243012422360248 edge acc: 0 node acc: 0.6708512902259827\n",
      "192, 50, 0.2070. loss_end: 0.1035, loss_recon_node: 1.0352, loss_recon_edge: 0.0000,acc_node: 0.6763, acc_edge: 0.0000\n",
      "Validation loss: 1.0061394396950216 ROC AUC: 0.9323563664596274 edge acc: 0 node acc: 0.6488819122314453\n",
      "193, 50, 0.1644. loss_end: 0.0224, loss_recon_node: 1.4206, loss_recon_edge: 0.0000,acc_node: 0.4935, acc_edge: 0.0000\n",
      "Validation loss: 0.7540264712537036 ROC AUC: 0.9332298136645963 edge acc: 0 node acc: 0.6414279937744141\n",
      "194, 50, 0.2494. loss_end: 0.1572, loss_recon_node: 0.9216, loss_recon_edge: 0.0000,acc_node: 0.7165, acc_edge: 0.0000\n",
      "Validation loss: 1.0454010612824385 ROC AUC: 0.9015916149068324 edge acc: 0 node acc: 0.6061200499534607\n",
      "195, 50, 0.1836. loss_end: 0.0869, loss_recon_node: 0.9669, loss_recon_edge: 0.0000,acc_node: 0.6515, acc_edge: 0.0000\n",
      "Validation loss: 0.7925747644667532 ROC AUC: 0.9343944099378882 edge acc: 0 node acc: 0.6304433345794678\n",
      "196, 50, 0.1417. loss_end: 0.0469, loss_recon_node: 0.9481, loss_recon_edge: 0.0000,acc_node: 0.7293, acc_edge: 0.0000\n",
      "Validation loss: 0.7185563886282491 ROC AUC: 0.9399262422360248 edge acc: 0 node acc: 0.662612795829773\n",
      "197, 50, 0.1059. loss_end: 0.0294, loss_recon_node: 0.7656, loss_recon_edge: 0.0000,acc_node: 0.7762, acc_edge: 0.0000\n",
      "Validation loss: 0.9605689305885166 ROC AUC: 0.9216809006211181 edge acc: 0 node acc: 0.6700667142868042\n",
      "198, 50, 0.2286. loss_end: 0.1391, loss_recon_node: 0.8947, loss_recon_edge: 0.0000,acc_node: 0.6627, acc_edge: 0.0000\n",
      "Validation loss: 0.796868779203471 ROC AUC: 0.9182841614906831 edge acc: 0 node acc: 0.6065123677253723\n",
      "199, 50, 0.1053. loss_end: 0.0208, loss_recon_node: 0.8452, loss_recon_edge: 0.0000,acc_node: 0.7500, acc_edge: 0.0000\n",
      "Validation loss: 0.8489974012561873 ROC AUC: 0.9300271739130433 edge acc: 0 node acc: 0.6488819122314453\n",
      "Loaded trained model with success.\n",
      "Figure(800x500)\n",
      "Test loss: 2.0065992112253226 ROC AUC: 0.7428571428571429 edge acc: 0 node acc: 0.6119334101676941\n"
     ]
    }
   ],
   "source": [
    "!python Recon+predict_acc.py \\\n",
    "--task_name bbbp \\\n",
    "--splitting scaffold \\\n",
    "--alpha 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ca6b2e7-c445-4dc0-922f-516d76356d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<networkx.classes.graph.Graph at 0x7f96a0560820>,\n",
       " {0: array([-0.26783334, -0.67593494]),\n",
       "  1: array([-0.06292945, -0.34773855]),\n",
       "  2: array([ 0.01255835, -0.72741183]),\n",
       "  3: array([0.0267215 , 0.14450721]),\n",
       "  4: array([0.11039129, 0.60657811]),\n",
       "  5: array([0.18109165, 1.        ])})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "\n",
    "# 노드 추가\n",
    "G.add_nodes_from([0, 1, 2, 3, 4, 5])\n",
    "\n",
    "# 엣지 추가\n",
    "G.add_edges_from([(0, 1), (0, 2), (1, 2), (1, 3), (3, 4), (4, 5)])\n",
    "\n",
    "# 시각화를 위한 포지션 결정\n",
    "pos = nx.spring_layout(G)\n",
    "\n",
    "# 그래프와 포지션 반환\n",
    "(G, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37cf66e5-fb67-4f55-88e2-e0ac8893718b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 5))\n",
    "nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=700, \n",
    "        edge_color='k', linewidths=1, font_size=15, \n",
    "        arrows=True, arrowsize=20)\n",
    "\n",
    "# 시각화 표시\n",
    "plt.title(\"Example Graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "825eaa4e-fd57-4b97-a2eb-2d96d56f8908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSubgraph(Graph, center, percent=0.2):\n",
    "    assert percent <= 1\n",
    "    G = Graph.copy()\n",
    "    num = int(np.floor(len(G.nodes) * percent))\n",
    "    removed_nodes = []\n",
    "    temp = [center]\n",
    "\n",
    "    while len(removed_nodes) < num:\n",
    "        if not temp:  # temp가 비어있으면 더 이상 제거할 노드가 없음\n",
    "            break\n",
    "        neighbors = []\n",
    "        for n in temp:\n",
    "            if n in G:  # 노드가 G에 존재하는지 확인\n",
    "                neighbors.extend([i for i in G.neighbors(n) if i not in temp and i not in removed_nodes])\n",
    "                if len(removed_nodes) < num:\n",
    "                    G.remove_node(n)\n",
    "                    removed_nodes.append(n)\n",
    "                else:\n",
    "                    break\n",
    "        temp = list(set(neighbors))\n",
    "\n",
    "    print(removed_nodes)\n",
    "    # 제거된 노드들 사이에 있는 엣지만 찾기\n",
    "    removed_edges = [(u, v) for u, v in Graph.edges() if u in removed_nodes and v in removed_nodes]\n",
    "    print(removed_edges)\n",
    "    \n",
    "\n",
    "    return removed_nodes, removed_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5c66636-6510-459e-b8a1-3443b5f3b9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 2]\n",
      "[(0, 1), (0, 2), (1, 2)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "node, edges = removeSubgraph(G, 1,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "911f693e-912a-4b46-a4f7-75e64c686098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 2]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64fddada-aac4-42d9-b82f-0b0be72bdaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61f9b189-f19e-4b3f-a3b2-22fe9a33e46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeView([(0, 1), (0, 2), (1, 2), (1, 3), (3, 4), (4, 5)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "415c5ff0-dfb0-4e50-878f-22b1b4b3eb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_edges = [(u, v) for u, v in G.edges() if u in node and v in node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "277594b3-8260-4ca9-bdbf-7a9e3cd7dd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (0, 2), (1, 2)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f51d1a0e-310d-4716-8831-06a7ef9b9a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 6, 7]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# edge_index 예시\n",
    "edge_index = torch.tensor([[0, 1, 2, 3, 3, 4, 4, 5], \n",
    "                           [1, 0, 3, 2, 4, 3, 5, 4]], dtype=torch.long)\n",
    "\n",
    "# removeSubgraph 함수를 통해 얻은 removed_edges 예시\n",
    "removed_edges = [(3, 4), (4, 5)]\n",
    "\n",
    "# removed_edges의 각 엣지에 대응하는 edge_index의 인덱스 찾기\n",
    "removed_edge_indices = []\n",
    "for edge in removed_edges:\n",
    "    u, v = edge\n",
    "    # 양방향 엣지 인덱스 찾기\n",
    "    index_uv = ((edge_index[0] == u) & (edge_index[1] == v)).nonzero(as_tuple=True)[0]\n",
    "    index_vu = ((edge_index[0] == v) & (edge_index[1] == u)).nonzero(as_tuple=True)[0]\n",
    "    if index_uv.numel() > 0:  # (u, v) 방향의 인덱스가 존재하면 리스트에 추가\n",
    "        removed_edge_indices.extend(index_uv.tolist())\n",
    "    if index_vu.numel() > 0:  # (v, u) 방향의 인덱스가 존재하면 리스트에 추가\n",
    "        removed_edge_indices.extend(index_vu.tolist())\n",
    "\n",
    "# 결과 출력\n",
    "removed_edge_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe559a59-1bc4-4ea8-91a8-a7f42540b4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 3, 4, 4, 5],\n",
       "        [1, 0, 3, 2, 4, 3, 5, 4]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979d2df-070e-48c9-a9c4-681ba8c2eb63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
