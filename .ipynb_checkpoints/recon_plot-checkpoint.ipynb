{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05b0aed4-34de-4964-8ad8-dfaca1cc0d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "\n",
    "from dataset.dataset_test_recon import MolTestDatasetWrapper\n",
    "\n",
    "from dataset.get_config import get_config \n",
    "import argparse\n",
    "from torch_geometric.utils import  scatter, softmax\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3c41f6a-013d-4dac-ab42-7397a7bfe63e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2721159092.py, line 52)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[32], line 52\u001b[0;36m\u001b[0m\n\u001b[0;31m    def load_state_dict(, state_dict):\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "apex_support = False\n",
    "try:\n",
    "    sys.path.append('./apex')\n",
    "    from apex import amp\n",
    "\n",
    "    apex_support = True\n",
    "except:\n",
    "    print(\"Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\")\n",
    "    apex_support = False\n",
    "\n",
    "\n",
    "def _save_config_file(model_checkpoints_folder):\n",
    "    if not os.path.exists(model_checkpoints_folder):\n",
    "        os.makedirs(model_checkpoints_folder)\n",
    "        shutil.copy('./config_finetune.yaml', os.path.join(model_checkpoints_folder, 'config_finetune.yaml'))\n",
    "\n",
    "def get_roc_auc_score(y_true, y_pred, is_valid):\n",
    "    roc_list = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        #AUC is only defined when there is at least one positive data.\n",
    "        if np.sum(y_true[:,i] == 1) > 0 and np.sum(y_true[:,i] == -1) > 0:\n",
    "            is_valid = y_true[:,i]**2 > 0\n",
    "            roc_list.append(roc_auc_score((y_true[is_valid,i] + 1)/2, y_pred[is_valid,i]))\n",
    "\n",
    "    if len(roc_list) < y_true.shape[1]:\n",
    "        print(\"Some target is missing!\")\n",
    "        print(\"Missing ratio: %f\" %(1 - float(len(roc_list))/y_true.shape[1]))\n",
    "\n",
    "    return  sum(roc_list)/len(roc_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Normalizer(object):\n",
    "    \"\"\"Normalize a Tensor and restore it later. \"\"\"\n",
    "\n",
    "    def __init__(self, tensor):\n",
    "        \"\"\"tensor is taken as a sample to calculate the mean and std\"\"\"\n",
    "        mean = torch.mean(tensor)\n",
    "        std = torch.std(tensor)\n",
    "\n",
    "    def norm(self, tensor):\n",
    "        return (tensor - mean) / std\n",
    "\n",
    "    def denorm(self, normed_tensor):\n",
    "        return normed_tensor * std + mean\n",
    "\n",
    "    def state_dict():\n",
    "        return {'mean': mean,\n",
    "                'std': std}\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        mean = state_dict['mean']\n",
    "        std = state_dict['std']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a86cb44-58ef-42cc-a2ed-37c26d40252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    batch_size = 32\n",
    "    epochs = 200\n",
    "    init_lr = 0.0005\n",
    "    init_base_lr = 0.0001\n",
    "    weight_decay = 1e-6\n",
    "    \n",
    "    gpu = 'cuda:0'\n",
    "    model_type = 'gin'\n",
    "    num_layer = 5\n",
    "    emb_dim = 300\n",
    "    feat_dim = 300\n",
    "    dropout = 0.3\n",
    "    pool = 'mean'\n",
    "    seed = '42'\n",
    "\n",
    "    task_name = 'qm7'\n",
    "    splitting = 'scaffold'\n",
    "    random_masking = 1\n",
    "    mask_rate = 0.2\n",
    "    mask_edge = 0 \n",
    "    alpha = 0.1\n",
    "    reduceTrain = 1\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eee7561c-363f-4a42-8de5-b22b4beaba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(\"config_finetune.yaml\", \"r\"), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be0ac5f0-d577-4be4-8323-19c35dc647f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = args.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c18dcf43-bdee-40a9-a8f4-433029ba59cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['batch_size'] = args.batch_size\n",
    "config['epochs'] = args.epochs\n",
    "config['init_lr'] = args.init_lr\n",
    "config['init_base_lr'] = args.init_base_lr\n",
    "# config['weight_decay'] = args.weight_decay\n",
    "config['gpu'] = args.gpu   \n",
    "config['model']['num_layer'] = args.num_layer\n",
    "config['model']['emb_dim'] = args.emb_dim\n",
    "config['model']['feat_dim'] = args.feat_dim\n",
    "config['model']['drop_ratio'] = args.dropout\n",
    "config['model']['pool'] = args.pool\n",
    "\n",
    "config['task_name'] = args.task_name\n",
    "config['dataset']['seed'] = seed\n",
    "\n",
    "config['dataset']['splitting'] = args.splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc712c3-244f-448e-9d43-99cddafaac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed =  int(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a636dc-8159-4763-87f4-c6fe1ba50a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "config['task_name'] = config['task_name'].lower()\n",
    "# config['model']['mask_rate'] = args.mask_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b20f03b-1a4b-42dc-81f4-8c504be84215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del config['model']['mask_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1d988de-9285-4bef-ace9-6a3227fadaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb7ee7-1560-4c35-8fbb-631e03767bdc",
   "metadata": {},
   "source": [
    "### main으로 넘어옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d9f3d30-3e31-49a8-b3c5-f83379976148",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MolTestDatasetWrapper(config['batch_size'],\n",
    "                                **config['dataset'],\n",
    "                                random_masking=args.random_masking,\n",
    "                                mask_rate=args.mask_rate,\n",
    "                                mask_edge=args.mask_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf54e6d-2cef-45bf-88c7-479488ac5400",
   "metadata": {},
   "source": [
    "## step 과 test 옮기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a68709b-b6ca-4450-9800-d679ef74268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _get_device():\n",
    "        if torch.cuda.is_available() and config['gpu'] != 'cpu':\n",
    "            device = config['gpu']\n",
    "            torch.cuda.set_device(device)\n",
    "            args.deviceName = \"cuda\" + str(device[-1])\n",
    "\n",
    "        else:\n",
    "            \n",
    "            device = 'cpu'\n",
    "            args.deviceName = 'cpu'\n",
    "\n",
    "        print(\"Running on:\", device)\n",
    "\n",
    "        return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8327c0cf-2d42-45fa-88ea-26f062449ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = _get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4237d4c3-d5dc-405a-85f1-8e68975ab766",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefilename = f\"finetunerandom_edgePred_{args.task_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79bd57f3-bf60-4837-9456-69acd3a8f6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finetunerandom_edgePred_qm7'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savefilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43b775ad-1124-4987-b333-fc269fa324b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = {\n",
    "    \"recon\": {\n",
    "        \"loss_end\": [\"Multiline\", [\"loss_end/train\", \"loss_end/validation\"]],\n",
    "        \"loss_recon_node\" : [\"Multiline\", [\"loss_recon_node/train\"]],\n",
    "        \"loss_recon_edge\" : [\"Multiline\", [\"loss_recon_edge/train\"]],\n",
    "        \"loss_total\" : [\"Multiline\", [\"loss_total/train\", \"loss_total/validation\"]],\n",
    "        \"accuracy\": [\"Multiline\", [ \"accuracy/validation\"]],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e4b42a9-4ec6-414d-8fc1-895222979bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "dir_name =  savefilename + config['task_name'] + '_' + str(args.num_layer) + '_' \\\n",
    "+ str(args.emb_dim) + '_' + str(args.feat_dim)  + '_' + str(args.dropout) + '_' \\\n",
    "+ str(args.splitting) + '_' + str(args.deviceName) + '_' + str(args.seed) + '_' + str(current_time)\n",
    "\n",
    "log_dir = os.path.join('finetune', dir_name)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "writer.add_custom_scalars(layout)\n",
    "\n",
    "dataset = dataset\n",
    "if config['dataset']['task'] == 'classification':\n",
    "    criterion =  nn.BCEWithLogitsLoss(reduction = \"none\")\n",
    "elif config['dataset']['task'] == 'regression':\n",
    "    if config[\"task_name\"] in ['qm7', 'qm8', 'qm9']:\n",
    "        criterion = nn.L1Loss()\n",
    "    else:\n",
    "        criterion = nn.MSELoss()\n",
    "criterion_recon = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "546abf17-3639-44d1-b445-d48e35ee8118",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6833\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/6833\n",
      "Generating scaffold 1000/6833\n",
      "Generating scaffold 2000/6833\n",
      "Generating scaffold 3000/6833\n",
      "Generating scaffold 4000/6833\n",
      "Generating scaffold 5000/6833\n",
      "Generating scaffold 6000/6833\n",
      "About to sort in scaffold sets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, test_loader = dataset.get_data_loaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbe2afa-e438-47e8-b2c4-289aaac5c3a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## train_loader 저장 후 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d0bc4e7-d9ba-405a-8a99-e0609f997004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data_save/bbbp/bbbp_scaffold_42.pkl'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_base = f\"./data_save/{config['task_name']}/{config['task_name']}_{args.splitting}_{args.seed}.pkl\"\n",
    "file_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6808e1aa-58d3-4ac2-9777-e6d12b73c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = f\"./data_save/{config['task_name']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06fb5132-e763-4cf2-ae95-9bd1f3469f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data_save/bbbp'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23038714-0b81-426d-b1ad-c42b96858f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_train = dir_name + f\"/{config['task_name']}_{args.splitting}_{args.seed}_train.pkl\" \n",
    "file_name_valid = dir_name + f\"/{config['task_name']}_{args.splitting}_{args.seed}_valid.pkl\" \n",
    "file_name_test = dir_name + f\"/{config['task_name']}_{args.splitting}_{args.seed}_test.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f5bdac9-ae96-4b50-a6a5-9f4c3d3e82f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f5a39e2-a3c9-4d1a-a96c-1fdf0a9f5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(file_name_train, 'wb') as f:\n",
    "    pickle.dump(train_loader.dataset, f)\n",
    "\n",
    "with open(file_name_valid, 'wb') as f:\n",
    "    pickle.dump(valid_loader.dataset, f)\n",
    "    \n",
    "with open(file_name_test, 'wb') as f:\n",
    "    pickle.dump(test_loader.dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8942875-0492-4b16-b626-ef779d0610ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(file_name_train, 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "with open(file_name_valid, 'rb') as f:\n",
    "    valid_dataset = pickle.load(f)\n",
    "\n",
    "with open(file_name_test, 'rb') as f:\n",
    "    test_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c170f9a-1cb3-4e61-937b-7490150694c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers = config['dataset']['num_workers'])\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers = config['dataset']['num_workers'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers = config['dataset']['num_workers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609956c-915b-4e0b-bf68-e0672151fcae",
   "metadata": {},
   "source": [
    "## 저장 끝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b90a4905-9f2d-44e4-a311-7c68ea78eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_datasets = ['FreeSolv',\n",
    "                        'ESOL',\n",
    "                         'qm7',\n",
    "                        'Lipo',\n",
    "                        'BACE',\n",
    "                        'BBBP',\n",
    "                        'ClinTox'\n",
    "                        'sider',\n",
    "                        'tox21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fbf227b-8515-4d28-8d7d-5962246133b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_datasets_lower = [x.lower() for x in selected_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d088a308-d1e9-440a-a7cd-a4bb649c4fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(object):\n",
    "    \"\"\"Normalize a Tensor and restore it later. \"\"\"\n",
    "\n",
    "    def __init__(self, tensor):\n",
    "        \"\"\"tensor is taken as a sample to calculate the mean and std\"\"\"\n",
    "        self.mean = torch.mean(tensor)\n",
    "        self.std = torch.std(tensor)\n",
    "\n",
    "    def norm(self, tensor):\n",
    "        return (tensor - self.mean) / self.std\n",
    "\n",
    "    def denorm(self, normed_tensor):\n",
    "        return normed_tensor * self.std + self.mean\n",
    "\n",
    "    def state_dict(self):\n",
    "        return {'mean': self.mean,\n",
    "                'std': self.std}\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.mean = state_dict['mean']\n",
    "        self.std = state_dict['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a67f5053-8b25-42fd-ab3b-6c3cebb02a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1553.3463) tensor(228.3718) torch.Size([5466, 1])\n"
     ]
    }
   ],
   "source": [
    "normalizer = None\n",
    "if config[\"task_name\"] in ['qm7', 'qm9']:\n",
    "    labels = []\n",
    "    for d  in train_loader:\n",
    "        labels.append(d.y)\n",
    "    labels = torch.cat(labels)\n",
    "    normalizer = Normalizer(labels)\n",
    "    print(normalizer.mean, normalizer.std, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "776348b9-60bf-4a23-8118-e8e2c6a1f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_atom_type = 120 # including the extra mask tokens\n",
    "num_chirality_tag = 3\n",
    "\n",
    "num_bond_type = 6 # including aromatic and -loop edge\n",
    "num_bond_direction = 3 \n",
    "\n",
    "num_atom_type = 120 # including the extra mask tokens\n",
    "num_chirality_tag = 3\n",
    "\n",
    "num_bond_type = 6 # including aromatic and self-loop edge\n",
    "num_bond_direction = 3 \n",
    "\n",
    "\n",
    "class GINEConv(MessagePassing):\n",
    "    def __init__(self, emb_dim, bias = None):\n",
    "        super(GINEConv, self,  ).__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        if bias is not None:\n",
    "            self.mlp = nn.Sequential(\n",
    "                nn.Linear(emb_dim, 2*emb_dim, bias = bias), \n",
    "                nn.ReLU(), \n",
    "                nn.Linear(2*emb_dim, emb_dim, bias = bias), \n",
    "                \n",
    "            )\n",
    "        else:\n",
    "            self.mlp = nn.Sequential(\n",
    "                nn.Linear(emb_dim, 2*emb_dim), \n",
    "                nn.ReLU(), \n",
    "                nn.Linear(2*emb_dim, emb_dim)\n",
    "            )\n",
    "        self.edge_embedding1 = nn.Embedding(num_bond_type, emb_dim)\n",
    "        self.edge_embedding2 = nn.Embedding(num_bond_direction, emb_dim)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.edge_embedding1.weight.data)\n",
    "        nn.init.xavier_uniform_(self.edge_embedding2.weight.data)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, mask_edge = None):\n",
    "        # add self loops in the edge space\n",
    "        edge_index = add_self_loops(edge_index, num_nodes=x.size(0))[0]\n",
    "\n",
    "        # add features corresponding to self-loop edges.\n",
    "        self_loop_attr = torch.zeros(x.size(0), 2)\n",
    "        self_loop_attr[:,0] = 4 # bond type for self-loop edge\n",
    "        self_loop_attr = self_loop_attr.to(edge_attr.device).to(edge_attr.dtype)\n",
    "        edge_attr = torch.cat((edge_attr, self_loop_attr), dim=0)\n",
    "\n",
    "        if mask_edge is not None:\n",
    "\n",
    "            edge_embeddings = torch.zeros(edge_attr.size(0), self.emb_dim).to(edge_attr.device)\n",
    "        \n",
    "        else: \n",
    "            edge_embeddings = self.edge_embedding1(edge_attr[:,0]) + \\\n",
    "            self.edge_embedding2(edge_attr[:,1])\n",
    "\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_embeddings)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        return x_j + edge_attr\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return self.mlp(aggr_out)\n",
    "\n",
    "class GINetReconEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        num_layer (int): the number of GNN layers\n",
    "        emb_dim (int): dimensionality of embeddings\n",
    "        drop_ratio (float): dropout rate\n",
    "        gnn_type: gin, gcn, graphsage, gat\n",
    "    Output:\n",
    "        node representations\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "        task='classification', num_layer=5, emb_dim=300, feat_dim=512, \n",
    "        drop_ratio=0, pool='mean', pred_n_layer=2, pred_act='softplus', num_task = 1\n",
    "    ):\n",
    "        super(GINetReconEmbedding, self).__init__()\n",
    "        self.num_layer = num_layer\n",
    "        self.emb_dim = emb_dim\n",
    "        self.feat_dim = feat_dim\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.task = task\n",
    "        self.num_task = num_task\n",
    "\n",
    "        self.x_embedding1 = nn.Embedding(num_atom_type, emb_dim)\n",
    "        self.x_embedding2 = nn.Embedding(num_chirality_tag, emb_dim)\n",
    "        nn.init.xavier_uniform_(self.x_embedding1.weight.data)\n",
    "        nn.init.xavier_uniform_(self.x_embedding2.weight.data)\n",
    "\n",
    "        # List of MLPs\n",
    "        self.gnns = nn.ModuleList()\n",
    "        for layer in range(num_layer):\n",
    "            self.gnns.append(GINEConv(emb_dim))\n",
    "\n",
    "        # List of batchnorms\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        for layer in range(num_layer):\n",
    "            self.batch_norms.append(nn.BatchNorm1d(emb_dim))\n",
    "\n",
    "        if pool == 'mean':\n",
    "            self.pool = global_mean_pool\n",
    "        elif pool == 'max':\n",
    "            self.pool = global_max_pool\n",
    "        elif pool == 'add':\n",
    "            self.pool = global_add_pool\n",
    "        self.feat_lin = nn.Linear(self.emb_dim, self.feat_dim)\n",
    "\n",
    "        \n",
    "        self.pred_n_layer = max(1, pred_n_layer)\n",
    "\n",
    "        if pred_act == 'relu':\n",
    "            pred_head = [\n",
    "                nn.Linear(self.feat_dim, self.feat_dim//2), \n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            for _ in range(self.pred_n_layer - 1):\n",
    "                pred_head.extend([\n",
    "                    nn.Linear(self.feat_dim//2, self.feat_dim//2), \n",
    "                    nn.ReLU(inplace=True),\n",
    "                ])\n",
    "            pred_head.append(nn.Linear(self.feat_dim//2, num_task))\n",
    "\n",
    "        elif pred_act == 'softplus':\n",
    "            pred_head = [\n",
    "                nn.Linear(self.feat_dim, self.feat_dim//2), \n",
    "                nn.Softplus()\n",
    "            ]\n",
    "            for _ in range(self.pred_n_layer - 1):\n",
    "                pred_head.extend([\n",
    "                    nn.Linear(self.feat_dim//2, self.feat_dim//2), \n",
    "                    nn.Softplus()\n",
    "                ])\n",
    "        else:\n",
    "            raise ValueError('Undefined activation function')\n",
    "        \n",
    "        self.dense_score = nn.Linear(self.feat_dim, 1)  # for node score\n",
    "\n",
    "        pred_head.append(nn.Linear(self.feat_dim//2, num_task))\n",
    "        self.pred_head = nn.Sequential(*pred_head)\n",
    "\n",
    "    def forward(self, data, mask_node = None, mask_edge = None):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "\n",
    "\n",
    "        if mask_node is not None:\n",
    "            # print(mask_node)\n",
    "            feature_0_mask = self.x_embedding1(x[:,0].long())\n",
    "            feature_1_mask = self.x_embedding2(x[:,1].long())\n",
    "            \n",
    "            feature_0_mask[mask_node] = torch.zeros(self.emb_dim).to(feature_0_mask.device)\n",
    "            feature_1_mask[mask_node] = torch.zeros(self.emb_dim).to(feature_1_mask.device)\n",
    "\n",
    "            h = feature_0_mask + feature_1_mask\n",
    "\n",
    "        else: \n",
    "            h = self.x_embedding1(x[:,0]) + self.x_embedding2(x[:,1])\n",
    "\n",
    "        for layer in range(self.num_layer):\n",
    "            if layer == 0:\n",
    "                h = self.gnns[layer](h, edge_index, edge_attr, mask_edge)\n",
    "            else:\n",
    "                h = self.gnns[layer](h, edge_index, edge_attr)\n",
    "\n",
    "            h = self.batch_norms[layer](h)\n",
    "            if layer == self.num_layer - 1:\n",
    "                h = F.dropout(h, self.drop_ratio, training=self.training)\n",
    "            else:\n",
    "                h = F.dropout(F.relu(h), self.drop_ratio, training=self.training)\n",
    "\n",
    "        h_node = h\n",
    "\n",
    "        h = self.pool(h_node, data.batch)\n",
    "        h = self.feat_lin(h)\n",
    "        \n",
    "        return  h_node, self.pred_head(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3767c452-a32a-4fcc-8b44-530b2caeae2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'global_mean_pool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mGINetReconEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[23], line 100\u001b[0m, in \u001b[0;36mGINetReconEmbedding.__init__\u001b[0;34m(self, task, num_layer, emb_dim, feat_dim, drop_ratio, pool, pred_n_layer, pred_act, num_task)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_norms\u001b[38;5;241m.\u001b[39mappend(nn\u001b[38;5;241m.\u001b[39mBatchNorm1d(emb_dim))\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pool \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool \u001b[38;5;241m=\u001b[39m \u001b[43mglobal_mean_pool\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pool \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool \u001b[38;5;241m=\u001b[39m global_max_pool\n",
      "\u001b[0;31mNameError\u001b[0m: name 'global_mean_pool' is not defined"
     ]
    }
   ],
   "source": [
    "model = GINetReconEmbedding(config['dataset']['task'], **config[\"model\"]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "06db7d6f-bd6e-4a03-93fc-519b2a754a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n"
     ]
    }
   ],
   "source": [
    "layer_list = []\n",
    "for name, param in model.named_parameters():\n",
    "    if 'pred_head' in name:\n",
    "        print(name, param.requires_grad)\n",
    "        layer_list.append(name)\n",
    "\n",
    "params = list(map(lambda x: x[1],list(filter(lambda kv: kv[0] in layer_list, model.named_parameters()))))\n",
    "base_params = list(map(lambda x: x[1],list(filter(lambda kv: kv[0] not in layer_list, model.named_parameters()))))\n",
    "\n",
    "linear_pred_atoms = torch.nn.Linear(args.emb_dim, 119).to(device)\n",
    "linear_pred_bonds = torch.nn.Linear(args.emb_dim, 4).to(device)\n",
    "\n",
    "\n",
    "optimizer_model = torch.optim.Adam(\n",
    "    [{'params': base_params, 'lr': config['init_base_lr']}, {'params': params}],\n",
    "    config['init_lr'], weight_decay=eval(config['weight_decay'])\n",
    ")\n",
    "\n",
    "optimizer_linear_pred_atoms = torch.optim.Adam(linear_pred_atoms.parameters(), lr=args.init_base_lr, weight_decay=eval(config['weight_decay']))\n",
    "optimizer_linear_pred_bonds = torch.optim.Adam(linear_pred_bonds.parameters(), lr=args.init_base_lr, weight_decay=eval(config['weight_decay']))\n",
    "\n",
    "model_list = [model, linear_pred_atoms, linear_pred_bonds]\n",
    "optimizer_list = [optimizer_model, optimizer_linear_pred_atoms, optimizer_linear_pred_bonds]\n",
    "\n",
    "if apex_support and config['fp16_precision']:\n",
    "    model, optimizer = amp.initialize(\n",
    "        model, optimizer, opt_level='O2', keep_batchnorm_fp32=True\n",
    "    )\n",
    "\n",
    "model_checkpoints_folder = os.path.join(writer.log_dir, 'checkpoints')\n",
    "\n",
    "# save config file\n",
    "_save_config_file(model_checkpoints_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "d0134926-264e-4db7-bd1a-de22e4527f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(pred, label):\n",
    "            # edge prediction   \n",
    "        _, predicted_classes = torch.max(pred, dim=1) # dim=1은 노드별로 최댓값을 찾음\n",
    "\n",
    "        correct_predictions = (predicted_classes == label)\n",
    "\n",
    "        accuracy = correct_predictions.float().mean().item()\n",
    "\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "3eff6f96-fc93-4063-9f66-ae7dfcdcddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _step( model_list, data, n_iter):\n",
    "    model, linear_pred_atoms, linear_pred_bonds = model_list\n",
    "\n",
    "    num_atom_type = 119\n",
    "    num_edge_type = 4\n",
    "\n",
    "    # get the prediction\n",
    "    _, pred = model(data)  # [N,C]\n",
    "\n",
    "    for atom_idx in data.masked_atom_indices:\n",
    "        data[atom_idx] = torch.tensor([num_atom_type, 0]).to(device)\n",
    "\n",
    "\n",
    "    if args.mask_edge:\n",
    "        \n",
    "        node_rep_masked, output2_masked = model(data)\n",
    "\n",
    "\n",
    "        for bond_idx in data.connected_edge_indices:\n",
    "                data.edge_attr[bond_idx] = torch.tensor(\n",
    "                    [num_edge_type, 0])\n",
    "\n",
    "        masked_edge_index = data.edge_index[:, data.connected_edge_indices]\n",
    "        # edge_rep \n",
    "        edge_rep = node_rep_masked[masked_edge_index[0]] + node_rep_masked[masked_edge_index[1]]\n",
    "\n",
    "        pred_edge = linear_pred_bonds(edge_rep)\n",
    "\n",
    "        \n",
    "        mask_edge_label = data.mask_edge_label.to(pred_edge.device)\n",
    "        loss_recon_edge = criterion_recon(pred_edge.float(),  mask_edge_label[:,0])\n",
    "\n",
    "\n",
    "        pred_node = linear_pred_atoms(node_rep_masked[data.masked_atom_indices])\n",
    "        loss_recon_node = criterion_recon(pred_node.float(), data.mask_node_label[:,0])\n",
    "\n",
    "    else: \n",
    "\n",
    "        node_repre2, output2_masked= model(data, data.masked_atom_indices)\n",
    "        \n",
    "        pred_node = linear_pred_atoms(node_repre2[data.masked_atom_indices])\n",
    "        loss_recon_node = criterion_recon(pred_node.float(), data.mask_node_label[:,0])\n",
    "\n",
    "    \n",
    "    if args.mask_edge:\n",
    "\n",
    "        # total_loss = loss + args.alpha * (loss_recon_node + loss_recon_edge)\n",
    "        # return pred, total_loss, loss, loss_recon_node, loss_recon_edge\n",
    "    \n",
    "    \n",
    "        total_loss = loss_recon_node + loss_recon_edge\n",
    "\n",
    "        return total_loss, loss_recon_node, loss_recon_edge, calc_acc(pred_node, data.mask_node_label[:,0]), calc_acc(pred_edge, mask_edge_label[:,0])\n",
    "    else:\n",
    "        \n",
    "        # total_loss = loss + args.alpha * loss_recon_node\n",
    "        # return pred, total_loss, loss, loss_recon_node, 0 \n",
    "    \n",
    "        total_loss = loss_recon_node\n",
    "        return total_loss, loss_recon_node, 0, calc_acc(pred_node, data.mask_node_label[:,0]),0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "e186794f-34b6-48d8-8e62-977bec846cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _step_test( model_list, data, n_iter):\n",
    "        # get the prediction\n",
    "\n",
    "        model, linear_pred_atoms, linear_pred_bonds = model_list\n",
    "\n",
    "        num_atom_type = 119\n",
    "        num_edge_type = 4\n",
    "\n",
    "        # get the prediction\n",
    "        node_rep, _ = model(data)  # [N,C]\n",
    "\n",
    "        for atom_idx in data.masked_atom_indices:\n",
    "            data[atom_idx] = torch.tensor([num_atom_type, 0]).to(device)\n",
    "\n",
    "\n",
    "        if args.mask_edge:\n",
    "\n",
    "\n",
    "          \n",
    "            node_rep_masked, output2_masked = model(data)\n",
    "\n",
    "            masked_edge_index = data.edge_index[:, data.connected_edge_indices]\n",
    "            \n",
    "\n",
    "            # edge_rep \n",
    "            edge_rep = node_rep_masked[masked_edge_index[0]] + node_rep_masked[masked_edge_index[1]]\n",
    "\n",
    "\n",
    "            pred_edge = linear_pred_bonds(edge_rep)\n",
    "\n",
    "            mask_edge_label = data.mask_edge_label.to(pred_edge.device)\n",
    "            loss_recon_edge = criterion_recon(pred_edge.float(),  mask_edge_label[:,0])\n",
    "\n",
    "            pred_node = linear_pred_atoms(node_rep_masked[data.masked_atom_indices])\n",
    "            loss_recon_node = criterion_recon(pred_node.float(), data.mask_node_label[:,0])\n",
    "\n",
    "            total_loss = loss_recon_node + loss_recon_edge\n",
    "\n",
    "            return total_loss, pred_node, data.mask_node_label[:,0], pred_edge, mask_edge_label[:,0]\n",
    "        \n",
    "        else:\n",
    "            node_rep_masked, output2_masked = model(data)\n",
    "\n",
    "            pred_node = linear_pred_atoms(node_rep_masked[data.masked_atom_indices])\n",
    "            loss_recon_node = criterion_recon(pred_node.float(), data.mask_node_label[:,0])\n",
    "\n",
    "\n",
    "            total_loss = loss_recon_node\n",
    "            \n",
    "            return total_loss, pred_node, data.mask_node_label[:,0], 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "ce1a6c9e-2b10-42af-968b-fd2f3888414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate( model_list, valid_loader):\n",
    "    model, linear_pred_atoms, linear_pred_bonds = model_list\n",
    "\n",
    "    predictions_node = []\n",
    "    labels_node = []\n",
    "    predictions_edge = []\n",
    "    labels_edge = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        linear_pred_atoms.eval()\n",
    "        linear_pred_bonds.eval()\n",
    "\n",
    "        valid_loss = 0.0\n",
    "        num_data = 0\n",
    "        for bn, data in enumerate(valid_loader):\n",
    "            data = data.to(device)\n",
    "\n",
    "            \n",
    "            if args.mask_edge:\n",
    "                loss, pred_node,mask_node_label0, pred_edge,mask_edge_label  = _step_test([model, linear_pred_atoms, linear_pred_bonds], data, bn)\n",
    "                labels_node.append(mask_node_label0)\n",
    "                predictions_node.append(pred_node)\n",
    "\n",
    "                labels_edge.append(mask_edge_label)\n",
    "                predictions_edge.append(pred_edge)\n",
    "\n",
    "            else:\n",
    "                loss, pred_node, mask_node_label0, _, _ = _step_test([model, linear_pred_atoms, linear_pred_bonds], data, bn)\n",
    "\n",
    "                labels_node.append(mask_node_label0)\n",
    "                predictions_node.append(pred_node)\n",
    "\n",
    "            valid_loss += loss.item() * data.y.size(0)\n",
    "            num_data += data.y.size(0)\n",
    "\n",
    "        valid_loss /= num_data\n",
    "    \n",
    "    model.train()\n",
    "    linear_pred_atoms.train()\n",
    "    linear_pred_bonds.train()\n",
    "\n",
    "\n",
    "    if args.mask_edge:\n",
    "\n",
    "        labels_edge = torch.cat(labels_edge, dim=0).cpu()\n",
    "        predictions_edge = torch.cat(predictions_edge, dim=0).cpu().detach()\n",
    "\n",
    "        labels_node = torch.cat(labels_node, dim=0).cpu()\n",
    "        predictions_node = torch.cat(predictions_node, dim=0).cpu().detach()\n",
    "\n",
    "\n",
    "        accuracy_edge = calc_acc(predictions_edge, labels_edge)\n",
    "\n",
    "        accuracy_node = calc_acc(predictions_node, labels_node)\n",
    "\n",
    "\n",
    "        print('Validation loss:', valid_loss, 'edge acc:', accuracy_edge, 'node acc:', accuracy_node)\n",
    "        return valid_loss, accuracy_node, accuracy_edge\n",
    "    \n",
    "    else:\n",
    "\n",
    "        labels_node = torch.cat(labels_node, dim=0).cpu()\n",
    "        predictions_node = torch.cat(predictions_node, dim=0).cpu().detach()\n",
    "\n",
    "       \n",
    "        accuracy_node = calc_acc(predictions_node, labels_node)\n",
    "\n",
    "        \n",
    "        print('Validation loss:', valid_loss,  'node acc:', accuracy_node)\n",
    "\n",
    "        return valid_loss, accuracy_node, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "c5531a68-1f36-429f-8381-853603308f07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 6.515361785888672 0.0 0\n",
      "0 50 1.0056777000427246 0.7000000476837158 0\n",
      "0 100 0.8398643732070923 0.829059898853302 0\n",
      "0 150 0.8264986276626587 0.6495726704597473 0\n",
      "Validation loss: 4.905419536501343 node acc: 0.42456555366516113\n",
      "1 29 0.539435625076294 0.8512396216392517 0\n",
      "1 79 0.6437013745307922 0.8048779964447021 0\n",
      "1 129 0.5222564339637756 0.8387096524238586 0\n",
      "Validation loss: 5.898368411593967 node acc: 0.27883097529411316\n",
      "2 8 0.42120078206062317 0.8181818127632141 0\n",
      "2 58 0.6859586834907532 0.8360655307769775 0\n",
      "2 108 0.6075225472450256 0.8114753365516663 0\n",
      "2 158 0.5723339915275574 0.8235294818878174 0\n",
      "Validation loss: 5.551160870936879 node acc: 0.38823065161705017\n",
      "3 37 0.5269142389297485 0.8080000281333923 0\n",
      "3 87 1.1834275722503662 0.7181817889213562 0\n",
      "3 137 0.7171190977096558 0.7583333849906921 0\n",
      "Validation loss: 7.756070594341434 node acc: 0.27764612436294556\n",
      "4 16 0.7202697396278381 0.7796609997749329 0\n",
      "4 66 0.5081861615180969 0.8461539149284363 0\n",
      "4 116 0.4191255271434784 0.8677685856819153 0\n",
      "4 166 0.5375659465789795 0.8480000495910645 0\n",
      "Validation loss: 7.359516461690267 node acc: 0.27843600511550903\n",
      "5 45 0.5736443996429443 0.8245614171028137 0\n",
      "5 95 0.45924484729766846 0.8730159401893616 0\n",
      "5 145 0.4433952569961548 0.9032257795333862 0\n",
      "Validation loss: 6.2068946849532995 node acc: 0.34913110733032227\n",
      "6 24 0.8233347535133362 0.7413793206214905 0\n",
      "6 74 0.7303069233894348 0.6960000395774841 0\n",
      "6 124 0.5680695176124573 0.8559321761131287 0\n",
      "Validation loss: 6.936265778123286 node acc: 0.3127962052822113\n",
      "7 3 0.40545377135276794 0.8916667103767395 0\n",
      "7 53 0.5483508110046387 0.8319328427314758 0\n",
      "7 103 0.4445044994354248 0.888888955116272 0\n",
      "7 153 0.47502240538597107 0.8706896305084229 0\n",
      "Validation loss: 5.142886967686882 node acc: 0.4490521252155304\n",
      "8 32 0.5503079295158386 0.8017241358757019 0\n",
      "8 82 0.5592263340950012 0.8500000238418579 0\n",
      "8 132 0.676699697971344 0.7433628439903259 0\n",
      "Validation loss: 8.794959904854757 node acc: 0.24091626703739166\n",
      "9 11 0.5199583172798157 0.8461539149284363 0\n",
      "9 61 0.4889172315597534 0.8512396216392517 0\n",
      "9 111 0.5342890620231628 0.8292682766914368 0\n",
      "9 161 0.6715102791786194 0.7642276287078857 0\n",
      "Validation loss: 7.691651673344841 node acc: 0.31990522146224976\n",
      "10 40 0.5624966025352478 0.8400000333786011 0\n",
      "10 90 0.5182458758354187 0.846774160861969 0\n",
      "10 140 0.5116642117500305 0.8429751992225647 0\n",
      "Validation loss: 8.809724467539647 node acc: 0.24052132666110992\n",
      "11 19 0.4901353716850281 0.8699186444282532 0\n",
      "11 69 0.5973970890045166 0.811965823173523 0\n",
      "11 119 0.48063164949417114 0.8960000276565552 0\n",
      "11 169 0.5867953300476074 0.8305084705352783 0\n",
      "Validation loss: 6.6647199273806566 node acc: 0.40205371379852295\n",
      "12 48 0.464511513710022 0.8547009229660034 0\n",
      "12 98 0.5916622877120972 0.8699186444282532 0\n",
      "12 148 0.36376285552978516 0.8790322542190552 0\n",
      "Validation loss: 9.905964597623948 node acc: 0.24170616269111633\n",
      "13 27 0.5814558267593384 0.8278688192367554 0\n",
      "13 77 0.5711405873298645 0.8474576473236084 0\n",
      "13 127 0.7275859117507935 0.8064515590667725 0\n",
      "Validation loss: 9.12585615414625 node acc: 0.26342812180519104\n",
      "14 6 0.5009207129478455 0.8492063879966736 0\n",
      "14 56 0.48638880252838135 0.8666667342185974 0\n",
      "14 106 0.5283785462379456 0.805084764957428 0\n",
      "14 156 0.5110720992088318 0.8250000476837158 0\n",
      "Validation loss: 8.170190827888355 node acc: 0.3139810562133789\n",
      "15 35 0.6631935834884644 0.811965823173523 0\n",
      "15 85 0.4900515675544739 0.8632479310035706 0\n",
      "15 135 0.47488436102867126 0.8583333492279053 0\n",
      "Validation loss: 6.939050769248204 node acc: 0.35979461669921875\n",
      "16 14 1.1067368984222412 0.5833333730697632 0\n",
      "16 64 0.6097556352615356 0.8264462351799011 0\n",
      "16 114 0.5285707712173462 0.8620689511299133 0\n",
      "16 164 0.545659601688385 0.8595041036605835 0\n",
      "Validation loss: 14.940332423873812 node acc: 0.06793048977851868\n",
      "17 43 0.47744956612586975 0.8739496469497681 0\n",
      "17 93 0.4466160833835602 0.8666667342185974 0\n",
      "17 143 0.4303596317768097 0.8617885708808899 0\n",
      "Validation loss: 10.674611186423498 node acc: 0.21721959114074707\n",
      "18 22 0.4159238636493683 0.8595041036605835 0\n",
      "18 72 0.48349010944366455 0.8661417365074158 0\n",
      "18 122 0.45973101258277893 0.8644067645072937 0\n",
      "Validation loss: 8.041803106229905 node acc: 0.31240126490592957\n",
      "19 1 0.3531668186187744 0.888888955116272 0\n",
      "19 51 0.3626173734664917 0.9032257795333862 0\n",
      "19 101 0.5734342932701111 0.8617885708808899 0\n",
      "19 151 0.49321815371513367 0.8181818127632141 0\n",
      "Validation loss: 5.4390566474513005 node acc: 0.44549763202667236\n",
      "20 30 0.4046458303928375 0.8706896305084229 0\n",
      "20 80 0.3307449519634247 0.9137930870056152 0\n",
      "20 130 0.5456163287162781 0.860655665397644 0\n",
      "Validation loss: 8.226038297017416 node acc: 0.3127962052822113\n",
      "21 9 0.37158459424972534 0.8934425711631775 0\n",
      "21 59 0.5029559135437012 0.8347107172012329 0\n",
      "21 109 0.8413514494895935 0.8181818127632141 0\n",
      "21 159 0.38679566979408264 0.8717949390411377 0\n",
      "Validation loss: 10.678455336052075 node acc: 0.19984202086925507\n",
      "22 38 0.41685912013053894 0.868852436542511 0\n",
      "22 88 0.358511745929718 0.9008263945579529 0\n",
      "22 138 0.5412670969963074 0.8205128908157349 0\n",
      "Validation loss: 9.715451234962508 node acc: 0.2551342844963074\n",
      "23 17 0.6083419322967529 0.8333333730697632 0\n",
      "23 67 0.3954465389251709 0.8695651888847351 0\n",
      "23 117 0.32197490334510803 0.9098359942436218 0\n",
      "23 167 0.4009896218776703 0.8991597294807434 0\n",
      "Validation loss: 8.365799680787918 node acc: 0.22867298126220703\n",
      "24 46 0.3388747572898865 0.9186991453170776 0\n",
      "24 96 0.5193687081336975 0.8245614171028137 0\n",
      "24 146 0.39670422673225403 0.8196721076965332 0\n",
      "Validation loss: 7.209567415783977 node acc: 0.32503950595855713\n",
      "25 25 0.45169439911842346 0.8487395644187927 0\n",
      "25 75 0.49504193663597107 0.8319328427314758 0\n",
      "25 125 0.423538476228714 0.8803419470787048 0\n",
      "Validation loss: 9.115518720526444 node acc: 0.27646130323410034\n",
      "26 4 0.4634557366371155 0.8571429252624512 0\n",
      "26 54 0.27926355600357056 0.9224137663841248 0\n",
      "26 104 0.3525840640068054 0.874015748500824 0\n",
      "26 154 0.3485127389431 0.8943089246749878 0\n",
      "Validation loss: 7.128068620001364 node acc: 0.36650869250297546\n",
      "27 33 0.713001012802124 0.7747747898101807 0\n",
      "27 83 0.38380587100982666 0.9075630903244019 0\n",
      "27 133 0.3940577805042267 0.8898305296897888 0\n",
      "Validation loss: 10.532558485778452 node acc: 0.24289099872112274\n",
      "28 12 0.5090174674987793 0.7863247990608215 0\n",
      "28 62 0.4333184063434601 0.8644067645072937 0\n",
      "28 112 0.4767552614212036 0.8684210777282715 0\n",
      "28 162 0.46091142296791077 0.8376069068908691 0\n",
      "Validation loss: 11.714126765379431 node acc: 0.18167456984519958\n",
      "29 41 0.32880041003227234 0.9090908765792847 0\n",
      "29 91 0.45679113268852234 0.8225806355476379 0\n",
      "29 141 0.4818410575389862 0.8803419470787048 0\n",
      "Validation loss: 7.431084741625869 node acc: 0.33372828364372253\n",
      "30 20 0.46135130524635315 0.8677685856819153 0\n",
      "30 70 0.3851009011268616 0.8407079577445984 0\n",
      "30 120 0.38073399662971497 0.8809524178504944 0\n",
      "30 170 0.38501566648483276 0.8942307829856873 0\n",
      "Validation loss: 7.776678651396991 node acc: 0.3507108986377716\n",
      "31 49 0.4242100715637207 0.8661417365074158 0\n",
      "31 99 0.44597113132476807 0.8583333492279053 0\n",
      "31 149 0.5418220162391663 0.8461539149284363 0\n",
      "Validation loss: 8.691492303770188 node acc: 0.334518164396286\n",
      "32 28 0.49593883752822876 0.8925619721412659 0\n",
      "32 78 0.5059095025062561 0.8655462861061096 0\n",
      "32 128 0.5427578687667847 0.8173912763595581 0\n",
      "Validation loss: 6.008616330330832 node acc: 0.4806477129459381\n",
      "33 7 0.5156388282775879 0.8416666984558105 0\n",
      "33 57 0.3516453504562378 0.8870967626571655 0\n",
      "33 107 0.3195871114730835 0.9098359942436218 0\n",
      "33 157 0.4302626848220825 0.8750000596046448 0\n",
      "Validation loss: 6.823082065024571 node acc: 0.4415481686592102\n",
      "34 36 0.48753753304481506 0.8512396216392517 0\n",
      "34 86 0.4312437176704407 0.8666667342185974 0\n",
      "34 136 0.39683982729911804 0.8833333849906921 0\n",
      "Validation loss: 11.470080300381309 node acc: 0.2239336520433426\n",
      "35 15 0.40745148062705994 0.8442622423171997 0\n",
      "35 65 0.45313408970832825 0.8515625 0\n",
      "35 115 0.4151504635810852 0.868852436542511 0\n",
      "35 165 0.3985447585582733 0.9075630903244019 0\n",
      "Validation loss: 7.237391443977579 node acc: 0.3601895868778229\n",
      "36 44 0.49510112404823303 0.8770491480827332 0\n",
      "36 94 0.5863398313522339 0.8407079577445984 0\n",
      "36 144 0.4818822145462036 0.8739496469497681 0\n",
      "Validation loss: 6.815221156293188 node acc: 0.39770931005477905\n",
      "37 23 0.33519071340560913 0.9180327653884888 0\n",
      "37 73 0.49291619658470154 0.8480000495910645 0\n",
      "37 123 0.4414873719215393 0.8823530077934265 0\n",
      "Validation loss: 10.985088775032445 node acc: 0.22669826447963715\n",
      "38 2 0.5387986302375793 0.8666667342185974 0\n",
      "38 52 0.4743351340293884 0.868852436542511 0\n",
      "38 102 0.41875219345092773 0.8699186444282532 0\n",
      "38 152 0.45953264832496643 0.8487395644187927 0\n",
      "Validation loss: 9.28604457252904 node acc: 0.3084518313407898\n",
      "39 31 0.513746440410614 0.8559321761131287 0\n",
      "39 81 1.1314640045166016 0.76106196641922 0\n",
      "39 131 0.4402826428413391 0.8750000596046448 0\n",
      "Validation loss: 9.721391175922594 node acc: 0.2855450212955475\n",
      "40 10 0.3631556034088135 0.888888955116272 0\n",
      "40 60 0.3612825870513916 0.8934425711631775 0\n",
      "40 110 0.42199280858039856 0.8442622423171997 0\n",
      "40 160 0.5454451441764832 0.7822580337524414 0\n",
      "Validation loss: 10.195761039243108 node acc: 0.2887045741081238\n",
      "41 39 0.4526757299900055 0.8536584973335266 0\n",
      "41 89 0.4230835735797882 0.8803419470787048 0\n",
      "41 139 0.42383310198783875 0.9051724076271057 0\n",
      "Validation loss: 5.493558755395008 node acc: 0.3613744080066681\n",
      "42 18 0.3703649938106537 0.8974359631538391 0\n",
      "42 68 0.45077890157699585 0.8421052694320679 0\n",
      "42 118 1.1041817665100098 0.7438015937805176 0\n",
      "42 168 0.35254591703414917 0.9026548862457275 0\n",
      "Validation loss: 6.148063071289955 node acc: 0.3724328577518463\n",
      "43 47 0.4297284781932831 0.8739496469497681 0\n",
      "43 97 0.40853363275527954 0.9009009003639221 0\n",
      "43 147 0.44550493359565735 0.8500000238418579 0\n",
      "Validation loss: 8.087852377640573 node acc: 0.32109004259109497\n",
      "44 26 0.5206433534622192 0.8429751992225647 0\n",
      "44 76 0.5729507803916931 0.8429751992225647 0\n",
      "44 126 0.5334116816520691 0.756302535533905 0\n",
      "Validation loss: 9.398421320998878 node acc: 0.29699841141700745\n",
      "45 5 0.35350900888442993 0.8879310488700867 0\n",
      "45 55 0.597117006778717 0.7933883666992188 0\n",
      "45 105 0.9305962324142456 0.7272726893424988 0\n",
      "45 155 0.6357438564300537 0.7711864709854126 0\n",
      "Validation loss: 11.06664182428728 node acc: 0.21879936754703522\n",
      "46 34 0.5768130421638489 0.8389830589294434 0\n",
      "46 84 0.44444310665130615 0.8833333849906921 0\n",
      "46 134 0.6756017208099365 0.7666667103767395 0\n",
      "Validation loss: 9.382833121115702 node acc: 0.274881511926651\n",
      "47 13 0.5042840838432312 0.8275861740112305 0\n",
      "47 63 0.3152303993701935 0.8925619721412659 0\n",
      "47 113 0.47026994824409485 0.8387096524238586 0\n",
      "47 163 0.45282843708992004 0.8699186444282532 0\n",
      "Validation loss: 11.677795499388935 node acc: 0.2263033241033554\n",
      "48 42 0.4166021943092346 0.8728813529014587 0\n",
      "48 92 0.42948058247566223 0.8620689511299133 0\n",
      "48 142 0.36624738574028015 0.9000000357627869 0\n",
      "Validation loss: 8.75728288170887 node acc: 0.2654028534889221\n",
      "49 21 0.4404294490814209 0.8706896305084229 0\n",
      "49 71 0.37048232555389404 0.8813559412956238 0\n",
      "49 121 0.4257729649543762 0.8305084705352783 0\n",
      "Validation loss: 7.306235324569613 node acc: 0.42812007665634155\n",
      "50 0 0.3618554174900055 0.9075630903244019 0\n",
      "50 50 0.5023422837257385 0.8559321761131287 0\n",
      "50 100 0.41577982902526855 0.8823530077934265 0\n",
      "50 150 0.42674708366394043 0.860655665397644 0\n",
      "Validation loss: 9.762703042281302 node acc: 0.309636652469635\n",
      "51 29 0.5125200748443604 0.8760330080986023 0\n",
      "51 79 0.4996505677700043 0.8220338821411133 0\n",
      "51 129 0.47077757120132446 0.8559321761131287 0\n",
      "Validation loss: 9.288284951483297 node acc: 0.26026856899261475\n",
      "52 8 0.35267776250839233 0.9067796468734741 0\n",
      "52 58 0.8221516013145447 0.71074378490448 0\n",
      "52 108 0.3687324821949005 0.9112902879714966 0\n",
      "52 158 0.62786465883255 0.8292682766914368 0\n",
      "Validation loss: 16.87022210282889 node acc: 0.10703001916408539\n",
      "53 37 0.3716682493686676 0.8837209343910217 0\n",
      "53 87 0.4670647382736206 0.8512396216392517 0\n",
      "53 137 0.47843417525291443 0.8571429252624512 0\n",
      "Validation loss: 10.529592079028749 node acc: 0.319510281085968\n",
      "54 16 0.4193120002746582 0.8536584973335266 0\n",
      "54 66 0.43525370955467224 0.7903225421905518 0\n",
      "54 116 0.7614925503730774 0.8114753365516663 0\n",
      "54 166 0.6340506076812744 0.8181818127632141 0\n",
      "Validation loss: 9.452012823339095 node acc: 0.32306477427482605\n",
      "55 45 0.41884511709213257 0.8790322542190552 0\n",
      "55 95 0.3178136944770813 0.9055117964744568 0\n",
      "55 145 0.3793642818927765 0.8771929740905762 0\n",
      "Validation loss: 11.16230613028097 node acc: 0.25592416524887085\n",
      "56 24 0.43062353134155273 0.8728813529014587 0\n",
      "56 74 0.3245029151439667 0.9067796468734741 0\n",
      "56 124 0.3654326796531677 0.9016392827033997 0\n",
      "Validation loss: 12.141577717853568 node acc: 0.3033175468444824\n",
      "57 3 0.5334450602531433 0.8455284237861633 0\n",
      "57 53 0.4290789067745209 0.8595041036605835 0\n",
      "57 103 0.32398489117622375 0.9237288236618042 0\n",
      "57 153 0.4757005572319031 0.8416666984558105 0\n",
      "Validation loss: 9.361024700410185 node acc: 0.40639811754226685\n",
      "58 32 0.4549068510532379 0.8739496469497681 0\n",
      "58 82 0.3590996563434601 0.8974359631538391 0\n",
      "58 132 0.2917023301124573 0.9291338324546814 0\n",
      "Validation loss: 9.078501514524048 node acc: 0.3297788202762604\n",
      "59 11 0.4721342623233795 0.8583333492279053 0\n",
      "59 61 0.4502463638782501 0.8487395644187927 0\n",
      "59 111 0.3103332817554474 0.9152542352676392 0\n",
      "59 161 0.4279616177082062 0.8739496469497681 0\n",
      "Validation loss: 11.380876663832636 node acc: 0.2369668185710907\n",
      "60 40 0.3702329397201538 0.8916667103767395 0\n",
      "60 90 0.38227391242980957 0.8717949390411377 0\n",
      "60 140 0.3919129967689514 0.8934425711631775 0\n",
      "Validation loss: 8.988817981809204 node acc: 0.29146918654441833\n",
      "61 19 0.42252764105796814 0.8790322542190552 0\n",
      "61 69 0.4731232821941376 0.8559321761131287 0\n",
      "61 119 0.5874654650688171 0.7881355881690979 0\n",
      "61 169 0.5373185276985168 0.8461539149284363 0\n",
      "Validation loss: 9.353171619058353 node acc: 0.24723538756370544\n",
      "62 48 0.5029243230819702 0.8264462351799011 0\n",
      "62 98 0.40496107935905457 0.8823530077934265 0\n",
      "62 148 0.6026037931442261 0.8305084705352783 0\n",
      "Validation loss: 9.989115734546505 node acc: 0.28751975297927856\n",
      "63 27 0.43089407682418823 0.8595041036605835 0\n",
      "63 77 0.34283217787742615 0.8992248177528381 0\n",
      "63 127 0.5110514760017395 0.8583333492279053 0\n",
      "Validation loss: 10.663124123511956 node acc: 0.2756713926792145\n",
      "64 6 0.3569791913032532 0.890756368637085 0\n",
      "64 56 0.3309275805950165 0.9016392827033997 0\n",
      "64 106 0.465293824672699 0.8387096524238586 0\n",
      "64 156 0.5376390814781189 0.8608695268630981 0\n",
      "Validation loss: 14.571557301526878 node acc: 0.1429699808359146\n",
      "65 35 0.4258710741996765 0.9008263945579529 0\n",
      "65 85 0.42198923230171204 0.8852458596229553 0\n",
      "65 135 0.42431777715682983 0.9016392827033997 0\n",
      "Validation loss: 10.380574449461106 node acc: 0.284755140542984\n",
      "66 14 0.44295230507850647 0.8898305296897888 0\n",
      "66 64 0.492811918258667 0.8389830589294434 0\n",
      "66 114 0.5398226976394653 0.8235294818878174 0\n",
      "66 164 0.547151505947113 0.8571429252624512 0\n",
      "Validation loss: 12.761938056053474 node acc: 0.24960505962371826\n",
      "67 43 0.5663876533508301 0.8706896305084229 0\n",
      "67 93 0.403493195772171 0.8760330080986023 0\n",
      "67 143 0.5385986566543579 0.8198198676109314 0\n",
      "Validation loss: 12.300532190423263 node acc: 0.29067930579185486\n",
      "68 22 0.4519033133983612 0.8655462861061096 0\n",
      "68 72 0.4198690950870514 0.8833333849906921 0\n",
      "68 122 0.3314579725265503 0.8632479310035706 0\n",
      "Validation loss: 5.24743765453149 node acc: 0.5308057069778442\n",
      "69 1 0.42777684330940247 0.8672566413879395 0\n",
      "69 51 0.4081084132194519 0.8750000596046448 0\n",
      "69 101 0.5606387257575989 0.8083333969116211 0\n",
      "69 151 0.47174686193466187 0.8448275923728943 0\n",
      "Validation loss: 7.056625892544351 node acc: 0.45063191652297974\n",
      "70 30 0.40629836916923523 0.8750000596046448 0\n",
      "70 80 0.2948361039161682 0.9152542352676392 0\n",
      "70 130 0.40812012553215027 0.8583333492279053 0\n",
      "Validation loss: 12.538878078349153 node acc: 0.27843600511550903\n",
      "71 9 0.4024043679237366 0.9130434393882751 0\n",
      "71 59 0.39624136686325073 0.9043477773666382 0\n",
      "71 109 0.5112403035163879 0.8130080699920654 0\n",
      "71 159 0.6167964339256287 0.7606837749481201 0\n",
      "Validation loss: 11.421057009557535 node acc: 0.2681674659252167\n",
      "72 38 0.5345283150672913 0.8362069129943848 0\n",
      "72 88 0.8458985090255737 0.7565217018127441 0\n",
      "72 138 0.4803188741207123 0.8416666984558105 0\n",
      "Validation loss: 11.82227473231087 node acc: 0.3281990587711334\n",
      "73 17 0.4146106541156769 0.8790322542190552 0\n",
      "73 67 0.41970741748809814 0.8803419470787048 0\n",
      "73 117 0.30805787444114685 0.9090908765792847 0\n",
      "73 167 0.4818749725818634 0.8813559412956238 0\n",
      "Validation loss: 12.40924812896907 node acc: 0.2669826149940491\n",
      "74 46 0.44490984082221985 0.8761062026023865 0\n",
      "74 96 0.45400291681289673 0.8387096524238586 0\n",
      "74 146 0.5810695290565491 0.7368420958518982 0\n",
      "Validation loss: 10.791175396121734 node acc: 0.3570300042629242\n",
      "75 25 0.3747209310531616 0.9000000357627869 0\n",
      "75 75 0.5349982380867004 0.7903225421905518 0\n",
      "75 125 0.4173738956451416 0.890756368637085 0\n",
      "Validation loss: 13.961873812982214 node acc: 0.22748814523220062\n",
      "76 4 0.3403007984161377 0.890756368637085 0\n",
      "76 54 0.5746697187423706 0.8387096524238586 0\n",
      "76 104 0.49563688039779663 0.8655462861061096 0\n",
      "76 154 0.37440723180770874 0.8934425711631775 0\n",
      "Validation loss: 11.890381930167216 node acc: 0.2804107367992401\n",
      "77 33 0.4885864853858948 0.8376069068908691 0\n",
      "77 83 0.3449414074420929 0.9105690717697144 0\n",
      "77 133 0.564683735370636 0.8157894611358643 0\n",
      "Validation loss: 10.494082099513003 node acc: 0.32187992334365845\n",
      "78 12 0.598605751991272 0.8416666984558105 0\n",
      "78 62 0.42288318276405334 0.890756368637085 0\n",
      "78 112 0.5166420340538025 0.8250000476837158 0\n",
      "78 162 0.8032467365264893 0.719298243522644 0\n",
      "Validation loss: 9.656316545274523 node acc: 0.3266192674636841\n",
      "79 41 0.5424147248268127 0.8319328427314758 0\n",
      "79 91 0.46829888224601746 0.8655462861061096 0\n",
      "79 141 0.4394402801990509 0.868852436542511 0\n",
      "Validation loss: 12.67386535733764 node acc: 0.18127961456775665\n",
      "80 20 0.32273468375205994 0.9256197810173035 0\n",
      "80 70 0.5759583711624146 0.834782600402832 0\n",
      "80 120 0.5221372246742249 0.846774160861969 0\n",
      "80 170 0.5410698652267456 0.8247422575950623 0\n",
      "Validation loss: 11.278635448879665 node acc: 0.2306477129459381\n",
      "81 49 0.4690876603126526 0.8548386693000793 0\n",
      "81 99 0.4555460512638092 0.8070175647735596 0\n",
      "81 149 0.4869821071624756 0.847328245639801 0\n",
      "Validation loss: 9.436270292739422 node acc: 0.35110583901405334\n",
      "82 28 0.5549998879432678 0.8389830589294434 0\n",
      "82 78 0.4126890003681183 0.8666667342185974 0\n",
      "82 128 0.4361349642276764 0.8644067645072937 0\n",
      "Validation loss: 10.1273819549739 node acc: 0.259873628616333\n",
      "83 7 0.37743327021598816 0.8983050584793091 0\n",
      "83 57 0.3587213456630707 0.8770491480827332 0\n",
      "83 107 0.5124869346618652 0.8461539149284363 0\n",
      "83 157 0.3512420952320099 0.8793103694915771 0\n",
      "Validation loss: 10.433060495476974 node acc: 0.3033175468444824\n",
      "84 36 0.39710164070129395 0.8536584973335266 0\n",
      "84 86 0.40946492552757263 0.8474576473236084 0\n",
      "84 136 0.3466605544090271 0.9090908765792847 0\n",
      "Validation loss: 12.19934778603894 node acc: 0.2740916311740875\n",
      "85 15 0.4410440921783447 0.8709677457809448 0\n",
      "85 65 0.4943774342536926 0.848214328289032 0\n",
      "85 115 0.4459305703639984 0.8655462861061096 0\n",
      "85 165 0.3700729012489319 0.888888955116272 0\n",
      "Validation loss: 8.976323576698526 node acc: 0.4123222827911377\n",
      "86 44 0.8501954078674316 0.6974790096282959 0\n",
      "86 94 0.41403770446777344 0.8833333849906921 0\n",
      "86 144 0.47738295793533325 0.834782600402832 0\n",
      "Validation loss: 10.758332720974035 node acc: 0.24170616269111633\n",
      "87 23 0.3601105213165283 0.8595041036605835 0\n",
      "87 73 0.3591880798339844 0.8974359631538391 0\n",
      "87 123 0.4452381730079651 0.8559321761131287 0\n",
      "Validation loss: 13.54727003867166 node acc: 0.18127961456775665\n",
      "88 2 0.42788460850715637 0.8677685856819153 0\n",
      "88 52 0.4069167971611023 0.8717949390411377 0\n",
      "88 102 0.4074898064136505 0.8373983502388 0\n",
      "88 152 0.36588066816329956 0.8852458596229553 0\n",
      "Validation loss: 11.56625497271443 node acc: 0.2898894250392914\n",
      "89 31 0.3763929605484009 0.8739496469497681 0\n",
      "89 81 0.3651157021522522 0.9230769872665405 0\n",
      "89 131 0.40440264344215393 0.8617885708808899 0\n",
      "Validation loss: 9.438627471700746 node acc: 0.40955767035484314\n",
      "90 10 0.480500191450119 0.8524589538574219 0\n",
      "90 60 0.45370030403137207 0.8524589538574219 0\n",
      "90 110 0.8682796359062195 0.7603305578231812 0\n",
      "90 160 0.4747418165206909 0.8305084705352783 0\n",
      "Validation loss: 13.025725950274552 node acc: 0.31556081771850586\n",
      "91 39 0.5213872790336609 0.8512396216392517 0\n",
      "91 89 0.537467896938324 0.8083333969116211 0\n",
      "91 139 0.471500039100647 0.8421052694320679 0\n",
      "Validation loss: 8.175111876593697 node acc: 0.4135071039199829\n",
      "92 18 0.3925851881504059 0.8500000238418579 0\n",
      "92 68 0.4564187526702881 0.8695651888847351 0\n",
      "92 118 0.3763485550880432 0.8870967626571655 0\n",
      "92 168 0.5065730810165405 0.8278688192367554 0\n",
      "Validation loss: 12.955439522949575 node acc: 0.190363347530365\n",
      "93 47 0.365294873714447 0.9024389982223511 0\n",
      "93 97 0.4553601145744324 0.8373983502388 0\n",
      "93 147 0.382688045501709 0.8661417365074158 0\n",
      "Validation loss: 11.73338033999616 node acc: 0.26658767461776733\n",
      "94 26 0.4047718644142151 0.8666667342185974 0\n",
      "94 76 0.3773767948150635 0.8974359631538391 0\n",
      "94 126 0.48618078231811523 0.8347107172012329 0\n",
      "Validation loss: 12.557644364429496 node acc: 0.3483412265777588\n",
      "95 5 0.30114391446113586 0.9098359942436218 0\n",
      "95 55 0.3514060080051422 0.8870967626571655 0\n",
      "95 105 0.3947385549545288 0.8666667342185974 0\n",
      "95 155 0.6451807022094727 0.8319328427314758 0\n",
      "Validation loss: 13.724846410472491 node acc: 0.3048973083496094\n",
      "96 34 0.45489537715911865 0.8275861740112305 0\n",
      "96 84 0.41804039478302 0.8991597294807434 0\n",
      "96 134 0.7508825659751892 0.7768594622612 0\n",
      "Validation loss: 10.493862969136378 node acc: 0.3676935136318207\n",
      "97 13 0.41441410779953003 0.8842974901199341 0\n",
      "97 63 0.46988916397094727 0.860655665397644 0\n",
      "97 113 0.6868792772293091 0.7983870506286621 0\n",
      "97 163 0.7760851383209229 0.7478260397911072 0\n",
      "Validation loss: 12.435833640963013 node acc: 0.2760663628578186\n",
      "98 42 0.36629006266593933 0.8943089246749878 0\n",
      "98 92 0.4739611744880676 0.8389830589294434 0\n",
      "98 142 0.4461477994918823 0.8617885708808899 0\n",
      "Validation loss: 13.671233829699064 node acc: 0.24921010434627533\n",
      "99 21 0.44679388403892517 0.8595041036605835 0\n",
      "99 71 0.4143941104412079 0.8761062026023865 0\n",
      "99 121 0.44900012016296387 0.860655665397644 0\n",
      "Validation loss: 13.096526614406653 node acc: 0.21366508305072784\n",
      "100 0 0.4838213324546814 0.8879310488700867 0\n",
      "100 50 0.6395065188407898 0.7692307829856873 0\n",
      "100 100 0.24575702846050262 0.9406779408454895 0\n",
      "100 150 0.36440497636795044 0.9180327653884888 0\n",
      "Validation loss: 12.737758340891341 node acc: 0.20853079855442047\n",
      "101 29 0.3943266272544861 0.8699186444282532 0\n",
      "101 79 0.5751197338104248 0.8644067645072937 0\n",
      "101 129 0.4263765215873718 0.8666667342185974 0\n",
      "Validation loss: 30.167680115727652 node acc: 0.009873617440462112\n",
      "102 8 0.4542081952095032 0.8750000596046448 0\n",
      "102 58 0.5553213357925415 0.8305084705352783 0\n",
      "102 108 0.4966104328632355 0.8421052694320679 0\n",
      "102 158 0.6920251250267029 0.7982456088066101 0\n",
      "Validation loss: 14.261143957662304 node acc: 0.26974722743034363\n",
      "103 37 0.4742944836616516 0.8842974901199341 0\n",
      "103 87 0.31497424840927124 0.9098359942436218 0\n",
      "103 137 0.4865478575229645 0.8620689511299133 0\n",
      "Validation loss: 10.204926317895366 node acc: 0.2804107367992401\n",
      "104 16 0.45451146364212036 0.8373983502388 0\n",
      "104 66 0.3462398648262024 0.8925619721412659 0\n",
      "104 116 0.7949023246765137 0.7863247990608215 0\n",
      "104 166 0.49246999621391296 0.8429751992225647 0\n",
      "Validation loss: 8.598067456518697 node acc: 0.33175355195999146\n",
      "105 45 0.6318140625953674 0.8360655307769775 0\n",
      "105 95 0.3286367654800415 0.9159664511680603 0\n",
      "105 145 0.3845742642879486 0.8620689511299133 0\n",
      "Validation loss: 13.390369861446626 node acc: 0.2239336520433426\n",
      "106 24 0.4043003022670746 0.8869564533233643 0\n",
      "106 74 0.3893203139305115 0.8739496469497681 0\n",
      "106 124 0.4212707281112671 0.8813559412956238 0\n",
      "Validation loss: 12.358218678256922 node acc: 0.3357030153274536\n",
      "107 3 0.3981955349445343 0.8548386693000793 0\n",
      "107 53 0.3787364363670349 0.8947368264198303 0\n",
      "107 103 0.4749487638473511 0.8320000171661377 0\n",
      "107 153 0.3208554685115814 0.9105690717697144 0\n",
      "Validation loss: 9.772222407380042 node acc: 0.35466036200523376\n",
      "108 32 0.5917525291442871 0.7815126180648804 0\n",
      "108 82 0.5864660739898682 0.7913042902946472 0\n",
      "108 132 0.4150305390357971 0.8739496469497681 0\n",
      "Validation loss: 11.346731632076509 node acc: 0.28830963373184204\n",
      "109 11 0.5647520422935486 0.8099173307418823 0\n",
      "109 61 0.49815720319747925 0.8196721076965332 0\n",
      "109 111 0.4069076180458069 0.8640000224113464 0\n",
      "109 161 0.40450969338417053 0.8666667342185974 0\n",
      "Validation loss: 13.62582228476541 node acc: 0.2555292248725891\n",
      "110 40 0.3555201590061188 0.8991597294807434 0\n",
      "110 90 0.3758501708507538 0.8739496469497681 0\n",
      "110 140 0.3603783845901489 0.9043477773666382 0\n",
      "Validation loss: 11.396937989352041 node acc: 0.36729857325553894\n",
      "111 19 0.46215012669563293 0.8319328427314758 0\n",
      "111 69 0.4316573143005371 0.8655462861061096 0\n",
      "111 119 0.43560031056404114 0.868852436542511 0\n",
      "111 169 0.5578046441078186 0.8362069129943848 0\n",
      "Validation loss: 12.68945907012761 node acc: 0.21998420357704163\n",
      "112 48 0.5520462989807129 0.7931034564971924 0\n",
      "112 98 0.4134223163127899 0.8828828930854797 0\n",
      "112 148 0.4808518588542938 0.8018018007278442 0\n",
      "Validation loss: 10.972027837184438 node acc: 0.365718811750412\n",
      "113 27 0.475850373506546 0.8699186444282532 0\n",
      "113 77 0.4261317253112793 0.8640000224113464 0\n",
      "113 127 0.46313372254371643 0.8500000238418579 0\n",
      "Validation loss: 12.982392344558448 node acc: 0.34241706132888794\n",
      "114 6 0.3337748050689697 0.9016392827033997 0\n",
      "114 56 0.4565788507461548 0.8521738648414612 0\n",
      "114 106 0.3551099896430969 0.890756368637085 0\n",
      "114 156 0.4208340346813202 0.8870967626571655 0\n",
      "Validation loss: 13.228950572989838 node acc: 0.2934439182281494\n",
      "115 35 0.5787813663482666 0.8103448152542114 0\n",
      "115 85 0.3123442232608795 0.9024389982223511 0\n",
      "115 135 1.0886931419372559 0.6495726704597473 0\n",
      "Validation loss: 9.706895384872169 node acc: 0.3159557580947876\n",
      "116 14 0.47460800409317017 0.7948718070983887 0\n",
      "116 64 0.514199435710907 0.8706896305084229 0\n",
      "116 114 0.3041839003562927 0.9166666865348816 0\n",
      "116 164 0.40612247586250305 0.8571429252624512 0\n",
      "Validation loss: 13.680526582818283 node acc: 0.18325434625148773\n",
      "117 43 0.5010977983474731 0.818965494632721 0\n",
      "117 93 0.45438188314437866 0.8655462861061096 0\n",
      "117 143 0.40798166394233704 0.8842974901199341 0\n",
      "Validation loss: 12.4914662099024 node acc: 0.20537124574184418\n",
      "118 22 0.4877072274684906 0.8376069068908691 0\n",
      "118 72 0.41081002354621887 0.8434782028198242 0\n",
      "118 122 0.5443349480628967 0.7863247990608215 0\n",
      "Validation loss: 15.701279233073631 node acc: 0.21445497870445251\n",
      "119 1 0.4029061794281006 0.8595041036605835 0\n",
      "119 51 0.380806028842926 0.8717949390411377 0\n",
      "119 101 0.5579944849014282 0.8595041036605835 0\n",
      "119 151 0.4305766224861145 0.860655665397644 0\n",
      "Validation loss: 17.311337621588457 node acc: 0.13270142674446106\n",
      "120 30 0.37192830443382263 0.8661417365074158 0\n",
      "120 80 0.421622097492218 0.8547009229660034 0\n",
      "120 130 0.4438417851924896 0.868852436542511 0\n",
      "Validation loss: 16.706061240525273 node acc: 0.1082148477435112\n",
      "121 9 0.6864469647407532 0.8260869383811951 0\n",
      "121 59 0.41888394951820374 0.8666667342185974 0\n",
      "121 109 0.39440643787384033 0.888888955116272 0\n",
      "121 159 0.4278734624385834 0.8480000495910645 0\n",
      "Validation loss: 10.708920261316132 node acc: 0.31674566864967346\n",
      "122 38 0.29798880219459534 0.9090908765792847 0\n",
      "122 88 0.4482390880584717 0.8706896305084229 0\n",
      "122 138 0.40941354632377625 0.8660714626312256 0\n",
      "Validation loss: 12.526284150909959 node acc: 0.2661927342414856\n",
      "123 17 0.41835424304008484 0.868852436542511 0\n",
      "123 67 0.8101212978363037 0.7698413133621216 0\n",
      "123 117 0.5894445180892944 0.8205128908157349 0\n",
      "123 167 0.40682801604270935 0.8666667342185974 0\n",
      "Validation loss: 12.447246314489353 node acc: 0.27093207836151123\n",
      "124 46 0.43624719977378845 0.8512396216392517 0\n",
      "124 96 0.4378182888031006 0.8629031777381897 0\n",
      "124 146 0.41758105158805847 0.8583333492279053 0\n",
      "Validation loss: 16.003448809796605 node acc: 0.13151659071445465\n",
      "125 25 0.3620617687702179 0.8813559412956238 0\n",
      "125 75 0.46399518847465515 0.8403362035751343 0\n",
      "125 125 0.38999614119529724 0.8897637724876404 0\n",
      "Validation loss: 16.416467822783176 node acc: 0.21366508305072784\n",
      "126 4 0.45746156573295593 0.829059898853302 0\n",
      "126 54 0.38827160000801086 0.8739496469497681 0\n",
      "126 104 0.35098421573638916 0.9016392827033997 0\n",
      "126 154 0.42093297839164734 0.888888955116272 0\n",
      "Validation loss: 13.366385565863716 node acc: 0.24170616269111633\n",
      "127 33 0.5579900741577148 0.8347107172012329 0\n",
      "127 83 0.5879215598106384 0.811965823173523 0\n",
      "127 133 0.43736180663108826 0.8956521153450012 0\n",
      "Validation loss: 13.626420188368412 node acc: 0.14849920570850372\n",
      "128 12 0.6157723069190979 0.8534482717514038 0\n",
      "128 62 0.4894082248210907 0.8376069068908691 0\n",
      "128 112 0.3878210484981537 0.9016392827033997 0\n",
      "128 162 0.21479910612106323 0.942148745059967 0\n",
      "Validation loss: 9.937507891515542 node acc: 0.38033175468444824\n",
      "129 41 0.47690990567207336 0.8292682766914368 0\n",
      "129 91 0.5750681161880493 0.8135592937469482 0\n",
      "129 141 0.371609628200531 0.8534482717514038 0\n",
      "Validation loss: 4.909654810414676 node acc: 0.5102685689926147\n",
      "130 20 0.5894345641136169 0.8416666984558105 0\n",
      "130 70 0.44354578852653503 0.8595041036605835 0\n",
      "130 120 0.4677852392196655 0.8250000476837158 0\n",
      "130 170 0.5559258460998535 0.8556700944900513 0\n",
      "Validation loss: 14.70896001447711 node acc: 0.10466034710407257\n",
      "131 49 0.3346739113330841 0.9051724076271057 0\n",
      "131 99 0.39546704292297363 0.8717949390411377 0\n",
      "131 149 0.3995063900947571 0.8660714626312256 0\n",
      "Validation loss: 11.914100027920908 node acc: 0.32187992334365845\n",
      "132 28 0.6044692993164062 0.8319328427314758 0\n",
      "132 78 0.4928602874279022 0.8360655307769775 0\n",
      "132 128 0.3400631844997406 0.9059829711914062 0\n",
      "Validation loss: 15.226872048182795 node acc: 0.2673775553703308\n",
      "133 7 0.40427494049072266 0.8655462861061096 0\n",
      "133 57 0.4941651523113251 0.8717949390411377 0\n",
      "133 107 0.4022972583770752 0.8620689511299133 0\n",
      "133 157 0.33181899785995483 0.8983050584793091 0\n",
      "Validation loss: 8.710526181940446 node acc: 0.38072669506073\n",
      "134 36 0.4748166799545288 0.8403362035751343 0\n",
      "134 86 0.49178874492645264 0.8376069068908691 0\n",
      "134 136 0.42387068271636963 0.8699186444282532 0\n",
      "Validation loss: 10.152866837574027 node acc: 0.3159557580947876\n",
      "135 15 0.4539429843425751 0.8559321761131287 0\n",
      "135 65 0.6074053049087524 0.7894737124443054 0\n",
      "135 115 0.4211750328540802 0.8492063879966736 0\n",
      "135 165 0.3620477318763733 0.890756368637085 0\n",
      "Validation loss: 12.899871268467596 node acc: 0.21484991908073425\n",
      "136 44 0.36945468187332153 0.890756368637085 0\n",
      "136 94 0.5491982102394104 0.7946428656578064 0\n",
      "136 144 0.5751025676727295 0.8461539149284363 0\n",
      "Validation loss: 18.025502199317977 node acc: 0.19312795996665955\n",
      "137 23 0.43049395084381104 0.8548386693000793 0\n",
      "137 73 0.5205193161964417 0.8373983502388 0\n",
      "137 123 0.3864057958126068 0.8739496469497681 0\n",
      "Validation loss: 12.517119424384937 node acc: 0.3226698338985443\n",
      "138 2 0.38230815529823303 0.8750000596046448 0\n",
      "138 52 0.4261525273323059 0.8861788511276245 0\n",
      "138 102 0.4291499853134155 0.8492063879966736 0\n",
      "138 152 0.4758482277393341 0.8461539149284363 0\n",
      "Validation loss: 16.719280443693464 node acc: 0.24802528321743011\n",
      "139 31 0.4153284430503845 0.868852436542511 0\n",
      "139 81 0.4716525971889496 0.8632479310035706 0\n",
      "139 131 0.39019572734832764 0.8728813529014587 0\n",
      "Validation loss: 15.60382420277735 node acc: 0.25473934412002563\n",
      "140 10 0.31934085488319397 0.9016392827033997 0\n",
      "140 60 0.39190438389778137 0.8934425711631775 0\n",
      "140 110 0.3852372467517853 0.8730159401893616 0\n",
      "140 160 0.49642133712768555 0.8166667222976685 0\n",
      "Validation loss: 16.808652587801394 node acc: 0.22472353279590607\n",
      "141 39 0.2875550091266632 0.9186991453170776 0\n",
      "141 89 0.5155619382858276 0.8559321761131287 0\n",
      "141 139 0.501578152179718 0.8166667222976685 0\n",
      "Validation loss: 16.161607190182334 node acc: 0.20497630536556244\n",
      "142 18 0.4327010214328766 0.8559321761131287 0\n",
      "142 68 0.406243234872818 0.8780487775802612 0\n",
      "142 118 0.4567406475543976 0.8181818127632141 0\n",
      "142 168 0.5305002927780151 0.8699186444282532 0\n",
      "Validation loss: 15.43568874381439 node acc: 0.20221169292926788\n",
      "143 47 0.351976603269577 0.8991597294807434 0\n",
      "143 97 0.42509469389915466 0.8750000596046448 0\n",
      "143 147 0.35446861386299133 0.8897637724876404 0\n",
      "Validation loss: 17.532250895137675 node acc: 0.23301738500595093\n",
      "144 26 0.4163949489593506 0.8709677457809448 0\n",
      "144 76 0.3845173418521881 0.8782608509063721 0\n",
      "144 126 0.4487256705760956 0.8770491480827332 0\n",
      "Validation loss: 14.682202746296486 node acc: 0.28317534923553467\n",
      "145 5 0.4507007598876953 0.8389830589294434 0\n",
      "145 55 0.3764760494232178 0.8823530077934265 0\n",
      "145 105 0.48263081908226013 0.8362069129943848 0\n",
      "145 155 0.3523252308368683 0.9152542352676392 0\n",
      "Validation loss: 17.889326954445643 node acc: 0.22156397998332977\n",
      "146 34 0.3334195017814636 0.8951612710952759 0\n",
      "146 84 0.4344431161880493 0.8559321761131287 0\n",
      "146 134 0.2739794850349426 0.9349592924118042 0\n",
      "Validation loss: 11.36675360607125 node acc: 0.37164297699928284\n",
      "147 13 0.48364096879959106 0.8103448152542114 0\n",
      "147 63 0.6478660106658936 0.7768594622612 0\n",
      "147 113 0.5272039771080017 0.8387096524238586 0\n",
      "147 163 0.36217474937438965 0.8852458596229553 0\n",
      "Validation loss: 15.824707544337937 node acc: 0.24052132666110992\n",
      "148 42 0.37154489755630493 0.9120000600814819 0\n",
      "148 92 0.41431036591529846 0.8695651888847351 0\n",
      "148 142 0.45030462741851807 0.8205128908157349 0\n",
      "Validation loss: 14.45941464385094 node acc: 0.32938387989997864\n",
      "149 21 0.34642425179481506 0.9000000357627869 0\n",
      "149 71 0.3788515031337738 0.8793103694915771 0\n",
      "149 121 0.5219821333885193 0.8275861740112305 0\n",
      "Validation loss: 17.433911585668373 node acc: 0.2859399616718292\n",
      "150 0 0.2825237810611725 0.9186991453170776 0\n",
      "150 50 0.3636986017227173 0.9083333611488342 0\n",
      "150 100 0.4073578715324402 0.8560000658035278 0\n",
      "150 150 0.257375568151474 0.9250000715255737 0\n",
      "Validation loss: 15.320872189705831 node acc: 0.33293840289115906\n",
      "151 29 0.3462264835834503 0.9047619700431824 0\n",
      "151 79 0.4504619836807251 0.8360655307769775 0\n",
      "151 129 0.41664591431617737 0.8644067645072937 0\n",
      "Validation loss: 17.60959810401961 node acc: 0.2314375936985016\n",
      "152 8 0.3765478730201721 0.868852436542511 0\n",
      "152 58 0.31037646532058716 0.9047619700431824 0\n",
      "152 108 0.3902534246444702 0.8655462861061096 0\n",
      "152 158 0.31081610918045044 0.9120000600814819 0\n",
      "Validation loss: 14.684008023892229 node acc: 0.3017377555370331\n",
      "153 37 0.5231661200523376 0.834782600402832 0\n",
      "153 87 0.38427966833114624 0.9090908765792847 0\n",
      "153 137 0.4465399384498596 0.8416666984558105 0\n",
      "Validation loss: 10.51556360791301 node acc: 0.365718811750412\n",
      "154 16 0.42441171407699585 0.8823530077934265 0\n",
      "154 66 0.4661613702774048 0.8474576473236084 0\n",
      "154 116 0.6122931838035583 0.7704917788505554 0\n",
      "154 166 0.6005504727363586 0.792792797088623 0\n",
      "Validation loss: 14.52309631325348 node acc: 0.2444707751274109\n",
      "155 45 0.5466130971908569 0.8392857313156128 0\n",
      "155 95 0.4284721910953522 0.8782608509063721 0\n",
      "155 145 0.3475501537322998 0.9032257795333862 0\n",
      "Validation loss: 18.79436631230583 node acc: 0.14257504045963287\n",
      "156 24 0.3658786714076996 0.8968254327774048 0\n",
      "156 74 0.4223079979419708 0.860655665397644 0\n",
      "156 124 0.3697413504123688 0.8503937125205994 0\n",
      "Validation loss: 12.94691090277064 node acc: 0.19431279599666595\n",
      "157 3 0.46217986941337585 0.8448275923728943 0\n",
      "157 53 0.4627911448478699 0.8429751992225647 0\n",
      "157 103 0.28958460688591003 0.9067796468734741 0\n",
      "157 153 0.36768969893455505 0.8823530077934265 0\n",
      "Validation loss: 13.22982643082825 node acc: 0.1860189586877823\n",
      "158 32 0.3434489369392395 0.9112902879714966 0\n",
      "158 82 0.42434966564178467 0.8803419470787048 0\n",
      "158 132 0.4275287091732025 0.8666667342185974 0\n",
      "Validation loss: 15.042349692673712 node acc: 0.17575038969516754\n",
      "159 11 0.4640246331691742 0.8595041036605835 0\n",
      "159 61 0.4306783974170685 0.8595041036605835 0\n",
      "159 111 0.5322802662849426 0.7966101765632629 0\n",
      "159 161 0.5162758827209473 0.8220338821411133 0\n",
      "Validation loss: 10.887785638284962 node acc: 0.3017377555370331\n",
      "160 40 0.33544227480888367 0.9075630903244019 0\n",
      "160 90 0.9596695899963379 0.6695652008056641 0\n",
      "160 140 0.3606421947479248 0.8870967626571655 0\n",
      "Validation loss: 22.54474768164562 node acc: 0.1330963671207428\n",
      "161 19 0.32821959257125854 0.9008263945579529 0\n",
      "161 69 0.4471781551837921 0.8461539149284363 0\n",
      "161 119 0.33441564440727234 0.8925619721412659 0\n",
      "161 169 0.3855668306350708 0.8880000710487366 0\n",
      "Validation loss: 11.254340177391008 node acc: 0.36966824531555176\n",
      "162 48 0.4042421877384186 0.874015748500824 0\n",
      "162 98 0.4535789489746094 0.8416666984558105 0\n",
      "162 148 0.36773717403411865 0.8870967626571655 0\n",
      "Validation loss: 19.39846201668009 node acc: 0.21366508305072784\n",
      "163 27 0.5785703063011169 0.8480000495910645 0\n",
      "163 77 0.3797048330307007 0.8684210777282715 0\n",
      "163 127 0.3223126232624054 0.8991597294807434 0\n",
      "Validation loss: 19.356186125013565 node acc: 0.20813585817813873\n",
      "164 6 0.34231749176979065 0.8869564533233643 0\n",
      "164 56 0.4097999632358551 0.8728813529014587 0\n",
      "164 106 0.4351269602775574 0.8278688192367554 0\n",
      "164 156 0.3755919635295868 0.8770491480827332 0\n",
      "Validation loss: 17.613641326190436 node acc: 0.24605055153369904\n",
      "165 35 0.4640529453754425 0.8620689511299133 0\n",
      "165 85 0.3452325761318207 0.9137930870056152 0\n",
      "165 135 1.1183745861053467 0.719008207321167 0\n",
      "Validation loss: 14.041036154094495 node acc: 0.3313586115837097\n",
      "166 14 0.4741286337375641 0.9016392827033997 0\n",
      "166 64 0.4795186519622803 0.8362069129943848 0\n",
      "166 114 0.5303472280502319 0.8495575189590454 0\n",
      "166 164 0.36121702194213867 0.9067796468734741 0\n",
      "Validation loss: 17.476096850389627 node acc: 0.23183254897594452\n",
      "167 43 0.4253954291343689 0.8699186444282532 0\n",
      "167 93 0.39111289381980896 0.8803419470787048 0\n",
      "167 143 0.42311233282089233 0.860655665397644 0\n",
      "Validation loss: 20.788210339016384 node acc: 0.2282780408859253\n",
      "168 22 0.4615499675273895 0.868852436542511 0\n",
      "168 72 0.5081486105918884 0.8220338821411133 0\n",
      "168 122 0.4933563470840454 0.8709677457809448 0\n",
      "Validation loss: 14.144712169267978 node acc: 0.26777252554893494\n",
      "169 1 0.2987227737903595 0.9243698120117188 0\n",
      "169 51 0.42168980836868286 0.8780487775802612 0\n",
      "169 101 0.452404260635376 0.8803419470787048 0\n",
      "169 151 0.3373101055622101 0.8925619721412659 0\n",
      "Validation loss: 16.956723949365447 node acc: 0.29818326234817505\n",
      "170 30 0.44169020652770996 0.8728813529014587 0\n",
      "170 80 0.43233343958854675 0.8699186444282532 0\n",
      "170 130 0.40650469064712524 0.8521738648414612 0\n",
      "Validation loss: 14.097220203332734 node acc: 0.2717219591140747\n",
      "171 9 0.41818732023239136 0.8760330080986023 0\n",
      "171 59 0.49261903762817383 0.8135592937469482 0\n",
      "171 109 0.3522547483444214 0.8880000710487366 0\n",
      "171 159 0.3223123550415039 0.9105690717697144 0\n",
      "Validation loss: 12.536572456359863 node acc: 0.33056873083114624\n",
      "172 38 0.4552117884159088 0.8196721076965332 0\n",
      "172 88 0.46991005539894104 0.8560000658035278 0\n",
      "172 138 1.2343380451202393 0.5655737519264221 0\n",
      "Validation loss: 15.051239917152806 node acc: 0.3353080451488495\n",
      "173 17 0.4058169722557068 0.8800000548362732 0\n",
      "173 67 0.46380963921546936 0.8739496469497681 0\n",
      "173 117 0.587864875793457 0.7652173638343811 0\n",
      "173 167 0.3629884123802185 0.8925619721412659 0\n",
      "Validation loss: 16.0747587527448 node acc: 0.2756713926792145\n",
      "174 46 0.6893155574798584 0.767241358757019 0\n",
      "174 96 0.590411901473999 0.8103448152542114 0\n",
      "174 146 0.391681045293808 0.8632479310035706 0\n",
      "Validation loss: 16.449825827838385 node acc: 0.2918641269207001\n",
      "175 25 0.46142342686653137 0.8474576473236084 0\n",
      "175 75 0.33064714074134827 0.888888955116272 0\n",
      "175 125 0.9943980574607849 0.7142857313156128 0\n",
      "Validation loss: 16.07189179024501 node acc: 0.3258293867111206\n",
      "176 4 0.35350602865219116 0.8914728760719299 0\n",
      "176 54 0.4619445204734802 0.8655462861061096 0\n",
      "176 104 0.47364580631256104 0.8512396216392517 0\n",
      "176 154 0.35996848344802856 0.8859649300575256 0\n",
      "Validation loss: 18.50560342219838 node acc: 0.21406003832817078\n",
      "177 33 0.4522809386253357 0.8455284237861633 0\n",
      "177 83 0.4598388075828552 0.8474576473236084 0\n",
      "177 133 0.4974033236503601 0.8250000476837158 0\n",
      "Validation loss: 16.666624325757834 node acc: 0.22235387563705444\n",
      "178 12 0.46834704279899597 0.8571429252624512 0\n",
      "178 62 0.34739023447036743 0.8916667103767395 0\n",
      "178 112 0.38384801149368286 0.9000000357627869 0\n",
      "178 162 0.5709892511367798 0.7962962985038757 0\n",
      "Validation loss: 15.84612098493074 node acc: 0.2523696720600128\n",
      "179 41 0.5063614249229431 0.8770491480827332 0\n",
      "179 91 0.32723572850227356 0.9152542352676392 0\n",
      "179 141 0.3000320494174957 0.9105690717697144 0\n",
      "Validation loss: 15.281453718218888 node acc: 0.23657187819480896\n",
      "180 20 0.41836854815483093 0.8617885708808899 0\n",
      "180 70 0.47070544958114624 0.8474576473236084 0\n",
      "180 120 0.6057981252670288 0.8114753365516663 0\n",
      "180 170 0.29444652795791626 0.9199999570846558 0\n",
      "Validation loss: 13.782453319482636 node acc: 0.3376777172088623\n",
      "181 49 0.37006744742393494 0.8916667103767395 0\n",
      "181 99 0.48929348587989807 0.8595041036605835 0\n",
      "181 149 0.3409554660320282 0.9075630903244019 0\n",
      "Validation loss: 17.21585003813805 node acc: 0.29502370953559875\n",
      "182 28 0.43826955556869507 0.8925619721412659 0\n",
      "182 78 0.309217244386673 0.9159664511680603 0\n",
      "182 128 0.43039119243621826 0.8571429252624512 0\n",
      "Validation loss: 11.245270500406187 node acc: 0.39454975724220276\n",
      "183 7 0.4418659806251526 0.8983050584793091 0\n",
      "183 57 0.4481995403766632 0.8487395644187927 0\n",
      "183 107 0.4599749445915222 0.829059898853302 0\n",
      "183 157 0.3869923949241638 0.8983050584793091 0\n",
      "Validation loss: 15.52050903387237 node acc: 0.32622432708740234\n",
      "184 36 0.4434475898742676 0.8582677245140076 0\n",
      "184 86 0.3196205496788025 0.888888955116272 0\n",
      "184 136 0.40909257531166077 0.8677685856819153 0\n",
      "Validation loss: 21.02991861488387 node acc: 0.2922590970993042\n",
      "185 15 0.36450788378715515 0.8803419470787048 0\n",
      "185 65 0.5482013821601868 0.8684210777282715 0\n",
      "185 115 0.6122060418128967 0.8048779964447021 0\n",
      "185 165 0.5769073367118835 0.8571429252624512 0\n",
      "Validation loss: 23.12068559970075 node acc: 0.17890995740890503\n",
      "186 44 0.3527366816997528 0.8813559412956238 0\n",
      "186 94 0.4322833716869354 0.8495575189590454 0\n",
      "186 144 0.3156532049179077 0.9256197810173035 0\n",
      "Validation loss: 20.112542866266264 node acc: 0.20813585817813873\n",
      "187 23 0.37076935172080994 0.8709677457809448 0\n",
      "187 73 0.4338109493255615 0.8793103694915771 0\n",
      "187 123 0.5736695528030396 0.8220338821411133 0\n",
      "Validation loss: 22.71097682930573 node acc: 0.24091626703739166\n",
      "188 2 0.5093337893486023 0.8547009229660034 0\n",
      "188 52 0.44917091727256775 0.8461539149284363 0\n",
      "188 102 0.42604437470436096 0.8595041036605835 0\n",
      "188 152 0.5990327000617981 0.8103448152542114 0\n",
      "Validation loss: 19.60644459027296 node acc: 0.20971563458442688\n",
      "189 31 0.4667603075504303 0.8376069068908691 0\n",
      "189 81 0.39282649755477905 0.8728813529014587 0\n",
      "189 131 0.44706088304519653 0.8717949390411377 0\n",
      "Validation loss: 14.166894823487041 node acc: 0.3052922487258911\n",
      "190 10 0.32794129848480225 0.8943089246749878 0\n",
      "190 60 0.5144823789596558 0.8245614171028137 0\n",
      "190 110 0.39402109384536743 0.860655665397644 0\n",
      "190 160 0.3556639850139618 0.890756368637085 0\n",
      "Validation loss: 25.2430416268912 node acc: 0.18562401831150055\n",
      "191 39 0.4716770350933075 0.8416666984558105 0\n",
      "191 89 0.3847738802433014 0.8861788511276245 0\n",
      "191 139 0.34789541363716125 0.8925619721412659 0\n",
      "Validation loss: 18.01402090864572 node acc: 0.26777252554893494\n",
      "192 18 0.6054242849349976 0.8250000476837158 0\n",
      "192 68 0.38510945439338684 0.890756368637085 0\n",
      "192 118 0.4459932744503021 0.8416666984558105 0\n",
      "192 168 0.27576297521591187 0.9344261884689331 0\n",
      "Validation loss: 17.292229211818405 node acc: 0.15323854982852936\n",
      "193 47 0.36731934547424316 0.8770491480827332 0\n",
      "193 97 0.2972647547721863 0.9186991453170776 0\n",
      "193 147 0.3984905779361725 0.8655462861061096 0\n",
      "Validation loss: 14.681976162202178 node acc: 0.25710901618003845\n",
      "194 26 0.4562966525554657 0.8521738648414612 0\n",
      "194 76 0.45815637707710266 0.8583333492279053 0\n",
      "194 126 0.4103437066078186 0.8595041036605835 0\n",
      "Validation loss: 17.998946574696323 node acc: 0.1741706132888794\n",
      "195 5 0.4128319323062897 0.8938053250312805 0\n",
      "195 55 0.4023747742176056 0.8750000596046448 0\n",
      "195 105 0.4389837384223938 0.8879310488700867 0\n",
      "195 155 0.4207899868488312 0.8617885708808899 0\n",
      "Validation loss: 16.21616106423718 node acc: 0.25394943356513977\n",
      "196 34 0.3388919532299042 0.9000000357627869 0\n",
      "196 84 0.3754003345966339 0.8870967626571655 0\n",
      "196 134 0.4548797011375427 0.8632479310035706 0\n",
      "Validation loss: 14.038788469214188 node acc: 0.3009478747844696\n",
      "197 13 0.4391533136367798 0.8677685856819153 0\n",
      "197 63 0.3659309446811676 0.8983050584793091 0\n",
      "197 113 0.4017193019390106 0.8495575189590454 0\n",
      "197 163 0.4565921425819397 0.8790322542190552 0\n",
      "Validation loss: 11.172625803808023 node acc: 0.3396524488925934\n",
      "198 42 0.4016873240470886 0.8373983502388 0\n",
      "198 92 0.569637656211853 0.8508772253990173 0\n",
      "198 142 0.37593889236450195 0.8943089246749878 0\n",
      "Validation loss: 15.600608569139625 node acc: 0.28515008091926575\n",
      "199 21 0.3576465845108032 0.8823530077934265 0\n",
      "199 71 0.48682332038879395 0.8559321761131287 0\n",
      "199 121 0.7368785738945007 0.7416667342185974 0\n",
      "Validation loss: 17.32351285254049 node acc: 0.2717219591140747\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "valid_n_iter = 0\n",
    "best_valid_loss = np.inf\n",
    "best_valid_rgr = np.inf\n",
    "best_valid_cls = 0\n",
    "\n",
    "# for epoch_counter in range(config['epochs']):\n",
    "for epoch_counter in range(200):\n",
    "    \n",
    "    for bn, data in enumerate(train_loader):\n",
    "        predictions = []\n",
    "        labels = []\n",
    "\n",
    "        optimizer_model.zero_grad()\n",
    "        optimizer_linear_pred_atoms.zero_grad()\n",
    "        if args.mask_edge:\n",
    "            optimizer_linear_pred_bonds.zero_grad()\n",
    "\n",
    "        data = data.to(device)\n",
    "        total_loss, loss_recon, loss_recon_edge, acc_node, acc_edge = _step(model_list, data, n_iter)\n",
    "\n",
    "        if n_iter % config['log_every_n_steps'] == 0:\n",
    "            # writer.add_scalar('loss_total/train', total_loss, global_step=n_iter)\n",
    "            writer.add_scalar('loss_total/train_loss_total', total_loss, epoch_counter)\n",
    "            writer.add_scalar('loss_recon_node/train_loss_recon_node', loss_recon, epoch_counter)\n",
    "            writer.add_scalar('loss_recon_edge/train_loss_recon_edge', loss_recon_edge, epoch_counter)\n",
    "            writer.add_scalar('accuracy/train_recon_node', acc_node, epoch_counter)\n",
    "            writer.add_scalar('accuracy/train_recon_edge', acc_edge, epoch_counter)\n",
    "\n",
    "\n",
    "\n",
    "            print(epoch_counter, bn, total_loss.item(), acc_node, acc_edge)\n",
    "\n",
    "        if apex_support and config['fp16_precision']:\n",
    "            with amp.scale_loss(total_loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            total_loss.backward()\n",
    "\n",
    "        optimizer_model.step()\n",
    "        optimizer_linear_pred_atoms.step()\n",
    "        if args.mask_edge:\n",
    "            optimizer_linear_pred_bonds.step()\n",
    "\n",
    "        n_iter += 1\n",
    "\n",
    "\n",
    "    # validate the model if requested\n",
    "    if epoch_counter % config['eval_every_n_epochs'] == 0:\n",
    "\n",
    "        valid_loss, valid_cls_node, valid_cls_edge  = _validate(model_list, valid_loader)\n",
    "        valid_cls = valid_cls_node + valid_cls_edge\n",
    "\n",
    "        if valid_cls > best_valid_cls:\n",
    "            # save the model weights\n",
    "            best_valid_cls = valid_cls\n",
    "            torch.save(model.state_dict(), os.path.join(model_checkpoints_folder, 'model.pth'))\n",
    "\n",
    "        writer.add_scalar('accuracy/validation', valid_cls, epoch_counter)\n",
    "\n",
    "        writer.add_scalar('loss_total/validation_loss_total', valid_loss, epoch_counter)\n",
    "        writer.add_scalar('accuracy/validation_recon_node', valid_cls_node, epoch_counter)\n",
    "        writer.add_scalar('accuracy/validation_recon_edge', valid_cls_edge, epoch_counter)\n",
    "\n",
    "        valid_n_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f9f9a3-e5f6-4c06-ae10-b1fad12c5280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "48fbeed4-1a0b-4424-9dab-4da50d5b1db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trained model with success.\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(writer.log_dir, 'checkpoints', 'model.pth')\n",
    "state_dict = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "print(\"Loaded trained model with success.\")\n",
    "\n",
    "num_atom_type = 119\n",
    "num_edge_type = 4\n",
    "\n",
    "predictions_node = []\n",
    "labels_node = []\n",
    "predictions_edge = []\n",
    "labels_edge = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "91b502d3-dc36-4eb0-b947-d70127ac78a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_atom_type = 119\n",
    "num_edge_type = 4\n",
    "\n",
    "predictions_node = []\n",
    "labels_node = []\n",
    "predictions_edge = []\n",
    "labels_edge = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    linear_pred_atoms.eval()\n",
    "    linear_pred_bonds.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36f1103-1f0e-4308-a845-f4f61e15ee2c",
   "metadata": {},
   "source": [
    "## test data 전체에 대해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "090dd750-c201-4908-84f2-6097ed44c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "# all_batches에 모든 배치를 리스트로 저장합니다.\n",
    "all_batches = []\n",
    "\n",
    "# train_loader로부터 배치를 가져와 리스트에 추가합니다.\n",
    "for batch in test_loader:\n",
    "    all_batches.append(batch)\n",
    "\n",
    "# 모든 배치를 하나로 합칩니다.\n",
    "merged_batch = Batch.from_data_list(all_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e39a9f42-e470-45f1-b40c-b77b1ba0384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_batch = merged_batch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9334cd6d-196a-4895-af06-8b8aed3c523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for atom_idx in merged_batch.masked_atom_indices:\n",
    "    merged_batch.x[atom_idx] = torch.tensor([num_atom_type, 0]).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2aeb973a-3ee7-402b-8618-5e547bef9a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.mask_edge:\n",
    "\n",
    "  \n",
    "    node_rep_masked, output2_masked = model(data)\n",
    "\n",
    "    masked_edge_index = data.edge_index[:, merged_batch.connected_edge_indices]\n",
    "    \n",
    "\n",
    "    # edge_rep \n",
    "    edge_rep = node_rep_masked[masked_edge_index[0]] + node_rep_masked[masked_edge_index[1]]\n",
    "\n",
    "\n",
    "    pred_edge = linear_pred_bonds(edge_rep)\n",
    "\n",
    "    mask_edge_label = data.mask_edge_label.to(pred_edge.device)\n",
    "    loss_recon_edge = criterion_recon(pred_edge.float(),  mask_edge_label[:,0])\n",
    "\n",
    "    pred_node = linear_pred_atoms(node_rep_masked[data.masked_atom_indices])\n",
    "    loss_recon_node = criterion_recon(pred_node.float(), data.mask_node_label[:,0])\n",
    "\n",
    "    total_loss = loss_recon_node + loss_recon_edge\n",
    "\n",
    "\n",
    "else:\n",
    "    node_rep_masked, output2_masked = model(data)\n",
    "\n",
    "    pred_node = linear_pred_atoms(node_rep_masked[merged_batch.masked_atom_indices])\n",
    "    loss_recon_node = criterion_recon(pred_node.float(), merged_batch.mask_node_label[:,0])\n",
    "\n",
    "\n",
    "    total_loss = loss_recon_node\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f1e98468-5a1e-4d92-b6b4-524580df5465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3657543361186981"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_node = calc_acc(pred_node, merged_batch.mask_node_label[:,0])\n",
    "accuracy_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bcbd40b8-e070-4636-9587-78ad5b62cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted_classes = torch.max(pred_node, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2dc37a4d-1ad4-4e43-8b62-4838741697e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = max(predicted_classes.max().item(), merged_batch.mask_node_label[:,0].max().item()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5d09de14-ff93-4179-93bc-3a44b2b19737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "43505382-5019-4e5e-a29b-c6f2e3ea4cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_classes = merged_batch.mask_node_label[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "cb479b74-9791-4027-a3a1-b59d5af67fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스의 수를 세기 위한 빈 리스트를 초기화\n",
    "predicted_count = [0] * num_classes\n",
    "actual_count = [0] * num_classes\n",
    "\n",
    "# 예측값의 횟수 세기\n",
    "for pred in predicted_classes:\n",
    "    predicted_count[pred.item()] += 1\n",
    "\n",
    "# 실제 정답값의 횟수 세기\n",
    "for actual in actual_classes:\n",
    "    actual_count[actual.item()] += 1\n",
    "\n",
    "# 막대그래프 그리기\n",
    "labels = np.arange(num_classes)  # 클래스 라벨\n",
    "\n",
    "x = np.arange(len(labels))  # x축 좌표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d0ae381c-0252-4307-8f77-a68298b776d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_labels = []\n",
    "filtered_predicted_count = []\n",
    "filtered_actual_count = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7ada89f9-67e3-4a58-8514-11b59a30a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_classes):\n",
    "    if predicted_count[i] != 0 or actual_count[i] != 0:\n",
    "        filtered_labels.append(i)\n",
    "        filtered_predicted_count.append(predicted_count[i])\n",
    "        filtered_actual_count.append(actual_count[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "531d5cf0-6604-4d5c-abfb-5b4673246266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 막대그래프 그리기\n",
    "x = np.arange(len(filtered_labels))  # x축 좌표\n",
    "width = 0.3  # 막대 너비\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, filtered_predicted_count, width, label='Predicted')\n",
    "rects2 = ax.bar(x + width/2, filtered_actual_count, width, label='Actual')\n",
    "\n",
    "# 그래프에 레이블 추가\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Predicted vs Actual Class Counts')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(filtered_labels)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9768fdd4-8593-4fff-b512-a04735ba8c35",
   "metadata": {},
   "source": [
    "## test data 하나씩1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "85ae59ac-cac0-4d40-82a2-0cdce37d2e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc_plot(pred, label):\n",
    "            # edge prediction   \n",
    "        _, predicted_classes = torch.max(pred, dim=1) # dim=1은 노드별로 최댓값을 찾음\n",
    "\n",
    "\n",
    "\n",
    "        correct_predictions = (predicted_classes == label)\n",
    "\n",
    "        accuracy = correct_predictions.float().mean().item()\n",
    "\n",
    "        plot_class_frequencies(predicted_classes, label)\n",
    "\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "def plot_class_frequencies(predicted_classes, label):\n",
    "    # Convert tensors to numpy arrays for plotting\n",
    "    predicted_classes = predicted_classes.numpy()\n",
    "    label = label.numpy()\n",
    "\n",
    "    # Get unique classes and their counts\n",
    "    classes = np.unique(np.concatenate((predicted_classes, label)))\n",
    "    pred_counts = [np.sum(predicted_classes == cls) for cls in classes]\n",
    "    label_counts = [np.sum(label == cls) for cls in classes]\n",
    "\n",
    "    # Set up the figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    \n",
    "    # Set the bar width\n",
    "    bar_width = 0.35\n",
    "    # Set the index for groups\n",
    "    index = np.arange(len(classes))\n",
    "\n",
    "    # Create bars for predicted and actual labels\n",
    "    ax.bar(index, pred_counts, bar_width, label='Predicted')\n",
    "    ax.bar(index + bar_width, label_counts, bar_width, label='Actual')\n",
    "\n",
    "    ax.set_xlabel('Classes')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title('Predicted vs Actual Class Frequencies')\n",
    "    ax.set_xticks(index + bar_width / 2)\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.legend()\n",
    "\n",
    "    # Save the plot to a file\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('class_frequencies.png')  # Saves the plot as a PNG file\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "5c269a84-62ec-42cd-b581-8df003d8e044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 7.892797851283239 MAE: 178.5118 edge acc: 0 node acc: 0.42409032583236694\n"
     ]
    }
   ],
   "source": [
    "num_atom_type = 119\n",
    "num_edge_type = 4\n",
    "\n",
    "predictions_node = []\n",
    "labels_node = []\n",
    "predictions_edge = []\n",
    "labels_edge = []\n",
    "\n",
    "\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    linear_pred_atoms.eval()\n",
    "    linear_pred_bonds.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    num_data = 0\n",
    "    for bn, data in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "\n",
    "        data_recon = data.clone()\n",
    "\n",
    "        if args.mask_edge:\n",
    "            loss, pred_node,mask_node_label0, pred_edge,mask_edge_label  = _step_test([model, linear_pred_atoms, linear_pred_bonds], data, bn)\n",
    "            labels_node.append(mask_node_label0)\n",
    "            predictions_node.append(pred_node)\n",
    "\n",
    "            labels_edge.append(mask_edge_label)\n",
    "            predictions_edge.append(pred_edge)\n",
    "\n",
    "        else:\n",
    "            loss, pred_node, mask_node_label0, _, _ = _step_test([model, linear_pred_atoms, linear_pred_bonds], data, bn)\n",
    "\n",
    "            labels_node.append(mask_node_label0)\n",
    "            predictions_node.append(pred_node)\n",
    "\n",
    "        test_loss += loss.item() * data.y.size(0)\n",
    "        num_data += data.y.size(0)\n",
    "\n",
    "    test_loss /= num_data\n",
    "\n",
    "if args.mask_edge:\n",
    "\n",
    "    labels_edge = torch.cat(labels_edge, dim=0).cpu()\n",
    "    predictions_edge = torch.cat(predictions_edge, dim=0).cpu().detach()\n",
    "\n",
    "    labels_node = torch.cat(labels_node, dim=0).cpu()\n",
    "    predictions_node = torch.cat(predictions_node, dim=0).cpu().detach()\n",
    "\n",
    "\n",
    "    accuracy_edge = calc_acc(predictions_edge, labels_edge)\n",
    "\n",
    "    accuracy_node = calc_acc_plot(predictions_node, labels_node)\n",
    "\n",
    "    acc_node = accuracy_node\n",
    "    acc_edge = accuracy_edge\n",
    "\n",
    "else:\n",
    "\n",
    "    labels_node = torch.cat(labels_node, dim=0).cpu()\n",
    "    predictions_node = torch.cat(predictions_node, dim=0).cpu().detach()\n",
    "\n",
    "    accuracy_node = calc_acc_plot(predictions_node, labels_node)\n",
    "    accuracy_edge = 0\n",
    "   \n",
    "\n",
    "    acc_node = accuracy_node\n",
    "    acc_edge = accuracy_edge\n",
    "\n",
    "\n",
    "_, pred = model(data)  # [N,C]  \n",
    "\n",
    "if normalizer: \n",
    "    pred = normalizer.denorm(pred)\n",
    "\n",
    "if config['dataset']['task'] == 'classification':\n",
    "    \n",
    "    labels.append(data.y.view(pred.shape))\n",
    "    predictions.append(pred)\n",
    "\n",
    "else:\n",
    "    if device == 'cpu':\n",
    "        predictions.extend(pred.detach().numpy())\n",
    "        labels.extend(data.y.flatten().numpy())\n",
    "    else:\n",
    "        predictions.extend(pred.cpu().detach().numpy())\n",
    "        labels.extend(data.y.cpu().flatten().numpy())\n",
    "\n",
    "if config['dataset']['task'] == 'regression':\n",
    "    predictions = np.array(predictions)\n",
    "    labels = np.array(labels)\n",
    "    if config['task_name'] in ['qm7', 'qm8', 'qm9']:\n",
    "        mae = mean_absolute_error(labels, predictions)\n",
    "        mae = mae\n",
    "        print('Test loss:', test_loss, 'MAE:', mae,  'edge acc:', accuracy_edge, 'node acc:', accuracy_node)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        rmse = root_mean_squared_error(labels, predictions, )\n",
    "        rmse = rmse\n",
    "\n",
    "        print('Test loss:', test_loss, 'RMSE:', rmse, 'edge acc:', accuracy_edge, 'node acc:', accuracy_node)\n",
    "\n",
    "\n",
    "elif config['dataset']['task'] == 'classification':\n",
    "    \n",
    "    labels = torch.cat(labels, dim=0).cpu().numpy()\n",
    "    predictions = torch.cat(predictions, dim=0).cpu().detach().numpy()\n",
    "\n",
    "    is_valid = labels**2 > 0\n",
    "    roc_auc = get_roc_auc_score(labels, predictions, is_valid)\n",
    "    roc_auc = roc_auc\n",
    "\n",
    "    print('Test loss:', test_loss, 'ROC AUC:', roc_auc, 'edge acc:', accuracy_edge, 'node acc:', accuracy_node)\n",
    "\n",
    "\n",
    "# model.train()\n",
    "# linear_pred_atoms.train()\n",
    "# linear_pred_bonds.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "223c9e56-1149-481a-b318-86ef0e40697b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5c44c86a-38e0-4e7e-ba1e-f416baba5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(test_loader)\n",
    "test = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "eeba09bf-923f-4718-b73b-83a2774b2a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572eba5b-4717-47e5-914e-ee4beb6f1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdchem import HybridizationType\n",
    "from rdkit.Chem.rdchem import BondType as BT\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Scaffolds.MurckoScaffold import MurckoScaffoldSmiles\n",
    "from rdkit import RDLogger\n",
    "\n",
    "ATOM_LIST = list(range(1,119))\n",
    "CHIRALITY_LIST = [\n",
    "    Chem.rdchem.ChiralType.CHI_UNSPECIFIED,\n",
    "    Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
    "    Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CCW,\n",
    "    Chem.rdchem.ChiralType.CHI_OTHER\n",
    "]\n",
    "BOND_LIST = [BT.SINGLE, BT.DOUBLE, BT.TRIPLE, BT.AROMATIC]\n",
    "BONDDIR_LIST = [\n",
    "    Chem.rdchem.BondDir.NONE,\n",
    "    Chem.rdchem.BondDir.ENDUPRIGHT,\n",
    "    Chem.rdchem.BondDir.ENDDOWNRIGHT\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "68434d95-81ac-45b6-a011-efc20bc833c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = Chem.MolFromSmiles(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aa1e47be-56b9-4f6d-bfe9-9951292938c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classification'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['dataset']['task']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "15328811-7d54-4c1c-99c3-8cd5891c7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "96833730-40f1-4d1c-a97a-7f331662960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm as core_tqdm\n",
    "from typing import List, Set, Tuple, Union, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "def onek_encoding_unk(value : int, choices: List[int]) -> List[int]:\n",
    "    \"\"\"\n",
    "        Creates a one-hot encoding.\n",
    "\n",
    "    :param value: The value for which the encoding should be one.\n",
    "    :param choices: A list of possible values.\n",
    "    :return: A one-hot encoding of the value in a list of length len(choices) + 1.\n",
    "    If value is not in the list of choices, then the final element in the encoding is 1.\n",
    "\n",
    "    \"\"\"\n",
    "    encoding = [0] * len(choices)\n",
    "    if value in choices:\n",
    "        encoding[choices.index(value)] = 1\n",
    "    else:\n",
    "        encoding[-1] = 1\n",
    "    return encoding\n",
    "\n",
    "# rich_feature로 사용할 feature\n",
    "ATOM_FEATURES = {\n",
    "    'atomic_num' : list(range(1, 119)),\n",
    "    'degree' : [0,1,2,3,4,5],\n",
    "    'formal_charge' : [0, -1, -2, 1, 2],\n",
    "    'chiral_tag' : [0,1,2,3],\n",
    "    'num_Hs' : [0,1,2,3,4],\n",
    "    'hybridization': [\n",
    "\n",
    "        Chem.rdchem.HybridizationType.SP,\n",
    "        Chem.rdchem.HybridizationType.SP2,\n",
    "        Chem.rdchem.HybridizationType.SP3,\n",
    "        Chem.rdchem.HybridizationType.SP3D,\n",
    "        Chem.rdchem.HybridizationType.SP3D2\n",
    "    ],\n",
    "}\n",
    "\n",
    "from descriptastorus.descriptors import rdDescriptors, rdNormalizedDescriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "da78c32a-8b3e-464f-8100-4a21a6495cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classification'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['dataset']['task']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d96329c3-d57a-49aa-a242-a46811bc2960",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = Chem.AddHs(mol)\n",
    "\n",
    "N = mol.GetNumAtoms()\n",
    "M = mol.GetNumBonds()\n",
    "\n",
    "type_idx = []\n",
    "chirality_idx = []\n",
    "atomic_number = []\n",
    "formal_charge = []\n",
    "total_numHs = []\n",
    "hybridzation = []\n",
    "aromatic = []\n",
    "mass = []\n",
    "\n",
    "implicitValence_list = []\n",
    "hydrogen_acceptor_match_list = []\n",
    "hydrogen_donor_match_list = []\n",
    "acidic_match_list = []\n",
    "basic_match_list = []\n",
    "ring_info_list = []\n",
    "\n",
    "degree = []\n",
    "\n",
    "\n",
    "hydrogen_donor = Chem.MolFromSmarts(\"[$([N;!H0;v3,v4&+1]),$([O,S;H1;+0]),n&H1&+0]\")\n",
    "hydrogen_acceptor = Chem.MolFromSmarts(\n",
    "    \"[$([O,S;H1;v2;!$(*-*=[O,N,P,S])]),$([O,S;H0;v2]),$([O,S;-]),$([N;v3;!$(N-*=[O,N,P,S])]),\"\n",
    "    \"n&H0&+0,$([o,s;+0;!$([o,s]:n);!$([o,s]:c:n)])]\")\n",
    "acidic = Chem.MolFromSmarts(\"[$([C,S](=[O,S,P])-[O;H1,-1])]\")\n",
    "basic = Chem.MolFromSmarts(\n",
    "    \"[#7;+,$([N;H2&+0][$([C,a]);!$([C,a](=O))]),$([N;H1&+0]([$([C,a]);!$([C,a](=O))])[$([C,a]);\"\n",
    "\"!$([C,a](=O))]),$([N;H0&+0]([C;!$(C(=O))])([C;!$(C(=O))])[C;!$(C(=O))])]\")\n",
    "\n",
    "\n",
    "for atom in mol.GetAtoms():\n",
    "    type_idx.append(ATOM_LIST.index(atom.GetAtomicNum()))\n",
    "    chirality_idx.append(CHIRALITY_LIST.index(atom.GetChiralTag()))\n",
    "    degree.append( onek_encoding_unk(atom.GetTotalDegree(), ATOM_FEATURES['degree']) )\n",
    "    formal_charge.append( onek_encoding_unk(atom.GetFormalCharge(), ATOM_FEATURES['formal_charge']) )\n",
    "    total_numHs.append( onek_encoding_unk(int(atom.GetTotalNumHs()), ATOM_FEATURES['num_Hs']) )\n",
    "    hybridzation.append( onek_encoding_unk(int(atom.GetHybridization()), ATOM_FEATURES['hybridization']) )\n",
    "    aromatic.append([1 if atom.GetIsAromatic() else 0])\n",
    "    mass.append([atom.GetMass() * 0.01])\n",
    "\n",
    "    atom_idx = atom.GetIdx()\n",
    "\n",
    "    hydrogen_donor_match = sum(mol.GetSubstructMatches(hydrogen_donor), ())\n",
    "    hydrogen_acceptor_match = sum(mol.GetSubstructMatches(hydrogen_acceptor), ())\n",
    "    acidic_match = sum(mol.GetSubstructMatches(acidic), ())\n",
    "    basic_match = sum(mol.GetSubstructMatches(basic), ())\n",
    "\n",
    "    implicitValence_list.append(onek_encoding_unk(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5, 6]))\n",
    "    hydrogen_acceptor_match_list.append([atom_idx in hydrogen_acceptor_match])\n",
    "    hydrogen_donor_match_list.append([atom_idx in hydrogen_donor_match])\n",
    "    acidic_match_list.append([atom_idx in acidic_match])\n",
    "    basic_match_list.append([atom_idx in basic_match])\n",
    "\n",
    "    ring_info = mol.GetRingInfo()\n",
    "    ring_info_list.append(                [ring_info.IsAtomInRingOfSize(atom_idx, 3),\n",
    "            ring_info.IsAtomInRingOfSize(atom_idx, 4),\n",
    "            ring_info.IsAtomInRingOfSize(atom_idx, 5),\n",
    "            ring_info.IsAtomInRingOfSize(atom_idx, 6),\n",
    "            ring_info.IsAtomInRingOfSize(atom_idx, 7),\n",
    "            ring_info.IsAtomInRingOfSize(atom_idx, 8)])\n",
    "                                   \n",
    "                   \n",
    "x1 = torch.tensor(type_idx, dtype=torch.long).view(-1, 1)\n",
    "x2 = torch.tensor(chirality_idx, dtype=torch.long).view(-1, 1)\n",
    "x3 = torch.tensor(degree, dtype=torch.long)\n",
    "x4 = torch.tensor(formal_charge, dtype=torch.long)\n",
    "x5 = torch.tensor(total_numHs, dtype=torch.long)\n",
    "x6 = torch.tensor(hybridzation, dtype=torch.long)\n",
    "x7 = torch.tensor(aromatic, dtype=torch.long)\n",
    "x8 = torch.tensor(mass, dtype=torch.float)\n",
    "\n",
    "x9 = torch.tensor(implicitValence_list, dtype=torch.long)\n",
    "x10 = torch.tensor(hydrogen_acceptor_match_list, dtype=torch.long)\n",
    "x11 = torch.tensor(hydrogen_donor_match_list, dtype=torch.long)\n",
    "x12 = torch.tensor(acidic_match_list, dtype=torch.long)\n",
    "x13 = torch.tensor(basic_match_list, dtype=torch.long)\n",
    "x14 = torch.tensor(ring_info_list, dtype=torch.long)\n",
    "\n",
    "\n",
    "x = torch.cat([x1, x2, x3, x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14], dim=1)\n",
    "\n",
    "row, col, edge_feat = [], [], []\n",
    "for bond in mol.GetBonds():\n",
    "    start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "    row += [start, end]\n",
    "    col += [end, start]\n",
    "    bt = bond.GetBondType()\n",
    "    feat1 = [\n",
    "        BOND_LIST.index(bond.GetBondType()),\n",
    "        BONDDIR_LIST.index(bond.GetBondDir()),\n",
    "        bond.GetIsConjugated() if bt is not None else 0,\n",
    "        bond.IsInRing() if bt is not None else 0,\n",
    "        *onek_encoding_unk(int(bond.GetStereo()), list(range(6)))\n",
    "    ]\n",
    "    edge_feat.append(feat1)\n",
    "\n",
    "    # 반대 방향의 엣지(또는 같은 특성을 반복) 특성 계산\n",
    "    # 여기서는 예시로 feat1을 그대로 사용합니다. 필요에 따라 다른 계산을 할 수 있습니다.\n",
    "    feat2 = feat1  # 또는 반대 방향에 대한 다른 계산 결과\n",
    "    edge_feat.append(feat2)\n",
    "        \n",
    "\n",
    "edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "edge_attr = torch.tensor(np.array(edge_feat), dtype=torch.long)\n",
    "if config['dataset']['task'] == 'classification':\n",
    "    y = torch.tensor(labels, dtype=torch.long).view(1,-1)\n",
    "elif config['dataset']['task'] == 'regression':\n",
    "    y = torch.tensor(labels * conversion, dtype=torch.float).view(1,-1)\n",
    "\n",
    "\n",
    "normalized_2d_generator = rdNormalizedDescriptors.RDKit2DNormalized()\n",
    "x_add = normalized_2d_generator.process(smiles)\n",
    "if x_add is None:\n",
    "    # x_add가 None인 경우, 처리 방식 결정\n",
    "    # 예: 빈 특성 리스트 또는 기본값 설정\n",
    "    print(f\"Warning: No features generated for SMILES: {smiles}\")\n",
    "    x_add = [] # 예시 기본값\n",
    "else:\n",
    "    # x_add를 텐서로 변환\n",
    "\n",
    "    x_add = torch.tensor(np.array(x_add[1:]), dtype=torch.long).view(1, -1)\n",
    "\n",
    "\n",
    "data = Data(x=x, y=y, edge_index=edge_index, edge_attr=edge_attr, x_add = x_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d29cf482-9dab-41c7-91d4-05392b6474b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dd5a1b1e-8670-44e9-837b-6780368a4b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.batch = torch.zeros(x.size(0), dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0cbe1e8d-a42e-4f98-a36b-8229cdfbece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_node, pred, node = model(data,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9eef16e4-5d55-4c06-b5f7-a48f153fd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = mol.GetNumAtoms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7fa8e531-f6f9-4b47-b10d-0b3151fd7b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rdkit.Chem import Draw\n",
    "\n",
    "img = Draw.MolToImage(mol, highlightAtoms=node.tolist())\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "pred_max_index = pred.detach().cpu().numpy().argmax()\n",
    "# 이미지에 텍스트 추가 (예측 결과와 실제 레이블)\n",
    "draw = ImageDraw.Draw(img)\n",
    "text = f\"Pred: {pred_max_index}, Label: {data.y.item()}\"\n",
    "draw.text((10, 10), text, fill=\"black\")\n",
    "\n",
    "# save_path = os.path.join(save_dir, f\"molecule_3mr.png\")\n",
    "# img.save(save_path)  # 파일 이름을 분자의 인덱스에 따라 지정\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbee979d-8bff-413e-96b4-e7e276fff528",
   "metadata": {},
   "source": [
    "## 파이썬 파일 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4b354065-c0d7-4b26-868d-1ac7377f8dfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'tox21', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'classification', 'data_path': 'data/tox21/tox21.csv', 'target': ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53']}}\n",
      "Running on: cuda:1\n",
      "3079\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/3079\n",
      "Generating scaffold 1000/3079\n",
      "Generating scaffold 2000/3079\n",
      "Generating scaffold 3000/3079\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 5.861543655395508\n",
      "0 50 1.028709888458252\n",
      "Validation loss: 0.18781258920570473 ROC AUC: 0.5875913697023415\n",
      "1 23 0.678257942199707\n",
      "1 73 0.4906783401966095\n",
      "Validation loss: 0.1856672273247273 ROC AUC: 0.6015072866995744\n",
      "2 46 0.6303895711898804\n",
      "Validation loss: 0.18399313053527436 ROC AUC: 0.6481495679735095\n",
      "3 19 0.36276742815971375\n",
      "3 69 0.2885846495628357\n",
      "Validation loss: 0.18235699174466072 ROC AUC: 0.7002781844372303\n",
      "4 42 0.3113635778427124\n",
      "Validation loss: 0.17947657445034423 ROC AUC: 0.7367003473635768\n",
      "5 15 0.19894316792488098\n",
      "5 65 0.1877320557832718\n",
      "Validation loss: 0.18151112152384474 ROC AUC: 0.741869423995421\n",
      "6 38 0.36431556940078735\n",
      "Validation loss: 0.17397557895678978 ROC AUC: 0.7235092281404601\n",
      "7 11 0.19684958457946777\n",
      "7 61 0.15392355620861053\n",
      "Validation loss: 0.17260799063490584 ROC AUC: 0.7528852375477483\n",
      "8 34 0.12430731952190399\n",
      "Validation loss: 0.17673060336670318 ROC AUC: 0.7395391208400882\n",
      "9 7 0.14984774589538574\n",
      "9 57 0.162988543510437\n",
      "Validation loss: 0.16789231226815807 ROC AUC: 0.7504340091177949\n",
      "10 30 0.2113928198814392\n",
      "Validation loss: 0.1670701401187228 ROC AUC: 0.7711515102773737\n",
      "11 3 0.14663207530975342\n",
      "11 53 0.15056899189949036\n",
      "Validation loss: 0.17328856749968094 ROC AUC: 0.7482932924418585\n",
      "12 26 0.14107197523117065\n",
      "12 76 0.13054639101028442\n",
      "Validation loss: 0.16767196666884732 ROC AUC: 0.7496334778888386\n",
      "13 49 0.18980705738067627\n",
      "Validation loss: 0.16900489430922966 ROC AUC: 0.7714110214452475\n",
      "14 22 0.13264386355876923\n",
      "14 72 0.19090841710567474\n",
      "Validation loss: 0.18256094664722294 ROC AUC: 0.7043285657833698\n",
      "15 45 0.20162354409694672\n",
      "Validation loss: 0.16693824007139577 ROC AUC: 0.7512208613497199\n",
      "16 18 0.11543639004230499\n",
      "16 68 0.11850738525390625\n",
      "Validation loss: 0.16838745821218987 ROC AUC: 0.7396908915717654\n",
      "17 41 0.1408734768629074\n",
      "Validation loss: 0.1651639626784758 ROC AUC: 0.7463979899265741\n",
      "18 14 0.12511876225471497\n",
      "18 64 0.12492719292640686\n",
      "Validation loss: 0.16350215402516452 ROC AUC: 0.7644962684997467\n",
      "19 37 0.14457736909389496\n",
      "Validation loss: 0.15895161555184947 ROC AUC: 0.7639958052678661\n",
      "20 10 0.18950942158699036\n",
      "20 60 0.1294490247964859\n",
      "Validation loss: 0.16141002112394803 ROC AUC: 0.7477784402745887\n",
      "21 33 0.07488719373941422\n",
      "Validation loss: 0.16193604391890687 ROC AUC: 0.7583273726618597\n",
      "22 6 0.1732499599456787\n",
      "22 56 0.08224021643400192\n",
      "Validation loss: 0.16429714916588425 ROC AUC: 0.7521559708800849\n",
      "23 29 0.1449672281742096\n",
      "Validation loss: 0.16146279194138266 ROC AUC: 0.7526040061909822\n",
      "24 2 0.13211137056350708\n",
      "24 52 0.08812994509935379\n",
      "Validation loss: 0.16204202755705102 ROC AUC: 0.7563553928655723\n",
      "25 25 0.10653525590896606\n",
      "25 75 0.10557305812835693\n",
      "Validation loss: 0.16515552978236953 ROC AUC: 0.745859874768967\n",
      "26 48 0.07768576592206955\n",
      "Validation loss: 0.16186718255668492 ROC AUC: 0.7370352163114999\n",
      "27 21 0.13708461821079254\n",
      "27 71 0.10643918812274933\n",
      "Validation loss: 0.16464980585234507 ROC AUC: 0.732419974269057\n",
      "28 44 0.16620001196861267\n",
      "Validation loss: 0.16117362697403154 ROC AUC: 0.7546414186528834\n",
      "29 17 0.10863201320171356\n",
      "29 67 0.08922281116247177\n",
      "Validation loss: 0.16008476080832543 ROC AUC: 0.7398525828586894\n",
      "30 40 0.0858013778924942\n",
      "Validation loss: 0.15759602053598923 ROC AUC: 0.7353545169742167\n",
      "31 13 0.22998708486557007\n",
      "31 63 0.09412772208452225\n",
      "Validation loss: 0.16814591280825728 ROC AUC: 0.7208515599642866\n",
      "32 36 0.09168383479118347\n",
      "Validation loss: 0.17317882644665705 ROC AUC: 0.7364672455913704\n",
      "33 9 0.10733316093683243\n",
      "33 59 0.18649691343307495\n",
      "Validation loss: 0.1638335690095827 ROC AUC: 0.7402588279035474\n",
      "34 32 0.11904029548168182\n",
      "Validation loss: 0.16297434154268983 ROC AUC: 0.7277530491473808\n",
      "35 5 0.06947200000286102\n",
      "35 55 0.11412696540355682\n",
      "Validation loss: 0.16405043276873502 ROC AUC: 0.7246200906784486\n",
      "36 28 0.18571187555789948\n",
      "Validation loss: 0.1594109320408338 ROC AUC: 0.7407611348538773\n",
      "37 1 0.11569824069738388\n",
      "37 51 0.0893017128109932\n",
      "Validation loss: 0.16250442761879463 ROC AUC: 0.7406881568383826\n",
      "38 24 0.09072739630937576\n",
      "38 74 0.12378300726413727\n",
      "Validation loss: 0.15998869418323813 ROC AUC: 0.7423546483538582\n",
      "39 47 0.148135244846344\n",
      "Validation loss: 0.1778089079957504 ROC AUC: 0.7455611557458437\n",
      "40 20 0.11488749831914902\n",
      "40 70 0.15416501462459564\n",
      "Validation loss: 0.17137532071633774 ROC AUC: 0.7319082259983652\n",
      "41 43 0.07888966798782349\n",
      "Validation loss: 0.16109521609622163 ROC AUC: 0.7618481752684726\n",
      "42 16 0.069098100066185\n",
      "42 66 0.06492426991462708\n",
      "Validation loss: 0.1653964604650225 ROC AUC: 0.7434834656403974\n",
      "43 39 0.10253260284662247\n",
      "Validation loss: 0.17847519435665823 ROC AUC: 0.7225089510006016\n",
      "44 12 0.10857658088207245\n",
      "44 62 0.161362886428833\n",
      "Validation loss: 0.166410212779974 ROC AUC: 0.7474270574378082\n",
      "45 35 0.17911824584007263\n",
      "Validation loss: 0.16227229539450114 ROC AUC: 0.7498302865538768\n",
      "46 8 0.16255956888198853\n",
      "46 58 0.16049724817276\n",
      "Validation loss: 0.1667061871909476 ROC AUC: 0.7324760293100566\n",
      "47 31 0.06964831054210663\n",
      "Validation loss: 0.17216914447097034 ROC AUC: 0.7413307703685715\n",
      "48 4 0.12188124656677246\n",
      "48 54 0.11859602481126785\n",
      "Validation loss: 0.16887907529032076 ROC AUC: 0.734519141586026\n",
      "49 27 0.06203276291489601\n",
      "Validation loss: 0.16616757117308578 ROC AUC: 0.7469941293355102\n",
      "50 0 0.12057512998580933\n",
      "50 50 0.09623449295759201\n",
      "Validation loss: 0.16883230964084725 ROC AUC: 0.7191254659858649\n",
      "51 23 0.07879484444856644\n",
      "51 73 0.13012295961380005\n",
      "Validation loss: 0.1715626586954315 ROC AUC: 0.7299079227553954\n",
      "52 46 0.11872982978820801\n",
      "Validation loss: 0.16057094883222084 ROC AUC: 0.7430503788151711\n",
      "53 19 0.10610616207122803\n",
      "53 69 0.03930778428912163\n",
      "Validation loss: 0.16605969179760327 ROC AUC: 0.7341871599003752\n",
      "54 42 0.10182669758796692\n",
      "Validation loss: 0.1645692281134717 ROC AUC: 0.7471732533079954\n",
      "55 15 0.13987475633621216\n",
      "55 65 0.08048359304666519\n",
      "Validation loss: 0.16700463306594204 ROC AUC: 0.7368474837190289\n",
      "56 38 0.08358301967382431\n",
      "Validation loss: 0.1644685028435348 ROC AUC: 0.7337141775465694\n",
      "57 11 0.08279726654291153\n",
      "57 61 0.09120407700538635\n",
      "Validation loss: 0.16988117818708542 ROC AUC: 0.7271677946199594\n",
      "58 34 0.0934469997882843\n",
      "Validation loss: 0.17539221899850027 ROC AUC: 0.7214629707257122\n",
      "59 7 0.08210819214582443\n",
      "59 57 0.07923472672700882\n",
      "Validation loss: 0.17219602810097978 ROC AUC: 0.7180661421477086\n",
      "60 30 0.1794670671224594\n",
      "Validation loss: 0.17619567983723305 ROC AUC: 0.7223899952558569\n",
      "61 3 0.13303832709789276\n",
      "61 53 0.08739478886127472\n",
      "Validation loss: 0.17393310116483018 ROC AUC: 0.724643585738448\n",
      "62 26 0.07930329442024231\n",
      "62 76 0.07838031649589539\n",
      "Validation loss: 0.17165536636655981 ROC AUC: 0.7448649318342352\n",
      "63 49 0.0844235047698021\n",
      "Validation loss: 0.18174887690451239 ROC AUC: 0.7079499278994241\n",
      "64 22 0.0871543139219284\n",
      "64 72 0.14181534945964813\n",
      "Validation loss: 0.1837674319357067 ROC AUC: 0.7090666022044708\n",
      "65 45 0.09784413874149323\n",
      "Validation loss: 0.17425161619465074 ROC AUC: 0.7120877620590552\n",
      "66 18 0.14340922236442566\n",
      "66 68 0.08319837599992752\n",
      "Validation loss: 0.16955298746561076 ROC AUC: 0.7253223764011977\n",
      "67 41 0.0711607038974762\n",
      "Validation loss: 0.16659888779962218 ROC AUC: 0.7096550414224764\n",
      "68 14 0.06664585322141647\n",
      "68 64 0.1191835105419159\n",
      "Validation loss: 0.18176231039808943 ROC AUC: 0.7194299208812005\n",
      "69 37 0.0790078267455101\n",
      "Validation loss: 0.18259362470019946 ROC AUC: 0.7125460045048725\n",
      "70 10 0.07096268236637115\n",
      "70 60 0.11346236616373062\n",
      "Validation loss: 0.18164016093526567 ROC AUC: 0.7026364055829118\n",
      "71 33 0.1281498819589615\n",
      "Validation loss: 0.17734415190560476 ROC AUC: 0.7095629794284258\n",
      "72 6 0.059085797518491745\n",
      "72 56 0.12919257581233978\n",
      "Validation loss: 0.16731434847627366 ROC AUC: 0.7507589748238944\n",
      "73 29 0.11162053048610687\n",
      "Validation loss: 0.16792573025087257 ROC AUC: 0.7213165488986314\n",
      "74 2 0.07765255868434906\n",
      "74 52 0.11184171587228775\n",
      "Validation loss: 0.1788891085556575 ROC AUC: 0.7299600958532203\n",
      "75 25 0.10236290842294693\n",
      "75 75 0.07128774374723434\n",
      "Validation loss: 0.17366682360698651 ROC AUC: 0.7095017187864733\n",
      "76 48 0.03826058655977249\n",
      "Validation loss: 0.17418946093553073 ROC AUC: 0.7351526922533084\n",
      "77 21 0.13868504762649536\n",
      "77 71 0.10512606054544449\n",
      "Validation loss: 0.17366955090652814 ROC AUC: 0.7131692550334314\n",
      "78 44 0.048237331211566925\n",
      "Validation loss: 0.19451126901360302 ROC AUC: 0.7005479560988112\n",
      "79 17 0.1270172894001007\n",
      "79 67 0.09059766680002213\n",
      "Validation loss: 0.20101944521650092 ROC AUC: 0.694571591151488\n",
      "80 40 0.12885718047618866\n",
      "Validation loss: 0.17918386649001727 ROC AUC: 0.7388995570605195\n",
      "81 13 0.10603605210781097\n",
      "81 63 0.0625365599989891\n",
      "Validation loss: 0.17566562279478296 ROC AUC: 0.734051307916725\n",
      "82 36 0.1036774218082428\n",
      "Validation loss: 0.17449320446361194 ROC AUC: 0.730742801510253\n",
      "83 9 0.0749785453081131\n",
      "83 59 0.10799311846494675\n",
      "Validation loss: 0.17770267674675236 ROC AUC: 0.7273436405317842\n",
      "84 32 0.051578763872385025\n",
      "Validation loss: 0.17620565074604827 ROC AUC: 0.7184805664715744\n",
      "85 5 0.07053644955158234\n",
      "85 55 0.11553959548473358\n",
      "Validation loss: 0.18909027978971407 ROC AUC: 0.7191919426980417\n",
      "86 28 0.08224905282258987\n",
      "Validation loss: 0.17651286798638183 ROC AUC: 0.7292782587800283\n",
      "87 1 0.10471947491168976\n",
      "87 51 0.0746752917766571\n",
      "Validation loss: 0.17821001929122132 ROC AUC: 0.736628770383727\n",
      "88 24 0.08559928834438324\n",
      "88 74 0.0825217068195343\n",
      "Validation loss: 0.171485047061722 ROC AUC: 0.7429294494252984\n",
      "89 47 0.07305978238582611\n",
      "Validation loss: 0.18291523742985416 ROC AUC: 0.717237882013738\n",
      "90 20 0.08430146425962448\n",
      "90 70 0.061214420944452286\n",
      "Validation loss: 0.1755380579209947 ROC AUC: 0.7249278143813077\n",
      "91 43 0.06289210915565491\n",
      "Validation loss: 0.18805120014525079 ROC AUC: 0.713697343610816\n",
      "92 16 0.08768655359745026\n",
      "92 66 0.09260834753513336\n",
      "Validation loss: 0.20167412976552915 ROC AUC: 0.7091112537192519\n",
      "93 39 0.11788556724786758\n",
      "Validation loss: 0.18541263750234208 ROC AUC: 0.7402273414199295\n",
      "94 12 0.04611679166555405\n",
      "94 62 0.10634180158376694\n",
      "Validation loss: 0.18972222700521543 ROC AUC: 0.6986766754627242\n",
      "95 35 0.10015364736318588\n",
      "Validation loss: 0.17378768082950022 ROC AUC: 0.7397320055350485\n",
      "96 8 0.08752080053091049\n",
      "96 58 0.13436979055404663\n",
      "Validation loss: 0.18494938197848085 ROC AUC: 0.7168864464450945\n",
      "97 31 0.09579557180404663\n",
      "Validation loss: 0.1907377622344277 ROC AUC: 0.7130692404052699\n",
      "98 4 0.09311018884181976\n",
      "98 54 0.15997515618801117\n",
      "Validation loss: 0.18335212747772017 ROC AUC: 0.7346313945864877\n",
      "99 27 0.08250805735588074\n",
      "Validation loss: 0.20086085312552265 ROC AUC: 0.6905223922851617\n",
      "100 0 0.13397665321826935\n",
      "100 50 0.07128030806779861\n",
      "Validation loss: 0.1865153850673081 ROC AUC: 0.7242326420568337\n",
      "101 23 0.11465729027986526\n",
      "101 73 0.04022819921374321\n",
      "Validation loss: 0.1939519260610853 ROC AUC: 0.7299122526734236\n",
      "102 46 0.15474969148635864\n",
      "Validation loss: 0.18806923858144067 ROC AUC: 0.7169995792814\n",
      "103 19 0.07262032479047775\n",
      "103 69 0.1039307713508606\n",
      "Validation loss: 0.18607604116588444 ROC AUC: 0.7340259065877216\n",
      "104 42 0.11578485369682312\n",
      "Validation loss: 0.1923578054486931 ROC AUC: 0.7068407388719563\n",
      "105 15 0.0773487240076065\n",
      "105 65 0.1362501084804535\n",
      "Validation loss: 0.20014409256445898 ROC AUC: 0.6906198962035764\n",
      "106 38 0.09899966418743134\n",
      "Validation loss: 0.19736008307376465 ROC AUC: 0.7125142369226874\n",
      "107 11 0.0686822310090065\n",
      "107 61 0.09110825508832932\n",
      "Validation loss: 0.19546879982793486 ROC AUC: 0.7344969449327635\n",
      "108 34 0.11216206848621368\n",
      "Validation loss: 0.2153165698438496 ROC AUC: 0.7051130145054518\n",
      "109 7 0.08856203407049179\n",
      "109 57 0.05140185356140137\n",
      "Validation loss: 0.19001401341580726 ROC AUC: 0.7398264870955084\n",
      "110 30 0.05086510628461838\n",
      "Validation loss: 0.20078765610595803 ROC AUC: 0.7227164862394497\n",
      "111 3 0.11972229927778244\n",
      "111 53 0.07815955579280853\n",
      "Validation loss: 0.18674938961282952 ROC AUC: 0.7449541082441348\n",
      "112 26 0.04885537177324295\n",
      "112 76 0.14167939126491547\n",
      "Validation loss: 0.20977187142163128 ROC AUC: 0.7248501872126133\n",
      "113 49 0.06378579884767532\n",
      "Validation loss: 0.20101727313035495 ROC AUC: 0.7382727501663964\n",
      "114 22 0.10373680293560028\n",
      "114 72 0.04397425428032875\n",
      "Validation loss: 0.2017153384430068 ROC AUC: 0.7284733512815497\n",
      "115 45 0.08521655201911926\n",
      "Validation loss: 0.22092582420869308 ROC AUC: 0.7048313537736054\n",
      "116 18 0.03920475393533707\n",
      "116 68 0.04447737708687782\n",
      "Validation loss: 0.22727989879521457 ROC AUC: 0.7134467633715249\n",
      "117 41 0.06657299399375916\n",
      "Validation loss: 0.21490309203599955 ROC AUC: 0.7022493989469233\n",
      "118 14 0.06368188560009003\n",
      "118 64 0.11018820106983185\n",
      "Validation loss: 0.20633533616344651 ROC AUC: 0.7087997485949197\n",
      "119 37 0.10521410405635834\n",
      "Validation loss: 0.21503310505445902 ROC AUC: 0.7341935393390745\n",
      "120 10 0.09661465883255005\n",
      "120 60 0.10971052944660187\n",
      "Validation loss: 0.19896768923703725 ROC AUC: 0.711592270036533\n",
      "121 33 0.07642539590597153\n",
      "Validation loss: 0.2241144309957306 ROC AUC: 0.6984531360639662\n",
      "122 6 0.15206675231456757\n",
      "122 56 0.055383093655109406\n",
      "Validation loss: 0.20922620459036392 ROC AUC: 0.7185284976306701\n",
      "123 29 0.051167842000722885\n",
      "Validation loss: 0.2305571384631194 ROC AUC: 0.71471508075241\n",
      "124 2 0.032287489622831345\n",
      "124 52 0.07457707077264786\n",
      "Validation loss: 0.1989431661831868 ROC AUC: 0.7353847114956866\n",
      "125 25 0.05594188719987869\n",
      "125 75 0.11877128481864929\n",
      "Validation loss: 0.21156875866574126 ROC AUC: 0.7158092191489608\n",
      "126 48 0.05190303549170494\n",
      "Validation loss: 0.19145189206321517 ROC AUC: 0.7574768550811032\n",
      "127 21 0.072409488260746\n",
      "127 71 0.05278610438108444\n",
      "Validation loss: 0.21075587768059273 ROC AUC: 0.7237300525269067\n",
      "128 44 0.08215096592903137\n",
      "Validation loss: 0.20706453125972252 ROC AUC: 0.732890772055085\n",
      "129 17 0.05512015521526337\n",
      "129 67 0.11456997692584991\n",
      "Validation loss: 0.21577652340585535 ROC AUC: 0.7318482356591006\n",
      "130 40 0.08881564438343048\n",
      "Validation loss: 0.2195942814086939 ROC AUC: 0.7097267297131994\n",
      "131 13 0.09352844953536987\n",
      "131 63 0.06869077682495117\n",
      "Validation loss: 0.215373660836901 ROC AUC: 0.7268935832960278\n",
      "132 36 0.07064653187990189\n",
      "Validation loss: 0.21828165379437534 ROC AUC: 0.725143544972978\n",
      "133 9 0.022930573672056198\n",
      "133 59 0.05887165665626526\n",
      "Validation loss: 0.20522693031794065 ROC AUC: 0.7299827729808651\n",
      "134 32 0.09451574087142944\n",
      "Validation loss: 0.21836564989833088 ROC AUC: 0.7212807638484143\n",
      "135 5 0.05996672064065933\n",
      "135 55 0.07423453032970428\n",
      "Validation loss: 0.2130597864652609 ROC AUC: 0.7520375642149907\n",
      "136 28 0.055223509669303894\n",
      "Validation loss: 0.20947268469767136 ROC AUC: 0.7325116337723975\n",
      "137 1 0.10086912661790848\n",
      "137 51 0.07312728464603424\n",
      "Validation loss: 0.2167586072698816 ROC AUC: 0.7183541116002473\n",
      "138 24 0.05297108367085457\n",
      "138 74 0.0701427161693573\n",
      "Validation loss: 0.22253851311934458 ROC AUC: 0.7122502073143249\n",
      "139 47 0.06095173954963684\n",
      "Validation loss: 0.22253093549183436 ROC AUC: 0.7178953862528257\n",
      "140 20 0.10279235988855362\n",
      "140 70 0.03383495658636093\n",
      "Validation loss: 0.21601201729340988 ROC AUC: 0.7391422218094709\n",
      "141 43 0.12391336262226105\n",
      "Validation loss: 0.2137296757140717 ROC AUC: 0.7284067100087243\n",
      "142 16 0.05440808832645416\n",
      "142 66 0.04898005723953247\n",
      "Validation loss: 0.23069924793460153 ROC AUC: 0.7404893278812931\n",
      "143 39 0.06719077378511429\n",
      "Validation loss: 0.22104794290158655 ROC AUC: 0.7233965741971033\n",
      "144 12 0.07528965920209885\n",
      "144 62 0.06055445224046707\n",
      "Validation loss: 0.23334837477509077 ROC AUC: 0.7191424503883819\n",
      "145 35 0.0446915440261364\n",
      "Validation loss: 0.2183434603276191 ROC AUC: 0.7339896472650486\n",
      "146 8 0.02784818597137928\n",
      "146 58 0.04629890248179436\n",
      "Validation loss: 0.23666086928410965 ROC AUC: 0.7248027680179862\n",
      "147 31 0.04861097410321236\n",
      "Validation loss: 0.23763297324056748 ROC AUC: 0.6943922715801504\n",
      "148 4 0.04911031946539879\n",
      "148 54 0.09116692841053009\n",
      "Validation loss: 0.23694631960484888 ROC AUC: 0.7311320514334555\n",
      "149 27 0.05050889402627945\n",
      "Validation loss: 0.24352483683592313 ROC AUC: 0.7120539435237401\n",
      "150 0 0.042868804186582565\n",
      "150 50 0.047510333359241486\n",
      "Validation loss: 0.22418348413783235 ROC AUC: 0.7303509606453361\n",
      "151 23 0.08163642883300781\n",
      "151 73 0.046900756657123566\n",
      "Validation loss: 0.2500725349822602 ROC AUC: 0.6873168909441606\n",
      "152 46 0.07336325943470001\n",
      "Validation loss: 0.32116572268597493 ROC AUC: 0.6907254383516356\n",
      "153 19 0.06305893510580063\n",
      "153 69 0.08679360151290894\n",
      "Validation loss: 0.22549190817328243 ROC AUC: 0.714484837940168\n",
      "154 42 0.08482399582862854\n",
      "Validation loss: 0.24847975489381072 ROC AUC: 0.6991385072846873\n",
      "155 15 0.0274213794618845\n",
      "155 65 0.05395108088850975\n",
      "Validation loss: 0.2525502501370071 ROC AUC: 0.7106761366862386\n",
      "156 38 0.03731631487607956\n",
      "Validation loss: 0.22859708055273278 ROC AUC: 0.7199248642844759\n",
      "157 11 0.05868494138121605\n",
      "157 61 0.060547929257154465\n",
      "Validation loss: 0.25363111089576373 ROC AUC: 0.712134384318193\n",
      "158 34 0.06669960170984268\n",
      "Validation loss: 0.24877388330249042 ROC AUC: 0.7172164725036358\n",
      "159 7 0.04703088849782944\n",
      "159 57 0.04061919450759888\n",
      "Validation loss: 0.2699057866226543 ROC AUC: 0.706565504462141\n",
      "160 30 0.08613120764493942\n",
      "Validation loss: 0.23093715871309306 ROC AUC: 0.7253627881579274\n",
      "161 3 0.05867714062333107\n",
      "161 53 0.05897543579339981\n",
      "Validation loss: 0.263419412173234 ROC AUC: 0.6991709526410612\n",
      "162 26 0.08335404843091965\n",
      "162 76 0.051063522696495056\n",
      "Validation loss: 0.2655896335453182 ROC AUC: 0.7155130101135123\n",
      "163 49 0.07191377133131027\n",
      "Validation loss: 0.2665039045470102 ROC AUC: 0.7125620975312228\n",
      "164 22 0.046025704592466354\n",
      "164 72 0.02792256511747837\n",
      "Validation loss: 0.2517758487881004 ROC AUC: 0.7190276460687092\n",
      "165 45 0.061782002449035645\n",
      "Validation loss: 0.2721057029126526 ROC AUC: 0.708113607750206\n",
      "166 18 0.0608215406537056\n",
      "166 68 0.13608725368976593\n",
      "Validation loss: 0.25403333755282614 ROC AUC: 0.7274357049453389\n",
      "167 41 0.0506727509200573\n",
      "Validation loss: 0.25510222629293217 ROC AUC: 0.7303718224395119\n",
      "168 14 0.09883074462413788\n",
      "168 64 0.05173606052994728\n",
      "Validation loss: 0.25832580049316606 ROC AUC: 0.7166835045944716\n",
      "169 37 0.04194994643330574\n",
      "Validation loss: 0.2779763536406802 ROC AUC: 0.7046791602298094\n",
      "170 10 0.026262855157256126\n",
      "170 60 0.04703745245933533\n",
      "Validation loss: 0.27129882767603 ROC AUC: 0.7197851631393726\n",
      "171 33 0.057624172419309616\n",
      "Validation loss: 0.2720709197319947 ROC AUC: 0.7341845497325582\n",
      "172 6 0.04052003473043442\n",
      "172 56 0.025910424068570137\n",
      "Validation loss: 0.266898567800398 ROC AUC: 0.740665524424975\n",
      "173 29 0.06523207575082779\n",
      "Validation loss: 0.260845433194916 ROC AUC: 0.7249838665533183\n",
      "174 2 0.038622405380010605\n",
      "174 52 0.07567230612039566\n",
      "Validation loss: 0.2602001678246956 ROC AUC: 0.7322435591039231\n",
      "175 25 0.058159101754426956\n",
      "175 75 0.09113439917564392\n",
      "Validation loss: 0.26690162447365845 ROC AUC: 0.7308905497493319\n",
      "176 48 0.04598701000213623\n",
      "Validation loss: 0.26229478220467445 ROC AUC: 0.7321023191523485\n",
      "177 21 0.0406847707927227\n",
      "177 71 0.042017195373773575\n",
      "Validation loss: 0.2773811553979849 ROC AUC: 0.7203900038563421\n",
      "178 44 0.08058831840753555\n",
      "Validation loss: 0.2734564689846782 ROC AUC: 0.7302931214965311\n",
      "179 17 0.054973192512989044\n",
      "179 67 0.06195322051644325\n",
      "Validation loss: 0.28875328387532917 ROC AUC: 0.7115907998883778\n",
      "180 40 0.06139698624610901\n",
      "Validation loss: 0.2780949543048809 ROC AUC: 0.7053254502397436\n",
      "181 13 0.03707234561443329\n",
      "181 63 0.07503719627857208\n",
      "Validation loss: 0.29067734038674986 ROC AUC: 0.716362968858649\n",
      "182 36 0.04626383259892464\n",
      "Validation loss: 0.29548529158164927 ROC AUC: 0.6853187944874902\n",
      "183 9 0.0535670630633831\n",
      "183 59 0.0750054195523262\n",
      "Validation loss: 0.2965800402226386 ROC AUC: 0.6900774007672345\n",
      "184 32 0.07335066795349121\n",
      "Validation loss: 0.2848877866159786 ROC AUC: 0.7162437006633108\n",
      "185 5 0.021847698837518692\n",
      "185 55 0.08915991336107254\n",
      "Validation loss: 0.25914903430195596 ROC AUC: 0.734644649154642\n",
      "186 28 0.04825510457158089\n",
      "Validation loss: 0.26602608778259973 ROC AUC: 0.7354942008489735\n",
      "187 1 0.042303718626499176\n",
      "187 51 0.03317301347851753\n",
      "Validation loss: 0.28011192478142777 ROC AUC: 0.7295985584960784\n",
      "188 24 0.06811419874429703\n",
      "188 74 0.06252218782901764\n",
      "Validation loss: 0.27423375844955444 ROC AUC: 0.7333191226203676\n",
      "189 47 0.041592180728912354\n",
      "Validation loss: 0.2842934619296681 ROC AUC: 0.7234498273254428\n",
      "190 20 0.06935624778270721\n",
      "190 70 0.058223266154527664\n",
      "Validation loss: 0.29993326052442776 ROC AUC: 0.710286133252901\n",
      "191 43 0.049518026411533356\n",
      "Validation loss: 0.2823220845553782 ROC AUC: 0.7069243061795812\n",
      "192 16 0.03519264608621597\n",
      "192 66 0.05651377886533737\n",
      "Validation loss: 0.2776585439969967 ROC AUC: 0.7150321744529058\n",
      "193 39 0.04421495273709297\n",
      "Validation loss: 0.30872315990847427 ROC AUC: 0.7142403846297886\n",
      "194 12 0.046911198645830154\n",
      "194 62 0.12015366554260254\n",
      "Validation loss: 0.2881134810385766 ROC AUC: 0.7074048118769461\n",
      "195 35 0.026688238605856895\n",
      "Validation loss: 0.28537712875124693 ROC AUC: 0.718117185864148\n",
      "196 8 0.04752129688858986\n",
      "196 58 0.04968568682670593\n",
      "Validation loss: 0.2926940801855806 ROC AUC: 0.724066763975979\n",
      "197 31 0.05401765555143356\n",
      "Validation loss: 0.311186173906574 ROC AUC: 0.7183750614732398\n",
      "198 4 0.02269836515188217\n",
      "198 54 0.029971899464726448\n",
      "Validation loss: 0.29419604330867916 ROC AUC: 0.7060086789984427\n",
      "199 27 0.04248862713575363\n",
      "Validation loss: 0.31562170231497133 ROC AUC: 0.7206074978707756\n",
      "Loaded trained model with success.\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Test loss: 0.156017064709555 Test ROC AUC: 0.7178629169809311\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:1', 'task_name': 'sider', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'classification', 'data_path': 'data/sider/sider.csv', 'target': ['Hepatobiliary disorders', 'Metabolism and nutrition disorders', 'Product issues', 'Eye disorders', 'Investigations', 'Musculoskeletal and connective tissue disorders', 'Gastrointestinal disorders', 'Social circumstances', 'Immune system disorders', 'Reproductive system and breast disorders', 'Neoplasms benign, malignant and unspecified (incl cysts and polyps)', 'General disorders and administration site conditions', 'Endocrine disorders', 'Surgical and medical procedures', 'Vascular disorders', 'Blood and lymphatic system disorders', 'Skin and subcutaneous tissue disorders', 'Congenital, familial and genetic disorders', 'Infections and infestations', 'Respiratory, thoracic and mediastinal disorders', 'Psychiatric disorders', 'Renal and urinary disorders', 'Pregnancy, puerperium and perinatal conditions', 'Ear and labyrinth disorders', 'Cardiac disorders', 'Nervous system disorders', 'Injury, poisoning and procedural complications']}}\n",
      "Running on: cuda:1\n",
      "1426\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1426\n",
      "Generating scaffold 1000/1426\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 5.7441840171813965\n",
      "Validation loss: 0.48586990949990866 ROC AUC: 0.5220544626755083\n",
      "1 14 1.5114197731018066\n",
      "Validation loss: 0.48023435848576207 ROC AUC: 0.4987004066201361\n",
      "2 28 1.1113147735595703\n",
      "Validation loss: 0.481921700330881 ROC AUC: 0.504207813677613\n",
      "Validation loss: 0.4825370415940985 ROC AUC: 0.5022016117709279\n",
      "4 6 0.9552667140960693\n",
      "Validation loss: 0.4768159908431393 ROC AUC: 0.504492352896171\n",
      "5 20 0.8157427310943604\n",
      "Validation loss: 0.4752351095626404 ROC AUC: 0.520872961137975\n",
      "6 34 0.7744313478469849\n",
      "Validation loss: 0.474671211276021 ROC AUC: 0.5187614251263764\n",
      "Validation loss: 0.4744550739968573 ROC AUC: 0.5205017403731843\n",
      "8 12 0.714701771736145\n",
      "Validation loss: 0.4746977422204051 ROC AUC: 0.523094471986147\n",
      "9 26 0.6545764803886414\n",
      "Validation loss: 0.4739537464155184 ROC AUC: 0.5258291976998353\n",
      "Validation loss: 0.47532001075211106 ROC AUC: 0.5192285667071181\n",
      "11 4 0.7002981901168823\n",
      "Validation loss: 0.47259585007087335 ROC AUC: 0.5328479983126969\n",
      "12 18 0.6262142062187195\n",
      "Validation loss: 0.4732270280381183 ROC AUC: 0.5426338045156622\n",
      "13 32 0.6261722445487976\n",
      "Validation loss: 0.4726892847281236 ROC AUC: 0.539552474923873\n",
      "Validation loss: 0.4736958556658738 ROC AUC: 0.5461444625660368\n",
      "15 10 0.6117462515830994\n",
      "Validation loss: 0.4763488577796029 ROC AUC: 0.5514921374327614\n",
      "16 24 0.6776102781295776\n",
      "Validation loss: 0.47622595821227226 ROC AUC: 0.528571872167274\n",
      "Validation loss: 0.4731357947929756 ROC AUC: 0.5495960497817377\n",
      "18 2 0.5596187710762024\n",
      "Validation loss: 0.47664941399247496 ROC AUC: 0.5524614135443395\n",
      "19 16 0.578578770160675\n",
      "Validation loss: 0.4719268056479367 ROC AUC: 0.5639190002147813\n",
      "20 30 0.6087011694908142\n",
      "Validation loss: 0.4737230214205655 ROC AUC: 0.5600775628690909\n",
      "Validation loss: 0.4728341556929208 ROC AUC: 0.5591454587139404\n",
      "22 8 0.6059061884880066\n",
      "Validation loss: 0.4756894578466882 ROC AUC: 0.5640412586746488\n",
      "23 22 0.5348350405693054\n",
      "Validation loss: 0.4717913420050294 ROC AUC: 0.5615135494598376\n",
      "Validation loss: 0.47031884072543856 ROC AUC: 0.5669456203695288\n",
      "25 0 0.5652058720588684\n",
      "Validation loss: 0.4698502952819104 ROC AUC: 0.5613173997702043\n",
      "26 14 0.5297225713729858\n",
      "Validation loss: 0.46919207181130257 ROC AUC: 0.5716318046599634\n",
      "27 28 0.5075372457504272\n",
      "Validation loss: 0.4699156655298246 ROC AUC: 0.5690709309328535\n",
      "Validation loss: 0.4785918541304715 ROC AUC: 0.5455488831718837\n",
      "29 6 0.5209344029426575\n",
      "Validation loss: 0.4707907536229887 ROC AUC: 0.5754955277861851\n",
      "30 20 0.5313657522201538\n",
      "Validation loss: 0.4809889447438967 ROC AUC: 0.5629832838666854\n",
      "31 34 0.49246421456336975\n",
      "Validation loss: 0.4738590829855912 ROC AUC: 0.5748631085697974\n",
      "Validation loss: 0.46972079022781 ROC AUC: 0.5731034944533631\n",
      "33 12 0.5108563303947449\n",
      "Validation loss: 0.46778486700324745 ROC AUC: 0.5887484615201195\n",
      "34 26 0.48222100734710693\n",
      "Validation loss: 0.4759541674927398 ROC AUC: 0.5779105611790412\n",
      "Validation loss: 0.4678951578957218 ROC AUC: 0.5881524315066117\n",
      "36 4 0.5197255611419678\n",
      "Validation loss: 0.4703462144711634 ROC AUC: 0.586049594257292\n",
      "37 18 0.49602898955345154\n",
      "Validation loss: 0.47250896192097164 ROC AUC: 0.5690747190095095\n",
      "38 32 0.5735154151916504\n",
      "Validation loss: 0.4684447223073119 ROC AUC: 0.5940175008262498\n",
      "Validation loss: 0.46848978862895835 ROC AUC: 0.5893509085463415\n",
      "40 10 0.5243184566497803\n",
      "Validation loss: 0.48305057333065915 ROC AUC: 0.5893367739720587\n",
      "41 24 0.45733341574668884\n",
      "Validation loss: 0.4744244013632928 ROC AUC: 0.580016736485034\n",
      "Validation loss: 0.47115193046889936 ROC AUC: 0.585604622211507\n",
      "43 2 0.5334338545799255\n",
      "Validation loss: 0.48205814786724277 ROC AUC: 0.560690381352597\n",
      "44 16 0.5343077778816223\n",
      "Validation loss: 0.4717971524158558 ROC AUC: 0.5817330729183514\n",
      "45 30 0.5323642492294312\n",
      "Validation loss: 0.474409033993741 ROC AUC: 0.5965962953385836\n",
      "Validation loss: 0.47242100463880526 ROC AUC: 0.5809717243361068\n",
      "47 8 0.4390786588191986\n",
      "Validation loss: 0.47704339277494207 ROC AUC: 0.5883675502284551\n",
      "48 22 0.497479647397995\n",
      "Validation loss: 0.4698284176679758 ROC AUC: 0.5867504600422552\n",
      "Validation loss: 0.4720412067600063 ROC AUC: 0.5814371862650708\n",
      "50 0 0.45966970920562744\n",
      "Validation loss: 0.4729182186660233 ROC AUC: 0.5912170341233397\n",
      "51 14 0.5118891596794128\n",
      "Validation loss: 0.47415910588277804 ROC AUC: 0.5956144963210176\n",
      "52 28 0.48863187432289124\n",
      "Validation loss: 0.48414828748136135 ROC AUC: 0.5723481455845858\n",
      "Validation loss: 0.47316719039336785 ROC AUC: 0.5879014254062775\n",
      "54 6 0.42827606201171875\n",
      "Validation loss: 0.47247858251725044 ROC AUC: 0.5906748909291077\n",
      "55 20 0.5080082416534424\n",
      "Validation loss: 0.47686805987691544 ROC AUC: 0.5937759595176341\n",
      "56 34 0.5645178556442261\n",
      "Validation loss: 0.48449326290950906 ROC AUC: 0.5712403088685412\n",
      "Validation loss: 0.48320551602156847 ROC AUC: 0.590505674545449\n",
      "58 12 0.5016979575157166\n",
      "Validation loss: 0.4638655792166303 ROC AUC: 0.6047078453573144\n",
      "59 26 0.48981571197509766\n",
      "Validation loss: 0.4684736509839972 ROC AUC: 0.6046748073424347\n",
      "Validation loss: 0.5012949538397622 ROC AUC: 0.586409442448059\n",
      "61 4 0.43163520097732544\n",
      "Validation loss: 0.4750620714434377 ROC AUC: 0.6001761488805054\n",
      "62 18 0.4872440993785858\n",
      "Validation loss: 0.4848864020167531 ROC AUC: 0.5894978963249388\n",
      "63 32 0.44671115279197693\n",
      "Validation loss: 0.4920196593641401 ROC AUC: 0.5873996158874627\n",
      "Validation loss: 0.47211085374538714 ROC AUC: 0.6041535232995168\n",
      "65 10 0.5059410929679871\n",
      "Validation loss: 0.473400940428247 ROC AUC: 0.5962252583804895\n",
      "66 24 0.4829770624637604\n",
      "Validation loss: 0.47880459040194956 ROC AUC: 0.5996253388113743\n",
      "Validation loss: 0.46568763068505936 ROC AUC: 0.6132790688232606\n",
      "68 2 0.4668847918510437\n",
      "Validation loss: 0.47005290814212985 ROC AUC: 0.6174418576850612\n",
      "69 16 0.43024763464927673\n",
      "Validation loss: 0.48367562890052795 ROC AUC: 0.606149601577452\n",
      "70 30 0.5100984573364258\n",
      "Validation loss: 0.4883308777442345 ROC AUC: 0.5880407761464177\n",
      "Validation loss: 0.47345500600921525 ROC AUC: 0.6079336529619033\n",
      "72 8 0.48519620299339294\n",
      "Validation loss: 0.48198541561206737 ROC AUC: 0.6060950888619047\n",
      "73 22 0.5239078998565674\n",
      "Validation loss: 0.4778024570925252 ROC AUC: 0.6045459721841546\n",
      "Validation loss: 0.4751964807510376 ROC AUC: 0.6099842815875738\n",
      "75 0 0.5192609429359436\n",
      "Validation loss: 0.4815503763152169 ROC AUC: 0.6093186495934049\n",
      "76 14 0.5201943516731262\n",
      "Validation loss: 0.4893571213408784 ROC AUC: 0.6096694585635224\n",
      "77 28 0.5481259822845459\n",
      "Validation loss: 0.49103683316624247 ROC AUC: 0.6058354869828764\n",
      "Validation loss: 0.4946958360138473 ROC AUC: 0.5905690665248909\n",
      "79 6 0.4453912079334259\n",
      "Validation loss: 0.48120226997595567 ROC AUC: 0.6116020300889572\n",
      "80 20 0.5000206828117371\n",
      "Validation loss: 0.48387136409332704 ROC AUC: 0.5988876673362794\n",
      "81 34 0.48242485523223877\n",
      "Validation loss: 0.49379236985753466 ROC AUC: 0.5962227817184997\n",
      "Validation loss: 0.47527012124761836 ROC AUC: 0.6121987753299174\n",
      "83 12 0.46612781286239624\n",
      "Validation loss: 0.48699541712974337 ROC AUC: 0.608926824688636\n",
      "84 26 0.44129592180252075\n",
      "Validation loss: 0.48066007257341503 ROC AUC: 0.608743157493622\n",
      "Validation loss: 0.4903087634723503 ROC AUC: 0.6169459458285284\n",
      "86 4 0.4895714521408081\n",
      "Validation loss: 0.4848627118797569 ROC AUC: 0.6222811271080869\n",
      "87 18 0.4901706874370575\n",
      "Validation loss: 0.499354908516357 ROC AUC: 0.5878208819728162\n",
      "88 32 0.4352814257144928\n",
      "Validation loss: 0.4773386531359666 ROC AUC: 0.6065320198422728\n",
      "Validation loss: 0.47605935030883845 ROC AUC: 0.6279752526160303\n",
      "90 10 0.5015095472335815\n",
      "Validation loss: 0.4888308473400303 ROC AUC: 0.599116484807022\n",
      "91 24 0.47071731090545654\n",
      "Validation loss: 0.4912263980278602 ROC AUC: 0.6064186703634759\n",
      "Validation loss: 0.4875259095138603 ROC AUC: 0.6186943311641376\n",
      "93 2 0.44827717542648315\n",
      "Validation loss: 0.4943675357145029 ROC AUC: 0.61904104835499\n",
      "94 16 0.38269269466400146\n",
      "Validation loss: 0.5002697731231476 ROC AUC: 0.5996754171118811\n",
      "95 30 0.48088619112968445\n",
      "Validation loss: 0.48977730074128906 ROC AUC: 0.6190250585746585\n",
      "Validation loss: 0.4837611473940469 ROC AUC: 0.6111137792012339\n",
      "97 8 0.4483449459075928\n",
      "Validation loss: 0.48722836729529856 ROC AUC: 0.6265751191254688\n",
      "98 22 0.43494462966918945\n",
      "Validation loss: 0.4899948774934649 ROC AUC: 0.6030237328642977\n",
      "Validation loss: 0.4868497185773783 ROC AUC: 0.6169690705106153\n",
      "100 0 0.4476601481437683\n",
      "Validation loss: 0.4929490635445068 ROC AUC: 0.6225618572581155\n",
      "101 14 0.4538131356239319\n",
      "Validation loss: 0.49078178530806427 ROC AUC: 0.6191655159852288\n",
      "102 28 0.45632997155189514\n",
      "Validation loss: 0.5107090298112456 ROC AUC: 0.6097609421483141\n",
      "Validation loss: 0.4843617631838872 ROC AUC: 0.6184196611768319\n",
      "104 6 0.3834387958049774\n",
      "Validation loss: 0.49610201566369383 ROC AUC: 0.6200352692164435\n",
      "105 20 0.4808817207813263\n",
      "Validation loss: 0.4845708967088819 ROC AUC: 0.6302527078528655\n",
      "106 34 0.4222586154937744\n",
      "Validation loss: 0.5058946951285942 ROC AUC: 0.604680333790414\n",
      "Validation loss: 0.48468824658360515 ROC AUC: 0.6338603416112129\n",
      "108 12 0.4799852669239044\n",
      "Validation loss: 0.48048754338617927 ROC AUC: 0.6238880378678537\n",
      "109 26 0.44052794575691223\n",
      "Validation loss: 0.519970178604126 ROC AUC: 0.6122058749871646\n",
      "Validation loss: 0.5085492046562942 ROC AUC: 0.6092328141846314\n",
      "111 4 0.4032597839832306\n",
      "Validation loss: 0.5029840867419343 ROC AUC: 0.6136379867504348\n",
      "112 18 0.4141105115413666\n",
      "Validation loss: 0.5127027976762998 ROC AUC: 0.6112613703307763\n",
      "113 32 0.4045008718967438\n",
      "Validation loss: 0.5063815627481554 ROC AUC: 0.607732962261766\n",
      "Validation loss: 0.49529975277560573 ROC AUC: 0.632799707402688\n",
      "115 10 0.41581910848617554\n",
      "Validation loss: 0.5045546424555611 ROC AUC: 0.6215125168270542\n",
      "116 24 0.4178514778614044\n",
      "Validation loss: 0.5111390644020134 ROC AUC: 0.6102613245485633\n",
      "Validation loss: 0.5179945443060014 ROC AUC: 0.5978613387787314\n",
      "118 2 0.3822501599788666\n",
      "Validation loss: 0.5074395543628639 ROC AUC: 0.6264572502382335\n",
      "119 16 0.4018508493900299\n",
      "Validation loss: 0.5135521659484277 ROC AUC: 0.6165814120619593\n",
      "120 30 0.40599533915519714\n",
      "Validation loss: 0.5247860655084357 ROC AUC: 0.6009091703611623\n",
      "Validation loss: 0.5034262275362348 ROC AUC: 0.6207921231239747\n",
      "122 8 0.4092749357223511\n",
      "Validation loss: 0.5171472280175535 ROC AUC: 0.5984787188105606\n",
      "123 22 0.45254385471343994\n",
      "Validation loss: 0.49349797980768695 ROC AUC: 0.6217226440118426\n",
      "Validation loss: 0.511275070947367 ROC AUC: 0.6194390928992306\n",
      "125 0 0.41769134998321533\n",
      "Validation loss: 0.5217487388974303 ROC AUC: 0.5972504637148015\n",
      "126 14 0.45997968316078186\n",
      "Validation loss: 0.5108165132415878 ROC AUC: 0.6194139966904636\n",
      "127 28 0.42424485087394714\n",
      "Validation loss: 0.5067397118448378 ROC AUC: 0.6018814232413612\n",
      "Validation loss: 0.5147965808848401 ROC AUC: 0.6207426990069351\n",
      "129 6 0.41505518555641174\n",
      "Validation loss: 0.5144829460374125 ROC AUC: 0.6320719500025597\n",
      "130 20 0.3645392954349518\n",
      "Validation loss: 0.5038098013484394 ROC AUC: 0.6350685726025591\n",
      "131 34 0.4129542112350464\n",
      "Validation loss: 0.5110622102564032 ROC AUC: 0.6233309607630678\n",
      "Validation loss: 0.5171838411084422 ROC AUC: 0.609908786528839\n",
      "133 12 0.33950769901275635\n",
      "Validation loss: 0.5188244712519479 ROC AUC: 0.61836905689959\n",
      "134 26 0.39752456545829773\n",
      "Validation loss: 0.5242615671424599 ROC AUC: 0.6284202967040529\n",
      "Validation loss: 0.5236342482633524 ROC AUC: 0.6254416835643214\n",
      "136 4 0.425934761762619\n",
      "Validation loss: 0.5181209951430767 ROC AUC: 0.6153679015174349\n",
      "137 18 0.40404319763183594\n",
      "Validation loss: 0.5263821778597532 ROC AUC: 0.6269701406446577\n",
      "138 32 0.3980424404144287\n",
      "Validation loss: 0.5295275478929906 ROC AUC: 0.6017268110349684\n",
      "Validation loss: 0.5333639404156825 ROC AUC: 0.5959613798965696\n",
      "140 10 0.44931524991989136\n",
      "Validation loss: 0.5297034353643031 ROC AUC: 0.6139798704898516\n",
      "141 24 0.4087534546852112\n",
      "Validation loss: 0.5182162660818833 ROC AUC: 0.6144533408427155\n",
      "Validation loss: 0.5241246458950576 ROC AUC: 0.6237718622471474\n",
      "143 2 0.3214021921157837\n",
      "Validation loss: 0.5242498075211799 ROC AUC: 0.6364432381451756\n",
      "144 16 0.344825804233551\n",
      "Validation loss: 0.5390456731502826 ROC AUC: 0.6109845012937496\n",
      "145 30 0.4781683087348938\n",
      "Validation loss: 0.5229164128536945 ROC AUC: 0.6173516096423047\n",
      "Validation loss: 0.5340088564199168 ROC AUC: 0.6144045853205978\n",
      "147 8 0.428217351436615\n",
      "Validation loss: 0.5313451029620804 ROC AUC: 0.6280646392346988\n",
      "148 22 0.4521239399909973\n",
      "Validation loss: 0.5289405121669902 ROC AUC: 0.6326579281947107\n",
      "Validation loss: 0.5417331423792806 ROC AUC: 0.6096308719854049\n",
      "150 0 0.39282503724098206\n",
      "Validation loss: 0.5462145284339265 ROC AUC: 0.6101522756219394\n",
      "151 14 0.38409385085105896\n",
      "Validation loss: 0.5473757561270174 ROC AUC: 0.6127896468811568\n",
      "152 28 0.4183918535709381\n",
      "Validation loss: 0.5424874424934387 ROC AUC: 0.599960868094337\n",
      "Validation loss: 0.5402815260670402 ROC AUC: 0.6107586878775477\n",
      "154 6 0.357686847448349\n",
      "Validation loss: 0.5466332377253712 ROC AUC: 0.6227563322297208\n",
      "155 20 0.35179954767227173\n",
      "Validation loss: 0.5550582754862058 ROC AUC: 0.6082436059110621\n",
      "156 34 0.40549540519714355\n",
      "Validation loss: 0.5409001912270393 ROC AUC: 0.6221440549520102\n",
      "Validation loss: 0.5546466641492777 ROC AUC: 0.5959139382782049\n",
      "158 12 0.31822681427001953\n",
      "Validation loss: 0.5413282892920754 ROC AUC: 0.6095468330375992\n",
      "159 26 0.36826762557029724\n",
      "Validation loss: 0.5552734749300496 ROC AUC: 0.612228401310185\n",
      "Validation loss: 0.5746417541603942 ROC AUC: 0.6077388091359291\n",
      "161 4 0.4123314321041107\n",
      "Validation loss: 0.5481023004838637 ROC AUC: 0.6168299185669383\n",
      "162 18 0.3588990271091461\n",
      "Validation loss: 0.5572436856223153 ROC AUC: 0.6159422082418947\n",
      "163 32 0.3473499119281769\n",
      "Validation loss: 0.5683672323927179 ROC AUC: 0.623872697859511\n",
      "Validation loss: 0.5548052950338884 ROC AUC: 0.6280993706926592\n",
      "165 10 0.39509937167167664\n",
      "Validation loss: 0.5731199483771424 ROC AUC: 0.6143490918939176\n",
      "166 24 0.4046170711517334\n",
      "Validation loss: 0.5557857001578057 ROC AUC: 0.6218535857275755\n",
      "Validation loss: 0.5494006492874839 ROC AUC: 0.6119401539344754\n",
      "168 2 0.43287426233291626\n",
      "Validation loss: 0.5685490972095436 ROC AUC: 0.6142173623209097\n",
      "169 16 0.3801432251930237\n",
      "Validation loss: 0.5857636240812448 ROC AUC: 0.6167549756964479\n",
      "170 30 0.371242880821228\n",
      "Validation loss: 0.5766531520790154 ROC AUC: 0.6176035480306502\n",
      "Validation loss: 0.5779312232157567 ROC AUC: 0.6157977560348159\n",
      "172 8 0.30647075176239014\n",
      "Validation loss: 0.5586890895049889 ROC AUC: 0.6099994642215273\n",
      "173 22 0.38844066858291626\n",
      "Validation loss: 0.5741876951464406 ROC AUC: 0.6095904102053672\n",
      "Validation loss: 0.5684429663461406 ROC AUC: 0.6115239636395453\n",
      "175 0 0.3836619555950165\n",
      "Validation loss: 0.5833864791409953 ROC AUC: 0.615009690092659\n",
      "176 14 0.3253749907016754\n",
      "Validation loss: 0.5910464912861377 ROC AUC: 0.6202826020257954\n",
      "177 28 0.35311150550842285\n",
      "Validation loss: 0.5726195798887239 ROC AUC: 0.612825726732816\n",
      "Validation loss: 0.5932777903296731 ROC AUC: 0.605484447955621\n",
      "179 6 0.4086272120475769\n",
      "Validation loss: 0.6039913671833652 ROC AUC: 0.6127902279591576\n",
      "180 20 0.34749835729599\n",
      "Validation loss: 0.5761435832177009 ROC AUC: 0.6184112343876941\n",
      "181 34 0.31580784916877747\n",
      "Validation loss: 0.5852836341291041 ROC AUC: 0.6166236943370416\n",
      "Validation loss: 0.5716713725270092 ROC AUC: 0.6164961013908955\n",
      "183 12 0.41539466381073\n",
      "Validation loss: 0.5896851895572423 ROC AUC: 0.623568467084472\n",
      "184 26 0.31194111704826355\n",
      "Validation loss: 0.5885098368137867 ROC AUC: 0.6264657457020961\n",
      "Validation loss: 0.6026582705391037 ROC AUC: 0.6058575063842758\n",
      "186 4 0.3244355320930481\n",
      "Validation loss: 0.5861784811620112 ROC AUC: 0.6184215711328735\n",
      "187 18 0.32849088311195374\n",
      "Validation loss: 0.5911526638311106 ROC AUC: 0.6035730860704881\n",
      "188 32 0.3807867765426636\n",
      "Validation loss: 0.6072810594435338 ROC AUC: 0.6062778648586241\n",
      "Validation loss: 0.588928451488068 ROC AUC: 0.6024962845574147\n",
      "190 10 0.36027470231056213\n",
      "Validation loss: 0.6004462017045988 ROC AUC: 0.6099390958260484\n",
      "191 24 0.2978481650352478\n",
      "Validation loss: 0.6130856642356286 ROC AUC: 0.5998591330228339\n",
      "Validation loss: 0.5896162857542505 ROC AUC: 0.6084607614661408\n",
      "193 2 0.29105913639068604\n",
      "Validation loss: 0.6043396437918389 ROC AUC: 0.6281102065623919\n",
      "194 16 0.3233755826950073\n",
      "Validation loss: 0.6052122036893884 ROC AUC: 0.6081145500613512\n",
      "195 30 0.34666693210601807\n",
      "Validation loss: 0.5927133282998225 ROC AUC: 0.6193925917751926\n",
      "Validation loss: 0.6175307623156301 ROC AUC: 0.6050059493329238\n",
      "197 8 0.3658899962902069\n",
      "Validation loss: 0.5922188346202557 ROC AUC: 0.6195277342475677\n",
      "198 22 0.3894363045692444\n",
      "Validation loss: 0.5879512871062005 ROC AUC: 0.6287221882653148\n",
      "Validation loss: 0.6063946752281456 ROC AUC: 0.6092749787685826\n",
      "Loaded trained model with success.\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Test loss: 0.5743815323689601 Test ROC AUC: 0.6074221158497031\n"
     ]
    }
   ],
   "source": [
    "datasets = ['tox21',  'sider',]\n",
    "\n",
    "for dataset in datasets:\n",
    "            if dataset == 'FreeSolv':\n",
    "            # FreeSolv 데이터셋에 대한 특정 옵션을 적용\n",
    "                !python finetuneReconEmbedding_random_tsne.py \\\n",
    "                --task_name {dataset} \\\n",
    "                --seed 781 \\\n",
    "                --dropout 0.5 \\\n",
    "                --num_layer 3 \\\n",
    "                --emb_dim 64 \\\n",
    "                --feat_dim 64 \\\n",
    "                --gpu cuda:1\n",
    "         \n",
    "                    \n",
    "            else:\n",
    "                !python finetuneReconEmbedding_random_tsne.py \\\n",
    "                --task_name {dataset} \\\n",
    "                --seed 781 \\\n",
    "                --gpu cuda:1 \\\n",
    "                --mask_rate 0.2 \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c9838013-4840-475b-a99d-15652855531f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 1, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'sider', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'classification', 'data_path': 'data/sider/sider.csv', 'target': ['Hepatobiliary disorders', 'Metabolism and nutrition disorders', 'Product issues', 'Eye disorders', 'Investigations', 'Musculoskeletal and connective tissue disorders', 'Gastrointestinal disorders', 'Social circumstances', 'Immune system disorders', 'Reproductive system and breast disorders', 'Neoplasms benign, malignant and unspecified (incl cysts and polyps)', 'General disorders and administration site conditions', 'Endocrine disorders', 'Surgical and medical procedures', 'Vascular disorders', 'Blood and lymphatic system disorders', 'Skin and subcutaneous tissue disorders', 'Congenital, familial and genetic disorders', 'Infections and infestations', 'Respiratory, thoracic and mediastinal disorders', 'Psychiatric disorders', 'Renal and urinary disorders', 'Pregnancy, puerperium and perinatal conditions', 'Ear and labyrinth disorders', 'Cardiac disorders', 'Nervous system disorders', 'Injury, poisoning and procedural complications']}}\n",
      "Running on: cuda:0\n",
      "1426\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1426\n",
      "Generating scaffold 1000/1426\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.2196385860443115\n",
      "Validation loss: 0.4854218603430928 ROC AUC: 0.5231910060039552\n",
      "Loaded trained model with success.\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Figure(1000x1000)\n",
      "Test loss: 0.49468863302177485 Test ROC AUC: 0.5269151666314731\n"
     ]
    }
   ],
   "source": [
    "!python finetuneReconEmbedding_random_tsne.py \\\n",
    "--task_name sider \\\n",
    "--seed 781 \\\n",
    "--gpu cuda:0 \\\n",
    "--alpha 0.1 \\\n",
    "--weight_decay 1e-6 \\\n",
    "--mask_rate 0.2 \\\n",
    "--epochs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1a1198e4-b849-4e2b-b3e8-4ca3a7145dc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'bace', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 750, 'task': 'classification', 'data_path': 'data/bace/bace.csv', 'target': ['Class']}}\n",
      "Running on: cuda:0\n",
      "1512\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1512\n",
      "Generating scaffold 1000/1512\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 0.6962036490440369\n",
      "Validation loss: 0.831542025338735 ROC AUC: 0.4737774627923459\n",
      "1 12 0.5055834054946899\n",
      "Validation loss: 0.8816528280839225 ROC AUC: 0.5124025513819985\n",
      "2 24 0.5589752197265625\n",
      "Validation loss: 1.4423722226098674 ROC AUC: 0.5597094259390503\n",
      "3 36 0.5188508629798889\n",
      "Validation loss: 0.7214681247606972 ROC AUC: 0.6277462792345854\n",
      "Validation loss: 1.518642781586047 ROC AUC: 0.6504252303330971\n",
      "5 10 0.5236238837242126\n",
      "Validation loss: 0.7362420456298929 ROC AUC: 0.5754783841247342\n",
      "6 22 0.3155011236667633\n",
      "Validation loss: 0.7414200550673024 ROC AUC: 0.5797306874557052\n",
      "7 34 0.46754348278045654\n",
      "Validation loss: 0.8952645541026892 ROC AUC: 0.5871722182849044\n",
      "Validation loss: 0.6963896502722178 ROC AUC: 0.6029411764705882\n",
      "9 8 0.7371493577957153\n",
      "Validation loss: 0.7139334939173515 ROC AUC: 0.6367824238128985\n",
      "10 20 0.4397616684436798\n",
      "Validation loss: 1.0470574892909321 ROC AUC: 0.6927710843373494\n",
      "11 32 0.3753582835197449\n",
      "Validation loss: 0.6847242760342478 ROC AUC: 0.628632175761871\n",
      "Validation loss: 1.413045685022872 ROC AUC: 0.622785258681786\n",
      "13 6 0.38098853826522827\n",
      "Validation loss: 0.7014400686649297 ROC AUC: 0.6050673281360737\n",
      "14 18 0.5945939421653748\n",
      "Validation loss: 0.7302486580728695 ROC AUC: 0.6346562721474132\n",
      "15 30 0.4760518968105316\n",
      "Validation loss: 0.7744501730464152 ROC AUC: 0.6644223954642098\n",
      "Validation loss: 0.7621341505587496 ROC AUC: 0.6440467753366407\n",
      "17 4 0.39215290546417236\n",
      "Validation loss: 0.7100849029244176 ROC AUC: 0.6897590361445782\n",
      "18 16 0.5024417042732239\n",
      "Validation loss: 0.833378793388013 ROC AUC: 0.6486534372785259\n",
      "19 28 0.28987857699394226\n",
      "Validation loss: 0.870947165599722 ROC AUC: 0.6899362154500354\n",
      "Validation loss: 0.84016952135705 ROC AUC: 0.6684975194897236\n",
      "21 2 0.48689278960227966\n",
      "Validation loss: 0.7414222643864865 ROC AUC: 0.6975549255846917\n",
      "22 14 0.40604037046432495\n",
      "Validation loss: 0.8413909334220634 ROC AUC: 0.6732813607370659\n",
      "23 26 0.38616999983787537\n",
      "Validation loss: 0.774614987783874 ROC AUC: 0.6511339475549256\n",
      "Validation loss: 1.045611471529828 ROC AUC: 0.7058823529411764\n",
      "25 0 0.2973904609680176\n",
      "Validation loss: 0.8184274032415934 ROC AUC: 0.6954287739192062\n",
      "26 12 0.337484210729599\n",
      "Validation loss: 0.6704745738711578 ROC AUC: 0.6709780297661233\n",
      "27 24 0.803382396697998\n",
      "Validation loss: 0.8559488950186218 ROC AUC: 0.6830262225372076\n",
      "28 36 0.2809032201766968\n",
      "Validation loss: 0.8612133159937448 ROC AUC: 0.6599929128277817\n",
      "Validation loss: 0.8063601350152729 ROC AUC: 0.7009213323883771\n",
      "30 10 0.34981638193130493\n",
      "Validation loss: 0.7586411636396749 ROC AUC: 0.6945428773919206\n",
      "31 22 0.6541658043861389\n",
      "Validation loss: 0.8907884904090931 ROC AUC: 0.6757618710134656\n",
      "32 34 0.26660484075546265\n",
      "Validation loss: 0.9292173985613893 ROC AUC: 0.6963146704464919\n",
      "Validation loss: 0.7811729777727695 ROC AUC: 0.6626506024096385\n",
      "34 8 0.5187357664108276\n",
      "Validation loss: 1.0421326539374345 ROC AUC: 0.6527285613040397\n",
      "35 20 0.39484739303588867\n",
      "Validation loss: 0.7386654579876274 ROC AUC: 0.709603118355776\n",
      "36 32 0.34758859872817993\n",
      "Validation loss: 0.9373128816781454 ROC AUC: 0.693656980864635\n",
      "Validation loss: 0.6632937244232128 ROC AUC: 0.7166902905740609\n",
      "38 6 0.5354396104812622\n",
      "Validation loss: 0.7943337658383199 ROC AUC: 0.6692062367115521\n",
      "39 18 0.44326046109199524\n",
      "Validation loss: 0.8186032033913972 ROC AUC: 0.7113749114103473\n",
      "40 30 0.3733175992965698\n",
      "Validation loss: 0.763156065482967 ROC AUC: 0.6865698086463502\n",
      "Validation loss: 0.8040263984377021 ROC AUC: 0.6927710843373494\n",
      "42 4 0.48419758677482605\n",
      "Validation loss: 0.8272556855978556 ROC AUC: 0.7494684620836287\n",
      "43 16 0.5055751800537109\n",
      "Validation loss: 0.7290336742306387 ROC AUC: 0.6794826364280653\n",
      "44 28 0.2710351049900055\n",
      "Validation loss: 0.7434497826936229 ROC AUC: 0.6940113394755493\n",
      "Validation loss: 1.0530820240248118 ROC AUC: 0.6722182849043231\n",
      "46 2 0.31566566228866577\n",
      "Validation loss: 1.3054881293252605 ROC AUC: 0.6323529411764707\n",
      "47 14 0.48872512578964233\n",
      "Validation loss: 0.9048091935006198 ROC AUC: 0.6784195605953224\n",
      "48 26 0.2610587179660797\n",
      "Validation loss: 0.7273179367678055 ROC AUC: 0.700921332388377\n",
      "^C\n",
      "Exception ignored in: <function _releaseLock at 0x7f41dec62ef0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "!python finetune3_tsne.py \\\n",
    " --task_name bace \\\n",
    "--seed 750 \\\n",
    "--gpu cuda:0 \\\n",
    "--weight_decay 1e-6 \\\n",
    "--mask_rate 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c071958-056b-4b7a-9d88-913fb1e53610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
