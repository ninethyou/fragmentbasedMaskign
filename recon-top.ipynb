{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78cbc95c-8c82-4b39-9acb-eac3d7dea845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'freesolv', 'model_type': 'gin', 'model': {'num_layer': 3, 'emb_dim': 64, 'feat_dim': 64, 'drop_ratio': 0.5, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'target': ['expt']}}\n",
      "Running on: cuda:0\n",
      "641\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/641\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 28.644306182861328\n",
      "Validation loss: 64.89720153808594 RMSE: 8.05588\n",
      "Validation loss: 57.45367240905762 RMSE: 7.5798206\n",
      "Validation loss: 47.454193115234375 RMSE: 6.8887\n",
      "3 2 8.199435234069824\n",
      "Validation loss: 37.20687675476074 RMSE: 6.0997443\n",
      "Validation loss: 18.382222175598145 RMSE: 4.2874494\n",
      "Validation loss: 17.764988899230957 RMSE: 4.214854\n",
      "6 4 8.261720657348633\n",
      "Validation loss: 17.828346252441406 RMSE: 4.2223625\n",
      "Validation loss: 15.245631217956543 RMSE: 3.9045653\n",
      "Validation loss: 17.915550231933594 RMSE: 4.232676\n",
      "9 6 10.128081321716309\n",
      "Validation loss: 16.514182567596436 RMSE: 4.0637646\n",
      "Validation loss: 16.03499126434326 RMSE: 4.0043716\n",
      "Validation loss: 19.483867645263672 RMSE: 4.4140534\n",
      "12 8 4.773705005645752\n",
      "Validation loss: 14.122929573059082 RMSE: 3.7580488\n",
      "Validation loss: 14.95869493484497 RMSE: 3.8676472\n",
      "Validation loss: 18.293437957763672 RMSE: 4.277083\n",
      "15 10 3.580686092376709\n",
      "Validation loss: 14.950103282928467 RMSE: 3.8665361\n",
      "Validation loss: 13.41484260559082 RMSE: 3.662628\n",
      "Validation loss: 16.570475101470947 RMSE: 4.070685\n",
      "18 12 5.348771572113037\n",
      "Validation loss: 16.421813011169434 RMSE: 4.052384\n",
      "Validation loss: 14.097779273986816 RMSE: 3.754701\n",
      "Validation loss: 14.326315879821777 RMSE: 3.7850118\n",
      "21 14 5.238226413726807\n",
      "Validation loss: 14.344599723815918 RMSE: 3.7874267\n",
      "Validation loss: 15.963862419128418 RMSE: 3.99548\n",
      "Validation loss: 11.242000579833984 RMSE: 3.3529093\n",
      "Validation loss: 10.74891185760498 RMSE: 3.2785532\n",
      "25 0 1.8727481365203857\n",
      "Validation loss: 16.38282585144043 RMSE: 4.04757\n",
      "Validation loss: 15.274253845214844 RMSE: 3.9082289\n",
      "Validation loss: 15.19847059249878 RMSE: 3.8985217\n",
      "28 2 4.205440044403076\n",
      "Validation loss: 14.007463932037354 RMSE: 3.7426546\n",
      "Validation loss: 12.390299797058105 RMSE: 3.5199857\n",
      "Validation loss: 15.927972793579102 RMSE: 3.9909863\n",
      "31 4 3.0205023288726807\n",
      "Validation loss: 17.477458000183105 RMSE: 4.180605\n",
      "Validation loss: 14.574165344238281 RMSE: 3.8176124\n",
      "Validation loss: 10.708346366882324 RMSE: 3.272361\n",
      "34 6 3.201611042022705\n",
      "Validation loss: 13.99198293685913 RMSE: 3.740586\n",
      "Validation loss: 15.28709888458252 RMSE: 3.9098718\n",
      "Validation loss: 14.069499015808105 RMSE: 3.7509332\n",
      "37 8 6.130540370941162\n",
      "Validation loss: 12.470795154571533 RMSE: 3.5314012\n",
      "Validation loss: 13.692557334899902 RMSE: 3.7003455\n",
      "Validation loss: 11.01100206375122 RMSE: 3.3182828\n",
      "40 10 2.4543423652648926\n",
      "Validation loss: 11.293025016784668 RMSE: 3.3605096\n",
      "Validation loss: 15.373977661132812 RMSE: 3.9209666\n",
      "Validation loss: 14.454527854919434 RMSE: 3.8019109\n",
      "43 12 1.6223268508911133\n",
      "Validation loss: 13.905638217926025 RMSE: 3.7290263\n",
      "Validation loss: 13.895737171173096 RMSE: 3.7276988\n",
      "Validation loss: 13.372166633605957 RMSE: 3.6567974\n",
      "46 14 2.42512583732605\n",
      "Validation loss: 13.961436748504639 RMSE: 3.7365007\n",
      "Validation loss: 13.700119495391846 RMSE: 3.7013671\n",
      "Validation loss: 13.939337253570557 RMSE: 3.7335422\n",
      "Validation loss: 14.169749736785889 RMSE: 3.764273\n",
      "50 0 4.435867786407471\n",
      "Validation loss: 12.824970722198486 RMSE: 3.5811968\n",
      "Validation loss: 12.986132621765137 RMSE: 3.603628\n",
      "Validation loss: 12.324058532714844 RMSE: 3.510564\n",
      "53 2 2.5485970973968506\n",
      "Validation loss: 15.135883808135986 RMSE: 3.8904862\n",
      "Validation loss: 12.36220932006836 RMSE: 3.5159936\n",
      "Validation loss: 10.311840057373047 RMSE: 3.2112055\n",
      "56 4 2.315702199935913\n",
      "Validation loss: 14.235227108001709 RMSE: 3.77296\n",
      "Validation loss: 13.17979907989502 RMSE: 3.6303995\n",
      "Validation loss: 11.807283878326416 RMSE: 3.436173\n",
      "59 6 2.3746438026428223\n",
      "Validation loss: 12.322544574737549 RMSE: 3.5103483\n",
      "Validation loss: 13.562897205352783 RMSE: 3.6827838\n",
      "Validation loss: 14.200101375579834 RMSE: 3.7683022\n",
      "62 8 1.2535812854766846\n",
      "Validation loss: 14.217379093170166 RMSE: 3.770594\n",
      "Validation loss: 15.675963401794434 RMSE: 3.9592881\n",
      "Validation loss: 14.429154872894287 RMSE: 3.7985725\n",
      "65 10 2.904554843902588\n",
      "Validation loss: 16.48590087890625 RMSE: 4.060283\n",
      "Validation loss: 12.669914722442627 RMSE: 3.5594823\n",
      "Validation loss: 14.675124168395996 RMSE: 3.8308125\n",
      "68 12 3.176124095916748\n",
      "Validation loss: 16.972060203552246 RMSE: 4.1197157\n",
      "Validation loss: 13.775762557983398 RMSE: 3.7115715\n",
      "Validation loss: 16.519514560699463 RMSE: 4.0644207\n",
      "71 14 2.0985639095306396\n",
      "Validation loss: 14.9742112159729 RMSE: 3.8696525\n",
      "Validation loss: 11.914995193481445 RMSE: 3.4518104\n",
      "Validation loss: 12.588517665863037 RMSE: 3.5480301\n",
      "Validation loss: 15.308327674865723 RMSE: 3.9125857\n",
      "75 0 2.4891438484191895\n",
      "Validation loss: 14.185378074645996 RMSE: 3.766348\n",
      "Validation loss: 14.367823600769043 RMSE: 3.7904913\n",
      "Validation loss: 13.521979331970215 RMSE: 3.6772242\n",
      "78 2 2.274953842163086\n",
      "Validation loss: 14.472464561462402 RMSE: 3.8042693\n",
      "Validation loss: 13.16105604171753 RMSE: 3.627817\n",
      "Validation loss: 15.112703323364258 RMSE: 3.887506\n",
      "81 4 3.8602287769317627\n",
      "Validation loss: 14.050768852233887 RMSE: 3.7484355\n",
      "Validation loss: 18.29547691345215 RMSE: 4.2773213\n",
      "Validation loss: 16.38743019104004 RMSE: 4.0481396\n",
      "84 6 1.2719030380249023\n",
      "Validation loss: 14.29069185256958 RMSE: 3.7803028\n",
      "Validation loss: 17.292665481567383 RMSE: 4.1584454\n",
      "Validation loss: 11.113592147827148 RMSE: 3.3337054\n",
      "87 8 3.018249750137329\n",
      "Validation loss: 12.124493598937988 RMSE: 3.4820244\n",
      "Validation loss: 12.820579528808594 RMSE: 3.5805836\n",
      "Validation loss: 11.243029594421387 RMSE: 3.3530626\n",
      "90 10 2.8376379013061523\n",
      "Validation loss: 13.884827375411987 RMSE: 3.7262352\n",
      "Validation loss: 12.47643232345581 RMSE: 3.5321994\n",
      "Validation loss: 12.98471736907959 RMSE: 3.6034315\n",
      "93 12 2.799666166305542\n",
      "Validation loss: 10.747344970703125 RMSE: 3.278314\n",
      "Validation loss: 12.1874098777771 RMSE: 3.4910471\n",
      "Validation loss: 13.345478534698486 RMSE: 3.6531465\n",
      "96 14 1.9607293605804443\n",
      "Validation loss: 13.415776252746582 RMSE: 3.6627553\n",
      "Validation loss: 13.127867698669434 RMSE: 3.62324\n",
      "Validation loss: 10.490641593933105 RMSE: 3.238926\n",
      "Validation loss: 13.57650375366211 RMSE: 3.6846306\n",
      "100 0 1.9146314859390259\n",
      "Validation loss: 13.380459308624268 RMSE: 3.6579313\n",
      "Validation loss: 11.189104080200195 RMSE: 3.3450117\n",
      "Validation loss: 13.60293197631836 RMSE: 3.6882153\n",
      "103 2 2.7600607872009277\n",
      "Validation loss: 14.149791717529297 RMSE: 3.761621\n",
      "Validation loss: 14.783699035644531 RMSE: 3.8449576\n",
      "Validation loss: 13.79472827911377 RMSE: 3.7141254\n",
      "106 4 2.1446146965026855\n",
      "Validation loss: 11.968015193939209 RMSE: 3.459482\n",
      "Validation loss: 13.655515193939209 RMSE: 3.695337\n",
      "Validation loss: 19.003799438476562 RMSE: 4.359335\n",
      "109 6 0.9380277395248413\n",
      "Validation loss: 14.153072357177734 RMSE: 3.7620568\n",
      "Validation loss: 12.734285354614258 RMSE: 3.5685132\n",
      "Validation loss: 14.204306602478027 RMSE: 3.7688603\n",
      "112 8 4.586659908294678\n",
      "Validation loss: 17.03639316558838 RMSE: 4.1275167\n",
      "Validation loss: 18.68842887878418 RMSE: 4.3230114\n",
      "Validation loss: 14.282537937164307 RMSE: 3.7792244\n",
      "115 10 1.7733505964279175\n",
      "Validation loss: 14.109276294708252 RMSE: 3.7562318\n",
      "Validation loss: 17.029961109161377 RMSE: 4.1267376\n",
      "Validation loss: 14.471025466918945 RMSE: 3.80408\n",
      "118 12 1.4635192155838013\n",
      "Validation loss: 12.81093978881836 RMSE: 3.5792372\n",
      "Validation loss: 15.504849433898926 RMSE: 3.9376197\n",
      "Validation loss: 13.867562294006348 RMSE: 3.7239177\n",
      "121 14 2.1101720333099365\n",
      "Validation loss: 13.123278617858887 RMSE: 3.6226063\n",
      "Validation loss: 14.893874168395996 RMSE: 3.8592584\n",
      "Validation loss: 14.80488920211792 RMSE: 3.8477123\n",
      "Validation loss: 13.843019008636475 RMSE: 3.7206206\n",
      "125 0 2.5893115997314453\n",
      "Validation loss: 14.22961711883545 RMSE: 3.7722166\n",
      "Validation loss: 13.580606460571289 RMSE: 3.6851873\n",
      "Validation loss: 13.678921699523926 RMSE: 3.6985028\n",
      "128 2 2.326080083847046\n",
      "Validation loss: 12.548050880432129 RMSE: 3.5423229\n",
      "Validation loss: 14.518296718597412 RMSE: 3.8102882\n",
      "Validation loss: 15.992144584655762 RMSE: 3.9990177\n",
      "131 4 1.549338459968567\n",
      "Validation loss: 15.018538475036621 RMSE: 3.8753757\n",
      "Validation loss: 13.557485103607178 RMSE: 3.682049\n",
      "Validation loss: 14.500117778778076 RMSE: 3.807902\n",
      "134 6 3.1790332794189453\n",
      "Validation loss: 13.109634399414062 RMSE: 3.620723\n",
      "Validation loss: 14.268189430236816 RMSE: 3.7773259\n",
      "Validation loss: 15.844425678253174 RMSE: 3.9805057\n",
      "137 8 2.8781588077545166\n",
      "Validation loss: 14.154872417449951 RMSE: 3.762296\n",
      "Validation loss: 14.468818187713623 RMSE: 3.80379\n",
      "Validation loss: 15.580867767333984 RMSE: 3.9472609\n",
      "140 10 1.8412566184997559\n",
      "Validation loss: 16.221383094787598 RMSE: 4.027578\n",
      "Validation loss: 16.888547897338867 RMSE: 4.1095676\n",
      "Validation loss: 15.33859920501709 RMSE: 3.9164522\n",
      "143 12 1.6623069047927856\n",
      "Validation loss: 16.136115074157715 RMSE: 4.0169783\n",
      "Validation loss: 15.113435745239258 RMSE: 3.8876002\n",
      "Validation loss: 18.06997060775757 RMSE: 4.250879\n",
      "146 14 2.254326343536377\n",
      "Validation loss: 16.10592794418335 RMSE: 4.0132194\n",
      "Validation loss: 17.078085899353027 RMSE: 4.1325645\n",
      "Validation loss: 19.741769790649414 RMSE: 4.4431715\n",
      "Validation loss: 15.746871948242188 RMSE: 3.9682329\n",
      "150 0 2.208510160446167\n",
      "Validation loss: 13.211061000823975 RMSE: 3.6347022\n",
      "Validation loss: 13.504706382751465 RMSE: 3.6748753\n",
      "Validation loss: 15.388858795166016 RMSE: 3.9228635\n",
      "153 2 2.5477802753448486\n",
      "Validation loss: 18.42518663406372 RMSE: 4.292457\n",
      "Validation loss: 17.452537536621094 RMSE: 4.1776233\n",
      "Validation loss: 14.372028827667236 RMSE: 3.7910461\n",
      "156 4 2.383582830429077\n",
      "Validation loss: 15.659690380096436 RMSE: 3.9572327\n",
      "Validation loss: 19.045709133148193 RMSE: 4.3641386\n",
      "Validation loss: 18.640302658081055 RMSE: 4.3174415\n",
      "159 6 1.2739344835281372\n",
      "Validation loss: 20.3677921295166 RMSE: 4.5130687\n",
      "Validation loss: 15.751198768615723 RMSE: 3.968778\n",
      "Validation loss: 15.489764213562012 RMSE: 3.9357038\n",
      "162 8 1.119550108909607\n",
      "Validation loss: 18.610456466674805 RMSE: 4.313984\n",
      "Validation loss: 16.757429122924805 RMSE: 4.0935836\n",
      "Validation loss: 18.580045700073242 RMSE: 4.3104577\n",
      "165 10 1.458265781402588\n",
      "Validation loss: 13.981012344360352 RMSE: 3.7391195\n",
      "Validation loss: 16.810365676879883 RMSE: 4.1000447\n",
      "Validation loss: 16.499598503112793 RMSE: 4.0619698\n",
      "168 12 1.3095340728759766\n",
      "Validation loss: 15.875027656555176 RMSE: 3.9843476\n",
      "Validation loss: 16.4232816696167 RMSE: 4.0525646\n",
      "Validation loss: 15.772927284240723 RMSE: 3.9715145\n",
      "171 14 1.951235055923462\n",
      "Validation loss: 13.53874397277832 RMSE: 3.6795032\n",
      "Validation loss: 17.892789840698242 RMSE: 4.2299867\n",
      "Validation loss: 18.054786205291748 RMSE: 4.2490926\n",
      "Validation loss: 16.993884086608887 RMSE: 4.122364\n",
      "175 0 1.053935170173645\n",
      "Validation loss: 16.085931301116943 RMSE: 4.010727\n",
      "Validation loss: 14.666865348815918 RMSE: 3.8297346\n",
      "Validation loss: 22.21088695526123 RMSE: 4.712843\n",
      "178 2 1.6958776712417603\n",
      "Validation loss: 18.365760326385498 RMSE: 4.285529\n",
      "Validation loss: 16.070337772369385 RMSE: 4.008783\n",
      "Validation loss: 17.37081813812256 RMSE: 4.167831\n",
      "181 4 1.8419179916381836\n",
      "Validation loss: 18.88502788543701 RMSE: 4.3456907\n",
      "Validation loss: 21.617114067077637 RMSE: 4.6494207\n",
      "Validation loss: 16.964550495147705 RMSE: 4.1188045\n",
      "184 6 2.1261167526245117\n",
      "Validation loss: 18.963080406188965 RMSE: 4.3546615\n",
      "Validation loss: 16.571760654449463 RMSE: 4.0708427\n",
      "Validation loss: 18.008482456207275 RMSE: 4.24364\n",
      "187 8 1.7444303035736084\n",
      "Validation loss: 16.253440856933594 RMSE: 4.0315557\n",
      "Validation loss: 19.704899787902832 RMSE: 4.4390206\n",
      "Validation loss: 17.77365016937256 RMSE: 4.2158804\n",
      "190 10 0.9790627360343933\n",
      "Validation loss: 17.011056900024414 RMSE: 4.1244464\n",
      "Validation loss: 18.861961841583252 RMSE: 4.343036\n",
      "Validation loss: 18.906038284301758 RMSE: 4.3481073\n",
      "193 12 1.665891408920288\n",
      "Validation loss: 18.26264238357544 RMSE: 4.2734814\n",
      "Validation loss: 16.727764129638672 RMSE: 4.089959\n",
      "Validation loss: 16.27880620956421 RMSE: 4.0347004\n",
      "196 14 2.494269847869873\n",
      "Validation loss: 19.780513763427734 RMSE: 4.447529\n",
      "Validation loss: 17.17146110534668 RMSE: 4.143846\n",
      "Validation loss: 19.281787872314453 RMSE: 4.3911033\n",
      "Validation loss: 16.24959945678711 RMSE: 4.0310793\n",
      "Loaded trained model with success.\n",
      "Test loss: 11.38114236684946 Test RMSE: 3.3735948\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'freesolv', 'model_type': 'gin', 'model': {'num_layer': 3, 'emb_dim': 64, 'feat_dim': 64, 'drop_ratio': 0.5, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 778, 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'target': ['expt']}}\n",
      "Running on: cuda:0\n",
      "641\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/641\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 17.994754791259766\n",
      "Validation loss: 69.05142402648926 RMSE: 8.309719\n",
      "Validation loss: 62.361305236816406 RMSE: 7.8969173\n",
      "Validation loss: 52.12139129638672 RMSE: 7.219515\n",
      "3 2 16.623231887817383\n",
      "Validation loss: 37.17647457122803 RMSE: 6.0972514\n",
      "Validation loss: 15.046906471252441 RMSE: 3.8790343\n",
      "Validation loss: 12.431118488311768 RMSE: 3.5257792\n",
      "6 4 10.757863998413086\n",
      "Validation loss: 24.418280601501465 RMSE: 4.9414854\n",
      "Validation loss: 15.231598377227783 RMSE: 3.902768\n",
      "Validation loss: 12.62651777267456 RMSE: 3.5533812\n",
      "9 6 3.9093399047851562\n",
      "Validation loss: 19.138739585876465 RMSE: 4.3747845\n",
      "Validation loss: 17.228487968444824 RMSE: 4.1507215\n",
      "Validation loss: 14.287827491760254 RMSE: 3.7799244\n",
      "12 8 9.005624771118164\n",
      "Validation loss: 11.327998638153076 RMSE: 3.3657093\n",
      "Validation loss: 16.030729293823242 RMSE: 4.0038395\n",
      "Validation loss: 14.133439540863037 RMSE: 3.7594469\n",
      "15 10 4.115781307220459\n",
      "Validation loss: 13.165738105773926 RMSE: 3.628462\n",
      "Validation loss: 12.750306129455566 RMSE: 3.5707572\n",
      "Validation loss: 13.535670757293701 RMSE: 3.6790857\n",
      "18 12 5.278323173522949\n",
      "Validation loss: 11.970222473144531 RMSE: 3.459801\n",
      "Validation loss: 12.859423160552979 RMSE: 3.5860038\n",
      "Validation loss: 12.704238891601562 RMSE: 3.5643005\n",
      "21 14 2.6332452297210693\n",
      "Validation loss: 12.340507507324219 RMSE: 3.5129058\n",
      "Validation loss: 13.537834167480469 RMSE: 3.6793797\n",
      "Validation loss: 10.956255912780762 RMSE: 3.3100235\n",
      "Validation loss: 11.416400909423828 RMSE: 3.3788164\n",
      "25 0 3.4584314823150635\n",
      "Validation loss: 12.159676551818848 RMSE: 3.487073\n",
      "Validation loss: 13.963153839111328 RMSE: 3.7367303\n",
      "Validation loss: 12.313783645629883 RMSE: 3.5091002\n",
      "28 2 3.3858206272125244\n",
      "Validation loss: 11.586756706237793 RMSE: 3.4039326\n",
      "Validation loss: 11.481637001037598 RMSE: 3.3884563\n",
      "Validation loss: 13.346155643463135 RMSE: 3.653239\n",
      "31 4 4.388903617858887\n",
      "Validation loss: 11.508086204528809 RMSE: 3.392357\n",
      "Validation loss: 10.494865894317627 RMSE: 3.239578\n",
      "Validation loss: 13.239418506622314 RMSE: 3.638601\n",
      "34 6 2.7382655143737793\n",
      "Validation loss: 12.97293758392334 RMSE: 3.6017964\n",
      "Validation loss: 12.367920398712158 RMSE: 3.5168054\n",
      "Validation loss: 11.835322380065918 RMSE: 3.4402504\n",
      "37 8 3.722012996673584\n",
      "Validation loss: 12.001736164093018 RMSE: 3.4643521\n",
      "Validation loss: 11.954954147338867 RMSE: 3.4575937\n",
      "Validation loss: 10.718618392944336 RMSE: 3.2739303\n",
      "40 10 3.915055990219116\n",
      "Validation loss: 9.384750604629517 RMSE: 3.063454\n",
      "Validation loss: 10.29149866104126 RMSE: 3.2080364\n",
      "Validation loss: 10.293256521224976 RMSE: 3.2083104\n",
      "43 12 5.660671710968018\n",
      "Validation loss: 9.981757640838623 RMSE: 3.159392\n",
      "Validation loss: 9.57688856124878 RMSE: 3.0946546\n",
      "Validation loss: 9.561509609222412 RMSE: 3.092169\n",
      "46 14 2.9685869216918945\n",
      "Validation loss: 10.651915073394775 RMSE: 3.2637272\n",
      "Validation loss: 8.436641693115234 RMSE: 2.9045897\n",
      "Validation loss: 8.974159002304077 RMSE: 2.99569\n",
      "Validation loss: 8.775633573532104 RMSE: 2.9623694\n",
      "50 0 2.958130121231079\n",
      "Validation loss: 8.657145023345947 RMSE: 2.9423027\n",
      "Validation loss: 9.189289093017578 RMSE: 3.031384\n",
      "Validation loss: 7.19135856628418 RMSE: 2.681671\n",
      "53 2 2.8680453300476074\n",
      "Validation loss: 8.662578105926514 RMSE: 2.9432259\n",
      "Validation loss: 8.638455867767334 RMSE: 2.9391248\n",
      "Validation loss: 7.8664045333862305 RMSE: 2.804711\n",
      "56 4 3.4646644592285156\n",
      "Validation loss: 9.296643257141113 RMSE: 3.0490398\n",
      "Validation loss: 9.64759087562561 RMSE: 3.1060572\n",
      "Validation loss: 8.586338996887207 RMSE: 2.9302454\n",
      "59 6 3.02553653717041\n",
      "Validation loss: 7.558578729629517 RMSE: 2.749287\n",
      "Validation loss: 9.098641395568848 RMSE: 3.0163953\n",
      "Validation loss: 9.444887161254883 RMSE: 3.0732536\n",
      "62 8 2.935121774673462\n",
      "Validation loss: 7.986175537109375 RMSE: 2.8259823\n",
      "Validation loss: 8.597811222076416 RMSE: 2.932202\n",
      "Validation loss: 8.63224482536316 RMSE: 2.9380682\n",
      "65 10 1.494482398033142\n",
      "Validation loss: 8.349157810211182 RMSE: 2.8894908\n",
      "Validation loss: 7.646000385284424 RMSE: 2.76514\n",
      "Validation loss: 9.991606712341309 RMSE: 3.1609502\n",
      "68 12 2.2324957847595215\n",
      "Validation loss: 7.719643831253052 RMSE: 2.7784247\n",
      "Validation loss: 7.854931831359863 RMSE: 2.8026652\n",
      "Validation loss: 8.930869579315186 RMSE: 2.9884562\n",
      "71 14 2.0922350883483887\n",
      "Validation loss: 9.877895832061768 RMSE: 3.1429121\n",
      "Validation loss: 9.129531383514404 RMSE: 3.0215113\n",
      "Validation loss: 8.455816984176636 RMSE: 2.907889\n",
      "Validation loss: 11.229847431182861 RMSE: 3.3510964\n",
      "75 0 1.494467854499817\n",
      "Validation loss: 8.896677494049072 RMSE: 2.98273\n",
      "Validation loss: 9.863915920257568 RMSE: 3.140687\n",
      "Validation loss: 9.773377418518066 RMSE: 3.1262403\n",
      "78 2 2.1730711460113525\n",
      "Validation loss: 7.544068813323975 RMSE: 2.746647\n",
      "Validation loss: 7.6021528244018555 RMSE: 2.7572002\n",
      "Validation loss: 8.635130405426025 RMSE: 2.938559\n",
      "81 4 1.8499376773834229\n",
      "Validation loss: 9.732686996459961 RMSE: 3.1197255\n",
      "Validation loss: 9.522063732147217 RMSE: 3.0857842\n",
      "Validation loss: 8.157532215118408 RMSE: 2.8561394\n",
      "84 6 1.8629246950149536\n",
      "Validation loss: 10.323856353759766 RMSE: 3.2130759\n",
      "Validation loss: 10.383172512054443 RMSE: 3.2222931\n",
      "Validation loss: 10.84456491470337 RMSE: 3.2931087\n",
      "87 8 1.764188289642334\n",
      "Validation loss: 9.187682151794434 RMSE: 3.0311189\n",
      "Validation loss: 9.155234813690186 RMSE: 3.0257618\n",
      "Validation loss: 8.929783344268799 RMSE: 2.9882743\n",
      "90 10 1.3624868392944336\n",
      "Validation loss: 11.188743591308594 RMSE: 3.3449576\n",
      "Validation loss: 9.776684761047363 RMSE: 3.1267693\n",
      "Validation loss: 9.100460052490234 RMSE: 3.016697\n",
      "93 12 1.2192981243133545\n",
      "Validation loss: 9.822116374969482 RMSE: 3.1340256\n",
      "Validation loss: 10.261007308959961 RMSE: 3.2032807\n",
      "Validation loss: 8.331795454025269 RMSE: 2.886485\n",
      "96 14 1.4756220579147339\n",
      "Validation loss: 7.802018642425537 RMSE: 2.7932093\n",
      "Validation loss: 9.335478782653809 RMSE: 3.0554016\n",
      "Validation loss: 8.436842441558838 RMSE: 2.9046242\n",
      "Validation loss: 8.377253293991089 RMSE: 2.8943486\n",
      "100 0 1.6767325401306152\n",
      "Validation loss: 10.013642311096191 RMSE: 3.1644342\n",
      "Validation loss: 9.156501531600952 RMSE: 3.0259712\n",
      "Validation loss: 8.521942615509033 RMSE: 2.9192367\n",
      "103 2 2.8312082290649414\n",
      "Validation loss: 9.889373779296875 RMSE: 3.1447375\n",
      "Validation loss: 9.452260732650757 RMSE: 3.0744529\n",
      "Validation loss: 8.529028177261353 RMSE: 2.9204502\n",
      "106 4 2.6882357597351074\n",
      "Validation loss: 8.022686243057251 RMSE: 2.8324347\n",
      "Validation loss: 10.1636643409729 RMSE: 3.1880503\n",
      "Validation loss: 9.406513214111328 RMSE: 3.067004\n",
      "109 6 1.871873140335083\n",
      "Validation loss: 9.009339809417725 RMSE: 3.0015564\n",
      "Validation loss: 7.9632768630981445 RMSE: 2.8219278\n",
      "Validation loss: 9.014014720916748 RMSE: 3.002335\n",
      "112 8 1.9713915586471558\n",
      "Validation loss: 8.244083404541016 RMSE: 2.871251\n",
      "Validation loss: 8.210517883300781 RMSE: 2.8654\n",
      "Validation loss: 9.806232929229736 RMSE: 3.1314905\n",
      "115 10 2.307405948638916\n",
      "Validation loss: 8.67548942565918 RMSE: 2.9454184\n",
      "Validation loss: 9.66583251953125 RMSE: 3.108992\n",
      "Validation loss: 9.032530784606934 RMSE: 3.005417\n",
      "118 12 2.3718371391296387\n",
      "Validation loss: 9.704340934753418 RMSE: 3.115179\n",
      "Validation loss: 10.757337093353271 RMSE: 3.279838\n",
      "Validation loss: 8.531106948852539 RMSE: 2.920806\n",
      "121 14 7.637035369873047\n",
      "Validation loss: 8.822465419769287 RMSE: 2.9702637\n",
      "Validation loss: 9.246402740478516 RMSE: 3.0407898\n",
      "Validation loss: 10.91121244430542 RMSE: 3.3032124\n",
      "Validation loss: 9.162761688232422 RMSE: 3.0270054\n",
      "125 0 1.2230275869369507\n",
      "Validation loss: 9.364693641662598 RMSE: 3.0601788\n",
      "Validation loss: 9.204818487167358 RMSE: 3.0339444\n",
      "Validation loss: 10.948215961456299 RMSE: 3.3088088\n",
      "128 2 1.269991397857666\n",
      "Validation loss: 8.30509352684021 RMSE: 2.8818557\n",
      "Validation loss: 7.697985410690308 RMSE: 2.7745245\n",
      "Validation loss: 8.885363578796387 RMSE: 2.9808326\n",
      "131 4 2.063323497772217\n",
      "Validation loss: 11.141872882843018 RMSE: 3.3379445\n",
      "Validation loss: 8.92223334312439 RMSE: 2.9870107\n",
      "Validation loss: 8.02903413772583 RMSE: 2.833555\n",
      "134 6 2.4494175910949707\n",
      "Validation loss: 9.031585454940796 RMSE: 3.0052593\n",
      "Validation loss: 8.598344564437866 RMSE: 2.9322934\n",
      "Validation loss: 8.057244777679443 RMSE: 2.8385286\n",
      "137 8 1.377334713935852\n",
      "Validation loss: 9.108222484588623 RMSE: 3.0179837\n",
      "Validation loss: 8.10396122932434 RMSE: 2.846746\n",
      "Validation loss: 9.323532819747925 RMSE: 3.053446\n",
      "140 10 1.554724097251892\n",
      "Validation loss: 7.322065353393555 RMSE: 2.7059317\n",
      "Validation loss: 7.276660203933716 RMSE: 2.6975288\n",
      "Validation loss: 8.154878377914429 RMSE: 2.8556747\n",
      "143 12 2.134953260421753\n",
      "Validation loss: 7.753225326538086 RMSE: 2.7844613\n",
      "Validation loss: 7.667367458343506 RMSE: 2.7690012\n",
      "Validation loss: 7.560549020767212 RMSE: 2.7496452\n",
      "146 14 1.790238618850708\n",
      "Validation loss: 10.91564130783081 RMSE: 3.3038828\n",
      "Validation loss: 9.814989566802979 RMSE: 3.1328883\n",
      "Validation loss: 7.747246980667114 RMSE: 2.7833877\n",
      "Validation loss: 7.759634494781494 RMSE: 2.785612\n",
      "150 0 2.2461702823638916\n",
      "Validation loss: 8.900125980377197 RMSE: 2.9833078\n",
      "Validation loss: 9.307531356811523 RMSE: 3.0508246\n",
      "Validation loss: 10.092679023742676 RMSE: 3.1768978\n",
      "153 2 2.073047161102295\n",
      "Validation loss: 7.7584006786346436 RMSE: 2.7853909\n",
      "Validation loss: 9.768116474151611 RMSE: 3.1253984\n",
      "Validation loss: 8.239994764328003 RMSE: 2.8705392\n",
      "156 4 3.6742796897888184\n",
      "Validation loss: 9.494720220565796 RMSE: 3.08135\n",
      "Validation loss: 9.591109991073608 RMSE: 3.0969515\n",
      "Validation loss: 11.546149253845215 RMSE: 3.3979626\n",
      "159 6 2.501349687576294\n",
      "Validation loss: 9.955432891845703 RMSE: 3.155223\n",
      "Validation loss: 9.76352834701538 RMSE: 3.1246645\n",
      "Validation loss: 10.733057975769043 RMSE: 3.2761345\n",
      "162 8 1.6755213737487793\n",
      "Validation loss: 8.6880784034729 RMSE: 2.9475546\n",
      "Validation loss: 11.68635368347168 RMSE: 3.418531\n",
      "Validation loss: 8.038532495498657 RMSE: 2.8352306\n",
      "165 10 1.8863292932510376\n",
      "Validation loss: 8.061033487319946 RMSE: 2.839196\n",
      "Validation loss: 10.332792282104492 RMSE: 3.214466\n",
      "Validation loss: 10.588822364807129 RMSE: 3.254047\n",
      "168 12 1.5703116655349731\n",
      "Validation loss: 8.502322673797607 RMSE: 2.9158742\n",
      "Validation loss: 9.416529178619385 RMSE: 3.0686362\n",
      "Validation loss: 7.476007461547852 RMSE: 2.7342288\n",
      "171 14 2.1066229343414307\n",
      "Validation loss: 6.549880504608154 RMSE: 2.5592735\n",
      "Validation loss: 9.928380012512207 RMSE: 3.1509333\n",
      "Validation loss: 8.884444952011108 RMSE: 2.9806786\n",
      "Validation loss: 11.774576902389526 RMSE: 3.4314103\n",
      "175 0 3.291437864303589\n",
      "Validation loss: 9.737734079360962 RMSE: 3.1205342\n",
      "Validation loss: 8.508543491363525 RMSE: 2.9169407\n",
      "Validation loss: 9.485666751861572 RMSE: 3.079881\n",
      "178 2 2.6421170234680176\n",
      "Validation loss: 8.270431756973267 RMSE: 2.875836\n",
      "Validation loss: 9.160740852355957 RMSE: 3.0266716\n",
      "Validation loss: 10.788357734680176 RMSE: 3.2845635\n",
      "181 4 1.1987384557724\n",
      "Validation loss: 12.82921552658081 RMSE: 3.5817893\n",
      "Validation loss: 12.145978450775146 RMSE: 3.4851081\n",
      "Validation loss: 8.386347770690918 RMSE: 2.895919\n",
      "184 6 1.8943926095962524\n",
      "Validation loss: 10.638221740722656 RMSE: 3.2616284\n",
      "Validation loss: 8.398158311843872 RMSE: 2.8979576\n",
      "Validation loss: 7.8070478439331055 RMSE: 2.7941096\n",
      "187 8 1.6778870820999146\n",
      "Validation loss: 12.621593475341797 RMSE: 3.5526884\n",
      "Validation loss: 9.769475936889648 RMSE: 3.1256163\n",
      "Validation loss: 8.576884508132935 RMSE: 2.928632\n",
      "190 10 2.4004476070404053\n",
      "Validation loss: 10.44148063659668 RMSE: 3.2313282\n",
      "Validation loss: 9.095539569854736 RMSE: 3.0158813\n",
      "Validation loss: 9.141917705535889 RMSE: 3.0235603\n",
      "193 12 1.249176263809204\n",
      "Validation loss: 11.337235450744629 RMSE: 3.3670814\n",
      "Validation loss: 11.003162622451782 RMSE: 3.3171012\n",
      "Validation loss: 9.513353824615479 RMSE: 3.0843725\n",
      "196 14 2.1456692218780518\n",
      "Validation loss: 11.356237173080444 RMSE: 3.3699014\n",
      "Validation loss: 11.70400094985962 RMSE: 3.4211113\n",
      "Validation loss: 8.921652555465698 RMSE: 2.9869137\n",
      "Validation loss: 9.775144577026367 RMSE: 3.1265228\n",
      "Loaded trained model with success.\n",
      "Test loss: 5.929728968899983 Test RMSE: 2.4351037\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'freesolv', 'model_type': 'gin', 'model': {'num_layer': 3, 'emb_dim': 64, 'feat_dim': 64, 'drop_ratio': 0.5, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 779, 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'target': ['expt']}}\n",
      "Running on: cuda:0\n",
      "641\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/641\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 26.833911895751953\n",
      "Validation loss: 75.14535140991211 RMSE: 8.668642\n",
      "Validation loss: 69.53347778320312 RMSE: 8.338674\n",
      "Validation loss: 63.90630912780762 RMSE: 7.9941425\n",
      "3 2 19.771894454956055\n",
      "Validation loss: 53.97502517700195 RMSE: 7.34677\n",
      "Validation loss: 41.96715545654297 RMSE: 6.478206\n",
      "Validation loss: 26.56889247894287 RMSE: 5.154502\n",
      "6 4 6.239280700683594\n",
      "Validation loss: 16.31663703918457 RMSE: 4.0393853\n",
      "Validation loss: 17.174287796020508 RMSE: 4.1441875\n",
      "Validation loss: 19.049377918243408 RMSE: 4.364559\n",
      "9 6 6.2061262130737305\n",
      "Validation loss: 20.621625900268555 RMSE: 4.541104\n",
      "Validation loss: 14.87417984008789 RMSE: 3.856706\n",
      "Validation loss: 14.385821342468262 RMSE: 3.7928643\n",
      "12 8 5.220791339874268\n",
      "Validation loss: 13.67252492904663 RMSE: 3.6976378\n",
      "Validation loss: 14.62456226348877 RMSE: 3.8242073\n",
      "Validation loss: 14.25782060623169 RMSE: 3.775953\n",
      "15 10 4.8218793869018555\n",
      "Validation loss: 12.703794002532959 RMSE: 3.5642383\n",
      "Validation loss: 12.186807632446289 RMSE: 3.4909608\n",
      "Validation loss: 16.679476737976074 RMSE: 4.0840516\n",
      "18 12 4.892270088195801\n",
      "Validation loss: 14.408047676086426 RMSE: 3.7957935\n",
      "Validation loss: 16.19285249710083 RMSE: 4.0240345\n",
      "Validation loss: 16.178367614746094 RMSE: 4.022234\n",
      "21 14 4.248053550720215\n",
      "Validation loss: 12.123283863067627 RMSE: 3.4818506\n",
      "Validation loss: 13.593700408935547 RMSE: 3.6869633\n",
      "Validation loss: 15.509928703308105 RMSE: 3.9382646\n",
      "Validation loss: 13.74887228012085 RMSE: 3.7079473\n",
      "25 0 6.09351921081543\n",
      "Validation loss: 13.810126304626465 RMSE: 3.716198\n",
      "Validation loss: 12.9635009765625 RMSE: 3.6004863\n",
      "Validation loss: 15.107490539550781 RMSE: 3.8868358\n",
      "28 2 3.771604061126709\n",
      "Validation loss: 15.70130443572998 RMSE: 3.962487\n",
      "Validation loss: 14.812631607055664 RMSE: 3.8487186\n",
      "Validation loss: 18.78047466278076 RMSE: 4.3336444\n",
      "31 4 5.303384780883789\n",
      "Validation loss: 15.678581237792969 RMSE: 3.959619\n",
      "Validation loss: 16.06588363647461 RMSE: 4.008227\n",
      "Validation loss: 13.339862823486328 RMSE: 3.6523778\n",
      "34 6 4.035593509674072\n",
      "Validation loss: 17.53206205368042 RMSE: 4.1871305\n",
      "Validation loss: 13.232747077941895 RMSE: 3.637684\n",
      "Validation loss: 15.893486976623535 RMSE: 3.9866636\n",
      "37 8 2.5991663932800293\n",
      "Validation loss: 21.052067756652832 RMSE: 4.5882535\n",
      "Validation loss: 15.283482551574707 RMSE: 3.9094095\n",
      "Validation loss: 14.889749526977539 RMSE: 3.8587236\n",
      "40 10 2.8445279598236084\n",
      "Validation loss: 19.962360382080078 RMSE: 4.467926\n",
      "Validation loss: 19.84711742401123 RMSE: 4.4550104\n",
      "Validation loss: 19.873504638671875 RMSE: 4.457971\n",
      "43 12 2.2854692935943604\n",
      "Validation loss: 19.615334510803223 RMSE: 4.4289203\n",
      "Validation loss: 16.757787704467773 RMSE: 4.093628\n",
      "Validation loss: 17.161802291870117 RMSE: 4.14268\n",
      "46 14 3.1475284099578857\n",
      "Validation loss: 17.047658920288086 RMSE: 4.1288815\n",
      "Validation loss: 13.790183544158936 RMSE: 3.7135136\n",
      "Validation loss: 16.57191514968872 RMSE: 4.070862\n",
      "Validation loss: 18.23945903778076 RMSE: 4.270768\n",
      "50 0 2.029430389404297\n",
      "Validation loss: 18.245609760284424 RMSE: 4.2714877\n",
      "Validation loss: 15.26039171218872 RMSE: 3.9064553\n",
      "Validation loss: 16.467967987060547 RMSE: 4.0580745\n",
      "53 2 2.261784553527832\n",
      "Validation loss: 17.17769145965576 RMSE: 4.1445975\n",
      "Validation loss: 18.570123195648193 RMSE: 4.3093066\n",
      "Validation loss: 21.626076221466064 RMSE: 4.650385\n",
      "56 4 2.436230182647705\n",
      "Validation loss: 12.716606140136719 RMSE: 3.566035\n",
      "Validation loss: 16.61033344268799 RMSE: 4.0755777\n",
      "Validation loss: 19.73094940185547 RMSE: 4.441953\n",
      "59 6 2.3978188037872314\n",
      "Validation loss: 17.318079948425293 RMSE: 4.1614995\n",
      "Validation loss: 23.333457946777344 RMSE: 4.830472\n",
      "Validation loss: 16.461294174194336 RMSE: 4.0572524\n",
      "62 8 2.9022376537323\n",
      "Validation loss: 18.448674201965332 RMSE: 4.295192\n",
      "Validation loss: 13.296722888946533 RMSE: 3.6464672\n",
      "Validation loss: 15.329339981079102 RMSE: 3.91527\n",
      "65 10 4.636717319488525\n",
      "Validation loss: 15.818836212158203 RMSE: 3.9772897\n",
      "Validation loss: 14.820087909698486 RMSE: 3.8496869\n",
      "Validation loss: 22.064376831054688 RMSE: 4.6972737\n",
      "68 12 3.478229284286499\n",
      "Validation loss: 11.544463157653809 RMSE: 3.3977144\n",
      "Validation loss: 11.231579303741455 RMSE: 3.3513548\n",
      "Validation loss: 13.888216972351074 RMSE: 3.72669\n",
      "71 14 3.7229433059692383\n",
      "Validation loss: 16.756369590759277 RMSE: 4.0934544\n",
      "Validation loss: 15.607864379882812 RMSE: 3.950679\n",
      "Validation loss: 18.456669330596924 RMSE: 4.2961226\n",
      "Validation loss: 15.668131828308105 RMSE: 3.958299\n",
      "75 0 2.2745370864868164\n",
      "Validation loss: 21.638070583343506 RMSE: 4.651674\n",
      "Validation loss: 14.770442485809326 RMSE: 3.843233\n",
      "Validation loss: 20.774573802947998 RMSE: 4.557913\n",
      "78 2 1.8419630527496338\n",
      "Validation loss: 15.624029159545898 RMSE: 3.9527245\n",
      "Validation loss: 20.086277961730957 RMSE: 4.4817715\n",
      "Validation loss: 16.01990056037903 RMSE: 4.0024867\n",
      "81 4 2.3348910808563232\n",
      "Validation loss: 18.28067970275879 RMSE: 4.2755914\n",
      "Validation loss: 18.054944038391113 RMSE: 4.249111\n",
      "Validation loss: 13.872078895568848 RMSE: 3.724524\n",
      "84 6 1.8191039562225342\n",
      "Validation loss: 15.928908348083496 RMSE: 3.9911036\n",
      "Validation loss: 16.610236644744873 RMSE: 4.075566\n",
      "Validation loss: 15.536523818969727 RMSE: 3.9416397\n",
      "87 8 2.6335272789001465\n",
      "Validation loss: 16.825642585754395 RMSE: 4.1019073\n",
      "Validation loss: 16.46008825302124 RMSE: 4.0571036\n",
      "Validation loss: 18.814749717712402 RMSE: 4.3375974\n",
      "90 10 2.8121938705444336\n",
      "Validation loss: 17.24258327484131 RMSE: 4.152419\n",
      "Validation loss: 15.928171634674072 RMSE: 3.9910114\n",
      "Validation loss: 17.306909561157227 RMSE: 4.1601577\n",
      "93 12 2.706005811691284\n",
      "Validation loss: 19.269320487976074 RMSE: 4.3896837\n",
      "Validation loss: 15.81341552734375 RMSE: 3.9766088\n",
      "Validation loss: 20.225346565246582 RMSE: 4.49726\n",
      "96 14 1.89673912525177\n",
      "Validation loss: 13.95846700668335 RMSE: 3.7361033\n",
      "Validation loss: 18.868152618408203 RMSE: 4.3437486\n",
      "Validation loss: 16.583091259002686 RMSE: 4.072234\n",
      "Validation loss: 15.877457618713379 RMSE: 3.984653\n",
      "100 0 2.186100721359253\n",
      "Validation loss: 17.52266025543213 RMSE: 4.186008\n",
      "Validation loss: 15.60267162322998 RMSE: 3.950022\n",
      "Validation loss: 12.183313369750977 RMSE: 3.4904606\n",
      "103 2 1.1707788705825806\n",
      "Validation loss: 15.245354175567627 RMSE: 3.90453\n",
      "Validation loss: 17.562718391418457 RMSE: 4.190789\n",
      "Validation loss: 21.820302963256836 RMSE: 4.6712203\n",
      "106 4 1.5817619562149048\n",
      "Validation loss: 16.093507766723633 RMSE: 4.011671\n",
      "Validation loss: 17.38798427581787 RMSE: 4.1698904\n",
      "Validation loss: 21.550257682800293 RMSE: 4.6422253\n",
      "109 6 1.7039650678634644\n",
      "Validation loss: 17.423501014709473 RMSE: 4.1741467\n",
      "Validation loss: 22.05449390411377 RMSE: 4.6962214\n",
      "Validation loss: 17.076004028320312 RMSE: 4.1323123\n",
      "112 8 1.5616363286972046\n",
      "Validation loss: 21.183292388916016 RMSE: 4.602531\n",
      "Validation loss: 15.812175273895264 RMSE: 3.9764526\n",
      "Validation loss: 17.348429679870605 RMSE: 4.1651444\n",
      "115 10 1.7468383312225342\n",
      "Validation loss: 18.277002811431885 RMSE: 4.2751613\n",
      "Validation loss: 16.114961624145508 RMSE: 4.0143447\n",
      "Validation loss: 12.373105525970459 RMSE: 3.5175424\n",
      "118 12 2.5194694995880127\n",
      "Validation loss: 13.858355522155762 RMSE: 3.7226813\n",
      "Validation loss: 20.86101722717285 RMSE: 4.5673866\n",
      "Validation loss: 23.092485427856445 RMSE: 4.8054643\n",
      "121 14 1.7915257215499878\n",
      "Validation loss: 14.402115821838379 RMSE: 3.7950118\n",
      "Validation loss: 17.160143852233887 RMSE: 4.142481\n",
      "Validation loss: 18.630568504333496 RMSE: 4.316314\n",
      "Validation loss: 15.525225162506104 RMSE: 3.9402063\n",
      "125 0 2.1414568424224854\n",
      "Validation loss: 14.970685005187988 RMSE: 3.869197\n",
      "Validation loss: 14.489550113677979 RMSE: 3.8065143\n",
      "Validation loss: 16.486279487609863 RMSE: 4.06033\n",
      "128 2 1.658356785774231\n",
      "Validation loss: 16.188836097717285 RMSE: 4.0235353\n",
      "Validation loss: 13.842485427856445 RMSE: 3.720549\n",
      "Validation loss: 17.723724365234375 RMSE: 4.2099557\n",
      "131 4 3.260406017303467\n",
      "Validation loss: 17.876319885253906 RMSE: 4.2280393\n",
      "Validation loss: 16.732515335083008 RMSE: 4.0905395\n",
      "Validation loss: 17.392055988311768 RMSE: 4.170378\n",
      "134 6 1.766388177871704\n",
      "Validation loss: 13.313592910766602 RMSE: 3.6487796\n",
      "Validation loss: 14.289844036102295 RMSE: 3.7801907\n",
      "Validation loss: 16.498984336853027 RMSE: 4.0618944\n",
      "137 8 1.549184799194336\n",
      "Validation loss: 17.01658535003662 RMSE: 4.1251163\n",
      "Validation loss: 13.099739074707031 RMSE: 3.6193562\n",
      "Validation loss: 17.611160278320312 RMSE: 4.1965656\n",
      "140 10 1.4453418254852295\n",
      "Validation loss: 18.248090744018555 RMSE: 4.271778\n",
      "Validation loss: 14.711624145507812 RMSE: 3.8355734\n",
      "Validation loss: 16.465950965881348 RMSE: 4.057826\n",
      "143 12 1.4708713293075562\n",
      "Validation loss: 18.02699089050293 RMSE: 4.24582\n",
      "Validation loss: 13.481312274932861 RMSE: 3.6716905\n",
      "Validation loss: 20.004650115966797 RMSE: 4.472656\n",
      "146 14 1.3956975936889648\n",
      "Validation loss: 13.82935905456543 RMSE: 3.7187846\n",
      "Validation loss: 12.446490287780762 RMSE: 3.5279584\n",
      "Validation loss: 11.754411697387695 RMSE: 3.4284704\n",
      "Validation loss: 22.258967399597168 RMSE: 4.717941\n",
      "150 0 1.2610523700714111\n",
      "Validation loss: 14.371780395507812 RMSE: 3.791013\n",
      "Validation loss: 15.369440078735352 RMSE: 3.920388\n",
      "Validation loss: 14.130956172943115 RMSE: 3.7591164\n",
      "153 2 2.779575824737549\n",
      "Validation loss: 14.982024192810059 RMSE: 3.8706622\n",
      "Validation loss: 15.327020168304443 RMSE: 3.9149737\n",
      "Validation loss: 19.121707916259766 RMSE: 4.372837\n",
      "156 4 1.3910233974456787\n",
      "Validation loss: 14.302133083343506 RMSE: 3.7818162\n",
      "Validation loss: 13.794383525848389 RMSE: 3.714079\n",
      "Validation loss: 12.402904987335205 RMSE: 3.521776\n",
      "159 6 1.2175309658050537\n",
      "Validation loss: 16.710355281829834 RMSE: 4.08783\n",
      "Validation loss: 15.416357040405273 RMSE: 3.9263668\n",
      "Validation loss: 14.829877853393555 RMSE: 3.850958\n",
      "162 8 1.2051267623901367\n",
      "Validation loss: 13.770137786865234 RMSE: 3.7108135\n",
      "Validation loss: 13.090353965759277 RMSE: 3.6180594\n",
      "Validation loss: 16.95158624649048 RMSE: 4.1172304\n",
      "165 10 1.7934730052947998\n",
      "Validation loss: 17.60290288925171 RMSE: 4.1955814\n",
      "Validation loss: 17.141735076904297 RMSE: 4.1402574\n",
      "Validation loss: 16.298860549926758 RMSE: 4.0371847\n",
      "168 12 2.148359775543213\n",
      "Validation loss: 16.22042751312256 RMSE: 4.027459\n",
      "Validation loss: 14.631096363067627 RMSE: 3.8250616\n",
      "Validation loss: 14.969284057617188 RMSE: 3.869016\n",
      "171 14 2.3792226314544678\n",
      "Validation loss: 16.25592613220215 RMSE: 4.031864\n",
      "Validation loss: 14.979633808135986 RMSE: 3.8703535\n",
      "Validation loss: 13.216647148132324 RMSE: 3.6354709\n",
      "Validation loss: 16.108505249023438 RMSE: 4.0135403\n",
      "175 0 2.5042874813079834\n",
      "Validation loss: 17.274282455444336 RMSE: 4.1562343\n",
      "Validation loss: 16.997748374938965 RMSE: 4.122833\n",
      "Validation loss: 15.715939044952393 RMSE: 3.9643333\n",
      "178 2 1.6845232248306274\n",
      "Validation loss: 14.912731170654297 RMSE: 3.8617005\n",
      "Validation loss: 14.334722518920898 RMSE: 3.7861223\n",
      "Validation loss: 14.049922943115234 RMSE: 3.7483227\n",
      "181 4 1.0155107975006104\n",
      "Validation loss: 14.09898567199707 RMSE: 3.7548616\n",
      "Validation loss: 16.763413429260254 RMSE: 4.094315\n",
      "Validation loss: 17.14583921432495 RMSE: 4.1407537\n",
      "184 6 2.0093541145324707\n",
      "Validation loss: 16.814468383789062 RMSE: 4.100545\n",
      "Validation loss: 16.379138946533203 RMSE: 4.047115\n",
      "Validation loss: 14.616911888122559 RMSE: 3.823207\n",
      "187 8 1.5749152898788452\n",
      "Validation loss: 17.37217140197754 RMSE: 4.1679935\n",
      "Validation loss: 17.079776763916016 RMSE: 4.1327686\n",
      "Validation loss: 18.08379578590393 RMSE: 4.252505\n",
      "190 10 1.7685546875\n",
      "Validation loss: 16.03535747528076 RMSE: 4.0044174\n",
      "Validation loss: 16.642029285430908 RMSE: 4.0794644\n",
      "Validation loss: 16.70466423034668 RMSE: 4.0871344\n",
      "193 12 1.3419111967086792\n",
      "Validation loss: 16.797399044036865 RMSE: 4.098463\n",
      "Validation loss: 12.633465766906738 RMSE: 3.5543587\n",
      "Validation loss: 14.488470077514648 RMSE: 3.8063724\n",
      "196 14 1.4202499389648438\n",
      "Validation loss: 16.81575345993042 RMSE: 4.100702\n",
      "Validation loss: 14.80267858505249 RMSE: 3.847425\n",
      "Validation loss: 14.118471622467041 RMSE: 3.7574556\n",
      "Validation loss: 15.861045360565186 RMSE: 3.9825928\n",
      "Loaded trained model with success.\n",
      "Test loss: 6.714103647378775 Test RMSE: 2.5911589\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'freesolv', 'model_type': 'gin', 'model': {'num_layer': 3, 'emb_dim': 64, 'feat_dim': 64, 'drop_ratio': 0.5, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 780, 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'target': ['expt']}}\n",
      "Running on: cuda:0\n",
      "641\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/641\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 42.58760452270508\n",
      "Validation loss: 60.91456604003906 RMSE: 7.8047786\n",
      "Validation loss: 55.44733428955078 RMSE: 7.4462967\n",
      "Validation loss: 48.12409782409668 RMSE: 6.9371533\n",
      "3 2 8.643755912780762\n",
      "Validation loss: 36.869951248168945 RMSE: 6.072063\n",
      "Validation loss: 23.278786182403564 RMSE: 4.8248096\n",
      "Validation loss: 18.97474956512451 RMSE: 4.356002\n",
      "6 4 6.208542346954346\n",
      "Validation loss: 17.79307270050049 RMSE: 4.2181835\n",
      "Validation loss: 15.542820930480957 RMSE: 3.9424384\n",
      "Validation loss: 17.184685707092285 RMSE: 4.145442\n",
      "9 6 6.778143405914307\n",
      "Validation loss: 22.971793174743652 RMSE: 4.79289\n",
      "Validation loss: 14.742758750915527 RMSE: 3.83963\n",
      "Validation loss: 15.474694728851318 RMSE: 3.933789\n",
      "12 8 3.9012954235076904\n",
      "Validation loss: 11.669149398803711 RMSE: 3.4160135\n",
      "Validation loss: 11.792389869689941 RMSE: 3.434005\n",
      "Validation loss: 13.151586532592773 RMSE: 3.6265116\n",
      "15 10 5.34123420715332\n",
      "Validation loss: 11.348540306091309 RMSE: 3.3687596\n",
      "Validation loss: 11.752169609069824 RMSE: 3.4281437\n",
      "Validation loss: 13.037576675415039 RMSE: 3.6107585\n",
      "18 12 5.1892924308776855\n",
      "Validation loss: 11.332599639892578 RMSE: 3.3663926\n",
      "Validation loss: 12.587846755981445 RMSE: 3.5479355\n",
      "Validation loss: 11.69992446899414 RMSE: 3.4205153\n",
      "21 14 4.469419002532959\n",
      "Validation loss: 12.092957019805908 RMSE: 3.4774928\n",
      "Validation loss: 11.830615043640137 RMSE: 3.439566\n",
      "Validation loss: 10.354318618774414 RMSE: 3.2178123\n",
      "Validation loss: 11.073052883148193 RMSE: 3.32762\n",
      "25 0 3.9219305515289307\n",
      "Validation loss: 11.131033420562744 RMSE: 3.3363206\n",
      "Validation loss: 11.421395301818848 RMSE: 3.3795555\n",
      "Validation loss: 10.120388507843018 RMSE: 3.1812558\n",
      "28 2 3.3865585327148438\n",
      "Validation loss: 10.962528705596924 RMSE: 3.3109708\n",
      "Validation loss: 9.394875049591064 RMSE: 3.065106\n",
      "Validation loss: 9.247347831726074 RMSE: 3.0409453\n",
      "31 4 1.9734941720962524\n",
      "Validation loss: 12.270503997802734 RMSE: 3.502928\n",
      "Validation loss: 10.810574054718018 RMSE: 3.2879436\n",
      "Validation loss: 12.312551021575928 RMSE: 3.5089245\n",
      "34 6 2.427647113800049\n",
      "Validation loss: 12.365488052368164 RMSE: 3.5164595\n",
      "Validation loss: 10.22634220123291 RMSE: 3.1978648\n",
      "Validation loss: 12.512873411178589 RMSE: 3.537354\n",
      "37 8 3.9127492904663086\n",
      "Validation loss: 11.069737911224365 RMSE: 3.3271213\n",
      "Validation loss: 11.214856624603271 RMSE: 3.348859\n",
      "Validation loss: 11.580851554870605 RMSE: 3.403065\n",
      "40 10 2.437734842300415\n",
      "Validation loss: 13.101481437683105 RMSE: 3.6195974\n",
      "Validation loss: 12.376518726348877 RMSE: 3.5180275\n",
      "Validation loss: 13.242687225341797 RMSE: 3.63905\n",
      "43 12 2.538630485534668\n",
      "Validation loss: 12.215502262115479 RMSE: 3.4950683\n",
      "Validation loss: 15.889572620391846 RMSE: 3.9861727\n",
      "Validation loss: 10.97521162033081 RMSE: 3.312886\n",
      "46 14 3.6367027759552\n",
      "Validation loss: 11.720011711120605 RMSE: 3.4234505\n",
      "Validation loss: 11.828330039978027 RMSE: 3.439234\n",
      "Validation loss: 11.016089916229248 RMSE: 3.3190496\n",
      "Validation loss: 11.18707013130188 RMSE: 3.344708\n",
      "50 0 1.7241379022598267\n",
      "Validation loss: 13.243088722229004 RMSE: 3.6391056\n",
      "Validation loss: 9.94249963760376 RMSE: 3.153173\n",
      "Validation loss: 9.156996726989746 RMSE: 3.0260532\n",
      "53 2 2.0372023582458496\n",
      "Validation loss: 8.932614803314209 RMSE: 2.988748\n",
      "Validation loss: 11.232106685638428 RMSE: 3.3514335\n",
      "Validation loss: 12.20315146446228 RMSE: 3.4933007\n",
      "56 4 5.676271438598633\n",
      "Validation loss: 14.129022598266602 RMSE: 3.7588594\n",
      "Validation loss: 9.146448373794556 RMSE: 3.0243094\n",
      "Validation loss: 14.874916553497314 RMSE: 3.856801\n",
      "59 6 2.2941091060638428\n",
      "Validation loss: 10.725690841674805 RMSE: 3.2750099\n",
      "Validation loss: 10.783423900604248 RMSE: 3.2838125\n",
      "Validation loss: 11.504956722259521 RMSE: 3.3918955\n",
      "62 8 2.211960554122925\n",
      "Validation loss: 10.412421226501465 RMSE: 3.2268283\n",
      "Validation loss: 13.209897994995117 RMSE: 3.634543\n",
      "Validation loss: 13.196643829345703 RMSE: 3.6327183\n",
      "65 10 2.731257915496826\n",
      "Validation loss: 10.953927040100098 RMSE: 3.3096719\n",
      "Validation loss: 8.245187520980835 RMSE: 2.8714433\n",
      "Validation loss: 9.546358585357666 RMSE: 3.089718\n",
      "68 12 2.1764068603515625\n",
      "Validation loss: 10.081706285476685 RMSE: 3.1751704\n",
      "Validation loss: 11.684249877929688 RMSE: 3.4182234\n",
      "Validation loss: 13.013961553573608 RMSE: 3.607487\n",
      "71 14 2.5208048820495605\n",
      "Validation loss: 12.777329444885254 RMSE: 3.5745394\n",
      "Validation loss: 10.417006731033325 RMSE: 3.2275388\n",
      "Validation loss: 12.373898029327393 RMSE: 3.5176554\n",
      "Validation loss: 9.703170776367188 RMSE: 3.114991\n",
      "75 0 2.1246073246002197\n",
      "Validation loss: 14.844768047332764 RMSE: 3.8528907\n",
      "Validation loss: 14.62920331954956 RMSE: 3.8248146\n",
      "Validation loss: 9.313632011413574 RMSE: 3.0518243\n",
      "78 2 2.052844524383545\n",
      "Validation loss: 12.603326320648193 RMSE: 3.5501165\n",
      "Validation loss: 13.48622751235962 RMSE: 3.6723602\n",
      "Validation loss: 14.361445903778076 RMSE: 3.78965\n",
      "81 4 3.6130995750427246\n",
      "Validation loss: 12.722134113311768 RMSE: 3.56681\n",
      "Validation loss: 11.418821811676025 RMSE: 3.379175\n",
      "Validation loss: 9.883975982666016 RMSE: 3.1438792\n",
      "84 6 1.9237819910049438\n",
      "Validation loss: 13.178135395050049 RMSE: 3.6301696\n",
      "Validation loss: 11.499197959899902 RMSE: 3.3910468\n",
      "Validation loss: 10.241638660430908 RMSE: 3.2002566\n",
      "87 8 2.090210437774658\n",
      "Validation loss: 14.232540130615234 RMSE: 3.772604\n",
      "Validation loss: 11.993147373199463 RMSE: 3.4631124\n",
      "Validation loss: 16.08390998840332 RMSE: 4.010475\n",
      "90 10 1.2220901250839233\n",
      "Validation loss: 9.823535919189453 RMSE: 3.1342518\n",
      "Validation loss: 13.7837632894516 RMSE: 3.7126493\n",
      "Validation loss: 11.181392431259155 RMSE: 3.3438587\n",
      "93 12 2.987382411956787\n",
      "Validation loss: 21.986931800842285 RMSE: 4.6890225\n",
      "Validation loss: 9.426644325256348 RMSE: 3.0702841\n",
      "Validation loss: 18.056252479553223 RMSE: 4.249265\n",
      "96 14 1.7637661695480347\n",
      "Validation loss: 11.762689352035522 RMSE: 3.4296775\n",
      "Validation loss: 20.643527507781982 RMSE: 4.543515\n",
      "Validation loss: 13.020130157470703 RMSE: 3.6083422\n",
      "Validation loss: 11.7112398147583 RMSE: 3.4221687\n",
      "100 0 2.019716501235962\n",
      "Validation loss: 11.823119640350342 RMSE: 3.4384766\n",
      "Validation loss: 11.08609676361084 RMSE: 3.3295789\n",
      "Validation loss: 16.437037467956543 RMSE: 4.0542617\n",
      "103 2 2.41351056098938\n",
      "Validation loss: 11.506646156311035 RMSE: 3.3921447\n",
      "Validation loss: 10.569897174835205 RMSE: 3.2511377\n",
      "Validation loss: 11.641484498977661 RMSE: 3.411962\n",
      "106 4 2.718533515930176\n",
      "Validation loss: 8.649471998214722 RMSE: 2.9409983\n",
      "Validation loss: 10.343430042266846 RMSE: 3.21612\n",
      "Validation loss: 12.408530712127686 RMSE: 3.5225744\n",
      "109 6 1.2691460847854614\n",
      "Validation loss: 11.268739223480225 RMSE: 3.3568943\n",
      "Validation loss: 10.17220163345337 RMSE: 3.1893888\n",
      "Validation loss: 8.950523376464844 RMSE: 2.9917426\n",
      "112 8 1.3245139122009277\n",
      "Validation loss: 12.105135917663574 RMSE: 3.4792438\n",
      "Validation loss: 8.108371257781982 RMSE: 2.8475204\n",
      "Validation loss: 10.179800271987915 RMSE: 3.1905797\n",
      "115 10 1.2853162288665771\n",
      "Validation loss: 13.336934089660645 RMSE: 3.651977\n",
      "Validation loss: 12.169151306152344 RMSE: 3.488431\n",
      "Validation loss: 11.368256568908691 RMSE: 3.371685\n",
      "118 12 2.8884975910186768\n",
      "Validation loss: 9.946524620056152 RMSE: 3.153811\n",
      "Validation loss: 12.725843667984009 RMSE: 3.5673306\n",
      "Validation loss: 13.166963577270508 RMSE: 3.6286306\n",
      "121 14 1.375496506690979\n",
      "Validation loss: 11.76710033416748 RMSE: 3.4303207\n",
      "Validation loss: 14.265364646911621 RMSE: 3.7769516\n",
      "Validation loss: 13.225653648376465 RMSE: 3.6367092\n",
      "Validation loss: 11.352447509765625 RMSE: 3.369339\n",
      "125 0 1.9103699922561646\n",
      "Validation loss: 12.59903335571289 RMSE: 3.5495112\n",
      "Validation loss: 12.698612213134766 RMSE: 3.5635111\n",
      "Validation loss: 13.0237717628479 RMSE: 3.6088462\n",
      "128 2 1.08621346950531\n",
      "Validation loss: 12.749138832092285 RMSE: 3.5705938\n",
      "Validation loss: 10.824121475219727 RMSE: 3.2900033\n",
      "Validation loss: 15.516630172729492 RMSE: 3.939116\n",
      "131 4 2.2056641578674316\n",
      "Validation loss: 15.012210369110107 RMSE: 3.8745594\n",
      "Validation loss: 14.866405963897705 RMSE: 3.8556974\n",
      "Validation loss: 17.941640853881836 RMSE: 4.235758\n",
      "134 6 1.7409381866455078\n",
      "Validation loss: 13.78948450088501 RMSE: 3.7134194\n",
      "Validation loss: 10.003874778747559 RMSE: 3.1628902\n",
      "Validation loss: 8.923800945281982 RMSE: 2.9872732\n",
      "137 8 1.2967348098754883\n",
      "Validation loss: 13.169797420501709 RMSE: 3.6290216\n",
      "Validation loss: 13.395010709762573 RMSE: 3.6599193\n",
      "Validation loss: 11.64824390411377 RMSE: 3.4129527\n",
      "140 10 2.2112390995025635\n",
      "Validation loss: 12.163836479187012 RMSE: 3.4876697\n",
      "Validation loss: 13.845115184783936 RMSE: 3.7209024\n",
      "Validation loss: 13.589969635009766 RMSE: 3.6864576\n",
      "143 12 1.7933746576309204\n",
      "Validation loss: 12.730515718460083 RMSE: 3.5679843\n",
      "Validation loss: 9.055929899215698 RMSE: 3.0093071\n",
      "Validation loss: 10.88559865951538 RMSE: 3.299333\n",
      "146 14 2.10542368888855\n",
      "Validation loss: 11.38187837600708 RMSE: 3.3737042\n",
      "Validation loss: 13.020573616027832 RMSE: 3.608403\n",
      "Validation loss: 16.517863035202026 RMSE: 4.064217\n",
      "Validation loss: 14.650874137878418 RMSE: 3.827646\n",
      "150 0 1.815199375152588\n",
      "Validation loss: 10.89470660686493 RMSE: 3.300713\n",
      "Validation loss: 10.71056079864502 RMSE: 3.2726994\n",
      "Validation loss: 10.96188497543335 RMSE: 3.3108737\n",
      "153 2 0.9771010875701904\n",
      "Validation loss: 11.456686019897461 RMSE: 3.3847723\n",
      "Validation loss: 11.00437617301941 RMSE: 3.3172848\n",
      "Validation loss: 9.665681838989258 RMSE: 3.1089678\n",
      "156 4 1.2208918333053589\n",
      "Validation loss: 13.509871006011963 RMSE: 3.6755772\n",
      "Validation loss: 13.553699493408203 RMSE: 3.681535\n",
      "Validation loss: 11.402918338775635 RMSE: 3.3768203\n",
      "159 6 2.503875494003296\n",
      "Validation loss: 14.600645065307617 RMSE: 3.821079\n",
      "Validation loss: 13.53804636001587 RMSE: 3.679408\n",
      "Validation loss: 10.241910934448242 RMSE: 3.2002985\n",
      "162 8 2.728170871734619\n",
      "Validation loss: 14.66383695602417 RMSE: 3.8293395\n",
      "Validation loss: 11.743343353271484 RMSE: 3.4268558\n",
      "Validation loss: 15.048683166503906 RMSE: 3.8792632\n",
      "165 10 1.2281756401062012\n",
      "Validation loss: 11.30041790008545 RMSE: 3.3616095\n",
      "Validation loss: 11.310253143310547 RMSE: 3.3630717\n",
      "Validation loss: 12.594178676605225 RMSE: 3.548828\n",
      "168 12 1.592933177947998\n",
      "Validation loss: 10.798129081726074 RMSE: 3.2860506\n",
      "Validation loss: 11.604544162750244 RMSE: 3.406544\n",
      "Validation loss: 12.239467144012451 RMSE: 3.498495\n",
      "171 14 0.9535010457038879\n",
      "Validation loss: 11.498438358306885 RMSE: 3.3909347\n",
      "Validation loss: 15.516568422317505 RMSE: 3.9391077\n",
      "Validation loss: 16.2843337059021 RMSE: 4.035385\n",
      "Validation loss: 13.122459411621094 RMSE: 3.6224935\n",
      "175 0 2.1889076232910156\n",
      "Validation loss: 9.356445789337158 RMSE: 3.0588307\n",
      "Validation loss: 12.830583333969116 RMSE: 3.5819805\n",
      "Validation loss: 13.998468160629272 RMSE: 3.7414525\n",
      "178 2 1.5270222425460815\n",
      "Validation loss: 12.264874458312988 RMSE: 3.5021243\n",
      "Validation loss: 16.762385368347168 RMSE: 4.0941896\n",
      "Validation loss: 14.761747360229492 RMSE: 3.8421023\n",
      "181 4 2.6912825107574463\n",
      "Validation loss: 13.693156719207764 RMSE: 3.7004268\n",
      "Validation loss: 12.274080276489258 RMSE: 3.5034385\n",
      "Validation loss: 15.521556377410889 RMSE: 3.939741\n",
      "184 6 1.2647347450256348\n",
      "Validation loss: 11.50955843925476 RMSE: 3.3925738\n",
      "Validation loss: 9.94952392578125 RMSE: 3.1542864\n",
      "Validation loss: 10.399190425872803 RMSE: 3.2247777\n",
      "187 8 1.467136263847351\n",
      "Validation loss: 12.627490520477295 RMSE: 3.5535183\n",
      "Validation loss: 17.45857858657837 RMSE: 4.178346\n",
      "Validation loss: 17.966118335723877 RMSE: 4.238646\n",
      "190 10 1.334456205368042\n",
      "Validation loss: 12.457963466644287 RMSE: 3.5295842\n",
      "Validation loss: 13.004022598266602 RMSE: 3.6061094\n",
      "Validation loss: 17.996313095092773 RMSE: 4.2422066\n",
      "193 12 1.1635252237319946\n",
      "Validation loss: 15.531999111175537 RMSE: 3.9410658\n",
      "Validation loss: 15.152225494384766 RMSE: 3.8925855\n",
      "Validation loss: 14.575106620788574 RMSE: 3.8177366\n",
      "196 14 1.1705167293548584\n",
      "Validation loss: 14.115416049957275 RMSE: 3.7570488\n",
      "Validation loss: 12.65699577331543 RMSE: 3.5576673\n",
      "Validation loss: 13.233227014541626 RMSE: 3.63775\n",
      "Validation loss: 17.737749099731445 RMSE: 4.2116203\n",
      "Loaded trained model with success.\n",
      "Test loss: 9.400721472960251 Test RMSE: 3.0660596\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'freesolv', 'model_type': 'gin', 'model': {'num_layer': 3, 'emb_dim': 64, 'feat_dim': 64, 'drop_ratio': 0.5, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'target': ['expt']}}\n",
      "Running on: cuda:0\n",
      "641\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/641\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 15.836889266967773\n",
      "Validation loss: 62.68455696105957 RMSE: 7.917358\n",
      "Validation loss: 57.012123107910156 RMSE: 7.5506372\n",
      "Validation loss: 49.085941314697266 RMSE: 7.006136\n",
      "3 2 11.097665786743164\n",
      "Validation loss: 37.3757266998291 RMSE: 6.1135693\n",
      "Validation loss: 23.515806198120117 RMSE: 4.8493094\n",
      "Validation loss: 20.730826377868652 RMSE: 4.553112\n",
      "6 4 5.90051794052124\n",
      "Validation loss: 21.17693519592285 RMSE: 4.6018405\n",
      "Validation loss: 17.914713382720947 RMSE: 4.232578\n",
      "Validation loss: 18.17143154144287 RMSE: 4.2627964\n",
      "9 6 3.825971841812134\n",
      "Validation loss: 14.819700241088867 RMSE: 3.8496363\n",
      "Validation loss: 14.551791667938232 RMSE: 3.814681\n",
      "Validation loss: 14.97362995147705 RMSE: 3.8695776\n",
      "12 8 2.416637897491455\n",
      "Validation loss: 13.107136249542236 RMSE: 3.6203778\n",
      "Validation loss: 14.856726169586182 RMSE: 3.8544424\n",
      "Validation loss: 11.476296424865723 RMSE: 3.3876681\n",
      "15 10 4.606116771697998\n",
      "Validation loss: 10.793209075927734 RMSE: 3.285302\n",
      "Validation loss: 12.606517791748047 RMSE: 3.5505662\n",
      "Validation loss: 11.202290534973145 RMSE: 3.3469822\n",
      "18 12 3.968108892440796\n",
      "Validation loss: 11.56775188446045 RMSE: 3.4011397\n",
      "Validation loss: 12.340059757232666 RMSE: 3.512842\n",
      "Validation loss: 11.889330863952637 RMSE: 3.4480908\n",
      "21 14 4.42728328704834\n",
      "Validation loss: 10.505716323852539 RMSE: 3.2412522\n",
      "Validation loss: 9.666511535644531 RMSE: 3.1091015\n",
      "Validation loss: 11.678947925567627 RMSE: 3.4174476\n",
      "Validation loss: 12.349506378173828 RMSE: 3.5141864\n",
      "25 0 3.3486368656158447\n",
      "Validation loss: 11.350107669830322 RMSE: 3.368992\n",
      "Validation loss: 12.857425689697266 RMSE: 3.585725\n",
      "Validation loss: 12.576523780822754 RMSE: 3.5463395\n",
      "28 2 3.531459093093872\n",
      "Validation loss: 10.85176420211792 RMSE: 3.2942016\n",
      "Validation loss: 10.810914993286133 RMSE: 3.2879956\n",
      "Validation loss: 12.989429950714111 RMSE: 3.6040852\n",
      "31 4 5.334830284118652\n",
      "Validation loss: 12.307062149047852 RMSE: 3.508142\n",
      "Validation loss: 12.18878698348999 RMSE: 3.4912443\n",
      "Validation loss: 12.768138885498047 RMSE: 3.5732532\n",
      "34 6 3.705237627029419\n",
      "Validation loss: 10.988348960876465 RMSE: 3.314868\n",
      "Validation loss: 11.850507736206055 RMSE: 3.4424567\n",
      "Validation loss: 12.680110931396484 RMSE: 3.5609143\n",
      "37 8 4.009194374084473\n",
      "Validation loss: 13.52130126953125 RMSE: 3.6771321\n",
      "Validation loss: 12.062522888183594 RMSE: 3.4731143\n",
      "Validation loss: 13.142631530761719 RMSE: 3.6252768\n",
      "40 10 2.0575759410858154\n",
      "Validation loss: 14.776654243469238 RMSE: 3.8440413\n",
      "Validation loss: 13.624809265136719 RMSE: 3.6911802\n",
      "Validation loss: 11.707929134368896 RMSE: 3.4216855\n",
      "43 12 3.3251421451568604\n",
      "Validation loss: 12.87522554397583 RMSE: 3.5882063\n",
      "Validation loss: 14.42274808883667 RMSE: 3.7977295\n",
      "Validation loss: 11.104069232940674 RMSE: 3.3322768\n",
      "46 14 2.722989797592163\n",
      "Validation loss: 13.46968412399292 RMSE: 3.6701066\n",
      "Validation loss: 12.654985427856445 RMSE: 3.5573847\n",
      "Validation loss: 14.58470630645752 RMSE: 3.8189926\n",
      "Validation loss: 13.35507583618164 RMSE: 3.6544595\n",
      "50 0 2.2430777549743652\n",
      "Validation loss: 12.784138679504395 RMSE: 3.5754914\n",
      "Validation loss: 14.523705005645752 RMSE: 3.8109982\n",
      "Validation loss: 14.35234785079956 RMSE: 3.788449\n",
      "53 2 3.6090385913848877\n",
      "Validation loss: 14.503986835479736 RMSE: 3.80841\n",
      "Validation loss: 13.892802238464355 RMSE: 3.7273052\n",
      "Validation loss: 11.849605560302734 RMSE: 3.4423254\n",
      "56 4 2.521409749984741\n",
      "Validation loss: 12.664141654968262 RMSE: 3.5586712\n",
      "Validation loss: 13.48801040649414 RMSE: 3.6726024\n",
      "Validation loss: 11.906646490097046 RMSE: 3.450601\n",
      "59 6 1.855533480644226\n",
      "Validation loss: 13.754634857177734 RMSE: 3.7087243\n",
      "Validation loss: 12.813763618469238 RMSE: 3.5796318\n",
      "Validation loss: 13.120113849639893 RMSE: 3.6221697\n",
      "62 8 3.2364661693573\n",
      "Validation loss: 14.574722290039062 RMSE: 3.8176854\n",
      "Validation loss: 13.453378200531006 RMSE: 3.6678846\n",
      "Validation loss: 13.660676956176758 RMSE: 3.6960354\n",
      "65 10 4.507146835327148\n",
      "Validation loss: 11.87881326675415 RMSE: 3.4465654\n",
      "Validation loss: 13.9548659324646 RMSE: 3.7356212\n",
      "Validation loss: 14.491736888885498 RMSE: 3.8068013\n",
      "68 12 2.113509178161621\n",
      "Validation loss: 11.007071495056152 RMSE: 3.3176906\n",
      "Validation loss: 14.98388957977295 RMSE: 3.870903\n",
      "Validation loss: 12.86396312713623 RMSE: 3.5866365\n",
      "71 14 3.598642110824585\n",
      "Validation loss: 14.224241733551025 RMSE: 3.771504\n",
      "Validation loss: 15.031939506530762 RMSE: 3.8771045\n",
      "Validation loss: 14.29060173034668 RMSE: 3.7802913\n",
      "Validation loss: 14.89383316040039 RMSE: 3.859253\n",
      "75 0 1.5618822574615479\n",
      "Validation loss: 14.052214622497559 RMSE: 3.7486284\n",
      "Validation loss: 13.947000503540039 RMSE: 3.7345684\n",
      "Validation loss: 15.76298999786377 RMSE: 3.9702632\n",
      "78 2 1.5523728132247925\n",
      "Validation loss: 12.060805320739746 RMSE: 3.472867\n",
      "Validation loss: 14.686697483062744 RMSE: 3.8323226\n",
      "Validation loss: 12.895263671875 RMSE: 3.5909977\n",
      "81 4 4.050037860870361\n",
      "Validation loss: 13.584814548492432 RMSE: 3.6857584\n",
      "Validation loss: 14.314716815948486 RMSE: 3.7834797\n",
      "Validation loss: 13.439750671386719 RMSE: 3.6660266\n",
      "84 6 3.3195230960845947\n",
      "Validation loss: 11.729799270629883 RMSE: 3.4248796\n",
      "Validation loss: 13.083785057067871 RMSE: 3.6171515\n",
      "Validation loss: 13.220550060272217 RMSE: 3.6360075\n",
      "87 8 2.701209783554077\n",
      "Validation loss: 14.578010559082031 RMSE: 3.8181162\n",
      "Validation loss: 14.177767753601074 RMSE: 3.7653377\n",
      "Validation loss: 16.154043197631836 RMSE: 4.0192094\n",
      "90 10 3.4278204441070557\n",
      "Validation loss: 14.159347534179688 RMSE: 3.762891\n",
      "Validation loss: 15.047846794128418 RMSE: 3.8791556\n",
      "Validation loss: 14.032790660858154 RMSE: 3.7460368\n",
      "93 12 1.29795241355896\n",
      "Validation loss: 16.597023963928223 RMSE: 4.0739446\n",
      "Validation loss: 14.729246616363525 RMSE: 3.8378696\n",
      "Validation loss: 13.5913724899292 RMSE: 3.6866477\n",
      "96 14 1.5326571464538574\n",
      "Validation loss: 15.078452110290527 RMSE: 3.8830981\n",
      "Validation loss: 15.145539283752441 RMSE: 3.8917272\n",
      "Validation loss: 17.842333793640137 RMSE: 4.2240186\n",
      "Validation loss: 15.47825574874878 RMSE: 3.9342415\n",
      "100 0 1.9359506368637085\n",
      "Validation loss: 13.931262016296387 RMSE: 3.7324605\n",
      "Validation loss: 14.182850360870361 RMSE: 3.7660124\n",
      "Validation loss: 16.30178451538086 RMSE: 4.0375466\n",
      "103 2 1.914188027381897\n",
      "Validation loss: 15.348910808563232 RMSE: 3.9177687\n",
      "Validation loss: 15.840888977050781 RMSE: 3.9800615\n",
      "Validation loss: 17.193900108337402 RMSE: 4.146553\n",
      "106 4 1.9533716440200806\n",
      "Validation loss: 16.558000564575195 RMSE: 4.0691524\n",
      "Validation loss: 18.790475368499756 RMSE: 4.3347983\n",
      "Validation loss: 14.875694751739502 RMSE: 3.8569021\n",
      "109 6 1.8790496587753296\n",
      "Validation loss: 16.566755771636963 RMSE: 4.070228\n",
      "Validation loss: 15.474287986755371 RMSE: 3.933737\n",
      "Validation loss: 15.642772674560547 RMSE: 3.9550946\n",
      "112 8 1.9986177682876587\n",
      "Validation loss: 13.138240337371826 RMSE: 3.6246712\n",
      "Validation loss: 14.817541122436523 RMSE: 3.8493557\n",
      "Validation loss: 15.146055698394775 RMSE: 3.8917935\n",
      "115 10 1.4149750471115112\n",
      "Validation loss: 15.309179782867432 RMSE: 3.9126947\n",
      "Validation loss: 15.582376956939697 RMSE: 3.9474518\n",
      "Validation loss: 16.87795877456665 RMSE: 4.108279\n",
      "118 12 2.2196009159088135\n",
      "Validation loss: 16.568329334259033 RMSE: 4.070421\n",
      "Validation loss: 14.83411455154419 RMSE: 3.8515081\n",
      "Validation loss: 16.379456520080566 RMSE: 4.047154\n",
      "121 14 1.6021028757095337\n",
      "Validation loss: 14.650845527648926 RMSE: 3.8276422\n",
      "Validation loss: 12.476433277130127 RMSE: 3.5321996\n",
      "Validation loss: 14.652266025543213 RMSE: 3.8278277\n",
      "Validation loss: 16.005722999572754 RMSE: 4.0007153\n",
      "125 0 1.6334266662597656\n",
      "Validation loss: 16.885493755340576 RMSE: 4.109196\n",
      "Validation loss: 15.592400550842285 RMSE: 3.9487214\n",
      "Validation loss: 17.140564918518066 RMSE: 4.140116\n",
      "128 2 1.4495500326156616\n",
      "Validation loss: 15.437652111053467 RMSE: 3.9290779\n",
      "Validation loss: 20.381781578063965 RMSE: 4.5146184\n",
      "Validation loss: 15.501226425170898 RMSE: 3.9371598\n",
      "131 4 2.0520524978637695\n",
      "Validation loss: 15.923194885253906 RMSE: 3.990388\n",
      "Validation loss: 14.766668319702148 RMSE: 3.842742\n",
      "Validation loss: 16.079764366149902 RMSE: 4.0099583\n",
      "134 6 1.9603219032287598\n",
      "Validation loss: 13.499643325805664 RMSE: 3.674186\n",
      "Validation loss: 21.311403274536133 RMSE: 4.616428\n",
      "Validation loss: 17.208723545074463 RMSE: 4.14834\n",
      "137 8 3.1161627769470215\n",
      "Validation loss: 17.64346408843994 RMSE: 4.2004123\n",
      "Validation loss: 16.138182640075684 RMSE: 4.0172358\n",
      "Validation loss: 14.691280841827393 RMSE: 3.8329208\n",
      "140 10 2.387836456298828\n",
      "Validation loss: 13.008587837219238 RMSE: 3.6067421\n",
      "Validation loss: 15.835911750793457 RMSE: 3.979436\n",
      "Validation loss: 15.761628150939941 RMSE: 3.9700918\n",
      "143 12 0.9798659086227417\n",
      "Validation loss: 14.683408260345459 RMSE: 3.8318934\n",
      "Validation loss: 17.120700359344482 RMSE: 4.137717\n",
      "Validation loss: 21.087583541870117 RMSE: 4.592122\n",
      "146 14 2.135769844055176\n",
      "Validation loss: 18.535487174987793 RMSE: 4.305286\n",
      "Validation loss: 17.420568466186523 RMSE: 4.173795\n",
      "Validation loss: 15.036506175994873 RMSE: 3.8776934\n",
      "Validation loss: 17.11328363418579 RMSE: 4.136821\n",
      "150 0 1.94441819190979\n",
      "Validation loss: 17.2722430229187 RMSE: 4.1559887\n",
      "Validation loss: 13.934503555297852 RMSE: 3.732895\n",
      "Validation loss: 17.51425266265869 RMSE: 4.1850033\n",
      "153 2 1.4875587224960327\n",
      "Validation loss: 15.877665519714355 RMSE: 3.9846785\n",
      "Validation loss: 23.429883003234863 RMSE: 4.8404427\n",
      "Validation loss: 16.79820442199707 RMSE: 4.0985613\n",
      "156 4 2.4910237789154053\n",
      "Validation loss: 17.360262870788574 RMSE: 4.166565\n",
      "Validation loss: 17.252824783325195 RMSE: 4.1536517\n",
      "Validation loss: 16.52699613571167 RMSE: 4.065341\n",
      "159 6 1.9406969547271729\n",
      "Validation loss: 17.562942504882812 RMSE: 4.1908164\n",
      "Validation loss: 17.05458116531372 RMSE: 4.1297193\n",
      "Validation loss: 14.776034355163574 RMSE: 3.8439605\n",
      "162 8 2.6326963901519775\n",
      "Validation loss: 19.181628227233887 RMSE: 4.3796835\n",
      "Validation loss: 18.748898029327393 RMSE: 4.33\n",
      "Validation loss: 18.741426467895508 RMSE: 4.329137\n",
      "165 10 2.839773416519165\n",
      "Validation loss: 18.13044500350952 RMSE: 4.257986\n",
      "Validation loss: 22.59136962890625 RMSE: 4.753038\n",
      "Validation loss: 16.357956886291504 RMSE: 4.044497\n",
      "168 12 1.2345364093780518\n",
      "Validation loss: 17.60714054107666 RMSE: 4.1960864\n",
      "Validation loss: 16.54814338684082 RMSE: 4.0679407\n",
      "Validation loss: 16.50381898880005 RMSE: 4.062489\n",
      "171 14 1.2747893333435059\n",
      "Validation loss: 21.683622360229492 RMSE: 4.656568\n",
      "Validation loss: 17.52825117111206 RMSE: 4.1866755\n",
      "Validation loss: 21.67080783843994 RMSE: 4.6551914\n",
      "Validation loss: 16.7213454246521 RMSE: 4.089174\n",
      "175 0 1.0611820220947266\n",
      "Validation loss: 21.034027099609375 RMSE: 4.586287\n",
      "Validation loss: 18.452611923217773 RMSE: 4.2956505\n",
      "Validation loss: 20.44581413269043 RMSE: 4.521705\n",
      "178 2 2.0078864097595215\n",
      "Validation loss: 18.716838836669922 RMSE: 4.3262963\n",
      "Validation loss: 18.727206230163574 RMSE: 4.3274937\n",
      "Validation loss: 20.322877883911133 RMSE: 4.5080905\n",
      "181 4 1.10328209400177\n",
      "Validation loss: 17.925917148590088 RMSE: 4.233901\n",
      "Validation loss: 14.752135276794434 RMSE: 3.8408508\n",
      "Validation loss: 17.188231468200684 RMSE: 4.145869\n",
      "184 6 1.4969754219055176\n",
      "Validation loss: 20.12010097503662 RMSE: 4.4855433\n",
      "Validation loss: 17.058608055114746 RMSE: 4.1302066\n",
      "Validation loss: 15.463094711303711 RMSE: 3.9323142\n",
      "187 8 1.3695558309555054\n",
      "Validation loss: 19.69688129425049 RMSE: 4.4381166\n",
      "Validation loss: 14.748483657836914 RMSE: 3.8403757\n",
      "Validation loss: 13.8600754737854 RMSE: 3.7229123\n",
      "190 10 0.7963688969612122\n",
      "Validation loss: 19.457613468170166 RMSE: 4.4110785\n",
      "Validation loss: 17.936443328857422 RMSE: 4.2351437\n",
      "Validation loss: 14.148600101470947 RMSE: 3.7614622\n",
      "193 12 1.528286337852478\n",
      "Validation loss: 19.342254161834717 RMSE: 4.3979826\n",
      "Validation loss: 16.326866626739502 RMSE: 4.040652\n",
      "Validation loss: 13.628666877746582 RMSE: 3.6917024\n",
      "196 14 1.2697595357894897\n",
      "Validation loss: 14.597075462341309 RMSE: 3.8206117\n",
      "Validation loss: 21.475959300994873 RMSE: 4.6342163\n",
      "Validation loss: 13.356581687927246 RMSE: 3.6546657\n",
      "Validation loss: 14.02692985534668 RMSE: 3.7452543\n",
      "Loaded trained model with success.\n",
      "Test loss: 13.429134275363042 Test RMSE: 3.6645787\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'target': ['measured log solubility in mols per litre']}}\n",
      "Running on: cuda:0\n",
      "1127\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1127\n",
      "Generating scaffold 1000/1127\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 6.542383193969727\n",
      "Validation loss: 2.1550592078571826 RMSE: 1.468012\n",
      "1 21 4.693037986755371\n",
      "Validation loss: 4.276926690498285 RMSE: 2.068073\n",
      "Validation loss: 9.51169905198359 RMSE: 3.084104\n",
      "3 13 0.9443207383155823\n",
      "Validation loss: 10.782457330585581 RMSE: 3.2836654\n",
      "Validation loss: 9.700266686161008 RMSE: 3.1145253\n",
      "5 5 1.8848166465759277\n",
      "Validation loss: 14.102408307843504 RMSE: 3.7553172\n",
      "6 26 1.2941434383392334\n",
      "Validation loss: 15.588344219511589 RMSE: 3.9482079\n",
      "Validation loss: 6.164780363572382 RMSE: 2.4828975\n",
      "8 18 1.221293330192566\n",
      "Validation loss: 19.010431728531827 RMSE: 4.3600955\n",
      "Validation loss: 15.792114502560777 RMSE: 3.9739294\n",
      "10 10 1.3018630743026733\n",
      "Validation loss: 13.700597155410632 RMSE: 3.7014318\n",
      "Validation loss: 9.987162961369068 RMSE: 3.1602473\n",
      "12 2 0.5829788446426392\n",
      "Validation loss: 15.230230331420898 RMSE: 3.9025927\n",
      "13 23 0.8842197060585022\n",
      "Validation loss: 6.403542649429457 RMSE: 2.5305223\n",
      "Validation loss: 7.669462199759694 RMSE: 2.7693794\n",
      "15 15 0.8252661824226379\n",
      "Validation loss: 6.888736509643825 RMSE: 2.6246402\n",
      "Validation loss: 3.89911531558079 RMSE: 1.9746177\n",
      "17 7 3.0797617435455322\n",
      "Validation loss: 8.909604984047139 RMSE: 2.9848962\n",
      "18 28 1.0680866241455078\n",
      "Validation loss: 7.995262871801326 RMSE: 2.8275895\n",
      "Validation loss: 8.466968895059772 RMSE: 2.9098058\n",
      "20 20 0.6330023407936096\n",
      "Validation loss: 9.234182501261213 RMSE: 3.0387797\n",
      "Validation loss: 6.027292188289946 RMSE: 2.4550543\n",
      "22 12 1.2552261352539062\n",
      "Validation loss: 5.783382297617145 RMSE: 2.4048662\n",
      "Validation loss: 3.2867647272295657 RMSE: 1.8129438\n",
      "24 4 0.7864307165145874\n",
      "Validation loss: 4.950107983783283 RMSE: 2.224884\n",
      "25 25 0.9977188110351562\n",
      "Validation loss: 9.463211262120609 RMSE: 3.0762331\n",
      "Validation loss: 9.153290512287512 RMSE: 3.0254405\n",
      "27 17 0.7203858494758606\n",
      "Validation loss: 4.63848202629427 RMSE: 2.1537135\n",
      "Validation loss: 6.960286954862881 RMSE: 2.6382356\n",
      "29 9 0.776146650314331\n",
      "Validation loss: 2.300785456083517 RMSE: 1.516834\n",
      "Validation loss: 4.055785626436757 RMSE: 2.013898\n",
      "31 1 0.9799058437347412\n",
      "Validation loss: 2.6266546966755286 RMSE: 1.6206957\n",
      "32 22 0.5275142192840576\n",
      "Validation loss: 2.9044202365706453 RMSE: 1.704236\n",
      "Validation loss: 4.86657902202775 RMSE: 2.2060325\n",
      "34 14 0.7122330069541931\n",
      "Validation loss: 4.605301194486365 RMSE: 2.1459966\n",
      "Validation loss: 4.96570070654945 RMSE: 2.2283852\n",
      "36 6 0.22545617818832397\n",
      "Validation loss: 4.412725368432239 RMSE: 2.1006489\n",
      "37 27 0.4931987226009369\n",
      "Validation loss: 6.29962708464766 RMSE: 2.5099056\n",
      "Validation loss: 3.544827146867735 RMSE: 1.8827711\n",
      "39 19 0.47300979495048523\n",
      "Validation loss: 3.8502637432739797 RMSE: 1.962209\n",
      "Validation loss: 7.323227882385254 RMSE: 2.7061465\n",
      "41 11 0.5762791037559509\n",
      "Validation loss: 8.16506870236017 RMSE: 2.8574584\n",
      "Validation loss: 2.1900862191630677 RMSE: 1.4798939\n",
      "43 3 1.1876641511917114\n",
      "Validation loss: 4.762290676083185 RMSE: 2.1822674\n",
      "44 24 1.4720430374145508\n",
      "Validation loss: 2.483670200921793 RMSE: 1.5759665\n",
      "Validation loss: 4.696570862711003 RMSE: 2.1671574\n",
      "46 16 1.015872836112976\n",
      "Validation loss: 3.507135047321826 RMSE: 1.8727347\n",
      "Validation loss: 2.5668896394493306 RMSE: 1.6021516\n",
      "48 8 0.9366257786750793\n",
      "Validation loss: 3.452276504145259 RMSE: 1.8580303\n",
      "Validation loss: 5.236083431581481 RMSE: 2.288249\n",
      "50 0 0.38919955492019653\n",
      "Validation loss: 3.8383810857755947 RMSE: 1.9591787\n",
      "51 21 0.4477389454841614\n",
      "Validation loss: 4.8539864236274655 RMSE: 2.2031765\n",
      "Validation loss: 7.059931442800877 RMSE: 2.657053\n",
      "53 13 0.5969052314758301\n",
      "Validation loss: 5.461819555907123 RMSE: 2.3370535\n",
      "Validation loss: 7.674851358464334 RMSE: 2.7703521\n",
      "55 5 0.49996280670166016\n",
      "Validation loss: 4.04164246331274 RMSE: 2.0103836\n",
      "56 26 0.5562180280685425\n",
      "Validation loss: 4.847647915899226 RMSE: 2.2017376\n",
      "Validation loss: 2.9760107656495762 RMSE: 1.725112\n",
      "58 18 0.8013144135475159\n",
      "Validation loss: 3.5990432553586706 RMSE: 1.8971144\n",
      "Validation loss: 6.662896219608003 RMSE: 2.5812585\n",
      "60 10 0.6024275422096252\n",
      "Validation loss: 6.188967135100238 RMSE: 2.4877634\n",
      "Validation loss: 3.60860230859402 RMSE: 1.8996321\n",
      "62 2 0.6098146438598633\n",
      "Validation loss: 2.348800838521097 RMSE: 1.5325798\n",
      "63 23 0.28704696893692017\n",
      "Validation loss: 4.238525711329637 RMSE: 2.058768\n",
      "Validation loss: 3.0511548983312284 RMSE: 1.7467556\n",
      "65 15 0.6723828315734863\n",
      "Validation loss: 2.7110666237046233 RMSE: 1.6465318\n",
      "Validation loss: 3.009938343436317 RMSE: 1.7349174\n",
      "67 7 0.8865921497344971\n",
      "Validation loss: 3.878939542095218 RMSE: 1.9695022\n",
      "68 28 1.048007845878601\n",
      "Validation loss: 4.1880409147887105 RMSE: 2.0464704\n",
      "Validation loss: 2.2085721935846108 RMSE: 1.4861264\n",
      "70 20 0.4763656556606293\n",
      "Validation loss: 4.174867819895787 RMSE: 2.0432494\n",
      "Validation loss: 7.278462815073739 RMSE: 2.6978626\n",
      "72 12 0.37852200865745544\n",
      "Validation loss: 2.421913756733447 RMSE: 1.55625\n",
      "Validation loss: 3.3917552834063507 RMSE: 1.841672\n",
      "74 4 0.39117103815078735\n",
      "Validation loss: 6.120859158777558 RMSE: 2.474037\n",
      "75 25 0.4971882700920105\n",
      "Validation loss: 2.9637533647824177 RMSE: 1.7215556\n",
      "Validation loss: 3.4436256358053834 RMSE: 1.855701\n",
      "77 17 0.5292566418647766\n",
      "Validation loss: 3.293717321041411 RMSE: 1.8148601\n",
      "Validation loss: 3.275937675374799 RMSE: 1.8099552\n",
      "79 9 0.6454417705535889\n",
      "Validation loss: 3.092446920091072 RMSE: 1.7585355\n",
      "Validation loss: 2.0835579654811758 RMSE: 1.4434534\n",
      "81 1 0.5217885375022888\n",
      "Validation loss: 3.446739846626214 RMSE: 1.8565397\n",
      "82 22 1.1621795892715454\n",
      "Validation loss: 3.650101708099905 RMSE: 1.9105239\n",
      "Validation loss: 2.8643622609366357 RMSE: 1.6924427\n",
      "84 14 0.3802264332771301\n",
      "Validation loss: 5.256073848336144 RMSE: 2.2926128\n",
      "Validation loss: 3.762227282059931 RMSE: 1.9396461\n",
      "86 6 0.6038574576377869\n",
      "Validation loss: 2.94093313364856 RMSE: 1.714915\n",
      "87 27 0.5317209362983704\n",
      "Validation loss: 3.0791472228227463 RMSE: 1.7547498\n",
      "Validation loss: 5.6252188977942 RMSE: 2.3717544\n",
      "89 19 1.0390455722808838\n",
      "Validation loss: 2.9953519221955696 RMSE: 1.7307084\n",
      "Validation loss: 2.566719126912345 RMSE: 1.6020983\n",
      "91 11 0.7142745852470398\n",
      "Validation loss: 3.4646396214983106 RMSE: 1.8613542\n",
      "Validation loss: 3.4471385626666313 RMSE: 1.8566473\n",
      "93 3 0.4886510670185089\n",
      "Validation loss: 4.092343047656844 RMSE: 2.022954\n",
      "94 24 0.3504929840564728\n",
      "Validation loss: 3.79675275245599 RMSE: 1.9485258\n",
      "Validation loss: 3.8970886416139856 RMSE: 1.9741045\n",
      "96 16 0.4961601495742798\n",
      "Validation loss: 4.24229742151446 RMSE: 2.0596838\n",
      "Validation loss: 3.7773311897716693 RMSE: 1.9435358\n",
      "98 8 0.7236322164535522\n",
      "Validation loss: 4.644390001761175 RMSE: 2.1550844\n",
      "Validation loss: 2.8612255480437154 RMSE: 1.6915156\n",
      "100 0 0.5295901894569397\n",
      "Validation loss: 3.9757719504094755 RMSE: 1.9939339\n",
      "101 21 0.4691411256790161\n",
      "Validation loss: 3.3228497906068784 RMSE: 1.8228686\n",
      "Validation loss: 4.494395268701874 RMSE: 2.119999\n",
      "103 13 0.9212981462478638\n",
      "Validation loss: 2.5592130011161873 RMSE: 1.599754\n",
      "Validation loss: 3.7301506932857817 RMSE: 1.9313599\n",
      "105 5 0.31796684861183167\n",
      "Validation loss: 9.291378493857595 RMSE: 3.0481763\n",
      "106 26 1.106097936630249\n",
      "Validation loss: 3.3564762288490226 RMSE: 1.8320689\n",
      "Validation loss: 5.127863930389944 RMSE: 2.2644787\n",
      "108 18 0.34610792994499207\n",
      "Validation loss: 3.7947738318316704 RMSE: 1.9480178\n",
      "Validation loss: 3.5798011290288603 RMSE: 1.8920363\n",
      "110 10 0.21835799515247345\n",
      "Validation loss: 3.2509222811302254 RMSE: 1.8030314\n",
      "Validation loss: 6.87425217586281 RMSE: 2.6218793\n",
      "112 2 0.8092785477638245\n",
      "Validation loss: 4.717385600098466 RMSE: 2.1719544\n",
      "113 23 0.4440459609031677\n",
      "Validation loss: 8.78268995538222 RMSE: 2.9635603\n",
      "Validation loss: 3.65859584048786 RMSE: 1.9127456\n",
      "115 15 0.3401549458503723\n",
      "Validation loss: 4.181840368076763 RMSE: 2.044955\n",
      "Validation loss: 14.557397251635527 RMSE: 3.8154156\n",
      "117 7 0.6912372708320618\n",
      "Validation loss: 2.6392768442103294 RMSE: 1.6245852\n",
      "118 28 2.297351360321045\n",
      "Validation loss: 5.44677377380101 RMSE: 2.3338323\n",
      "Validation loss: 3.2760932930802875 RMSE: 1.8099982\n",
      "120 20 0.7825402021408081\n",
      "Validation loss: 3.5539054912803447 RMSE: 1.8851805\n",
      "Validation loss: 4.345380968752161 RMSE: 2.0845578\n",
      "122 12 0.5313402414321899\n",
      "Validation loss: 2.451921469342392 RMSE: 1.5658612\n",
      "Validation loss: 3.3181358354281536 RMSE: 1.821575\n",
      "124 4 0.4249289035797119\n",
      "Validation loss: 3.71151355726529 RMSE: 1.9265289\n",
      "125 25 0.5189369320869446\n",
      "Validation loss: 2.7481650799776602 RMSE: 1.6577591\n",
      "Validation loss: 2.3102476596832275 RMSE: 1.5199499\n",
      "127 17 0.6327404975891113\n",
      "Validation loss: 2.9401619075673873 RMSE: 1.7146901\n",
      "Validation loss: 2.0380839425905615 RMSE: 1.4276148\n",
      "129 9 1.0481951236724854\n",
      "Validation loss: 2.144406434708992 RMSE: 1.4643792\n",
      "Validation loss: 2.882476538683461 RMSE: 1.6977857\n",
      "131 1 0.5657325387001038\n",
      "Validation loss: 2.4002424341387454 RMSE: 1.5492716\n",
      "132 22 0.7221516966819763\n",
      "Validation loss: 3.690818900555636 RMSE: 1.9211503\n",
      "Validation loss: 3.2345959401763644 RMSE: 1.7984984\n",
      "134 14 0.23854108154773712\n",
      "Validation loss: 2.046883112561386 RMSE: 1.4306933\n",
      "Validation loss: 2.1887505001726404 RMSE: 1.4794426\n",
      "136 6 0.24756789207458496\n",
      "Validation loss: 2.225569772509347 RMSE: 1.4918344\n",
      "137 27 0.3645782768726349\n",
      "Validation loss: 3.0143894009885535 RMSE: 1.7361999\n",
      "Validation loss: 4.361358380950658 RMSE: 2.0883865\n",
      "139 19 0.3592199683189392\n",
      "Validation loss: 3.272445666051544 RMSE: 1.8089901\n",
      "Validation loss: 2.4779705885237298 RMSE: 1.5741571\n",
      "141 11 0.6485277414321899\n",
      "Validation loss: 5.387285734699891 RMSE: 2.3210526\n",
      "Validation loss: 3.3178865361002696 RMSE: 1.8215069\n",
      "143 3 0.2314750850200653\n",
      "Validation loss: 3.1656850776841154 RMSE: 1.7792373\n",
      "144 24 0.3333994150161743\n",
      "Validation loss: 4.03963885265114 RMSE: 2.0098853\n",
      "Validation loss: 3.063753956187088 RMSE: 1.7503582\n",
      "146 16 0.3970538377761841\n",
      "Validation loss: 3.6493609647835252 RMSE: 1.91033\n",
      "Validation loss: 2.29762199494691 RMSE: 1.5157908\n",
      "148 8 0.5208112001419067\n",
      "Validation loss: 2.0730701684951782 RMSE: 1.4398161\n",
      "Validation loss: 2.15588465623096 RMSE: 1.4682932\n",
      "150 0 0.6318179368972778\n",
      "Validation loss: 3.1818373751851308 RMSE: 1.7837706\n",
      "151 21 0.48722711205482483\n",
      "Validation loss: 2.4277299547617415 RMSE: 1.5581175\n",
      "Validation loss: 4.994589244369912 RMSE: 2.2348578\n",
      "153 13 1.0635465383529663\n",
      "Validation loss: 4.925806359907167 RMSE: 2.2194157\n",
      "Validation loss: 3.5421926321181574 RMSE: 1.8820714\n",
      "155 5 0.5033639073371887\n",
      "Validation loss: 2.773644147721012 RMSE: 1.6654263\n",
      "156 26 0.4373755156993866\n",
      "Validation loss: 4.8088351983939654 RMSE: 2.1929057\n",
      "Validation loss: 2.348242628890856 RMSE: 1.5323976\n",
      "158 18 0.21666906774044037\n",
      "Validation loss: 3.0368416119465786 RMSE: 1.7426536\n",
      "Validation loss: 6.988386441121059 RMSE: 2.6435556\n",
      "160 10 0.32407769560813904\n",
      "Validation loss: 2.517562116141868 RMSE: 1.5866827\n",
      "Validation loss: 3.5333181714589617 RMSE: 1.8797123\n",
      "162 2 0.6397833228111267\n",
      "Validation loss: 2.734089144563253 RMSE: 1.6535083\n",
      "163 23 0.39437928795814514\n",
      "Validation loss: 2.97789951552332 RMSE: 1.7256591\n",
      "Validation loss: 2.396236580030053 RMSE: 1.5479782\n",
      "165 15 0.7326216697692871\n",
      "Validation loss: 2.488013099780125 RMSE: 1.5773436\n",
      "Validation loss: 2.771295349154852 RMSE: 1.6647209\n",
      "167 7 0.6072171330451965\n",
      "Validation loss: 4.657389472016191 RMSE: 2.1580985\n",
      "168 28 0.47168099880218506\n",
      "Validation loss: 5.257440875061845 RMSE: 2.292911\n",
      "Validation loss: 4.052622286619338 RMSE: 2.0131125\n",
      "170 20 0.6280129551887512\n",
      "Validation loss: 4.026801586151123 RMSE: 2.0066893\n",
      "Validation loss: 3.2545276500482476 RMSE: 1.8040309\n",
      "172 12 0.28823578357696533\n",
      "Validation loss: 2.3299251383384774 RMSE: 1.5264093\n",
      "Validation loss: 2.3898746397642965 RMSE: 1.5459219\n",
      "174 4 0.34765100479125977\n",
      "Validation loss: 2.3817294688351387 RMSE: 1.5432854\n",
      "175 25 0.5923177599906921\n",
      "Validation loss: 3.0637787717633542 RMSE: 1.7503653\n",
      "Validation loss: 3.088415087851803 RMSE: 1.7573887\n",
      "177 17 0.6334691047668457\n",
      "Validation loss: 4.827383501339803 RMSE: 2.1971307\n",
      "Validation loss: 2.4193812091793636 RMSE: 1.555436\n",
      "179 9 0.20158837735652924\n",
      "Validation loss: 2.281639751079863 RMSE: 1.5105097\n",
      "Validation loss: 2.590329942450059 RMSE: 1.6094502\n",
      "181 1 0.9405263066291809\n",
      "Validation loss: 3.2342223066144284 RMSE: 1.7983944\n",
      "182 22 0.48026043176651\n",
      "Validation loss: 2.6319313344702255 RMSE: 1.6223229\n",
      "Validation loss: 3.0515805145280552 RMSE: 1.7468773\n",
      "184 14 0.34182995557785034\n",
      "Validation loss: 6.002514607083481 RMSE: 2.4500031\n",
      "Validation loss: 4.750869662360808 RMSE: 2.179649\n",
      "186 6 0.6362467408180237\n",
      "Validation loss: 2.8820021025902403 RMSE: 1.697646\n",
      "187 27 0.5039639472961426\n",
      "Validation loss: 2.5554897890681714 RMSE: 1.5985901\n",
      "Validation loss: 4.152282233786794 RMSE: 2.0377147\n",
      "189 19 0.18707476556301117\n",
      "Validation loss: 8.759742888729129 RMSE: 2.9596863\n",
      "Validation loss: 3.705050835567238 RMSE: 1.9248508\n",
      "191 11 0.4309253692626953\n",
      "Validation loss: 3.1719190842282456 RMSE: 1.7809883\n",
      "Validation loss: 2.3347807679556114 RMSE: 1.5279989\n",
      "193 3 0.42964601516723633\n",
      "Validation loss: 3.2214560234441167 RMSE: 1.7948415\n",
      "194 24 0.43667730689048767\n",
      "Validation loss: 2.603066045626075 RMSE: 1.613402\n",
      "Validation loss: 2.7555303658004355 RMSE: 1.659979\n",
      "196 16 0.585239052772522\n",
      "Validation loss: 3.737591781447419 RMSE: 1.9332852\n",
      "Validation loss: 3.48134154345082 RMSE: 1.8658353\n",
      "198 8 0.6526398658752441\n",
      "Validation loss: 2.53968480203004 RMSE: 1.5936389\n",
      "Validation loss: 4.071798172672238 RMSE: 2.0178697\n",
      "Loaded trained model with success.\n",
      "Test loss: 2.1635213594521043 Test RMSE: 1.4708914\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 778, 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'target': ['measured log solubility in mols per litre']}}\n",
      "Running on: cuda:0\n",
      "1127\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1127\n",
      "Generating scaffold 1000/1127\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 8.101311683654785\n",
      "Validation loss: 2.2298171224847305 RMSE: 1.4932573\n",
      "1 21 1.9943225383758545\n",
      "Validation loss: 10.210442597887157 RMSE: 3.1953783\n",
      "Validation loss: 11.020536017628897 RMSE: 3.319719\n",
      "3 13 3.2810370922088623\n",
      "Validation loss: 3.013152567686233 RMSE: 1.7358435\n",
      "Validation loss: 2.5251434123621577 RMSE: 1.5890698\n",
      "5 5 1.2158747911453247\n",
      "Validation loss: 5.302868079295201 RMSE: 2.3027956\n",
      "6 26 1.5511175394058228\n",
      "Validation loss: 3.9995012030137325 RMSE: 1.9998753\n",
      "Validation loss: 4.086249127852178 RMSE: 2.0214472\n",
      "8 18 1.2474253177642822\n",
      "Validation loss: 3.521792116418349 RMSE: 1.8766438\n",
      "Validation loss: 3.6721923477881777 RMSE: 1.9162965\n",
      "10 10 1.7975131273269653\n",
      "Validation loss: 2.9836394238260997 RMSE: 1.7273214\n",
      "Validation loss: 2.5860246873534884 RMSE: 1.6081122\n",
      "12 2 1.4187206029891968\n",
      "Validation loss: 2.8996841169036593 RMSE: 1.7028459\n",
      "13 23 1.4552422761917114\n",
      "Validation loss: 3.817493352214847 RMSE: 1.9538406\n",
      "Validation loss: 3.3239460772117684 RMSE: 1.8231692\n",
      "15 15 1.0520633459091187\n",
      "Validation loss: 3.148805827166127 RMSE: 1.7744874\n",
      "Validation loss: 2.7086390605015036 RMSE: 1.6457943\n",
      "17 7 1.7953238487243652\n",
      "Validation loss: 2.4221334626189375 RMSE: 1.5563205\n",
      "18 28 2.353358268737793\n",
      "Validation loss: 3.235713429155603 RMSE: 1.7988089\n",
      "Validation loss: 2.2496522580627847 RMSE: 1.499884\n",
      "20 20 0.9860371947288513\n",
      "Validation loss: 2.615683922725441 RMSE: 1.6173077\n",
      "Validation loss: 1.919453322359946 RMSE: 1.3854434\n",
      "22 12 0.7284182906150818\n",
      "Validation loss: 2.2819565355250266 RMSE: 1.5106146\n",
      "Validation loss: 2.3786874787997356 RMSE: 1.5422995\n",
      "24 4 0.5199676752090454\n",
      "Validation loss: 2.909809729694265 RMSE: 1.7058165\n",
      "25 25 1.0020244121551514\n",
      "Validation loss: 2.9653041257267505 RMSE: 1.7220058\n",
      "Validation loss: 2.041353491555273 RMSE: 1.4287595\n",
      "27 17 0.6451528668403625\n",
      "Validation loss: 3.8997687322903523 RMSE: 1.9747832\n",
      "Validation loss: 2.514218617329555 RMSE: 1.5856287\n",
      "29 9 0.7453689575195312\n",
      "Validation loss: 2.342913128633415 RMSE: 1.5306578\n",
      "Validation loss: 2.246718184082909 RMSE: 1.4989057\n",
      "31 1 0.8538960218429565\n",
      "Validation loss: 2.654813768589391 RMSE: 1.6293601\n",
      "32 22 1.2272108793258667\n",
      "Validation loss: 1.886435627937317 RMSE: 1.3734758\n",
      "Validation loss: 2.1316767224168354 RMSE: 1.4600263\n",
      "34 14 0.80483478307724\n",
      "Validation loss: 2.762629846555997 RMSE: 1.6621159\n",
      "Validation loss: 2.140017515790146 RMSE: 1.4628799\n",
      "36 6 0.769996166229248\n",
      "Validation loss: 2.9558007105261876 RMSE: 1.7192441\n",
      "37 27 0.5807454586029053\n",
      "Validation loss: 2.6364699528280613 RMSE: 1.623721\n",
      "Validation loss: 2.2024251528545817 RMSE: 1.4840571\n",
      "39 19 0.8027656674385071\n",
      "Validation loss: 2.5358032315178254 RMSE: 1.5924207\n",
      "Validation loss: 2.2794464963727292 RMSE: 1.5097837\n",
      "41 11 0.5119016170501709\n",
      "Validation loss: 3.0515666029094595 RMSE: 1.7468733\n",
      "Validation loss: 2.857137080842415 RMSE: 1.6903068\n",
      "43 3 0.741037130355835\n",
      "Validation loss: 2.584589116341245 RMSE: 1.6076657\n",
      "44 24 0.8861410617828369\n",
      "Validation loss: 1.9242986514505032 RMSE: 1.3871909\n",
      "Validation loss: 2.3630699330726554 RMSE: 1.537228\n",
      "46 16 0.6059294939041138\n",
      "Validation loss: 3.651514011146748 RMSE: 1.9108934\n",
      "Validation loss: 1.9063471882744174 RMSE: 1.3807054\n",
      "48 8 0.9003989696502686\n",
      "Validation loss: 2.205520786015333 RMSE: 1.4850997\n",
      "Validation loss: 1.9250142268374957 RMSE: 1.3874488\n",
      "50 0 0.7829598784446716\n",
      "Validation loss: 2.013445682230249 RMSE: 1.4189594\n",
      "51 21 0.7602775692939758\n",
      "Validation loss: 1.9207886003814967 RMSE: 1.3859252\n",
      "Validation loss: 2.076469752640851 RMSE: 1.440996\n",
      "53 13 1.279445767402649\n",
      "Validation loss: 2.0289778266332847 RMSE: 1.4244219\n",
      "Validation loss: 2.1671995124985686 RMSE: 1.472141\n",
      "55 5 1.6523878574371338\n",
      "Validation loss: 2.192358006418279 RMSE: 1.4806614\n",
      "56 26 0.8356373310089111\n",
      "Validation loss: 1.7958132334515058 RMSE: 1.3400795\n",
      "Validation loss: 3.8988402185186875 RMSE: 1.9745481\n",
      "58 18 0.3549972176551819\n",
      "Validation loss: 1.8571277255505587 RMSE: 1.3627647\n",
      "Validation loss: 2.0985882967974234 RMSE: 1.4486506\n",
      "60 10 0.40343019366264343\n",
      "Validation loss: 1.8669469651922714 RMSE: 1.3663628\n",
      "Validation loss: 2.5368669328436386 RMSE: 1.5927545\n",
      "62 2 1.1509568691253662\n",
      "Validation loss: 1.78090147845513 RMSE: 1.3345041\n",
      "63 23 0.9646130204200745\n",
      "Validation loss: 2.5780006467768577 RMSE: 1.6056153\n",
      "Validation loss: 2.227467701498386 RMSE: 1.4924703\n",
      "65 15 0.4638015627861023\n",
      "Validation loss: 1.967022659504308 RMSE: 1.4025059\n",
      "Validation loss: 1.9379802478098236 RMSE: 1.3921134\n",
      "67 7 0.7691926956176758\n",
      "Validation loss: 1.8507032436607158 RMSE: 1.3604054\n",
      "68 28 0.5680397152900696\n",
      "Validation loss: 1.8696343666684312 RMSE: 1.3673457\n",
      "Validation loss: 1.8926653840900522 RMSE: 1.3757417\n",
      "70 20 0.4766850173473358\n",
      "Validation loss: 1.6592074273961834 RMSE: 1.2881023\n",
      "Validation loss: 1.7149983422946087 RMSE: 1.3095795\n",
      "72 12 0.4159330129623413\n",
      "Validation loss: 2.018278275970864 RMSE: 1.4206612\n",
      "Validation loss: 1.8816341931841014 RMSE: 1.3717268\n",
      "74 4 0.6093376874923706\n",
      "Validation loss: 2.5639496915108335 RMSE: 1.601234\n",
      "75 25 0.4207770824432373\n",
      "Validation loss: 2.4286374929731926 RMSE: 1.5584087\n",
      "Validation loss: 2.064899825416835 RMSE: 1.436976\n",
      "77 17 0.682460606098175\n",
      "Validation loss: 1.8700422270108112 RMSE: 1.3674948\n",
      "Validation loss: 2.0236271029025055 RMSE: 1.4225425\n",
      "79 9 0.5943928956985474\n",
      "Validation loss: 2.4094525596736807 RMSE: 1.5522411\n",
      "Validation loss: 1.864473109751676 RMSE: 1.3654572\n",
      "81 1 1.2183232307434082\n",
      "Validation loss: 1.9377308123934585 RMSE: 1.392024\n",
      "82 22 0.5914798974990845\n",
      "Validation loss: 2.065686747036149 RMSE: 1.4372497\n",
      "Validation loss: 2.0685564870327973 RMSE: 1.4382477\n",
      "84 14 0.5866608619689941\n",
      "Validation loss: 2.3089473310825044 RMSE: 1.5195221\n",
      "Validation loss: 1.7637804409043978 RMSE: 1.328074\n",
      "86 6 1.1556243896484375\n",
      "Validation loss: 2.1774966547974444 RMSE: 1.4756343\n",
      "87 27 0.7705949544906616\n",
      "Validation loss: 1.971335104081483 RMSE: 1.4040424\n",
      "Validation loss: 1.8564232408472923 RMSE: 1.3625062\n",
      "89 19 0.4593117833137512\n",
      "Validation loss: 2.0761678092247617 RMSE: 1.4408914\n",
      "Validation loss: 1.9838401807092987 RMSE: 1.4084886\n",
      "91 11 0.4945075809955597\n",
      "Validation loss: 1.8291752370057908 RMSE: 1.35247\n",
      "Validation loss: 2.2252046808732295 RMSE: 1.491712\n",
      "93 3 0.851700484752655\n",
      "Validation loss: 2.204952667244768 RMSE: 1.4849083\n",
      "94 24 0.7383664846420288\n",
      "Validation loss: 1.9182883796438706 RMSE: 1.3850229\n",
      "Validation loss: 1.7027081335540366 RMSE: 1.3048785\n",
      "96 16 0.4674965739250183\n",
      "Validation loss: 1.868089561968778 RMSE: 1.3667808\n",
      "Validation loss: 1.9056774578263274 RMSE: 1.3804628\n",
      "98 8 0.2472880333662033\n",
      "Validation loss: 1.7308373261342007 RMSE: 1.3156129\n",
      "Validation loss: 1.9501005147410706 RMSE: 1.39646\n",
      "100 0 0.755174994468689\n",
      "Validation loss: 2.0998508297236618 RMSE: 1.4490862\n",
      "101 21 0.5763952732086182\n",
      "Validation loss: 1.812711004134828 RMSE: 1.3463695\n",
      "Validation loss: 1.9010417218756888 RMSE: 1.3787827\n",
      "103 13 0.29531872272491455\n",
      "Validation loss: 2.1780865614393115 RMSE: 1.4758341\n",
      "Validation loss: 2.3179767648730656 RMSE: 1.5224904\n",
      "105 5 0.4732339680194855\n",
      "Validation loss: 1.5860637310331902 RMSE: 1.2593902\n",
      "106 26 0.5724813342094421\n",
      "Validation loss: 2.289111015015999 RMSE: 1.5129809\n",
      "Validation loss: 1.8384068613558744 RMSE: 1.3558787\n",
      "108 18 0.5077935457229614\n",
      "Validation loss: 2.1092622111328936 RMSE: 1.45233\n",
      "Validation loss: 1.9269613017023137 RMSE: 1.3881503\n",
      "110 10 0.48366621136665344\n",
      "Validation loss: 1.9444613266835171 RMSE: 1.3944393\n",
      "Validation loss: 1.9978638433777125 RMSE: 1.4134581\n",
      "112 2 0.9494106769561768\n",
      "Validation loss: 1.5960812352399911 RMSE: 1.263361\n",
      "113 23 0.5990666151046753\n",
      "Validation loss: 1.8885388891253851 RMSE: 1.3742412\n",
      "Validation loss: 2.0415421882561877 RMSE: 1.4288254\n",
      "115 15 0.5870360732078552\n",
      "Validation loss: 2.3495769458534443 RMSE: 1.532833\n",
      "Validation loss: 2.1764726596595967 RMSE: 1.4752873\n",
      "117 7 0.547751784324646\n",
      "Validation loss: 1.9389180936644563 RMSE: 1.3924505\n",
      "118 28 0.9753893613815308\n",
      "Validation loss: 1.7827269376906674 RMSE: 1.3351879\n",
      "Validation loss: 2.094793450515882 RMSE: 1.4473401\n",
      "120 20 0.43883582949638367\n",
      "Validation loss: 2.02421766466799 RMSE: 1.42275\n",
      "Validation loss: 2.105951952723275 RMSE: 1.4511899\n",
      "122 12 0.37144070863723755\n",
      "Validation loss: 2.016958167067671 RMSE: 1.4201965\n",
      "Validation loss: 1.7572956222348508 RMSE: 1.3256303\n",
      "124 4 0.4019958972930908\n",
      "Validation loss: 1.7858460371473195 RMSE: 1.3363554\n",
      "125 25 0.2654450833797455\n",
      "Validation loss: 2.1551087282400214 RMSE: 1.4680289\n",
      "Validation loss: 1.6940442202365504 RMSE: 1.3015546\n",
      "127 17 0.5020115971565247\n",
      "Validation loss: 2.230298510694926 RMSE: 1.4934183\n",
      "Validation loss: 2.6341768640332517 RMSE: 1.6230148\n",
      "129 9 0.4667547047138214\n",
      "Validation loss: 1.7359742822900284 RMSE: 1.3175638\n",
      "Validation loss: 2.4450756237570164 RMSE: 1.5636739\n",
      "131 1 0.5762052536010742\n",
      "Validation loss: 2.3327145259992212 RMSE: 1.5273226\n",
      "132 22 0.6590930819511414\n",
      "Validation loss: 1.8051233101735074 RMSE: 1.3435488\n",
      "Validation loss: 2.3082219235664976 RMSE: 1.5192833\n",
      "134 14 0.7131665945053101\n",
      "Validation loss: 1.5748278567221312 RMSE: 1.2549214\n",
      "Validation loss: 1.8763514124186693 RMSE: 1.3697997\n",
      "136 6 0.4998709559440613\n",
      "Validation loss: 1.9630744409772147 RMSE: 1.4010977\n",
      "137 27 0.4218111038208008\n",
      "Validation loss: 1.8756170125134224 RMSE: 1.3695316\n",
      "Validation loss: 2.120187187616804 RMSE: 1.4560862\n",
      "139 19 0.6240831017494202\n",
      "Validation loss: 2.071673629558192 RMSE: 1.4393309\n",
      "Validation loss: 1.7941282850451175 RMSE: 1.3394507\n",
      "141 11 0.4646134078502655\n",
      "Validation loss: 1.7434590580189122 RMSE: 1.3204011\n",
      "Validation loss: 2.6525172343296286 RMSE: 1.6286551\n",
      "143 3 0.30972644686698914\n",
      "Validation loss: 1.7064819399234468 RMSE: 1.3063239\n",
      "144 24 0.643189549446106\n",
      "Validation loss: 1.917716216197056 RMSE: 1.3848164\n",
      "Validation loss: 1.7730749096490641 RMSE: 1.3315685\n",
      "146 16 0.3453614115715027\n",
      "Validation loss: 1.980129045722759 RMSE: 1.4071705\n",
      "Validation loss: 1.7725210411358723 RMSE: 1.3313606\n",
      "148 8 0.308781236410141\n",
      "Validation loss: 1.6522384744829837 RMSE: 1.2853943\n",
      "Validation loss: 2.070491647298357 RMSE: 1.4389203\n",
      "150 0 0.33073854446411133\n",
      "Validation loss: 1.5155996073663762 RMSE: 1.2310969\n",
      "151 21 0.5101401805877686\n",
      "Validation loss: 2.0151680064412343 RMSE: 1.4195662\n",
      "Validation loss: 1.9342375919882175 RMSE: 1.3907688\n",
      "153 13 0.5524907112121582\n",
      "Validation loss: 1.6742448986104104 RMSE: 1.2939261\n",
      "Validation loss: 1.8726811556689507 RMSE: 1.3684595\n",
      "155 5 0.5211617946624756\n",
      "Validation loss: 1.5481862156792026 RMSE: 1.2442614\n",
      "156 26 0.4593142867088318\n",
      "Validation loss: 1.7682771988674604 RMSE: 1.3297658\n",
      "Validation loss: 1.9728022486762662 RMSE: 1.4045647\n",
      "158 18 0.45776915550231934\n",
      "Validation loss: 1.9433612570298457 RMSE: 1.3940449\n",
      "Validation loss: 1.8573085670977567 RMSE: 1.362831\n",
      "160 10 0.5650086402893066\n",
      "Validation loss: 2.137283793592875 RMSE: 1.4619453\n",
      "Validation loss: 1.6144085784928988 RMSE: 1.2705938\n",
      "162 2 0.35333195328712463\n",
      "Validation loss: 1.7138358090831116 RMSE: 1.3091354\n",
      "163 23 0.36489206552505493\n",
      "Validation loss: 1.902756602363249 RMSE: 1.3794044\n",
      "Validation loss: 1.5962366066147795 RMSE: 1.2634225\n",
      "165 15 0.3082078695297241\n",
      "Validation loss: 1.6992429610902229 RMSE: 1.3035501\n",
      "Validation loss: 1.8574933425515099 RMSE: 1.3628988\n",
      "167 7 0.3537863790988922\n",
      "Validation loss: 1.6025222856386574 RMSE: 1.2659078\n",
      "168 28 0.4946718215942383\n",
      "Validation loss: 2.238584526872213 RMSE: 1.4961901\n",
      "Validation loss: 1.9924305962250295 RMSE: 1.4115348\n",
      "170 20 0.6207868456840515\n",
      "Validation loss: 1.7434024314964767 RMSE: 1.3203796\n",
      "Validation loss: 2.210998399067769 RMSE: 1.4869426\n",
      "172 12 0.34661757946014404\n",
      "Validation loss: 1.727834363954257 RMSE: 1.3144711\n",
      "Validation loss: 2.271979688543134 RMSE: 1.5073087\n",
      "174 4 0.3501952886581421\n",
      "Validation loss: 1.8444906800194125 RMSE: 1.3581203\n",
      "175 25 0.6528626680374146\n",
      "Validation loss: 1.8202138664448155 RMSE: 1.349153\n",
      "Validation loss: 2.151300033636853 RMSE: 1.4667311\n",
      "177 17 0.7684731483459473\n",
      "Validation loss: 1.6807297805769255 RMSE: 1.2964296\n",
      "Validation loss: 1.876285855749012 RMSE: 1.3697759\n",
      "179 9 0.8838412165641785\n",
      "Validation loss: 1.6879248745673525 RMSE: 1.2992016\n",
      "Validation loss: 2.2318583906224343 RMSE: 1.4939407\n",
      "181 1 0.2292580008506775\n",
      "Validation loss: 1.781118706264327 RMSE: 1.3345857\n",
      "182 22 0.28958797454833984\n",
      "Validation loss: 1.6676524001940163 RMSE: 1.2913761\n",
      "Validation loss: 1.841963502158106 RMSE: 1.3571895\n",
      "184 14 0.40391501784324646\n",
      "Validation loss: 1.6292467243903506 RMSE: 1.2764194\n",
      "Validation loss: 2.0116485589373427 RMSE: 1.4183259\n",
      "186 6 0.35040614008903503\n",
      "Validation loss: 1.747805511001992 RMSE: 1.322046\n",
      "187 27 0.33213770389556885\n",
      "Validation loss: 1.85164757428971 RMSE: 1.3607525\n",
      "Validation loss: 1.5315729369104436 RMSE: 1.2375673\n",
      "189 19 0.4629771113395691\n",
      "Validation loss: 1.6334540369236363 RMSE: 1.2780665\n",
      "Validation loss: 1.6978288593545425 RMSE: 1.3030076\n",
      "191 11 0.39025089144706726\n",
      "Validation loss: 2.0648073031839016 RMSE: 1.4369438\n",
      "Validation loss: 1.8313611091765682 RMSE: 1.3532779\n",
      "193 3 0.3291635513305664\n",
      "Validation loss: 1.556941753995102 RMSE: 1.2477747\n",
      "194 24 0.35318422317504883\n",
      "Validation loss: 1.4058411205764365 RMSE: 1.1856817\n",
      "Validation loss: 1.908782040123391 RMSE: 1.3815868\n",
      "196 16 0.4292929172515869\n",
      "Validation loss: 1.7529669440953077 RMSE: 1.3239965\n",
      "Validation loss: 1.9721450457530738 RMSE: 1.4043307\n",
      "198 8 1.7508118152618408\n",
      "Validation loss: 1.8651933775538891 RMSE: 1.3657209\n",
      "Validation loss: 2.15880249242867 RMSE: 1.4692864\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.4997137236384164 Test RMSE: 1.2246281\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 779, 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'target': ['measured log solubility in mols per litre']}}\n",
      "Running on: cuda:0\n",
      "1127\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1127\n",
      "Generating scaffold 1000/1127\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 8.452099800109863\n",
      "Validation loss: 1.8606134600343958 RMSE: 1.364043\n",
      "1 21 2.10312557220459\n",
      "Validation loss: 6.420641882229695 RMSE: 2.5338986\n",
      "Validation loss: 10.928057067162168 RMSE: 3.3057613\n",
      "3 13 2.0987186431884766\n",
      "Validation loss: 14.592965092279215 RMSE: 3.8200738\n",
      "Validation loss: 15.85905465826524 RMSE: 3.982343\n",
      "5 5 1.1481202840805054\n",
      "Validation loss: 13.889128440249282 RMSE: 3.7268121\n",
      "6 26 2.9511096477508545\n",
      "Validation loss: 6.930795635797281 RMSE: 2.6326404\n",
      "Validation loss: 9.222943305969238 RMSE: 3.0369298\n",
      "8 18 1.3909735679626465\n",
      "Validation loss: 12.390679047170993 RMSE: 3.5200398\n",
      "Validation loss: 14.36214875752947 RMSE: 3.7897427\n",
      "10 10 1.57631254196167\n",
      "Validation loss: 6.533997392232439 RMSE: 2.5561686\n",
      "Validation loss: 14.666222209424044 RMSE: 3.8296504\n",
      "12 2 0.9365140795707703\n",
      "Validation loss: 13.805477264708122 RMSE: 3.715572\n",
      "13 23 0.697513997554779\n",
      "Validation loss: 6.711208351945455 RMSE: 2.5906\n",
      "Validation loss: 5.988822325141029 RMSE: 2.447207\n",
      "15 15 0.4847111701965332\n",
      "Validation loss: 9.502673157548482 RMSE: 3.0826404\n",
      "Validation loss: 8.636093164967225 RMSE: 2.938723\n",
      "17 7 0.6645398139953613\n",
      "Validation loss: 7.078939864065795 RMSE: 2.6606276\n",
      "18 28 3.161895990371704\n",
      "Validation loss: 5.22006849694041 RMSE: 2.284747\n",
      "Validation loss: 9.026647972849618 RMSE: 3.004438\n",
      "20 20 1.8228473663330078\n",
      "Validation loss: 2.9409084720949155 RMSE: 1.7149076\n",
      "Validation loss: 5.503648656659422 RMSE: 2.3459857\n",
      "22 12 0.7528173923492432\n",
      "Validation loss: 4.398822383543031 RMSE: 2.097337\n",
      "Validation loss: 4.554841898183907 RMSE: 2.1342075\n",
      "24 4 2.1529433727264404\n",
      "Validation loss: 3.101936492244754 RMSE: 1.7612315\n",
      "25 25 0.8033789992332458\n",
      "Validation loss: 4.98005635337492 RMSE: 2.2316039\n",
      "Validation loss: 4.59670001848609 RMSE: 2.1439915\n",
      "27 17 0.7274025678634644\n",
      "Validation loss: 4.932212913985801 RMSE: 2.2208586\n",
      "Validation loss: 4.9492338484367435 RMSE: 2.2246876\n",
      "29 9 0.5821298956871033\n",
      "Validation loss: 2.4825260829081577 RMSE: 1.5756035\n",
      "Validation loss: 3.69828866857343 RMSE: 1.9230934\n",
      "31 1 1.7415871620178223\n",
      "Validation loss: 8.546157288340341 RMSE: 2.923381\n",
      "32 22 0.6101580262184143\n",
      "Validation loss: 3.260888249473234 RMSE: 1.805793\n",
      "Validation loss: 3.129791166930072 RMSE: 1.7691215\n",
      "34 14 0.36087799072265625\n",
      "Validation loss: 2.5128956632276553 RMSE: 1.5852114\n",
      "Validation loss: 3.4937653098486168 RMSE: 1.8691615\n",
      "36 6 0.6791731715202332\n",
      "Validation loss: 5.290626639813448 RMSE: 2.300136\n",
      "37 27 0.6495535373687744\n",
      "Validation loss: 2.0397403050312954 RMSE: 1.4281948\n",
      "Validation loss: 2.631913642967697 RMSE: 1.6223174\n",
      "39 19 0.5946244597434998\n",
      "Validation loss: 4.588118097423452 RMSE: 2.1419892\n",
      "Validation loss: 2.137381745650705 RMSE: 1.4619787\n",
      "41 11 1.130831003189087\n",
      "Validation loss: 3.6559761667673567 RMSE: 1.9120609\n",
      "Validation loss: 5.2716260462735605 RMSE: 2.2960021\n",
      "43 3 0.2856829762458801\n",
      "Validation loss: 3.104697501764888 RMSE: 1.7620152\n",
      "44 24 1.1728286743164062\n",
      "Validation loss: 4.995127217959514 RMSE: 2.2349784\n",
      "Validation loss: 3.295127290540037 RMSE: 1.8152486\n",
      "46 16 0.7484549880027771\n",
      "Validation loss: 5.314622435949545 RMSE: 2.3053465\n",
      "Validation loss: 4.796999889137471 RMSE: 2.1902056\n",
      "48 8 0.5928214192390442\n",
      "Validation loss: 3.7553223909529962 RMSE: 1.9378654\n",
      "Validation loss: 2.9223289257657212 RMSE: 1.7094822\n",
      "50 0 1.2178819179534912\n",
      "Validation loss: 5.6221324574630875 RMSE: 2.3711035\n",
      "51 21 0.598624587059021\n",
      "Validation loss: 6.139575088973594 RMSE: 2.4778166\n",
      "Validation loss: 2.7558575309483353 RMSE: 1.6600776\n",
      "53 13 0.5835414528846741\n",
      "Validation loss: 2.688159735856858 RMSE: 1.6395608\n",
      "Validation loss: 3.169040449952657 RMSE: 1.7801799\n",
      "55 5 1.067337989807129\n",
      "Validation loss: 4.766916863686215 RMSE: 2.1833272\n",
      "56 26 0.30854782462120056\n",
      "Validation loss: 3.1025978780425754 RMSE: 1.7614193\n",
      "Validation loss: 4.852380203989755 RMSE: 2.202812\n",
      "58 18 1.3194926977157593\n",
      "Validation loss: 3.9343045749495515 RMSE: 1.9835081\n",
      "Validation loss: 4.4421278080054085 RMSE: 2.1076355\n",
      "60 10 0.5443023443222046\n",
      "Validation loss: 3.3217121900710382 RMSE: 1.8225565\n",
      "Validation loss: 3.929834239250791 RMSE: 1.9823809\n",
      "62 2 1.0131405591964722\n",
      "Validation loss: 3.026479689420852 RMSE: 1.7396781\n",
      "63 23 0.8846548795700073\n",
      "Validation loss: 3.109590912287214 RMSE: 1.7634033\n",
      "Validation loss: 2.2633504276782013 RMSE: 1.5044435\n",
      "65 15 0.7913640141487122\n",
      "Validation loss: 3.3149113802783257 RMSE: 1.8206898\n",
      "Validation loss: 4.649614705448657 RMSE: 2.1562965\n",
      "67 7 1.3347375392913818\n",
      "Validation loss: 3.0234751258276207 RMSE: 1.7388144\n",
      "68 28 0.4693061113357544\n",
      "Validation loss: 2.9697838736846385 RMSE: 1.7233062\n",
      "Validation loss: 2.060810719971108 RMSE: 1.4355524\n",
      "70 20 0.4902510941028595\n",
      "Validation loss: 6.487001545661319 RMSE: 2.5469592\n",
      "Validation loss: 2.8476257218723804 RMSE: 1.6874909\n",
      "72 12 1.0784785747528076\n",
      "Validation loss: 3.177147078303109 RMSE: 1.7824553\n",
      "Validation loss: 2.020179482687891 RMSE: 1.4213301\n",
      "74 4 1.0266300439834595\n",
      "Validation loss: 3.6989485141450325 RMSE: 1.923265\n",
      "75 25 0.8953437805175781\n",
      "Validation loss: 3.296249733561963 RMSE: 1.8155577\n",
      "Validation loss: 2.2804482489560556 RMSE: 1.5101153\n",
      "77 17 0.5130527019500732\n",
      "Validation loss: 2.1496824152701723 RMSE: 1.4661796\n",
      "Validation loss: 3.8588877969083533 RMSE: 1.9644051\n",
      "79 9 0.449238657951355\n",
      "Validation loss: 2.127822523623441 RMSE: 1.4587058\n",
      "Validation loss: 1.9402454331912826 RMSE: 1.3929269\n",
      "81 1 1.3351784944534302\n",
      "Validation loss: 2.045295285967599 RMSE: 1.4301381\n",
      "82 22 0.32038572430610657\n",
      "Validation loss: 2.1258694091729358 RMSE: 1.4580361\n",
      "Validation loss: 2.0461730250215107 RMSE: 1.4304451\n",
      "84 14 0.2551717162132263\n",
      "Validation loss: 4.452893797275239 RMSE: 2.1101882\n",
      "Validation loss: 2.331192147415296 RMSE: 1.5268242\n",
      "86 6 0.46153634786605835\n",
      "Validation loss: 2.172149605455652 RMSE: 1.4738214\n",
      "87 27 0.3729078769683838\n",
      "Validation loss: 2.6347329025774933 RMSE: 1.623186\n",
      "Validation loss: 2.679936719151725 RMSE: 1.6370511\n",
      "89 19 0.5027863383293152\n",
      "Validation loss: 2.4882000167812923 RMSE: 1.577403\n",
      "Validation loss: 2.72274252798705 RMSE: 1.6500734\n",
      "91 11 0.42754098773002625\n",
      "Validation loss: 2.7708705146755794 RMSE: 1.6645932\n",
      "Validation loss: 2.6363737414368487 RMSE: 1.6236916\n",
      "93 3 0.5676369667053223\n",
      "Validation loss: 2.05506142156314 RMSE: 1.4335486\n",
      "94 24 0.4144447445869446\n",
      "Validation loss: 2.357673237809038 RMSE: 1.5354716\n",
      "Validation loss: 2.548302956387005 RMSE: 1.5963404\n",
      "96 16 0.383499413728714\n",
      "Validation loss: 2.375506584623219 RMSE: 1.5412679\n",
      "Validation loss: 2.957769948824317 RMSE: 1.7198169\n",
      "98 8 0.36498555541038513\n",
      "Validation loss: 2.1757883856781817 RMSE: 1.4750555\n",
      "Validation loss: 1.9951599256127281 RMSE: 1.4125013\n",
      "100 0 0.616901159286499\n",
      "Validation loss: 2.0365750462608 RMSE: 1.4270862\n",
      "101 21 0.532431960105896\n",
      "Validation loss: 2.437630064719546 RMSE: 1.5612911\n",
      "Validation loss: 2.046592341060132 RMSE: 1.4305917\n",
      "103 13 0.7124485373497009\n",
      "Validation loss: 5.861948439505248 RMSE: 2.4211462\n",
      "Validation loss: 2.272080588129769 RMSE: 1.5073422\n",
      "105 5 0.5538183450698853\n",
      "Validation loss: 2.132124046836279 RMSE: 1.4601794\n",
      "106 26 0.48197606205940247\n",
      "Validation loss: 2.459358856741306 RMSE: 1.5682343\n",
      "Validation loss: 2.541933777058019 RMSE: 1.5943443\n",
      "108 18 0.5710656642913818\n",
      "Validation loss: 2.4746831982536652 RMSE: 1.5731126\n",
      "Validation loss: 2.6095273811205297 RMSE: 1.6154032\n",
      "110 10 0.5314596891403198\n",
      "Validation loss: 2.202681178540255 RMSE: 1.4841433\n",
      "Validation loss: 2.2237024328349966 RMSE: 1.4912083\n",
      "112 2 0.3060104548931122\n",
      "Validation loss: 4.221832980096868 RMSE: 2.05471\n",
      "113 23 0.888920783996582\n",
      "Validation loss: 2.2670562520491337 RMSE: 1.5056747\n",
      "Validation loss: 3.2511904176357573 RMSE: 1.8031058\n",
      "115 15 0.41060638427734375\n",
      "Validation loss: 4.141463383109168 RMSE: 2.0350587\n",
      "Validation loss: 2.9652550347083437 RMSE: 1.7219915\n",
      "117 7 0.26497215032577515\n",
      "Validation loss: 4.537291265166966 RMSE: 2.130092\n",
      "118 28 3.0396199226379395\n",
      "Validation loss: 5.505252618705277 RMSE: 2.3463273\n",
      "Validation loss: 1.9332514421074791 RMSE: 1.3904141\n",
      "120 20 0.43463239073753357\n",
      "Validation loss: 1.8686883154168594 RMSE: 1.3669997\n",
      "Validation loss: 2.090792687593308 RMSE: 1.4459574\n",
      "122 12 0.7317006587982178\n",
      "Validation loss: 2.096082063902796 RMSE: 1.4477851\n",
      "Validation loss: 2.2256546410839113 RMSE: 1.4918628\n",
      "124 4 0.5814926624298096\n",
      "Validation loss: 2.1146083247345104 RMSE: 1.4541693\n",
      "125 25 0.5642628073692322\n",
      "Validation loss: 2.2716634442320967 RMSE: 1.5072038\n",
      "Validation loss: 1.9160298742024244 RMSE: 1.3842072\n",
      "127 17 0.7185044884681702\n",
      "Validation loss: 2.2505894846620813 RMSE: 1.5001965\n",
      "Validation loss: 3.042624754188335 RMSE: 1.744312\n",
      "129 9 0.5476744174957275\n",
      "Validation loss: 2.397202681651158 RMSE: 1.5482903\n",
      "Validation loss: 3.5073522128890047 RMSE: 1.8727926\n",
      "131 1 0.19180893898010254\n",
      "Validation loss: 2.472588007429005 RMSE: 1.5724465\n",
      "132 22 0.5112277269363403\n",
      "Validation loss: 2.8859101755429157 RMSE: 1.6987967\n",
      "Validation loss: 2.808398628656843 RMSE: 1.6758277\n",
      "134 14 0.5162588953971863\n",
      "Validation loss: 2.3216411328948703 RMSE: 1.5236933\n",
      "Validation loss: 2.9847485955837554 RMSE: 1.7276425\n",
      "136 6 0.5194097757339478\n",
      "Validation loss: 2.0257097092349974 RMSE: 1.4232743\n",
      "137 27 0.581907331943512\n",
      "Validation loss: 2.922567312696339 RMSE: 1.7095518\n",
      "Validation loss: 2.0900633124123633 RMSE: 1.4457052\n",
      "139 19 0.41672149300575256\n",
      "Validation loss: 3.2312161690365953 RMSE: 1.7975584\n",
      "Validation loss: 2.920039145292434 RMSE: 1.7088121\n",
      "141 11 0.5841957926750183\n",
      "Validation loss: 2.5137961269479936 RMSE: 1.5854956\n",
      "Validation loss: 3.2142216431356108 RMSE: 1.792825\n",
      "143 3 0.5897531509399414\n",
      "Validation loss: 2.3635130645954505 RMSE: 1.5373721\n",
      "144 24 0.3731158375740051\n",
      "Validation loss: 2.0930007949339604 RMSE: 1.4467206\n",
      "Validation loss: 1.9991338717199005 RMSE: 1.4139072\n",
      "146 16 1.4924039840698242\n",
      "Validation loss: 3.9517043417533944 RMSE: 1.9878894\n",
      "Validation loss: 2.4176629655129087 RMSE: 1.5548836\n",
      "148 8 0.48195043206214905\n",
      "Validation loss: 2.430517248347797 RMSE: 1.5590116\n",
      "Validation loss: 2.4296592062553475 RMSE: 1.5587364\n",
      "150 0 0.43447452783584595\n",
      "Validation loss: 1.6760554313659668 RMSE: 1.2946256\n",
      "151 21 0.402138888835907\n",
      "Validation loss: 2.712464978209639 RMSE: 1.6469562\n",
      "Validation loss: 2.128910393841499 RMSE: 1.4590786\n",
      "153 13 0.8199656009674072\n",
      "Validation loss: 2.523923133326843 RMSE: 1.588686\n",
      "Validation loss: 1.9172924809751257 RMSE: 1.3846633\n",
      "155 5 0.5169245004653931\n",
      "Validation loss: 2.662353363712277 RMSE: 1.6316719\n",
      "156 26 0.5010498762130737\n",
      "Validation loss: 3.086191299742302 RMSE: 1.756756\n",
      "Validation loss: 2.2646335205145642 RMSE: 1.5048699\n",
      "158 18 0.30911529064178467\n",
      "Validation loss: 2.418785662777656 RMSE: 1.5552446\n",
      "Validation loss: 2.4644743583898627 RMSE: 1.5698644\n",
      "160 10 0.5663145184516907\n",
      "Validation loss: 2.2730142511097733 RMSE: 1.507652\n",
      "Validation loss: 2.825570567519264 RMSE: 1.6809435\n",
      "162 2 0.5105874538421631\n",
      "Validation loss: 2.3636826023591304 RMSE: 1.5374272\n",
      "163 23 0.2779536843299866\n",
      "Validation loss: 3.5191142031576783 RMSE: 1.8759302\n",
      "Validation loss: 2.038317143389609 RMSE: 1.4276965\n",
      "165 15 0.3408259153366089\n",
      "Validation loss: 1.9557071428383346 RMSE: 1.398466\n",
      "Validation loss: 2.4566288036582744 RMSE: 1.5673637\n",
      "167 7 0.3799533247947693\n",
      "Validation loss: 1.9790825168643378 RMSE: 1.4067986\n",
      "168 28 0.8289095163345337\n",
      "Validation loss: 2.0355877897380728 RMSE: 1.4267403\n",
      "Validation loss: 2.1957126507716898 RMSE: 1.4817936\n",
      "170 20 0.33626511693000793\n",
      "Validation loss: 2.4101922311614046 RMSE: 1.5524794\n",
      "Validation loss: 3.81105126743823 RMSE: 1.9521914\n",
      "172 12 0.32064929604530334\n",
      "Validation loss: 2.4165462466467797 RMSE: 1.5545244\n",
      "Validation loss: 2.3975789757956445 RMSE: 1.5484117\n",
      "174 4 0.45240914821624756\n",
      "Validation loss: 2.251822448409764 RMSE: 1.5006074\n",
      "175 25 0.5921172499656677\n",
      "Validation loss: 2.3301967730564352 RMSE: 1.5264982\n",
      "Validation loss: 3.104358137181375 RMSE: 1.7619189\n",
      "177 17 0.3160434067249298\n",
      "Validation loss: 2.4613794035616174 RMSE: 1.5688784\n",
      "Validation loss: 2.263790833211578 RMSE: 1.5045898\n",
      "179 9 0.7512773275375366\n",
      "Validation loss: 2.656554211557439 RMSE: 1.629894\n",
      "Validation loss: 2.2851457205493895 RMSE: 1.5116698\n",
      "181 1 0.40682804584503174\n",
      "Validation loss: 2.107655723538019 RMSE: 1.4517767\n",
      "182 22 0.602154016494751\n",
      "Validation loss: 2.4144266432365487 RMSE: 1.5538425\n",
      "Validation loss: 2.178404205668289 RMSE: 1.4759418\n",
      "184 14 0.5846098065376282\n",
      "Validation loss: 2.372051258002762 RMSE: 1.5401465\n",
      "Validation loss: 2.0400403727472356 RMSE: 1.4282998\n",
      "186 6 0.5641297101974487\n",
      "Validation loss: 1.7585902984163402 RMSE: 1.3261185\n",
      "187 27 0.5763270854949951\n",
      "Validation loss: 2.0112977787456683 RMSE: 1.4182024\n",
      "Validation loss: 2.946400264723111 RMSE: 1.7165082\n",
      "189 19 0.40313073992729187\n",
      "Validation loss: 1.9244355796712689 RMSE: 1.3872402\n",
      "Validation loss: 1.5667330037176082 RMSE: 1.251692\n",
      "191 11 0.3989737629890442\n",
      "Validation loss: 2.6750164939238963 RMSE: 1.6355478\n",
      "Validation loss: 1.47351594836311 RMSE: 1.2138847\n",
      "193 3 0.2683119773864746\n",
      "Validation loss: 1.7455359032723756 RMSE: 1.3211874\n",
      "194 24 0.18896128237247467\n",
      "Validation loss: 1.9819134484350154 RMSE: 1.4078045\n",
      "Validation loss: 1.7889998127928877 RMSE: 1.337535\n",
      "196 16 0.3898181915283203\n",
      "Validation loss: 1.6896984956960763 RMSE: 1.299884\n",
      "Validation loss: 2.2388521907603844 RMSE: 1.4962795\n",
      "198 8 0.5028912425041199\n",
      "Validation loss: 1.9531266699850032 RMSE: 1.3975431\n",
      "Validation loss: 1.8479093133875755 RMSE: 1.3593783\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.691272290407029 Test RMSE: 1.3004893\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 780, 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'target': ['measured log solubility in mols per litre']}}\n",
      "Running on: cuda:0\n",
      "1127\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1127\n",
      "Generating scaffold 1000/1127\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 12.4379243850708\n",
      "Validation loss: 3.6786133715536744 RMSE: 1.9179711\n",
      "1 21 3.469560146331787\n",
      "Validation loss: 13.13957651526527 RMSE: 3.6248553\n",
      "Validation loss: 4.592813732349767 RMSE: 2.143085\n",
      "3 13 2.0649595260620117\n",
      "Validation loss: 12.953557934381266 RMSE: 3.5991051\n",
      "Validation loss: 6.911371349233441 RMSE: 2.6289485\n",
      "5 5 0.8461370468139648\n",
      "Validation loss: 7.755242381475668 RMSE: 2.7848234\n",
      "6 26 1.6046772003173828\n",
      "Validation loss: 10.404999707652404 RMSE: 3.2256784\n",
      "Validation loss: 4.368737284061128 RMSE: 2.0901525\n",
      "8 18 1.5879179239273071\n",
      "Validation loss: 9.63618619463085 RMSE: 3.1042209\n",
      "Validation loss: 5.926446509572257 RMSE: 2.4344294\n",
      "10 10 1.7827491760253906\n",
      "Validation loss: 8.942400746640907 RMSE: 2.9903848\n",
      "Validation loss: 4.562934175001836 RMSE: 2.1361027\n",
      "12 2 1.115892767906189\n",
      "Validation loss: 7.691988151685327 RMSE: 2.7734432\n",
      "13 23 0.9476475715637207\n",
      "Validation loss: 5.961859707283763 RMSE: 2.441692\n",
      "Validation loss: 7.233770252329059 RMSE: 2.6895669\n",
      "15 15 1.104303240776062\n",
      "Validation loss: 4.148960033349232 RMSE: 2.0368996\n",
      "Validation loss: 9.500495066684959 RMSE: 3.0822873\n",
      "17 7 1.9802587032318115\n",
      "Validation loss: 7.694848938325865 RMSE: 2.7739592\n",
      "18 28 1.045080304145813\n",
      "Validation loss: 3.337558041631648 RMSE: 1.8268985\n",
      "Validation loss: 5.018869108858362 RMSE: 2.2402833\n",
      "20 20 0.9296135306358337\n",
      "Validation loss: 4.770277213206334 RMSE: 2.1840963\n",
      "Validation loss: 4.632441476383041 RMSE: 2.1523108\n",
      "22 12 0.5712741017341614\n",
      "Validation loss: 7.747131592404526 RMSE: 2.7833672\n",
      "Validation loss: 6.201541605248916 RMSE: 2.4902894\n",
      "24 4 1.111803650856018\n",
      "Validation loss: 7.235292054910575 RMSE: 2.6898499\n",
      "25 25 0.7387971878051758\n",
      "Validation loss: 3.679571071557239 RMSE: 1.9182208\n",
      "Validation loss: 7.685065311668193 RMSE: 2.772195\n",
      "27 17 0.7141066193580627\n",
      "Validation loss: 7.178268154110529 RMSE: 2.679229\n",
      "Validation loss: 5.100358397559782 RMSE: 2.258397\n",
      "29 9 0.704390823841095\n",
      "Validation loss: 3.9485813305441257 RMSE: 1.9871037\n",
      "Validation loss: 9.735174466023404 RMSE: 3.1201239\n",
      "31 1 0.6447580456733704\n",
      "Validation loss: 4.435626253617548 RMSE: 2.1060927\n",
      "32 22 0.9744394421577454\n",
      "Validation loss: 4.2156596183776855 RMSE: 2.053207\n",
      "Validation loss: 4.0352639434611906 RMSE: 2.0087967\n",
      "34 14 0.4133223295211792\n",
      "Validation loss: 6.072472487930703 RMSE: 2.464239\n",
      "Validation loss: 3.661735100028789 RMSE: 1.9135661\n",
      "36 6 0.6837719678878784\n",
      "Validation loss: 5.976231233208581 RMSE: 2.4446332\n",
      "37 27 0.6527023315429688\n",
      "Validation loss: 4.905438613047642 RMSE: 2.2148225\n",
      "Validation loss: 7.345863177713039 RMSE: 2.7103252\n",
      "39 19 0.5076996088027954\n",
      "Validation loss: 3.3057635779929373 RMSE: 1.8181759\n",
      "Validation loss: 2.8652386813037163 RMSE: 1.6927016\n",
      "41 11 0.6542806625366211\n",
      "Validation loss: 3.905157220047132 RMSE: 1.9761472\n",
      "Validation loss: 4.791098176905539 RMSE: 2.1888578\n",
      "43 3 0.6538625359535217\n",
      "Validation loss: 3.7212957386421945 RMSE: 1.929066\n",
      "44 24 1.1112782955169678\n",
      "Validation loss: 4.76202118291264 RMSE: 2.1822054\n",
      "Validation loss: 3.826614274387866 RMSE: 1.9561733\n",
      "46 16 0.8231261372566223\n",
      "Validation loss: 3.905192027049782 RMSE: 1.9761559\n",
      "Validation loss: 5.90909674315326 RMSE: 2.4308634\n",
      "48 8 1.1257792711257935\n",
      "Validation loss: 3.629680173586955 RMSE: 1.905172\n",
      "Validation loss: 3.186408542953761 RMSE: 1.7850513\n",
      "50 0 0.8104901313781738\n",
      "Validation loss: 3.6554618514744583 RMSE: 1.9119262\n",
      "51 21 0.35380223393440247\n",
      "Validation loss: 7.5630828469200475 RMSE: 2.7501059\n",
      "Validation loss: 7.191767593400669 RMSE: 2.6817472\n",
      "53 13 0.4408929646015167\n",
      "Validation loss: 5.202568159694165 RMSE: 2.2809138\n",
      "Validation loss: 4.7198247993941855 RMSE: 2.1725159\n",
      "55 5 0.36544206738471985\n",
      "Validation loss: 3.0429163717590604 RMSE: 1.7443957\n",
      "56 26 1.120705246925354\n",
      "Validation loss: 2.870072909161053 RMSE: 1.6941289\n",
      "Validation loss: 2.1944665296942785 RMSE: 1.4813732\n",
      "58 18 0.6685054302215576\n",
      "Validation loss: 2.9727959696170503 RMSE: 1.7241797\n",
      "Validation loss: 3.0410463767769063 RMSE: 1.7438595\n",
      "60 10 0.47811317443847656\n",
      "Validation loss: 4.272717880991708 RMSE: 2.0670555\n",
      "Validation loss: 3.3138398892056626 RMSE: 1.8203954\n",
      "62 2 0.7235994935035706\n",
      "Validation loss: 6.721733354889186 RMSE: 2.5926306\n",
      "63 23 0.9816283583641052\n",
      "Validation loss: 6.87467652295543 RMSE: 2.6219604\n",
      "Validation loss: 4.4717534369072025 RMSE: 2.114652\n",
      "65 15 0.7698630094528198\n",
      "Validation loss: 5.680809886054655 RMSE: 2.383445\n",
      "Validation loss: 3.2079375191072446 RMSE: 1.7910717\n",
      "67 7 0.8683886528015137\n",
      "Validation loss: 3.2401430796732944 RMSE: 1.8000398\n",
      "68 28 0.1913267970085144\n",
      "Validation loss: 3.735910951563742 RMSE: 1.9328505\n",
      "Validation loss: 4.819016435505015 RMSE: 2.195226\n",
      "70 20 0.7654811143875122\n",
      "Validation loss: 5.940221166188738 RMSE: 2.4372568\n",
      "Validation loss: 5.081874716598375 RMSE: 2.2543013\n",
      "72 12 0.7462230324745178\n",
      "Validation loss: 5.479638306440505 RMSE: 2.340863\n",
      "Validation loss: 3.6165217129530105 RMSE: 1.9017155\n",
      "74 4 0.29203611612319946\n",
      "Validation loss: 5.565052357395138 RMSE: 2.3590362\n",
      "75 25 0.5295907258987427\n",
      "Validation loss: 3.0626086914433843 RMSE: 1.7500312\n",
      "Validation loss: 4.158639582912479 RMSE: 2.0392745\n",
      "77 17 1.0791749954223633\n",
      "Validation loss: 3.561417634508251 RMSE: 1.8871719\n",
      "Validation loss: 3.8475445793793264 RMSE: 1.9615159\n",
      "79 9 0.4938450753688812\n",
      "Validation loss: 5.207853443854678 RMSE: 2.282072\n",
      "Validation loss: 3.4796535314711847 RMSE: 1.8653829\n",
      "81 1 0.527495801448822\n",
      "Validation loss: 3.5634062501181543 RMSE: 1.8876985\n",
      "82 22 0.6277739405632019\n",
      "Validation loss: 2.8394609573668084 RMSE: 1.68507\n",
      "Validation loss: 4.534720551651136 RMSE: 2.1294882\n",
      "84 14 0.7089791893959045\n",
      "Validation loss: 7.413894159603963 RMSE: 2.7228467\n",
      "Validation loss: 3.767754744639439 RMSE: 1.9410706\n",
      "86 6 1.1916241645812988\n",
      "Validation loss: 4.997368854759014 RMSE: 2.2354796\n",
      "87 27 0.6388543844223022\n",
      "Validation loss: 7.174464708935898 RMSE: 2.6785192\n",
      "Validation loss: 7.685804369175329 RMSE: 2.7723284\n",
      "89 19 0.2663622200489044\n",
      "Validation loss: 6.336747135736246 RMSE: 2.5172896\n",
      "Validation loss: 3.084434834201779 RMSE: 1.7562559\n",
      "91 11 0.5423505902290344\n",
      "Validation loss: 3.6789404945035953 RMSE: 1.9180564\n",
      "Validation loss: 3.005220651626587 RMSE: 1.7335572\n",
      "93 3 1.2545500993728638\n",
      "Validation loss: 6.6588121768647595 RMSE: 2.5804675\n",
      "94 24 0.928519070148468\n",
      "Validation loss: 2.282700203161324 RMSE: 1.5108608\n",
      "Validation loss: 4.201781173722934 RMSE: 2.0498247\n",
      "96 16 0.30539771914482117\n",
      "Validation loss: 5.255271042342734 RMSE: 2.292438\n",
      "Validation loss: 2.8738833929585144 RMSE: 1.6952531\n",
      "98 8 0.5422848463058472\n",
      "Validation loss: 4.231917123878952 RMSE: 2.0571623\n",
      "Validation loss: 4.15367143766015 RMSE: 2.038056\n",
      "100 0 0.7692866921424866\n",
      "Validation loss: 3.650108991471012 RMSE: 1.9105257\n",
      "101 21 0.4225579500198364\n",
      "Validation loss: 2.4242723969231665 RMSE: 1.5570076\n",
      "Validation loss: 3.0069697894881258 RMSE: 1.7340617\n",
      "103 13 0.7371510863304138\n",
      "Validation loss: 3.4067091984031475 RMSE: 1.8457273\n",
      "Validation loss: 6.479476532049938 RMSE: 2.5454817\n",
      "105 5 0.6284348964691162\n",
      "Validation loss: 2.6119254795850906 RMSE: 1.6161453\n",
      "106 26 0.7346722483634949\n",
      "Validation loss: 2.7190817773869607 RMSE: 1.6489639\n",
      "Validation loss: 3.8383103113258836 RMSE: 1.9591606\n",
      "108 18 0.6773752570152283\n",
      "Validation loss: 3.0091487369706145 RMSE: 1.7346897\n",
      "Validation loss: 3.6577688571626106 RMSE: 1.9125296\n",
      "110 10 0.5430410504341125\n",
      "Validation loss: 2.4695361694403455 RMSE: 1.5714759\n",
      "Validation loss: 6.43885577041491 RMSE: 2.53749\n",
      "112 2 0.2919364869594574\n",
      "Validation loss: 2.7067413055791265 RMSE: 1.6452175\n",
      "113 23 0.7472069263458252\n",
      "Validation loss: 2.9896819570423228 RMSE: 1.7290696\n",
      "Validation loss: 3.0254866865883887 RMSE: 1.7393926\n",
      "115 15 0.35240116715431213\n",
      "Validation loss: 2.14055787145564 RMSE: 1.4630646\n",
      "Validation loss: 4.320447752961015 RMSE: 2.0785687\n",
      "117 7 1.2963649034500122\n",
      "Validation loss: 3.785444040214066 RMSE: 1.9456217\n",
      "118 28 0.9281765818595886\n",
      "Validation loss: 3.7576825956327724 RMSE: 1.9384743\n",
      "Validation loss: 2.7818984183589968 RMSE: 1.6679025\n",
      "120 20 0.42903876304626465\n",
      "Validation loss: 4.424137322248611 RMSE: 2.1033633\n",
      "Validation loss: 3.7049099491760793 RMSE: 1.9248141\n",
      "122 12 0.5413457155227661\n",
      "Validation loss: 5.171283536252722 RMSE: 2.2740457\n",
      "Validation loss: 3.5317445814082054 RMSE: 1.8792936\n",
      "124 4 0.6279745101928711\n",
      "Validation loss: 3.068432934516299 RMSE: 1.7516943\n",
      "125 25 0.40488582849502563\n",
      "Validation loss: 2.643135267021382 RMSE: 1.6257722\n",
      "Validation loss: 2.0968211720475054 RMSE: 1.4480405\n",
      "127 17 0.9985449910163879\n",
      "Validation loss: 3.8908541898811815 RMSE: 1.9725248\n",
      "Validation loss: 2.8799833449642214 RMSE: 1.6970513\n",
      "129 9 0.3662419319152832\n",
      "Validation loss: 4.624167792564999 RMSE: 2.150388\n",
      "Validation loss: 3.0133115549003127 RMSE: 1.7358893\n",
      "131 1 0.24028408527374268\n",
      "Validation loss: 2.731432062334719 RMSE: 1.6527046\n",
      "132 22 1.0993987321853638\n",
      "Validation loss: 3.542336696017105 RMSE: 1.8821095\n",
      "Validation loss: 6.749620327907326 RMSE: 2.5980031\n",
      "134 14 0.5949319005012512\n",
      "Validation loss: 2.4024901833154457 RMSE: 1.5499969\n",
      "Validation loss: 4.981339070649273 RMSE: 2.2318914\n",
      "136 6 0.6043698191642761\n",
      "Validation loss: 3.099402689300807 RMSE: 1.760512\n",
      "137 27 0.3713671565055847\n",
      "Validation loss: 2.3889766435707567 RMSE: 1.5456314\n",
      "Validation loss: 2.500781538212194 RMSE: 1.581386\n",
      "139 19 0.5071579217910767\n",
      "Validation loss: 2.289515853983111 RMSE: 1.5131146\n",
      "Validation loss: 4.464028771999663 RMSE: 2.1128247\n",
      "141 11 0.5197626352310181\n",
      "Validation loss: 2.6575719877681903 RMSE: 1.6302061\n",
      "Validation loss: 3.1143566865836623 RMSE: 1.7647539\n",
      "143 3 0.537570059299469\n",
      "Validation loss: 2.437874353037471 RMSE: 1.5613694\n",
      "144 24 0.35074687004089355\n",
      "Validation loss: 3.169079310071152 RMSE: 1.7801908\n",
      "Validation loss: 2.771358471001144 RMSE: 1.6647397\n",
      "146 16 0.339654803276062\n",
      "Validation loss: 2.613143572765114 RMSE: 1.6165221\n",
      "Validation loss: 2.653144450314277 RMSE: 1.6288476\n",
      "148 8 0.31282874941825867\n",
      "Validation loss: 2.4435667717351324 RMSE: 1.5631912\n",
      "Validation loss: 2.7262672185897827 RMSE: 1.6511412\n",
      "150 0 0.5851787328720093\n",
      "Validation loss: 3.54564133998567 RMSE: 1.8829874\n",
      "151 21 1.1884675025939941\n",
      "Validation loss: 2.0694591524326698 RMSE: 1.4385616\n",
      "Validation loss: 2.962695782163502 RMSE: 1.7212483\n",
      "153 13 0.17959177494049072\n",
      "Validation loss: 2.257926397618994 RMSE: 1.5026398\n",
      "Validation loss: 4.170273905306791 RMSE: 2.042125\n",
      "155 5 0.6764358282089233\n",
      "Validation loss: 2.214595706061979 RMSE: 1.4881519\n",
      "156 26 0.6399380564689636\n",
      "Validation loss: 2.984378267705968 RMSE: 1.7275354\n",
      "Validation loss: 2.592740588483557 RMSE: 1.610199\n",
      "158 18 0.520591676235199\n",
      "Validation loss: 2.1814901005905285 RMSE: 1.4769869\n",
      "Validation loss: 2.7812888843823322 RMSE: 1.6677196\n",
      "160 10 0.6988677382469177\n",
      "Validation loss: 2.0759114259112197 RMSE: 1.4408023\n",
      "Validation loss: 2.416223109295938 RMSE: 1.5544205\n",
      "162 2 0.27423685789108276\n",
      "Validation loss: 6.298729174959976 RMSE: 2.509727\n",
      "163 23 0.5395481586456299\n",
      "Validation loss: 3.4023417118376336 RMSE: 1.8445437\n",
      "Validation loss: 2.789508121203532 RMSE: 1.670182\n",
      "165 15 0.3942173719406128\n",
      "Validation loss: 3.011711812652318 RMSE: 1.7354285\n",
      "Validation loss: 2.1142851916034666 RMSE: 1.4540582\n",
      "167 7 0.17376501858234406\n",
      "Validation loss: 2.4382213828837975 RMSE: 1.5614805\n",
      "168 28 0.17701227962970734\n",
      "Validation loss: 2.322949365176986 RMSE: 1.5241226\n",
      "Validation loss: 2.9426696195011646 RMSE: 1.7154211\n",
      "170 20 0.3177379369735718\n",
      "Validation loss: 2.8703724430725637 RMSE: 1.6942174\n",
      "Validation loss: 2.7358527225730693 RMSE: 1.6540413\n",
      "172 12 0.805045485496521\n",
      "Validation loss: 2.5563566209995643 RMSE: 1.5988609\n",
      "Validation loss: 2.7287533473124546 RMSE: 1.6518939\n",
      "174 4 0.320291668176651\n",
      "Validation loss: 2.450534501961902 RMSE: 1.5654184\n",
      "175 25 0.37761807441711426\n",
      "Validation loss: 2.385988769278062 RMSE: 1.5446646\n",
      "Validation loss: 2.9751857318709383 RMSE: 1.7248726\n",
      "177 17 0.34320542216300964\n",
      "Validation loss: 2.003357439969493 RMSE: 1.4154001\n",
      "Validation loss: 2.6636349595753495 RMSE: 1.6320647\n",
      "179 9 0.44735005497932434\n",
      "Validation loss: 2.9079786465231297 RMSE: 1.7052797\n",
      "Validation loss: 2.2683761267535454 RMSE: 1.5061129\n",
      "181 1 0.6131153106689453\n",
      "Validation loss: 2.8986277664657187 RMSE: 1.7025356\n",
      "182 22 0.3498603403568268\n",
      "Validation loss: 2.340233085429774 RMSE: 1.5297819\n",
      "Validation loss: 2.0832894017211103 RMSE: 1.4433604\n",
      "184 14 0.2354435920715332\n",
      "Validation loss: 2.8516684717836633 RMSE: 1.6886884\n",
      "Validation loss: 2.161937346500633 RMSE: 1.4703528\n",
      "186 6 0.8209235072135925\n",
      "Validation loss: 2.1129774519827516 RMSE: 1.4536084\n",
      "187 27 0.5279264450073242\n",
      "Validation loss: 2.642423517936099 RMSE: 1.6255533\n",
      "Validation loss: 1.9280103244612703 RMSE: 1.3885281\n",
      "189 19 0.5579757690429688\n",
      "Validation loss: 1.8589047889793868 RMSE: 1.3634166\n",
      "Validation loss: 2.5566024316095675 RMSE: 1.5989379\n",
      "191 11 0.4169939458370209\n",
      "Validation loss: 3.3518066279656065 RMSE: 1.830794\n",
      "Validation loss: 3.3466582424872744 RMSE: 1.8293874\n",
      "193 3 0.37089329957962036\n",
      "Validation loss: 2.280075101725823 RMSE: 1.5099919\n",
      "194 24 1.195954442024231\n",
      "Validation loss: 2.4861587380940935 RMSE: 1.5767558\n",
      "Validation loss: 2.2682128817634246 RMSE: 1.5060587\n",
      "196 16 0.2923804819583893\n",
      "Validation loss: 2.2354736665708828 RMSE: 1.4951501\n",
      "Validation loss: 2.474357379221283 RMSE: 1.5730089\n",
      "198 8 0.2688402831554413\n",
      "Validation loss: 4.426171682577218 RMSE: 2.1038468\n",
      "Validation loss: 2.127554112831048 RMSE: 1.4586138\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.926458614062419 Test RMSE: 1.3879693\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'target': ['measured log solubility in mols per litre']}}\n",
      "Running on: cuda:0\n",
      "1127\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1127\n",
      "Generating scaffold 1000/1127\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 11.863816261291504\n",
      "Validation loss: 2.978037458605471 RMSE: 1.7256992\n",
      "1 21 1.8796970844268799\n",
      "Validation loss: 6.678636500265746 RMSE: 2.5843058\n",
      "Validation loss: 3.2445008986819106 RMSE: 1.8012499\n",
      "3 13 2.381974697113037\n",
      "Validation loss: 5.647501761934398 RMSE: 2.3764474\n",
      "Validation loss: 5.594234128968906 RMSE: 2.3652134\n",
      "5 5 1.6288081407546997\n",
      "Validation loss: 4.624315759776968 RMSE: 2.1504223\n",
      "6 26 1.4234141111373901\n",
      "Validation loss: 2.963453702167072 RMSE: 1.7214684\n",
      "Validation loss: 4.81787071818799 RMSE: 2.194965\n",
      "8 18 1.0940754413604736\n",
      "Validation loss: 8.598227821620165 RMSE: 2.9322736\n",
      "Validation loss: 2.1647746594606248 RMSE: 1.4713174\n",
      "10 10 1.5400128364562988\n",
      "Validation loss: 3.407304989553131 RMSE: 1.8458887\n",
      "Validation loss: 3.827363353914919 RMSE: 1.9563648\n",
      "12 2 1.0869473218917847\n",
      "Validation loss: 2.8498099715308807 RMSE: 1.6881379\n",
      "13 23 1.4753249883651733\n",
      "Validation loss: 3.6175751095324493 RMSE: 1.9019923\n",
      "Validation loss: 7.352634543866182 RMSE: 2.711574\n",
      "15 15 1.055484414100647\n",
      "Validation loss: 2.2819717732151 RMSE: 1.5106196\n",
      "Validation loss: 1.6696322259649765 RMSE: 1.2921425\n",
      "17 7 1.5514112710952759\n",
      "Validation loss: 2.688106914537143 RMSE: 1.6395447\n",
      "18 28 2.658341646194458\n",
      "Validation loss: 2.734617001187485 RMSE: 1.6536677\n",
      "Validation loss: 2.4022105167397356 RMSE: 1.5499065\n",
      "20 20 0.7671740651130676\n",
      "Validation loss: 3.271778321899144 RMSE: 1.8088057\n",
      "Validation loss: 1.7959021045043406 RMSE: 1.3401127\n",
      "22 12 1.387556552886963\n",
      "Validation loss: 2.0526575092720774 RMSE: 1.4327098\n",
      "Validation loss: 2.6709390847028884 RMSE: 1.6343008\n",
      "24 4 0.6331072449684143\n",
      "Validation loss: 2.5363080796942246 RMSE: 1.592579\n",
      "25 25 1.0900046825408936\n",
      "Validation loss: 2.4212470212868884 RMSE: 1.5560356\n",
      "Validation loss: 2.4995173880484254 RMSE: 1.5809863\n",
      "27 17 1.299015998840332\n",
      "Validation loss: 1.7391482697123974 RMSE: 1.3187677\n",
      "Validation loss: 2.2129925668767068 RMSE: 1.4876131\n",
      "29 9 0.9389283657073975\n",
      "Validation loss: 2.23775360647556 RMSE: 1.4959123\n",
      "Validation loss: 2.2293339282010507 RMSE: 1.4930954\n",
      "31 1 0.8633456826210022\n",
      "Validation loss: 2.9121752165060126 RMSE: 1.7065096\n",
      "32 22 0.7899267077445984\n",
      "Validation loss: 2.324948215906599 RMSE: 1.5247781\n",
      "Validation loss: 2.6152568454236054 RMSE: 1.6171756\n",
      "34 14 0.6208603382110596\n",
      "Validation loss: 2.1928101345501116 RMSE: 1.4808139\n",
      "Validation loss: 2.01026812485889 RMSE: 1.4178392\n",
      "36 6 1.031114935874939\n",
      "Validation loss: 2.0315612470154214 RMSE: 1.4253285\n",
      "37 27 0.4629708528518677\n",
      "Validation loss: 1.9261595084603909 RMSE: 1.3878616\n",
      "Validation loss: 1.9500825806001647 RMSE: 1.3964537\n",
      "39 19 0.7608790397644043\n",
      "Validation loss: 2.215548015273778 RMSE: 1.4884717\n",
      "Validation loss: 2.2719640299282244 RMSE: 1.5073036\n",
      "41 11 1.0292179584503174\n",
      "Validation loss: 1.56678654134801 RMSE: 1.2517135\n",
      "Validation loss: 3.7309235893519577 RMSE: 1.9315599\n",
      "43 3 1.3530019521713257\n",
      "Validation loss: 2.6550827722633836 RMSE: 1.6294423\n",
      "44 24 0.705292820930481\n",
      "Validation loss: 2.529470802408404 RMSE: 1.590431\n",
      "Validation loss: 1.8681236821993263 RMSE: 1.3667932\n",
      "46 16 0.715490460395813\n",
      "Validation loss: 1.9538662354503058 RMSE: 1.3978076\n",
      "Validation loss: 2.016217067178372 RMSE: 1.4199356\n",
      "48 8 0.4403602182865143\n",
      "Validation loss: 2.284726785347525 RMSE: 1.5115314\n",
      "Validation loss: 2.3894750375663283 RMSE: 1.5457927\n",
      "50 0 0.5538615584373474\n",
      "Validation loss: 3.044193980968104 RMSE: 1.744762\n",
      "51 21 0.7220370769500732\n",
      "Validation loss: 2.3377209448181424 RMSE: 1.5289608\n",
      "Validation loss: 2.322451355183019 RMSE: 1.5239592\n",
      "53 13 0.6246020793914795\n",
      "Validation loss: 1.89277864346462 RMSE: 1.375783\n",
      "Validation loss: 2.1885791120275986 RMSE: 1.4793847\n",
      "55 5 0.6206908822059631\n",
      "Validation loss: 2.432696694821383 RMSE: 1.5597104\n",
      "56 26 0.45574554800987244\n",
      "Validation loss: 2.022566198247724 RMSE: 1.4221694\n",
      "Validation loss: 2.09112012386322 RMSE: 1.4460706\n",
      "58 18 0.9318623542785645\n",
      "Validation loss: 1.8900856708003357 RMSE: 1.3748038\n",
      "Validation loss: 1.9288334477264268 RMSE: 1.3888245\n",
      "60 10 0.6797772645950317\n",
      "Validation loss: 1.8281499833132313 RMSE: 1.3520911\n",
      "Validation loss: 2.183293798328501 RMSE: 1.4775974\n",
      "62 2 0.7412304878234863\n",
      "Validation loss: 2.099799410431786 RMSE: 1.4490685\n",
      "63 23 0.7327562570571899\n",
      "Validation loss: 1.8466233563634147 RMSE: 1.3589051\n",
      "Validation loss: 1.877091115554877 RMSE: 1.3700697\n",
      "65 15 0.5199164748191833\n",
      "Validation loss: 2.4190106502676434 RMSE: 1.5553169\n",
      "Validation loss: 1.9144565605484278 RMSE: 1.3836389\n",
      "67 7 0.5244336128234863\n",
      "Validation loss: 1.786077648137523 RMSE: 1.3364421\n",
      "68 28 1.4318941831588745\n",
      "Validation loss: 2.12448527327681 RMSE: 1.4575614\n",
      "Validation loss: 1.7719808996251198 RMSE: 1.3311577\n",
      "70 20 0.44056621193885803\n",
      "Validation loss: 1.999821145977594 RMSE: 1.4141504\n",
      "Validation loss: 2.426326825555447 RMSE: 1.5576671\n",
      "72 12 0.8188871145248413\n",
      "Validation loss: 2.2543265988341474 RMSE: 1.5014415\n",
      "Validation loss: 2.4491639517049872 RMSE: 1.5649805\n",
      "74 4 0.7170110940933228\n",
      "Validation loss: 3.9060493064137685 RMSE: 1.9763727\n",
      "75 25 0.7535718083381653\n",
      "Validation loss: 2.5319815631461355 RMSE: 1.5912201\n",
      "Validation loss: 2.1350229989110896 RMSE: 1.4611717\n",
      "77 17 0.5323727130889893\n",
      "Validation loss: 2.199426904188848 RMSE: 1.4830465\n",
      "Validation loss: 1.7906457217393723 RMSE: 1.3381501\n",
      "79 9 0.6581017971038818\n",
      "Validation loss: 2.280319205427592 RMSE: 1.5100727\n",
      "Validation loss: 2.00855109438432 RMSE: 1.4172336\n",
      "81 1 0.49834582209587097\n",
      "Validation loss: 1.8885097524761099 RMSE: 1.3742306\n",
      "82 22 0.7962985038757324\n",
      "Validation loss: 1.9905167332792704 RMSE: 1.4108567\n",
      "Validation loss: 1.70640462900685 RMSE: 1.3062942\n",
      "84 14 0.7139018177986145\n",
      "Validation loss: 2.194598763389925 RMSE: 1.4814178\n",
      "Validation loss: 2.4414947771393094 RMSE: 1.5625284\n",
      "86 6 0.6941678524017334\n",
      "Validation loss: 1.6953418233753306 RMSE: 1.302053\n",
      "87 27 0.7855607867240906\n",
      "Validation loss: 1.9279405448289044 RMSE: 1.388503\n",
      "Validation loss: 1.6830054489912185 RMSE: 1.297307\n",
      "89 19 0.3011939823627472\n",
      "Validation loss: 1.993000247837168 RMSE: 1.4117366\n",
      "Validation loss: 1.7632257853989053 RMSE: 1.327865\n",
      "91 11 0.4816112518310547\n",
      "Validation loss: 1.8887418825014504 RMSE: 1.374315\n",
      "Validation loss: 2.0281496849735228 RMSE: 1.4241312\n",
      "93 3 0.32701003551483154\n",
      "Validation loss: 1.9232113393007126 RMSE: 1.386799\n",
      "94 24 0.7903996109962463\n",
      "Validation loss: 1.8766942720497604 RMSE: 1.369925\n",
      "Validation loss: 2.2245570790451183 RMSE: 1.4914949\n",
      "96 16 0.5971788167953491\n",
      "Validation loss: 2.6673410234198105 RMSE: 1.6331996\n",
      "Validation loss: 3.216381482318439 RMSE: 1.7934273\n",
      "98 8 0.6282772421836853\n",
      "Validation loss: 2.53755123425374 RMSE: 1.5929692\n",
      "Validation loss: 2.204586540703225 RMSE: 1.484785\n",
      "100 0 0.9202867150306702\n",
      "Validation loss: 2.49568446969564 RMSE: 1.5797735\n",
      "101 21 0.39261335134506226\n",
      "Validation loss: 2.8232042525721863 RMSE: 1.6802393\n",
      "Validation loss: 2.2161806347095863 RMSE: 1.4886842\n",
      "103 13 0.7840991020202637\n",
      "Validation loss: 2.7487070518257344 RMSE: 1.6579224\n",
      "Validation loss: 2.2158284820286576 RMSE: 1.4885659\n",
      "105 5 0.4795447587966919\n",
      "Validation loss: 1.8373443521229567 RMSE: 1.3554868\n",
      "106 26 0.6773092150688171\n",
      "Validation loss: 1.679195607657981 RMSE: 1.2958378\n",
      "Validation loss: 2.0935857369836453 RMSE: 1.4469229\n",
      "108 18 0.45700281858444214\n",
      "Validation loss: 1.870800124860443 RMSE: 1.367772\n",
      "Validation loss: 2.4442455494298345 RMSE: 1.5634085\n",
      "110 10 0.6369522213935852\n",
      "Validation loss: 1.9097885020011294 RMSE: 1.381951\n",
      "Validation loss: 2.2037721038919633 RMSE: 1.4845107\n",
      "112 2 0.7724306583404541\n",
      "Validation loss: 1.980784973212048 RMSE: 1.4074036\n",
      "113 23 1.1207466125488281\n",
      "Validation loss: 1.588746491786653 RMSE: 1.2604549\n",
      "Validation loss: 1.9857589860933016 RMSE: 1.4091696\n",
      "115 15 0.9061777591705322\n",
      "Validation loss: 1.9253094860937743 RMSE: 1.3875552\n",
      "Validation loss: 1.9123150500576054 RMSE: 1.3828648\n",
      "117 7 1.1683249473571777\n",
      "Validation loss: 2.03244904923228 RMSE: 1.4256399\n",
      "118 28 1.9357476234436035\n",
      "Validation loss: 1.8851971710677695 RMSE: 1.3730248\n",
      "Validation loss: 1.93894869247369 RMSE: 1.3924613\n",
      "120 20 0.7580500245094299\n",
      "Validation loss: 1.9171706385317102 RMSE: 1.3846192\n",
      "Validation loss: 1.8273799662041452 RMSE: 1.3518062\n",
      "122 12 0.8873271346092224\n",
      "Validation loss: 2.6490596627767107 RMSE: 1.6275933\n",
      "Validation loss: 1.8402265363034949 RMSE: 1.3565495\n",
      "124 4 0.2948390543460846\n",
      "Validation loss: 1.9597271670282415 RMSE: 1.3999025\n",
      "125 25 0.9489933848381042\n",
      "Validation loss: 2.041986300881985 RMSE: 1.4289808\n",
      "Validation loss: 2.414286563881731 RMSE: 1.5537974\n",
      "127 17 0.30868828296661377\n",
      "Validation loss: 1.9728270294392003 RMSE: 1.4045736\n",
      "Validation loss: 2.1800124054461456 RMSE: 1.4764864\n",
      "129 9 0.4086122214794159\n",
      "Validation loss: 1.986172046281595 RMSE: 1.4093162\n",
      "Validation loss: 1.9625000320704638 RMSE: 1.4008926\n",
      "131 1 0.9279942512512207\n",
      "Validation loss: 1.985507514624469 RMSE: 1.4090804\n",
      "132 22 0.22707706689834595\n",
      "Validation loss: 2.0565237935665435 RMSE: 1.4340585\n",
      "Validation loss: 2.080861251966088 RMSE: 1.4425191\n",
      "134 14 0.6274256110191345\n",
      "Validation loss: 1.9774711912712164 RMSE: 1.4062258\n",
      "Validation loss: 2.0955618577720845 RMSE: 1.4476056\n",
      "136 6 0.6101439595222473\n",
      "Validation loss: 2.0492515479568887 RMSE: 1.4315207\n",
      "137 27 1.1296292543411255\n",
      "Validation loss: 1.7557454657765617 RMSE: 1.3250455\n",
      "Validation loss: 2.00951211642375 RMSE: 1.4175726\n",
      "139 19 0.4670999348163605\n",
      "Validation loss: 1.965569271450549 RMSE: 1.4019877\n",
      "Validation loss: 2.1003795746153435 RMSE: 1.4492687\n",
      "141 11 0.6509021520614624\n",
      "Validation loss: 2.0514675716383266 RMSE: 1.4322945\n",
      "Validation loss: 1.8396059854895668 RMSE: 1.3563207\n",
      "143 3 0.5751395225524902\n",
      "Validation loss: 2.196765813152347 RMSE: 1.482149\n",
      "144 24 0.4620024263858795\n",
      "Validation loss: 2.457898456438453 RMSE: 1.5677686\n",
      "Validation loss: 1.8578956844532384 RMSE: 1.3630464\n",
      "146 16 0.33079081773757935\n",
      "Validation loss: 2.1000003160628595 RMSE: 1.4491377\n",
      "Validation loss: 1.9906809815263327 RMSE: 1.410915\n",
      "148 8 0.4381992518901825\n",
      "Validation loss: 1.9258853545231103 RMSE: 1.3877627\n",
      "Validation loss: 1.7367637220737153 RMSE: 1.3178632\n",
      "150 0 0.47259521484375\n",
      "Validation loss: 2.0372297900967893 RMSE: 1.4273157\n",
      "151 21 0.5708896517753601\n",
      "Validation loss: 2.2387035694797484 RMSE: 1.4962299\n",
      "Validation loss: 2.8146293986160145 RMSE: 1.6776859\n",
      "153 13 1.0536308288574219\n",
      "Validation loss: 1.9942836476638255 RMSE: 1.4121909\n",
      "Validation loss: 2.0229878910874897 RMSE: 1.4223177\n",
      "155 5 0.7402915954589844\n",
      "Validation loss: 2.1464970280638838 RMSE: 1.4650928\n",
      "156 26 0.34757718443870544\n",
      "Validation loss: 1.858671989061136 RMSE: 1.3633313\n",
      "Validation loss: 2.483202233778692 RMSE: 1.5758181\n",
      "158 18 0.4087049663066864\n",
      "Validation loss: 2.227082963538381 RMSE: 1.4923414\n",
      "Validation loss: 1.861245205972047 RMSE: 1.3642746\n",
      "160 10 0.3442337214946747\n",
      "Validation loss: 1.9935867765308481 RMSE: 1.4119443\n",
      "Validation loss: 2.062721586332912 RMSE: 1.4362178\n",
      "162 2 0.40097957849502563\n",
      "Validation loss: 2.1509955942103294 RMSE: 1.4666272\n",
      "163 23 0.3309329152107239\n",
      "Validation loss: 1.7875997587642838 RMSE: 1.3370115\n",
      "Validation loss: 2.2184258657219136 RMSE: 1.4894382\n",
      "165 15 0.7880644202232361\n",
      "Validation loss: 2.1373809808123427 RMSE: 1.4619784\n",
      "Validation loss: 2.0836502688120953 RMSE: 1.4434854\n",
      "167 7 0.5139512419700623\n",
      "Validation loss: 2.17213024291317 RMSE: 1.473815\n",
      "168 28 1.2794309854507446\n",
      "Validation loss: 2.0237648624234494 RMSE: 1.4225909\n",
      "Validation loss: 2.02302812053039 RMSE: 1.4223318\n",
      "170 20 0.5481802821159363\n",
      "Validation loss: 2.382516892610398 RMSE: 1.5435404\n",
      "Validation loss: 1.8593583645018856 RMSE: 1.363583\n",
      "172 12 0.5057606101036072\n",
      "Validation loss: 1.8115840823249478 RMSE: 1.345951\n",
      "Validation loss: 1.9299276365643054 RMSE: 1.3892183\n",
      "174 4 0.4937715530395508\n",
      "Validation loss: 2.576282992827154 RMSE: 1.6050804\n",
      "175 25 0.40722906589508057\n",
      "Validation loss: 1.924368547654785 RMSE: 1.3872161\n",
      "Validation loss: 2.1424402642039073 RMSE: 1.4637077\n",
      "177 17 0.4199430048465729\n",
      "Validation loss: 1.9288072818148452 RMSE: 1.388815\n",
      "Validation loss: 2.039942035632851 RMSE: 1.4282653\n",
      "179 9 0.6907621622085571\n",
      "Validation loss: 2.1554858726737773 RMSE: 1.4681573\n",
      "Validation loss: 2.2772257591770813 RMSE: 1.509048\n",
      "181 1 0.45856210589408875\n",
      "Validation loss: 1.9619320071904005 RMSE: 1.4006898\n",
      "182 22 0.44106408953666687\n",
      "Validation loss: 2.0458247956976425 RMSE: 1.4303234\n",
      "Validation loss: 2.2284175146997502 RMSE: 1.4927884\n",
      "184 14 0.6755478978157043\n",
      "Validation loss: 2.1301842242215585 RMSE: 1.4595151\n",
      "Validation loss: 2.2043852521254954 RMSE: 1.4847174\n",
      "186 6 0.40020257234573364\n",
      "Validation loss: 2.0936980057606656 RMSE: 1.4469616\n",
      "187 27 1.0170236825942993\n",
      "Validation loss: 2.3616439768698365 RMSE: 1.5367641\n",
      "Validation loss: 2.2060940835328227 RMSE: 1.4852926\n",
      "189 19 0.34906473755836487\n",
      "Validation loss: 2.003895236327585 RMSE: 1.4155902\n",
      "Validation loss: 2.0118701521274263 RMSE: 1.4184041\n",
      "191 11 0.5671734809875488\n",
      "Validation loss: 2.1464417160084817 RMSE: 1.465074\n",
      "Validation loss: 1.9568128438122505 RMSE: 1.3988613\n",
      "193 3 0.5348824262619019\n",
      "Validation loss: 2.0181146385395423 RMSE: 1.4206035\n",
      "194 24 0.6174088716506958\n",
      "Validation loss: 2.139519584917389 RMSE: 1.4627097\n",
      "Validation loss: 2.0460995826046022 RMSE: 1.4304194\n",
      "196 16 0.5166544318199158\n",
      "Validation loss: 2.3763888314761945 RMSE: 1.5415541\n",
      "Validation loss: 2.0679446342772088 RMSE: 1.438035\n",
      "198 8 0.24074240028858185\n",
      "Validation loss: 1.992460026150256 RMSE: 1.4115453\n",
      "Validation loss: 2.096156457884122 RMSE: 1.4478109\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.7710106425580725 Test RMSE: 1.3307933\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'target': ['exp']}}\n",
      "Running on: cuda:0\n",
      "4199\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/4199\n",
      "Generating scaffold 1000/4199\n",
      "Generating scaffold 2000/4199\n",
      "Generating scaffold 3000/4199\n",
      "Generating scaffold 4000/4199\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 8.847333908081055\n",
      "0 50 1.0298036336898804\n",
      "0 100 1.2619425058364868\n",
      "Validation loss: 1.9674819265093122 RMSE: 1.4026697\n",
      "1 45 0.672385036945343\n",
      "1 95 1.196257472038269\n",
      "Validation loss: 1.3912916308357601 RMSE: 1.1795303\n",
      "2 40 1.2293829917907715\n",
      "2 90 0.4441090226173401\n",
      "Validation loss: 2.0395976225535075 RMSE: 1.4281448\n",
      "3 35 0.8108477592468262\n",
      "3 85 0.46144670248031616\n",
      "Validation loss: 1.8018077759515672 RMSE: 1.3423144\n",
      "4 30 0.8457676768302917\n",
      "4 80 0.8001357913017273\n",
      "Validation loss: 1.9359833938734872 RMSE: 1.3913962\n",
      "5 25 0.9307956695556641\n",
      "5 75 0.9678729176521301\n",
      "Validation loss: 1.4026952269531432 RMSE: 1.1843543\n",
      "6 20 0.7907795310020447\n",
      "6 70 0.725287914276123\n",
      "Validation loss: 1.3649076836449758 RMSE: 1.1682926\n",
      "7 15 0.6245154142379761\n",
      "7 65 0.6607343554496765\n",
      "Validation loss: 1.33109022464071 RMSE: 1.1537287\n",
      "8 10 0.5405529737472534\n",
      "8 60 0.44700342416763306\n",
      "Validation loss: 1.1905877431233725 RMSE: 1.0911405\n",
      "9 5 0.6393667459487915\n",
      "9 55 0.498898446559906\n",
      "Validation loss: 1.310496455147153 RMSE: 1.1447692\n",
      "10 0 0.4501653015613556\n",
      "10 50 1.0928741693496704\n",
      "10 100 0.9296563267707825\n",
      "Validation loss: 1.811904321398054 RMSE: 1.3460699\n",
      "11 45 0.7122452855110168\n",
      "11 95 0.5712223052978516\n",
      "Validation loss: 1.6646337157204039 RMSE: 1.2902068\n",
      "12 40 0.5647798776626587\n",
      "12 90 0.4689294695854187\n",
      "Validation loss: 1.565146995726086 RMSE: 1.2510583\n",
      "13 35 0.45574963092803955\n",
      "13 85 0.5562254190444946\n",
      "Validation loss: 2.037158459708804 RMSE: 1.4272906\n",
      "14 30 0.6029786467552185\n",
      "14 80 0.6465718150138855\n",
      "Validation loss: 1.155858218102228 RMSE: 1.0751084\n",
      "15 25 0.4781404137611389\n",
      "15 75 0.46776100993156433\n",
      "Validation loss: 1.5377902553195044 RMSE: 1.2400767\n",
      "16 20 0.5048121213912964\n",
      "16 70 0.3821480870246887\n",
      "Validation loss: 1.3326898143405006 RMSE: 1.1544219\n",
      "17 15 0.45956915616989136\n",
      "17 65 0.8282154202461243\n",
      "Validation loss: 1.2198550513812474 RMSE: 1.1044705\n",
      "18 10 0.4782404601573944\n",
      "18 60 0.639388382434845\n",
      "Validation loss: 1.3008965350332715 RMSE: 1.1405685\n",
      "19 5 0.31826743483543396\n",
      "19 55 0.41736334562301636\n",
      "Validation loss: 2.6134568759373256 RMSE: 1.6166189\n",
      "20 0 0.3390505015850067\n",
      "20 50 0.4855414032936096\n",
      "20 100 0.304659366607666\n",
      "Validation loss: 1.7642290297008696 RMSE: 1.3282429\n",
      "21 45 0.49822214245796204\n",
      "21 95 0.5449198484420776\n",
      "Validation loss: 1.462107657250904 RMSE: 1.2091764\n",
      "22 40 0.9580163359642029\n",
      "22 90 0.5088405013084412\n",
      "Validation loss: 1.0041978064037504 RMSE: 1.0020967\n",
      "23 35 0.6017296314239502\n",
      "23 85 0.27262458205223083\n",
      "Validation loss: 1.1858078922544206 RMSE: 1.088948\n",
      "24 30 0.7105683088302612\n",
      "24 80 0.3283856511116028\n",
      "Validation loss: 1.340491551444644 RMSE: 1.157796\n",
      "25 25 0.5631611943244934\n",
      "25 75 0.46883684396743774\n",
      "Validation loss: 1.4957167966025215 RMSE: 1.222995\n",
      "26 20 0.5385435223579407\n",
      "26 70 0.3680306673049927\n",
      "Validation loss: 1.244492458729517 RMSE: 1.1155683\n",
      "27 15 0.378769189119339\n",
      "27 65 0.6917752027511597\n",
      "Validation loss: 1.388157606124878 RMSE: 1.1782011\n",
      "28 10 0.8152211904525757\n",
      "28 60 0.39689338207244873\n",
      "Validation loss: 1.9520118656612577 RMSE: 1.3971442\n",
      "29 5 0.43645015358924866\n",
      "29 55 0.3863412141799927\n",
      "Validation loss: 1.1248297838937669 RMSE: 1.0605799\n",
      "30 0 0.4770694971084595\n",
      "30 50 0.5041560530662537\n",
      "30 100 0.4589126408100128\n",
      "Validation loss: 1.3171385231472197 RMSE: 1.1476666\n",
      "31 45 0.7936365008354187\n",
      "31 95 0.1898173987865448\n",
      "Validation loss: 1.5669327440715972 RMSE: 1.2517718\n",
      "32 40 0.49740591645240784\n",
      "32 90 0.6733118891716003\n",
      "Validation loss: 1.5051196711403982 RMSE: 1.2268332\n",
      "33 35 0.4670276939868927\n",
      "33 85 0.5365167856216431\n",
      "Validation loss: 1.322702153523763 RMSE: 1.150088\n",
      "34 30 0.500979483127594\n",
      "34 80 0.49757519364356995\n",
      "Validation loss: 1.796450628553118 RMSE: 1.3403174\n",
      "35 25 0.30176013708114624\n",
      "35 75 0.27461981773376465\n",
      "Validation loss: 1.3198211811837697 RMSE: 1.1488347\n",
      "36 20 0.7155715823173523\n",
      "36 70 0.37717708945274353\n",
      "Validation loss: 1.7726787249247233 RMSE: 1.3314198\n",
      "37 15 0.6326864957809448\n",
      "37 65 0.24661383032798767\n",
      "Validation loss: 1.6358606383914038 RMSE: 1.2790077\n",
      "38 10 0.8160163760185242\n",
      "38 60 0.4061376750469208\n",
      "Validation loss: 1.4313619451863424 RMSE: 1.1963954\n",
      "39 5 0.3576843738555908\n",
      "39 55 0.5890384316444397\n",
      "Validation loss: 1.1238005070459276 RMSE: 1.0600946\n",
      "40 0 0.4400537312030792\n",
      "40 50 0.41403740644454956\n",
      "40 100 0.36768028140068054\n",
      "Validation loss: 1.6146231878371466 RMSE: 1.2706783\n",
      "41 45 0.5236106514930725\n",
      "41 95 0.37125125527381897\n",
      "Validation loss: 1.2084511121114094 RMSE: 1.0992957\n",
      "42 40 0.29912784695625305\n",
      "42 90 0.41734078526496887\n",
      "Validation loss: 1.5479040038018 RMSE: 1.2441479\n",
      "43 35 0.3347298800945282\n",
      "43 85 0.44827064871788025\n",
      "Validation loss: 1.245707696960086 RMSE: 1.1161128\n",
      "44 30 0.6207454204559326\n",
      "44 80 0.2570880651473999\n",
      "Validation loss: 1.2580747547603788 RMSE: 1.1216393\n",
      "45 25 0.5969805121421814\n",
      "45 75 0.6321873068809509\n",
      "Validation loss: 1.5367651110603695 RMSE: 1.2396632\n",
      "46 20 0.4946081340312958\n",
      "46 70 0.40199199318885803\n",
      "Validation loss: 1.506486988067627 RMSE: 1.2273903\n",
      "47 15 0.3799892067909241\n",
      "47 65 0.2752231955528259\n",
      "Validation loss: 1.1018743594487508 RMSE: 1.049702\n",
      "48 10 0.3861507773399353\n",
      "48 60 0.39483141899108887\n",
      "Validation loss: 1.1982781523749941 RMSE: 1.094659\n",
      "49 5 0.6234470009803772\n",
      "49 55 0.6165523529052734\n",
      "Validation loss: 1.759438028789702 RMSE: 1.3264381\n",
      "50 0 0.5521872639656067\n",
      "50 50 0.3013012707233429\n",
      "50 100 0.236665740609169\n",
      "Validation loss: 1.9274823824564615 RMSE: 1.388338\n",
      "51 45 0.33075428009033203\n",
      "51 95 0.2869184613227844\n",
      "Validation loss: 1.6157232931682042 RMSE: 1.271111\n",
      "52 40 0.33170926570892334\n",
      "52 90 0.40413233637809753\n",
      "Validation loss: 1.9990017073495048 RMSE: 1.4138606\n",
      "53 35 0.6543568968772888\n",
      "53 85 0.42456910014152527\n",
      "Validation loss: 1.5357665107363747 RMSE: 1.2392606\n",
      "54 30 0.22784925997257233\n",
      "54 80 0.28090953826904297\n",
      "Validation loss: 1.3199197723751976 RMSE: 1.1488776\n",
      "55 25 0.66105055809021\n",
      "55 75 0.5438913106918335\n",
      "Validation loss: 1.2469146813665117 RMSE: 1.1166534\n",
      "56 20 0.29429125785827637\n",
      "56 70 0.4009707272052765\n",
      "Validation loss: 1.6871043988636563 RMSE: 1.2988858\n",
      "57 15 0.22521358728408813\n",
      "57 65 0.5189428329467773\n",
      "Validation loss: 2.094783768199739 RMSE: 1.4473368\n",
      "58 10 0.5551214218139648\n",
      "58 60 0.24357981979846954\n",
      "Validation loss: 1.5847474718732493 RMSE: 1.2588675\n",
      "59 5 0.2625233829021454\n",
      "59 55 0.4890193045139313\n",
      "Validation loss: 1.9911082222348169 RMSE: 1.4110664\n",
      "60 0 0.37142395973205566\n",
      "60 50 0.42565882205963135\n",
      "60 100 0.34580737352371216\n",
      "Validation loss: 1.3588913835230327 RMSE: 1.165715\n",
      "61 45 0.3628540337085724\n",
      "61 95 0.2181650549173355\n",
      "Validation loss: 1.6036985394500551 RMSE: 1.2663722\n",
      "62 40 0.40613847970962524\n",
      "62 90 0.2558477520942688\n",
      "Validation loss: 1.499093316850208 RMSE: 1.2243747\n",
      "63 35 0.2603911757469177\n",
      "63 85 0.5368573665618896\n",
      "Validation loss: 0.845765615644909 RMSE: 0.91965514\n",
      "64 30 0.3687363862991333\n",
      "64 80 0.24211658537387848\n",
      "Validation loss: 1.7871227162224905 RMSE: 1.3368331\n",
      "65 25 0.4244847595691681\n",
      "65 75 0.4095003008842468\n",
      "Validation loss: 1.6381471849623181 RMSE: 1.2799013\n",
      "66 20 0.30693912506103516\n",
      "66 70 0.34920942783355713\n",
      "Validation loss: 1.4970632632573446 RMSE: 1.2235454\n",
      "67 15 0.2950609028339386\n",
      "67 65 0.1934894174337387\n",
      "Validation loss: 1.393049394232886 RMSE: 1.1802751\n",
      "68 10 0.36816585063934326\n",
      "68 60 0.4514414668083191\n",
      "Validation loss: 1.4335945617584955 RMSE: 1.1973281\n",
      "69 5 0.44394001364707947\n",
      "69 55 0.2766873240470886\n",
      "Validation loss: 1.827396313349406 RMSE: 1.3518122\n",
      "70 0 0.300397127866745\n",
      "70 50 0.3638525903224945\n",
      "70 100 0.27928751707077026\n",
      "Validation loss: 1.487069000516619 RMSE: 1.2194544\n",
      "71 45 0.3048977553844452\n",
      "71 95 0.5438356995582581\n",
      "Validation loss: 1.2798267023903982 RMSE: 1.1312943\n",
      "72 40 0.2852821946144104\n",
      "72 90 0.1954018920660019\n",
      "Validation loss: 1.0891298941203527 RMSE: 1.0436139\n",
      "73 35 0.3934798836708069\n",
      "73 85 0.5042441487312317\n",
      "Validation loss: 1.908866514478411 RMSE: 1.3816173\n",
      "74 30 0.2867085337638855\n",
      "74 80 0.33961161971092224\n",
      "Validation loss: 1.347092423268727 RMSE: 1.1606431\n",
      "75 25 0.2477751225233078\n",
      "75 75 0.2628495395183563\n",
      "Validation loss: 1.1909820261455717 RMSE: 1.0913212\n",
      "76 20 0.3539014756679535\n",
      "76 70 0.31315523386001587\n",
      "Validation loss: 2.0129782949175152 RMSE: 1.4187946\n",
      "77 15 0.26362112164497375\n",
      "77 65 0.40480536222457886\n",
      "Validation loss: 1.6802868002936953 RMSE: 1.2962588\n",
      "78 10 0.20095324516296387\n",
      "78 60 0.1909295618534088\n",
      "Validation loss: 1.9328238169352214 RMSE: 1.3902603\n",
      "79 5 0.21805843710899353\n",
      "79 55 0.2592051923274994\n",
      "Validation loss: 1.3576501278650193 RMSE: 1.1651824\n",
      "80 0 0.17739823460578918\n",
      "80 50 0.3024883568286896\n",
      "80 100 0.4080718755722046\n",
      "Validation loss: 1.1202672220411756 RMSE: 1.0584267\n",
      "81 45 0.3179537057876587\n",
      "81 95 0.45819029211997986\n",
      "Validation loss: 1.4466119837193263 RMSE: 1.2027519\n",
      "82 40 0.5267819762229919\n",
      "82 90 0.40262556076049805\n",
      "Validation loss: 2.001661870593116 RMSE: 1.414801\n",
      "83 35 0.26715487241744995\n",
      "83 85 0.29608118534088135\n",
      "Validation loss: 1.3422241165524438 RMSE: 1.158544\n",
      "84 30 0.355442076921463\n",
      "84 80 0.4434055685997009\n",
      "Validation loss: 1.508853549049014 RMSE: 1.228354\n",
      "85 25 0.315662682056427\n",
      "85 75 0.38369467854499817\n",
      "Validation loss: 1.497597703479585 RMSE: 1.2237637\n",
      "86 20 0.25297296047210693\n",
      "86 70 0.3183089792728424\n",
      "Validation loss: 1.641987833522615 RMSE: 1.2814007\n",
      "87 15 0.38260072469711304\n",
      "87 65 0.4036347568035126\n",
      "Validation loss: 1.7144328798566546 RMSE: 1.3093635\n",
      "88 10 0.3569074869155884\n",
      "88 60 0.4233136475086212\n",
      "Validation loss: 1.0273764246986026 RMSE: 1.0135958\n",
      "89 5 0.27142709493637085\n",
      "89 55 0.20607540011405945\n",
      "Validation loss: 2.021375150907607 RMSE: 1.4217508\n",
      "90 0 0.5029320120811462\n",
      "90 50 0.18635013699531555\n",
      "90 100 0.28477558493614197\n",
      "Validation loss: 1.855151723680042 RMSE: 1.3620396\n",
      "91 45 0.4591364860534668\n",
      "91 95 0.37428024411201477\n",
      "Validation loss: 1.5299337443851289 RMSE: 1.236905\n",
      "92 40 0.367620587348938\n",
      "92 90 0.32945165038108826\n",
      "Validation loss: 1.26592283703032 RMSE: 1.1251324\n",
      "93 35 0.5998003482818604\n",
      "93 85 0.37200313806533813\n",
      "Validation loss: 1.100397224653335 RMSE: 1.0489982\n",
      "94 30 0.49263274669647217\n",
      "94 80 0.35039618611335754\n",
      "Validation loss: 1.5022209939502535 RMSE: 1.2256513\n",
      "95 25 0.3076176345348358\n",
      "95 75 0.3214586675167084\n",
      "Validation loss: 1.1510940120333717 RMSE: 1.0728905\n",
      "96 20 0.15527063608169556\n",
      "96 70 0.3614688515663147\n",
      "Validation loss: 1.378040177481515 RMSE: 1.1738995\n",
      "97 15 0.3379841148853302\n",
      "97 65 0.3114158511161804\n",
      "Validation loss: 1.5300961630684988 RMSE: 1.2369705\n",
      "98 10 0.20529943704605103\n",
      "98 60 0.19832423329353333\n",
      "Validation loss: 1.4595063516071864 RMSE: 1.2081003\n",
      "99 5 0.19815358519554138\n",
      "99 55 0.2735947370529175\n",
      "Validation loss: 1.4126286393120175 RMSE: 1.1885405\n",
      "100 0 0.24192999303340912\n",
      "100 50 0.1981431394815445\n",
      "100 100 0.27821722626686096\n",
      "Validation loss: 1.690300668988909 RMSE: 1.3001156\n",
      "101 45 0.6706233024597168\n",
      "101 95 0.48400428891181946\n",
      "Validation loss: 1.2411033891496204 RMSE: 1.1140482\n",
      "102 40 0.2578078508377075\n",
      "102 90 0.2452327311038971\n",
      "Validation loss: 1.3276502768198648 RMSE: 1.152237\n",
      "103 35 0.13923963904380798\n",
      "103 85 0.211679607629776\n",
      "Validation loss: 1.3148566609337216 RMSE: 1.146672\n",
      "104 30 0.4600647985935211\n",
      "104 80 0.13956090807914734\n",
      "Validation loss: 1.522447311310541 RMSE: 1.2338749\n",
      "105 25 0.18761450052261353\n",
      "105 75 0.2713477909564972\n",
      "Validation loss: 1.545624676204863 RMSE: 1.2432315\n",
      "106 20 0.18078891932964325\n",
      "106 70 0.33681055903434753\n",
      "Validation loss: 1.7685283751714798 RMSE: 1.3298603\n",
      "107 15 0.15876679122447968\n",
      "107 65 0.26253217458724976\n",
      "Validation loss: 1.1180738193648203 RMSE: 1.0573902\n",
      "108 10 0.13738687336444855\n",
      "108 60 0.392198383808136\n",
      "Validation loss: 1.202704261598133 RMSE: 1.0966787\n",
      "109 5 0.17481549084186554\n",
      "109 55 0.18976211547851562\n",
      "Validation loss: 1.193589362644014 RMSE: 1.0925151\n",
      "110 0 0.23908331990242004\n",
      "110 50 0.25684258341789246\n",
      "110 100 0.29642191529273987\n",
      "Validation loss: 1.852419137954712 RMSE: 1.3610361\n",
      "111 45 0.2160419374704361\n",
      "111 95 0.33589619398117065\n",
      "Validation loss: 1.9533956550416491 RMSE: 1.3976393\n",
      "112 40 0.4887899160385132\n",
      "112 90 0.2751011550426483\n",
      "Validation loss: 1.4964589981805712 RMSE: 1.2232984\n",
      "113 35 0.303372859954834\n",
      "113 85 0.1948217898607254\n",
      "Validation loss: 1.5464887664431617 RMSE: 1.243579\n",
      "114 30 0.3651497960090637\n",
      "114 80 0.20978927612304688\n",
      "Validation loss: 1.6242014112926664 RMSE: 1.2744416\n",
      "115 25 0.26112839579582214\n",
      "115 75 0.2289525717496872\n",
      "Validation loss: 1.7258180799938383 RMSE: 1.313704\n",
      "116 20 0.21573972702026367\n",
      "116 70 0.4803861975669861\n",
      "Validation loss: 1.4212693759373256 RMSE: 1.19217\n",
      "117 15 0.21725916862487793\n",
      "117 65 0.3585204482078552\n",
      "Validation loss: 1.4811899139767601 RMSE: 1.2170414\n",
      "118 10 0.21869732439517975\n",
      "118 60 0.2598782479763031\n",
      "Validation loss: 1.1643222218468077 RMSE: 1.0790375\n",
      "119 5 0.11869166046380997\n",
      "119 55 0.5242594480514526\n",
      "Validation loss: 1.2050099389893667 RMSE: 1.0977294\n",
      "120 0 0.2338716685771942\n",
      "120 50 0.21736906468868256\n",
      "120 100 0.41394487023353577\n",
      "Validation loss: 1.304604280562628 RMSE: 1.1421927\n",
      "121 45 0.31121721863746643\n",
      "121 95 0.2589074671268463\n",
      "Validation loss: 1.371969501887049 RMSE: 1.171311\n",
      "122 40 0.38700664043426514\n",
      "122 90 0.34959447383880615\n",
      "Validation loss: 1.4853332173256648 RMSE: 1.2187425\n",
      "123 35 0.21460090577602386\n",
      "123 85 0.1896997094154358\n",
      "Validation loss: 1.130110922313872 RMSE: 1.0630667\n",
      "124 30 0.229735866189003\n",
      "124 80 0.19984544813632965\n",
      "Validation loss: 1.6426049141656784 RMSE: 1.2816415\n",
      "125 25 0.4341857135295868\n",
      "125 75 0.25661560893058777\n",
      "Validation loss: 1.4303019696048327 RMSE: 1.1959523\n",
      "126 20 0.6027883887290955\n",
      "126 70 0.2270132303237915\n",
      "Validation loss: 1.5834162628366835 RMSE: 1.2583387\n",
      "127 15 0.16622711718082428\n",
      "127 65 0.3200480341911316\n",
      "Validation loss: 1.4217583338419597 RMSE: 1.1923751\n",
      "128 10 0.3806261420249939\n",
      "128 60 0.2612907886505127\n",
      "Validation loss: 1.2618655613490513 RMSE: 1.1233279\n",
      "129 5 0.12883734703063965\n",
      "129 55 0.16728220880031586\n",
      "Validation loss: 1.0260465247290476 RMSE: 1.0129396\n",
      "130 0 0.24840594828128815\n",
      "130 50 0.2623670995235443\n",
      "130 100 0.18662220239639282\n",
      "Validation loss: 1.5248340515863328 RMSE: 1.2348417\n",
      "131 45 0.15652602910995483\n",
      "131 95 0.4084174335002899\n",
      "Validation loss: 1.3469494524456205 RMSE: 1.1605815\n",
      "132 40 0.17734989523887634\n",
      "132 90 0.21293741464614868\n",
      "Validation loss: 1.2720998764038085 RMSE: 1.1278741\n",
      "133 35 0.24356520175933838\n",
      "133 85 0.17990350723266602\n",
      "Validation loss: 1.138871188958486 RMSE: 1.0671791\n",
      "134 30 0.27270928025245667\n",
      "134 80 0.25677672028541565\n",
      "Validation loss: 1.1386995451790947 RMSE: 1.0670987\n",
      "135 25 0.2144685685634613\n",
      "135 75 0.27101823687553406\n",
      "Validation loss: 1.0724555889765421 RMSE: 1.0355943\n",
      "136 20 0.36752253770828247\n",
      "136 70 0.3364901542663574\n",
      "Validation loss: 1.105794409768922 RMSE: 1.0515676\n",
      "137 15 0.20362631976604462\n",
      "137 65 0.17024511098861694\n",
      "Validation loss: 1.1716609943480718 RMSE: 1.0824329\n",
      "138 10 0.20354925096035004\n",
      "138 60 0.20854304730892181\n",
      "Validation loss: 1.311045671644665 RMSE: 1.145009\n",
      "139 5 0.23914138972759247\n",
      "139 55 0.24345508217811584\n",
      "Validation loss: 1.0033684208279565 RMSE: 1.0016828\n",
      "140 0 0.21620255708694458\n",
      "140 50 0.09888742864131927\n",
      "140 100 0.1718359738588333\n",
      "Validation loss: 1.1902527820496331 RMSE: 1.0909871\n",
      "141 45 0.19299958646297455\n",
      "141 95 0.12307655811309814\n",
      "Validation loss: 1.2496088760239736 RMSE: 1.117859\n",
      "142 40 0.1517035961151123\n",
      "142 90 0.13769279420375824\n",
      "Validation loss: 0.8641457736492157 RMSE: 0.9295944\n",
      "143 35 0.1313399076461792\n",
      "143 85 0.3366541266441345\n",
      "Validation loss: 1.2856255077180407 RMSE: 1.1338544\n",
      "144 30 0.20751933753490448\n",
      "144 80 0.25938108563423157\n",
      "Validation loss: 1.2419148541632152 RMSE: 1.1144123\n",
      "145 25 0.22635169327259064\n",
      "145 75 0.14770670235157013\n",
      "Validation loss: 1.4679638703664144 RMSE: 1.2115955\n",
      "146 20 0.27504703402519226\n",
      "146 70 0.30174651741981506\n",
      "Validation loss: 1.8031351316542852 RMSE: 1.3428087\n",
      "147 15 0.2683349549770355\n",
      "147 65 0.18479672074317932\n",
      "Validation loss: 1.3288598033643904 RMSE: 1.1527618\n",
      "148 10 0.2376956343650818\n",
      "148 60 0.1306353211402893\n",
      "Validation loss: 1.4234808058965773 RMSE: 1.1930971\n",
      "149 5 0.12317102402448654\n",
      "149 55 0.25047609210014343\n",
      "Validation loss: 1.612003501256307 RMSE: 1.269647\n",
      "150 0 0.1260909140110016\n",
      "150 50 0.16630084812641144\n",
      "150 100 0.22175368666648865\n",
      "Validation loss: 1.835492612066723 RMSE: 1.3548034\n",
      "151 45 0.21246454119682312\n",
      "151 95 0.15760022401809692\n",
      "Validation loss: 1.2689822094781058 RMSE: 1.1264911\n",
      "152 40 0.17857344448566437\n",
      "152 90 0.28005096316337585\n",
      "Validation loss: 1.5197758765447706 RMSE: 1.2327919\n",
      "153 35 0.37970083951950073\n",
      "153 85 0.19305844604969025\n",
      "Validation loss: 1.7216892151605516 RMSE: 1.3121315\n",
      "154 30 0.1706266850233078\n",
      "154 80 0.19468894600868225\n",
      "Validation loss: 1.5675219467708044 RMSE: 1.2520072\n",
      "155 25 0.210829496383667\n",
      "155 75 0.269456684589386\n",
      "Validation loss: 1.2273380432810101 RMSE: 1.1078529\n",
      "156 20 0.14933916926383972\n",
      "156 70 0.23976366221904755\n",
      "Validation loss: 1.6250648441768827 RMSE: 1.2747804\n",
      "157 15 0.27385297417640686\n",
      "157 65 0.2722265124320984\n",
      "Validation loss: 1.5816648687635149 RMSE: 1.2576426\n",
      "158 10 0.12477191537618637\n",
      "158 60 0.21959251165390015\n",
      "Validation loss: 1.6474918127059937 RMSE: 1.2835466\n",
      "159 5 0.18128184974193573\n",
      "159 55 0.26355263590812683\n",
      "Validation loss: 1.4220622658729554 RMSE: 1.1925025\n",
      "160 0 0.20675212144851685\n",
      "160 50 0.26377710700035095\n",
      "160 100 0.21166035532951355\n",
      "Validation loss: 1.8455894697280157 RMSE: 1.3585248\n",
      "161 45 0.11822514981031418\n",
      "161 95 0.22899459302425385\n",
      "Validation loss: 1.2174056143987746 RMSE: 1.1033611\n",
      "162 40 0.27975213527679443\n",
      "162 90 0.23999245464801788\n",
      "Validation loss: 1.4505758296875726 RMSE: 1.2043986\n",
      "163 35 0.15506640076637268\n",
      "163 85 0.30625468492507935\n",
      "Validation loss: 1.546614028158642 RMSE: 1.2436293\n",
      "164 30 0.47503113746643066\n",
      "164 80 0.17576995491981506\n",
      "Validation loss: 1.3712348370324998 RMSE: 1.1709974\n",
      "165 25 0.2839110791683197\n",
      "165 75 0.14586400985717773\n",
      "Validation loss: 1.5154099999439148 RMSE: 1.23102\n",
      "166 20 0.18400134146213531\n",
      "166 70 0.2087220400571823\n",
      "Validation loss: 1.3363821776140303 RMSE: 1.1560199\n",
      "167 15 0.18512198328971863\n",
      "167 65 0.24806049466133118\n",
      "Validation loss: 1.1805838130769275 RMSE: 1.0865467\n",
      "168 10 0.14209452271461487\n",
      "168 60 0.17422333359718323\n",
      "Validation loss: 1.8937828597568331 RMSE: 1.3761479\n",
      "169 5 0.1839168220758438\n",
      "169 55 0.20825619995594025\n",
      "Validation loss: 1.2757711501348585 RMSE: 1.1295004\n",
      "170 0 0.3124072551727295\n",
      "170 50 0.16919267177581787\n",
      "170 100 0.1942450851202011\n",
      "Validation loss: 1.8011757510049002 RMSE: 1.3420789\n",
      "171 45 0.16184787452220917\n",
      "171 95 0.1383555829524994\n",
      "Validation loss: 1.3004979736748197 RMSE: 1.1403939\n",
      "172 40 0.1392410844564438\n",
      "172 90 0.3214658498764038\n",
      "Validation loss: 1.3986909701710655 RMSE: 1.1826626\n",
      "173 35 0.36968258023262024\n",
      "173 85 0.1313961297273636\n",
      "Validation loss: 1.3817119030725389 RMSE: 1.1754624\n",
      "174 30 0.13882076740264893\n",
      "174 80 0.39442184567451477\n",
      "Validation loss: 1.579845122496287 RMSE: 1.2569189\n",
      "175 25 0.1874205768108368\n",
      "175 75 0.15107354521751404\n",
      "Validation loss: 1.6459122294471378 RMSE: 1.2829311\n",
      "176 20 0.19532626867294312\n",
      "176 70 0.10784922540187836\n",
      "Validation loss: 1.1341891805330913 RMSE: 1.0649831\n",
      "177 15 0.17288777232170105\n",
      "177 65 0.17445507645606995\n",
      "Validation loss: 1.1914293425423759 RMSE: 1.0915262\n",
      "178 10 0.12486007809638977\n",
      "178 60 0.2119559943675995\n",
      "Validation loss: 1.3061831281298684 RMSE: 1.1428837\n",
      "179 5 0.39303329586982727\n",
      "179 55 0.17103902995586395\n",
      "Validation loss: 1.2870439938136509 RMSE: 1.1344796\n",
      "180 0 0.1774376630783081\n",
      "180 50 0.13448114693164825\n",
      "180 100 0.2129567414522171\n",
      "Validation loss: 1.467598357654753 RMSE: 1.2114447\n",
      "181 45 0.3008398115634918\n",
      "181 95 0.18405181169509888\n",
      "Validation loss: 1.6628349213373093 RMSE: 1.2895097\n",
      "182 40 0.17134928703308105\n",
      "182 90 0.15519152581691742\n",
      "Validation loss: 1.1756672741401764 RMSE: 1.0842819\n",
      "183 35 0.17355172336101532\n",
      "183 85 0.18004725873470306\n",
      "Validation loss: 1.3922053064618791 RMSE: 1.1799175\n",
      "184 30 0.25665876269340515\n",
      "184 80 0.2194773256778717\n",
      "Validation loss: 1.485649905885969 RMSE: 1.2188724\n",
      "185 25 0.11809806525707245\n",
      "185 75 0.21772460639476776\n",
      "Validation loss: 1.2469857352120535 RMSE: 1.1166852\n",
      "186 20 0.16088494658470154\n",
      "186 70 0.2531009614467621\n",
      "Validation loss: 1.3526431583222889 RMSE: 1.1630318\n",
      "187 15 0.15358000993728638\n",
      "187 65 0.1400868445634842\n",
      "Validation loss: 1.0463751974559965 RMSE: 1.0229248\n",
      "188 10 0.2584780752658844\n",
      "188 60 0.30329614877700806\n",
      "Validation loss: 1.663312562306722 RMSE: 1.2896948\n",
      "189 5 0.08367713540792465\n",
      "189 55 0.2765170633792877\n",
      "Validation loss: 1.1967746785708837 RMSE: 1.093972\n",
      "190 0 0.14023733139038086\n",
      "190 50 0.27972212433815\n",
      "190 100 0.1537131816148758\n",
      "Validation loss: 1.517181994801476 RMSE: 1.2317394\n",
      "191 45 0.25794047117233276\n",
      "191 95 0.14014801383018494\n",
      "Validation loss: 1.394523344721113 RMSE: 1.1808994\n",
      "192 40 0.13534589111804962\n",
      "192 90 0.11608417332172394\n",
      "Validation loss: 1.0330572128295898 RMSE: 1.0163943\n",
      "193 35 0.2008320689201355\n",
      "193 85 0.1028050109744072\n",
      "Validation loss: 1.4858287243616013 RMSE: 1.2189457\n",
      "194 30 0.11436856538057327\n",
      "194 80 0.1308443695306778\n",
      "Validation loss: 1.1717602411905925 RMSE: 1.0824788\n",
      "195 25 0.15826360881328583\n",
      "195 75 0.2368759661912918\n",
      "Validation loss: 1.5650969573429652 RMSE: 1.2510383\n",
      "196 20 0.22813346982002258\n",
      "196 70 0.0872374102473259\n",
      "Validation loss: 1.0932826382773264 RMSE: 1.0456016\n",
      "197 15 0.11611928045749664\n",
      "197 65 0.25541865825653076\n",
      "Validation loss: 1.048801969346546 RMSE: 1.0241103\n",
      "198 10 0.22349639236927032\n",
      "198 60 0.271039754152298\n",
      "Validation loss: 1.591640114500409 RMSE: 1.2616022\n",
      "199 5 0.2814704477787018\n",
      "199 55 0.144163116812706\n",
      "Validation loss: 1.0289790653047108 RMSE: 1.014386\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.7483196860268002 Test RMSE: 0.8650548\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 778, 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'target': ['exp']}}\n",
      "Running on: cuda:0\n",
      "4199\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/4199\n",
      "Generating scaffold 1000/4199\n",
      "Generating scaffold 2000/4199\n",
      "Generating scaffold 3000/4199\n",
      "Generating scaffold 4000/4199\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 6.65452241897583\n",
      "0 50 1.2941210269927979\n",
      "0 100 1.0449621677398682\n",
      "Validation loss: 1.9389270237513951 RMSE: 1.3924536\n",
      "1 45 1.0291063785552979\n",
      "1 95 0.9441091418266296\n",
      "Validation loss: 1.145456602459862 RMSE: 1.07026\n",
      "2 40 0.9697041511535645\n",
      "2 90 1.0093815326690674\n",
      "Validation loss: 2.046205693767184 RMSE: 1.4304564\n",
      "3 35 0.8814839124679565\n",
      "3 85 0.9193076491355896\n",
      "Validation loss: 1.0654507671083724 RMSE: 1.0322068\n",
      "4 30 1.1836611032485962\n",
      "4 80 1.1392896175384521\n",
      "Validation loss: 1.1635404632205055 RMSE: 1.0786754\n",
      "5 25 0.688430666923523\n",
      "5 75 0.785964846611023\n",
      "Validation loss: 1.2885520333335514 RMSE: 1.135144\n",
      "6 20 0.7486445307731628\n",
      "6 70 0.9757649898529053\n",
      "Validation loss: 1.7565016127768016 RMSE: 1.3253307\n",
      "7 15 1.0196664333343506\n",
      "7 65 0.7539941072463989\n",
      "Validation loss: 0.9558435076758975 RMSE: 0.9776725\n",
      "8 10 1.0130727291107178\n",
      "8 60 0.6939053535461426\n",
      "Validation loss: 1.434172484988258 RMSE: 1.1975694\n",
      "9 5 0.6010076999664307\n",
      "9 55 0.8418659567832947\n",
      "Validation loss: 1.1519592239743188 RMSE: 1.0732936\n",
      "10 0 0.5820434093475342\n",
      "10 50 0.7234193086624146\n",
      "10 100 0.4626971483230591\n",
      "Validation loss: 1.441389691262018 RMSE: 1.2005789\n",
      "11 45 0.610102117061615\n",
      "11 95 0.5350172519683838\n",
      "Validation loss: 0.9261635950633458 RMSE: 0.962374\n",
      "12 40 0.8696814179420471\n",
      "12 90 0.4734530746936798\n",
      "Validation loss: 0.8682435012999035 RMSE: 0.93179584\n",
      "13 35 0.6022341847419739\n",
      "13 85 0.48454606533050537\n",
      "Validation loss: 1.3256363584881736 RMSE: 1.1513629\n",
      "14 30 0.8395012617111206\n",
      "14 80 0.7112749814987183\n",
      "Validation loss: 1.2420385054179601 RMSE: 1.1144677\n",
      "15 25 0.9505363702774048\n",
      "15 75 0.4111950397491455\n",
      "Validation loss: 0.9322586477512405 RMSE: 0.9655354\n",
      "16 20 0.4789133071899414\n",
      "16 70 0.5697165131568909\n",
      "Validation loss: 0.7738927625474475 RMSE: 0.8797117\n",
      "17 15 0.4080936312675476\n",
      "17 65 0.959138810634613\n",
      "Validation loss: 1.1071935313088552 RMSE: 1.0522326\n",
      "18 10 0.5442792177200317\n",
      "18 60 0.6665905117988586\n",
      "Validation loss: 1.1570449193318686 RMSE: 1.0756602\n",
      "19 5 0.733820378780365\n",
      "19 55 0.629576563835144\n",
      "Validation loss: 1.0949402082534063 RMSE: 1.0463939\n",
      "20 0 0.7459521889686584\n",
      "20 50 0.6227746605873108\n",
      "20 100 0.6669380068778992\n",
      "Validation loss: 1.3864425046103341 RMSE: 1.177473\n",
      "21 45 0.6986933946609497\n",
      "21 95 0.3740910589694977\n",
      "Validation loss: 0.8567895168349856 RMSE: 0.9256293\n",
      "22 40 0.5463626384735107\n",
      "22 90 0.5393102169036865\n",
      "Validation loss: 0.9419629897390093 RMSE: 0.97054774\n",
      "23 35 0.515108585357666\n",
      "23 85 0.5341920852661133\n",
      "Validation loss: 1.0519483452751524 RMSE: 1.0256453\n",
      "24 30 0.5584802627563477\n",
      "24 80 0.5235112309455872\n",
      "Validation loss: 1.1546312808990478 RMSE: 1.0745378\n",
      "25 25 0.3841416835784912\n",
      "25 75 0.38045305013656616\n",
      "Validation loss: 0.9713847784768967 RMSE: 0.98558855\n",
      "26 20 0.6614229083061218\n",
      "26 70 0.7142350077629089\n",
      "Validation loss: 1.0073334739321753 RMSE: 1.0036601\n",
      "27 15 0.3482976257801056\n",
      "27 65 0.3730723559856415\n",
      "Validation loss: 0.8756468171165103 RMSE: 0.93576\n",
      "28 10 0.534654438495636\n",
      "28 60 0.5316093564033508\n",
      "Validation loss: 1.26790786697751 RMSE: 1.1260141\n",
      "29 5 0.5263704657554626\n",
      "29 55 0.37815946340560913\n",
      "Validation loss: 1.4495940685272217 RMSE: 1.2039908\n",
      "30 0 0.5825083255767822\n",
      "30 50 0.4873657822608948\n",
      "30 100 0.9745590686798096\n",
      "Validation loss: 1.0266221091860817 RMSE: 1.0132236\n",
      "31 45 0.527121365070343\n",
      "31 95 0.6279762387275696\n",
      "Validation loss: 1.019465092250279 RMSE: 1.0096856\n",
      "32 40 0.5677309632301331\n",
      "32 90 0.8745185136795044\n",
      "Validation loss: 0.9444724514370872 RMSE: 0.97183967\n",
      "33 35 0.32512974739074707\n",
      "33 85 0.3234013020992279\n",
      "Validation loss: 0.9058387279510498 RMSE: 0.9517556\n",
      "34 30 0.33094027638435364\n",
      "34 80 0.873723030090332\n",
      "Validation loss: 1.362993441025416 RMSE: 1.1674731\n",
      "35 25 0.3807637691497803\n",
      "35 75 0.9871296882629395\n",
      "Validation loss: 0.6489860114597139 RMSE: 0.80559665\n",
      "36 20 0.37109696865081787\n",
      "36 70 0.5168488025665283\n",
      "Validation loss: 0.695720328603472 RMSE: 0.8340985\n",
      "37 15 0.547217845916748\n",
      "37 65 0.39344948530197144\n",
      "Validation loss: 0.7586572402999514 RMSE: 0.87100935\n",
      "38 10 0.5557039380073547\n",
      "38 60 0.6012162566184998\n",
      "Validation loss: 1.078204007375808 RMSE: 1.0383661\n",
      "39 5 0.3416396975517273\n",
      "39 55 0.5866090059280396\n",
      "Validation loss: 1.054872054713113 RMSE: 1.0270697\n",
      "40 0 0.4633963108062744\n",
      "40 50 0.560171902179718\n",
      "40 100 0.4350641071796417\n",
      "Validation loss: 1.1004588217962357 RMSE: 1.0490276\n",
      "41 45 0.3279303014278412\n",
      "41 95 0.3366950750350952\n",
      "Validation loss: 1.0047821303918247 RMSE: 1.0023882\n",
      "42 40 0.3504137098789215\n",
      "42 90 0.6884544491767883\n",
      "Validation loss: 1.130914040406545 RMSE: 1.0634445\n",
      "43 35 0.5735926628112793\n",
      "43 85 0.5181146860122681\n",
      "Validation loss: 1.0550875538871403 RMSE: 1.0271745\n",
      "44 30 0.5653414130210876\n",
      "44 80 0.5181763172149658\n",
      "Validation loss: 1.05082730168388 RMSE: 1.0250987\n",
      "45 25 0.4403609037399292\n",
      "45 75 0.37904348969459534\n",
      "Validation loss: 0.6562078311329796 RMSE: 0.8100666\n",
      "46 20 0.5177844762802124\n",
      "46 70 0.5756567120552063\n",
      "Validation loss: 0.8920937538146972 RMSE: 0.9445072\n",
      "47 15 0.5014034509658813\n",
      "47 65 0.3445476293563843\n",
      "Validation loss: 0.9209893181210472 RMSE: 0.95968187\n",
      "48 10 0.4336926341056824\n",
      "48 60 0.35936906933784485\n",
      "Validation loss: 0.733085432506743 RMSE: 0.85620403\n",
      "49 5 0.524915874004364\n",
      "49 55 0.5361443758010864\n",
      "Validation loss: 1.217790835244315 RMSE: 1.1035357\n",
      "50 0 0.3405250012874603\n",
      "50 50 0.21581408381462097\n",
      "50 100 0.5723517537117004\n",
      "Validation loss: 0.9473305407024565 RMSE: 0.9733091\n",
      "51 45 0.39548975229263306\n",
      "51 95 0.3150698244571686\n",
      "Validation loss: 1.057075029327756 RMSE: 1.0281415\n",
      "52 40 0.47392117977142334\n",
      "52 90 0.9108788371086121\n",
      "Validation loss: 1.0640044200988044 RMSE: 1.031506\n",
      "53 35 0.5095140337944031\n",
      "53 85 0.42967739701271057\n",
      "Validation loss: 0.829426786445436 RMSE: 0.9107287\n",
      "54 30 0.3203934133052826\n",
      "54 80 0.6166255474090576\n",
      "Validation loss: 0.8607520500818888 RMSE: 0.9277672\n",
      "55 25 0.4765443503856659\n",
      "55 75 0.3714170753955841\n",
      "Validation loss: 0.6772375277110508 RMSE: 0.82294446\n",
      "56 20 0.31176427006721497\n",
      "56 70 0.9828720688819885\n",
      "Validation loss: 0.842178874356406 RMSE: 0.91770303\n",
      "57 15 0.582078218460083\n",
      "57 65 0.40895482897758484\n",
      "Validation loss: 0.8820774787948245 RMSE: 0.9391898\n",
      "58 10 0.565638542175293\n",
      "58 60 0.6373937129974365\n",
      "Validation loss: 0.9964783327920096 RMSE: 0.9982376\n",
      "59 5 0.42230215668678284\n",
      "59 55 0.3149549067020416\n",
      "Validation loss: 0.9352862468787602 RMSE: 0.96710193\n",
      "60 0 0.23680174350738525\n",
      "60 50 0.5638741254806519\n",
      "60 100 0.2685902714729309\n",
      "Validation loss: 1.0504076458158946 RMSE: 1.024894\n",
      "61 45 0.5118964314460754\n",
      "61 95 0.36175596714019775\n",
      "Validation loss: 1.111462284269787 RMSE: 1.0542591\n",
      "62 40 0.24150213599205017\n",
      "62 90 0.33801576495170593\n",
      "Validation loss: 0.9460572651454381 RMSE: 0.97265476\n",
      "63 35 0.3343866467475891\n",
      "63 85 0.2212243378162384\n",
      "Validation loss: 1.3305655404215768 RMSE: 1.1535014\n",
      "64 30 0.43079161643981934\n",
      "64 80 0.4714994430541992\n",
      "Validation loss: 1.3687101545787992 RMSE: 1.1699189\n",
      "65 25 0.4446254074573517\n",
      "65 75 0.30865713953971863\n",
      "Validation loss: 1.086506944610959 RMSE: 1.0423564\n",
      "66 20 0.29834088683128357\n",
      "66 70 0.3188275694847107\n",
      "Validation loss: 1.081222100484939 RMSE: 1.0398183\n",
      "67 15 0.4709700644016266\n",
      "67 65 0.2800443768501282\n",
      "Validation loss: 0.9465529569557735 RMSE: 0.97290957\n",
      "68 10 0.3832181692123413\n",
      "68 60 0.31632891297340393\n",
      "Validation loss: 1.052413635026841 RMSE: 1.0258721\n",
      "69 5 0.2537915110588074\n",
      "69 55 0.3580142557621002\n",
      "Validation loss: 1.088609224274045 RMSE: 1.0433644\n",
      "70 0 0.21891388297080994\n",
      "70 50 0.348527729511261\n",
      "70 100 0.23049022257328033\n",
      "Validation loss: 0.8964253496556055 RMSE: 0.94679743\n",
      "71 45 0.3870088756084442\n",
      "71 95 0.2556734085083008\n",
      "Validation loss: 0.9361602283659436 RMSE: 0.9675537\n",
      "72 40 0.6644874811172485\n",
      "72 90 0.23151138424873352\n",
      "Validation loss: 0.9243479178065346 RMSE: 0.96143013\n",
      "73 35 0.20450899004936218\n",
      "73 85 0.386775940656662\n",
      "Validation loss: 0.82223468990553 RMSE: 0.9067716\n",
      "74 30 0.3628867268562317\n",
      "74 80 0.24948707222938538\n",
      "Validation loss: 0.9132757765906198 RMSE: 0.9556546\n",
      "75 25 0.386263370513916\n",
      "75 75 0.32097962498664856\n",
      "Validation loss: 0.9090820743924095 RMSE: 0.95345795\n",
      "76 20 0.45029279589653015\n",
      "76 70 0.2628430426120758\n",
      "Validation loss: 0.975225563844045 RMSE: 0.9875351\n",
      "77 15 0.2195676863193512\n",
      "77 65 0.3587687611579895\n",
      "Validation loss: 0.9153566371826899 RMSE: 0.9567427\n",
      "78 10 0.30178987979888916\n",
      "78 60 0.25597691535949707\n",
      "Validation loss: 0.6284142556644622 RMSE: 0.79272586\n",
      "79 5 0.4183427691459656\n",
      "79 55 0.28023213148117065\n",
      "Validation loss: 0.6840739204770043 RMSE: 0.8270876\n",
      "80 0 0.24137069284915924\n",
      "80 50 0.24717792868614197\n",
      "80 100 0.3913297951221466\n",
      "Validation loss: 0.8710680598304386 RMSE: 0.9333102\n",
      "81 45 0.46771949529647827\n",
      "81 95 0.3388354182243347\n",
      "Validation loss: 0.8309305639494033 RMSE: 0.9115539\n",
      "82 40 0.26042279601097107\n",
      "82 90 0.33635038137435913\n",
      "Validation loss: 0.9023144665218535 RMSE: 0.9499024\n",
      "83 35 0.29027989506721497\n",
      "83 85 0.3054264783859253\n",
      "Validation loss: 0.9033502719232014 RMSE: 0.9504474\n",
      "84 30 0.5432378649711609\n",
      "84 80 0.33528846502304077\n",
      "Validation loss: 0.8317255332356408 RMSE: 0.91198987\n",
      "85 25 0.3088991940021515\n",
      "85 75 0.15835821628570557\n",
      "Validation loss: 0.6900374665146782 RMSE: 0.83068496\n",
      "86 20 0.246440589427948\n",
      "86 70 0.4987439513206482\n",
      "Validation loss: 0.697146204255876 RMSE: 0.8349528\n",
      "87 15 0.33512914180755615\n",
      "87 65 0.17125099897384644\n",
      "Validation loss: 0.8512469586871919 RMSE: 0.9226304\n",
      "88 10 0.2974306344985962\n",
      "88 60 0.46122196316719055\n",
      "Validation loss: 0.6756428377968925 RMSE: 0.821975\n",
      "89 5 0.2592184543609619\n",
      "89 55 0.2510685324668884\n",
      "Validation loss: 0.7612954292978559 RMSE: 0.8725225\n",
      "90 0 0.2553839683532715\n",
      "90 50 0.29143691062927246\n",
      "90 100 0.23411385715007782\n",
      "Validation loss: 0.7652500958669753 RMSE: 0.8747857\n",
      "91 45 0.29095765948295593\n",
      "91 95 0.19134797155857086\n",
      "Validation loss: 0.8146466607139224 RMSE: 0.90257776\n",
      "92 40 0.28187304735183716\n",
      "92 90 0.5308655500411987\n",
      "Validation loss: 0.8541235793204535 RMSE: 0.924188\n",
      "93 35 0.2671144902706146\n",
      "93 85 0.306272029876709\n",
      "Validation loss: 0.7245215268362136 RMSE: 0.85118836\n",
      "94 30 0.26306235790252686\n",
      "94 80 0.25513795018196106\n",
      "Validation loss: 0.7493454433622815 RMSE: 0.86564744\n",
      "95 25 0.24709005653858185\n",
      "95 75 0.30620962381362915\n",
      "Validation loss: 0.8220006284259614 RMSE: 0.90664256\n",
      "96 20 0.38558775186538696\n",
      "96 70 0.35061851143836975\n",
      "Validation loss: 0.7042598928724016 RMSE: 0.83920187\n",
      "97 15 0.3036019802093506\n",
      "97 65 0.3606075644493103\n",
      "Validation loss: 0.747155997866676 RMSE: 0.8643818\n",
      "98 10 0.38296428322792053\n",
      "98 60 0.2508288025856018\n",
      "Validation loss: 0.7256166917937142 RMSE: 0.8518313\n",
      "99 5 0.24420107901096344\n",
      "99 55 0.32691073417663574\n",
      "Validation loss: 0.6945963544504983 RMSE: 0.83342445\n",
      "100 0 0.19995877146720886\n",
      "100 50 0.3197038769721985\n",
      "100 100 0.17381615936756134\n",
      "Validation loss: 0.684843845594497 RMSE: 0.8275529\n",
      "101 45 0.13025662302970886\n",
      "101 95 0.5478590726852417\n",
      "Validation loss: 0.6454962049211774 RMSE: 0.80342776\n",
      "102 40 0.22549322247505188\n",
      "102 90 0.2481285035610199\n",
      "Validation loss: 0.7211518934794835 RMSE: 0.8492066\n",
      "103 35 0.3019908666610718\n",
      "103 85 0.2724953889846802\n",
      "Validation loss: 0.7463296640486944 RMSE: 0.8639037\n",
      "104 30 0.3283958435058594\n",
      "104 80 0.33781880140304565\n",
      "Validation loss: 0.9018303984687441 RMSE: 0.9496475\n",
      "105 25 0.36932483315467834\n",
      "105 75 0.28794634342193604\n",
      "Validation loss: 0.6752526379766919 RMSE: 0.8217376\n",
      "106 20 0.34475722908973694\n",
      "106 70 0.30632147192955017\n",
      "Validation loss: 0.9376485977854048 RMSE: 0.9683226\n",
      "107 15 0.3793625831604004\n",
      "107 65 0.254597544670105\n",
      "Validation loss: 0.6781324023292178 RMSE: 0.82348794\n",
      "108 10 0.2803567349910736\n",
      "108 60 0.3954826593399048\n",
      "Validation loss: 0.8004158928280785 RMSE: 0.8946597\n",
      "109 5 0.11505475640296936\n",
      "109 55 0.22065241634845734\n",
      "Validation loss: 0.6430924120403472 RMSE: 0.8019304\n",
      "110 0 0.1877862513065338\n",
      "110 50 0.24267588555812836\n",
      "110 100 0.6344508528709412\n",
      "Validation loss: 0.6881721896784646 RMSE: 0.8295614\n",
      "111 45 0.29903173446655273\n",
      "111 95 0.3632600009441376\n",
      "Validation loss: 0.8042108955837431 RMSE: 0.89677805\n",
      "112 40 0.20731288194656372\n",
      "112 90 0.31236281991004944\n",
      "Validation loss: 0.6259108168738229 RMSE: 0.79114527\n",
      "113 35 0.3073589503765106\n",
      "113 85 0.3752206563949585\n",
      "Validation loss: 0.8718381024542309 RMSE: 0.93372273\n",
      "114 30 0.21807043254375458\n",
      "114 80 0.2974758744239807\n",
      "Validation loss: 0.689906411795389 RMSE: 0.83060604\n",
      "115 25 0.19332389533519745\n",
      "115 75 0.3791656494140625\n",
      "Validation loss: 0.790293231180736 RMSE: 0.8889844\n",
      "116 20 0.20633140206336975\n",
      "116 70 0.1408146768808365\n",
      "Validation loss: 0.7200235747155689 RMSE: 0.84854203\n",
      "117 15 0.26376110315322876\n",
      "117 65 0.22881446778774261\n",
      "Validation loss: 0.7899631863548642 RMSE: 0.8887987\n",
      "118 10 0.24734778702259064\n",
      "118 60 0.3418784439563751\n",
      "Validation loss: 0.9060375616663978 RMSE: 0.9518601\n",
      "119 5 0.2326393723487854\n",
      "119 55 0.14305226504802704\n",
      "Validation loss: 0.6973125014986311 RMSE: 0.8350524\n",
      "120 0 0.44388332962989807\n",
      "120 50 0.25963094830513\n",
      "120 100 0.28478074073791504\n",
      "Validation loss: 0.6586735963821411 RMSE: 0.81158704\n",
      "121 45 0.23232221603393555\n",
      "121 95 0.21738284826278687\n",
      "Validation loss: 0.827004506048702 RMSE: 0.9093979\n",
      "122 40 0.19442568719387054\n",
      "122 90 0.22416256368160248\n",
      "Validation loss: 0.7188999931017558 RMSE: 0.8478797\n",
      "123 35 0.2031269371509552\n",
      "123 85 0.18902790546417236\n",
      "Validation loss: 0.7227336378324599 RMSE: 0.8501374\n",
      "124 30 0.2792963683605194\n",
      "124 80 0.12748990952968597\n",
      "Validation loss: 0.6018466063908168 RMSE: 0.7757877\n",
      "125 25 0.4734008312225342\n",
      "125 75 0.4393191635608673\n",
      "Validation loss: 0.8765487784431094 RMSE: 0.9362418\n",
      "126 20 0.2583249807357788\n",
      "126 70 0.2054787427186966\n",
      "Validation loss: 0.8322393576304118 RMSE: 0.9122715\n",
      "127 15 0.2581378221511841\n",
      "127 65 0.30822739005088806\n",
      "Validation loss: 0.7329472306228819 RMSE: 0.8561234\n",
      "128 10 0.29338014125823975\n",
      "128 60 0.18163004517555237\n",
      "Validation loss: 0.7599514277208419 RMSE: 0.8717519\n",
      "129 5 0.18904869258403778\n",
      "129 55 0.3408036530017853\n",
      "Validation loss: 0.7590532949992589 RMSE: 0.8712366\n",
      "130 0 0.14445462822914124\n",
      "130 50 0.14529038965702057\n",
      "130 100 0.14969971776008606\n",
      "Validation loss: 0.6888583177611941 RMSE: 0.8299749\n",
      "131 45 0.25359827280044556\n",
      "131 95 0.2889232337474823\n",
      "Validation loss: 0.5581426098233178 RMSE: 0.74708945\n",
      "132 40 0.3756449818611145\n",
      "132 90 0.26544389128685\n",
      "Validation loss: 0.7615471680959066 RMSE: 0.8726667\n",
      "133 35 0.18981711566448212\n",
      "133 85 0.23245199024677277\n",
      "Validation loss: 0.8508531865619477 RMSE: 0.92241704\n",
      "134 30 0.14418484270572662\n",
      "134 80 0.15210330486297607\n",
      "Validation loss: 0.6517417496158964 RMSE: 0.8073053\n",
      "135 25 0.28058815002441406\n",
      "135 75 0.33235853910446167\n",
      "Validation loss: 0.8036722535178775 RMSE: 0.8964777\n",
      "136 20 0.47067251801490784\n",
      "136 70 0.2342759519815445\n",
      "Validation loss: 0.6790017902851104 RMSE: 0.8240156\n",
      "137 15 0.17369335889816284\n",
      "137 65 0.24773387610912323\n",
      "Validation loss: 0.5755906275340489 RMSE: 0.75867695\n",
      "138 10 0.163238063454628\n",
      "138 60 0.1828252077102661\n",
      "Validation loss: 0.6757204362324306 RMSE: 0.8220222\n",
      "139 5 0.1831120401620865\n",
      "139 55 0.23844942450523376\n",
      "Validation loss: 0.6167508647555396 RMSE: 0.7853349\n",
      "140 0 0.5449534058570862\n",
      "140 50 0.21763473749160767\n",
      "140 100 0.2713034749031067\n",
      "Validation loss: 0.6378838561120488 RMSE: 0.7986763\n",
      "141 45 0.2823088467121124\n",
      "141 95 0.29868313670158386\n",
      "Validation loss: 0.6055387990815299 RMSE: 0.77816373\n",
      "142 40 0.2783324122428894\n",
      "142 90 0.3168245851993561\n",
      "Validation loss: 0.5912638488269988 RMSE: 0.7689369\n",
      "143 35 0.3330760598182678\n",
      "143 85 0.1472310870885849\n",
      "Validation loss: 0.8629284654344831 RMSE: 0.9289394\n",
      "144 30 0.2328239232301712\n",
      "144 80 0.1661963015794754\n",
      "Validation loss: 0.7063233472052075 RMSE: 0.84043044\n",
      "145 25 0.11771620810031891\n",
      "145 75 0.14480745792388916\n",
      "Validation loss: 0.6049316633315314 RMSE: 0.7777735\n",
      "146 20 0.2364211082458496\n",
      "146 70 0.19214849174022675\n",
      "Validation loss: 0.8139563946496873 RMSE: 0.90219533\n",
      "147 15 0.2034769505262375\n",
      "147 65 0.1807376742362976\n",
      "Validation loss: 0.5822817371005103 RMSE: 0.76307386\n",
      "148 10 0.1577029973268509\n",
      "148 60 0.26873815059661865\n",
      "Validation loss: 0.6397600165435247 RMSE: 0.79985\n",
      "149 5 0.22748222947120667\n",
      "149 55 0.1568661332130432\n",
      "Validation loss: 0.652724243913378 RMSE: 0.8079135\n",
      "150 0 0.21760442852973938\n",
      "150 50 0.2800626754760742\n",
      "150 100 0.1505288928747177\n",
      "Validation loss: 0.7184140483538309 RMSE: 0.8475931\n",
      "151 45 0.3157011866569519\n",
      "151 95 0.2272513061761856\n",
      "Validation loss: 0.6726030795347123 RMSE: 0.8201238\n",
      "152 40 0.18233242630958557\n",
      "152 90 0.10831423103809357\n",
      "Validation loss: 0.5810274090085711 RMSE: 0.7622515\n",
      "153 35 0.20024380087852478\n",
      "153 85 0.18311963975429535\n",
      "Validation loss: 0.6414065786770412 RMSE: 0.8008786\n",
      "154 30 0.30333590507507324\n",
      "154 80 0.213444784283638\n",
      "Validation loss: 0.7078570155870347 RMSE: 0.84134233\n",
      "155 25 0.43473729491233826\n",
      "155 75 0.18433938920497894\n",
      "Validation loss: 0.5975475674583799 RMSE: 0.77301204\n",
      "156 20 0.22039014101028442\n",
      "156 70 0.3440978229045868\n",
      "Validation loss: 0.5428243656953176 RMSE: 0.7367661\n",
      "157 15 0.13105744123458862\n",
      "157 65 0.12938545644283295\n",
      "Validation loss: 0.6537756829034714 RMSE: 0.808564\n",
      "158 10 0.2033277004957199\n",
      "158 60 0.2655933201313019\n",
      "Validation loss: 0.6213857139859881 RMSE: 0.7882802\n",
      "159 5 0.27082324028015137\n",
      "159 55 0.23521682620048523\n",
      "Validation loss: 0.6469442378906977 RMSE: 0.80432844\n",
      "160 0 0.21387937664985657\n",
      "160 50 0.3203137516975403\n",
      "160 100 0.19719064235687256\n",
      "Validation loss: 0.6492213144188835 RMSE: 0.80574274\n",
      "161 45 0.15935365855693817\n",
      "161 95 0.167368084192276\n",
      "Validation loss: 0.6651562801429204 RMSE: 0.8155711\n",
      "162 40 0.1162077933549881\n",
      "162 90 0.13497762382030487\n",
      "Validation loss: 0.6788394878307978 RMSE: 0.8239171\n",
      "163 35 0.17718878388404846\n",
      "163 85 0.1728116124868393\n",
      "Validation loss: 0.5671581401711419 RMSE: 0.75309896\n",
      "164 30 0.33083412051200867\n",
      "164 80 0.24052676558494568\n",
      "Validation loss: 0.7416614895775204 RMSE: 0.86119765\n",
      "165 25 0.3156205415725708\n",
      "165 75 0.4455007314682007\n",
      "Validation loss: 0.6132786489668347 RMSE: 0.7831211\n",
      "166 20 0.28394389152526855\n",
      "166 70 0.21275560557842255\n",
      "Validation loss: 0.8001077964192345 RMSE: 0.8944875\n",
      "167 15 0.13468405604362488\n",
      "167 65 0.21443670988082886\n",
      "Validation loss: 0.6840127002625238 RMSE: 0.8270506\n",
      "168 10 0.16836225986480713\n",
      "168 60 0.1935766488313675\n",
      "Validation loss: 0.6486983526320684 RMSE: 0.8054181\n",
      "169 5 0.10660794377326965\n",
      "169 55 0.21571357548236847\n",
      "Validation loss: 0.5547722021738688 RMSE: 0.7448303\n",
      "170 0 0.13090880215168\n",
      "170 50 0.1296146810054779\n",
      "170 100 0.1294482946395874\n",
      "Validation loss: 0.6498842801366533 RMSE: 0.80615395\n",
      "171 45 0.2507994472980499\n",
      "171 95 0.3261895179748535\n",
      "Validation loss: 0.6656499198504857 RMSE: 0.8158737\n",
      "172 40 0.16828718781471252\n",
      "172 90 0.15540514886379242\n",
      "Validation loss: 0.6028156831150964 RMSE: 0.77641207\n",
      "173 35 0.19114840030670166\n",
      "173 85 0.1667911559343338\n",
      "Validation loss: 0.5962752353577386 RMSE: 0.7721886\n",
      "174 30 0.2951456606388092\n",
      "174 80 0.2035834938287735\n",
      "Validation loss: 0.615578158270745 RMSE: 0.78458786\n",
      "175 25 0.17514535784721375\n",
      "175 75 0.15871936082839966\n",
      "Validation loss: 0.5212398321855636 RMSE: 0.7219694\n",
      "176 20 0.14294715225696564\n",
      "176 70 0.22354114055633545\n",
      "Validation loss: 0.5074490339983078 RMSE: 0.71235454\n",
      "177 15 0.1280864030122757\n",
      "177 65 0.14887183904647827\n",
      "Validation loss: 0.7674231114841643 RMSE: 0.8760269\n",
      "178 10 0.06972385942935944\n",
      "178 60 0.08847921341657639\n",
      "Validation loss: 0.6231602680115472 RMSE: 0.789405\n",
      "179 5 0.18068024516105652\n",
      "179 55 0.21093390882015228\n",
      "Validation loss: 0.6836008230845133 RMSE: 0.82680154\n",
      "180 0 0.159432053565979\n",
      "180 50 0.39834436774253845\n",
      "180 100 0.23043292760849\n",
      "Validation loss: 0.623239003760474 RMSE: 0.7894549\n",
      "181 45 0.2589336633682251\n",
      "181 95 0.17138774693012238\n",
      "Validation loss: 0.7243048040639787 RMSE: 0.851061\n",
      "182 40 0.20318767428398132\n",
      "182 90 0.2304706871509552\n",
      "Validation loss: 0.6941139380137126 RMSE: 0.833135\n",
      "183 35 0.2333863079547882\n",
      "183 85 0.10878381878137589\n",
      "Validation loss: 0.6357311126731691 RMSE: 0.7973275\n",
      "184 30 0.13383111357688904\n",
      "184 80 0.1762743890285492\n",
      "Validation loss: 0.5868272009350005 RMSE: 0.76604646\n",
      "185 25 0.19821128249168396\n",
      "185 75 0.19933170080184937\n",
      "Validation loss: 0.6591275941757929 RMSE: 0.81186676\n",
      "186 20 0.24624349176883698\n",
      "186 70 0.16708984971046448\n",
      "Validation loss: 0.7262931176594325 RMSE: 0.8522284\n",
      "187 15 0.19450555741786957\n",
      "187 65 0.2670823335647583\n",
      "Validation loss: 0.6749817997217178 RMSE: 0.8215727\n",
      "188 10 0.3869037926197052\n",
      "188 60 0.2720198929309845\n",
      "Validation loss: 0.5866695426759265 RMSE: 0.7659435\n",
      "189 5 0.2109367847442627\n",
      "189 55 0.24468110501766205\n",
      "Validation loss: 0.5986396403539749 RMSE: 0.77371806\n",
      "190 0 0.15164902806282043\n",
      "190 50 0.26307347416877747\n",
      "190 100 0.24339698255062103\n",
      "Validation loss: 0.6720248000962393 RMSE: 0.81977123\n",
      "191 45 0.16862517595291138\n",
      "191 95 0.18347033858299255\n",
      "Validation loss: 0.5910803772154308 RMSE: 0.7688175\n",
      "192 40 0.24518181383609772\n",
      "192 90 0.18771333992481232\n",
      "Validation loss: 0.5564077326229641 RMSE: 0.74592745\n",
      "193 35 0.16430392861366272\n",
      "193 85 0.18240772187709808\n",
      "Validation loss: 0.7591856184459868 RMSE: 0.8713126\n",
      "194 30 0.17027893662452698\n",
      "194 80 0.26981163024902344\n",
      "Validation loss: 0.5698243566921779 RMSE: 0.7548671\n",
      "195 25 0.2632959485054016\n",
      "195 75 0.2256391942501068\n",
      "Validation loss: 0.6116020108972277 RMSE: 0.7820499\n",
      "196 20 0.21433591842651367\n",
      "196 70 0.15783746540546417\n",
      "Validation loss: 0.6280529941831317 RMSE: 0.792498\n",
      "197 15 0.10981886833906174\n",
      "197 65 0.10211735963821411\n",
      "Validation loss: 0.6773552940005347 RMSE: 0.823016\n",
      "198 10 0.23415787518024445\n",
      "198 60 0.12024500221014023\n",
      "Validation loss: 0.7690288413138616 RMSE: 0.87694293\n",
      "199 5 0.1666547954082489\n",
      "199 55 0.1389455497264862\n",
      "Validation loss: 0.560886633963812 RMSE: 0.74892366\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.5565604096367246 Test RMSE: 0.7460298\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 779, 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'target': ['exp']}}\n",
      "Running on: cuda:0\n",
      "4199\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/4199\n",
      "Generating scaffold 1000/4199\n",
      "Generating scaffold 2000/4199\n",
      "Generating scaffold 3000/4199\n",
      "Generating scaffold 4000/4199\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 6.152665138244629\n",
      "0 50 0.7964825630187988\n",
      "0 100 1.2729390859603882\n",
      "Validation loss: 1.4586591584341866 RMSE: 1.2077496\n",
      "1 45 1.0740454196929932\n",
      "1 95 0.9085339307785034\n",
      "Validation loss: 1.4702275185357956 RMSE: 1.2125294\n",
      "2 40 1.4315767288208008\n",
      "2 90 1.4296728372573853\n",
      "Validation loss: 1.0564314998331523 RMSE: 1.0278286\n",
      "3 35 0.5258476138114929\n",
      "3 85 0.9362184405326843\n",
      "Validation loss: 1.1627334628786359 RMSE: 1.0783012\n",
      "4 30 0.8589717149734497\n",
      "4 80 0.6769343614578247\n",
      "Validation loss: 1.1355914231567157 RMSE: 1.0656413\n",
      "5 25 0.7718868851661682\n",
      "5 75 1.0743939876556396\n",
      "Validation loss: 1.0860793130738395 RMSE: 1.0421513\n",
      "6 20 1.2398028373718262\n",
      "6 70 1.2422586679458618\n",
      "Validation loss: 0.9947781473398208 RMSE: 0.9973857\n",
      "7 15 0.5194118618965149\n",
      "7 65 0.6754127144813538\n",
      "Validation loss: 0.9963616825285412 RMSE: 0.9981792\n",
      "8 10 1.4770139455795288\n",
      "8 60 1.0283303260803223\n",
      "Validation loss: 1.0409871680395943 RMSE: 1.0202878\n",
      "9 5 1.1779050827026367\n",
      "9 55 0.5731697678565979\n",
      "Validation loss: 1.1050872530256 RMSE: 1.0512313\n",
      "10 0 0.6736482381820679\n",
      "10 50 0.788463294506073\n",
      "10 100 1.1529812812805176\n",
      "Validation loss: 1.0096073184694563 RMSE: 1.0047922\n",
      "11 45 0.6659001111984253\n",
      "11 95 1.1660798788070679\n",
      "Validation loss: 1.0409392004921323 RMSE: 1.0202643\n",
      "12 40 1.0434883832931519\n",
      "12 90 0.5515323877334595\n",
      "Validation loss: 1.0427167279379708 RMSE: 1.021135\n",
      "13 35 0.6074841022491455\n",
      "13 85 0.43441152572631836\n",
      "Validation loss: 0.8291290521621704 RMSE: 0.91056526\n",
      "14 30 0.6263958215713501\n",
      "14 80 0.5600502490997314\n",
      "Validation loss: 0.8343750842979976 RMSE: 0.91344136\n",
      "15 25 0.22906160354614258\n",
      "15 75 0.8270179033279419\n",
      "Validation loss: 0.7505320265179589 RMSE: 0.86633253\n",
      "16 20 0.5960076451301575\n",
      "16 70 0.716037929058075\n",
      "Validation loss: 0.981140509105864 RMSE: 0.9905253\n",
      "17 15 0.8058478236198425\n",
      "17 65 0.6724576950073242\n",
      "Validation loss: 0.9910494032360259 RMSE: 0.99551463\n",
      "18 10 0.5515474081039429\n",
      "18 60 0.5227600336074829\n",
      "Validation loss: 0.9500762212844122 RMSE: 0.9747186\n",
      "19 5 0.5717952251434326\n",
      "19 55 0.8237398266792297\n",
      "Validation loss: 0.8674811754907881 RMSE: 0.93138665\n",
      "20 0 0.5069934725761414\n",
      "20 50 0.48760125041007996\n",
      "20 100 0.46577176451683044\n",
      "Validation loss: 0.9139527956644694 RMSE: 0.9560088\n",
      "21 45 0.8447579145431519\n",
      "21 95 0.4702116847038269\n",
      "Validation loss: 0.8142616819767725 RMSE: 0.9023645\n",
      "22 40 0.4561588168144226\n",
      "22 90 0.38970187306404114\n",
      "Validation loss: 0.8795428775605701 RMSE: 0.9378395\n",
      "23 35 0.6022675037384033\n",
      "23 85 0.37392547726631165\n",
      "Validation loss: 0.8014624402636573 RMSE: 0.8952443\n",
      "24 30 0.5272368788719177\n",
      "24 80 0.3946106433868408\n",
      "Validation loss: 1.0091912973494757 RMSE: 1.0045851\n",
      "25 25 0.37133684754371643\n",
      "25 75 0.902776837348938\n",
      "Validation loss: 0.9521701443763007 RMSE: 0.97579205\n",
      "26 20 0.4417071044445038\n",
      "26 70 0.45151060819625854\n",
      "Validation loss: 0.7346249452659062 RMSE: 0.8571027\n",
      "27 15 0.5091086626052856\n",
      "27 65 0.8629022836685181\n",
      "Validation loss: 0.7453073399407523 RMSE: 0.8633118\n",
      "28 10 0.27087950706481934\n",
      "28 60 0.5907891392707825\n",
      "Validation loss: 0.839628757749285 RMSE: 0.91631263\n",
      "29 5 0.3232872486114502\n",
      "29 55 0.9079679250717163\n",
      "Validation loss: 0.7529576818148295 RMSE: 0.86773133\n",
      "30 0 0.5791889429092407\n",
      "30 50 0.2761993706226349\n",
      "30 100 0.6329860091209412\n",
      "Validation loss: 0.701958265758696 RMSE: 0.83782953\n",
      "31 45 0.4753319025039673\n",
      "31 95 0.5272533297538757\n",
      "Validation loss: 0.7662868872994468 RMSE: 0.8753781\n",
      "32 40 0.3117719888687134\n",
      "32 90 0.6837020516395569\n",
      "Validation loss: 0.7493667091642108 RMSE: 0.8656597\n",
      "33 35 0.6062667369842529\n",
      "33 85 0.5621330142021179\n",
      "Validation loss: 0.8095511754353841 RMSE: 0.8997506\n",
      "34 30 0.5808654427528381\n",
      "34 80 0.5793329477310181\n",
      "Validation loss: 0.8342183771587554 RMSE: 0.9133555\n",
      "35 25 0.5648430585861206\n",
      "35 75 0.36294835805892944\n",
      "Validation loss: 0.7107428493953887 RMSE: 0.84305567\n",
      "36 20 0.5262981057167053\n",
      "36 70 0.9975707530975342\n",
      "Validation loss: 0.7483942226994605 RMSE: 0.8650978\n",
      "37 15 0.30939391255378723\n",
      "37 65 0.39916545152664185\n",
      "Validation loss: 0.6768339026541937 RMSE: 0.82269907\n",
      "38 10 0.4237189292907715\n",
      "38 60 0.8726359009742737\n",
      "Validation loss: 0.9329190793491545 RMSE: 0.96587735\n",
      "39 5 0.34524914622306824\n",
      "39 55 0.4242957830429077\n",
      "Validation loss: 0.7914412935574849 RMSE: 0.88962984\n",
      "40 0 0.48111671209335327\n",
      "40 50 0.39575645327568054\n",
      "40 100 0.4595893323421478\n",
      "Validation loss: 0.7657881169092088 RMSE: 0.8750932\n",
      "41 45 0.6309764385223389\n",
      "41 95 0.5013653039932251\n",
      "Validation loss: 0.868500067222686 RMSE: 0.9319335\n",
      "42 40 0.8090410232543945\n",
      "42 90 0.39522087574005127\n",
      "Validation loss: 0.7229415189652216 RMSE: 0.85025966\n",
      "43 35 0.47664356231689453\n",
      "43 85 0.4986132085323334\n",
      "Validation loss: 0.7337201175235567 RMSE: 0.85657465\n",
      "44 30 0.5941081643104553\n",
      "44 80 0.6967186331748962\n",
      "Validation loss: 0.733320262886229 RMSE: 0.8563412\n",
      "45 25 0.3300856947898865\n",
      "45 75 0.7563987374305725\n",
      "Validation loss: 0.6616827692304339 RMSE: 0.8134389\n",
      "46 20 0.849873960018158\n",
      "46 70 0.4958620071411133\n",
      "Validation loss: 0.7218090579623267 RMSE: 0.84959346\n",
      "47 15 0.44870832562446594\n",
      "47 65 0.301584929227829\n",
      "Validation loss: 0.6721228229148047 RMSE: 0.81983095\n",
      "48 10 0.5545387864112854\n",
      "48 60 0.2782495617866516\n",
      "Validation loss: 0.7282025019327799 RMSE: 0.85334784\n",
      "49 5 0.42002856731414795\n",
      "49 55 0.33014196157455444\n",
      "Validation loss: 0.7042327046394348 RMSE: 0.8391857\n",
      "50 0 0.27793586254119873\n",
      "50 50 0.3867025673389435\n",
      "50 100 0.30957525968551636\n",
      "Validation loss: 0.8744268911225456 RMSE: 0.93510795\n",
      "51 45 0.4826841950416565\n",
      "51 95 0.4530164897441864\n",
      "Validation loss: 0.73111960206713 RMSE: 0.85505533\n",
      "52 40 0.5418469905853271\n",
      "52 90 0.3052867352962494\n",
      "Validation loss: 0.7080135751338232 RMSE: 0.8414355\n",
      "53 35 0.506727933883667\n",
      "53 85 0.36020389199256897\n",
      "Validation loss: 0.8610043835072291 RMSE: 0.92790323\n",
      "54 30 0.28648027777671814\n",
      "54 80 0.35172829031944275\n",
      "Validation loss: 0.8039966106414795 RMSE: 0.89665854\n",
      "55 25 0.7452481389045715\n",
      "55 75 0.4812004268169403\n",
      "Validation loss: 0.7655644239414305 RMSE: 0.87496537\n",
      "56 20 0.3725794553756714\n",
      "56 70 0.41696277260780334\n",
      "Validation loss: 0.7097861406349001 RMSE: 0.84248805\n",
      "57 15 0.3375142514705658\n",
      "57 65 0.6032879948616028\n",
      "Validation loss: 0.7321719210062708 RMSE: 0.85567045\n",
      "58 10 0.42520830035209656\n",
      "58 60 0.563871443271637\n",
      "Validation loss: 0.7803557100750151 RMSE: 0.8833775\n",
      "59 5 0.3080976605415344\n",
      "59 55 0.34748053550720215\n",
      "Validation loss: 0.834489277430943 RMSE: 0.9135038\n",
      "60 0 0.262778103351593\n",
      "60 50 0.2696555554866791\n",
      "60 100 0.46736469864845276\n",
      "Validation loss: 0.7949598354952676 RMSE: 0.89160526\n",
      "61 45 0.23595966398715973\n",
      "61 95 0.6924777030944824\n",
      "Validation loss: 0.722862164179484 RMSE: 0.85021305\n",
      "62 40 0.6319757103919983\n",
      "62 90 0.40018898248672485\n",
      "Validation loss: 0.6992033731369746 RMSE: 0.8361838\n",
      "63 35 0.25816890597343445\n",
      "63 85 0.4484598636627197\n",
      "Validation loss: 0.7940188680376326 RMSE: 0.8910774\n",
      "64 30 0.23740650713443756\n",
      "64 80 0.40968677401542664\n",
      "Validation loss: 0.7579869974227179 RMSE: 0.8706245\n",
      "65 25 0.4214271903038025\n",
      "65 75 0.24365077912807465\n",
      "Validation loss: 0.7464906556265695 RMSE: 0.86399686\n",
      "66 20 0.35200849175453186\n",
      "66 70 0.3505856394767761\n",
      "Validation loss: 0.7202125100862412 RMSE: 0.8486534\n",
      "67 15 0.253141313791275\n",
      "67 65 0.44632697105407715\n",
      "Validation loss: 0.7573728232156662 RMSE: 0.87027174\n",
      "68 10 0.25565898418426514\n",
      "68 60 0.253093421459198\n",
      "Validation loss: 0.7179757810774303 RMSE: 0.8473345\n",
      "69 5 0.5257226824760437\n",
      "69 55 0.47344470024108887\n",
      "Validation loss: 0.6970919064113072 RMSE: 0.8349202\n",
      "70 0 0.5642831921577454\n",
      "70 50 0.5712158679962158\n",
      "70 100 0.35537198185920715\n",
      "Validation loss: 0.8204920927683512 RMSE: 0.9058102\n",
      "71 45 0.38098305463790894\n",
      "71 95 0.3564154803752899\n",
      "Validation loss: 0.6717012223743257 RMSE: 0.81957376\n",
      "72 40 0.3004690110683441\n",
      "72 90 0.2963685393333435\n",
      "Validation loss: 0.6108200629552205 RMSE: 0.78154975\n",
      "73 35 0.36146309971809387\n",
      "73 85 0.3909119665622711\n",
      "Validation loss: 0.7325626799038478 RMSE: 0.8558988\n",
      "74 30 0.3455415964126587\n",
      "74 80 0.8159322738647461\n",
      "Validation loss: 0.6927252724057152 RMSE: 0.8323012\n",
      "75 25 0.4511067867279053\n",
      "75 75 0.3521789610385895\n",
      "Validation loss: 0.7550868278458005 RMSE: 0.86895734\n",
      "76 20 0.41004475951194763\n",
      "76 70 0.4144275486469269\n",
      "Validation loss: 0.7095525332859585 RMSE: 0.84234947\n",
      "77 15 0.41921722888946533\n",
      "77 65 0.44765761494636536\n",
      "Validation loss: 0.7788284244991485 RMSE: 0.8825125\n",
      "78 10 0.4266052842140198\n",
      "78 60 0.3297872543334961\n",
      "Validation loss: 0.7297126781372797 RMSE: 0.85423225\n",
      "79 5 0.595928966999054\n",
      "79 55 0.28610676527023315\n",
      "Validation loss: 0.7245476279939924 RMSE: 0.8512037\n",
      "80 0 0.4475051164627075\n",
      "80 50 0.2343171387910843\n",
      "80 100 0.32661890983581543\n",
      "Validation loss: 0.727294220668929 RMSE: 0.85281545\n",
      "81 45 0.3863164186477661\n",
      "81 95 0.2606460750102997\n",
      "Validation loss: 0.683737173534575 RMSE: 0.82688403\n",
      "82 40 0.2014729082584381\n",
      "82 90 0.4950768053531647\n",
      "Validation loss: 0.8156064893518176 RMSE: 0.9031093\n",
      "83 35 0.3177126348018646\n",
      "83 85 0.26683899760246277\n",
      "Validation loss: 0.7956322885694957 RMSE: 0.89198226\n",
      "84 30 0.35872918367385864\n",
      "84 80 0.30219408869743347\n",
      "Validation loss: 0.7621861054783776 RMSE: 0.8730327\n",
      "85 25 0.2903231382369995\n",
      "85 75 0.4526926875114441\n",
      "Validation loss: 0.697951128369286 RMSE: 0.8354347\n",
      "86 20 0.286761611700058\n",
      "86 70 0.3392030894756317\n",
      "Validation loss: 0.7990686067513058 RMSE: 0.8939064\n",
      "87 15 0.44383206963539124\n",
      "87 65 0.3379150629043579\n",
      "Validation loss: 0.6534918061324528 RMSE: 0.8083884\n",
      "88 10 0.30502891540527344\n",
      "88 60 0.24792906641960144\n",
      "Validation loss: 0.8355416570390973 RMSE: 0.91407967\n",
      "89 5 0.32450008392333984\n",
      "89 55 0.43486422300338745\n",
      "Validation loss: 0.7034910840647561 RMSE: 0.83874375\n",
      "90 0 0.4980764091014862\n",
      "90 50 0.2784656286239624\n",
      "90 100 0.22594305872917175\n",
      "Validation loss: 0.7360734814689273 RMSE: 0.85794723\n",
      "91 45 0.2763964831829071\n",
      "91 95 0.43935245275497437\n",
      "Validation loss: 0.841044419152396 RMSE: 0.91708475\n",
      "92 40 0.30181416869163513\n",
      "92 90 0.2848127484321594\n",
      "Validation loss: 1.0107044265383767 RMSE: 1.005338\n",
      "93 35 0.1471141278743744\n",
      "93 85 0.41462936997413635\n",
      "Validation loss: 0.756407155025573 RMSE: 0.8697167\n",
      "94 30 0.4405760169029236\n",
      "94 80 0.3085359036922455\n",
      "Validation loss: 0.72747894014631 RMSE: 0.85292375\n",
      "95 25 0.23266613483428955\n",
      "95 75 0.36018869280815125\n",
      "Validation loss: 0.6632244814009893 RMSE: 0.81438595\n",
      "96 20 0.18240968883037567\n",
      "96 70 0.37631577253341675\n",
      "Validation loss: 0.7616925625574021 RMSE: 0.87275\n",
      "97 15 0.3752810060977936\n",
      "97 65 0.49871671199798584\n",
      "Validation loss: 0.7878473412422907 RMSE: 0.88760763\n",
      "98 10 0.4236387610435486\n",
      "98 60 0.31326353549957275\n",
      "Validation loss: 0.7095183503060114 RMSE: 0.84232914\n",
      "99 5 0.2532426416873932\n",
      "99 55 0.35088542103767395\n",
      "Validation loss: 0.7310172410238357 RMSE: 0.8549955\n",
      "100 0 0.24999156594276428\n",
      "100 50 0.2892283499240875\n",
      "100 100 0.1664188653230667\n",
      "Validation loss: 0.7183012916928246 RMSE: 0.84752655\n",
      "101 45 0.21319861710071564\n",
      "101 95 0.2287043035030365\n",
      "Validation loss: 0.8649360304787046 RMSE: 0.9300193\n",
      "102 40 0.34098517894744873\n",
      "102 90 0.20222941040992737\n",
      "Validation loss: 0.7059971332550049 RMSE: 0.84023637\n",
      "103 35 0.2903345227241516\n",
      "103 85 0.34720370173454285\n",
      "Validation loss: 0.7181686543283008 RMSE: 0.84744835\n",
      "104 30 0.33642739057540894\n",
      "104 80 0.23665881156921387\n",
      "Validation loss: 0.7331717088108971 RMSE: 0.8562545\n",
      "105 25 0.28060072660446167\n",
      "105 75 0.21821394562721252\n",
      "Validation loss: 0.6809707465625945 RMSE: 0.8252095\n",
      "106 20 0.3547790050506592\n",
      "106 70 0.2703363299369812\n",
      "Validation loss: 0.7209207932154338 RMSE: 0.84907055\n",
      "107 15 0.35046979784965515\n",
      "107 65 0.2629263401031494\n",
      "Validation loss: 0.6968166828155518 RMSE: 0.8347555\n",
      "108 10 0.44084736704826355\n",
      "108 60 0.26088815927505493\n",
      "Validation loss: 0.7419751479512169 RMSE: 0.8613798\n",
      "109 5 0.13006098568439484\n",
      "109 55 0.3150256276130676\n",
      "Validation loss: 0.9487977703412374 RMSE: 0.97406256\n",
      "110 0 0.24123695492744446\n",
      "110 50 0.5495111346244812\n",
      "110 100 0.26275134086608887\n",
      "Validation loss: 0.8311553046816871 RMSE: 0.9116772\n",
      "111 45 0.25961098074913025\n",
      "111 95 0.21579870581626892\n",
      "Validation loss: 0.8232585214433216 RMSE: 0.90733594\n",
      "112 40 0.23070399463176727\n",
      "112 90 0.20020906627178192\n",
      "Validation loss: 0.7649928095794859 RMSE: 0.8746387\n",
      "113 35 0.4386095404624939\n",
      "113 85 0.2501264214515686\n",
      "Validation loss: 0.7645653537341527 RMSE: 0.87439424\n",
      "114 30 0.3050282597541809\n",
      "114 80 0.25210273265838623\n",
      "Validation loss: 0.7791879880995978 RMSE: 0.8827163\n",
      "115 25 0.1435089260339737\n",
      "115 75 0.27812787890434265\n",
      "Validation loss: 0.821362871215457 RMSE: 0.90629077\n",
      "116 20 0.26989465951919556\n",
      "116 70 0.3016820549964905\n",
      "Validation loss: 0.8525696354252952 RMSE: 0.923347\n",
      "117 15 0.29637831449508667\n",
      "117 65 0.3550928235054016\n",
      "Validation loss: 0.7516385766012328 RMSE: 0.86697096\n",
      "118 10 0.35685959458351135\n",
      "118 60 0.21147646009922028\n",
      "Validation loss: 0.7288989055724371 RMSE: 0.8537557\n",
      "119 5 0.4249374270439148\n",
      "119 55 0.25568100810050964\n",
      "Validation loss: 0.6953345721676236 RMSE: 0.83386725\n",
      "120 0 0.3023326098918915\n",
      "120 50 0.2693176567554474\n",
      "120 100 0.16322799026966095\n",
      "Validation loss: 0.683367665608724 RMSE: 0.8266605\n",
      "121 45 0.19258442521095276\n",
      "121 95 0.17854224145412445\n",
      "Validation loss: 0.7954271975017729 RMSE: 0.8918672\n",
      "122 40 0.24387724697589874\n",
      "122 90 0.38220202922821045\n",
      "Validation loss: 0.7998033157416753 RMSE: 0.8943172\n",
      "123 35 0.2589280605316162\n",
      "123 85 0.42069271206855774\n",
      "Validation loss: 0.7308009306589762 RMSE: 0.85486895\n",
      "124 30 0.11498285830020905\n",
      "124 80 0.30229702591896057\n",
      "Validation loss: 0.7499333006995065 RMSE: 0.8659869\n",
      "125 25 0.2506391704082489\n",
      "125 75 0.2617354989051819\n",
      "Validation loss: 0.7549205359958467 RMSE: 0.8688617\n",
      "126 20 0.23852238059043884\n",
      "126 70 0.17582042515277863\n",
      "Validation loss: 0.6912863141014463 RMSE: 0.83143634\n",
      "127 15 0.42165541648864746\n",
      "127 65 0.40428826212882996\n",
      "Validation loss: 0.7706254706496284 RMSE: 0.87785274\n",
      "128 10 0.3099847435951233\n",
      "128 60 0.3877878785133362\n",
      "Validation loss: 0.7288038375831786 RMSE: 0.8537001\n",
      "129 5 0.23500747978687286\n",
      "129 55 0.31296506524086\n",
      "Validation loss: 0.6887789783023652 RMSE: 0.8299271\n",
      "130 0 0.19436143338680267\n",
      "130 50 0.18293456733226776\n",
      "130 100 0.31537583470344543\n",
      "Validation loss: 0.6960797928628467 RMSE: 0.834314\n",
      "131 45 0.24670149385929108\n",
      "131 95 0.14132337272167206\n",
      "Validation loss: 0.8212703227996826 RMSE: 0.9062396\n",
      "132 40 0.3247552514076233\n",
      "132 90 0.37881121039390564\n",
      "Validation loss: 0.6916285074892499 RMSE: 0.83164203\n",
      "133 35 0.18353579938411713\n",
      "133 85 0.20208807289600372\n",
      "Validation loss: 0.7537545953478132 RMSE: 0.86819047\n",
      "134 30 0.15464583039283752\n",
      "134 80 0.15557646751403809\n",
      "Validation loss: 0.6580270701930636 RMSE: 0.81118864\n",
      "135 25 0.226162388920784\n",
      "135 75 0.21618038415908813\n",
      "Validation loss: 0.798250443027133 RMSE: 0.89344865\n",
      "136 20 0.34398454427719116\n",
      "136 70 0.17502491176128387\n",
      "Validation loss: 0.789301932425726 RMSE: 0.8884267\n",
      "137 15 0.10258108377456665\n",
      "137 65 0.2636150121688843\n",
      "Validation loss: 0.7263276264781043 RMSE: 0.85224855\n",
      "138 10 0.21357275545597076\n",
      "138 60 0.24009943008422852\n",
      "Validation loss: 0.7089745748610724 RMSE: 0.84200627\n",
      "139 5 0.2558310031890869\n",
      "139 55 0.23043540120124817\n",
      "Validation loss: 0.7177064979360217 RMSE: 0.84717554\n",
      "140 0 0.278238445520401\n",
      "140 50 0.26221543550491333\n",
      "140 100 0.3423779308795929\n",
      "Validation loss: 0.7454236226422446 RMSE: 0.8633792\n",
      "141 45 0.23957431316375732\n",
      "141 95 0.12999793887138367\n",
      "Validation loss: 0.76810316046079 RMSE: 0.87641495\n",
      "142 40 0.3700312376022339\n",
      "142 90 0.1837998330593109\n",
      "Validation loss: 0.8087633289041973 RMSE: 0.8993127\n",
      "143 35 0.2661294937133789\n",
      "143 85 0.1350959986448288\n",
      "Validation loss: 0.7663653802304041 RMSE: 0.875423\n",
      "144 30 0.20336969196796417\n",
      "144 80 0.23172272741794586\n",
      "Validation loss: 0.7777781091985249 RMSE: 0.88191724\n",
      "145 25 0.16671298444271088\n",
      "145 75 0.27422481775283813\n",
      "Validation loss: 0.8711352399417333 RMSE: 0.9333462\n",
      "146 20 0.1901644766330719\n",
      "146 70 0.2801637351512909\n",
      "Validation loss: 0.7128034773327055 RMSE: 0.8442769\n",
      "147 15 0.2805081307888031\n",
      "147 65 0.21822501718997955\n",
      "Validation loss: 0.746788011278425 RMSE: 0.86416894\n",
      "148 10 0.2155330777168274\n",
      "148 60 0.20865626633167267\n",
      "Validation loss: 0.722390284708568 RMSE: 0.8499355\n",
      "149 5 0.13662052154541016\n",
      "149 55 0.21420696377754211\n",
      "Validation loss: 0.7529182348932538 RMSE: 0.86770856\n",
      "150 0 0.2854723632335663\n",
      "150 50 0.23244830965995789\n",
      "150 100 0.24497506022453308\n",
      "Validation loss: 0.7586809680575416 RMSE: 0.87102294\n",
      "151 45 0.18289528787136078\n",
      "151 95 0.19733403623104095\n",
      "Validation loss: 0.7142127669992901 RMSE: 0.84511113\n",
      "152 40 0.31227555871009827\n",
      "152 90 0.27745890617370605\n",
      "Validation loss: 0.8350079286666143 RMSE: 0.91378766\n",
      "153 35 0.49032077193260193\n",
      "153 85 0.19436544179916382\n",
      "Validation loss: 0.7632266680399576 RMSE: 0.87362844\n",
      "154 30 0.2145959436893463\n",
      "154 80 0.2386663258075714\n",
      "Validation loss: 0.7222250688643682 RMSE: 0.84983826\n",
      "155 25 0.40210023522377014\n",
      "155 75 0.212477907538414\n",
      "Validation loss: 0.7784759635017031 RMSE: 0.88231283\n",
      "156 20 0.22030487656593323\n",
      "156 70 0.22232136130332947\n",
      "Validation loss: 0.8704410669349488 RMSE: 0.93297434\n",
      "157 15 0.13895367085933685\n",
      "157 65 0.25284335017204285\n",
      "Validation loss: 0.880084897222973 RMSE: 0.93812835\n",
      "158 10 0.2158086597919464\n",
      "158 60 0.11520900577306747\n",
      "Validation loss: 0.9256222656794957 RMSE: 0.96209264\n",
      "159 5 0.1795654296875\n",
      "159 55 0.23044539988040924\n",
      "Validation loss: 0.8351453758421399 RMSE: 0.9138629\n",
      "160 0 0.25132811069488525\n",
      "160 50 0.11474056541919708\n",
      "160 100 0.2634754180908203\n",
      "Validation loss: 0.700721568153018 RMSE: 0.83709115\n",
      "161 45 0.137353777885437\n",
      "161 95 0.33295416831970215\n",
      "Validation loss: 0.7271369428861709 RMSE: 0.85272324\n",
      "162 40 0.19048060476779938\n",
      "162 90 0.19558043777942657\n",
      "Validation loss: 0.7847714287894113 RMSE: 0.88587326\n",
      "163 35 0.21457763016223907\n",
      "163 85 0.17597375810146332\n",
      "Validation loss: 0.772159370921907 RMSE: 0.878726\n",
      "164 30 0.13297942280769348\n",
      "164 80 0.19202956557273865\n",
      "Validation loss: 0.7194147359757196 RMSE: 0.84818316\n",
      "165 25 0.14467602968215942\n",
      "165 75 0.12380805611610413\n",
      "Validation loss: 0.8607811649640401 RMSE: 0.9277829\n",
      "166 20 0.19135059416294098\n",
      "166 70 0.20397423207759857\n",
      "Validation loss: 0.6893718682584309 RMSE: 0.83028424\n",
      "167 15 0.516028642654419\n",
      "167 65 0.1355404257774353\n",
      "Validation loss: 0.7865192243031093 RMSE: 0.8868592\n",
      "168 10 0.19877752661705017\n",
      "168 60 0.1727086752653122\n",
      "Validation loss: 0.8933350733348302 RMSE: 0.9451641\n",
      "169 5 0.14202678203582764\n",
      "169 55 0.21479985117912292\n",
      "Validation loss: 0.6923645973205567 RMSE: 0.8320845\n",
      "170 0 0.20486192405223846\n",
      "170 50 0.12749014794826508\n",
      "170 100 0.14696472883224487\n",
      "Validation loss: 0.8717187899918784 RMSE: 0.9336588\n",
      "171 45 0.2358686774969101\n",
      "171 95 0.14991343021392822\n",
      "Validation loss: 0.8228848190534682 RMSE: 0.90713\n",
      "172 40 0.36319389939308167\n",
      "172 90 0.13907009363174438\n",
      "Validation loss: 0.8796762670789446 RMSE: 0.93791056\n",
      "173 35 0.23575825989246368\n",
      "173 85 0.18079590797424316\n",
      "Validation loss: 0.8615296993936811 RMSE: 0.92818624\n",
      "174 30 0.28477534651756287\n",
      "174 80 0.2151758372783661\n",
      "Validation loss: 0.8121958505539667 RMSE: 0.9012191\n",
      "175 25 0.1345577836036682\n",
      "175 75 0.26333087682724\n",
      "Validation loss: 0.8401667776561919 RMSE: 0.9166061\n",
      "176 20 0.14451222121715546\n",
      "176 70 0.16694824397563934\n",
      "Validation loss: 0.9965847974731809 RMSE: 0.9982909\n",
      "177 15 0.20014342665672302\n",
      "177 65 0.12639574706554413\n",
      "Validation loss: 0.70113464537121 RMSE: 0.83733785\n",
      "178 10 0.17224130034446716\n",
      "178 60 0.23423819243907928\n",
      "Validation loss: 0.8645396840004694 RMSE: 0.92980623\n",
      "179 5 0.12085852026939392\n",
      "179 55 0.08582266420125961\n",
      "Validation loss: 0.9385498512358893 RMSE: 0.96878785\n",
      "180 0 0.17494525015354156\n",
      "180 50 0.20502373576164246\n",
      "180 100 0.2027345597743988\n",
      "Validation loss: 0.9261448518151328 RMSE: 0.9623642\n",
      "181 45 0.11102557927370071\n",
      "181 95 0.1468496173620224\n",
      "Validation loss: 0.8357765932877859 RMSE: 0.9142082\n",
      "182 40 0.1329912543296814\n",
      "182 90 0.2662903964519501\n",
      "Validation loss: 0.7544165849685669 RMSE: 0.8685715\n",
      "183 35 0.18587984144687653\n",
      "183 85 0.27123889327049255\n",
      "Validation loss: 0.8058405932925996 RMSE: 0.89768624\n",
      "184 30 0.20915520191192627\n",
      "184 80 0.27768954634666443\n",
      "Validation loss: 0.7351305382592338 RMSE: 0.85739756\n",
      "185 25 0.2878681719303131\n",
      "185 75 0.17027004063129425\n",
      "Validation loss: 0.7854866288957142 RMSE: 0.88627684\n",
      "186 20 0.17715059220790863\n",
      "186 70 0.1430184245109558\n",
      "Validation loss: 0.8617605107171195 RMSE: 0.9283106\n",
      "187 15 0.16182225942611694\n",
      "187 65 0.32355746626853943\n",
      "Validation loss: 0.82916278782345 RMSE: 0.91058373\n",
      "188 10 0.24625125527381897\n",
      "188 60 0.1537262350320816\n",
      "Validation loss: 0.7631628104618617 RMSE: 0.8735919\n",
      "189 5 0.1046101450920105\n",
      "189 55 0.2254355251789093\n",
      "Validation loss: 1.0112269617262342 RMSE: 1.0055978\n",
      "190 0 0.19049103558063507\n",
      "190 50 0.1799548864364624\n",
      "190 100 0.1398821473121643\n",
      "Validation loss: 0.8287549461637225 RMSE: 0.9103598\n",
      "191 45 0.20703460276126862\n",
      "191 95 0.25820910930633545\n",
      "Validation loss: 0.8749084069615318 RMSE: 0.9353654\n",
      "192 40 0.1893511712551117\n",
      "192 90 0.16167432069778442\n",
      "Validation loss: 0.8783098323004587 RMSE: 0.9371819\n",
      "193 35 0.19187819957733154\n",
      "193 85 0.15381863713264465\n",
      "Validation loss: 0.8608660516284761 RMSE: 0.92782867\n",
      "194 30 0.17488686740398407\n",
      "194 80 0.14966589212417603\n",
      "Validation loss: 0.8483042122352691 RMSE: 0.92103434\n",
      "195 25 0.2248450219631195\n",
      "195 75 0.1493721604347229\n",
      "Validation loss: 0.7948602256320771 RMSE: 0.89154935\n",
      "196 20 0.1254153698682785\n",
      "196 70 0.12649503350257874\n",
      "Validation loss: 0.7239005900564648 RMSE: 0.8508235\n",
      "197 15 0.1767539083957672\n",
      "197 65 0.19172686338424683\n",
      "Validation loss: 0.7896551938284011 RMSE: 0.8886255\n",
      "198 10 0.14722968637943268\n",
      "198 60 0.20558705925941467\n",
      "Validation loss: 0.7863795240720113 RMSE: 0.88678044\n",
      "199 5 0.11418811976909637\n",
      "199 55 0.1945144236087799\n",
      "Validation loss: 0.78967663588978 RMSE: 0.8886375\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.5743650254749116 Test RMSE: 0.7578687\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 780, 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'target': ['exp']}}\n",
      "Running on: cuda:0\n",
      "4199\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/4199\n",
      "Generating scaffold 1000/4199\n",
      "Generating scaffold 2000/4199\n",
      "Generating scaffold 3000/4199\n",
      "Generating scaffold 4000/4199\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 6.978732109069824\n",
      "0 50 1.554866075515747\n",
      "0 100 1.547669768333435\n",
      "Validation loss: 1.8387825125739687 RMSE: 1.3560171\n",
      "1 45 1.3354705572128296\n",
      "1 95 0.9657600522041321\n",
      "Validation loss: 2.4215626285189673 RMSE: 1.5561371\n",
      "2 40 0.5864139795303345\n",
      "2 90 0.6563160419464111\n",
      "Validation loss: 1.6712337153298513 RMSE: 1.2927622\n",
      "3 35 0.9147838354110718\n",
      "3 85 0.9611925482749939\n",
      "Validation loss: 1.2958784182866414 RMSE: 1.1383666\n",
      "4 30 0.5258001089096069\n",
      "4 80 0.7965937256813049\n",
      "Validation loss: 1.3769477270898365 RMSE: 1.1734341\n",
      "5 25 0.5214919447898865\n",
      "5 75 0.5241571664810181\n",
      "Validation loss: 1.7523318983259655 RMSE: 1.3237567\n",
      "6 20 0.5839914083480835\n",
      "6 70 0.5520857572555542\n",
      "Validation loss: 1.0699430715470086 RMSE: 1.0343806\n",
      "7 15 0.8788225054740906\n",
      "7 65 0.6609492897987366\n",
      "Validation loss: 1.7461933862595331 RMSE: 1.3214362\n",
      "8 10 0.698363184928894\n",
      "8 60 0.6864075064659119\n",
      "Validation loss: 1.1624796369246073 RMSE: 1.0781835\n",
      "9 5 1.277816891670227\n",
      "9 55 0.8336033821105957\n",
      "Validation loss: 1.0825225375947498 RMSE: 1.0404434\n",
      "10 0 0.5577072501182556\n",
      "10 50 0.6893602013587952\n",
      "10 100 0.855857253074646\n",
      "Validation loss: 1.0790511199406214 RMSE: 1.0387739\n",
      "11 45 0.4454817473888397\n",
      "11 95 0.893520712852478\n",
      "Validation loss: 1.2366053149813698 RMSE: 1.1120276\n",
      "12 40 0.7089619636535645\n",
      "12 90 0.7228957414627075\n",
      "Validation loss: 1.3949900218418667 RMSE: 1.181097\n",
      "13 35 0.5732923746109009\n",
      "13 85 0.5905399918556213\n",
      "Validation loss: 1.6866814613342285 RMSE: 1.298723\n",
      "14 30 0.679103672504425\n",
      "14 80 0.48330017924308777\n",
      "Validation loss: 0.8557887627964929 RMSE: 0.9250885\n",
      "15 25 0.5390263199806213\n",
      "15 75 1.0805156230926514\n",
      "Validation loss: 0.9857751403536116 RMSE: 0.9928621\n",
      "16 20 0.4681510627269745\n",
      "16 70 0.67904132604599\n",
      "Validation loss: 1.25237892582303 RMSE: 1.1190974\n",
      "17 15 0.8276891708374023\n",
      "17 65 0.5301957726478577\n",
      "Validation loss: 0.8369617745989845 RMSE: 0.9148562\n",
      "18 10 0.379377543926239\n",
      "18 60 0.48994529247283936\n",
      "Validation loss: 0.9012193407331194 RMSE: 0.94932574\n",
      "19 5 0.4341970682144165\n",
      "19 55 0.32390040159225464\n",
      "Validation loss: 1.2076915359922817 RMSE: 1.0989501\n",
      "20 0 0.43478113412857056\n",
      "20 50 0.3259836733341217\n",
      "20 100 0.4547593295574188\n",
      "Validation loss: 0.8630797306696574 RMSE: 0.9290208\n",
      "21 45 0.6348512172698975\n",
      "21 95 0.8757749795913696\n",
      "Validation loss: 1.0075274739946638 RMSE: 1.0037566\n",
      "22 40 0.7186090350151062\n",
      "22 90 0.45823511481285095\n",
      "Validation loss: 0.9049494896616255 RMSE: 0.9512883\n",
      "23 35 0.7199516892433167\n",
      "23 85 0.49123942852020264\n",
      "Validation loss: 1.0654401518049694 RMSE: 1.0322016\n",
      "24 30 0.5396335124969482\n",
      "24 80 0.5429025888442993\n",
      "Validation loss: 1.2794895586513337 RMSE: 1.1311452\n",
      "25 25 0.7245349884033203\n",
      "25 75 0.4728148281574249\n",
      "Validation loss: 1.0478211584545316 RMSE: 1.0236313\n",
      "26 20 0.4791644513607025\n",
      "26 70 0.37513110041618347\n",
      "Validation loss: 0.8302746023450579 RMSE: 0.911194\n",
      "27 15 0.42636579275131226\n",
      "27 65 0.720100462436676\n",
      "Validation loss: 0.8093948761622111 RMSE: 0.89966375\n",
      "28 10 0.3708617389202118\n",
      "28 60 0.5045798420906067\n",
      "Validation loss: 0.7544492108481271 RMSE: 0.86859035\n",
      "29 5 0.47140970826148987\n",
      "29 55 0.4512840509414673\n",
      "Validation loss: 0.7641058853694371 RMSE: 0.87413144\n",
      "30 0 0.3344958424568176\n",
      "30 50 0.6664130687713623\n",
      "30 100 0.5789374709129333\n",
      "Validation loss: 0.6868355370703197 RMSE: 0.82875544\n",
      "31 45 0.6767368912696838\n",
      "31 95 0.32867196202278137\n",
      "Validation loss: 0.8518188624154954 RMSE: 0.9229403\n",
      "32 40 0.3941601514816284\n",
      "32 90 0.6985913515090942\n",
      "Validation loss: 0.8030959359237126 RMSE: 0.8961562\n",
      "33 35 0.49385133385658264\n",
      "33 85 0.8616538047790527\n",
      "Validation loss: 0.7407972994304839 RMSE: 0.86069584\n",
      "34 30 0.35912927985191345\n",
      "34 80 0.5257032513618469\n",
      "Validation loss: 0.8271980836277917 RMSE: 0.9095043\n",
      "35 25 0.3659444749355316\n",
      "35 75 0.41551849246025085\n",
      "Validation loss: 1.0297575019654774 RMSE: 1.0147697\n",
      "36 20 0.3658663034439087\n",
      "36 70 0.608729362487793\n",
      "Validation loss: 0.7917915094466437 RMSE: 0.88982666\n",
      "37 15 0.295235276222229\n",
      "37 65 0.3108081519603729\n",
      "Validation loss: 0.817417489914667 RMSE: 0.9041114\n",
      "38 10 0.5324126482009888\n",
      "38 60 0.5273423194885254\n",
      "Validation loss: 0.6932948776653834 RMSE: 0.8326433\n",
      "39 5 0.36526602506637573\n",
      "39 55 0.6667273044586182\n",
      "Validation loss: 0.736752124059768 RMSE: 0.8583427\n",
      "40 0 0.3177158832550049\n",
      "40 50 0.29454389214515686\n",
      "40 100 0.5251725316047668\n",
      "Validation loss: 0.7942139824231466 RMSE: 0.89118683\n",
      "41 45 0.3604235351085663\n",
      "41 95 0.5468116998672485\n",
      "Validation loss: 0.9007911784308297 RMSE: 0.94910014\n",
      "42 40 0.4857645332813263\n",
      "42 90 0.24252547323703766\n",
      "Validation loss: 0.7399952945255098 RMSE: 0.8602298\n",
      "43 35 0.2827901244163513\n",
      "43 85 0.48456084728240967\n",
      "Validation loss: 0.8254424306608382 RMSE: 0.90853864\n",
      "44 30 0.46340787410736084\n",
      "44 80 0.4762651026248932\n",
      "Validation loss: 0.879315219606672 RMSE: 0.9377181\n",
      "45 25 0.6370697021484375\n",
      "45 75 0.2547604441642761\n",
      "Validation loss: 1.1114290918622698 RMSE: 1.0542433\n",
      "46 20 0.4830623269081116\n",
      "46 70 0.2539484202861786\n",
      "Validation loss: 0.7144090868177868 RMSE: 0.84522724\n",
      "47 15 0.45460930466651917\n",
      "47 65 0.3259476125240326\n",
      "Validation loss: 0.6815407298860096 RMSE: 0.8255548\n",
      "48 10 0.4348193407058716\n",
      "48 60 0.48042118549346924\n",
      "Validation loss: 0.8782509690239316 RMSE: 0.9371505\n",
      "49 5 0.35177427530288696\n",
      "49 55 0.5659337043762207\n",
      "Validation loss: 0.6900797230856759 RMSE: 0.8307104\n",
      "50 0 0.7959167957305908\n",
      "50 50 0.3019041419029236\n",
      "50 100 0.559741199016571\n",
      "Validation loss: 0.7940576672554016 RMSE: 0.89109915\n",
      "51 45 0.548502504825592\n",
      "51 95 0.4316127598285675\n",
      "Validation loss: 0.7926445943968636 RMSE: 0.89030594\n",
      "52 40 0.49835485219955444\n",
      "52 90 0.5335524082183838\n",
      "Validation loss: 0.820437951315017 RMSE: 0.9057803\n",
      "53 35 0.2835223972797394\n",
      "53 85 0.41700223088264465\n",
      "Validation loss: 0.7775416760217576 RMSE: 0.88178325\n",
      "54 30 0.42450353503227234\n",
      "54 80 0.838699460029602\n",
      "Validation loss: 0.7507094874268486 RMSE: 0.86643493\n",
      "55 25 0.2783316671848297\n",
      "55 75 0.3482303023338318\n",
      "Validation loss: 0.6481690741720654 RMSE: 0.8050895\n",
      "56 20 0.18136310577392578\n",
      "56 70 0.308238685131073\n",
      "Validation loss: 0.8315699100494385 RMSE: 0.9119045\n",
      "57 15 0.3104701042175293\n",
      "57 65 0.32827016711235046\n",
      "Validation loss: 0.7579422167369297 RMSE: 0.87059873\n",
      "58 10 0.270281046628952\n",
      "58 60 0.6112293004989624\n",
      "Validation loss: 0.6927753139109839 RMSE: 0.83233124\n",
      "59 5 0.36990517377853394\n",
      "59 55 0.6403814554214478\n",
      "Validation loss: 0.7173280659176055 RMSE: 0.8469522\n",
      "60 0 0.5960363745689392\n",
      "60 50 0.38012996315956116\n",
      "60 100 0.3271992802619934\n",
      "Validation loss: 0.67776299175762 RMSE: 0.82326365\n",
      "61 45 0.471026748418808\n",
      "61 95 0.42379114031791687\n",
      "Validation loss: 0.7489382834661574 RMSE: 0.8654122\n",
      "62 40 0.28282126784324646\n",
      "62 90 0.4784794747829437\n",
      "Validation loss: 0.7456850971494402 RMSE: 0.8635306\n",
      "63 35 0.3330441117286682\n",
      "63 85 0.31987547874450684\n",
      "Validation loss: 0.8674239181336902 RMSE: 0.93135595\n",
      "64 30 0.4134659171104431\n",
      "64 80 0.3434552550315857\n",
      "Validation loss: 0.750900061357589 RMSE: 0.86654496\n",
      "65 25 0.7518501281738281\n",
      "65 75 0.2864435911178589\n",
      "Validation loss: 0.826715087890625 RMSE: 0.90923876\n",
      "66 20 0.3111412823200226\n",
      "66 70 0.5984019041061401\n",
      "Validation loss: 0.722017442612421 RMSE: 0.8497161\n",
      "67 15 0.22699187695980072\n",
      "67 65 0.42365762591362\n",
      "Validation loss: 0.6885138613837106 RMSE: 0.82976735\n",
      "68 10 0.21258008480072021\n",
      "68 60 0.3298080861568451\n",
      "Validation loss: 0.6546088672819592 RMSE: 0.80907905\n",
      "69 5 1.1821162700653076\n",
      "69 55 0.5271947979927063\n",
      "Validation loss: 0.7696968345415025 RMSE: 0.8773237\n",
      "70 0 0.2458098828792572\n",
      "70 50 0.34683215618133545\n",
      "70 100 0.1839040219783783\n",
      "Validation loss: 0.7870139950797671 RMSE: 0.88713807\n",
      "71 45 0.22457389533519745\n",
      "71 95 0.3426693379878998\n",
      "Validation loss: 0.8177926801499866 RMSE: 0.9043189\n",
      "72 40 0.3326931893825531\n",
      "72 90 0.3334086835384369\n",
      "Validation loss: 0.6617701399893988 RMSE: 0.81349254\n",
      "73 35 0.4942706227302551\n",
      "73 85 0.3435531556606293\n",
      "Validation loss: 0.8099607558477493 RMSE: 0.8999782\n",
      "74 30 0.3011980950832367\n",
      "74 80 0.22369495034217834\n",
      "Validation loss: 0.6513887394042243 RMSE: 0.8070865\n",
      "75 25 0.4142857789993286\n",
      "75 75 0.322810560464859\n",
      "Validation loss: 0.8194113089924767 RMSE: 0.9052134\n",
      "76 20 0.36263900995254517\n",
      "76 70 0.4570886492729187\n",
      "Validation loss: 0.6533740645363217 RMSE: 0.8083156\n",
      "77 15 0.2664153277873993\n",
      "77 65 0.3909359574317932\n",
      "Validation loss: 0.6727683771224249 RMSE: 0.8202246\n",
      "78 10 0.42540284991264343\n",
      "78 60 0.2526051700115204\n",
      "Validation loss: 0.705562455597378 RMSE: 0.8399777\n",
      "79 5 0.46449363231658936\n",
      "79 55 0.1873028576374054\n",
      "Validation loss: 0.7323214417412167 RMSE: 0.85575783\n",
      "80 0 0.43423959612846375\n",
      "80 50 0.6102365255355835\n",
      "80 100 0.2518812417984009\n",
      "Validation loss: 0.7743063543524061 RMSE: 0.87994677\n",
      "81 45 0.32259902358055115\n",
      "81 95 0.2818312644958496\n",
      "Validation loss: 0.7957720836003621 RMSE: 0.89206064\n",
      "82 40 0.2422609180212021\n",
      "82 90 0.28392714262008667\n",
      "Validation loss: 0.6057160059611003 RMSE: 0.7782776\n",
      "83 35 0.4412166476249695\n",
      "83 85 0.367519736289978\n",
      "Validation loss: 0.6083969184330531 RMSE: 0.779998\n",
      "84 30 0.34484246373176575\n",
      "84 80 0.3677782714366913\n",
      "Validation loss: 0.6659721669696627 RMSE: 0.81607115\n",
      "85 25 0.30347540974617004\n",
      "85 75 0.39082181453704834\n",
      "Validation loss: 0.7110119181019919 RMSE: 0.8432152\n",
      "86 20 0.24876250326633453\n",
      "86 70 0.3372092843055725\n",
      "Validation loss: 0.6446320505369277 RMSE: 0.8028898\n",
      "87 15 0.3228190541267395\n",
      "87 65 0.5517266988754272\n",
      "Validation loss: 0.6858388026555379 RMSE: 0.82815385\n",
      "88 10 0.21217377483844757\n",
      "88 60 0.3591771721839905\n",
      "Validation loss: 0.6460118575642506 RMSE: 0.80374867\n",
      "89 5 0.2157556414604187\n",
      "89 55 0.22236202657222748\n",
      "Validation loss: 0.7438811472484044 RMSE: 0.8624854\n",
      "90 0 0.33120426535606384\n",
      "90 50 0.2972859740257263\n",
      "90 100 0.5266830325126648\n",
      "Validation loss: 0.6188761293888092 RMSE: 0.78668684\n",
      "91 45 0.31912505626678467\n",
      "91 95 0.5898643732070923\n",
      "Validation loss: 0.6604275487718128 RMSE: 0.8126669\n",
      "92 40 0.42558756470680237\n",
      "92 90 0.2302318811416626\n",
      "Validation loss: 0.6719100509371077 RMSE: 0.8197012\n",
      "93 35 0.2929176688194275\n",
      "93 85 0.2084185630083084\n",
      "Validation loss: 0.750019587789263 RMSE: 0.8660367\n",
      "94 30 0.3372128903865814\n",
      "94 80 0.22102221846580505\n",
      "Validation loss: 0.782383668422699 RMSE: 0.8845246\n",
      "95 25 0.17712616920471191\n",
      "95 75 0.2809580862522125\n",
      "Validation loss: 0.7002844765072778 RMSE: 0.83682996\n",
      "96 20 0.3082335293292999\n",
      "96 70 0.3371376395225525\n",
      "Validation loss: 0.7488342148917062 RMSE: 0.8653521\n",
      "97 15 0.38401228189468384\n",
      "97 65 0.20564457774162292\n",
      "Validation loss: 0.7555203403745379 RMSE: 0.8692067\n",
      "98 10 0.22516849637031555\n",
      "98 60 0.34844666719436646\n",
      "Validation loss: 0.5937867374647231 RMSE: 0.7705756\n",
      "99 5 0.29012569785118103\n",
      "99 55 0.34561148285865784\n",
      "Validation loss: 0.6969637870788574 RMSE: 0.8348436\n",
      "100 0 0.2017206996679306\n",
      "100 50 0.2857086956501007\n",
      "100 100 0.4800889492034912\n",
      "Validation loss: 0.6494083966527666 RMSE: 0.8058588\n",
      "101 45 0.241375133395195\n",
      "101 95 0.22236452996730804\n",
      "Validation loss: 0.820778052579789 RMSE: 0.90596807\n",
      "102 40 0.37751302123069763\n",
      "102 90 0.2064429223537445\n",
      "Validation loss: 0.6702486075106121 RMSE: 0.81868714\n",
      "103 35 0.26047325134277344\n",
      "103 85 0.37827762961387634\n",
      "Validation loss: 0.692790040515718 RMSE: 0.8323401\n",
      "104 30 0.3837296962738037\n",
      "104 80 0.2072041630744934\n",
      "Validation loss: 0.7652644502265112 RMSE: 0.87479395\n",
      "105 25 0.3242984712123871\n",
      "105 75 0.2759641110897064\n",
      "Validation loss: 0.7564014366694859 RMSE: 0.8697134\n",
      "106 20 0.3221951723098755\n",
      "106 70 0.3521629273891449\n",
      "Validation loss: 0.8544317886942909 RMSE: 0.9243548\n",
      "107 15 0.2812238037586212\n",
      "107 65 0.20658117532730103\n",
      "Validation loss: 0.6981543413230351 RMSE: 0.8355563\n",
      "108 10 0.2005520910024643\n",
      "108 60 0.3680255711078644\n",
      "Validation loss: 0.7304451783498128 RMSE: 0.8546608\n",
      "109 5 0.19471168518066406\n",
      "109 55 0.39543652534484863\n",
      "Validation loss: 0.6782625899428413 RMSE: 0.823567\n",
      "110 0 0.21206866204738617\n",
      "110 50 0.32035496830940247\n",
      "110 100 0.17100505530834198\n",
      "Validation loss: 0.9031269720622471 RMSE: 0.95032996\n",
      "111 45 0.30879294872283936\n",
      "111 95 0.6304408311843872\n",
      "Validation loss: 0.717930361202785 RMSE: 0.84730774\n",
      "112 40 0.18209174275398254\n",
      "112 90 0.39866194128990173\n",
      "Validation loss: 0.7067051984014965 RMSE: 0.8406576\n",
      "113 35 0.3706364333629608\n",
      "113 85 0.23465260863304138\n",
      "Validation loss: 0.7008207519849141 RMSE: 0.83715034\n",
      "114 30 0.19116456806659698\n",
      "114 80 0.25073811411857605\n",
      "Validation loss: 0.6693164240746271 RMSE: 0.8181176\n",
      "115 25 0.3894987404346466\n",
      "115 75 0.24066944420337677\n",
      "Validation loss: 0.7146414268584479 RMSE: 0.8453647\n",
      "116 20 0.2075110375881195\n",
      "116 70 0.21349793672561646\n",
      "Validation loss: 0.9235469767025539 RMSE: 0.96101356\n",
      "117 15 0.2476879209280014\n",
      "117 65 0.32322946190834045\n",
      "Validation loss: 0.6862087982041495 RMSE: 0.82837725\n",
      "118 10 0.24263599514961243\n",
      "118 60 0.21491333842277527\n",
      "Validation loss: 0.7316992123921712 RMSE: 0.8553942\n",
      "119 5 0.38012605905532837\n",
      "119 55 0.1321207880973816\n",
      "Validation loss: 0.801814725853148 RMSE: 0.89544106\n",
      "120 0 0.3147987127304077\n",
      "120 50 0.2114698886871338\n",
      "120 100 0.5107875466346741\n",
      "Validation loss: 0.8848250252859933 RMSE: 0.9406514\n",
      "121 45 0.27538570761680603\n",
      "121 95 0.43280622363090515\n",
      "Validation loss: 0.7615533107802981 RMSE: 0.87267023\n",
      "122 40 0.25275734066963196\n",
      "122 90 0.21492794156074524\n",
      "Validation loss: 0.7814185074397496 RMSE: 0.88397884\n",
      "123 35 0.18710827827453613\n",
      "123 85 0.3498375117778778\n",
      "Validation loss: 0.9185511747996012 RMSE: 0.9584108\n",
      "124 30 0.23899106681346893\n",
      "124 80 0.22975656390190125\n",
      "Validation loss: 0.842111695380438 RMSE: 0.9176665\n",
      "125 25 0.20868641138076782\n",
      "125 75 0.2891584038734436\n",
      "Validation loss: 0.9105517648515247 RMSE: 0.9542284\n",
      "126 20 0.2764216959476471\n",
      "126 70 0.21810506284236908\n",
      "Validation loss: 0.862065289134071 RMSE: 0.92847466\n",
      "127 15 0.22362647950649261\n",
      "127 65 0.20999078452587128\n",
      "Validation loss: 0.7207025505247571 RMSE: 0.84894204\n",
      "128 10 0.36476799845695496\n",
      "128 60 0.2032313346862793\n",
      "Validation loss: 0.9175435747419085 RMSE: 0.9578849\n",
      "129 5 0.4005972743034363\n",
      "129 55 0.1804196685552597\n",
      "Validation loss: 0.8619707743326823 RMSE: 0.92842376\n",
      "130 0 0.2043815404176712\n",
      "130 50 0.2656101584434509\n",
      "130 100 0.2452094852924347\n",
      "Validation loss: 0.8376176879519508 RMSE: 0.91521454\n",
      "131 45 0.15341341495513916\n",
      "131 95 0.28282904624938965\n",
      "Validation loss: 0.8120823519570487 RMSE: 0.9011561\n",
      "132 40 0.2582445740699768\n",
      "132 90 0.32972556352615356\n",
      "Validation loss: 0.8324343834604536 RMSE: 0.91237843\n",
      "133 35 0.13591721653938293\n",
      "133 85 0.5247499346733093\n",
      "Validation loss: 0.9016689189842769 RMSE: 0.94956243\n",
      "134 30 0.2711261510848999\n",
      "134 80 0.11853879690170288\n",
      "Validation loss: 0.7974487838290987 RMSE: 0.8929999\n",
      "135 25 0.3438819646835327\n",
      "135 75 0.5026974678039551\n",
      "Validation loss: 1.0308098895209177 RMSE: 1.0152881\n",
      "136 20 0.28282418847084045\n",
      "136 70 0.48406699299812317\n",
      "Validation loss: 0.8385376828057426 RMSE: 0.91571707\n",
      "137 15 0.2843339443206787\n",
      "137 65 0.20715372264385223\n",
      "Validation loss: 0.9221487119084313 RMSE: 0.9602857\n",
      "138 10 0.2887614369392395\n",
      "138 60 0.14832830429077148\n",
      "Validation loss: 0.908004215217772 RMSE: 0.95289254\n",
      "139 5 0.205362007021904\n",
      "139 55 0.21327102184295654\n",
      "Validation loss: 0.7841528915223621 RMSE: 0.88552403\n",
      "140 0 0.31692880392074585\n",
      "140 50 0.26728391647338867\n",
      "140 100 0.2750055491924286\n",
      "Validation loss: 0.6910733381907145 RMSE: 0.8313082\n",
      "141 45 0.15183310210704803\n",
      "141 95 0.4739414155483246\n",
      "Validation loss: 0.7790975116548085 RMSE: 0.882665\n",
      "142 40 0.21554173529148102\n",
      "142 90 0.18211838603019714\n",
      "Validation loss: 0.9243979612986247 RMSE: 0.9614562\n",
      "143 35 0.2111021876335144\n",
      "143 85 0.20316916704177856\n",
      "Validation loss: 0.9233097581636338 RMSE: 0.96089005\n",
      "144 30 0.21764250099658966\n",
      "144 80 0.16480061411857605\n",
      "Validation loss: 0.8541465352333727 RMSE: 0.9242005\n",
      "145 25 0.20642966032028198\n",
      "145 75 0.31661680340766907\n",
      "Validation loss: 0.6725210672333127 RMSE: 0.82007384\n",
      "146 20 0.2026292085647583\n",
      "146 70 0.298342764377594\n",
      "Validation loss: 0.8919583502269927 RMSE: 0.9444355\n",
      "147 15 0.28841301798820496\n",
      "147 65 0.19146828353405\n",
      "Validation loss: 0.7228754577182588 RMSE: 0.85022086\n",
      "148 10 0.2703014016151428\n",
      "148 60 0.18380244076251984\n",
      "Validation loss: 0.8050344137918382 RMSE: 0.89723706\n",
      "149 5 0.18039292097091675\n",
      "149 55 0.17076972126960754\n",
      "Validation loss: 0.9217053727025077 RMSE: 0.96005493\n",
      "150 0 0.23142875730991364\n",
      "150 50 0.2879989743232727\n",
      "150 100 0.24564416706562042\n",
      "Validation loss: 0.9127463022867839 RMSE: 0.9553776\n",
      "151 45 0.16792401671409607\n",
      "151 95 0.18698520958423615\n",
      "Validation loss: 0.8208250267165048 RMSE: 0.90599394\n",
      "152 40 0.14417016506195068\n",
      "152 90 0.1848374754190445\n",
      "Validation loss: 0.6912507477260771 RMSE: 0.8314149\n",
      "153 35 0.16656354069709778\n",
      "153 85 0.15807382762432098\n",
      "Validation loss: 0.7626822082769303 RMSE: 0.8733168\n",
      "154 30 0.27850842475891113\n",
      "154 80 0.2707916498184204\n",
      "Validation loss: 0.7815346740541004 RMSE: 0.88404447\n",
      "155 25 0.10565390437841415\n",
      "155 75 0.27206018567085266\n",
      "Validation loss: 1.0349520819527762 RMSE: 1.0173259\n",
      "156 20 0.19085319340229034\n",
      "156 70 0.41426652669906616\n",
      "Validation loss: 0.9749779610406785 RMSE: 0.9874097\n",
      "157 15 0.09926154464483261\n",
      "157 65 0.21582268178462982\n",
      "Validation loss: 0.7545426831358955 RMSE: 0.86864424\n",
      "158 10 0.284944623708725\n",
      "158 60 0.26004913449287415\n",
      "Validation loss: 0.9470089912414551 RMSE: 0.9731439\n",
      "159 5 0.11615347862243652\n",
      "159 55 0.3381192982196808\n",
      "Validation loss: 1.090147522517613 RMSE: 1.0441012\n",
      "160 0 0.15509754419326782\n",
      "160 50 0.1296669989824295\n",
      "160 100 0.1746257245540619\n",
      "Validation loss: 0.8354656491960798 RMSE: 0.9140381\n",
      "161 45 0.20661446452140808\n",
      "161 95 0.25438249111175537\n",
      "Validation loss: 0.7706744988759359 RMSE: 0.87788075\n",
      "162 40 0.23459726572036743\n",
      "162 90 0.3060228228569031\n",
      "Validation loss: 0.7483165763673328 RMSE: 0.86505294\n",
      "163 35 0.18372732400894165\n",
      "163 85 0.24033866822719574\n",
      "Validation loss: 0.7783411298479352 RMSE: 0.8822364\n",
      "164 30 0.16512326896190643\n",
      "164 80 0.21515244245529175\n",
      "Validation loss: 1.0223530650138855 RMSE: 1.0111147\n",
      "165 25 0.15729723870754242\n",
      "165 75 0.5311288833618164\n",
      "Validation loss: 0.904469186209497 RMSE: 0.95103586\n",
      "166 20 0.3068757653236389\n",
      "166 70 0.20727793872356415\n",
      "Validation loss: 0.6949396292368571 RMSE: 0.8336304\n",
      "167 15 0.18443141877651215\n",
      "167 65 0.15347076952457428\n",
      "Validation loss: 0.8500714523451669 RMSE: 0.9219932\n",
      "168 10 0.2293700873851776\n",
      "168 60 0.17200949788093567\n",
      "Validation loss: 0.9118317195347377 RMSE: 0.95489883\n",
      "169 5 0.1323055624961853\n",
      "169 55 0.3853178322315216\n",
      "Validation loss: 0.9323089684758867 RMSE: 0.9655615\n",
      "170 0 0.14781326055526733\n",
      "170 50 0.28110748529434204\n",
      "170 100 0.15293273329734802\n",
      "Validation loss: 0.9492760067894346 RMSE: 0.97430795\n",
      "171 45 0.16480056941509247\n",
      "171 95 0.15806229412555695\n",
      "Validation loss: 1.088601539248512 RMSE: 1.0433607\n",
      "172 40 0.16102103888988495\n",
      "172 90 0.2194914072751999\n",
      "Validation loss: 1.0641999772616795 RMSE: 1.0316007\n",
      "173 35 0.2648574411869049\n",
      "173 85 0.27913740277290344\n",
      "Validation loss: 1.1571409566061837 RMSE: 1.0757048\n",
      "174 30 0.1574179232120514\n",
      "174 80 0.31107932329177856\n",
      "Validation loss: 1.0104307912644885 RMSE: 1.0052019\n",
      "175 25 0.2274026870727539\n",
      "175 75 0.16252709925174713\n",
      "Validation loss: 0.9419943400791713 RMSE: 0.97056395\n",
      "176 20 0.11283891648054123\n",
      "176 70 0.20765438675880432\n",
      "Validation loss: 0.9335330179759435 RMSE: 0.9661951\n",
      "177 15 0.3380310535430908\n",
      "177 65 0.18054714798927307\n",
      "Validation loss: 1.0123049440838041 RMSE: 1.0061337\n",
      "178 10 0.20031577348709106\n",
      "178 60 0.2826036512851715\n",
      "Validation loss: 0.8444081933725448 RMSE: 0.9189168\n",
      "179 5 0.22379784286022186\n",
      "179 55 0.2708700895309448\n",
      "Validation loss: 1.1062942022369022 RMSE: 1.0518051\n",
      "180 0 0.13892793655395508\n",
      "180 50 0.1560044139623642\n",
      "180 100 0.17808480560779572\n",
      "Validation loss: 1.1348468598865327 RMSE: 1.0652919\n",
      "181 45 0.250066876411438\n",
      "181 95 0.15267552435398102\n",
      "Validation loss: 1.0601100260303133 RMSE: 1.0296165\n",
      "182 40 0.22490642964839935\n",
      "182 90 0.2163839340209961\n",
      "Validation loss: 0.9551969007367179 RMSE: 0.9773417\n",
      "183 35 0.14365005493164062\n",
      "183 85 0.179555281996727\n",
      "Validation loss: 0.9449858015491849 RMSE: 0.97210383\n",
      "184 30 0.1873834729194641\n",
      "184 80 0.17952537536621094\n",
      "Validation loss: 0.8148106126558213 RMSE: 0.9026686\n",
      "185 25 0.15437448024749756\n",
      "185 75 0.14039435982704163\n",
      "Validation loss: 0.8708480903080531 RMSE: 0.9331924\n",
      "186 20 0.09857109189033508\n",
      "186 70 0.18168526887893677\n",
      "Validation loss: 1.1681247677121844 RMSE: 1.0807981\n",
      "187 15 0.3098846971988678\n",
      "187 65 0.19981138408184052\n",
      "Validation loss: 1.0337383562610263 RMSE: 1.0167292\n",
      "188 10 0.18248552083969116\n",
      "188 60 0.2109309434890747\n",
      "Validation loss: 0.9270358131045386 RMSE: 0.96282697\n",
      "189 5 0.16535158455371857\n",
      "189 55 0.1872190237045288\n",
      "Validation loss: 1.142942630676996 RMSE: 1.0690849\n",
      "190 0 0.20934832096099854\n",
      "190 50 0.11491871625185013\n",
      "190 100 0.1860385239124298\n",
      "Validation loss: 0.9313150791894822 RMSE: 0.9650467\n",
      "191 45 0.1368556022644043\n",
      "191 95 0.21572650969028473\n",
      "Validation loss: 1.2094142062323434 RMSE: 1.0997337\n",
      "192 40 0.08078079670667648\n",
      "192 90 0.21094225347042084\n",
      "Validation loss: 0.9758477625392732 RMSE: 0.98785007\n",
      "193 35 0.14209088683128357\n",
      "193 85 0.27429983019828796\n",
      "Validation loss: 0.9645782879420689 RMSE: 0.98212945\n",
      "194 30 0.17998795211315155\n",
      "194 80 0.17204546928405762\n",
      "Validation loss: 0.8834992488225301 RMSE: 0.9399464\n",
      "195 25 0.19658976793289185\n",
      "195 75 0.15370692312717438\n",
      "Validation loss: 0.8352970336164747 RMSE: 0.91394585\n",
      "196 20 0.16076374053955078\n",
      "196 70 0.16921235620975494\n",
      "Validation loss: 0.808593613760812 RMSE: 0.8992183\n",
      "197 15 0.1193598285317421\n",
      "197 65 0.20972250401973724\n",
      "Validation loss: 0.8633572850908552 RMSE: 0.9291702\n",
      "198 10 0.15622049570083618\n",
      "198 60 0.15077053010463715\n",
      "Validation loss: 0.7341096543130421 RMSE: 0.856802\n",
      "199 5 0.11666607856750488\n",
      "199 55 0.16530418395996094\n",
      "Validation loss: 0.9121208486102876 RMSE: 0.9550501\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.5502584832055228 Test RMSE: 0.7417941\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'lipo', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'regression', 'data_path': 'data/lipophilicity/Lipophilicity.csv', 'target': ['exp']}}\n",
      "Running on: cuda:0\n",
      "4199\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/4199\n",
      "Generating scaffold 1000/4199\n",
      "Generating scaffold 2000/4199\n",
      "Generating scaffold 3000/4199\n",
      "Generating scaffold 4000/4199\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 7.914178371429443\n",
      "0 50 1.6977280378341675\n",
      "0 100 1.2883650064468384\n",
      "Validation loss: 1.7594350269862584 RMSE: 1.3264369\n",
      "1 45 1.2717149257659912\n",
      "1 95 1.1162235736846924\n",
      "Validation loss: 1.710676496369498 RMSE: 1.3079283\n",
      "2 40 1.2397677898406982\n",
      "2 90 0.7887941598892212\n",
      "Validation loss: 1.0114617143358504 RMSE: 1.0057145\n",
      "3 35 0.8975317478179932\n",
      "3 85 1.0435336828231812\n",
      "Validation loss: 1.0363665251504808 RMSE: 1.0180209\n",
      "4 30 0.9966097474098206\n",
      "4 80 1.0683317184448242\n",
      "Validation loss: 0.949554815746489 RMSE: 0.974451\n",
      "5 25 0.5040086507797241\n",
      "5 75 0.7607020735740662\n",
      "Validation loss: 0.8641146381696065 RMSE: 0.92957765\n",
      "6 20 1.2122434377670288\n",
      "6 70 0.996122419834137\n",
      "Validation loss: 1.0007060357502529 RMSE: 1.0003529\n",
      "7 15 1.0748695135116577\n",
      "7 65 0.7668465375900269\n",
      "Validation loss: 0.9398944613479433 RMSE: 0.9694815\n",
      "8 10 0.6607581377029419\n",
      "8 60 0.532756507396698\n",
      "Validation loss: 0.9218098396346682 RMSE: 0.9601093\n",
      "9 5 0.5293545722961426\n",
      "9 55 0.6141699552536011\n",
      "Validation loss: 1.0153570273092816 RMSE: 1.0076493\n",
      "10 0 0.48929446935653687\n",
      "10 50 0.7205502986907959\n",
      "10 100 0.8166196346282959\n",
      "Validation loss: 1.149199724765051 RMSE: 1.0720073\n",
      "11 45 0.7727912664413452\n",
      "11 95 0.7185189723968506\n",
      "Validation loss: 0.8439618068081992 RMSE: 0.918674\n",
      "12 40 0.7369561791419983\n",
      "12 90 0.6948344707489014\n",
      "Validation loss: 0.855063681943076 RMSE: 0.9246965\n",
      "13 35 0.5268499255180359\n",
      "13 85 0.8715667724609375\n",
      "Validation loss: 0.8898220153081985 RMSE: 0.94330376\n",
      "14 30 0.5642696619033813\n",
      "14 80 0.7428409457206726\n",
      "Validation loss: 0.8383771419525147 RMSE: 0.9156294\n",
      "15 25 0.5019292831420898\n",
      "15 75 0.7344772219657898\n",
      "Validation loss: 0.9643561840057373 RMSE: 0.9820164\n",
      "16 20 0.5592212080955505\n",
      "16 70 0.517807126045227\n",
      "Validation loss: 0.8870629265194847 RMSE: 0.94184023\n",
      "17 15 0.7202706336975098\n",
      "17 65 0.6658706665039062\n",
      "Validation loss: 1.4012298538571313 RMSE: 1.1837356\n",
      "18 10 0.5431092977523804\n",
      "18 60 0.48670557141304016\n",
      "Validation loss: 0.8946471569083986 RMSE: 0.9458579\n",
      "19 5 0.6078515648841858\n",
      "19 55 0.7018138766288757\n",
      "Validation loss: 1.0721693538484118 RMSE: 1.0354561\n",
      "20 0 0.5210572481155396\n",
      "20 50 0.7133104205131531\n",
      "20 100 0.4313236474990845\n",
      "Validation loss: 0.9478735515049526 RMSE: 0.973588\n",
      "21 45 0.6068731546401978\n",
      "21 95 0.6056955456733704\n",
      "Validation loss: 0.8260874532517932 RMSE: 0.9088935\n",
      "22 40 0.48471617698669434\n",
      "22 90 0.47056475281715393\n",
      "Validation loss: 0.8230222210997626 RMSE: 0.90720576\n",
      "23 35 0.5158861875534058\n",
      "23 85 0.8854199051856995\n",
      "Validation loss: 0.7157622507640293 RMSE: 0.8460273\n",
      "24 30 0.5058361887931824\n",
      "24 80 0.3812442123889923\n",
      "Validation loss: 0.7889672256651379 RMSE: 0.8882383\n",
      "25 25 0.2954111099243164\n",
      "25 75 0.39897897839546204\n",
      "Validation loss: 0.795752568755831 RMSE: 0.8920496\n",
      "26 20 0.5051978826522827\n",
      "26 70 0.5415040850639343\n",
      "Validation loss: 0.6824259553636823 RMSE: 0.82609075\n",
      "27 15 0.5067787170410156\n",
      "27 65 0.7000501155853271\n",
      "Validation loss: 0.6614290646144322 RMSE: 0.8132829\n",
      "28 10 0.5958955883979797\n",
      "28 60 0.30211523175239563\n",
      "Validation loss: 0.712881520816258 RMSE: 0.8443231\n",
      "29 5 0.2139434665441513\n",
      "29 55 0.4252927899360657\n",
      "Validation loss: 0.6822223464647929 RMSE: 0.82596755\n",
      "30 0 0.498421311378479\n",
      "30 50 0.4206496477127075\n",
      "30 100 0.45886945724487305\n",
      "Validation loss: 0.6607805047716413 RMSE: 0.8128841\n",
      "31 45 0.8911334276199341\n",
      "31 95 0.9374014735221863\n",
      "Validation loss: 0.7038422629946754 RMSE: 0.8389531\n",
      "32 40 0.49591463804244995\n",
      "32 90 0.5345731377601624\n",
      "Validation loss: 0.873770538965861 RMSE: 0.934757\n",
      "33 35 0.45173829793930054\n",
      "33 85 0.5236881971359253\n",
      "Validation loss: 0.7244837636039371 RMSE: 0.85116607\n",
      "34 30 0.5514308214187622\n",
      "34 80 0.4305524528026581\n",
      "Validation loss: 0.7437253094854809 RMSE: 0.8623951\n",
      "35 25 0.5019240379333496\n",
      "35 75 0.7859870195388794\n",
      "Validation loss: 0.8549716256913684 RMSE: 0.92464674\n",
      "36 20 0.2876863479614258\n",
      "36 70 0.4793270230293274\n",
      "Validation loss: 0.7885720962569827 RMSE: 0.88801587\n",
      "37 15 0.2596406936645508\n",
      "37 65 0.4557235538959503\n",
      "Validation loss: 0.826668511685871 RMSE: 0.90921307\n",
      "38 10 0.47061848640441895\n",
      "38 60 0.5692158341407776\n",
      "Validation loss: 0.9830639396395002 RMSE: 0.99149585\n",
      "39 5 0.7219813466072083\n",
      "39 55 0.503563642501831\n",
      "Validation loss: 0.69783931743531 RMSE: 0.8353678\n",
      "40 0 0.4506289064884186\n",
      "40 50 0.45804131031036377\n",
      "40 100 0.24498309195041656\n",
      "Validation loss: 0.7682069789795648 RMSE: 0.87647414\n",
      "41 45 0.6050493717193604\n",
      "41 95 0.4197166860103607\n",
      "Validation loss: 0.6233911077181499 RMSE: 0.78955126\n",
      "42 40 0.27450084686279297\n",
      "42 90 0.3941945731639862\n",
      "Validation loss: 0.8561404739107404 RMSE: 0.92527854\n",
      "43 35 0.48074308037757874\n",
      "43 85 0.7265487313270569\n",
      "Validation loss: 0.6591552564076015 RMSE: 0.81188375\n",
      "44 30 0.4756268858909607\n",
      "44 80 0.6855197548866272\n",
      "Validation loss: 0.8623620055970691 RMSE: 0.92863446\n",
      "45 25 0.3762756884098053\n",
      "45 75 0.3069424629211426\n",
      "Validation loss: 0.9266084202698299 RMSE: 0.96260506\n",
      "46 20 0.385096937417984\n",
      "46 70 0.7636202573776245\n",
      "Validation loss: 0.9083353928157262 RMSE: 0.95306635\n",
      "47 15 0.5008647441864014\n",
      "47 65 0.3641338348388672\n",
      "Validation loss: 0.9425768412294842 RMSE: 0.970864\n",
      "48 10 0.2827710807323456\n",
      "48 60 0.6008513569831848\n",
      "Validation loss: 0.8384291262853714 RMSE: 0.91565776\n",
      "49 5 0.38002657890319824\n",
      "49 55 0.37663134932518005\n",
      "Validation loss: 0.975423016434624 RMSE: 0.9876351\n",
      "50 0 0.3262935280799866\n",
      "50 50 0.44740423560142517\n",
      "50 100 0.4809991121292114\n",
      "Validation loss: 0.7504457019624255 RMSE: 0.8662827\n",
      "51 45 0.48579806089401245\n",
      "51 95 0.4677150249481201\n",
      "Validation loss: 0.8311981019519624 RMSE: 0.91170067\n",
      "52 40 0.5048689246177673\n",
      "52 90 0.48504188656806946\n",
      "Validation loss: 0.7320583150500343 RMSE: 0.85560405\n",
      "53 35 0.5489551424980164\n",
      "53 85 0.2336491346359253\n",
      "Validation loss: 0.7227555195490519 RMSE: 0.8501503\n",
      "54 30 0.426207035779953\n",
      "54 80 0.5665448307991028\n",
      "Validation loss: 0.777069141751244 RMSE: 0.88151526\n",
      "55 25 0.2415410578250885\n",
      "55 75 0.27127042412757874\n",
      "Validation loss: 0.8502991120020549 RMSE: 0.92211664\n",
      "56 20 0.23847804963588715\n",
      "56 70 0.27079063653945923\n",
      "Validation loss: 0.8638271638325282 RMSE: 0.92942303\n",
      "57 15 0.750138521194458\n",
      "57 65 0.3266160488128662\n",
      "Validation loss: 0.6824781014805749 RMSE: 0.82612234\n",
      "58 10 0.26017963886260986\n",
      "58 60 0.3265325427055359\n",
      "Validation loss: 0.7736723740895589 RMSE: 0.87958646\n",
      "59 5 0.5704132914543152\n",
      "59 55 0.2930123805999756\n",
      "Validation loss: 0.723285266331264 RMSE: 0.85046184\n",
      "60 0 0.2816031575202942\n",
      "60 50 0.3992860019207001\n",
      "60 100 0.2795412838459015\n",
      "Validation loss: 0.9319570291609991 RMSE: 0.9653792\n",
      "61 45 0.5958169102668762\n",
      "61 95 0.3517669439315796\n",
      "Validation loss: 0.6932993891693296 RMSE: 0.832646\n",
      "62 40 0.26253265142440796\n",
      "62 90 0.5140222311019897\n",
      "Validation loss: 0.6863746092433021 RMSE: 0.82847726\n",
      "63 35 0.2841501533985138\n",
      "63 85 0.3693655729293823\n",
      "Validation loss: 0.6870424452282133 RMSE: 0.8288802\n",
      "64 30 0.3881557583808899\n",
      "64 80 0.38158267736434937\n",
      "Validation loss: 0.6418836113952455 RMSE: 0.80117637\n",
      "65 25 0.3052641451358795\n",
      "65 75 0.3143078088760376\n",
      "Validation loss: 0.710595347342037 RMSE: 0.84296817\n",
      "66 20 0.37780851125717163\n",
      "66 70 0.31700292229652405\n",
      "Validation loss: 0.9691247423489888 RMSE: 0.98444134\n",
      "67 15 0.3514433801174164\n",
      "67 65 0.37964197993278503\n",
      "Validation loss: 0.8040936799276442 RMSE: 0.8967127\n",
      "68 10 0.3581051528453827\n",
      "68 60 0.5243812799453735\n",
      "Validation loss: 0.8224614688328334 RMSE: 0.90689653\n",
      "69 5 0.25368085503578186\n",
      "69 55 0.318688303232193\n",
      "Validation loss: 0.7032143394152324 RMSE: 0.83857876\n",
      "70 0 0.31819191575050354\n",
      "70 50 0.5106210112571716\n",
      "70 100 0.4406449794769287\n",
      "Validation loss: 0.7395911852518717 RMSE: 0.8599949\n",
      "71 45 0.21963831782341003\n",
      "71 95 0.3957289755344391\n",
      "Validation loss: 0.9842809461411975 RMSE: 0.99210936\n",
      "72 40 0.23668891191482544\n",
      "72 90 0.41034188866615295\n",
      "Validation loss: 0.7313594301541646 RMSE: 0.8551955\n",
      "73 35 0.22360432147979736\n",
      "73 85 0.35579633712768555\n",
      "Validation loss: 0.8695659188997178 RMSE: 0.9325052\n",
      "74 30 0.31240323185920715\n",
      "74 80 0.42816412448883057\n",
      "Validation loss: 0.7916061656815665 RMSE: 0.8897225\n",
      "75 25 0.4574149549007416\n",
      "75 75 0.16631008684635162\n",
      "Validation loss: 0.7301283118270693 RMSE: 0.8544755\n",
      "76 20 0.41353994607925415\n",
      "76 70 0.3169819116592407\n",
      "Validation loss: 0.6538567389760699 RMSE: 0.8086141\n",
      "77 15 0.38213425874710083\n",
      "77 65 0.31654489040374756\n",
      "Validation loss: 0.6224544267924059 RMSE: 0.7889578\n",
      "78 10 0.6228541731834412\n",
      "78 60 0.27393555641174316\n",
      "Validation loss: 0.7181245837892805 RMSE: 0.84742236\n",
      "79 5 0.2679847180843353\n",
      "79 55 0.3793233335018158\n",
      "Validation loss: 0.8276861781165713 RMSE: 0.9097726\n",
      "80 0 0.37238574028015137\n",
      "80 50 0.2607395350933075\n",
      "80 100 0.3987509310245514\n",
      "Validation loss: 0.6841969893092201 RMSE: 0.827162\n",
      "81 45 0.27050748467445374\n",
      "81 95 0.3318224549293518\n",
      "Validation loss: 0.8125878861972264 RMSE: 0.90143657\n",
      "82 40 0.3497157394886017\n",
      "82 90 0.3536709249019623\n",
      "Validation loss: 0.7690329710642497 RMSE: 0.87694526\n",
      "83 35 0.34664565324783325\n",
      "83 85 0.5162918567657471\n",
      "Validation loss: 0.7446030741646177 RMSE: 0.86290383\n",
      "84 30 0.2499592900276184\n",
      "84 80 0.30362454056739807\n",
      "Validation loss: 0.8346437570594606 RMSE: 0.9135884\n",
      "85 25 0.2164301574230194\n",
      "85 75 0.20985575020313263\n",
      "Validation loss: 0.7817366421222687 RMSE: 0.8841587\n",
      "86 20 0.47603639960289\n",
      "86 70 0.34069228172302246\n",
      "Validation loss: 0.7165641784667969 RMSE: 0.8465011\n",
      "87 15 0.22249719500541687\n",
      "87 65 0.4108312129974365\n",
      "Validation loss: 0.7088034516289121 RMSE: 0.8419047\n",
      "88 10 0.31102514266967773\n",
      "88 60 0.363847941160202\n",
      "Validation loss: 0.7843495048227764 RMSE: 0.8856351\n",
      "89 5 0.2594647705554962\n",
      "89 55 0.3907110095024109\n",
      "Validation loss: 0.7626350079263959 RMSE: 0.87328976\n",
      "90 0 0.18025948107242584\n",
      "90 50 0.43990951776504517\n",
      "90 100 0.33982399106025696\n",
      "Validation loss: 0.6094895964577085 RMSE: 0.7806982\n",
      "91 45 0.4397867023944855\n",
      "91 95 0.25675275921821594\n",
      "Validation loss: 0.7831953996703738 RMSE: 0.8849833\n",
      "92 40 0.16227585077285767\n",
      "92 90 0.25645092129707336\n",
      "Validation loss: 0.7578282378968738 RMSE: 0.8705333\n",
      "93 35 0.2815857529640198\n",
      "93 85 0.16815192997455597\n",
      "Validation loss: 0.6526291370391846 RMSE: 0.80785465\n",
      "94 30 0.33266115188598633\n",
      "94 80 0.18659180402755737\n",
      "Validation loss: 0.7042412360509237 RMSE: 0.8391908\n",
      "95 25 0.26754769682884216\n",
      "95 75 0.3372715413570404\n",
      "Validation loss: 0.9547659340358916 RMSE: 0.9771213\n",
      "96 20 0.24032573401927948\n",
      "96 70 0.29768964648246765\n",
      "Validation loss: 0.8827690760294596 RMSE: 0.9395579\n",
      "97 15 0.18046791851520538\n",
      "97 65 0.474918395280838\n",
      "Validation loss: 0.642066566717057 RMSE: 0.8012906\n",
      "98 10 0.19366785883903503\n",
      "98 60 0.26370924711227417\n",
      "Validation loss: 0.7350413594927107 RMSE: 0.8573455\n",
      "99 5 0.2700587809085846\n",
      "99 55 0.3395124077796936\n",
      "Validation loss: 0.883035458553405 RMSE: 0.93969965\n",
      "100 0 0.2309989631175995\n",
      "100 50 0.15407289564609528\n",
      "100 100 0.33053603768348694\n",
      "Validation loss: 0.6753550336474464 RMSE: 0.8217999\n",
      "101 45 0.25613030791282654\n",
      "101 95 0.21539537608623505\n",
      "Validation loss: 0.679785696665446 RMSE: 0.82449114\n",
      "102 40 0.25928837060928345\n",
      "102 90 0.289409339427948\n",
      "Validation loss: 0.6893998529229846 RMSE: 0.83030105\n",
      "103 35 0.25757214426994324\n",
      "103 85 0.2616174519062042\n",
      "Validation loss: 0.86376656464168 RMSE: 0.92939043\n",
      "104 30 0.22288653254508972\n",
      "104 80 0.36583417654037476\n",
      "Validation loss: 0.6367968468439011 RMSE: 0.79799545\n",
      "105 25 0.24117599427700043\n",
      "105 75 0.26871851086616516\n",
      "Validation loss: 0.8527115992137364 RMSE: 0.9234238\n",
      "106 20 0.36512553691864014\n",
      "106 70 0.23967796564102173\n",
      "Validation loss: 0.7526226770310175 RMSE: 0.8675383\n",
      "107 15 0.16582994163036346\n",
      "107 65 0.4757350981235504\n",
      "Validation loss: 0.843031138465518 RMSE: 0.91816723\n",
      "108 10 0.1578790247440338\n",
      "108 60 0.33020901679992676\n",
      "Validation loss: 0.6921296028863816 RMSE: 0.8319433\n",
      "109 5 0.32736968994140625\n",
      "109 55 0.3192526400089264\n",
      "Validation loss: 0.7915328321002778 RMSE: 0.8896813\n",
      "110 0 0.2694335877895355\n",
      "110 50 0.18730728328227997\n",
      "110 100 0.17675238847732544\n",
      "Validation loss: 0.7253775698798043 RMSE: 0.851691\n",
      "111 45 0.3342374861240387\n",
      "111 95 0.221096009016037\n",
      "Validation loss: 0.8135897395866257 RMSE: 0.9019921\n",
      "112 40 0.20115302503108978\n",
      "112 90 0.22086535394191742\n",
      "Validation loss: 0.8115752345039731 RMSE: 0.90087473\n",
      "113 35 0.23070038855075836\n",
      "113 85 0.23318977653980255\n",
      "Validation loss: 0.8674148184912546 RMSE: 0.93135107\n",
      "114 30 0.5084882378578186\n",
      "114 80 0.1964530050754547\n",
      "Validation loss: 0.7593079260417394 RMSE: 0.8713828\n",
      "115 25 0.29516395926475525\n",
      "115 75 0.27907130122184753\n",
      "Validation loss: 0.7708826367344175 RMSE: 0.8779992\n",
      "116 20 0.30921074748039246\n",
      "116 70 0.2223101407289505\n",
      "Validation loss: 0.6285432946114313 RMSE: 0.7928072\n",
      "117 15 0.33850908279418945\n",
      "117 65 0.25237837433815\n",
      "Validation loss: 0.7886719817206973 RMSE: 0.8880721\n",
      "118 10 0.14556816220283508\n",
      "118 60 0.25013333559036255\n",
      "Validation loss: 0.7897819131612778 RMSE: 0.88869673\n",
      "119 5 0.2444452941417694\n",
      "119 55 0.2527465522289276\n",
      "Validation loss: 0.8196284827731904 RMSE: 0.90533334\n",
      "120 0 0.19425159692764282\n",
      "120 50 0.20759724080562592\n",
      "120 100 0.2609533965587616\n",
      "Validation loss: 0.800229259332021 RMSE: 0.89455533\n",
      "121 45 0.27716144919395447\n",
      "121 95 0.31001800298690796\n",
      "Validation loss: 0.706576893443153 RMSE: 0.84058124\n",
      "122 40 0.2784806489944458\n",
      "122 90 0.16342516243457794\n",
      "Validation loss: 0.6915094937597003 RMSE: 0.83157045\n",
      "123 35 0.13896074891090393\n",
      "123 85 0.5265501737594604\n",
      "Validation loss: 0.7529739351499648 RMSE: 0.86774063\n",
      "124 30 0.17136307060718536\n",
      "124 80 0.21069341897964478\n",
      "Validation loss: 0.7659365949176606 RMSE: 0.87517804\n",
      "125 25 0.22573569416999817\n",
      "125 75 0.25754833221435547\n",
      "Validation loss: 0.625046330690384 RMSE: 0.79059875\n",
      "126 20 0.3334656059741974\n",
      "126 70 0.2377416342496872\n",
      "Validation loss: 0.7910538494586945 RMSE: 0.88941205\n",
      "127 15 0.20790375769138336\n",
      "127 65 0.18972653150558472\n",
      "Validation loss: 0.595685076713562 RMSE: 0.7718064\n",
      "128 10 0.13631440699100494\n",
      "128 60 0.34772026538848877\n",
      "Validation loss: 0.8909206254141672 RMSE: 0.9438859\n",
      "129 5 0.26415368914604187\n",
      "129 55 0.16803757846355438\n",
      "Validation loss: 0.8177060633897781 RMSE: 0.90427107\n",
      "130 0 0.1719091683626175\n",
      "130 50 0.3072575032711029\n",
      "130 100 0.4193410277366638\n",
      "Validation loss: 0.7313788167067936 RMSE: 0.8552069\n",
      "131 45 0.36776459217071533\n",
      "131 95 0.1280563622713089\n",
      "Validation loss: 0.8651219964027405 RMSE: 0.93011934\n",
      "132 40 0.26725783944129944\n",
      "132 90 0.4639601707458496\n",
      "Validation loss: 0.7865879487423669 RMSE: 0.8868979\n",
      "133 35 0.30302438139915466\n",
      "133 85 0.18591831624507904\n",
      "Validation loss: 0.7018449110644204 RMSE: 0.8377619\n",
      "134 30 0.35223478078842163\n",
      "134 80 0.39387479424476624\n",
      "Validation loss: 0.7122599556332543 RMSE: 0.8439549\n",
      "135 25 0.3837590515613556\n",
      "135 75 0.20242094993591309\n",
      "Validation loss: 0.6693842479160854 RMSE: 0.81815904\n",
      "136 20 0.30038636922836304\n",
      "136 70 0.2691870927810669\n",
      "Validation loss: 0.7107859832899911 RMSE: 0.84308124\n",
      "137 15 0.25789502263069153\n",
      "137 65 0.47490131855010986\n",
      "Validation loss: 0.6636376812344505 RMSE: 0.8146396\n",
      "138 10 0.3983969986438751\n",
      "138 60 0.29175376892089844\n",
      "Validation loss: 0.6794132749239604 RMSE: 0.8242653\n",
      "139 5 0.24099932610988617\n",
      "139 55 0.3981914818286896\n",
      "Validation loss: 0.6989578750516687 RMSE: 0.836037\n",
      "140 0 0.18008029460906982\n",
      "140 50 0.2679603099822998\n",
      "140 100 0.3868086040019989\n",
      "Validation loss: 0.8834165641239711 RMSE: 0.9399024\n",
      "141 45 0.29508572816848755\n",
      "141 95 0.3110252618789673\n",
      "Validation loss: 0.7311282214664278 RMSE: 0.85506034\n",
      "142 40 0.21606899797916412\n",
      "142 90 0.15586170554161072\n",
      "Validation loss: 0.6890407624698821 RMSE: 0.8300848\n",
      "143 35 0.08281904458999634\n",
      "143 85 0.2073320895433426\n",
      "Validation loss: 0.7721299154417856 RMSE: 0.8787092\n",
      "144 30 0.3062259256839752\n",
      "144 80 0.1734524816274643\n",
      "Validation loss: 0.6174373734565008 RMSE: 0.78577185\n",
      "145 25 0.19378529489040375\n",
      "145 75 0.2735438644886017\n",
      "Validation loss: 0.6828202622277396 RMSE: 0.8263294\n",
      "146 20 0.20445701479911804\n",
      "146 70 0.2043108344078064\n",
      "Validation loss: 0.8484241428829374 RMSE: 0.9210994\n",
      "147 15 0.32205772399902344\n",
      "147 65 0.3312751054763794\n",
      "Validation loss: 0.7284581672577631 RMSE: 0.8534976\n",
      "148 10 0.2108485847711563\n",
      "148 60 0.13934330642223358\n",
      "Validation loss: 0.7664093835013254 RMSE: 0.87544817\n",
      "149 5 0.32780325412750244\n",
      "149 55 0.3244169056415558\n",
      "Validation loss: 0.6834073259716942 RMSE: 0.82668453\n",
      "150 0 0.307517409324646\n",
      "150 50 0.18175727128982544\n",
      "150 100 0.3072030544281006\n",
      "Validation loss: 0.7175985191549573 RMSE: 0.8471119\n",
      "151 45 0.1995474100112915\n",
      "151 95 0.18904703855514526\n",
      "Validation loss: 0.6540325105190277 RMSE: 0.8087228\n",
      "152 40 0.19162620604038239\n",
      "152 90 0.2563982307910919\n",
      "Validation loss: 0.678243347009023 RMSE: 0.8235553\n",
      "153 35 0.20709331333637238\n",
      "153 85 0.20187225937843323\n",
      "Validation loss: 0.6242872258027394 RMSE: 0.79011846\n",
      "154 30 0.22006186842918396\n",
      "154 80 0.2876816391944885\n",
      "Validation loss: 0.726357783022381 RMSE: 0.8522663\n",
      "155 25 0.30132046341896057\n",
      "155 75 0.202630877494812\n",
      "Validation loss: 0.5924365475064233 RMSE: 0.769699\n",
      "156 20 0.3345983624458313\n",
      "156 70 0.2536119222640991\n",
      "Validation loss: 0.5902756761936915 RMSE: 0.768294\n",
      "157 15 0.21132110059261322\n",
      "157 65 0.3720151484012604\n",
      "Validation loss: 0.6481295120148431 RMSE: 0.805065\n",
      "158 10 0.2488347589969635\n",
      "158 60 0.3238133490085602\n",
      "Validation loss: 0.7258425817603157 RMSE: 0.85196394\n",
      "159 5 0.19578121602535248\n",
      "159 55 0.201637402176857\n",
      "Validation loss: 0.7597119910376412 RMSE: 0.8716146\n",
      "160 0 0.2752002477645874\n",
      "160 50 0.1899944543838501\n",
      "160 100 0.12302574515342712\n",
      "Validation loss: 0.677778205701283 RMSE: 0.8232728\n",
      "161 45 0.17015033960342407\n",
      "161 95 0.1518639326095581\n",
      "Validation loss: 0.6428739519346328 RMSE: 0.80179423\n",
      "162 40 0.23660124838352203\n",
      "162 90 0.14894092082977295\n",
      "Validation loss: 0.6272189526330857 RMSE: 0.7919715\n",
      "163 35 0.12775707244873047\n",
      "163 85 0.3186805844306946\n",
      "Validation loss: 0.742668997106098 RMSE: 0.8617825\n",
      "164 30 0.15899720788002014\n",
      "164 80 0.4759083092212677\n",
      "Validation loss: 0.6756689659186772 RMSE: 0.8219909\n",
      "165 25 0.2176978588104248\n",
      "165 75 0.15804465115070343\n",
      "Validation loss: 0.6734159424191429 RMSE: 0.8206193\n",
      "166 20 0.334375262260437\n",
      "166 70 0.1569139063358307\n",
      "Validation loss: 0.7294026593367259 RMSE: 0.85405076\n",
      "167 15 0.27121251821517944\n",
      "167 65 0.20729193091392517\n",
      "Validation loss: 0.7709276852153596 RMSE: 0.8780249\n",
      "168 10 0.10406708717346191\n",
      "168 60 0.22271406650543213\n",
      "Validation loss: 0.821229088306427 RMSE: 0.9062169\n",
      "169 5 0.2478315681219101\n",
      "169 55 0.13140997290611267\n",
      "Validation loss: 0.7009997032937549 RMSE: 0.8372572\n",
      "170 0 0.2176404446363449\n",
      "170 50 0.2185640037059784\n",
      "170 100 0.3025568723678589\n",
      "Validation loss: 0.6968534923735119 RMSE: 0.83477753\n",
      "171 45 0.15230470895767212\n",
      "171 95 0.21040962636470795\n",
      "Validation loss: 0.673233170452572 RMSE: 0.8205079\n",
      "172 40 0.28141871094703674\n",
      "172 90 0.22656138241291046\n",
      "Validation loss: 0.6135432649226416 RMSE: 0.78329\n",
      "173 35 0.11891119927167892\n",
      "173 85 0.2725381553173065\n",
      "Validation loss: 0.7228938886097499 RMSE: 0.8502317\n",
      "174 30 0.2556081712245941\n",
      "174 80 0.1519118696451187\n",
      "Validation loss: 0.6508572777112325 RMSE: 0.8067573\n",
      "175 25 0.1520017385482788\n",
      "175 75 0.11056550592184067\n",
      "Validation loss: 0.7062765175387973 RMSE: 0.8404026\n",
      "176 20 0.1608319729566574\n",
      "176 70 0.12459055334329605\n",
      "Validation loss: 0.7155283079260871 RMSE: 0.8458891\n",
      "177 15 0.15116356313228607\n",
      "177 65 0.20708432793617249\n",
      "Validation loss: 0.6228175322214763 RMSE: 0.7891879\n",
      "178 10 0.17293545603752136\n",
      "178 60 0.151247039437294\n",
      "Validation loss: 0.6607178239595323 RMSE: 0.81284547\n",
      "179 5 0.09925857186317444\n",
      "179 55 0.14528803527355194\n",
      "Validation loss: 0.7060126323075522 RMSE: 0.84024554\n",
      "180 0 0.1781245768070221\n",
      "180 50 0.10566128045320511\n",
      "180 100 0.14553643763065338\n",
      "Validation loss: 0.7566999702226548 RMSE: 0.869885\n",
      "181 45 0.20094695687294006\n",
      "181 95 0.10783299803733826\n",
      "Validation loss: 0.6753692751839048 RMSE: 0.8218085\n",
      "182 40 0.1860920786857605\n",
      "182 90 0.1668768972158432\n",
      "Validation loss: 0.7950652241706848 RMSE: 0.8916643\n",
      "183 35 0.23336604237556458\n",
      "183 85 0.19364464282989502\n",
      "Validation loss: 0.7088015153294518 RMSE: 0.8419035\n",
      "184 30 0.11011959612369537\n",
      "184 80 0.11895845830440521\n",
      "Validation loss: 0.8467662595567249 RMSE: 0.92019904\n",
      "185 25 0.3986971974372864\n",
      "185 75 0.23562119901180267\n",
      "Validation loss: 0.7925586181027549 RMSE: 0.89025766\n",
      "186 20 0.15143343806266785\n",
      "186 70 0.1543101668357849\n",
      "Validation loss: 0.7279750835327875 RMSE: 0.8532146\n",
      "187 15 0.10914759337902069\n",
      "187 65 0.1750931590795517\n",
      "Validation loss: 0.6809991422153655 RMSE: 0.8252267\n",
      "188 10 0.1460232436656952\n",
      "188 60 0.1228233054280281\n",
      "Validation loss: 0.9022984061922346 RMSE: 0.9498939\n",
      "189 5 0.17635329067707062\n",
      "189 55 0.2614108920097351\n",
      "Validation loss: 0.7515517341948691 RMSE: 0.8669208\n",
      "190 0 0.18324103951454163\n",
      "190 50 0.1834041178226471\n",
      "190 100 0.2837238907814026\n",
      "Validation loss: 0.6751221588679722 RMSE: 0.8216582\n",
      "191 45 0.13268297910690308\n",
      "191 95 0.13623084127902985\n",
      "Validation loss: 0.7763068227540879 RMSE: 0.8810828\n",
      "192 40 0.18491131067276\n",
      "192 90 0.1707874834537506\n",
      "Validation loss: 0.7159235596656799 RMSE: 0.8461227\n",
      "193 35 0.19262093305587769\n",
      "193 85 0.11083032190799713\n",
      "Validation loss: 0.6769933823318709 RMSE: 0.82279605\n",
      "194 30 0.1232706755399704\n",
      "194 80 0.10850732028484344\n",
      "Validation loss: 0.7816997701213473 RMSE: 0.88413787\n",
      "195 25 0.17739087343215942\n",
      "195 75 0.15505282580852509\n",
      "Validation loss: 0.8161732037862142 RMSE: 0.903423\n",
      "196 20 0.252554714679718\n",
      "196 70 0.24124914407730103\n",
      "Validation loss: 0.7867937320754641 RMSE: 0.8870139\n",
      "197 15 0.40606454014778137\n",
      "197 65 0.15648584067821503\n",
      "Validation loss: 0.7505859119551522 RMSE: 0.86636364\n",
      "198 10 0.25570881366729736\n",
      "198 60 0.1263885200023651\n",
      "Validation loss: 0.7407173281624204 RMSE: 0.8606494\n",
      "199 5 0.24135185778141022\n",
      "199 55 0.12589353322982788\n",
      "Validation loss: 0.7011897461754936 RMSE: 0.83737075\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.5991523961226145 Test RMSE: 0.77404934\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qm7', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'regression', 'data_path': 'data/qm7/qm7.csv', 'target': ['u0_atom']}}\n",
      "Running on: cuda:0\n",
      "6833\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/6833\n",
      "Generating scaffold 1000/6833\n",
      "Generating scaffold 2000/6833\n",
      "Generating scaffold 3000/6833\n",
      "Generating scaffold 4000/6833\n",
      "Generating scaffold 5000/6833\n",
      "Generating scaffold 6000/6833\n",
      "About to sort in scaffold sets\n",
      "tensor(-1553.3462) tensor(228.3718) torch.Size([5466, 1])\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.3532326221466064\n",
      "0 50 0.8523173332214355\n",
      "0 100 0.6163207292556763\n",
      "0 150 0.46498745679855347\n",
      "Validation loss: 0.5621937980428774 MAE: 128.38919\n",
      "1 29 0.5069011449813843\n",
      "1 79 0.5567235350608826\n",
      "1 129 0.6018566489219666\n",
      "Validation loss: 0.6081059550681309 MAE: 138.87425\n",
      "2 8 0.605940043926239\n",
      "2 58 0.40243953466415405\n",
      "2 108 0.40056127309799194\n",
      "2 158 0.5317502021789551\n",
      "Validation loss: 0.9056431041126363 MAE: 206.82333\n",
      "3 37 0.5530994534492493\n",
      "3 87 0.5339022874832153\n",
      "3 137 0.6302146315574646\n",
      "Validation loss: 0.5075628060346459 MAE: 115.913025\n",
      "4 16 0.4180828034877777\n",
      "4 66 0.3933361768722534\n",
      "4 116 0.31311044096946716\n",
      "4 166 0.4798606336116791\n",
      "Validation loss: 0.6995584954295242 MAE: 159.75943\n",
      "5 45 0.4669748842716217\n",
      "5 95 0.5585434436798096\n",
      "5 145 0.47833240032196045\n",
      "Validation loss: 0.9131013343208715 MAE: 208.5266\n",
      "6 24 0.6612297296524048\n",
      "6 74 0.5948796272277832\n",
      "6 124 0.5132505297660828\n",
      "Validation loss: 0.7272840738296509 MAE: 166.09116\n",
      "7 3 0.42751240730285645\n",
      "7 53 0.7734931707382202\n",
      "7 103 0.5186682939529419\n",
      "7 153 0.6176007390022278\n",
      "Validation loss: 0.451080774703221 MAE: 103.014114\n",
      "8 32 0.9646396636962891\n",
      "8 82 0.5941281318664551\n",
      "8 132 0.5602866411209106\n",
      "Validation loss: 0.7899726782625879 MAE: 180.40747\n",
      "9 11 0.5387753844261169\n",
      "9 61 0.46653106808662415\n",
      "9 111 0.40532177686691284\n",
      "9 161 0.43242010474205017\n",
      "Validation loss: 0.39037686063532245 MAE: 89.15106\n",
      "10 40 0.6571378111839294\n",
      "10 90 0.5191675424575806\n",
      "10 140 0.5360980033874512\n",
      "Validation loss: 0.4552840126885308 MAE: 103.97401\n",
      "11 19 0.4761859178543091\n",
      "11 69 0.417905330657959\n",
      "11 119 0.5951929688453674\n",
      "11 169 0.5081909894943237\n",
      "Validation loss: 0.5527923264001545 MAE: 126.242165\n",
      "12 48 0.38182348012924194\n",
      "12 98 0.6062157154083252\n",
      "12 148 0.4955483376979828\n",
      "Validation loss: 0.4070656777125353 MAE: 92.96231\n",
      "13 27 0.5298781991004944\n",
      "13 77 0.45321398973464966\n",
      "13 127 0.4372406005859375\n",
      "Validation loss: 0.49489401795013604 MAE: 113.01983\n",
      "14 6 0.5084334015846252\n",
      "14 56 0.3806689381599426\n",
      "14 106 0.471590131521225\n",
      "14 156 0.6921960115432739\n",
      "Validation loss: 0.4508890438149547 MAE: 102.97033\n",
      "15 35 0.46223556995391846\n",
      "15 85 0.3961311876773834\n",
      "15 135 0.4862125515937805\n",
      "Validation loss: 0.6800181865692139 MAE: 155.29697\n",
      "16 14 0.37786170840263367\n",
      "16 64 0.5161440372467041\n",
      "16 114 0.4068538546562195\n",
      "16 164 0.5403372049331665\n",
      "Validation loss: 0.4235622579591316 MAE: 96.72966\n",
      "17 43 0.4362262487411499\n",
      "17 93 0.44134286046028137\n",
      "17 143 0.3688424229621887\n",
      "Validation loss: 0.5702406865114357 MAE: 130.22688\n",
      "18 22 0.4185362756252289\n",
      "18 72 0.5731949806213379\n",
      "18 122 0.562391459941864\n",
      "Validation loss: 0.4301961834667719 MAE: 98.24467\n",
      "19 1 0.46519458293914795\n",
      "19 51 0.3695075809955597\n",
      "19 101 0.3912886679172516\n",
      "19 151 0.3106866478919983\n",
      "Validation loss: 0.3844717406390006 MAE: 87.80249\n",
      "20 30 0.5790600776672363\n",
      "20 80 0.4564116597175598\n",
      "20 130 0.4238578677177429\n",
      "Validation loss: 0.4344835554995732 MAE: 99.22378\n",
      "21 9 0.35927364230155945\n",
      "21 59 0.3990492820739746\n",
      "21 109 0.3232613503932953\n",
      "21 159 0.4860237240791321\n",
      "Validation loss: 0.44984281376788493 MAE: 102.73139\n",
      "22 38 0.5196005702018738\n",
      "22 88 0.35743507742881775\n",
      "22 138 0.4631378948688507\n",
      "Validation loss: 0.5133928332412452 MAE: 117.24442\n",
      "23 17 0.5217118859291077\n",
      "23 67 0.4060949981212616\n",
      "23 117 0.45116859674453735\n",
      "23 167 0.609135627746582\n",
      "Validation loss: 0.4293745700378864 MAE: 98.05703\n",
      "24 46 0.37471479177474976\n",
      "24 96 0.39371293783187866\n",
      "24 146 0.3377543091773987\n",
      "Validation loss: 0.5045589480483741 MAE: 115.22702\n",
      "25 25 0.4781147539615631\n",
      "25 75 0.3534301817417145\n",
      "25 125 0.4219714105129242\n",
      "Validation loss: 0.6311686467706111 MAE: 144.1411\n",
      "26 4 0.571361780166626\n",
      "26 54 0.3113431930541992\n",
      "26 104 0.4574652314186096\n",
      "26 154 0.28653401136398315\n",
      "Validation loss: 0.4506231067124863 MAE: 102.909584\n",
      "27 33 0.5216965675354004\n",
      "27 83 0.5262070894241333\n",
      "27 133 0.3327838182449341\n",
      "Validation loss: 0.45161542000129207 MAE: 103.136215\n",
      "28 12 0.41019338369369507\n",
      "28 62 0.4025285243988037\n",
      "28 112 0.3940247893333435\n",
      "28 162 0.4400235116481781\n",
      "Validation loss: 0.41230657731580456 MAE: 94.15919\n",
      "29 41 0.38482972979545593\n",
      "29 91 0.4004298746585846\n",
      "29 141 0.4789886772632599\n",
      "Validation loss: 0.5870695786866528 MAE: 134.07011\n",
      "30 20 0.5080845952033997\n",
      "30 70 0.25881537795066833\n",
      "30 120 0.30125653743743896\n",
      "30 170 0.4597572684288025\n",
      "Validation loss: 0.5661169970244692 MAE: 129.28514\n",
      "31 49 0.4526054263114929\n",
      "31 99 0.3696765899658203\n",
      "31 149 0.5403497815132141\n",
      "Validation loss: 0.4106511848363263 MAE: 93.78114\n",
      "32 28 0.3961502015590668\n",
      "32 78 0.40766337513923645\n",
      "32 128 0.38721945881843567\n",
      "Validation loss: 0.5086749569017287 MAE: 116.167\n",
      "33 7 0.4331167936325073\n",
      "33 57 0.48689597845077515\n",
      "33 107 0.46543827652931213\n",
      "33 157 0.3080487549304962\n",
      "Validation loss: 0.4297751505472507 MAE: 98.14851\n",
      "34 36 0.35233575105667114\n",
      "34 86 0.4243093430995941\n",
      "34 136 0.556522011756897\n",
      "Validation loss: 0.4936961878461447 MAE: 112.74628\n",
      "35 15 0.5631648302078247\n",
      "35 65 0.508088231086731\n",
      "35 115 0.3801979720592499\n",
      "35 165 0.35797202587127686\n",
      "Validation loss: 0.4641001377886499 MAE: 105.987366\n",
      "36 44 0.27861031889915466\n",
      "36 94 0.5149393081665039\n",
      "36 144 0.38394153118133545\n",
      "Validation loss: 0.5691368973743148 MAE: 129.97481\n",
      "37 23 0.5851631164550781\n",
      "37 73 0.3185648024082184\n",
      "37 123 0.2878139615058899\n",
      "Validation loss: 0.4293212294578552 MAE: 98.04485\n",
      "38 2 0.43426764011383057\n",
      "38 52 0.48696646094322205\n",
      "38 102 0.47486212849617004\n",
      "38 152 0.40869516134262085\n",
      "Validation loss: 0.40857852550975066 MAE: 93.3078\n",
      "39 31 0.35014060139656067\n",
      "39 81 0.5312008857727051\n",
      "39 131 0.3513927459716797\n",
      "Validation loss: 0.544111184209411 MAE: 124.25964\n",
      "40 10 0.44392120838165283\n",
      "40 60 0.4530358612537384\n",
      "40 110 0.30439549684524536\n",
      "40 160 0.2790273129940033\n",
      "Validation loss: 0.48053640336321113 MAE: 109.74095\n",
      "41 39 0.2670740783214569\n",
      "41 89 0.3062375783920288\n",
      "41 139 0.48341724276542664\n",
      "Validation loss: 0.48364105768371046 MAE: 110.44996\n",
      "42 18 0.36295974254608154\n",
      "42 68 0.45979514718055725\n",
      "42 118 0.31428223848342896\n",
      "42 168 0.5185067057609558\n",
      "Validation loss: 0.6678094633838587 MAE: 152.50883\n",
      "43 47 0.38275033235549927\n",
      "43 97 0.37403857707977295\n",
      "43 147 0.2913494110107422\n",
      "Validation loss: 0.5473302606253596 MAE: 124.99477\n",
      "44 26 0.3261602818965912\n",
      "44 76 0.3193134069442749\n",
      "44 126 0.44093868136405945\n",
      "Validation loss: 0.417958172441226 MAE: 95.449844\n",
      "45 5 0.4030802845954895\n",
      "45 55 0.343553751707077\n",
      "45 105 0.345168799161911\n",
      "45 155 0.3855636417865753\n",
      "Validation loss: 0.5703633040712591 MAE: 130.25488\n",
      "46 34 0.36786210536956787\n",
      "46 84 0.3039599359035492\n",
      "46 134 0.3538438081741333\n",
      "Validation loss: 0.5234386134914487 MAE: 119.538605\n",
      "47 13 0.4592798054218292\n",
      "47 63 0.43985092639923096\n",
      "47 113 0.38886508345603943\n",
      "47 163 0.43365615606307983\n",
      "Validation loss: 0.6158125327344526 MAE: 140.6342\n",
      "48 42 0.31447023153305054\n",
      "48 92 0.3116588592529297\n",
      "48 142 0.36261576414108276\n",
      "Validation loss: 0.6254733187413355 MAE: 142.84045\n",
      "49 21 0.2412654608488083\n",
      "49 71 0.34533366560935974\n",
      "49 121 0.41854771971702576\n",
      "Validation loss: 0.5993656794927273 MAE: 136.8782\n",
      "50 0 0.3818572759628296\n",
      "50 50 0.35283163189888\n",
      "50 100 0.29435986280441284\n",
      "50 150 0.38640546798706055\n",
      "Validation loss: 0.6234478682105304 MAE: 142.3779\n",
      "51 29 0.3185754120349884\n",
      "51 79 0.5743311047554016\n",
      "51 129 0.35802292823791504\n",
      "Validation loss: 0.5728386745118258 MAE: 130.82019\n",
      "52 8 0.6013121604919434\n",
      "52 58 0.4826662838459015\n",
      "52 108 0.40412813425064087\n",
      "52 158 0.34429600834846497\n",
      "Validation loss: 0.493807437824227 MAE: 112.771675\n",
      "53 37 0.3036567270755768\n",
      "53 87 0.41107070446014404\n",
      "53 137 0.38271212577819824\n",
      "Validation loss: 0.5816921051482709 MAE: 132.84206\n",
      "54 16 0.3085672855377197\n",
      "54 66 0.4012790322303772\n",
      "54 116 0.530102014541626\n",
      "54 166 0.45610371232032776\n",
      "Validation loss: 0.588804478010936 MAE: 134.46632\n",
      "55 45 0.3359564244747162\n",
      "55 95 0.35595574975013733\n",
      "55 145 0.5963464379310608\n",
      "Validation loss: 0.5618330557443942 MAE: 128.30681\n",
      "56 24 0.49127885699272156\n",
      "56 74 0.3923289477825165\n",
      "56 124 0.5407027006149292\n",
      "Validation loss: 0.500463446678474 MAE: 114.29173\n",
      "57 3 0.3311048746109009\n",
      "57 53 0.4871402978897095\n",
      "57 103 0.4498254954814911\n",
      "57 153 0.3567602336406708\n",
      "Validation loss: 0.5315341440557736 MAE: 121.38739\n",
      "58 32 0.5022820234298706\n",
      "58 82 0.2958220839500427\n",
      "58 132 0.40328848361968994\n",
      "Validation loss: 0.5136974994202106 MAE: 117.31401\n",
      "59 11 0.4092879593372345\n",
      "59 61 0.23812107741832733\n",
      "59 111 0.5438529253005981\n",
      "59 161 0.214711531996727\n",
      "Validation loss: 0.48130167297452514 MAE: 109.91571\n",
      "60 40 0.37585991621017456\n",
      "60 90 0.2958061993122101\n",
      "60 140 0.3249640464782715\n",
      "Validation loss: 0.5147838524559087 MAE: 117.5621\n",
      "61 19 0.4953530728816986\n",
      "61 69 0.29009556770324707\n",
      "61 119 0.40692460536956787\n",
      "61 169 0.5235673189163208\n",
      "Validation loss: 0.4919201689854003 MAE: 112.34069\n",
      "62 48 0.32651621103286743\n",
      "62 98 0.5077645778656006\n",
      "62 148 0.3055932819843292\n",
      "Validation loss: 0.46871916766752275 MAE: 107.04224\n",
      "63 27 0.4530836343765259\n",
      "63 77 0.362741082906723\n",
      "63 127 0.3650960922241211\n",
      "Validation loss: 0.5083803637334477 MAE: 116.09973\n",
      "64 6 0.24342294037342072\n",
      "64 56 0.4450238049030304\n",
      "64 106 0.3225878179073334\n",
      "64 156 0.4365518391132355\n",
      "Validation loss: 0.5926285002663819 MAE: 135.33961\n",
      "65 35 0.4468473494052887\n",
      "65 85 0.4236792027950287\n",
      "65 135 0.38600099086761475\n",
      "Validation loss: 0.6340051987017804 MAE: 144.78888\n",
      "66 14 0.2777106761932373\n",
      "66 64 0.3504287898540497\n",
      "66 114 0.3851388990879059\n",
      "66 164 0.2851429283618927\n",
      "Validation loss: 0.6184900228740179 MAE: 141.24567\n",
      "67 43 0.43716731667518616\n",
      "67 93 0.4028756320476532\n",
      "67 143 0.2341018170118332\n",
      "Validation loss: 0.5686120303750736 MAE: 129.85493\n",
      "68 22 0.24589234590530396\n",
      "68 72 0.31245332956314087\n",
      "68 122 0.2681470513343811\n",
      "Validation loss: 0.5790875020780062 MAE: 132.24725\n",
      "69 1 0.2953241169452667\n",
      "69 51 0.2465338110923767\n",
      "69 101 0.36084890365600586\n",
      "69 151 0.4066401422023773\n",
      "Validation loss: 0.48911381952943855 MAE: 111.69979\n",
      "70 30 0.5591988563537598\n",
      "70 80 0.6017488837242126\n",
      "70 130 0.44024181365966797\n",
      "Validation loss: 0.5666995341317695 MAE: 129.41817\n",
      "71 9 0.41372862458229065\n",
      "71 59 0.35978269577026367\n",
      "71 109 0.3711678683757782\n",
      "71 159 0.5372597575187683\n",
      "Validation loss: 0.5284536679585775 MAE: 120.68389\n",
      "72 38 0.36934494972229004\n",
      "72 88 0.3763495981693268\n",
      "72 138 0.2633291482925415\n",
      "Validation loss: 0.5664434133217349 MAE: 129.3597\n",
      "73 17 0.3860560357570648\n",
      "73 67 0.5871704816818237\n",
      "73 117 0.32466551661491394\n",
      "73 167 0.2943130433559418\n",
      "Validation loss: 0.5828775949994026 MAE: 133.1128\n",
      "74 46 0.32765376567840576\n",
      "74 96 0.30378544330596924\n",
      "74 146 0.31832078099250793\n",
      "Validation loss: 0.577533963828059 MAE: 131.89246\n",
      "75 25 0.36987823247909546\n",
      "75 75 0.2952956557273865\n",
      "75 125 0.3775399327278137\n",
      "Validation loss: 0.5986015197129277 MAE: 136.70369\n",
      "76 4 0.5467169880867004\n",
      "76 54 0.3475755453109741\n",
      "76 104 0.38591447472572327\n",
      "76 154 0.3077709972858429\n",
      "Validation loss: 0.5520797797113831 MAE: 126.07945\n",
      "77 33 0.19425560534000397\n",
      "77 83 0.2556045651435852\n",
      "77 133 0.3296818733215332\n",
      "Validation loss: 0.5784595654024716 MAE: 132.10382\n",
      "78 12 0.3492274880409241\n",
      "78 62 0.31960490345954895\n",
      "78 112 0.34911665320396423\n",
      "78 162 0.6002174019813538\n",
      "Validation loss: 0.5672226893274408 MAE: 129.53764\n",
      "79 41 0.29697346687316895\n",
      "79 91 0.38705652952194214\n",
      "79 141 0.3109024465084076\n",
      "Validation loss: 0.692426101506105 MAE: 158.13057\n",
      "80 20 0.5615461468696594\n",
      "80 70 0.47469204664230347\n",
      "80 120 0.49211883544921875\n",
      "80 170 0.3617936968803406\n",
      "Validation loss: 0.623149428625553 MAE: 142.30974\n",
      "81 49 0.3785444498062134\n",
      "81 99 0.5120682716369629\n",
      "81 149 0.2423974573612213\n",
      "Validation loss: 0.5397634164631715 MAE: 123.26672\n",
      "82 28 0.42708903551101685\n",
      "82 78 0.5160789489746094\n",
      "82 128 0.31955334544181824\n",
      "Validation loss: 0.558197900217179 MAE: 127.47664\n",
      "83 7 0.4574998617172241\n",
      "83 57 0.23412151634693146\n",
      "83 107 0.41362473368644714\n",
      "83 157 0.3015812039375305\n",
      "Validation loss: 0.5916347803428159 MAE: 135.11269\n",
      "84 36 0.2892487347126007\n",
      "84 86 0.2578981816768646\n",
      "84 136 0.5440244078636169\n",
      "Validation loss: 0.5967765405164127 MAE: 136.28691\n",
      "85 15 0.3544376492500305\n",
      "85 65 0.3541182577610016\n",
      "85 115 0.3205021619796753\n",
      "85 165 0.53072589635849\n",
      "Validation loss: 0.6285867945492616 MAE: 143.55148\n",
      "86 44 0.3336739242076874\n",
      "86 94 0.2461167573928833\n",
      "86 144 0.5024301409721375\n",
      "Validation loss: 0.643576273095538 MAE: 146.97466\n",
      "87 23 0.2459723949432373\n",
      "87 73 0.36905592679977417\n",
      "87 123 0.3121463656425476\n",
      "Validation loss: 0.618364197468897 MAE: 141.21693\n",
      "88 2 0.24927295744419098\n",
      "88 52 0.5202505588531494\n",
      "88 102 0.2720221281051636\n",
      "88 152 0.33516019582748413\n",
      "Validation loss: 0.6477211623163949 MAE: 147.92123\n",
      "89 31 0.4283166825771332\n",
      "89 81 0.45235276222229004\n",
      "89 131 0.3273937702178955\n",
      "Validation loss: 0.501243517761342 MAE: 114.46987\n",
      "90 10 0.2928968369960785\n",
      "90 60 0.26138460636138916\n",
      "90 110 0.21443891525268555\n",
      "90 160 0.3225056529045105\n",
      "Validation loss: 0.4801635564419261 MAE: 109.65579\n",
      "91 39 0.34289512038230896\n",
      "91 89 0.37810733914375305\n",
      "91 139 0.4276416003704071\n",
      "Validation loss: 0.5838160654257613 MAE: 133.3271\n",
      "92 18 0.2687537372112274\n",
      "92 68 0.4957258105278015\n",
      "92 118 0.6400658488273621\n",
      "92 168 0.29732412099838257\n",
      "Validation loss: 0.4573517720601712 MAE: 104.44623\n",
      "93 47 0.2356892079114914\n",
      "93 97 0.3858044445514679\n",
      "93 147 0.3810589909553528\n",
      "Validation loss: 0.6596479419379206 MAE: 150.64496\n",
      "94 26 0.3451271057128906\n",
      "94 76 0.3231290578842163\n",
      "94 126 0.27434593439102173\n",
      "Validation loss: 0.6156061462491577 MAE: 140.58707\n",
      "95 5 0.34068939089775085\n",
      "95 55 0.3579765856266022\n",
      "95 105 0.2959508001804352\n",
      "95 155 0.2895107865333557\n",
      "Validation loss: 0.5833214211185076 MAE: 133.21416\n",
      "96 34 0.4111138582229614\n",
      "96 84 0.286815881729126\n",
      "96 134 0.45063677430152893\n",
      "Validation loss: 0.46200515268838893 MAE: 105.508934\n",
      "97 13 0.4244324862957001\n",
      "97 63 0.4521113634109497\n",
      "97 113 0.44170433282852173\n",
      "97 163 0.5029975175857544\n",
      "Validation loss: 0.5694420351619609 MAE: 130.0445\n",
      "98 42 0.44230934977531433\n",
      "98 92 0.3712947368621826\n",
      "98 142 0.2672690749168396\n",
      "Validation loss: 0.5903753948490522 MAE: 134.82509\n",
      "99 21 0.28801560401916504\n",
      "99 71 0.4729653000831604\n",
      "99 121 0.34261709451675415\n",
      "Validation loss: 0.580674593908745 MAE: 132.60968\n",
      "100 0 0.2664066553115845\n",
      "100 50 0.3320767879486084\n",
      "100 100 0.34371626377105713\n",
      "100 150 0.4453744888305664\n",
      "Validation loss: 0.6209998186568768 MAE: 141.81883\n",
      "101 29 0.3061714768409729\n",
      "101 79 0.352352112531662\n",
      "101 129 0.3740050196647644\n",
      "Validation loss: 0.5685900759975813 MAE: 129.84991\n",
      "102 8 0.42375385761260986\n",
      "102 58 0.33127474784851074\n",
      "102 108 0.27131643891334534\n",
      "102 158 0.37564149498939514\n",
      "Validation loss: 0.593042224471332 MAE: 135.43411\n",
      "103 37 0.3791455328464508\n",
      "103 87 0.3493722975254059\n",
      "103 137 0.34684470295906067\n",
      "Validation loss: 0.5844296569015548 MAE: 133.46724\n",
      "104 16 0.3326563537120819\n",
      "104 66 0.3840295672416687\n",
      "104 116 0.42150402069091797\n",
      "104 166 0.44260284304618835\n",
      "Validation loss: 0.4558682556737933 MAE: 104.10743\n",
      "105 45 0.2900102436542511\n",
      "105 95 0.2964426875114441\n",
      "105 145 0.3001987934112549\n",
      "Validation loss: 0.4294818608384383 MAE: 98.08153\n",
      "106 24 0.46154043078422546\n",
      "106 74 0.2831171154975891\n",
      "106 124 0.3886975347995758\n",
      "Validation loss: 0.606535461910984 MAE: 138.51558\n",
      "107 3 0.33781126141548157\n",
      "107 53 0.39472997188568115\n",
      "107 103 0.21915164589881897\n",
      "107 153 0.28345754742622375\n",
      "Validation loss: 0.614837320227372 MAE: 140.4115\n",
      "108 32 0.37334054708480835\n",
      "108 82 0.38558682799339294\n",
      "108 132 0.3306260108947754\n",
      "Validation loss: 0.588864825273815 MAE: 134.4801\n",
      "109 11 0.2838951349258423\n",
      "109 61 0.3442091941833496\n",
      "109 111 0.40556252002716064\n",
      "109 161 0.2962891459465027\n",
      "Validation loss: 0.6137398355885556 MAE: 140.16086\n",
      "110 40 0.4010257124900818\n",
      "110 90 0.34147879481315613\n",
      "110 140 0.2487039715051651\n",
      "Validation loss: 0.4878015692471064 MAE: 111.400116\n",
      "111 19 0.2621251046657562\n",
      "111 69 0.24858464300632477\n",
      "111 119 0.396403431892395\n",
      "111 169 0.3667486906051636\n",
      "Validation loss: 0.476209938351871 MAE: 108.7529\n",
      "112 48 0.24862094223499298\n",
      "112 98 0.29878535866737366\n",
      "112 148 0.2852210998535156\n",
      "Validation loss: 0.5596428377586499 MAE: 127.80663\n",
      "113 27 0.2753221094608307\n",
      "113 77 0.26053598523139954\n",
      "113 127 0.3503984808921814\n",
      "Validation loss: 0.4948425969185188 MAE: 113.00809\n",
      "114 6 0.3245784342288971\n",
      "114 56 0.3313065469264984\n",
      "114 106 0.42593079805374146\n",
      "114 156 0.41944533586502075\n",
      "Validation loss: 0.6141338008537627 MAE: 140.25082\n",
      "115 35 0.4319360852241516\n",
      "115 85 0.2843731641769409\n",
      "115 135 0.3122729957103729\n",
      "Validation loss: 0.6489129707827206 MAE: 148.19342\n",
      "116 14 0.31851673126220703\n",
      "116 64 0.23931072652339935\n",
      "116 114 0.41716378927230835\n",
      "116 164 0.47835442423820496\n",
      "Validation loss: 0.6747916372198808 MAE: 154.10336\n",
      "117 43 0.1711939573287964\n",
      "117 93 0.34386155009269714\n",
      "117 143 0.26896408200263977\n",
      "Validation loss: 0.5856365467372694 MAE: 133.74286\n",
      "118 22 0.34064897894859314\n",
      "118 72 0.4079979360103607\n",
      "118 122 0.3997671604156494\n",
      "Validation loss: 0.6112547872359293 MAE: 139.59334\n",
      "119 1 0.5292747616767883\n",
      "119 51 0.25736722350120544\n",
      "119 101 0.2760542035102844\n",
      "119 151 0.43015745282173157\n",
      "Validation loss: 0.5199555015703391 MAE: 118.74316\n",
      "120 30 0.41055458784103394\n",
      "120 80 0.38199183344841003\n",
      "120 130 0.2800128757953644\n",
      "Validation loss: 0.5670810791484097 MAE: 129.50531\n",
      "121 9 0.3873155415058136\n",
      "121 59 0.39333829283714294\n",
      "121 109 0.47678738832473755\n",
      "121 159 0.46948039531707764\n",
      "Validation loss: 0.5084131882901777 MAE: 116.107216\n",
      "122 38 0.3399777412414551\n",
      "122 88 0.223874032497406\n",
      "122 138 0.3181585967540741\n",
      "Validation loss: 0.5381248018197846 MAE: 122.892525\n",
      "123 17 0.2143837958574295\n",
      "123 67 0.31008461117744446\n",
      "123 117 0.31393519043922424\n",
      "123 167 0.36015158891677856\n",
      "Validation loss: 0.7117349843532719 MAE: 162.54018\n",
      "124 46 0.2935178577899933\n",
      "124 96 0.3598841726779938\n",
      "124 146 0.25454095005989075\n",
      "Validation loss: 0.5187275660665411 MAE: 118.46273\n",
      "125 25 0.2838915288448334\n",
      "125 75 0.33693212270736694\n",
      "125 125 0.3011262118816376\n",
      "Validation loss: 0.6234201199827138 MAE: 142.37157\n",
      "126 4 0.32986798882484436\n",
      "126 54 0.34542861580848694\n",
      "126 104 0.2509145736694336\n",
      "126 154 0.2427198737859726\n",
      "Validation loss: 0.6514941603816741 MAE: 148.78287\n",
      "127 33 0.23686335980892181\n",
      "127 83 0.268248587846756\n",
      "127 133 0.39685195684432983\n",
      "Validation loss: 0.6695396917605261 MAE: 152.90396\n",
      "128 12 0.4562455117702484\n",
      "128 62 0.28236591815948486\n",
      "128 112 0.35221242904663086\n",
      "128 162 0.24173162877559662\n",
      "Validation loss: 0.7623568571101852 MAE: 174.1008\n",
      "129 41 0.2932277321815491\n",
      "129 91 0.40723034739494324\n",
      "129 141 0.2892603576183319\n",
      "Validation loss: 0.5413836709588592 MAE: 123.63674\n",
      "130 20 0.32405033707618713\n",
      "130 70 0.4524560272693634\n",
      "130 120 0.3476751446723938\n",
      "130 170 0.16343756020069122\n",
      "Validation loss: 0.5616390970018175 MAE: 128.26251\n",
      "131 49 0.38876813650131226\n",
      "131 99 0.28129658102989197\n",
      "131 149 0.4725368022918701\n",
      "Validation loss: 0.6510901576594302 MAE: 148.69061\n",
      "132 28 0.6412599086761475\n",
      "132 78 0.4965621829032898\n",
      "132 128 0.4337354302406311\n",
      "Validation loss: 0.5548945731586881 MAE: 126.722244\n",
      "133 7 0.258182168006897\n",
      "133 57 0.4141480028629303\n",
      "133 107 0.42005953192710876\n",
      "133 157 0.4939574599266052\n",
      "Validation loss: 0.7187122117009079 MAE: 164.13358\n",
      "134 36 0.37652239203453064\n",
      "134 86 0.34267014265060425\n",
      "134 136 0.3879022002220154\n",
      "Validation loss: 0.5631170718990571 MAE: 128.60005\n",
      "135 15 0.27499818801879883\n",
      "135 65 0.14596737921237946\n",
      "135 115 0.6489989757537842\n",
      "135 165 0.3019348978996277\n",
      "Validation loss: 0.7145891942475971 MAE: 163.192\n",
      "136 44 0.1597265601158142\n",
      "136 94 0.46149933338165283\n",
      "136 144 0.2441074401140213\n",
      "Validation loss: 0.6741752415372614 MAE: 153.9626\n",
      "137 23 0.14742882549762726\n",
      "137 73 0.38968080282211304\n",
      "137 123 0.34911665320396423\n",
      "Validation loss: 0.6634037745626349 MAE: 151.5027\n",
      "138 2 0.21755686402320862\n",
      "138 52 0.4391857087612152\n",
      "138 102 0.3235197961330414\n",
      "138 152 0.19834241271018982\n",
      "Validation loss: 0.5596681327847709 MAE: 127.81241\n",
      "139 31 0.2763773202896118\n",
      "139 81 0.19912143051624298\n",
      "139 131 0.3935438096523285\n",
      "Validation loss: 0.7363441792147899 MAE: 168.16023\n",
      "140 10 0.31542256474494934\n",
      "140 60 0.3532884418964386\n",
      "140 110 0.19472260773181915\n",
      "140 160 0.38614940643310547\n",
      "Validation loss: 0.780674592096206 MAE: 178.28404\n",
      "141 39 0.32149308919906616\n",
      "141 89 0.3435298204421997\n",
      "141 139 0.32119762897491455\n",
      "Validation loss: 0.6522122924787956 MAE: 148.94688\n",
      "142 18 0.3535855710506439\n",
      "142 68 0.25157877802848816\n",
      "142 118 0.2966166138648987\n",
      "142 168 0.36777263879776\n",
      "Validation loss: 0.5572136877573024 MAE: 127.25188\n",
      "143 47 0.30965766310691833\n",
      "143 97 0.3953704535961151\n",
      "143 147 0.45261648297309875\n",
      "Validation loss: 0.7661848381945962 MAE: 174.97499\n",
      "144 26 0.4537223279476166\n",
      "144 76 0.3494754731655121\n",
      "144 126 0.375841349363327\n",
      "Validation loss: 0.6839765543826142 MAE: 156.20093\n",
      "145 5 0.4134446084499359\n",
      "145 55 0.25026735663414\n",
      "145 105 0.3095828592777252\n",
      "145 155 0.24776922166347504\n",
      "Validation loss: 0.49958787361780804 MAE: 114.09177\n",
      "146 34 0.25693920254707336\n",
      "146 84 0.5163653492927551\n",
      "146 134 0.44286924600601196\n",
      "Validation loss: 0.6203138413485031 MAE: 141.66217\n",
      "147 13 0.3054355978965759\n",
      "147 63 0.31540778279304504\n",
      "147 113 0.21855399012565613\n",
      "147 163 0.1913432776927948\n",
      "Validation loss: 0.6642790039380392 MAE: 151.70258\n",
      "148 42 0.15203362703323364\n",
      "148 92 0.2142934948205948\n",
      "148 142 0.255672812461853\n",
      "Validation loss: 0.5201334569886414 MAE: 118.7838\n",
      "149 21 0.4658244550228119\n",
      "149 71 0.2926362454891205\n",
      "149 121 0.2608600854873657\n",
      "Validation loss: 0.6140577667637875 MAE: 140.23346\n",
      "150 0 0.17658686637878418\n",
      "150 50 0.36864516139030457\n",
      "150 100 0.22189080715179443\n",
      "150 150 0.3946509063243866\n",
      "Validation loss: 0.6409311298041316 MAE: 146.37057\n",
      "151 29 0.2143445611000061\n",
      "151 79 0.3045728802680969\n",
      "151 129 0.2684376537799835\n",
      "Validation loss: 0.6807338511734679 MAE: 155.46039\n",
      "152 8 0.22452743351459503\n",
      "152 58 0.36627548933029175\n",
      "152 108 0.1720469892024994\n",
      "152 158 0.37498924136161804\n",
      "Validation loss: 0.5754986590112162 MAE: 131.42766\n",
      "153 37 0.317604124546051\n",
      "153 87 0.3706769049167633\n",
      "153 137 0.29893046617507935\n",
      "Validation loss: 0.6945166465831779 MAE: 158.608\n",
      "154 16 0.2692883312702179\n",
      "154 66 0.35275715589523315\n",
      "154 116 0.3009452819824219\n",
      "154 166 0.28245809674263\n",
      "Validation loss: 0.6334195152709359 MAE: 144.65514\n",
      "155 45 0.33465784788131714\n",
      "155 95 0.42766156792640686\n",
      "155 145 0.3736398220062256\n",
      "Validation loss: 0.5754005023610522 MAE: 131.40524\n",
      "156 24 0.2261241376399994\n",
      "156 74 0.3903069794178009\n",
      "156 124 0.37449321150779724\n",
      "Validation loss: 0.5809982363243549 MAE: 132.6836\n",
      "157 3 0.34921813011169434\n",
      "157 53 0.3653889298439026\n",
      "157 103 0.2874481976032257\n",
      "157 153 0.3844301402568817\n",
      "Validation loss: 0.5821168933346955 MAE: 132.93907\n",
      "158 32 0.39080968499183655\n",
      "158 82 0.29949522018432617\n",
      "158 132 0.31652331352233887\n",
      "Validation loss: 0.6292065643427665 MAE: 143.69302\n",
      "159 11 0.3025604486465454\n",
      "159 61 0.43915027379989624\n",
      "159 111 0.2971041798591614\n",
      "159 161 0.2230055034160614\n",
      "Validation loss: 0.5895451356095878 MAE: 134.63547\n",
      "160 40 0.20727115869522095\n",
      "160 90 0.37738654017448425\n",
      "160 140 0.20585229992866516\n",
      "Validation loss: 0.7013417559060436 MAE: 160.16667\n",
      "161 19 0.3906913101673126\n",
      "161 69 0.24166668951511383\n",
      "161 119 0.21131476759910583\n",
      "161 169 0.2600261867046356\n",
      "Validation loss: 0.641805482886688 MAE: 146.57025\n",
      "162 48 0.2330145537853241\n",
      "162 98 0.20844115316867828\n",
      "162 148 0.3194860517978668\n",
      "Validation loss: 0.5645361047739174 MAE: 128.92412\n",
      "163 27 0.35471558570861816\n",
      "163 77 0.26682063937187195\n",
      "163 127 0.24015602469444275\n",
      "Validation loss: 0.6617522406996342 MAE: 151.12552\n",
      "164 6 0.27613455057144165\n",
      "164 56 0.45593976974487305\n",
      "164 106 0.3603469133377075\n",
      "164 156 0.2516501545906067\n",
      "Validation loss: 0.6517059248790407 MAE: 148.83124\n",
      "165 35 0.22991161048412323\n",
      "165 85 0.21299958229064941\n",
      "165 135 0.32734552025794983\n",
      "Validation loss: 0.6879545207957776 MAE: 157.10939\n",
      "166 14 0.2796892523765564\n",
      "166 64 0.37842419743537903\n",
      "166 114 0.26425376534461975\n",
      "166 164 0.437303364276886\n",
      "Validation loss: 0.6730262647595322 MAE: 153.7002\n",
      "167 43 0.2899848222732544\n",
      "167 93 0.3663901090621948\n",
      "167 143 0.23550370335578918\n",
      "Validation loss: 0.6282592966542606 MAE: 143.47668\n",
      "168 22 0.42501401901245117\n",
      "168 72 0.2474292516708374\n",
      "168 122 0.5699893832206726\n",
      "Validation loss: 0.6198005378246307 MAE: 141.54495\n",
      "169 1 0.2735753357410431\n",
      "169 51 0.25796425342559814\n",
      "169 101 0.41991835832595825\n",
      "169 151 0.289115846157074\n",
      "Validation loss: 0.6319235615562975 MAE: 144.3135\n",
      "170 30 0.31764331459999084\n",
      "170 80 0.47071558237075806\n",
      "170 130 0.22758318483829498\n",
      "Validation loss: 0.6072826158930684 MAE: 138.6862\n",
      "171 9 0.4752935767173767\n",
      "171 59 0.3804258108139038\n",
      "171 109 0.4354037046432495\n",
      "171 159 0.24891918897628784\n",
      "Validation loss: 0.6083587150127567 MAE: 138.93196\n",
      "172 38 0.25417184829711914\n",
      "172 88 0.23013147711753845\n",
      "172 138 0.3856009244918823\n",
      "Validation loss: 0.6595079334158647 MAE: 150.61299\n",
      "173 17 0.43216070532798767\n",
      "173 67 0.20433126389980316\n",
      "173 117 0.2893449068069458\n",
      "173 167 0.2736164331436157\n",
      "Validation loss: 0.6321502892594588 MAE: 144.3653\n",
      "174 46 0.24474601447582245\n",
      "174 96 0.2790532410144806\n",
      "174 146 0.291120707988739\n",
      "Validation loss: 0.7300333432983934 MAE: 166.71902\n",
      "175 25 0.3578774631023407\n",
      "175 75 0.35556501150131226\n",
      "175 125 0.25007352232933044\n",
      "Validation loss: 0.6043605548247957 MAE: 138.01889\n",
      "176 4 0.22958751022815704\n",
      "176 54 0.48730313777923584\n",
      "176 104 0.19387288391590118\n",
      "176 154 0.22613906860351562\n",
      "Validation loss: 0.6703089301349127 MAE: 153.07964\n",
      "177 33 0.4842306077480316\n",
      "177 83 0.33110663294792175\n",
      "177 133 0.24888703227043152\n",
      "Validation loss: 0.5549763995304442 MAE: 126.740944\n",
      "178 12 0.20478089153766632\n",
      "178 62 0.30888211727142334\n",
      "178 112 0.2794549763202667\n",
      "178 162 0.32244935631752014\n",
      "Validation loss: 0.4714433233640347 MAE: 107.664345\n",
      "179 41 0.27169230580329895\n",
      "179 91 0.28319066762924194\n",
      "179 141 0.3534158170223236\n",
      "Validation loss: 0.711807768595846 MAE: 162.55681\n",
      "180 20 0.2680540084838867\n",
      "180 70 0.47143295407295227\n",
      "180 120 0.24987030029296875\n",
      "180 170 0.24982090294361115\n",
      "Validation loss: 0.6593626131091201 MAE: 150.57982\n",
      "181 49 0.2964590787887573\n",
      "181 99 0.4004766643047333\n",
      "181 149 0.270940899848938\n",
      "Validation loss: 0.7217292761244969 MAE: 164.8226\n",
      "182 28 0.3564733862876892\n",
      "182 78 0.23021478950977325\n",
      "182 128 0.25239574909210205\n",
      "Validation loss: 0.595148089336373 MAE: 135.91504\n",
      "183 7 0.21548064053058624\n",
      "183 57 0.43014955520629883\n",
      "183 107 0.3819273114204407\n",
      "183 157 0.3517077565193176\n",
      "Validation loss: 0.5524661819837247 MAE: 126.16769\n",
      "184 36 0.2146611213684082\n",
      "184 86 0.16891366243362427\n",
      "184 136 0.2626676857471466\n",
      "Validation loss: 0.7518410055260909 MAE: 171.69926\n",
      "185 15 0.3921220302581787\n",
      "185 65 0.4257619082927704\n",
      "185 115 0.19746263325214386\n",
      "185 165 0.19368138909339905\n",
      "Validation loss: 0.5769944612742864 MAE: 131.76926\n",
      "186 44 0.3613983392715454\n",
      "186 94 0.38001859188079834\n",
      "186 144 0.2664160132408142\n",
      "Validation loss: 0.6042713902847111 MAE: 137.99852\n",
      "187 23 0.4370430111885071\n",
      "187 73 0.27145126461982727\n",
      "187 123 0.2570608854293823\n",
      "Validation loss: 0.5902329641476012 MAE: 134.79256\n",
      "188 2 0.25639989972114563\n",
      "188 52 0.28139424324035645\n",
      "188 102 0.26221269369125366\n",
      "188 152 0.2549537420272827\n",
      "Validation loss: 0.5578646844590617 MAE: 127.40055\n",
      "189 31 0.32476451992988586\n",
      "189 81 0.33403143286705017\n",
      "189 131 0.22839169204235077\n",
      "Validation loss: 0.6282529259285732 MAE: 143.47523\n",
      "190 10 0.16328880190849304\n",
      "190 60 0.29441529512405396\n",
      "190 110 0.32753854990005493\n",
      "190 160 0.4021930694580078\n",
      "Validation loss: 0.5901059797632764 MAE: 134.76355\n",
      "191 39 0.2502859830856323\n",
      "191 89 0.35318854451179504\n",
      "191 139 0.2581084668636322\n",
      "Validation loss: 0.6253923923648589 MAE: 142.82198\n",
      "192 18 0.33364614844322205\n",
      "192 68 0.3417673408985138\n",
      "192 118 0.3285450339317322\n",
      "192 168 0.3694554269313812\n",
      "Validation loss: 0.795074591162609 MAE: 181.5726\n",
      "193 47 0.2569708824157715\n",
      "193 97 0.4191100597381592\n",
      "193 147 0.21775934100151062\n",
      "Validation loss: 0.6698437831555194 MAE: 152.9734\n",
      "194 26 0.29565849900245667\n",
      "194 76 0.2045602798461914\n",
      "194 126 0.30751124024391174\n",
      "Validation loss: 0.6507969139612209 MAE: 148.62366\n",
      "195 5 0.3598105311393738\n",
      "195 55 0.2885028123855591\n",
      "195 105 0.28866052627563477\n",
      "195 155 0.307730108499527\n",
      "Validation loss: 0.6479661286922923 MAE: 147.97717\n",
      "196 34 0.2599796950817108\n",
      "196 84 0.4420855939388275\n",
      "196 134 0.1291053295135498\n",
      "Validation loss: 0.716689393882863 MAE: 163.67163\n",
      "197 13 0.22678367793560028\n",
      "197 63 0.26230236887931824\n",
      "197 113 0.32584068179130554\n",
      "197 163 0.30992111563682556\n",
      "Validation loss: 0.5886438220565082 MAE: 134.42964\n",
      "198 42 0.33370405435562134\n",
      "198 92 0.30635151267051697\n",
      "198 142 0.30048713088035583\n",
      "Validation loss: 0.6034283104695772 MAE: 137.80598\n",
      "199 21 0.2230420559644699\n",
      "199 71 0.21879208087921143\n",
      "199 121 0.1987738460302353\n",
      "Validation loss: 0.6826339290853132 MAE: 155.89433\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.3247379552392974 Test MAE: 74.16098\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qm7', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 778, 'task': 'regression', 'data_path': 'data/qm7/qm7.csv', 'target': ['u0_atom']}}\n",
      "Running on: cuda:0\n",
      "6833\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/6833\n",
      "Generating scaffold 1000/6833\n",
      "Generating scaffold 2000/6833\n",
      "Generating scaffold 3000/6833\n",
      "Generating scaffold 4000/6833\n",
      "Generating scaffold 5000/6833\n",
      "Generating scaffold 6000/6833\n",
      "About to sort in scaffold sets\n",
      "tensor(-1553.3462) tensor(228.3718) torch.Size([5466, 1])\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.4388442039489746\n",
      "0 50 0.48353487253189087\n",
      "0 100 0.6156197786331177\n",
      "0 150 0.49485155940055847\n",
      "Validation loss: 0.7215471023704574 MAE: 164.781\n",
      "1 29 0.6893667578697205\n",
      "1 79 0.5132638216018677\n",
      "1 129 0.5829137563705444\n",
      "Validation loss: 0.6874616187915468 MAE: 156.99683\n",
      "2 8 0.4407767057418823\n",
      "2 58 0.4152106046676636\n",
      "2 108 0.5768115520477295\n",
      "2 158 0.48096996545791626\n",
      "Validation loss: 0.5442492714402272 MAE: 124.291176\n",
      "3 37 0.3220823407173157\n",
      "3 87 0.7270335555076599\n",
      "3 137 0.6462990045547485\n",
      "Validation loss: 0.46387398608943875 MAE: 105.935715\n",
      "4 16 0.4802333414554596\n",
      "4 66 0.5554564595222473\n",
      "4 116 0.5015389323234558\n",
      "4 166 0.444907546043396\n",
      "Validation loss: 0.4213442162812105 MAE: 96.22312\n",
      "5 45 0.6357653737068176\n",
      "5 95 0.4616924226284027\n",
      "5 145 0.7983951568603516\n",
      "Validation loss: 0.4768461897010692 MAE: 108.89821\n",
      "6 24 0.4525783956050873\n",
      "6 74 0.5518786311149597\n",
      "6 124 0.40600085258483887\n",
      "Validation loss: 0.39759393219362227 MAE: 90.799225\n",
      "7 3 0.640610933303833\n",
      "7 53 0.4386787414550781\n",
      "7 103 0.6723818182945251\n",
      "7 153 0.6257016658782959\n",
      "Validation loss: 0.42496444921047366 MAE: 97.04988\n",
      "8 32 0.41024354100227356\n",
      "8 82 0.5808379054069519\n",
      "8 132 0.5047748684883118\n",
      "Validation loss: 0.513001372939662 MAE: 117.15504\n",
      "9 11 0.4568995535373688\n",
      "9 61 0.5059794187545776\n",
      "9 111 0.48340627551078796\n",
      "9 161 0.5098942518234253\n",
      "Validation loss: 0.5139924772301613 MAE: 117.38137\n",
      "10 40 0.43326184153556824\n",
      "10 90 0.41105887293815613\n",
      "10 140 0.5446460843086243\n",
      "Validation loss: 0.5035167423605221 MAE: 114.98901\n",
      "11 19 0.5165133476257324\n",
      "11 69 0.5820251107215881\n",
      "11 119 0.5440525412559509\n",
      "11 169 0.46577465534210205\n",
      "Validation loss: 0.6155203992163228 MAE: 140.56749\n",
      "12 48 0.4254266023635864\n",
      "12 98 0.6812220811843872\n",
      "12 148 0.6161279082298279\n",
      "Validation loss: 0.4470517783485658 MAE: 102.094\n",
      "13 27 0.3387441337108612\n",
      "13 77 0.6603623628616333\n",
      "13 127 0.37246012687683105\n",
      "Validation loss: 0.44569399029190776 MAE: 101.78392\n",
      "14 6 0.507975697517395\n",
      "14 56 0.4843026101589203\n",
      "14 106 0.4880989193916321\n",
      "14 156 0.5001154541969299\n",
      "Validation loss: 0.43191443514405636 MAE: 98.63706\n",
      "15 35 0.5159472227096558\n",
      "15 85 0.4568813741207123\n",
      "15 135 0.4168930947780609\n",
      "Validation loss: 0.444594554210964 MAE: 101.53284\n",
      "16 14 0.5878819227218628\n",
      "16 64 0.4404946267604828\n",
      "16 114 0.4784263074398041\n",
      "16 164 0.3769054114818573\n",
      "Validation loss: 0.4383444007028613 MAE: 100.10549\n",
      "17 43 0.4608088433742523\n",
      "17 93 0.4276016056537628\n",
      "17 143 0.5926501750946045\n",
      "Validation loss: 0.5283221459528159 MAE: 120.65388\n",
      "18 22 0.35906216502189636\n",
      "18 72 0.33254432678222656\n",
      "18 122 0.4352838099002838\n",
      "Validation loss: 0.5887477788311696 MAE: 134.45337\n",
      "19 1 0.34724748134613037\n",
      "19 51 0.38246285915374756\n",
      "19 101 0.4982067048549652\n",
      "19 151 0.3430189788341522\n",
      "Validation loss: 0.4486944096827368 MAE: 102.469124\n",
      "20 30 0.3635096251964569\n",
      "20 80 0.4917215406894684\n",
      "20 130 0.5023029446601868\n",
      "Validation loss: 0.45240249480420386 MAE: 103.31595\n",
      "21 9 0.31173253059387207\n",
      "21 59 0.48985323309898376\n",
      "21 109 0.4741309881210327\n",
      "21 159 0.430263489484787\n",
      "Validation loss: 0.43655079010634396 MAE: 99.69587\n",
      "22 38 0.45760005712509155\n",
      "22 88 0.36553454399108887\n",
      "22 138 0.3257685601711273\n",
      "Validation loss: 0.42059160533704254 MAE: 96.05125\n",
      "23 17 0.3750641644001007\n",
      "23 67 0.2742830812931061\n",
      "23 117 0.40314334630966187\n",
      "23 167 0.5259237885475159\n",
      "Validation loss: 0.4165660662260669 MAE: 95.131935\n",
      "24 46 0.3135960102081299\n",
      "24 96 0.37593141198158264\n",
      "24 146 0.4831492602825165\n",
      "Validation loss: 0.41304484550018755 MAE: 94.327774\n",
      "25 25 0.4340837001800537\n",
      "25 75 0.4939030110836029\n",
      "25 125 0.38070711493492126\n",
      "Validation loss: 0.455578629384961 MAE: 104.0413\n",
      "26 4 0.48173797130584717\n",
      "26 54 0.36356058716773987\n",
      "26 104 0.40515756607055664\n",
      "26 154 0.4140942096710205\n",
      "Validation loss: 0.4780446245656376 MAE: 109.1719\n",
      "27 33 0.4302501380443573\n",
      "27 83 0.40332505106925964\n",
      "27 133 0.3238166868686676\n",
      "Validation loss: 0.49946915650228313 MAE: 114.064644\n",
      "28 12 0.37844160199165344\n",
      "28 62 0.31253811717033386\n",
      "28 112 0.5597918629646301\n",
      "28 162 0.3360360264778137\n",
      "Validation loss: 0.4432072085246705 MAE: 101.21601\n",
      "29 41 0.349405437707901\n",
      "29 91 0.43393266201019287\n",
      "29 141 0.44180792570114136\n",
      "Validation loss: 0.45054463894046537 MAE: 102.89168\n",
      "30 20 0.2774406671524048\n",
      "30 70 0.24967727065086365\n",
      "30 120 0.49520280957221985\n",
      "30 170 0.39961355924606323\n",
      "Validation loss: 0.4478103337232132 MAE: 102.267235\n",
      "31 49 0.3545773923397064\n",
      "31 99 0.3278057873249054\n",
      "31 149 0.31966307759284973\n",
      "Validation loss: 0.45199932706983464 MAE: 103.22388\n",
      "32 28 0.7037578225135803\n",
      "32 78 0.36787086725234985\n",
      "32 128 0.505405843257904\n",
      "Validation loss: 0.48767672400725515 MAE: 111.3716\n",
      "33 7 0.3633664846420288\n",
      "33 57 0.4396057426929474\n",
      "33 107 0.3519929349422455\n",
      "33 157 0.4925614893436432\n",
      "Validation loss: 0.459504857397916 MAE: 104.937935\n",
      "34 36 0.2726778984069824\n",
      "34 86 0.2917696237564087\n",
      "34 136 0.3110678195953369\n",
      "Validation loss: 0.45825037900467364 MAE: 104.65145\n",
      "35 15 0.45312821865081787\n",
      "35 65 0.3813187777996063\n",
      "35 115 0.41537389159202576\n",
      "35 165 0.1883556991815567\n",
      "Validation loss: 0.5394738724357203 MAE: 123.2006\n",
      "36 44 0.4266694486141205\n",
      "36 94 0.3274427056312561\n",
      "36 144 0.34838151931762695\n",
      "Validation loss: 0.5141085525702315 MAE: 117.407875\n",
      "37 23 0.4971129298210144\n",
      "37 73 0.4354701042175293\n",
      "37 123 0.39000970125198364\n",
      "Validation loss: 0.4767653011439139 MAE: 108.87973\n",
      "38 2 0.40957149863243103\n",
      "38 52 0.20984449982643127\n",
      "38 102 0.394233375787735\n",
      "38 152 0.47359758615493774\n",
      "Validation loss: 0.5706459151373969 MAE: 130.31943\n",
      "39 31 0.4850641191005707\n",
      "39 81 0.3800707161426544\n",
      "39 131 0.45618101954460144\n",
      "Validation loss: 0.5290763050492047 MAE: 120.826096\n",
      "40 10 0.5699758529663086\n",
      "40 60 0.3832906484603882\n",
      "40 110 0.3672913610935211\n",
      "40 160 0.5524473786354065\n",
      "Validation loss: 0.44462741257851585 MAE: 101.540344\n",
      "41 39 0.46556803584098816\n",
      "41 89 0.4226972460746765\n",
      "41 139 0.39654937386512756\n",
      "Validation loss: 0.4886988708150317 MAE: 111.60503\n",
      "42 18 0.4078867435455322\n",
      "42 68 0.38961824774742126\n",
      "42 118 0.3488405644893646\n",
      "42 168 0.45946329832077026\n",
      "Validation loss: 0.45178511547066313 MAE: 103.17496\n",
      "43 47 0.2522015869617462\n",
      "43 97 0.38421759009361267\n",
      "43 147 0.38882768154144287\n",
      "Validation loss: 0.41378406404751783 MAE: 94.496605\n",
      "44 26 0.4271937310695648\n",
      "44 76 0.4352855086326599\n",
      "44 126 0.45877760648727417\n",
      "Validation loss: 0.43169165180440533 MAE: 98.58619\n",
      "45 5 0.4107094705104828\n",
      "45 55 0.2477109283208847\n",
      "45 105 0.3152950704097748\n",
      "45 155 0.2650076746940613\n",
      "Validation loss: 0.42576829696956436 MAE: 97.23346\n",
      "46 34 0.3174481987953186\n",
      "46 84 0.34992870688438416\n",
      "46 134 0.39549943804740906\n",
      "Validation loss: 0.42840274628142866 MAE: 97.83509\n",
      "47 13 0.46991223096847534\n",
      "47 63 0.4679735600948334\n",
      "47 113 0.49869504570961\n",
      "47 163 0.3333642780780792\n",
      "Validation loss: 0.4540487006742355 MAE: 103.691895\n",
      "48 42 0.45980289578437805\n",
      "48 92 0.34063053131103516\n",
      "48 142 0.3917999863624573\n",
      "Validation loss: 0.5897490532077544 MAE: 134.68204\n",
      "49 21 0.39427271485328674\n",
      "49 71 0.4306350648403168\n",
      "49 121 0.34522202610969543\n",
      "Validation loss: 0.5133110019895766 MAE: 117.22574\n",
      "50 0 0.3743181526660919\n",
      "50 50 0.40798595547676086\n",
      "50 100 0.20041638612747192\n",
      "50 150 0.373871386051178\n",
      "Validation loss: 0.4886243806944953 MAE: 111.58801\n",
      "51 29 0.39190566539764404\n",
      "51 79 0.5008696913719177\n",
      "51 129 0.22425571084022522\n",
      "Validation loss: 0.44095552176759956 MAE: 100.70179\n",
      "52 8 0.29612159729003906\n",
      "52 58 0.43711161613464355\n",
      "52 108 0.5792945027351379\n",
      "52 158 0.3725306987762451\n",
      "Validation loss: 0.44410564885501974 MAE: 101.42119\n",
      "53 37 0.3313046395778656\n",
      "53 87 0.4427584707736969\n",
      "53 137 0.32412925362586975\n",
      "Validation loss: 0.4091978087062724 MAE: 93.44922\n",
      "54 16 0.43574193120002747\n",
      "54 66 0.42105865478515625\n",
      "54 116 0.3617147207260132\n",
      "54 166 0.43991219997406006\n",
      "Validation loss: 0.4885235878459194 MAE: 111.56499\n",
      "55 45 0.5005255341529846\n",
      "55 95 0.39939332008361816\n",
      "55 145 0.3386421799659729\n",
      "Validation loss: 0.41675429804283276 MAE: 95.17493\n",
      "56 24 0.2994288206100464\n",
      "56 74 0.2674673795700073\n",
      "56 124 0.3684716820716858\n",
      "Validation loss: 0.46339048000804167 MAE: 105.8253\n",
      "57 3 0.29022732377052307\n",
      "57 53 0.3291829228401184\n",
      "57 103 0.4001603424549103\n",
      "57 153 0.30953550338745117\n",
      "Validation loss: 0.4026775509990447 MAE: 91.96018\n",
      "58 32 0.28590601682662964\n",
      "58 82 0.3319743573665619\n",
      "58 132 0.371357262134552\n",
      "Validation loss: 0.43826372320191903 MAE: 100.08706\n",
      "59 11 0.43547046184539795\n",
      "59 61 0.29617738723754883\n",
      "59 111 0.3675656318664551\n",
      "59 161 0.3302696943283081\n",
      "Validation loss: 0.4171291202829595 MAE: 95.26051\n",
      "60 40 0.4073064625263214\n",
      "60 90 0.33743029832839966\n",
      "60 140 0.35154837369918823\n",
      "Validation loss: 0.4667901424636618 MAE: 106.601685\n",
      "61 19 0.3683018684387207\n",
      "61 69 0.3742987811565399\n",
      "61 119 0.43462884426116943\n",
      "61 169 0.5637948513031006\n",
      "Validation loss: 0.43298776526200144 MAE: 98.88217\n",
      "62 48 0.32644006609916687\n",
      "62 98 0.5113763213157654\n",
      "62 148 0.25425463914871216\n",
      "Validation loss: 0.49739426060726766 MAE: 113.59081\n",
      "63 27 0.49008744955062866\n",
      "63 77 0.36799222230911255\n",
      "63 127 0.5159462094306946\n",
      "Validation loss: 0.46031056666931913 MAE: 105.12194\n",
      "64 6 0.33032315969467163\n",
      "64 56 0.36230719089508057\n",
      "64 106 0.341985821723938\n",
      "64 156 0.35396119952201843\n",
      "Validation loss: 0.4563843231452139 MAE: 104.225296\n",
      "65 35 0.39638715982437134\n",
      "65 85 0.4821467101573944\n",
      "65 135 0.35667845606803894\n",
      "Validation loss: 0.5297250901049341 MAE: 120.97426\n",
      "66 14 0.36936548352241516\n",
      "66 64 0.3544158637523651\n",
      "66 114 0.37778300046920776\n",
      "66 164 0.48810529708862305\n",
      "Validation loss: 0.4561577005344525 MAE: 104.173546\n",
      "67 43 0.4379921853542328\n",
      "67 93 0.36044082045555115\n",
      "67 143 0.4584314227104187\n",
      "Validation loss: 0.44494179292031893 MAE: 101.61214\n",
      "68 22 0.2628004550933838\n",
      "68 72 0.4649246037006378\n",
      "68 122 0.3315102458000183\n",
      "Validation loss: 0.43848636066704466 MAE: 100.13791\n",
      "69 1 0.18423236906528473\n",
      "69 51 0.44859474897384644\n",
      "69 101 0.2796645760536194\n",
      "69 151 0.2389059215784073\n",
      "Validation loss: 0.4324666422012954 MAE: 98.76316\n",
      "70 30 0.2092183530330658\n",
      "70 80 0.3437076807022095\n",
      "70 130 0.37597280740737915\n",
      "Validation loss: 0.4631212677871972 MAE: 105.76382\n",
      "71 9 0.26629018783569336\n",
      "71 59 0.3693161904811859\n",
      "71 109 0.3020159900188446\n",
      "71 159 0.39066019654273987\n",
      "Validation loss: 0.45201540272138274 MAE: 103.22757\n",
      "72 38 0.30137908458709717\n",
      "72 88 0.25054654479026794\n",
      "72 138 0.2735738158226013\n",
      "Validation loss: 0.5415083671870985 MAE: 123.66523\n",
      "73 17 0.30766093730926514\n",
      "73 67 0.3047187030315399\n",
      "73 117 0.48740673065185547\n",
      "73 167 0.47014182806015015\n",
      "Validation loss: 0.4811385711382704 MAE: 109.87846\n",
      "74 46 0.2401299774646759\n",
      "74 96 0.2717941999435425\n",
      "74 146 0.35856860876083374\n",
      "Validation loss: 0.5356000846589518 MAE: 122.31594\n",
      "75 25 0.2992246150970459\n",
      "75 75 0.31487777829170227\n",
      "75 125 0.3400600850582123\n",
      "Validation loss: 0.4740807773077 MAE: 108.26668\n",
      "76 4 0.4446733295917511\n",
      "76 54 0.3473253548145294\n",
      "76 104 0.43864572048187256\n",
      "76 154 0.2895829677581787\n",
      "Validation loss: 0.4327166812461719 MAE: 98.82027\n",
      "77 33 0.4923795759677887\n",
      "77 83 0.3373149633407593\n",
      "77 133 0.5881223082542419\n",
      "Validation loss: 0.6531083528061359 MAE: 149.15152\n",
      "78 12 0.44591280817985535\n",
      "78 62 0.2718457579612732\n",
      "78 112 0.5703363418579102\n",
      "78 162 0.3741343021392822\n",
      "Validation loss: 0.4341330908195317 MAE: 99.143745\n",
      "79 41 0.413335919380188\n",
      "79 91 0.5211811065673828\n",
      "79 141 0.44303202629089355\n",
      "Validation loss: 0.5640371905432807 MAE: 128.81017\n",
      "80 20 0.43689343333244324\n",
      "80 70 0.5132408738136292\n",
      "80 120 0.37590500712394714\n",
      "80 170 0.26903650164604187\n",
      "Validation loss: 0.49545892637375505 MAE: 113.14883\n",
      "81 49 0.37882503867149353\n",
      "81 99 0.2953144609928131\n",
      "81 149 0.3441779613494873\n",
      "Validation loss: 0.48498119910558063 MAE: 110.756004\n",
      "82 28 0.5088826417922974\n",
      "82 78 0.3576914668083191\n",
      "82 128 0.2443510740995407\n",
      "Validation loss: 0.5239764336954084 MAE: 119.66142\n",
      "83 7 0.2997087836265564\n",
      "83 57 0.18936358392238617\n",
      "83 107 0.4239248037338257\n",
      "83 157 0.29788681864738464\n",
      "Validation loss: 0.6316783532761691 MAE: 144.25752\n",
      "84 36 0.3763399124145508\n",
      "84 86 0.34300124645233154\n",
      "84 136 0.3651978075504303\n",
      "Validation loss: 0.6700548020719784 MAE: 153.0216\n",
      "85 15 0.203424334526062\n",
      "85 65 0.30301937460899353\n",
      "85 115 0.3092532455921173\n",
      "85 165 0.38197872042655945\n",
      "Validation loss: 0.7352311768029866 MAE: 167.90605\n",
      "86 44 0.2803407311439514\n",
      "86 94 0.3596172332763672\n",
      "86 144 0.37508392333984375\n",
      "Validation loss: 0.4843083064109958 MAE: 110.60235\n",
      "87 23 0.3588801622390747\n",
      "87 73 0.3764956295490265\n",
      "87 123 0.43325647711753845\n",
      "Validation loss: 0.5107157944935804 MAE: 116.63307\n",
      "88 2 0.3042425811290741\n",
      "88 52 0.29413795471191406\n",
      "88 102 0.2255774587392807\n",
      "88 152 0.4448882043361664\n",
      "Validation loss: 0.46787544335538184 MAE: 106.849556\n",
      "89 31 0.3350396156311035\n",
      "89 81 0.32349345088005066\n",
      "89 131 0.3673567771911621\n",
      "Validation loss: 0.47472193959163644 MAE: 108.41308\n",
      "90 10 0.25595036149024963\n",
      "90 60 0.29909849166870117\n",
      "90 110 0.4896353483200073\n",
      "90 160 0.38716867566108704\n",
      "Validation loss: 0.5271811704886588 MAE: 120.393295\n",
      "91 39 0.2950083613395691\n",
      "91 89 0.33757901191711426\n",
      "91 139 0.35307615995407104\n",
      "Validation loss: 0.5236605440664013 MAE: 119.589294\n",
      "92 18 0.37035617232322693\n",
      "92 68 0.36362287402153015\n",
      "92 118 0.31602323055267334\n",
      "92 168 0.43157556653022766\n",
      "Validation loss: 0.5237191420549537 MAE: 119.60267\n",
      "93 47 0.24154044687747955\n",
      "93 97 0.5873541831970215\n",
      "93 147 0.37392622232437134\n",
      "Validation loss: 0.4576995010264436 MAE: 104.52565\n",
      "94 26 0.38548916578292847\n",
      "94 76 0.45153069496154785\n",
      "94 126 0.342929482460022\n",
      "Validation loss: 0.48754338946258813 MAE: 111.34115\n",
      "95 5 0.2725110948085785\n",
      "95 55 0.40745118260383606\n",
      "95 105 0.35973238945007324\n",
      "95 155 0.34376344084739685\n",
      "Validation loss: 0.5500707713484067 MAE: 125.620636\n",
      "96 34 0.2769920229911804\n",
      "96 84 0.5507954359054565\n",
      "96 134 0.278626024723053\n",
      "Validation loss: 0.5060677803747835 MAE: 115.5716\n",
      "97 13 0.43741050362586975\n",
      "97 63 0.46837741136550903\n",
      "97 113 0.3955107033252716\n",
      "97 163 0.4944433271884918\n",
      "Validation loss: 0.4878253065354643 MAE: 111.40554\n",
      "98 42 0.48346054553985596\n",
      "98 92 0.3008477985858917\n",
      "98 142 0.4807814359664917\n",
      "Validation loss: 0.47765985915535375 MAE: 109.084015\n",
      "99 21 0.3438415825366974\n",
      "99 71 0.37704214453697205\n",
      "99 121 0.4741290509700775\n",
      "Validation loss: 0.5019432689711364 MAE: 114.62966\n",
      "100 0 0.5158991813659668\n",
      "100 50 0.3935481607913971\n",
      "100 100 0.4455178380012512\n",
      "100 150 0.21590107679367065\n",
      "Validation loss: 0.47960829246811004 MAE: 109.52899\n",
      "101 29 0.25921905040740967\n",
      "101 79 0.33527031540870667\n",
      "101 129 0.39246729016304016\n",
      "Validation loss: 0.5432738379428261 MAE: 124.06841\n",
      "102 8 0.2355670928955078\n",
      "102 58 0.22678354382514954\n",
      "102 108 0.47293317317962646\n",
      "102 158 0.23206272721290588\n",
      "Validation loss: 0.528860174424467 MAE: 120.776726\n",
      "103 37 0.43132948875427246\n",
      "103 87 0.3146752119064331\n",
      "103 137 0.32501325011253357\n",
      "Validation loss: 0.7150105433157313 MAE: 163.28822\n",
      "104 16 0.48888230323791504\n",
      "104 66 0.39457476139068604\n",
      "104 116 0.4602310061454773\n",
      "104 166 0.3377631902694702\n",
      "Validation loss: 0.5475376617838765 MAE: 125.042145\n",
      "105 45 0.3591247498989105\n",
      "105 95 0.41734081506729126\n",
      "105 145 0.31052178144454956\n",
      "Validation loss: 0.49509445024512666 MAE: 113.065605\n",
      "106 24 0.3285332918167114\n",
      "106 74 0.26304587721824646\n",
      "106 124 0.35577788949012756\n",
      "Validation loss: 0.8164133147189492 MAE: 186.44577\n",
      "107 3 0.27618280053138733\n",
      "107 53 0.3057897984981537\n",
      "107 103 0.4550183117389679\n",
      "107 153 0.3933534324169159\n",
      "Validation loss: 0.5282773778103945 MAE: 120.64363\n",
      "108 32 0.43643391132354736\n",
      "108 82 0.3129967451095581\n",
      "108 132 0.41764599084854126\n",
      "Validation loss: 0.7651370439613074 MAE: 174.73572\n",
      "109 11 0.46077874302864075\n",
      "109 61 0.22731764614582062\n",
      "109 111 0.35556960105895996\n",
      "109 161 0.3380953073501587\n",
      "Validation loss: 0.9364388588576289 MAE: 213.8562\n",
      "110 40 0.4263426959514618\n",
      "110 90 0.4633023142814636\n",
      "110 140 0.4154966175556183\n",
      "Validation loss: 0.7852543250859132 MAE: 179.32993\n",
      "111 19 0.31407007575035095\n",
      "111 69 0.46265578269958496\n",
      "111 119 0.28770917654037476\n",
      "111 169 0.32142648100852966\n",
      "Validation loss: 0.7850653609337165 MAE: 179.28677\n",
      "112 48 0.27187371253967285\n",
      "112 98 0.2543505132198334\n",
      "112 148 0.28651997447013855\n",
      "Validation loss: 0.8125965978667052 MAE: 185.57413\n",
      "113 27 0.36442115902900696\n",
      "113 77 0.36925840377807617\n",
      "113 127 0.4569202661514282\n",
      "Validation loss: 0.6978658395901061 MAE: 159.37285\n",
      "114 6 0.374233603477478\n",
      "114 56 0.2859605550765991\n",
      "114 106 0.28557366132736206\n",
      "114 156 0.22674326598644257\n",
      "Validation loss: 0.5682133178264774 MAE: 129.76389\n",
      "115 35 0.3424850106239319\n",
      "115 85 0.4411414563655853\n",
      "115 135 0.24442079663276672\n",
      "Validation loss: 0.4722083862762005 MAE: 107.839066\n",
      "116 14 0.2503677010536194\n",
      "116 64 0.2801165282726288\n",
      "116 114 0.35214322805404663\n",
      "116 164 0.3307585120201111\n",
      "Validation loss: 0.6950520385078519 MAE: 158.73027\n",
      "117 43 0.31078752875328064\n",
      "117 93 0.4176464378833771\n",
      "117 143 0.3586430549621582\n",
      "Validation loss: 0.5490958453618993 MAE: 125.398\n",
      "118 22 0.269057035446167\n",
      "118 72 0.22406813502311707\n",
      "118 122 0.22624537348747253\n",
      "Validation loss: 0.5167254781165318 MAE: 118.00553\n",
      "119 1 0.3597067594528198\n",
      "119 51 0.29933828115463257\n",
      "119 101 0.2998383641242981\n",
      "119 151 0.3256891667842865\n",
      "Validation loss: 0.4985119937456142 MAE: 113.84607\n",
      "120 30 0.3984116315841675\n",
      "120 80 0.2618214786052704\n",
      "120 130 0.28767186403274536\n",
      "Validation loss: 0.5187180349004199 MAE: 118.46055\n",
      "121 9 0.2893553674221039\n",
      "121 59 0.24895671010017395\n",
      "121 109 0.2916504740715027\n",
      "121 159 0.30388256907463074\n",
      "Validation loss: 0.5561681867342944 MAE: 127.013115\n",
      "122 38 0.29393869638442993\n",
      "122 88 0.20348918437957764\n",
      "122 138 0.28797563910484314\n",
      "Validation loss: 0.5727593098816118 MAE: 130.80205\n",
      "123 17 0.39742493629455566\n",
      "123 67 0.31847208738327026\n",
      "123 117 0.36403635144233704\n",
      "123 167 0.38423478603363037\n",
      "Validation loss: 0.7201804445500959 MAE: 164.46889\n",
      "124 46 0.3015383183956146\n",
      "124 96 0.31443652510643005\n",
      "124 146 0.3586450219154358\n",
      "Validation loss: 0.7509946209645411 MAE: 171.50598\n",
      "125 25 0.4024808704853058\n",
      "125 75 0.26863789558410645\n",
      "125 125 0.26510509848594666\n",
      "Validation loss: 0.6666894565548813 MAE: 152.25307\n",
      "126 4 0.23913513123989105\n",
      "126 54 0.2705092430114746\n",
      "126 104 0.4116398096084595\n",
      "126 154 0.26751795411109924\n",
      "Validation loss: 0.5827624274973284 MAE: 133.08649\n",
      "127 33 0.450293630361557\n",
      "127 83 0.29697319865226746\n",
      "127 133 0.22370381653308868\n",
      "Validation loss: 0.6842655828821729 MAE: 156.26695\n",
      "128 12 0.2970101535320282\n",
      "128 62 0.34801048040390015\n",
      "128 112 0.2973170578479767\n",
      "128 162 0.3582676649093628\n",
      "Validation loss: 0.8290586307731985 MAE: 189.3336\n",
      "129 41 0.4090961217880249\n",
      "129 91 0.23681354522705078\n",
      "129 141 0.2746834456920624\n",
      "Validation loss: 0.4863933025047793 MAE: 111.078514\n",
      "130 20 0.3078736364841461\n",
      "130 70 0.27876102924346924\n",
      "130 120 0.4019513428211212\n",
      "130 170 0.2744935154914856\n",
      "Validation loss: 0.6367794073116012 MAE: 145.42244\n",
      "131 49 0.30386826395988464\n",
      "131 99 0.30808669328689575\n",
      "131 149 0.34472042322158813\n",
      "Validation loss: 0.49559625547531755 MAE: 113.1802\n",
      "132 28 0.28272703289985657\n",
      "132 78 0.5695955753326416\n",
      "132 128 0.4279176592826843\n",
      "Validation loss: 0.561368045053984 MAE: 128.2006\n",
      "133 7 0.41003382205963135\n",
      "133 57 0.19356533885002136\n",
      "133 107 0.4068875312805176\n",
      "133 157 0.29851046204566956\n",
      "Validation loss: 0.7411562852692186 MAE: 169.25919\n",
      "134 36 0.3415219783782959\n",
      "134 86 0.35287097096443176\n",
      "134 136 0.2736148536205292\n",
      "Validation loss: 0.5796853087798893 MAE: 132.38376\n",
      "135 15 0.46175509691238403\n",
      "135 65 0.2258029729127884\n",
      "135 115 0.25966277718544006\n",
      "135 165 0.23831699788570404\n",
      "Validation loss: 0.5781968797159474 MAE: 132.04384\n",
      "136 44 0.3746057152748108\n",
      "136 94 0.45937231183052063\n",
      "136 144 0.35694581270217896\n",
      "Validation loss: 0.4946614531745688 MAE: 112.966705\n",
      "137 23 0.2597288489341736\n",
      "137 73 0.18483637273311615\n",
      "137 123 0.1739891767501831\n",
      "Validation loss: 0.49250404772005585 MAE: 112.47403\n",
      "138 2 0.3520797789096832\n",
      "138 52 0.26935309171676636\n",
      "138 102 0.3135281801223755\n",
      "138 152 0.2719835042953491\n",
      "Validation loss: 0.5283246814158925 MAE: 120.65444\n",
      "139 31 0.28872665762901306\n",
      "139 81 0.28300637006759644\n",
      "139 131 0.32518553733825684\n",
      "Validation loss: 0.48468440387681216 MAE: 110.68823\n",
      "140 10 0.3126194179058075\n",
      "140 60 0.2557378113269806\n",
      "140 110 0.268909215927124\n",
      "140 160 0.30094659328460693\n",
      "Validation loss: 0.47526294184707063 MAE: 108.536644\n",
      "141 39 0.29274436831474304\n",
      "141 89 0.4658454954624176\n",
      "141 139 0.20977483689785004\n",
      "Validation loss: 0.6278501933778239 MAE: 143.38327\n",
      "142 18 0.2970682978630066\n",
      "142 68 0.25411006808280945\n",
      "142 118 0.21751388907432556\n",
      "142 168 0.44982871413230896\n",
      "Validation loss: 0.4948308969798841 MAE: 113.00542\n",
      "143 47 0.31555211544036865\n",
      "143 97 0.3976447880268097\n",
      "143 147 0.22608312964439392\n",
      "Validation loss: 0.608288375954879 MAE: 138.9159\n",
      "144 26 0.30911514163017273\n",
      "144 76 0.3305654227733612\n",
      "144 126 0.33148208260536194\n",
      "Validation loss: 0.5191368631452148 MAE: 118.556206\n",
      "145 5 0.3302968442440033\n",
      "145 55 0.22818699479103088\n",
      "145 105 0.30491623282432556\n",
      "145 155 0.36969220638275146\n",
      "Validation loss: 0.47955735594208476 MAE: 109.517365\n",
      "146 34 0.4055742025375366\n",
      "146 84 0.299541711807251\n",
      "146 134 0.2539941668510437\n",
      "Validation loss: 0.47756626940610114 MAE: 109.06266\n",
      "147 13 0.2083563655614853\n",
      "147 63 0.43979611992836\n",
      "147 113 0.4227435290813446\n",
      "147 163 0.3461785316467285\n",
      "Validation loss: 0.4889906958529824 MAE: 111.67167\n",
      "148 42 0.37909644842147827\n",
      "148 92 0.15959729254245758\n",
      "148 142 0.1959553211927414\n",
      "Validation loss: 0.44563460106041 MAE: 101.770355\n",
      "149 21 0.3822058439254761\n",
      "149 71 0.14808419346809387\n",
      "149 121 0.29321902990341187\n",
      "Validation loss: 0.44410911219858984 MAE: 101.421974\n",
      "150 0 0.2264597862958908\n",
      "150 50 0.3447696268558502\n",
      "150 100 0.40288078784942627\n",
      "150 150 0.3135368824005127\n",
      "Validation loss: 0.5091914074462757 MAE: 116.28495\n",
      "151 29 0.19334617257118225\n",
      "151 79 0.30456462502479553\n",
      "151 129 0.339628130197525\n",
      "Validation loss: 0.46961477416300634 MAE: 107.24676\n",
      "152 8 0.12815751135349274\n",
      "152 58 0.355660617351532\n",
      "152 108 0.32833123207092285\n",
      "152 158 0.5491084456443787\n",
      "Validation loss: 0.4519818010385971 MAE: 103.21987\n",
      "153 37 0.2991822063922882\n",
      "153 87 0.3577860891819\n",
      "153 137 0.29765599966049194\n",
      "Validation loss: 0.42290614257779036 MAE: 96.57983\n",
      "154 16 0.40252402424812317\n",
      "154 66 0.2128726840019226\n",
      "154 116 0.2962346374988556\n",
      "154 166 0.30928733944892883\n",
      "Validation loss: 0.4982787621648688 MAE: 113.79281\n",
      "155 45 0.2521783709526062\n",
      "155 95 0.26984453201293945\n",
      "155 145 0.3786279857158661\n",
      "Validation loss: 0.4746914763896786 MAE: 108.406136\n",
      "156 24 0.15199294686317444\n",
      "156 74 0.25010088086128235\n",
      "156 124 0.27306610345840454\n",
      "Validation loss: 0.46904704654425905 MAE: 107.11711\n",
      "157 3 0.2969166338443756\n",
      "157 53 0.170326367020607\n",
      "157 103 0.3281903862953186\n",
      "157 153 0.2656795084476471\n",
      "Validation loss: 0.48205802106020745 MAE: 110.08844\n",
      "158 32 0.18807309865951538\n",
      "158 82 0.27467015385627747\n",
      "158 132 0.3187585473060608\n",
      "Validation loss: 0.42646795685528316 MAE: 97.39324\n",
      "159 11 0.26908987760543823\n",
      "159 61 0.34982889890670776\n",
      "159 111 0.34434249997138977\n",
      "159 161 0.3552176356315613\n",
      "Validation loss: 0.44964467782026146 MAE: 102.68615\n",
      "160 40 0.5039868950843811\n",
      "160 90 0.3270566165447235\n",
      "160 140 0.3147314786911011\n",
      "Validation loss: 0.4867391908726497 MAE: 111.15751\n",
      "161 19 0.35176417231559753\n",
      "161 69 0.39540714025497437\n",
      "161 119 0.4388785660266876\n",
      "161 169 0.33538442850112915\n",
      "Validation loss: 0.45405797808491 MAE: 103.69402\n",
      "162 48 0.191151425242424\n",
      "162 98 0.30242079496383667\n",
      "162 148 0.2651025652885437\n",
      "Validation loss: 0.4601322339292158 MAE: 105.08121\n",
      "163 27 0.28893887996673584\n",
      "163 77 0.2907615303993225\n",
      "163 127 0.2010030746459961\n",
      "Validation loss: 0.49735200204695873 MAE: 113.581154\n",
      "164 6 0.5058686137199402\n",
      "164 56 0.2245250642299652\n",
      "164 106 0.27250850200653076\n",
      "164 156 0.23989355564117432\n",
      "Validation loss: 0.5498009454785732 MAE: 125.55901\n",
      "165 35 0.30348315834999084\n",
      "165 85 0.3345661461353302\n",
      "165 135 0.2717015743255615\n",
      "Validation loss: 0.6138239340823993 MAE: 140.18005\n",
      "166 14 0.3012826144695282\n",
      "166 64 0.30123940110206604\n",
      "166 114 0.29530027508735657\n",
      "166 164 0.4887318015098572\n",
      "Validation loss: 0.49340480670594333 MAE: 112.67973\n",
      "167 43 0.10907525569200516\n",
      "167 93 0.3156948387622833\n",
      "167 143 0.2783750593662262\n",
      "Validation loss: 0.5125464755192137 MAE: 117.05115\n",
      "168 22 0.2472771406173706\n",
      "168 72 0.5000176429748535\n",
      "168 122 0.30016839504241943\n",
      "Validation loss: 0.5275696906429982 MAE: 120.482025\n",
      "169 1 0.22060851752758026\n",
      "169 51 0.39214906096458435\n",
      "169 101 0.1669641137123108\n",
      "169 151 0.19496852159500122\n",
      "Validation loss: 0.5027164625145538 MAE: 114.80625\n",
      "170 30 0.24251852929592133\n",
      "170 80 0.308073490858078\n",
      "170 130 0.27283811569213867\n",
      "Validation loss: 0.44812813488363523 MAE: 102.33982\n",
      "171 9 0.3747521638870239\n",
      "171 59 0.26184749603271484\n",
      "171 109 0.3455340564250946\n",
      "171 159 0.3185690939426422\n",
      "Validation loss: 0.6203733466522038 MAE: 141.67577\n",
      "172 38 0.30097439885139465\n",
      "172 88 0.32327595353126526\n",
      "172 138 0.3524143695831299\n",
      "Validation loss: 0.44413319186509004 MAE: 101.42748\n",
      "173 17 0.30861616134643555\n",
      "173 67 0.30742567777633667\n",
      "173 117 0.3022574782371521\n",
      "173 167 0.14564864337444305\n",
      "Validation loss: 0.48087478869142586 MAE: 109.81822\n",
      "174 46 0.39684492349624634\n",
      "174 96 0.4302356243133545\n",
      "174 146 0.23294836282730103\n",
      "Validation loss: 0.44335268638287373 MAE: 101.24924\n",
      "175 25 0.36069363355636597\n",
      "175 75 0.27651017904281616\n",
      "175 125 0.30915555357933044\n",
      "Validation loss: 0.43550420574277465 MAE: 99.45686\n",
      "176 4 0.24347776174545288\n",
      "176 54 0.25934672355651855\n",
      "176 104 0.33192116022109985\n",
      "176 154 0.27186518907546997\n",
      "Validation loss: 0.4614414457689252 MAE: 105.380196\n",
      "177 33 0.32826197147369385\n",
      "177 83 0.2740178406238556\n",
      "177 133 0.1709313690662384\n",
      "Validation loss: 0.4577896751855549 MAE: 104.54625\n",
      "178 12 0.2091435343027115\n",
      "178 62 0.28001344203948975\n",
      "178 112 0.3234785497188568\n",
      "178 162 0.1953727900981903\n",
      "Validation loss: 0.5899114012718201 MAE: 134.71912\n",
      "179 41 0.22453705966472626\n",
      "179 91 0.21484124660491943\n",
      "179 141 0.22358091175556183\n",
      "Validation loss: 0.47777234078847874 MAE: 109.10972\n",
      "180 20 0.25733184814453125\n",
      "180 70 0.2602200210094452\n",
      "180 120 0.39273419976234436\n",
      "180 170 0.2647642493247986\n",
      "Validation loss: 0.5320513088103623 MAE: 121.50551\n",
      "181 49 0.2738385498523712\n",
      "181 99 0.22084330022335052\n",
      "181 149 0.1899765431880951\n",
      "Validation loss: 0.4526413443841432 MAE: 103.3705\n",
      "182 28 0.42859023809432983\n",
      "182 78 0.3702352046966553\n",
      "182 128 0.32958006858825684\n",
      "Validation loss: 0.4934436049726274 MAE: 112.6886\n",
      "183 7 0.23684318363666534\n",
      "183 57 0.2950367033481598\n",
      "183 107 0.27113208174705505\n",
      "183 157 0.250887393951416\n",
      "Validation loss: 0.4459393902828819 MAE: 101.83996\n",
      "184 36 0.3763907551765442\n",
      "184 86 0.21359457075595856\n",
      "184 136 0.28001663088798523\n",
      "Validation loss: 0.5493389420342027 MAE: 125.453514\n",
      "185 15 0.5724141597747803\n",
      "185 65 0.2418995350599289\n",
      "185 115 0.24906408786773682\n",
      "185 165 0.3393697738647461\n",
      "Validation loss: 0.4540863803952758 MAE: 103.70052\n",
      "186 44 0.32696712017059326\n",
      "186 94 0.29067865014076233\n",
      "186 144 0.2562374770641327\n",
      "Validation loss: 0.4600449195730756 MAE: 105.061264\n",
      "187 23 0.3341120183467865\n",
      "187 73 0.2964819371700287\n",
      "187 123 0.2385231852531433\n",
      "Validation loss: 0.4533438455988789 MAE: 103.53093\n",
      "188 2 0.3431819677352905\n",
      "188 52 0.3034450113773346\n",
      "188 102 0.32181090116500854\n",
      "188 152 0.19640204310417175\n",
      "Validation loss: 0.45525909881842763 MAE: 103.96833\n",
      "189 31 0.22534936666488647\n",
      "189 81 0.462612509727478\n",
      "189 131 0.3437238931655884\n",
      "Validation loss: 0.3913826457938256 MAE: 89.380745\n",
      "190 10 0.5224480032920837\n",
      "190 60 0.18348228931427002\n",
      "190 110 0.28713521361351013\n",
      "190 160 0.34526747465133667\n",
      "Validation loss: 0.43619558267426073 MAE: 99.61475\n",
      "191 39 0.34400755167007446\n",
      "191 89 0.14067479968070984\n",
      "191 139 0.32099831104278564\n",
      "Validation loss: 0.4593210485246446 MAE: 104.89596\n",
      "192 18 0.2978471517562866\n",
      "192 68 0.24123996496200562\n",
      "192 118 0.23815204203128815\n",
      "192 168 0.24310944974422455\n",
      "Validation loss: 0.4702818979296768 MAE: 107.39911\n",
      "193 47 0.2769385874271393\n",
      "193 97 0.25302228331565857\n",
      "193 147 0.3463228940963745\n",
      "Validation loss: 0.4765229029962194 MAE: 108.82438\n",
      "194 26 0.2779075503349304\n",
      "194 76 0.2643388509750366\n",
      "194 126 0.32990264892578125\n",
      "Validation loss: 0.47883740084910253 MAE: 109.35296\n",
      "195 5 0.2223931849002838\n",
      "195 55 0.2703624367713928\n",
      "195 105 0.2581252157688141\n",
      "195 155 0.20927350223064423\n",
      "Validation loss: 0.4467019658339651 MAE: 102.014114\n",
      "196 34 0.32856279611587524\n",
      "196 84 0.23766100406646729\n",
      "196 134 0.22458523511886597\n",
      "Validation loss: 0.42040426654425284 MAE: 96.00846\n",
      "197 13 0.21073634922504425\n",
      "197 63 0.24921804666519165\n",
      "197 113 0.31446078419685364\n",
      "197 163 0.3592223823070526\n",
      "Validation loss: 0.4879783928742883 MAE: 111.44049\n",
      "198 42 0.27017590403556824\n",
      "198 92 0.23451802134513855\n",
      "198 142 0.17566506564617157\n",
      "Validation loss: 0.43726821147907546 MAE: 99.85972\n",
      "199 21 0.36086931824684143\n",
      "199 71 0.28046196699142456\n",
      "199 121 0.39502182602882385\n",
      "Validation loss: 0.5273018965595647 MAE: 120.42087\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.45757905704734264 Test MAE: 104.498146\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qm7', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 779, 'task': 'regression', 'data_path': 'data/qm7/qm7.csv', 'target': ['u0_atom']}}\n",
      "Running on: cuda:0\n",
      "6833\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/6833\n",
      "Generating scaffold 1000/6833\n",
      "Generating scaffold 2000/6833\n",
      "Generating scaffold 3000/6833\n",
      "Generating scaffold 4000/6833\n",
      "Generating scaffold 5000/6833\n",
      "Generating scaffold 6000/6833\n",
      "About to sort in scaffold sets\n",
      "tensor(-1553.3462) tensor(228.3718) torch.Size([5466, 1])\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.421558141708374\n",
      "0 50 0.6022976040840149\n",
      "0 100 0.5989736318588257\n",
      "0 150 0.7624615430831909\n",
      "Validation loss: 1.2198895222959463 MAE: 278.58835\n",
      "1 29 0.7338041067123413\n",
      "1 79 0.8032910823822021\n",
      "1 129 0.5656138062477112\n",
      "Validation loss: 1.0900669585891634 MAE: 248.94054\n",
      "2 8 0.7222054600715637\n",
      "2 58 0.5203461647033691\n",
      "2 108 0.6894542574882507\n",
      "2 158 0.4864620566368103\n",
      "Validation loss: 1.173580166889213 MAE: 268.0126\n",
      "3 37 0.3835182785987854\n",
      "3 87 0.4466646611690521\n",
      "3 137 0.36654549837112427\n",
      "Validation loss: 0.6203547974078976 MAE: 141.67154\n",
      "4 16 0.40264278650283813\n",
      "4 66 0.5414363741874695\n",
      "4 116 0.5148415565490723\n",
      "4 166 0.6063051223754883\n",
      "Validation loss: 0.771467675939638 MAE: 176.18144\n",
      "5 45 0.7873861193656921\n",
      "5 95 0.5851810574531555\n",
      "5 145 0.5915238857269287\n",
      "Validation loss: 0.925145935942555 MAE: 211.2772\n",
      "6 24 0.42269235849380493\n",
      "6 74 0.41533374786376953\n",
      "6 124 0.34085530042648315\n",
      "Validation loss: 0.4679186875708619 MAE: 106.85942\n",
      "7 3 0.5957822203636169\n",
      "7 53 0.48019447922706604\n",
      "7 103 0.35434287786483765\n",
      "7 153 0.7192487120628357\n",
      "Validation loss: 0.46595814614965203 MAE: 106.41169\n",
      "8 32 0.5011144280433655\n",
      "8 82 0.5624608397483826\n",
      "8 132 0.5378732681274414\n",
      "Validation loss: 0.5568100252346686 MAE: 127.1597\n",
      "9 11 0.5096376538276672\n",
      "9 61 0.704784095287323\n",
      "9 111 0.6077209711074829\n",
      "9 161 0.30643561482429504\n",
      "Validation loss: 0.6915155122851768 MAE: 157.92262\n",
      "10 40 0.5440130233764648\n",
      "10 90 0.48820406198501587\n",
      "10 140 0.4113227128982544\n",
      "Validation loss: 0.5062317653009069 MAE: 115.60905\n",
      "11 19 0.6704646348953247\n",
      "11 69 0.4442591965198517\n",
      "11 119 0.5992814302444458\n",
      "11 169 0.6141940355300903\n",
      "Validation loss: 0.484531206171415 MAE: 110.65326\n",
      "12 48 0.47606950998306274\n",
      "12 98 0.5683957934379578\n",
      "12 148 0.4010813534259796\n",
      "Validation loss: 0.4103289948917969 MAE: 93.707565\n",
      "13 27 0.5256115198135376\n",
      "13 77 0.41876834630966187\n",
      "13 127 0.4074963927268982\n",
      "Validation loss: 0.5806234602691137 MAE: 132.59802\n",
      "14 6 0.38960063457489014\n",
      "14 56 0.45012152194976807\n",
      "14 106 0.39811864495277405\n",
      "14 156 0.6474950313568115\n",
      "Validation loss: 0.5782457154396682 MAE: 132.05501\n",
      "15 35 0.6262219548225403\n",
      "15 85 0.3234936594963074\n",
      "15 135 0.411234587430954\n",
      "Validation loss: 0.506937902747539 MAE: 115.77031\n",
      "16 14 0.2817269265651703\n",
      "16 64 0.371646523475647\n",
      "16 114 0.4989360570907593\n",
      "16 164 0.4203867018222809\n",
      "Validation loss: 0.6204398907067483 MAE: 141.69098\n",
      "17 43 0.4268026351928711\n",
      "17 93 0.5267953276634216\n",
      "17 143 0.37406405806541443\n",
      "Validation loss: 0.5886231842096786 MAE: 134.42493\n",
      "18 22 0.29615816473960876\n",
      "18 72 0.3734613060951233\n",
      "18 122 0.44514143466949463\n",
      "Validation loss: 0.5833842405798839 MAE: 133.2285\n",
      "19 1 0.3279738426208496\n",
      "19 51 0.33558952808380127\n",
      "19 101 0.5442424416542053\n",
      "19 151 0.3984098434448242\n",
      "Validation loss: 0.6723542872228121 MAE: 153.54674\n",
      "20 30 0.4406285583972931\n",
      "20 80 0.3906843662261963\n",
      "20 130 0.40016770362854004\n",
      "Validation loss: 0.550641826021741 MAE: 125.75105\n",
      "21 9 0.4429464042186737\n",
      "21 59 0.5592727661132812\n",
      "21 109 0.36954599618911743\n",
      "21 159 0.36443212628364563\n",
      "Validation loss: 0.5118316917391549 MAE: 116.88792\n",
      "22 38 0.4013654589653015\n",
      "22 88 0.36392897367477417\n",
      "22 138 0.35587143898010254\n",
      "Validation loss: 0.6421919168784604 MAE: 146.65851\n",
      "23 17 0.4836961328983307\n",
      "23 67 0.4563691020011902\n",
      "23 117 0.366487056016922\n",
      "23 167 0.44469913840293884\n",
      "Validation loss: 0.6442021239570707 MAE: 147.11757\n",
      "24 46 0.41107937693595886\n",
      "24 96 0.4623446464538574\n",
      "24 146 0.5294618010520935\n",
      "Validation loss: 0.6182260603932609 MAE: 141.18538\n",
      "25 25 0.4188959002494812\n",
      "25 75 0.5915066599845886\n",
      "25 125 0.42681336402893066\n",
      "Validation loss: 0.7774315915609661 MAE: 177.54344\n",
      "26 4 0.356705904006958\n",
      "26 54 0.48797276616096497\n",
      "26 104 0.3855630159378052\n",
      "26 154 0.372018039226532\n",
      "Validation loss: 0.612419653357121 MAE: 139.85936\n",
      "27 33 0.3514512777328491\n",
      "27 83 0.3319455683231354\n",
      "27 133 0.45761924982070923\n",
      "Validation loss: 0.5246375347787177 MAE: 119.81241\n",
      "28 12 0.3400232493877411\n",
      "28 62 0.3743477165699005\n",
      "28 112 0.43955615162849426\n",
      "28 162 0.2604737877845764\n",
      "Validation loss: 0.6253297224379423 MAE: 142.80766\n",
      "29 41 0.4386321008205414\n",
      "29 91 0.42664676904678345\n",
      "29 141 0.40725862979888916\n",
      "Validation loss: 0.6367261970949452 MAE: 145.4103\n",
      "30 20 0.3856407403945923\n",
      "30 70 0.46983522176742554\n",
      "30 120 0.3439006805419922\n",
      "30 170 0.4476129114627838\n",
      "Validation loss: 0.5962476754746242 MAE: 136.16614\n",
      "31 49 0.47275033593177795\n",
      "31 99 0.4747472405433655\n",
      "31 149 0.35646000504493713\n",
      "Validation loss: 0.7832856683703194 MAE: 178.88034\n",
      "32 28 0.46481847763061523\n",
      "32 78 0.3409709632396698\n",
      "32 128 0.2582775056362152\n",
      "Validation loss: 0.5792373265439307 MAE: 132.28145\n",
      "33 7 0.3616577684879303\n",
      "33 57 0.32480528950691223\n",
      "33 107 0.45362699031829834\n",
      "33 157 0.3746986985206604\n",
      "Validation loss: 0.4901513927861264 MAE: 111.936745\n",
      "34 36 0.5800835490226746\n",
      "34 86 0.5217227935791016\n",
      "34 136 0.39584508538246155\n",
      "Validation loss: 0.514497404907182 MAE: 117.49669\n",
      "35 15 0.2711685001850128\n",
      "35 65 0.3150746822357178\n",
      "35 115 0.48935315012931824\n",
      "35 165 0.386465460062027\n",
      "Validation loss: 0.5715843686583446 MAE: 130.53374\n",
      "36 44 0.3756338953971863\n",
      "36 94 0.42806899547576904\n",
      "36 144 0.4374932646751404\n",
      "Validation loss: 0.6608577081334521 MAE: 150.92125\n",
      "37 23 0.3690425455570221\n",
      "37 73 0.5043345093727112\n",
      "37 123 0.45844510197639465\n",
      "Validation loss: 0.5057556287587037 MAE: 115.500305\n",
      "38 2 0.36540111899375916\n",
      "38 52 0.38806307315826416\n",
      "38 102 0.45550960302352905\n",
      "38 152 0.41988158226013184\n",
      "Validation loss: 0.5796325907372591 MAE: 132.37172\n",
      "39 31 0.5605470538139343\n",
      "39 81 0.47643470764160156\n",
      "39 131 0.4736892282962799\n",
      "Validation loss: 0.7310903609147545 MAE: 166.9604\n",
      "40 10 0.33969825506210327\n",
      "40 60 0.3896990120410919\n",
      "40 110 0.40467771887779236\n",
      "40 160 0.5135208964347839\n",
      "Validation loss: 0.7428513469054685 MAE: 169.64629\n",
      "41 39 0.3506753444671631\n",
      "41 89 0.3731757700443268\n",
      "41 139 0.44275400042533875\n",
      "Validation loss: 0.5054536148121482 MAE: 115.431335\n",
      "42 18 0.38327863812446594\n",
      "42 68 0.21909520030021667\n",
      "42 118 0.19655127823352814\n",
      "42 168 0.2605748474597931\n",
      "Validation loss: 0.5397297823638246 MAE: 123.25905\n",
      "43 47 0.4066506028175354\n",
      "43 97 0.5192049145698547\n",
      "43 147 0.28993165493011475\n",
      "Validation loss: 0.549366529573474 MAE: 125.45981\n",
      "44 26 0.3133361041545868\n",
      "44 76 0.4036414325237274\n",
      "44 126 0.5869263410568237\n",
      "Validation loss: 0.5386023488309648 MAE: 123.00158\n",
      "45 5 0.30916526913642883\n",
      "45 55 0.5587758421897888\n",
      "45 105 0.33055970072746277\n",
      "45 155 0.4863453805446625\n",
      "Validation loss: 0.6838101605225725 MAE: 156.16293\n",
      "46 34 0.25883203744888306\n",
      "46 84 0.6298599243164062\n",
      "46 134 0.4606720209121704\n",
      "Validation loss: 0.5624579407318294 MAE: 128.44951\n",
      "47 13 0.4831914007663727\n",
      "47 63 0.3636381924152374\n",
      "47 113 0.39646875858306885\n",
      "47 163 0.3803013265132904\n",
      "Validation loss: 0.6511315832361143 MAE: 148.70009\n",
      "48 42 0.49431613087654114\n",
      "48 92 0.4586014151573181\n",
      "48 142 0.42525818943977356\n",
      "Validation loss: 0.6129041359438534 MAE: 139.97\n",
      "49 21 0.3088698983192444\n",
      "49 71 0.31861814856529236\n",
      "49 121 0.2991114556789398\n",
      "Validation loss: 0.7027031350554082 MAE: 160.47757\n",
      "50 0 0.435738205909729\n",
      "50 50 0.3691006004810333\n",
      "50 100 0.4398808479309082\n",
      "50 150 0.27448904514312744\n",
      "Validation loss: 0.5417542154328865 MAE: 123.72137\n",
      "51 29 0.43936920166015625\n",
      "51 79 0.3944689631462097\n",
      "51 129 0.5010386109352112\n",
      "Validation loss: 0.6528350923493592 MAE: 149.08911\n",
      "52 8 0.5486041307449341\n",
      "52 58 0.3819447457790375\n",
      "52 108 0.5024826526641846\n",
      "52 158 0.24016031622886658\n",
      "Validation loss: 0.611337451558364 MAE: 139.61221\n",
      "53 37 0.47655826807022095\n",
      "53 87 0.4667128920555115\n",
      "53 137 0.41494616866111755\n",
      "Validation loss: 0.5798001122056392 MAE: 132.40997\n",
      "54 16 0.2539137005805969\n",
      "54 66 0.31385859847068787\n",
      "54 116 0.20983724296092987\n",
      "54 166 0.32110539078712463\n",
      "Validation loss: 0.5305267636887512 MAE: 121.15733\n",
      "55 45 0.4013368785381317\n",
      "55 95 0.41134488582611084\n",
      "55 145 0.25659576058387756\n",
      "Validation loss: 0.6349079699544181 MAE: 144.99507\n",
      "56 24 0.47142088413238525\n",
      "56 74 0.5163652300834656\n",
      "56 124 0.3657629191875458\n",
      "Validation loss: 0.6977869899649369 MAE: 159.35486\n",
      "57 3 0.4380163252353668\n",
      "57 53 0.45160728693008423\n",
      "57 103 0.44323232769966125\n",
      "57 153 0.5093029141426086\n",
      "Validation loss: 0.6354787827235217 MAE: 145.12541\n",
      "58 32 0.30233946442604065\n",
      "58 82 0.2455901801586151\n",
      "58 132 0.24962997436523438\n",
      "Validation loss: 0.5973089068953754 MAE: 136.4085\n",
      "59 11 0.5711001753807068\n",
      "59 61 0.38689106702804565\n",
      "59 111 0.4730677306652069\n",
      "59 161 0.2116628885269165\n",
      "Validation loss: 0.48268914518997685 MAE: 110.23257\n",
      "60 40 0.2740967273712158\n",
      "60 90 0.4160872995853424\n",
      "60 140 0.42046260833740234\n",
      "Validation loss: 0.5379596192237229 MAE: 122.85478\n",
      "61 19 0.4846879541873932\n",
      "61 69 0.3070301115512848\n",
      "61 119 0.3985373079776764\n",
      "61 169 0.27391281723976135\n",
      "Validation loss: 0.7295425983897427 MAE: 166.60693\n",
      "62 48 0.22648517787456512\n",
      "62 98 0.3304789364337921\n",
      "62 148 0.2824380397796631\n",
      "Validation loss: 0.7103858781836884 MAE: 162.23209\n",
      "63 27 0.3944469094276428\n",
      "63 77 0.3682421147823334\n",
      "63 127 0.4496859014034271\n",
      "Validation loss: 0.510685750615527 MAE: 116.62621\n",
      "64 6 0.38754862546920776\n",
      "64 56 0.352505624294281\n",
      "64 106 0.4381025433540344\n",
      "64 156 0.3036678433418274\n",
      "Validation loss: 0.5505179956293943 MAE: 125.72277\n",
      "65 35 0.2823626399040222\n",
      "65 85 0.339848130941391\n",
      "65 135 0.3229473829269409\n",
      "Validation loss: 0.5517570125429254 MAE: 126.00574\n",
      "66 14 0.5370627641677856\n",
      "66 64 0.3456512987613678\n",
      "66 114 0.40692874789237976\n",
      "66 164 0.32261937856674194\n",
      "Validation loss: 0.5018523040919276 MAE: 114.608894\n",
      "67 43 0.47567883133888245\n",
      "67 93 0.3268287181854248\n",
      "67 143 0.33436501026153564\n",
      "Validation loss: 0.678440417114057 MAE: 154.93665\n",
      "68 22 0.6195284724235535\n",
      "68 72 0.2917255163192749\n",
      "68 122 0.5316723585128784\n",
      "Validation loss: 0.5281902949015299 MAE: 120.62376\n",
      "69 1 0.3760184645652771\n",
      "69 51 0.23766082525253296\n",
      "69 101 0.3918110132217407\n",
      "69 151 0.3736809492111206\n",
      "Validation loss: 0.5306639748010021 MAE: 121.18867\n",
      "70 30 0.2985597550868988\n",
      "70 80 0.487946480512619\n",
      "70 130 0.3404831886291504\n",
      "Validation loss: 0.6059596761625413 MAE: 138.3841\n",
      "71 9 0.3310735523700714\n",
      "71 59 0.25991928577423096\n",
      "71 109 0.3150440454483032\n",
      "71 159 0.42685267329216003\n",
      "Validation loss: 0.5467032173223663 MAE: 124.851585\n",
      "72 38 0.4330671429634094\n",
      "72 88 0.2777143120765686\n",
      "72 138 0.5991422533988953\n",
      "Validation loss: 0.5525836205621909 MAE: 126.1945\n",
      "73 17 0.3196657598018646\n",
      "73 67 0.18695546686649323\n",
      "73 117 0.3022976517677307\n",
      "73 167 0.347768634557724\n",
      "Validation loss: 0.6132576193725854 MAE: 140.05074\n",
      "74 46 0.2287667840719223\n",
      "74 96 0.5050695538520813\n",
      "74 146 0.4479031562805176\n",
      "Validation loss: 0.5683154397540622 MAE: 129.78722\n",
      "75 25 0.41282784938812256\n",
      "75 75 0.4141213297843933\n",
      "75 125 0.2836538255214691\n",
      "Validation loss: 0.5170831533900478 MAE: 118.0872\n",
      "76 4 0.27877506613731384\n",
      "76 54 0.39048492908477783\n",
      "76 104 0.43128252029418945\n",
      "76 154 0.31392788887023926\n",
      "Validation loss: 0.5561007088736484 MAE: 126.9977\n",
      "77 33 0.3831905126571655\n",
      "77 83 0.32524484395980835\n",
      "77 133 0.2569672465324402\n",
      "Validation loss: 0.5083187058655142 MAE: 116.08564\n",
      "78 12 0.3730711042881012\n",
      "78 62 0.36568936705589294\n",
      "78 112 0.3120572566986084\n",
      "78 162 0.253672331571579\n",
      "Validation loss: 0.4911394474799173 MAE: 112.162384\n",
      "79 41 0.26503491401672363\n",
      "79 91 0.24036262929439545\n",
      "79 141 0.22570008039474487\n",
      "Validation loss: 0.6427637263696794 MAE: 146.7891\n",
      "80 20 0.3686700463294983\n",
      "80 70 0.44313549995422363\n",
      "80 120 0.5415977835655212\n",
      "80 170 0.24562610685825348\n",
      "Validation loss: 0.6367510459576434 MAE: 145.41595\n",
      "81 49 0.20023994147777557\n",
      "81 99 0.3894134759902954\n",
      "81 149 0.5348690748214722\n",
      "Validation loss: 0.595176567111099 MAE: 135.92154\n",
      "82 28 0.28022149205207825\n",
      "82 78 0.49327537417411804\n",
      "82 128 0.3070002794265747\n",
      "Validation loss: 0.5848891156458715 MAE: 133.57217\n",
      "83 7 0.2809816598892212\n",
      "83 57 0.44723448157310486\n",
      "83 107 0.4211873412132263\n",
      "83 157 0.2947145104408264\n",
      "Validation loss: 0.6485681338616979 MAE: 148.11465\n",
      "84 36 0.35985854268074036\n",
      "84 86 0.3211418688297272\n",
      "84 136 0.325894832611084\n",
      "Validation loss: 0.5882737545939217 MAE: 134.34512\n",
      "85 15 0.3048200011253357\n",
      "85 65 0.3055537939071655\n",
      "85 115 0.30591291189193726\n",
      "85 165 0.4302631616592407\n",
      "Validation loss: 0.535900554461786 MAE: 122.38456\n",
      "86 44 0.33144068717956543\n",
      "86 94 0.3814464509487152\n",
      "86 144 0.39381563663482666\n",
      "Validation loss: 0.5028045876332891 MAE: 114.82636\n",
      "87 23 0.506098210811615\n",
      "87 73 0.32071155309677124\n",
      "87 123 0.213445246219635\n",
      "Validation loss: 0.6259365489608363 MAE: 142.94624\n",
      "88 2 0.4873386323451996\n",
      "88 52 0.5823135375976562\n",
      "88 102 0.29334986209869385\n",
      "88 152 0.3727448880672455\n",
      "Validation loss: 0.5235813737612719 MAE: 119.571205\n",
      "89 31 0.3371124267578125\n",
      "89 81 0.3029431104660034\n",
      "89 131 0.30470412969589233\n",
      "Validation loss: 0.5683642165702686 MAE: 129.79836\n",
      "90 10 0.40543222427368164\n",
      "90 60 0.3887949585914612\n",
      "90 110 0.38153883814811707\n",
      "90 160 0.3096630871295929\n",
      "Validation loss: 0.5844303404378612 MAE: 133.4674\n",
      "91 39 0.4406641125679016\n",
      "91 89 0.327608197927475\n",
      "91 139 0.492197722196579\n",
      "Validation loss: 0.6670360986949407 MAE: 152.33223\n",
      "92 18 0.496177077293396\n",
      "92 68 0.344265341758728\n",
      "92 118 0.5617385506629944\n",
      "92 168 0.4185293912887573\n",
      "Validation loss: 0.5771025928140384 MAE: 131.79395\n",
      "93 47 0.27533990144729614\n",
      "93 97 0.24894963204860687\n",
      "93 147 0.3625815510749817\n",
      "Validation loss: 0.5435617451082196 MAE: 124.13416\n",
      "94 26 0.43888059258461\n",
      "94 76 0.3286142647266388\n",
      "94 126 0.39648595452308655\n",
      "Validation loss: 0.6425913858134844 MAE: 146.74974\n",
      "95 5 0.4957571029663086\n",
      "95 55 0.4316829741001129\n",
      "95 105 0.4232109785079956\n",
      "95 155 0.3654392957687378\n",
      "Validation loss: 0.5083686622262699 MAE: 116.09705\n",
      "96 34 0.4366835057735443\n",
      "96 84 0.2823811173439026\n",
      "96 134 0.3706403970718384\n",
      "Validation loss: 0.6361777155022872 MAE: 145.28502\n",
      "97 13 0.32960590720176697\n",
      "97 63 0.41729721426963806\n",
      "97 113 0.5418389439582825\n",
      "97 163 0.34323424100875854\n",
      "Validation loss: 0.6360161199904325 MAE: 145.24814\n",
      "98 42 0.36348333954811096\n",
      "98 92 0.4035422205924988\n",
      "98 142 0.3707386255264282\n",
      "Validation loss: 0.4986138082387155 MAE: 113.86932\n",
      "99 21 0.341717004776001\n",
      "99 71 0.14994263648986816\n",
      "99 121 0.3736977279186249\n",
      "Validation loss: 0.5159576719964457 MAE: 117.83017\n",
      "100 0 0.35048943758010864\n",
      "100 50 0.30393171310424805\n",
      "100 100 0.30314770340919495\n",
      "100 150 0.3408530354499817\n",
      "Validation loss: 0.6688580795338279 MAE: 152.7483\n",
      "101 29 0.42888274788856506\n",
      "101 79 0.4482291042804718\n",
      "101 129 0.35403504967689514\n",
      "Validation loss: 0.5374648898665668 MAE: 122.74181\n",
      "102 8 0.3348754644393921\n",
      "102 58 0.3148248493671417\n",
      "102 108 0.33110135793685913\n",
      "102 158 0.44374340772628784\n",
      "Validation loss: 0.5327151166765314 MAE: 121.6571\n",
      "103 37 0.2785775065422058\n",
      "103 87 0.31365758180618286\n",
      "103 137 0.2428124099969864\n",
      "Validation loss: 0.6695392675567091 MAE: 152.90387\n",
      "104 16 0.2043296843767166\n",
      "104 66 0.27525198459625244\n",
      "104 116 0.43774330615997314\n",
      "104 166 0.38599893450737\n",
      "Validation loss: 0.5931364810257628 MAE: 135.45564\n",
      "105 45 0.3698374629020691\n",
      "105 95 0.5575888156890869\n",
      "105 145 0.43205946683883667\n",
      "Validation loss: 0.6083121989902697 MAE: 138.92134\n",
      "106 24 0.4797959625720978\n",
      "106 74 0.37684425711631775\n",
      "106 124 0.3338512182235718\n",
      "Validation loss: 0.5699617779045775 MAE: 130.16318\n",
      "107 3 0.3853153884410858\n",
      "107 53 0.4190797507762909\n",
      "107 103 0.35597893595695496\n",
      "107 153 0.48080772161483765\n",
      "Validation loss: 0.5441173370818646 MAE: 124.26105\n",
      "108 32 0.30207502841949463\n",
      "108 82 0.24334979057312012\n",
      "108 132 0.231061190366745\n",
      "Validation loss: 0.6228480942068044 MAE: 142.24094\n",
      "109 11 0.306294709444046\n",
      "109 61 0.4794164299964905\n",
      "109 111 0.42760634422302246\n",
      "109 161 0.2518487572669983\n",
      "Validation loss: 0.483975420918381 MAE: 110.52631\n",
      "110 40 0.45497995615005493\n",
      "110 90 0.32415494322776794\n",
      "110 140 0.5274694561958313\n",
      "Validation loss: 0.5800594056558888 MAE: 132.4692\n",
      "111 19 0.3217013478279114\n",
      "111 69 0.4088347852230072\n",
      "111 119 0.4920091927051544\n",
      "111 169 0.3874378800392151\n",
      "Validation loss: 0.626797534568965 MAE: 143.14287\n",
      "112 48 0.36219164729118347\n",
      "112 98 0.3772642910480499\n",
      "112 148 0.4604465961456299\n",
      "Validation loss: 0.6370344015589932 MAE: 145.48067\n",
      "113 27 0.2927558124065399\n",
      "113 77 0.35488301515579224\n",
      "113 127 0.17917965352535248\n",
      "Validation loss: 0.5789212807577256 MAE: 132.20927\n",
      "114 6 0.39082565903663635\n",
      "114 56 0.27894505858421326\n",
      "114 106 0.2058899700641632\n",
      "114 156 0.3185517489910126\n",
      "Validation loss: 0.6199565508909393 MAE: 141.58058\n",
      "115 35 0.23512622714042664\n",
      "115 85 0.3723764717578888\n",
      "115 135 0.292684406042099\n",
      "Validation loss: 0.5941881610636126 MAE: 135.69579\n",
      "116 14 0.3194938004016876\n",
      "116 64 0.34349295496940613\n",
      "116 114 0.25285637378692627\n",
      "116 164 0.35706329345703125\n",
      "Validation loss: 0.5307578169114409 MAE: 121.210106\n",
      "117 43 0.23225055634975433\n",
      "117 93 0.3674628436565399\n",
      "117 143 0.3048486113548279\n",
      "Validation loss: 0.6061909651895713 MAE: 138.4369\n",
      "118 22 0.19590343534946442\n",
      "118 72 0.38620883226394653\n",
      "118 122 0.23346629738807678\n",
      "Validation loss: 0.6174237546865006 MAE: 141.00215\n",
      "119 1 0.36676082015037537\n",
      "119 51 0.26558905839920044\n",
      "119 101 0.29342278838157654\n",
      "119 151 0.33873698115348816\n",
      "Validation loss: 0.6211775983983313 MAE: 141.85944\n",
      "120 30 0.34384599328041077\n",
      "120 80 0.29970064759254456\n",
      "120 130 0.22767001390457153\n",
      "Validation loss: 0.6677391340858058 MAE: 152.49277\n",
      "121 9 0.26160749793052673\n",
      "121 59 0.28211355209350586\n",
      "121 109 0.36023786664009094\n",
      "121 159 0.4482622742652893\n",
      "Validation loss: 0.5493000681288758 MAE: 125.444626\n",
      "122 38 0.21177226305007935\n",
      "122 88 0.2898443639278412\n",
      "122 138 0.2622297406196594\n",
      "Validation loss: 0.5684696639838972 MAE: 129.82243\n",
      "123 17 0.39205217361450195\n",
      "123 67 0.2800169885158539\n",
      "123 117 0.3185913562774658\n",
      "123 167 0.48236820101737976\n",
      "Validation loss: 0.6033159351488303 MAE: 137.78033\n",
      "124 46 0.32754606008529663\n",
      "124 96 0.33541804552078247\n",
      "124 146 0.348702996969223\n",
      "Validation loss: 0.6514788764959191 MAE: 148.77939\n",
      "125 25 0.33453303575515747\n",
      "125 75 0.24091127514839172\n",
      "125 125 0.31821349263191223\n",
      "Validation loss: 0.6008477465451112 MAE: 137.21667\n",
      "126 4 0.49793022871017456\n",
      "126 54 0.26616737246513367\n",
      "126 104 0.30193454027175903\n",
      "126 154 0.529003918170929\n",
      "Validation loss: 0.835741933326275 MAE: 190.85988\n",
      "127 33 0.39954736828804016\n",
      "127 83 0.42562800645828247\n",
      "127 133 0.3333635628223419\n",
      "Validation loss: 0.5861623456255037 MAE: 133.86295\n",
      "128 12 0.21482455730438232\n",
      "128 62 0.32876986265182495\n",
      "128 112 0.36412662267684937\n",
      "128 162 0.36871179938316345\n",
      "Validation loss: 0.6695244117089879 MAE: 152.90047\n",
      "129 41 0.32269251346588135\n",
      "129 91 0.36586952209472656\n",
      "129 141 0.3521098494529724\n",
      "Validation loss: 0.539156897374761 MAE: 123.12822\n",
      "130 20 0.2615114748477936\n",
      "130 70 0.20258614420890808\n",
      "130 120 0.386276513338089\n",
      "130 170 0.21727566421031952\n",
      "Validation loss: 0.6371308641824108 MAE: 145.5027\n",
      "131 49 0.20298676192760468\n",
      "131 99 0.3063904941082001\n",
      "131 149 0.24619826674461365\n",
      "Validation loss: 0.7654123884892603 MAE: 174.79858\n",
      "132 28 0.3246484398841858\n",
      "132 78 0.4825359582901001\n",
      "132 128 0.3036138415336609\n",
      "Validation loss: 0.6841400492261027 MAE: 156.23828\n",
      "133 7 0.30550339818000793\n",
      "133 57 0.23088176548480988\n",
      "133 107 0.3621424734592438\n",
      "133 157 0.3119238018989563\n",
      "Validation loss: 0.6214090383540817 MAE: 141.9123\n",
      "134 36 0.3371407091617584\n",
      "134 86 0.31183743476867676\n",
      "134 136 0.33338662981987\n",
      "Validation loss: 0.6037242984214024 MAE: 137.87361\n",
      "135 15 0.2237621396780014\n",
      "135 65 0.40747272968292236\n",
      "135 115 0.31716176867485046\n",
      "135 165 0.44584423303604126\n",
      "Validation loss: 0.6270000544207835 MAE: 143.18912\n",
      "136 44 0.3618723154067993\n",
      "136 94 0.3030480444431305\n",
      "136 144 0.4780641794204712\n",
      "Validation loss: 0.6766978132794474 MAE: 154.53868\n",
      "137 23 0.24555812776088715\n",
      "137 73 0.36468109488487244\n",
      "137 123 0.2556777000427246\n",
      "Validation loss: 0.5336538215129696 MAE: 121.87147\n",
      "138 2 0.2762819230556488\n",
      "138 52 0.18000441789627075\n",
      "138 102 0.30418673157691956\n",
      "138 152 0.390362411737442\n",
      "Validation loss: 0.6346260303990883 MAE: 144.93066\n",
      "139 31 0.4146255850791931\n",
      "139 81 0.35390886664390564\n",
      "139 131 0.21238812804222107\n",
      "Validation loss: 0.6040089062431402 MAE: 137.93858\n",
      "140 10 0.3458012044429779\n",
      "140 60 0.43032070994377136\n",
      "140 110 0.24017289280891418\n",
      "140 160 0.3260468542575836\n",
      "Validation loss: 0.6005988713593511 MAE: 137.15982\n",
      "141 39 0.26320716738700867\n",
      "141 89 0.25791123509407043\n",
      "141 139 0.3614731729030609\n",
      "Validation loss: 0.6159184763306066 MAE: 140.6584\n",
      "142 18 0.2181326299905777\n",
      "142 68 0.4367396831512451\n",
      "142 118 0.3174320459365845\n",
      "142 168 0.3605964779853821\n",
      "Validation loss: 0.6768581678992823 MAE: 154.57529\n",
      "143 47 0.3912391662597656\n",
      "143 97 0.22024661302566528\n",
      "143 147 0.2295697033405304\n",
      "Validation loss: 0.7002165714899699 MAE: 159.9097\n",
      "144 26 0.16922052204608917\n",
      "144 76 0.49258026480674744\n",
      "144 126 0.19784152507781982\n",
      "Validation loss: 0.5863626355316207 MAE: 133.90868\n",
      "145 5 0.3097648322582245\n",
      "145 55 0.4566981792449951\n",
      "145 105 0.40774601697921753\n",
      "145 155 0.3781316578388214\n",
      "Validation loss: 0.605881360887784 MAE: 138.36621\n",
      "146 34 0.2470708042383194\n",
      "146 84 0.2747381627559662\n",
      "146 134 0.34031036496162415\n",
      "Validation loss: 0.7715013271186784 MAE: 176.18912\n",
      "147 13 0.21592944860458374\n",
      "147 63 0.3393649458885193\n",
      "147 113 0.24732084572315216\n",
      "147 163 0.4795743525028229\n",
      "Validation loss: 0.5625444478110263 MAE: 128.46927\n",
      "148 42 0.3589371144771576\n",
      "148 92 0.3217003047466278\n",
      "148 142 0.34766897559165955\n",
      "Validation loss: 0.567653254807344 MAE: 129.63599\n",
      "149 21 0.3306713402271271\n",
      "149 71 0.19971252977848053\n",
      "149 121 0.26670193672180176\n",
      "Validation loss: 0.5310208699856586 MAE: 121.27018\n",
      "150 0 0.4787859320640564\n",
      "150 50 0.3174844980239868\n",
      "150 100 0.4103296995162964\n",
      "150 150 0.28928428888320923\n",
      "Validation loss: 0.7191240442426581 MAE: 164.22763\n",
      "151 29 0.34103646874427795\n",
      "151 79 0.2352553755044937\n",
      "151 129 0.33251267671585083\n",
      "Validation loss: 0.6369048764831141 MAE: 145.4511\n",
      "152 8 0.23353607952594757\n",
      "152 58 0.4934735894203186\n",
      "152 108 0.26250743865966797\n",
      "152 158 0.30768534541130066\n",
      "Validation loss: 0.7193811873943485 MAE: 164.28636\n",
      "153 37 0.3900258541107178\n",
      "153 87 0.27570486068725586\n",
      "153 137 0.24818451702594757\n",
      "Validation loss: 0.5389462061095656 MAE: 123.080086\n",
      "154 16 0.23966433107852936\n",
      "154 66 0.3080291152000427\n",
      "154 116 0.23965875804424286\n",
      "154 166 0.323356568813324\n",
      "Validation loss: 0.6951648056158546 MAE: 158.75601\n",
      "155 45 0.24852964282035828\n",
      "155 95 0.2566273510456085\n",
      "155 145 0.2505761981010437\n",
      "Validation loss: 0.635642339263046 MAE: 145.16277\n",
      "156 24 0.37423837184906006\n",
      "156 74 0.32897523045539856\n",
      "156 124 0.199010968208313\n",
      "Validation loss: 0.6755738519785697 MAE: 154.282\n",
      "157 3 0.16182135045528412\n",
      "157 53 0.4274443984031677\n",
      "157 103 0.3933374583721161\n",
      "157 153 0.29674139618873596\n",
      "Validation loss: 0.6527729654869838 MAE: 149.07492\n",
      "158 32 0.32640978693962097\n",
      "158 82 0.2589397728443146\n",
      "158 132 0.24761033058166504\n",
      "Validation loss: 0.5919684952462626 MAE: 135.18889\n",
      "159 11 0.4037470519542694\n",
      "159 61 0.26628145575523376\n",
      "159 111 0.2521723508834839\n",
      "159 161 0.2558131217956543\n",
      "Validation loss: 0.5856240914579023 MAE: 133.74002\n",
      "160 40 0.3340807855129242\n",
      "160 90 0.32393649220466614\n",
      "160 140 0.29673776030540466\n",
      "Validation loss: 0.5299799194809987 MAE: 121.03245\n",
      "161 19 0.3058508634567261\n",
      "161 69 0.32630831003189087\n",
      "161 119 0.367960125207901\n",
      "161 169 0.45692452788352966\n",
      "Validation loss: 0.5538273415370294 MAE: 126.47852\n",
      "162 48 0.44447100162506104\n",
      "162 98 0.2774907648563385\n",
      "162 148 0.24876795709133148\n",
      "Validation loss: 0.5501121184979266 MAE: 125.63007\n",
      "163 27 0.24915800988674164\n",
      "163 77 0.35540086030960083\n",
      "163 127 0.4127006232738495\n",
      "Validation loss: 0.5771920642657586 MAE: 131.81438\n",
      "164 6 0.3455081284046173\n",
      "164 56 0.33994609117507935\n",
      "164 106 0.3704642653465271\n",
      "164 156 0.26859748363494873\n",
      "Validation loss: 0.5970796520947016 MAE: 136.35614\n",
      "165 35 0.2610614001750946\n",
      "165 85 0.2732890546321869\n",
      "165 135 0.19171082973480225\n",
      "Validation loss: 0.5898395187673513 MAE: 134.7027\n",
      "166 14 0.36278194189071655\n",
      "166 64 0.2836460769176483\n",
      "166 114 0.21516111493110657\n",
      "166 164 0.41416239738464355\n",
      "Validation loss: 0.5880397973004837 MAE: 134.29169\n",
      "167 43 0.24032224714756012\n",
      "167 93 0.24354323744773865\n",
      "167 143 0.37766212224960327\n",
      "Validation loss: 0.654401333359947 MAE: 149.4468\n",
      "168 22 0.3290867209434509\n",
      "168 72 0.3042405843734741\n",
      "168 122 0.19913530349731445\n",
      "Validation loss: 0.5871661260114078 MAE: 134.09218\n",
      "169 1 0.2623724937438965\n",
      "169 51 0.2376013845205307\n",
      "169 101 0.28205883502960205\n",
      "169 151 0.4456655979156494\n",
      "Validation loss: 0.72214717997445 MAE: 164.91803\n",
      "170 30 0.23066860437393188\n",
      "170 80 0.29756295680999756\n",
      "170 130 0.44074466824531555\n",
      "Validation loss: 0.5740952017711617 MAE: 131.10713\n",
      "171 9 0.4713396430015564\n",
      "171 59 0.3861527442932129\n",
      "171 109 0.2504971921443939\n",
      "171 159 0.3010694682598114\n",
      "Validation loss: 0.6314632261705677 MAE: 144.20837\n",
      "172 38 0.29091984033584595\n",
      "172 88 0.18517345190048218\n",
      "172 138 0.3760468065738678\n",
      "Validation loss: 0.5318988453575045 MAE: 121.47068\n",
      "173 17 0.36918434500694275\n",
      "173 67 0.2848362624645233\n",
      "173 117 0.3478175699710846\n",
      "173 167 0.22105209529399872\n",
      "Validation loss: 0.659046371952135 MAE: 150.50758\n",
      "174 46 0.27458593249320984\n",
      "174 96 0.32263216376304626\n",
      "174 146 0.326107919216156\n",
      "Validation loss: 0.6852676795240034 MAE: 156.4958\n",
      "175 25 0.2301582247018814\n",
      "175 75 0.19066892564296722\n",
      "175 125 0.21903814375400543\n",
      "Validation loss: 0.481525554991605 MAE: 109.96684\n",
      "176 4 0.2801039218902588\n",
      "176 54 0.22196978330612183\n",
      "176 104 0.39090365171432495\n",
      "176 154 0.2946019768714905\n",
      "Validation loss: 0.550866777436775 MAE: 125.80243\n",
      "177 33 0.3158430755138397\n",
      "177 83 0.283779501914978\n",
      "177 133 0.25005728006362915\n",
      "Validation loss: 0.5794995493359036 MAE: 132.34132\n",
      "178 12 0.2538776099681854\n",
      "178 62 0.13038498163223267\n",
      "178 112 0.1980886161327362\n",
      "178 162 0.2748275399208069\n",
      "Validation loss: 0.7054555238338939 MAE: 161.10612\n",
      "179 41 0.29623615741729736\n",
      "179 91 0.23414698243141174\n",
      "179 141 0.28453508019447327\n",
      "Validation loss: 0.6312720137729979 MAE: 144.1647\n",
      "180 20 0.2874310612678528\n",
      "180 70 0.3469493091106415\n",
      "180 120 0.3026847541332245\n",
      "180 170 0.39245855808258057\n",
      "Validation loss: 0.6667666972032067 MAE: 152.27069\n",
      "181 49 0.15175609290599823\n",
      "181 99 0.3406525254249573\n",
      "181 149 0.4045831263065338\n",
      "Validation loss: 0.6985725554806447 MAE: 159.53426\n",
      "182 28 0.31720253825187683\n",
      "182 78 0.4790950119495392\n",
      "182 128 0.33648014068603516\n",
      "Validation loss: 0.6380746183339615 MAE: 145.71823\n",
      "183 7 0.2908925414085388\n",
      "183 57 0.2892841398715973\n",
      "183 107 0.2948703467845917\n",
      "183 157 0.33334600925445557\n",
      "Validation loss: 0.6496686872683073 MAE: 148.366\n",
      "184 36 0.30579715967178345\n",
      "184 86 0.3053566813468933\n",
      "184 136 0.33409759402275085\n",
      "Validation loss: 0.687401655124642 MAE: 156.98314\n",
      "185 15 0.2304074466228485\n",
      "185 65 0.3176079988479614\n",
      "185 115 0.17328503727912903\n",
      "185 165 0.2871244549751282\n",
      "Validation loss: 0.5449814622165167 MAE: 124.45838\n",
      "186 44 0.16576658189296722\n",
      "186 94 0.12564639747142792\n",
      "186 144 0.3907506465911865\n",
      "Validation loss: 0.5535704838602167 MAE: 126.419876\n",
      "187 23 0.30221202969551086\n",
      "187 73 0.26245176792144775\n",
      "187 123 0.38419824838638306\n",
      "Validation loss: 0.5974543181776303 MAE: 136.4417\n",
      "188 2 0.2406480610370636\n",
      "188 52 0.3923903703689575\n",
      "188 102 0.18537308275699615\n",
      "188 152 0.5601730346679688\n",
      "Validation loss: 0.5774671069362707 MAE: 131.87718\n",
      "189 31 0.21555805206298828\n",
      "189 81 0.2418263554573059\n",
      "189 131 0.3056023418903351\n",
      "Validation loss: 0.6311746103721753 MAE: 144.14247\n",
      "190 10 0.31014156341552734\n",
      "190 60 0.263028621673584\n",
      "190 110 0.2579994201660156\n",
      "190 160 0.37062522768974304\n",
      "Validation loss: 0.6180506826144213 MAE: 141.14532\n",
      "191 39 0.3203967809677124\n",
      "191 89 0.3811320960521698\n",
      "191 139 0.3471139967441559\n",
      "Validation loss: 0.7233110394394189 MAE: 165.18384\n",
      "192 18 0.2582346200942993\n",
      "192 68 0.2682477533817291\n",
      "192 118 0.40405526757240295\n",
      "192 168 0.23549456894397736\n",
      "Validation loss: 0.8012564238051922 MAE: 182.98436\n",
      "193 47 0.40607571601867676\n",
      "193 97 0.3465351164340973\n",
      "193 147 0.2098645269870758\n",
      "Validation loss: 0.5282250276783056 MAE: 120.63168\n",
      "194 26 0.2007065862417221\n",
      "194 76 0.286498486995697\n",
      "194 126 0.24726548790931702\n",
      "Validation loss: 0.5973093161108898 MAE: 136.40858\n",
      "195 5 0.2473849058151245\n",
      "195 55 0.2865392863750458\n",
      "195 105 0.31338486075401306\n",
      "195 155 0.3868374228477478\n",
      "Validation loss: 0.6120352215237088 MAE: 139.77158\n",
      "196 34 0.4239518940448761\n",
      "196 84 0.2589368224143982\n",
      "196 134 0.40343454480171204\n",
      "Validation loss: 0.6537626368260523 MAE: 149.30093\n",
      "197 13 0.2470075488090515\n",
      "197 63 0.29673075675964355\n",
      "197 113 0.205263152718544\n",
      "197 163 0.21211402118206024\n",
      "Validation loss: 0.6959514687632957 MAE: 158.93567\n",
      "198 42 0.18470963835716248\n",
      "198 92 0.3586781919002533\n",
      "198 142 0.44735217094421387\n",
      "Validation loss: 0.6589447758351153 MAE: 150.48439\n",
      "199 21 0.32025468349456787\n",
      "199 71 0.2228328436613083\n",
      "199 121 0.2080868035554886\n",
      "Validation loss: 0.6590816542419077 MAE: 150.51564\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.38523156057339636 Test MAE: 87.97601\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qm7', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 780, 'task': 'regression', 'data_path': 'data/qm7/qm7.csv', 'target': ['u0_atom']}}\n",
      "Running on: cuda:0\n",
      "6833\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/6833\n",
      "Generating scaffold 1000/6833\n",
      "Generating scaffold 2000/6833\n",
      "Generating scaffold 3000/6833\n",
      "Generating scaffold 4000/6833\n",
      "Generating scaffold 5000/6833\n",
      "Generating scaffold 6000/6833\n",
      "About to sort in scaffold sets\n",
      "tensor(-1553.3462) tensor(228.3718) torch.Size([5466, 1])\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.440119981765747\n",
      "0 50 0.6331618428230286\n",
      "0 100 0.5467590093612671\n",
      "0 150 0.5201300382614136\n",
      "Validation loss: 0.4787675637250755 MAE: 109.337\n",
      "1 29 0.6616401672363281\n",
      "1 79 0.5856489539146423\n",
      "1 129 0.5450233817100525\n",
      "Validation loss: 0.4307770293358474 MAE: 98.377304\n",
      "2 8 0.5190269947052002\n",
      "2 58 0.7239212393760681\n",
      "2 108 0.8426088690757751\n",
      "2 158 0.7547635436058044\n",
      "Validation loss: 0.6711978521960521 MAE: 153.28264\n",
      "3 37 0.3722993731498718\n",
      "3 87 0.42768022418022156\n",
      "3 137 0.5327537655830383\n",
      "Validation loss: 0.6801482086990311 MAE: 155.32664\n",
      "4 16 0.4760192334651947\n",
      "4 66 0.5003669261932373\n",
      "4 116 0.44807395339012146\n",
      "4 166 0.7081943154335022\n",
      "Validation loss: 0.8331303265359666 MAE: 190.26344\n",
      "5 45 0.5335903167724609\n",
      "5 95 0.49210792779922485\n",
      "5 145 0.4041467607021332\n",
      "Validation loss: 0.7729258387409456 MAE: 176.51445\n",
      "6 24 0.40569910407066345\n",
      "6 74 0.49245473742485046\n",
      "6 124 0.578427255153656\n",
      "Validation loss: 0.6802948333366573 MAE: 155.36014\n",
      "7 3 0.6453414559364319\n",
      "7 53 0.6484631896018982\n",
      "7 103 0.3391658663749695\n",
      "7 153 0.5699835419654846\n",
      "Validation loss: 0.816352963796136 MAE: 186.43198\n",
      "8 32 0.6022262573242188\n",
      "8 82 0.6142590045928955\n",
      "8 132 0.6499689817428589\n",
      "Validation loss: 0.7200074398029618 MAE: 164.42938\n",
      "9 11 0.5540637969970703\n",
      "9 61 0.5960900783538818\n",
      "9 111 0.31468045711517334\n",
      "9 161 0.3537027835845947\n",
      "Validation loss: 0.552386194293262 MAE: 126.14941\n",
      "10 40 0.6267277598381042\n",
      "10 90 0.6450276374816895\n",
      "10 140 0.6637469530105591\n",
      "Validation loss: 0.7153925383300112 MAE: 163.37547\n",
      "11 19 0.5872214436531067\n",
      "11 69 0.3840769827365875\n",
      "11 119 0.7507646083831787\n",
      "11 169 0.7627124190330505\n",
      "Validation loss: 0.5096948000422695 MAE: 116.399925\n",
      "12 48 0.5201047658920288\n",
      "12 98 0.6804370284080505\n",
      "12 148 0.32103314995765686\n",
      "Validation loss: 0.8176459182075589 MAE: 186.72725\n",
      "13 27 0.3550548851490021\n",
      "13 77 0.6136406064033508\n",
      "13 127 0.4800252616405487\n",
      "Validation loss: 0.8708026632230882 MAE: 198.86673\n",
      "14 6 0.3924427628517151\n",
      "14 56 0.4816882908344269\n",
      "14 106 0.3719065487384796\n",
      "14 156 0.38824155926704407\n",
      "Validation loss: 0.6878753994640551 MAE: 157.09132\n",
      "15 35 0.4372571110725403\n",
      "15 85 0.5693843364715576\n",
      "15 135 0.5700096487998962\n",
      "Validation loss: 0.4392234569753123 MAE: 100.306244\n",
      "16 14 0.47702205181121826\n",
      "16 64 0.31872108578681946\n",
      "16 114 0.6514681577682495\n",
      "16 164 0.5543954968452454\n",
      "Validation loss: 0.46549081959222494 MAE: 106.30496\n",
      "17 43 0.5444604158401489\n",
      "17 93 0.4072906970977783\n",
      "17 143 0.32017064094543457\n",
      "Validation loss: 0.5900663447658918 MAE: 134.7545\n",
      "18 22 0.4345870614051819\n",
      "18 72 0.41191625595092773\n",
      "18 122 0.4194987714290619\n",
      "Validation loss: 0.5895796826011256 MAE: 134.64337\n",
      "19 1 0.44296780228614807\n",
      "19 51 0.30735257267951965\n",
      "19 101 0.34414049983024597\n",
      "19 151 0.3596078157424927\n",
      "Validation loss: 0.4498958904840793 MAE: 102.74352\n",
      "20 30 0.47181203961372375\n",
      "20 80 0.4573766589164734\n",
      "20 130 0.3476361036300659\n",
      "Validation loss: 0.48148824161256265 MAE: 109.95832\n",
      "21 9 0.5561937093734741\n",
      "21 59 0.4298588037490845\n",
      "21 109 0.36855629086494446\n",
      "21 159 0.42430105805397034\n",
      "Validation loss: 0.4887308056591547 MAE: 111.61232\n",
      "22 38 0.4328163266181946\n",
      "22 88 0.4039877653121948\n",
      "22 138 0.5830860137939453\n",
      "Validation loss: 0.5017878514284279 MAE: 114.594185\n",
      "23 17 0.4357396960258484\n",
      "23 67 0.3147178292274475\n",
      "23 117 0.5626474618911743\n",
      "23 167 0.37679609656333923\n",
      "Validation loss: 0.4424112168146156 MAE: 101.03424\n",
      "24 46 0.44992831349372864\n",
      "24 96 0.4431537389755249\n",
      "24 146 0.45484447479248047\n",
      "Validation loss: 0.5584408473550228 MAE: 127.53213\n",
      "25 25 0.5155198574066162\n",
      "25 75 0.4964912533760071\n",
      "25 125 0.5143311619758606\n",
      "Validation loss: 0.5383722405684622 MAE: 122.94903\n",
      "26 4 0.4966922104358673\n",
      "26 54 0.3920014500617981\n",
      "26 104 0.4594184458255768\n",
      "26 154 0.5113623142242432\n",
      "Validation loss: 0.5564114967284844 MAE: 127.06869\n",
      "27 33 0.43763071298599243\n",
      "27 83 0.5755969285964966\n",
      "27 133 0.4760885536670685\n",
      "Validation loss: 0.46828515104383056 MAE: 106.94311\n",
      "28 12 0.3986909091472626\n",
      "28 62 0.36045390367507935\n",
      "28 112 0.5621534585952759\n",
      "28 162 0.2415509819984436\n",
      "Validation loss: 0.6463664404132909 MAE: 147.61185\n",
      "29 41 0.36781349778175354\n",
      "29 91 0.5677672028541565\n",
      "29 141 0.4639628231525421\n",
      "Validation loss: 0.634584095045837 MAE: 144.92108\n",
      "30 20 0.4297265112400055\n",
      "30 70 0.49040424823760986\n",
      "30 120 0.3247826397418976\n",
      "30 170 0.41501370072364807\n",
      "Validation loss: 0.7580765356794436 MAE: 173.12329\n",
      "31 49 0.4060378670692444\n",
      "31 99 0.26853081583976746\n",
      "31 149 0.3661145269870758\n",
      "Validation loss: 0.46432472965870686 MAE: 106.038666\n",
      "32 28 0.4437493085861206\n",
      "32 78 0.3361099362373352\n",
      "32 128 0.3519836366176605\n",
      "Validation loss: 0.4911454640633879 MAE: 112.163765\n",
      "33 7 0.3454732894897461\n",
      "33 57 0.2979556620121002\n",
      "33 107 0.42859551310539246\n",
      "33 157 0.4458891749382019\n",
      "Validation loss: 0.5209687815772163 MAE: 118.974556\n",
      "34 36 0.4664851129055023\n",
      "34 86 0.4753401279449463\n",
      "34 136 0.39148634672164917\n",
      "Validation loss: 0.6602672404713101 MAE: 150.78639\n",
      "35 15 0.3753364682197571\n",
      "35 65 0.44009771943092346\n",
      "35 115 0.448154479265213\n",
      "35 165 0.5290131568908691\n",
      "Validation loss: 0.5103202179858559 MAE: 116.54274\n",
      "36 44 0.3676779270172119\n",
      "36 94 0.4113922417163849\n",
      "36 144 0.36481398344039917\n",
      "Validation loss: 0.4794125124724985 MAE: 109.48428\n",
      "37 23 0.5117858648300171\n",
      "37 73 0.3557617664337158\n",
      "37 123 0.2985491454601288\n",
      "Validation loss: 0.4711147869190975 MAE: 107.58932\n",
      "38 2 0.3995581865310669\n",
      "38 52 0.46726807951927185\n",
      "38 102 0.46749040484428406\n",
      "38 152 0.4706234633922577\n",
      "Validation loss: 0.6880660057067871 MAE: 157.13484\n",
      "39 31 0.34165412187576294\n",
      "39 81 0.3321978747844696\n",
      "39 131 0.288772851228714\n",
      "Validation loss: 0.6682421934534932 MAE: 152.60767\n",
      "40 10 0.5090802907943726\n",
      "40 60 0.4404699504375458\n",
      "40 110 0.37089860439300537\n",
      "40 160 0.5653926134109497\n",
      "Validation loss: 0.6653193151741698 MAE: 151.94016\n",
      "41 39 0.40366092324256897\n",
      "41 89 0.3060974180698395\n",
      "41 139 0.30153462290763855\n",
      "Validation loss: 0.4586298955462829 MAE: 104.73812\n",
      "42 18 0.3799940049648285\n",
      "42 68 0.47582146525382996\n",
      "42 118 0.4273892641067505\n",
      "42 168 0.37849679589271545\n",
      "Validation loss: 0.5580033555365446 MAE: 127.43221\n",
      "43 47 0.4457243084907532\n",
      "43 97 0.3244617283344269\n",
      "43 147 0.32506781816482544\n",
      "Validation loss: 0.507658090507775 MAE: 115.934784\n",
      "44 26 0.48644566535949707\n",
      "44 76 0.3813166916370392\n",
      "44 126 0.3840116858482361\n",
      "Validation loss: 0.42809157064783643 MAE: 97.76402\n",
      "45 5 0.62978595495224\n",
      "45 55 0.2432340383529663\n",
      "45 105 0.4769120216369629\n",
      "45 155 0.5187025666236877\n",
      "Validation loss: 0.635546947083278 MAE: 145.14099\n",
      "46 34 0.3228859007358551\n",
      "46 84 0.42926135659217834\n",
      "46 134 0.28717416524887085\n",
      "Validation loss: 0.5669996717519927 MAE: 129.48672\n",
      "47 13 0.383181095123291\n",
      "47 63 0.2960587441921234\n",
      "47 113 0.5151223540306091\n",
      "47 163 0.3355780839920044\n",
      "Validation loss: 0.48800988782916155 MAE: 111.44768\n",
      "48 42 0.35163354873657227\n",
      "48 92 0.361672580242157\n",
      "48 142 0.44310128688812256\n",
      "Validation loss: 0.43750434050783077 MAE: 99.91364\n",
      "49 21 0.4112631678581238\n",
      "49 71 0.59566730260849\n",
      "49 121 0.37009161710739136\n",
      "Validation loss: 0.562617606238315 MAE: 128.486\n",
      "50 0 0.38298776745796204\n",
      "50 50 0.416016161441803\n",
      "50 100 0.38320887088775635\n",
      "50 150 0.2912542223930359\n",
      "Validation loss: 0.5408027301057737 MAE: 123.50407\n",
      "51 29 0.2823439836502075\n",
      "51 79 0.4358710050582886\n",
      "51 129 0.3352392911911011\n",
      "Validation loss: 0.5309195277983683 MAE: 121.24703\n",
      "52 8 0.300078809261322\n",
      "52 58 0.3894709646701813\n",
      "52 108 0.47755035758018494\n",
      "52 158 0.48144853115081787\n",
      "Validation loss: 0.585573376967893 MAE: 133.72844\n",
      "53 37 0.4185335636138916\n",
      "53 87 0.3921368718147278\n",
      "53 137 0.35519862174987793\n",
      "Validation loss: 0.5689747420667904 MAE: 129.93777\n",
      "54 16 0.2918294072151184\n",
      "54 66 0.4394068717956543\n",
      "54 116 0.3934558033943176\n",
      "54 166 0.3205353915691376\n",
      "Validation loss: 0.5269628313549778 MAE: 120.34343\n",
      "55 45 0.29591888189315796\n",
      "55 95 0.4518306851387024\n",
      "55 145 0.40156471729278564\n",
      "Validation loss: 0.5970658572793704 MAE: 136.35298\n",
      "56 24 0.31356629729270935\n",
      "56 74 0.38758471608161926\n",
      "56 124 0.3868555724620819\n",
      "Validation loss: 0.584055613356027 MAE: 133.3818\n",
      "57 3 0.3091343641281128\n",
      "57 53 0.34974080324172974\n",
      "57 103 0.33788439631462097\n",
      "57 153 0.34174343943595886\n",
      "Validation loss: 0.792191427702095 MAE: 180.91415\n",
      "58 32 0.41025757789611816\n",
      "58 82 0.2961733937263489\n",
      "58 132 0.48437613248825073\n",
      "Validation loss: 0.5381787555259571 MAE: 122.90483\n",
      "59 11 0.27486687898635864\n",
      "59 61 0.3521887958049774\n",
      "59 111 0.41981253027915955\n",
      "59 161 0.25604528188705444\n",
      "Validation loss: 0.5344202020014935 MAE: 122.0465\n",
      "60 40 0.38877376914024353\n",
      "60 90 0.2539556324481964\n",
      "60 140 0.3236236870288849\n",
      "Validation loss: 0.5200697438061586 MAE: 118.76926\n",
      "61 19 0.39488109946250916\n",
      "61 69 0.2992607355117798\n",
      "61 119 0.34928375482559204\n",
      "61 169 0.33314409852027893\n",
      "Validation loss: 0.47650542890119274 MAE: 108.82038\n",
      "62 48 0.292861670255661\n",
      "62 98 0.3280240595340729\n",
      "62 148 0.3518417477607727\n",
      "Validation loss: 0.585262840254265 MAE: 133.6575\n",
      "63 27 0.4723525047302246\n",
      "63 77 0.5562554001808167\n",
      "63 127 0.29010313749313354\n",
      "Validation loss: 0.5294998627134234 MAE: 120.92281\n",
      "64 6 0.3892561197280884\n",
      "64 56 0.4272811710834503\n",
      "64 106 0.587006151676178\n",
      "64 156 0.37054044008255005\n",
      "Validation loss: 0.6214381425004256 MAE: 141.91893\n",
      "65 35 0.4345749318599701\n",
      "65 85 0.4533715546131134\n",
      "65 135 0.2321183681488037\n",
      "Validation loss: 0.6397180721076609 MAE: 146.09355\n",
      "66 14 0.22710780799388885\n",
      "66 64 0.37745827436447144\n",
      "66 114 0.36966952681541443\n",
      "66 164 0.32724082469940186\n",
      "Validation loss: 0.6843810559016222 MAE: 156.2933\n",
      "67 43 0.37950819730758667\n",
      "67 93 0.2983432710170746\n",
      "67 143 0.253697007894516\n",
      "Validation loss: 0.5544867714246114 MAE: 126.62912\n",
      "68 22 0.2019350379705429\n",
      "68 72 0.3382633626461029\n",
      "68 122 0.31934037804603577\n",
      "Validation loss: 0.6100779322155735 MAE: 139.32458\n",
      "69 1 0.2920907735824585\n",
      "69 51 0.31447461247444153\n",
      "69 101 0.3063163757324219\n",
      "69 151 0.2956157624721527\n",
      "Validation loss: 0.53535428399231 MAE: 122.259796\n",
      "70 30 0.3888435661792755\n",
      "70 80 0.2808803617954254\n",
      "70 130 0.32366350293159485\n",
      "Validation loss: 0.5980859437184027 MAE: 136.58594\n",
      "71 9 0.30825433135032654\n",
      "71 59 0.5404800772666931\n",
      "71 109 0.45113375782966614\n",
      "71 159 0.3648463189601898\n",
      "Validation loss: 0.6730755687805644 MAE: 153.71147\n",
      "72 38 0.28282666206359863\n",
      "72 88 0.3170304298400879\n",
      "72 138 0.28602901101112366\n",
      "Validation loss: 0.49173053698233 MAE: 112.29738\n",
      "73 17 0.4248499274253845\n",
      "73 67 0.32895198464393616\n",
      "73 117 0.239545077085495\n",
      "73 167 0.3539384603500366\n",
      "Validation loss: 0.5626435502927903 MAE: 128.49191\n",
      "74 46 0.35608527064323425\n",
      "74 96 0.3063083291053772\n",
      "74 146 0.30842578411102295\n",
      "Validation loss: 0.5608568799774549 MAE: 128.08388\n",
      "75 25 0.48468953371047974\n",
      "75 75 0.4274439513683319\n",
      "75 125 0.3122851848602295\n",
      "Validation loss: 0.6185239053260513 MAE: 141.2534\n",
      "76 4 0.4582503139972687\n",
      "76 54 0.31235212087631226\n",
      "76 104 0.5489479303359985\n",
      "76 154 0.28053292632102966\n",
      "Validation loss: 0.6434801297578198 MAE: 146.9527\n",
      "77 33 0.25826871395111084\n",
      "77 83 0.2995453178882599\n",
      "77 133 0.5432472229003906\n",
      "Validation loss: 0.5793470220956188 MAE: 132.30652\n",
      "78 12 0.4772225022315979\n",
      "78 62 0.3160809278488159\n",
      "78 112 0.46248185634613037\n",
      "78 162 0.24786436557769775\n",
      "Validation loss: 0.6011793327610395 MAE: 137.29239\n",
      "79 41 0.3109373152256012\n",
      "79 91 0.32958972454071045\n",
      "79 141 0.30706271529197693\n",
      "Validation loss: 0.6755876352912501 MAE: 154.28514\n",
      "80 20 0.4274100363254547\n",
      "80 70 0.4058396816253662\n",
      "80 120 0.27805760502815247\n",
      "80 170 0.24680596590042114\n",
      "Validation loss: 0.6009207639777869 MAE: 137.23334\n",
      "81 49 0.34744521975517273\n",
      "81 99 0.3954121768474579\n",
      "81 149 0.2773202955722809\n",
      "Validation loss: 0.6913418745436863 MAE: 157.88297\n",
      "82 28 0.32982781529426575\n",
      "82 78 0.4153456687927246\n",
      "82 128 0.2542467415332794\n",
      "Validation loss: 0.5239763001949467 MAE: 119.66139\n",
      "83 7 0.24203021824359894\n",
      "83 57 0.38935115933418274\n",
      "83 107 0.39238643646240234\n",
      "83 157 0.30923911929130554\n",
      "Validation loss: 0.5899415751646834 MAE: 134.726\n",
      "84 36 0.2602529227733612\n",
      "84 86 0.3945083022117615\n",
      "84 136 0.28518185019493103\n",
      "Validation loss: 0.6088764702367504 MAE: 139.0502\n",
      "85 15 0.26795709133148193\n",
      "85 65 0.34416860342025757\n",
      "85 115 0.29345762729644775\n",
      "85 165 0.3419747054576874\n",
      "Validation loss: 0.4828666791929836 MAE: 110.27312\n",
      "86 44 0.32386061549186707\n",
      "86 94 0.3249850273132324\n",
      "86 144 0.4208676517009735\n",
      "Validation loss: 0.5208897856418152 MAE: 118.95653\n",
      "87 23 0.3788371980190277\n",
      "87 73 0.29355818033218384\n",
      "87 123 0.43842586874961853\n",
      "Validation loss: 0.544946673320748 MAE: 124.45044\n",
      "88 2 0.41182219982147217\n",
      "88 52 0.25783830881118774\n",
      "88 102 0.3738822042942047\n",
      "88 152 0.3677094876766205\n",
      "Validation loss: 0.5945153006336146 MAE: 135.77051\n",
      "89 31 0.2208990603685379\n",
      "89 81 0.3946821987628937\n",
      "89 131 0.38018080592155457\n",
      "Validation loss: 0.5661433830595853 MAE: 129.29117\n",
      "90 10 0.4136936366558075\n",
      "90 60 0.36770299077033997\n",
      "90 110 0.38656845688819885\n",
      "90 160 0.5077992677688599\n",
      "Validation loss: 0.58164473060976 MAE: 132.83124\n",
      "91 39 0.3167288303375244\n",
      "91 89 0.326788067817688\n",
      "91 139 0.327321857213974\n",
      "Validation loss: 0.5460287538188243 MAE: 124.69755\n",
      "92 18 0.4881548285484314\n",
      "92 68 0.4181087017059326\n",
      "92 118 0.5051793456077576\n",
      "92 168 0.23753739893436432\n",
      "Validation loss: 0.5537969424710636 MAE: 126.47158\n",
      "93 47 0.2952306866645813\n",
      "93 97 0.28254419565200806\n",
      "93 147 0.545536458492279\n",
      "Validation loss: 0.6684682390146088 MAE: 152.65927\n",
      "94 26 0.5452702045440674\n",
      "94 76 0.2537759840488434\n",
      "94 126 0.4272160232067108\n",
      "Validation loss: 0.8109316714325844 MAE: 185.19391\n",
      "95 5 0.18517133593559265\n",
      "95 55 0.39032885432243347\n",
      "95 105 0.43395712971687317\n",
      "95 155 0.3074873089790344\n",
      "Validation loss: 0.4970725741651323 MAE: 113.51734\n",
      "96 34 0.43931257724761963\n",
      "96 84 0.4052439033985138\n",
      "96 134 0.194676011800766\n",
      "Validation loss: 0.8657540340869747 MAE: 197.71379\n",
      "97 13 0.2909834682941437\n",
      "97 63 0.22493334114551544\n",
      "97 113 0.5813058018684387\n",
      "97 163 0.3900532126426697\n",
      "Validation loss: 0.8048944445381387 MAE: 183.81517\n",
      "98 42 0.5456392765045166\n",
      "98 92 0.3519990146160126\n",
      "98 142 0.3585500121116638\n",
      "Validation loss: 0.49590783021603413 MAE: 113.25136\n",
      "99 21 0.4685300588607788\n",
      "99 71 0.3656693398952484\n",
      "99 121 0.4302873909473419\n",
      "Validation loss: 0.6647848169706021 MAE: 151.81808\n",
      "100 0 0.4002150893211365\n",
      "100 50 0.24731552600860596\n",
      "100 100 0.21029245853424072\n",
      "100 150 0.38213619589805603\n",
      "Validation loss: 0.7402330992514627 MAE: 169.04836\n",
      "101 29 0.22696848213672638\n",
      "101 79 0.2933574914932251\n",
      "101 129 0.3562832176685333\n",
      "Validation loss: 0.6960756573063588 MAE: 158.96404\n",
      "102 8 0.1987537443637848\n",
      "102 58 0.33666521310806274\n",
      "102 108 0.38033396005630493\n",
      "102 158 0.32300376892089844\n",
      "Validation loss: 0.4901373051760489 MAE: 111.933525\n",
      "103 37 0.2595245838165283\n",
      "103 87 0.2951146960258484\n",
      "103 137 0.2830754220485687\n",
      "Validation loss: 0.6851164642830341 MAE: 156.46126\n",
      "104 16 0.3730465769767761\n",
      "104 66 0.38627633452415466\n",
      "104 116 0.3950903117656708\n",
      "104 166 0.26372113823890686\n",
      "Validation loss: 0.5319256350310922 MAE: 121.47679\n",
      "105 45 0.26545488834381104\n",
      "105 95 0.4305212199687958\n",
      "105 145 0.384983628988266\n",
      "Validation loss: 0.6908988666813276 MAE: 157.7818\n",
      "106 24 0.2766864597797394\n",
      "106 74 0.42886871099472046\n",
      "106 124 0.4002354145050049\n",
      "Validation loss: 0.6037292919660869 MAE: 137.87473\n",
      "107 3 0.25464969873428345\n",
      "107 53 0.44384288787841797\n",
      "107 103 0.4072783589363098\n",
      "107 153 0.3477676212787628\n",
      "Validation loss: 0.6160762473853708 MAE: 140.69443\n",
      "108 32 0.429461270570755\n",
      "108 82 0.27810680866241455\n",
      "108 132 0.3456892669200897\n",
      "Validation loss: 0.6316112733026694 MAE: 144.24219\n",
      "109 11 0.48217707872390747\n",
      "109 61 0.275366872549057\n",
      "109 111 0.4948630630970001\n",
      "109 161 0.2409995198249817\n",
      "Validation loss: 0.6945540769058361 MAE: 158.61655\n",
      "110 40 0.31749671697616577\n",
      "110 90 0.2685971260070801\n",
      "110 140 0.34953537583351135\n",
      "Validation loss: 0.6968156235259876 MAE: 159.13303\n",
      "111 19 0.37068259716033936\n",
      "111 69 0.2340744286775589\n",
      "111 119 0.38434019684791565\n",
      "111 169 0.23973989486694336\n",
      "Validation loss: 0.7222297463500709 MAE: 164.93689\n",
      "112 48 0.23277750611305237\n",
      "112 98 0.432587593793869\n",
      "112 148 0.3159451484680176\n",
      "Validation loss: 0.6538698146914879 MAE: 149.32541\n",
      "113 27 0.3100038766860962\n",
      "113 77 0.42494821548461914\n",
      "113 127 0.21029964089393616\n",
      "Validation loss: 0.6522501219085782 MAE: 148.9555\n",
      "114 6 0.1775234341621399\n",
      "114 56 0.2975216507911682\n",
      "114 106 0.29793161153793335\n",
      "114 156 0.37913641333580017\n",
      "Validation loss: 0.562216531812099 MAE: 128.3944\n",
      "115 35 0.2994272708892822\n",
      "115 85 0.3523475229740143\n",
      "115 135 0.2766980230808258\n",
      "Validation loss: 0.5755128658305831 MAE: 131.4309\n",
      "116 14 0.2792624533176422\n",
      "116 64 0.25752928853034973\n",
      "116 114 0.26024237275123596\n",
      "116 164 0.2743094861507416\n",
      "Validation loss: 0.6549538980450547 MAE: 149.57298\n",
      "117 43 0.6258304715156555\n",
      "117 93 0.2435040920972824\n",
      "117 143 0.4369480609893799\n",
      "Validation loss: 0.5956099361006977 MAE: 136.0205\n",
      "118 22 0.24702727794647217\n",
      "118 72 0.1835121363401413\n",
      "118 122 0.24500729143619537\n",
      "Validation loss: 0.7139404705393384 MAE: 163.04385\n",
      "119 1 0.4008494019508362\n",
      "119 51 0.36560603976249695\n",
      "119 101 0.29320424795150757\n",
      "119 151 0.23668000102043152\n",
      "Validation loss: 0.6589811608108164 MAE: 150.49269\n",
      "120 30 0.437019020318985\n",
      "120 80 0.2554970681667328\n",
      "120 130 0.29972055554389954\n",
      "Validation loss: 0.6617767887505871 MAE: 151.13115\n",
      "121 9 0.33976244926452637\n",
      "121 59 0.3186427056789398\n",
      "121 109 0.3019416332244873\n",
      "121 159 0.27056771516799927\n",
      "Validation loss: 0.6566037448526126 MAE: 149.94977\n",
      "122 38 0.43595775961875916\n",
      "122 88 0.3165706992149353\n",
      "122 138 0.36727648973464966\n",
      "Validation loss: 0.7207781937387254 MAE: 164.60541\n",
      "123 17 0.39578965306282043\n",
      "123 67 0.26980090141296387\n",
      "123 117 0.3837036192417145\n",
      "123 167 0.3639037311077118\n",
      "Validation loss: 0.5297545776729695 MAE: 120.980995\n",
      "124 46 0.33880242705345154\n",
      "124 96 0.20101423561573029\n",
      "124 146 0.3236869275569916\n",
      "Validation loss: 0.5866795980442338 MAE: 133.98106\n",
      "125 25 0.19358091056346893\n",
      "125 75 0.34664684534072876\n",
      "125 125 0.2181069254875183\n",
      "Validation loss: 0.5273263025702092 MAE: 120.426445\n",
      "126 4 0.2190222591161728\n",
      "126 54 0.3613225221633911\n",
      "126 104 0.3147735297679901\n",
      "126 154 0.31687384843826294\n",
      "Validation loss: 0.7441145258340222 MAE: 169.93475\n",
      "127 33 0.4702209532260895\n",
      "127 83 0.39292243123054504\n",
      "127 133 0.27641886472702026\n",
      "Validation loss: 0.7196557410279213 MAE: 164.34906\n",
      "128 12 0.3111724257469177\n",
      "128 62 0.24839256703853607\n",
      "128 112 0.15925180912017822\n",
      "128 162 0.25967520475387573\n",
      "Validation loss: 0.7327351263392041 MAE: 167.33603\n",
      "129 41 0.3063676357269287\n",
      "129 91 0.26682689785957336\n",
      "129 141 0.38247618079185486\n",
      "Validation loss: 0.6530429386256034 MAE: 149.13657\n",
      "130 20 0.3527728021144867\n",
      "130 70 0.47231683135032654\n",
      "130 120 0.297742635011673\n",
      "130 170 0.18206802010536194\n",
      "Validation loss: 0.7106859799016986 MAE: 162.30063\n",
      "131 49 0.5757820010185242\n",
      "131 99 0.30549705028533936\n",
      "131 149 0.2762663662433624\n",
      "Validation loss: 0.6468107313440558 MAE: 147.71332\n",
      "132 28 0.29231777787208557\n",
      "132 78 0.2332981824874878\n",
      "132 128 0.341830313205719\n",
      "Validation loss: 0.7804915828314442 MAE: 178.24225\n",
      "133 7 0.3143869936466217\n",
      "133 57 0.42775532603263855\n",
      "133 107 0.43227171897888184\n",
      "133 157 0.3178441822528839\n",
      "Validation loss: 0.7243223992007518 MAE: 165.41478\n",
      "134 36 0.4066890776157379\n",
      "134 86 0.3473198413848877\n",
      "134 136 0.2799980044364929\n",
      "Validation loss: 0.7119430955390484 MAE: 162.58772\n",
      "135 15 0.3070526123046875\n",
      "135 65 0.4370351731777191\n",
      "135 115 0.42294055223464966\n",
      "135 165 0.31642818450927734\n",
      "Validation loss: 0.6641887977109318 MAE: 151.68198\n",
      "136 44 0.26865243911743164\n",
      "136 94 0.402927428483963\n",
      "136 144 0.42936840653419495\n",
      "Validation loss: 0.7754033469317252 MAE: 177.08023\n",
      "137 23 0.23450429737567902\n",
      "137 73 0.28368085622787476\n",
      "137 123 0.30258581042289734\n",
      "Validation loss: 0.6270109564937346 MAE: 143.1916\n",
      "138 2 0.3951772153377533\n",
      "138 52 0.46079882979393005\n",
      "138 102 0.29513320326805115\n",
      "138 152 0.3495227098464966\n",
      "Validation loss: 0.7345201219731604 MAE: 167.74367\n",
      "139 31 0.30292391777038574\n",
      "139 81 0.2352173626422882\n",
      "139 131 0.3337096869945526\n",
      "Validation loss: 0.7652898605106867 MAE: 174.7706\n",
      "140 10 0.19387522339820862\n",
      "140 60 0.4171583950519562\n",
      "140 110 0.2562877833843231\n",
      "140 160 0.3137193024158478\n",
      "Validation loss: 0.7308334035483021 MAE: 166.90173\n",
      "141 39 0.3015994131565094\n",
      "141 89 0.5571557283401489\n",
      "141 139 0.24861060082912445\n",
      "Validation loss: 0.8158731125948722 MAE: 186.32239\n",
      "142 18 0.2972997725009918\n",
      "142 68 0.18722626566886902\n",
      "142 118 0.5446748733520508\n",
      "142 168 0.3325560390949249\n",
      "Validation loss: 0.6841893084565102 MAE: 156.24953\n",
      "143 47 0.28132525086402893\n",
      "143 97 0.3364395797252655\n",
      "143 147 0.3171418309211731\n",
      "Validation loss: 0.70244202279208 MAE: 160.41795\n",
      "144 26 0.3915797770023346\n",
      "144 76 0.19172725081443787\n",
      "144 126 0.20684583485126495\n",
      "Validation loss: 0.7740448120741816 MAE: 176.77\n",
      "145 5 0.31288790702819824\n",
      "145 55 0.27295318245887756\n",
      "145 105 0.3288300335407257\n",
      "145 155 0.1942066103219986\n",
      "Validation loss: 0.6757479201980502 MAE: 154.32175\n",
      "146 34 0.3367248773574829\n",
      "146 84 0.28376609086990356\n",
      "146 134 0.16117382049560547\n",
      "Validation loss: 0.6291934328469616 MAE: 143.69002\n",
      "147 13 0.35588929057121277\n",
      "147 63 0.2983490228652954\n",
      "147 113 0.35136207938194275\n",
      "147 163 0.2958580553531647\n",
      "Validation loss: 0.7045612826681974 MAE: 160.90192\n",
      "148 42 0.3959670960903168\n",
      "148 92 0.3024154007434845\n",
      "148 142 0.31662261486053467\n",
      "Validation loss: 0.6670179736544515 MAE: 152.32808\n",
      "149 21 0.4609569311141968\n",
      "149 71 0.3271558880805969\n",
      "149 121 0.44971194863319397\n",
      "Validation loss: 0.6921700469234533 MAE: 158.0721\n",
      "150 0 0.2557116448879242\n",
      "150 50 0.3561148941516876\n",
      "150 100 0.19835340976715088\n",
      "150 150 0.35610252618789673\n",
      "Validation loss: 0.7422048648198446 MAE: 169.49864\n",
      "151 29 0.29998695850372314\n",
      "151 79 0.604914128780365\n",
      "151 129 0.36274591088294983\n",
      "Validation loss: 0.6926983539123981 MAE: 158.19275\n",
      "152 8 0.4002704620361328\n",
      "152 58 0.3256279230117798\n",
      "152 108 0.37958598136901855\n",
      "152 158 0.33845254778862\n",
      "Validation loss: 0.620977100573088 MAE: 141.81364\n",
      "153 37 0.24944446980953217\n",
      "153 87 0.31579524278640747\n",
      "153 137 0.47900477051734924\n",
      "Validation loss: 0.6115893055821022 MAE: 139.66972\n",
      "154 16 0.32744714617729187\n",
      "154 66 0.4025075435638428\n",
      "154 116 0.24145068228244781\n",
      "154 166 0.43046411871910095\n",
      "Validation loss: 0.7717178683531912 MAE: 176.23857\n",
      "155 45 0.2669386863708496\n",
      "155 95 0.32827597856521606\n",
      "155 145 0.3780535161495209\n",
      "Validation loss: 0.5594440196689806 MAE: 127.76123\n",
      "156 24 0.2550524175167084\n",
      "156 74 0.2884209454059601\n",
      "156 124 0.3121570646762848\n",
      "Validation loss: 0.6413144664457667 MAE: 146.45811\n",
      "157 3 0.24244166910648346\n",
      "157 53 0.31596770882606506\n",
      "157 103 0.2982327342033386\n",
      "157 153 0.30114248394966125\n",
      "Validation loss: 0.8131647613662029 MAE: 185.70387\n",
      "158 32 0.2883220911026001\n",
      "158 82 0.11334599554538727\n",
      "158 132 0.3066725730895996\n",
      "Validation loss: 0.7113848868866413 MAE: 162.46024\n",
      "159 11 0.2765759527683258\n",
      "159 61 0.2211960405111313\n",
      "159 111 0.16385087370872498\n",
      "159 161 0.17729198932647705\n",
      "Validation loss: 0.672407213010286 MAE: 153.55882\n",
      "160 40 0.28543367981910706\n",
      "160 90 0.35354286432266235\n",
      "160 140 0.2157765030860901\n",
      "Validation loss: 0.7923326603850426 MAE: 180.94643\n",
      "161 19 0.35606566071510315\n",
      "161 69 0.38052982091903687\n",
      "161 119 0.4323086142539978\n",
      "161 169 0.4297321140766144\n",
      "Validation loss: 0.6578352430410552 MAE: 150.231\n",
      "162 48 0.2645653784275055\n",
      "162 98 0.20990750193595886\n",
      "162 148 0.20658059418201447\n",
      "Validation loss: 0.7499639827605576 MAE: 171.27061\n",
      "163 27 0.3890792429447174\n",
      "163 77 0.1701541692018509\n",
      "163 127 0.21419553458690643\n",
      "Validation loss: 0.7582204387201901 MAE: 173.15614\n",
      "164 6 0.17548538744449615\n",
      "164 56 0.4158937335014343\n",
      "164 106 0.35047563910484314\n",
      "164 156 0.21038483083248138\n",
      "Validation loss: 0.5941321811480829 MAE: 135.68303\n",
      "165 35 0.2975125312805176\n",
      "165 85 0.23472805321216583\n",
      "165 135 0.2463332712650299\n",
      "Validation loss: 0.5801440749252051 MAE: 132.48853\n",
      "166 14 0.2472308874130249\n",
      "166 64 0.283508837223053\n",
      "166 114 0.23425674438476562\n",
      "166 164 0.17618054151535034\n",
      "Validation loss: 0.6942271419435914 MAE: 158.5419\n",
      "167 43 0.3102880120277405\n",
      "167 93 0.18136277794837952\n",
      "167 143 0.18849880993366241\n",
      "Validation loss: 0.6108826315193846 MAE: 139.50835\n",
      "168 22 0.24452437460422516\n",
      "168 72 0.2874782979488373\n",
      "168 122 0.3172285258769989\n",
      "Validation loss: 0.6112142194781387 MAE: 139.58408\n",
      "169 1 0.25337594747543335\n",
      "169 51 0.24807369709014893\n",
      "169 101 0.30886828899383545\n",
      "169 151 0.2722457945346832\n",
      "Validation loss: 0.5650400020922833 MAE: 129.0392\n",
      "170 30 0.3234541118144989\n",
      "170 80 0.3511980175971985\n",
      "170 130 0.3522654175758362\n",
      "Validation loss: 0.6069572933933192 MAE: 138.61191\n",
      "171 9 0.33446308970451355\n",
      "171 59 0.13122977316379547\n",
      "171 109 0.26921215653419495\n",
      "171 159 0.3129010498523712\n",
      "Validation loss: 0.6241277135603609 MAE: 142.53314\n",
      "172 38 0.296357661485672\n",
      "172 88 0.1705390214920044\n",
      "172 138 0.303200364112854\n",
      "Validation loss: 0.7917546950585661 MAE: 180.81442\n",
      "173 17 0.2892224192619324\n",
      "173 67 0.2232784628868103\n",
      "173 117 0.26133066415786743\n",
      "173 167 0.3311900496482849\n",
      "Validation loss: 0.6672734532788483 MAE: 152.38643\n",
      "174 46 0.3060453236103058\n",
      "174 96 0.3221109211444855\n",
      "174 146 0.19997438788414001\n",
      "Validation loss: 0.641614898603562 MAE: 146.52673\n",
      "175 25 0.36891672015190125\n",
      "175 75 0.22394895553588867\n",
      "175 125 0.40086981654167175\n",
      "Validation loss: 0.6563630940621359 MAE: 149.8948\n",
      "176 4 0.31255242228507996\n",
      "176 54 0.224750354886055\n",
      "176 104 0.19046688079833984\n",
      "176 154 0.20878438651561737\n",
      "Validation loss: 0.6204381867458946 MAE: 141.69057\n",
      "177 33 0.3246983289718628\n",
      "177 83 0.21974608302116394\n",
      "177 133 0.14773759245872498\n",
      "Validation loss: 0.6724363663043195 MAE: 153.56549\n",
      "178 12 0.2214626520872116\n",
      "178 62 0.3005635440349579\n",
      "178 112 0.3217597007751465\n",
      "178 162 0.2494657039642334\n",
      "Validation loss: 0.8287351065211825 MAE: 189.25972\n",
      "179 41 0.3815443813800812\n",
      "179 91 0.2241525948047638\n",
      "179 141 0.2292184829711914\n",
      "Validation loss: 0.6990296025025217 MAE: 159.63861\n",
      "180 20 0.2635101079940796\n",
      "180 70 0.3530307412147522\n",
      "180 120 0.22767890989780426\n",
      "180 170 0.300515353679657\n",
      "Validation loss: 0.697911768977405 MAE: 159.38333\n",
      "181 49 0.13322560489177704\n",
      "181 99 0.1226075142621994\n",
      "181 149 0.2448672652244568\n",
      "Validation loss: 0.6132533288838571 MAE: 140.04976\n",
      "182 28 0.2711901068687439\n",
      "182 78 0.30752620100975037\n",
      "182 128 0.28845587372779846\n",
      "Validation loss: 0.6215550286030909 MAE: 141.94562\n",
      "183 7 0.19348794221878052\n",
      "183 57 0.26480454206466675\n",
      "183 107 0.1771763414144516\n",
      "183 157 0.21276143193244934\n",
      "Validation loss: 0.5732218975212142 MAE: 130.9077\n",
      "184 36 0.19257386028766632\n",
      "184 86 0.31684234738349915\n",
      "184 136 0.46494612097740173\n",
      "Validation loss: 0.7707914615932264 MAE: 176.02701\n",
      "185 15 0.32334399223327637\n",
      "185 65 0.2130345106124878\n",
      "185 115 0.4273586571216583\n",
      "185 165 0.28390365839004517\n",
      "Validation loss: 0.5553471902657671 MAE: 126.82564\n",
      "186 44 0.2928263247013092\n",
      "186 94 0.27898338437080383\n",
      "186 144 0.38872456550598145\n",
      "Validation loss: 0.8178446334705018 MAE: 186.77264\n",
      "187 23 0.4025470018386841\n",
      "187 73 0.3337717354297638\n",
      "187 123 0.2624196708202362\n",
      "Validation loss: 0.6928528400889614 MAE: 158.22803\n",
      "188 2 0.17964372038841248\n",
      "188 52 0.2976456582546234\n",
      "188 102 0.40402552485466003\n",
      "188 152 0.3005841076374054\n",
      "Validation loss: 0.7185105751132408 MAE: 164.08754\n",
      "189 31 0.20182771980762482\n",
      "189 81 0.34434249997138977\n",
      "189 131 0.2350919246673584\n",
      "Validation loss: 0.6359934632541143 MAE: 145.24295\n",
      "190 10 0.2860521078109741\n",
      "190 60 0.2946685552597046\n",
      "190 110 0.35332509875297546\n",
      "190 160 0.31411853432655334\n",
      "Validation loss: 0.7515595084742496 MAE: 171.63498\n",
      "191 39 0.2660265266895294\n",
      "191 89 0.1523047387599945\n",
      "191 139 0.22907979786396027\n",
      "Validation loss: 0.5607370523332852 MAE: 128.05652\n",
      "192 18 0.164284348487854\n",
      "192 68 0.283208966255188\n",
      "192 118 0.25771209597587585\n",
      "192 168 0.30252349376678467\n",
      "Validation loss: 0.6485070892941882 MAE: 148.10071\n",
      "193 47 0.20583121478557587\n",
      "193 97 0.24290001392364502\n",
      "193 147 0.24193038046360016\n",
      "Validation loss: 0.5952774237471017 MAE: 135.94456\n",
      "194 26 0.4107579290866852\n",
      "194 76 0.23301248252391815\n",
      "194 126 0.21358007192611694\n",
      "Validation loss: 0.7351288105312147 MAE: 167.88268\n",
      "195 5 0.36629578471183777\n",
      "195 55 0.22478227317333221\n",
      "195 105 0.20814895629882812\n",
      "195 155 0.4460788369178772\n",
      "Validation loss: 0.6742411116410417 MAE: 153.97763\n",
      "196 34 0.264760285615921\n",
      "196 84 0.2608736455440521\n",
      "196 134 0.36823129653930664\n",
      "Validation loss: 0.6488948488793178 MAE: 148.18927\n",
      "197 13 0.2932474613189697\n",
      "197 63 0.3681776523590088\n",
      "197 113 0.2571116089820862\n",
      "197 163 0.24682611227035522\n",
      "Validation loss: 0.735017418512824 MAE: 167.85722\n",
      "198 42 0.3662303388118744\n",
      "198 92 0.356747031211853\n",
      "198 142 0.2595650255680084\n",
      "Validation loss: 0.7856960913591218 MAE: 179.43082\n",
      "199 21 0.14515255391597748\n",
      "199 71 0.2641523480415344\n",
      "199 121 0.4248523414134979\n",
      "Validation loss: 0.6970669616732681 MAE: 159.19043\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.48293594725833633 Test MAE: 110.28894\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'qm7', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'regression', 'data_path': 'data/qm7/qm7.csv', 'target': ['u0_atom']}}\n",
      "Running on: cuda:0\n",
      "6833\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/6833\n",
      "Generating scaffold 1000/6833\n",
      "Generating scaffold 2000/6833\n",
      "Generating scaffold 3000/6833\n",
      "Generating scaffold 4000/6833\n",
      "Generating scaffold 5000/6833\n",
      "Generating scaffold 6000/6833\n",
      "About to sort in scaffold sets\n",
      "tensor(-1553.3463) tensor(228.3718) torch.Size([5466, 1])\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.2504055500030518\n",
      "0 50 0.7017570734024048\n",
      "0 100 0.6133785247802734\n",
      "0 150 0.5614274144172668\n",
      "Validation loss: 0.533496373055274 MAE: 121.83552\n",
      "1 29 0.5414249897003174\n",
      "1 79 0.5474851727485657\n",
      "1 129 0.4965676963329315\n",
      "Validation loss: 0.9109127932821798 MAE: 208.02678\n",
      "2 8 0.6931604743003845\n",
      "2 58 0.9350875020027161\n",
      "2 108 0.6351353526115417\n",
      "2 158 0.48967722058296204\n",
      "Validation loss: 0.7112419145149097 MAE: 162.42758\n",
      "3 37 0.406416654586792\n",
      "3 87 0.5653513073921204\n",
      "3 137 0.5982270836830139\n",
      "Validation loss: 0.8644028909025137 MAE: 197.40523\n",
      "4 16 0.3948400020599365\n",
      "4 66 0.4131035804748535\n",
      "4 116 0.48030251264572144\n",
      "4 166 0.3145736753940582\n",
      "Validation loss: 0.7225678475976688 MAE: 165.0141\n",
      "5 45 0.4817256033420563\n",
      "5 95 0.7039406299591064\n",
      "5 145 0.5846547484397888\n",
      "Validation loss: 0.7010576867917825 MAE: 160.10179\n",
      "6 24 0.43623700737953186\n",
      "6 74 0.5112479329109192\n",
      "6 124 0.44885650277137756\n",
      "Validation loss: 0.877830445766449 MAE: 200.47173\n",
      "7 3 0.5759531259536743\n",
      "7 53 0.2896101176738739\n",
      "7 103 0.5959384441375732\n",
      "7 153 0.7093966007232666\n",
      "Validation loss: 0.5227155859707392 MAE: 119.37347\n",
      "8 32 0.5400309562683105\n",
      "8 82 0.45348992943763733\n",
      "8 132 0.5547387003898621\n",
      "Validation loss: 0.47540764937623897 MAE: 108.569695\n",
      "9 11 0.43095317482948303\n",
      "9 61 0.5440678596496582\n",
      "9 111 0.36368298530578613\n",
      "9 161 0.4243744909763336\n",
      "Validation loss: 0.8149871923770123 MAE: 186.12007\n",
      "10 40 0.349770724773407\n",
      "10 90 0.5975371599197388\n",
      "10 140 0.5731405019760132\n",
      "Validation loss: 0.5957221315618146 MAE: 136.04613\n",
      "11 19 0.7127546668052673\n",
      "11 69 0.5511192679405212\n",
      "11 119 0.6661242246627808\n",
      "11 169 0.5057646036148071\n",
      "Validation loss: 0.8267658314509698 MAE: 188.80998\n",
      "12 48 0.4772930443286896\n",
      "12 98 0.42251187562942505\n",
      "12 148 0.3861689269542694\n",
      "Validation loss: 0.6950279815852294 MAE: 158.72478\n",
      "13 27 0.4144497811794281\n",
      "13 77 0.5899438858032227\n",
      "13 127 0.5574346780776978\n",
      "Validation loss: 0.4339560988353707 MAE: 99.103325\n",
      "14 6 0.5267624258995056\n",
      "14 56 0.39360731840133667\n",
      "14 106 0.5726889967918396\n",
      "14 156 0.3383207321166992\n",
      "Validation loss: 0.4683336911842837 MAE: 106.9542\n",
      "15 35 0.37201225757598877\n",
      "15 85 0.2994508445262909\n",
      "15 135 0.5338959097862244\n",
      "Validation loss: 0.4990364074358466 MAE: 113.96583\n",
      "16 14 0.32385125756263733\n",
      "16 64 0.47258734703063965\n",
      "16 114 0.47196272015571594\n",
      "16 164 0.30672386288642883\n",
      "Validation loss: 0.691983183224996 MAE: 158.02943\n",
      "17 43 0.26357826590538025\n",
      "17 93 0.7269599437713623\n",
      "17 143 0.37151288986206055\n",
      "Validation loss: 0.6472706962050053 MAE: 147.81836\n",
      "18 22 0.5164942145347595\n",
      "18 72 0.41034695506095886\n",
      "18 122 0.2893472909927368\n",
      "Validation loss: 0.4690361179803547 MAE: 107.11461\n",
      "19 1 0.47598573565483093\n",
      "19 51 0.40099573135375977\n",
      "19 101 0.366897314786911\n",
      "19 151 0.3414798378944397\n",
      "Validation loss: 0.411753197162472 MAE: 94.03281\n",
      "20 30 0.3879326581954956\n",
      "20 80 0.3757709264755249\n",
      "20 130 0.3279740512371063\n",
      "Validation loss: 0.5944603883732132 MAE: 135.75797\n",
      "21 9 0.4598080515861511\n",
      "21 59 0.4683401882648468\n",
      "21 109 0.5111362338066101\n",
      "21 159 0.6425212621688843\n",
      "Validation loss: 0.5843692289458381 MAE: 133.45343\n",
      "22 38 0.34157925844192505\n",
      "22 88 0.3611752986907959\n",
      "22 138 0.4271693229675293\n",
      "Validation loss: 0.6466988039295576 MAE: 147.68774\n",
      "23 17 0.23437973856925964\n",
      "23 67 0.6335439085960388\n",
      "23 117 0.27534133195877075\n",
      "23 167 0.45265206694602966\n",
      "Validation loss: 0.480529534886455 MAE: 109.73938\n",
      "24 46 0.5302594304084778\n",
      "24 96 0.344196617603302\n",
      "24 146 0.5646585822105408\n",
      "Validation loss: 0.5535459159410487 MAE: 126.41427\n",
      "25 25 0.3519487679004669\n",
      "25 75 0.4843621850013733\n",
      "25 125 0.3947884738445282\n",
      "Validation loss: 0.5012021951856669 MAE: 114.460434\n",
      "26 4 0.44684725999832153\n",
      "26 54 0.4847932755947113\n",
      "26 104 0.46798643469810486\n",
      "26 154 0.4906727373600006\n",
      "Validation loss: 0.4109087603831152 MAE: 93.83996\n",
      "27 33 0.4674302339553833\n",
      "27 83 0.15255245566368103\n",
      "27 133 0.5013113021850586\n",
      "Validation loss: 0.5566954963039934 MAE: 127.133545\n",
      "28 12 0.3451373279094696\n",
      "28 62 0.45722001791000366\n",
      "28 112 0.49895554780960083\n",
      "28 162 0.3746890127658844\n",
      "Validation loss: 0.59175275501452 MAE: 135.13963\n",
      "29 41 0.3151392638683319\n",
      "29 91 0.5786023139953613\n",
      "29 141 0.3514556288719177\n",
      "Validation loss: 0.4915029563401875 MAE: 112.24541\n",
      "30 20 0.2642434239387512\n",
      "30 70 0.36685243248939514\n",
      "30 120 0.6357775926589966\n",
      "30 170 0.44041597843170166\n",
      "Validation loss: 0.4994814007254372 MAE: 114.06746\n",
      "31 49 0.3492646813392639\n",
      "31 99 0.5827139616012573\n",
      "31 149 0.4787834882736206\n",
      "Validation loss: 0.5370884107218848 MAE: 122.65584\n",
      "32 28 0.36622360348701477\n",
      "32 78 0.2842681109905243\n",
      "32 128 0.4256194531917572\n",
      "Validation loss: 0.580345260469537 MAE: 132.53448\n",
      "33 7 0.42219308018684387\n",
      "33 57 0.3480333983898163\n",
      "33 107 0.4574207365512848\n",
      "33 157 0.2890891432762146\n",
      "Validation loss: 0.5455238205647608 MAE: 124.58224\n",
      "34 36 0.38445332646369934\n",
      "34 86 0.31683751940727234\n",
      "34 136 0.4311341643333435\n",
      "Validation loss: 0.6555680412995187 MAE: 149.71324\n",
      "35 15 0.34253770112991333\n",
      "35 65 0.37250545620918274\n",
      "35 115 0.30106616020202637\n",
      "35 165 0.41304951906204224\n",
      "Validation loss: 0.47190731397846286 MAE: 107.77031\n",
      "36 44 0.35763615369796753\n",
      "36 94 0.45929598808288574\n",
      "36 144 0.3585245907306671\n",
      "Validation loss: 0.5276533170053136 MAE: 120.50112\n",
      "37 23 0.30439186096191406\n",
      "37 73 0.44997698068618774\n",
      "37 123 0.4025312662124634\n",
      "Validation loss: 0.6131450858032494 MAE: 140.02504\n",
      "38 2 0.3161410689353943\n",
      "38 52 0.360807329416275\n",
      "38 102 0.4079726040363312\n",
      "38 152 0.3650583326816559\n",
      "Validation loss: 0.5301920301035831 MAE: 121.08089\n",
      "39 31 0.3726957440376282\n",
      "39 81 0.26508909463882446\n",
      "39 131 0.37505006790161133\n",
      "Validation loss: 0.5858787695566813 MAE: 133.79817\n",
      "40 10 0.3118804395198822\n",
      "40 60 0.25268787145614624\n",
      "40 110 0.30572423338890076\n",
      "40 160 0.2966294288635254\n",
      "Validation loss: 0.5589589236075418 MAE: 127.650444\n",
      "41 39 0.34955909848213196\n",
      "41 89 0.3554251194000244\n",
      "41 139 0.4097374975681305\n",
      "Validation loss: 0.5933910142957118 MAE: 135.51375\n",
      "42 18 0.37677502632141113\n",
      "42 68 0.24816890060901642\n",
      "42 118 0.4797555208206177\n",
      "42 168 0.29839804768562317\n",
      "Validation loss: 0.6291739438709459 MAE: 143.68556\n",
      "43 47 0.3181489408016205\n",
      "43 97 0.4674690365791321\n",
      "43 147 0.35367533564567566\n",
      "Validation loss: 0.5266975223669532 MAE: 120.28285\n",
      "44 26 0.4105524718761444\n",
      "44 76 0.3216758072376251\n",
      "44 126 0.6974815130233765\n",
      "Validation loss: 0.4409279195885909 MAE: 100.695496\n",
      "45 5 0.42605090141296387\n",
      "45 55 0.4886248707771301\n",
      "45 105 0.29898878931999207\n",
      "45 155 0.6119787693023682\n",
      "Validation loss: 0.5118144123177779 MAE: 116.883965\n",
      "46 34 0.2571234405040741\n",
      "46 84 0.298019140958786\n",
      "46 134 0.28844863176345825\n",
      "Validation loss: 0.5748306927625199 MAE: 131.2751\n",
      "47 13 0.26263371109962463\n",
      "47 63 0.2882988750934601\n",
      "47 113 0.6151801347732544\n",
      "47 163 0.32934272289276123\n",
      "Validation loss: 0.43847386756835627 MAE: 100.13505\n",
      "48 42 0.5084621906280518\n",
      "48 92 0.4946255087852478\n",
      "48 142 0.44501060247421265\n",
      "Validation loss: 0.5188694666003624 MAE: 118.49513\n",
      "49 21 0.31141743063926697\n",
      "49 71 0.32869231700897217\n",
      "49 121 0.5767794847488403\n",
      "Validation loss: 0.6699626487598085 MAE: 153.00055\n",
      "50 0 0.4129970073699951\n",
      "50 50 0.43112891912460327\n",
      "50 100 0.5778684020042419\n",
      "50 150 0.3951677680015564\n",
      "Validation loss: 0.6024949449544762 MAE: 137.59283\n",
      "51 29 0.25731751322746277\n",
      "51 79 0.26272791624069214\n",
      "51 129 0.331518292427063\n",
      "Validation loss: 0.6730988487514139 MAE: 153.71678\n",
      "52 8 0.445026159286499\n",
      "52 58 0.46803271770477295\n",
      "52 108 0.17157314717769623\n",
      "52 158 0.358967661857605\n",
      "Validation loss: 0.5371065474393075 MAE: 122.65997\n",
      "53 37 0.3878670036792755\n",
      "53 87 0.4888151288032532\n",
      "53 137 0.39307722449302673\n",
      "Validation loss: 0.5197700324811434 MAE: 118.700806\n",
      "54 16 0.3669796288013458\n",
      "54 66 0.3043040931224823\n",
      "54 116 0.5657998919487\n",
      "54 166 0.2605269253253937\n",
      "Validation loss: 0.5339081357097069 MAE: 121.92955\n",
      "55 45 0.46275341510772705\n",
      "55 95 0.45246487855911255\n",
      "55 145 0.38651517033576965\n",
      "Validation loss: 0.5585724920557257 MAE: 127.56218\n",
      "56 24 0.3022913634777069\n",
      "56 74 0.4173949956893921\n",
      "56 124 0.3466132879257202\n",
      "Validation loss: 0.5619707494451288 MAE: 128.33824\n",
      "57 3 0.3837405741214752\n",
      "57 53 0.538765013217926\n",
      "57 103 0.6204794049263\n",
      "57 153 0.3675117492675781\n",
      "Validation loss: 0.5621640075717056 MAE: 128.38239\n",
      "58 32 0.40908315777778625\n",
      "58 82 0.40451857447624207\n",
      "58 132 0.3847419321537018\n",
      "Validation loss: 0.6993033483363035 MAE: 159.70114\n",
      "59 11 0.2771797776222229\n",
      "59 61 0.49926912784576416\n",
      "59 111 0.3627583682537079\n",
      "59 161 0.519805908203125\n",
      "Validation loss: 0.5530388696848998 MAE: 126.29848\n",
      "60 40 0.2858640253543854\n",
      "60 90 0.5308120250701904\n",
      "60 140 0.35683274269104004\n",
      "Validation loss: 0.5070066960931522 MAE: 115.786026\n",
      "61 19 0.5390893816947937\n",
      "61 69 0.3601040840148926\n",
      "61 119 0.33435505628585815\n",
      "61 169 0.41515809297561646\n",
      "Validation loss: 0.6634850386987653 MAE: 151.52124\n",
      "62 48 0.34054479002952576\n",
      "62 98 0.29657962918281555\n",
      "62 148 0.2990626096725464\n",
      "Validation loss: 0.5635583432097184 MAE: 128.70082\n",
      "63 27 0.4485832154750824\n",
      "63 77 0.3750830292701721\n",
      "63 127 0.34503230452537537\n",
      "Validation loss: 0.60442532712256 MAE: 138.03369\n",
      "64 6 0.38947102427482605\n",
      "64 56 0.39942046999931335\n",
      "64 106 0.29660022258758545\n",
      "64 156 0.30615001916885376\n",
      "Validation loss: 0.5327465481925429 MAE: 121.66427\n",
      "65 35 0.3196282684803009\n",
      "65 85 0.549534797668457\n",
      "65 135 0.3826490044593811\n",
      "Validation loss: 0.5708083050292835 MAE: 130.35649\n",
      "66 14 0.409941703081131\n",
      "66 64 0.34643399715423584\n",
      "66 114 0.4217630624771118\n",
      "66 164 0.35156968235969543\n",
      "Validation loss: 0.5290286223790799 MAE: 120.81519\n",
      "67 43 0.5008427500724792\n",
      "67 93 0.38785025477409363\n",
      "67 143 0.32154732942581177\n",
      "Validation loss: 0.43937028587213034 MAE: 100.33977\n",
      "68 22 0.3760744333267212\n",
      "68 72 0.4422995150089264\n",
      "68 122 0.5150606632232666\n",
      "Validation loss: 0.4211929667065715 MAE: 96.188576\n",
      "69 1 0.3108738958835602\n",
      "69 51 0.6082126498222351\n",
      "69 101 0.29371586441993713\n",
      "69 151 0.26137208938598633\n",
      "Validation loss: 0.48758812152851394 MAE: 111.35136\n",
      "70 30 0.4633602201938629\n",
      "70 80 0.299005925655365\n",
      "70 130 0.4826773703098297\n",
      "Validation loss: 0.5879112928234346 MAE: 134.26233\n",
      "71 9 0.3792966306209564\n",
      "71 59 0.38343849778175354\n",
      "71 109 0.5954774022102356\n",
      "71 159 0.4439762830734253\n",
      "Validation loss: 0.4814156853316123 MAE: 109.94175\n",
      "72 38 0.3834685683250427\n",
      "72 88 0.36605340242385864\n",
      "72 138 0.46449679136276245\n",
      "Validation loss: 0.4386206941995007 MAE: 100.16859\n",
      "73 17 0.5079191327095032\n",
      "73 67 0.2968691885471344\n",
      "73 117 0.4738486111164093\n",
      "73 167 0.23222175240516663\n",
      "Validation loss: 0.46867002799497015 MAE: 107.03101\n",
      "74 46 0.3703351616859436\n",
      "74 96 0.5471595525741577\n",
      "74 146 0.37989693880081177\n",
      "Validation loss: 0.6345310998938934 MAE: 144.909\n",
      "75 25 0.22249311208724976\n",
      "75 75 0.4817797541618347\n",
      "75 125 0.22999738156795502\n",
      "Validation loss: 0.5983212022056357 MAE: 136.63968\n",
      "76 4 0.24660782516002655\n",
      "76 54 0.3431759476661682\n",
      "76 104 0.5442492365837097\n",
      "76 154 0.3297424912452698\n",
      "Validation loss: 0.6051237990981654 MAE: 138.19319\n",
      "77 33 0.44801226258277893\n",
      "77 83 0.37871700525283813\n",
      "77 133 0.4434666037559509\n",
      "Validation loss: 0.6321623353233115 MAE: 144.36804\n",
      "78 12 0.360786110162735\n",
      "78 62 0.4516999125480652\n",
      "78 112 0.40571677684783936\n",
      "78 162 0.3055967688560486\n",
      "Validation loss: 0.49114866319455597 MAE: 112.1645\n",
      "79 41 0.39011672139167786\n",
      "79 91 0.31270501017570496\n",
      "79 141 0.27859583497047424\n",
      "Validation loss: 0.5237670352584437 MAE: 119.6136\n",
      "80 20 0.5335103273391724\n",
      "80 70 0.49061980843544006\n",
      "80 120 0.3494654595851898\n",
      "80 170 0.34601667523384094\n",
      "Validation loss: 0.5503330973156711 MAE: 125.68054\n",
      "81 49 0.26207730174064636\n",
      "81 99 0.26073622703552246\n",
      "81 149 0.3581198751926422\n",
      "Validation loss: 0.6374653075870714 MAE: 145.57909\n",
      "82 28 0.3703957200050354\n",
      "82 78 0.40952572226524353\n",
      "82 128 0.3401714861392975\n",
      "Validation loss: 0.6145639482297396 MAE: 140.34906\n",
      "83 7 0.4393705427646637\n",
      "83 57 0.3622986972332001\n",
      "83 107 0.2503856122493744\n",
      "83 157 0.30303704738616943\n",
      "Validation loss: 0.6000667067996243 MAE: 137.03831\n",
      "84 36 0.3897050619125366\n",
      "84 86 0.37717705965042114\n",
      "84 136 0.3620961308479309\n",
      "Validation loss: 0.5210621140853703 MAE: 118.99588\n",
      "85 15 0.2446223944425583\n",
      "85 65 0.30146726965904236\n",
      "85 115 0.37927675247192383\n",
      "85 165 0.2932843565940857\n",
      "Validation loss: 0.49426336699759055 MAE: 112.8758\n",
      "86 44 0.23215633630752563\n",
      "86 94 0.36098912358283997\n",
      "86 144 0.36339327692985535\n",
      "Validation loss: 0.606012117095858 MAE: 138.39606\n",
      "87 23 0.29011568427085876\n",
      "87 73 0.2740236818790436\n",
      "87 123 0.25321370363235474\n",
      "Validation loss: 0.5912496067627132 MAE: 135.02472\n",
      "88 2 0.25589627027511597\n",
      "88 52 0.33790072798728943\n",
      "88 102 0.3679486811161041\n",
      "88 152 0.38885417580604553\n",
      "Validation loss: 0.5485212935341729 MAE: 125.26678\n",
      "89 31 0.3673732578754425\n",
      "89 81 0.36871376633644104\n",
      "89 131 0.319792240858078\n",
      "Validation loss: 0.47213789123540734 MAE: 107.82296\n",
      "90 10 0.4427298903465271\n",
      "90 60 0.31502464413642883\n",
      "90 110 0.31734755635261536\n",
      "90 160 0.3622947633266449\n",
      "Validation loss: 0.5889062243595458 MAE: 134.48956\n",
      "91 39 0.250834196805954\n",
      "91 89 0.2643834054470062\n",
      "91 139 0.31663843989372253\n",
      "Validation loss: 0.5524787526381644 MAE: 126.17055\n",
      "92 18 0.3344568610191345\n",
      "92 68 0.3677193522453308\n",
      "92 118 0.24343913793563843\n",
      "92 168 0.5026718974113464\n",
      "Validation loss: 0.567835452438098 MAE: 129.67758\n",
      "93 47 0.29004377126693726\n",
      "93 97 0.2533411681652069\n",
      "93 147 0.31787627935409546\n",
      "Validation loss: 0.557235432647125 MAE: 127.25684\n",
      "94 26 0.3984377682209015\n",
      "94 76 0.4460788369178772\n",
      "94 126 0.3855666220188141\n",
      "Validation loss: 0.5181272601523594 MAE: 118.32564\n",
      "95 5 0.4254259169101715\n",
      "95 55 0.2948399484157562\n",
      "95 105 0.3243265450000763\n",
      "95 155 0.3316297233104706\n",
      "Validation loss: 0.5312099702525557 MAE: 121.31337\n",
      "96 34 0.4129098057746887\n",
      "96 84 0.2945612668991089\n",
      "96 134 0.3257374167442322\n",
      "Validation loss: 0.6291162383835218 MAE: 143.6724\n",
      "97 13 0.35431522130966187\n",
      "97 63 0.1560991257429123\n",
      "97 113 0.3686973452568054\n",
      "97 163 0.2847094237804413\n",
      "Validation loss: 0.5828930024515119 MAE: 133.11632\n",
      "98 42 0.328982949256897\n",
      "98 92 0.34437769651412964\n",
      "98 142 0.23037447035312653\n",
      "Validation loss: 0.520097189479404 MAE: 118.77551\n",
      "99 21 0.3292795717716217\n",
      "99 71 0.3680664300918579\n",
      "99 121 0.23805060982704163\n",
      "Validation loss: 0.6689763768026006 MAE: 152.77533\n",
      "100 0 0.3826841115951538\n",
      "100 50 0.33484402298927307\n",
      "100 100 0.28751063346862793\n",
      "100 150 0.3991657793521881\n",
      "Validation loss: 0.49973493117338036 MAE: 114.12534\n",
      "101 29 0.2624109089374542\n",
      "101 79 0.23202675580978394\n",
      "101 129 0.39852121472358704\n",
      "Validation loss: 0.5606321716866298 MAE: 128.03258\n",
      "102 8 0.34968289732933044\n",
      "102 58 0.3709943890571594\n",
      "102 108 0.40056759119033813\n",
      "102 158 0.319267213344574\n",
      "Validation loss: 0.4958746694681937 MAE: 113.24379\n",
      "103 37 0.3203253149986267\n",
      "103 87 0.44300326704978943\n",
      "103 137 0.352870911359787\n",
      "Validation loss: 0.5794785524669447 MAE: 132.33655\n",
      "104 16 0.3130663335323334\n",
      "104 66 0.26577919721603394\n",
      "104 116 0.49804025888442993\n",
      "104 166 0.2155468612909317\n",
      "Validation loss: 0.48945520234386825 MAE: 111.777756\n",
      "105 45 0.34322401881217957\n",
      "105 95 0.3364658057689667\n",
      "105 145 0.3801194131374359\n",
      "Validation loss: 0.5964019274153904 MAE: 136.20137\n",
      "106 24 0.5229973196983337\n",
      "106 74 0.3614342212677002\n",
      "106 124 0.23241212964057922\n",
      "Validation loss: 0.5527508701497351 MAE: 126.232704\n",
      "107 3 0.370947927236557\n",
      "107 53 0.32869845628738403\n",
      "107 103 0.420378178358078\n",
      "107 153 0.3948553204536438\n",
      "Validation loss: 0.48175515417467085 MAE: 110.01928\n",
      "108 32 0.3877008259296417\n",
      "108 82 0.3167247772216797\n",
      "108 132 0.30675071477890015\n",
      "Validation loss: 0.6785953569481944 MAE: 154.97203\n",
      "109 11 0.33581045269966125\n",
      "109 61 0.4629797339439392\n",
      "109 111 0.26425987482070923\n",
      "109 161 0.3454117178916931\n",
      "Validation loss: 0.49685759258549117 MAE: 113.46825\n",
      "110 40 0.22393850982189178\n",
      "110 90 0.4188928008079529\n",
      "110 140 0.29702499508857727\n",
      "Validation loss: 0.5539757577996505 MAE: 126.51243\n",
      "111 19 0.3606279790401459\n",
      "111 69 0.37373971939086914\n",
      "111 119 0.2956484854221344\n",
      "111 169 0.2790481746196747\n",
      "Validation loss: 0.5215575520755255 MAE: 119.109024\n",
      "112 48 0.38839414715766907\n",
      "112 98 0.4954580068588257\n",
      "112 148 0.26299014687538147\n",
      "Validation loss: 0.5360119126693547 MAE: 122.409996\n",
      "113 27 0.38684844970703125\n",
      "113 77 0.26208773255348206\n",
      "113 127 0.2894172966480255\n",
      "Validation loss: 0.6175276549936038 MAE: 141.02588\n",
      "114 6 0.313585489988327\n",
      "114 56 0.3556745648384094\n",
      "114 106 0.3066411316394806\n",
      "114 156 0.4282771944999695\n",
      "Validation loss: 0.5110274570727209 MAE: 116.70425\n",
      "115 35 0.4429219961166382\n",
      "115 85 0.4117369055747986\n",
      "115 135 0.3000204265117645\n",
      "Validation loss: 0.605901929370144 MAE: 138.3709\n",
      "116 14 0.41780951619148254\n",
      "116 64 0.3026462197303772\n",
      "116 114 0.25918659567832947\n",
      "116 164 0.30674391984939575\n",
      "Validation loss: 0.6028083381597061 MAE: 137.6644\n",
      "117 43 0.38751256465911865\n",
      "117 93 0.2526113986968994\n",
      "117 143 0.354052871465683\n",
      "Validation loss: 0.5735067505585519 MAE: 130.97275\n",
      "118 22 0.32755807042121887\n",
      "118 72 0.4081011414527893\n",
      "118 122 0.2915286421775818\n",
      "Validation loss: 0.5677041746022409 MAE: 129.64761\n",
      "119 1 0.43336060643196106\n",
      "119 51 0.36326563358306885\n",
      "119 101 0.36089664697647095\n",
      "119 151 0.3161272704601288\n",
      "Validation loss: 0.6651786663378888 MAE: 151.90804\n",
      "120 30 0.4057505428791046\n",
      "120 80 0.32255274057388306\n",
      "120 130 0.38898026943206787\n",
      "Validation loss: 0.47351685880917554 MAE: 108.137886\n",
      "121 9 0.44803282618522644\n",
      "121 59 0.29867637157440186\n",
      "121 109 0.25407230854034424\n",
      "121 159 0.29238948225975037\n",
      "Validation loss: 0.6397577161677399 MAE: 146.1026\n",
      "122 38 0.26897352933883667\n",
      "122 88 0.2911266088485718\n",
      "122 138 0.36375221610069275\n",
      "Validation loss: 0.6798525609468159 MAE: 155.25912\n",
      "123 17 0.3378843367099762\n",
      "123 67 0.3339273929595947\n",
      "123 117 0.39017146825790405\n",
      "123 167 0.2455267608165741\n",
      "Validation loss: 0.6778373470780445 MAE: 154.7989\n",
      "124 46 0.31646400690078735\n",
      "124 96 0.4975471794605255\n",
      "124 146 0.34789004921913147\n",
      "Validation loss: 0.5867995002813506 MAE: 134.00845\n",
      "125 25 0.22178567945957184\n",
      "125 75 0.35301586985588074\n",
      "125 125 0.3743981122970581\n",
      "Validation loss: 0.642799108697657 MAE: 146.79716\n",
      "126 4 0.30986008048057556\n",
      "126 54 0.4527278244495392\n",
      "126 104 0.34078583121299744\n",
      "126 154 0.33789992332458496\n",
      "Validation loss: 0.5791917227165043 MAE: 132.27104\n",
      "127 33 0.24904277920722961\n",
      "127 83 0.4855405390262604\n",
      "127 133 0.4173251986503601\n",
      "Validation loss: 0.6096954432844418 MAE: 139.23721\n",
      "128 12 0.3370775580406189\n",
      "128 62 0.3683716058731079\n",
      "128 112 0.3689625859260559\n",
      "128 162 0.327181875705719\n",
      "Validation loss: 0.6423708920241796 MAE: 146.69937\n",
      "129 41 0.16011416912078857\n",
      "129 91 0.22969938814640045\n",
      "129 141 0.2726205885410309\n",
      "Validation loss: 0.7609392564896255 MAE: 173.77705\n",
      "130 20 0.27205246686935425\n",
      "130 70 0.33326220512390137\n",
      "130 120 0.4094986915588379\n",
      "130 170 0.39015060663223267\n",
      "Validation loss: 0.6835367484399449 MAE: 156.10051\n",
      "131 49 0.21684052050113678\n",
      "131 99 0.31407931447029114\n",
      "131 149 0.17419473826885223\n",
      "Validation loss: 0.6362069705773515 MAE: 145.29172\n",
      "132 28 0.44050928950309753\n",
      "132 78 0.2880285978317261\n",
      "132 128 0.3484368324279785\n",
      "Validation loss: 0.5383091589860749 MAE: 122.93462\n",
      "133 7 0.38622626662254333\n",
      "133 57 0.31790533661842346\n",
      "133 107 0.6039309501647949\n",
      "133 157 0.3170118033885956\n",
      "Validation loss: 0.5510715943330909 MAE: 125.84919\n",
      "134 36 0.3981530964374542\n",
      "134 86 0.4887130856513977\n",
      "134 136 0.48046934604644775\n",
      "Validation loss: 0.5558611123185409 MAE: 126.942986\n",
      "135 15 0.27550914883613586\n",
      "135 65 0.24388599395751953\n",
      "135 115 0.4194950759410858\n",
      "135 165 0.21196943521499634\n",
      "Validation loss: 0.5992512410147148 MAE: 136.85207\n",
      "136 44 0.433046817779541\n",
      "136 94 0.39288511872291565\n",
      "136 144 0.31755173206329346\n",
      "Validation loss: 0.5844705132713095 MAE: 133.47658\n",
      "137 23 0.2792498469352722\n",
      "137 73 0.2785596549510956\n",
      "137 123 0.37275025248527527\n",
      "Validation loss: 0.5659311103541949 MAE: 129.24269\n",
      "138 2 0.3000282943248749\n",
      "138 52 0.36973902583122253\n",
      "138 102 0.24286319315433502\n",
      "138 152 0.14899441599845886\n",
      "Validation loss: 0.7048147693712111 MAE: 160.9598\n",
      "139 31 0.31195810437202454\n",
      "139 81 0.4658944308757782\n",
      "139 131 0.3351971507072449\n",
      "Validation loss: 0.6516386263551768 MAE: 148.81586\n",
      "140 10 0.239695742726326\n",
      "140 60 0.4196261465549469\n",
      "140 110 0.43157532811164856\n",
      "140 160 0.33272966742515564\n",
      "Validation loss: 0.6469904862300694 MAE: 147.75436\n",
      "141 39 0.2519286870956421\n",
      "141 89 0.40805724263191223\n",
      "141 139 0.33863455057144165\n",
      "Validation loss: 0.5997517196058529 MAE: 136.96637\n",
      "142 18 0.2770582139492035\n",
      "142 68 0.344914048910141\n",
      "142 118 0.3288729786872864\n",
      "142 168 0.35680973529815674\n",
      "Validation loss: 0.5063905998280174 MAE: 115.64533\n",
      "143 47 0.3798927664756775\n",
      "143 97 0.3012913167476654\n",
      "143 147 0.3668219745159149\n",
      "Validation loss: 0.5955500316898725 MAE: 136.00682\n",
      "144 26 0.43438464403152466\n",
      "144 76 0.4312730133533478\n",
      "144 126 0.1829817146062851\n",
      "Validation loss: 0.6499773417299951 MAE: 148.43648\n",
      "145 5 0.30061256885528564\n",
      "145 55 0.39265918731689453\n",
      "145 105 0.5059751272201538\n",
      "145 155 0.31425777077674866\n",
      "Validation loss: 0.6082364976057533 MAE: 138.90404\n",
      "146 34 0.24568578600883484\n",
      "146 84 0.38479387760162354\n",
      "146 134 0.18617036938667297\n",
      "Validation loss: 0.5376772636558578 MAE: 122.790306\n",
      "147 13 0.3008212745189667\n",
      "147 63 0.35076940059661865\n",
      "147 113 0.4358704090118408\n",
      "147 163 0.36715027689933777\n",
      "Validation loss: 0.5140432893184194 MAE: 117.392975\n",
      "148 42 0.27591851353645325\n",
      "148 92 0.2692984640598297\n",
      "148 142 0.31829220056533813\n",
      "Validation loss: 0.494637748302772 MAE: 112.96129\n",
      "149 21 0.22829821705818176\n",
      "149 71 0.2459111213684082\n",
      "149 121 0.30422407388687134\n",
      "Validation loss: 0.5489822019610489 MAE: 125.37204\n",
      "150 0 0.3425973951816559\n",
      "150 50 0.22590117156505585\n",
      "150 100 0.3632713258266449\n",
      "150 150 0.3186068832874298\n",
      "Validation loss: 0.5336570105357477 MAE: 121.87219\n",
      "151 29 0.37507620453834534\n",
      "151 79 0.37246257066726685\n",
      "151 129 0.3356308043003082\n",
      "Validation loss: 0.5597482440415879 MAE: 127.830696\n",
      "152 8 0.18726791441440582\n",
      "152 58 0.31328290700912476\n",
      "152 108 0.439503937959671\n",
      "152 158 0.39675575494766235\n",
      "Validation loss: 0.7487544288412172 MAE: 170.99438\n",
      "153 37 0.26571255922317505\n",
      "153 87 0.3390950560569763\n",
      "153 137 0.1993912160396576\n",
      "Validation loss: 0.6595236976244296 MAE: 150.6166\n",
      "154 16 0.14509768784046173\n",
      "154 66 0.27605125308036804\n",
      "154 116 0.2146141082048416\n",
      "154 166 0.26003438234329224\n",
      "Validation loss: 0.5118286261084484 MAE: 116.88722\n",
      "155 45 0.31108662486076355\n",
      "155 95 0.18837757408618927\n",
      "155 145 0.3140930235385895\n",
      "Validation loss: 0.5628058110412798 MAE: 128.52896\n",
      "156 24 0.2802248001098633\n",
      "156 74 0.5183038115501404\n",
      "156 124 0.26736441254615784\n",
      "Validation loss: 0.6737923454820064 MAE: 153.87515\n",
      "157 3 0.27658015489578247\n",
      "157 53 0.3535963296890259\n",
      "157 103 0.23623771965503693\n",
      "157 153 0.23328720033168793\n",
      "Validation loss: 0.6255113088596634 MAE: 142.84914\n",
      "158 32 0.24413815140724182\n",
      "158 82 0.3270207941532135\n",
      "158 132 0.35486581921577454\n",
      "Validation loss: 0.5959074263684234 MAE: 136.08844\n",
      "159 11 0.379201740026474\n",
      "159 61 0.23674069344997406\n",
      "159 111 0.2896912097930908\n",
      "159 161 0.29169175028800964\n",
      "Validation loss: 0.7915949431079173 MAE: 180.77794\n",
      "160 40 0.25095903873443604\n",
      "160 90 0.17621378600597382\n",
      "160 140 0.4698185920715332\n",
      "Validation loss: 0.6445019698282431 MAE: 147.18607\n",
      "161 19 0.23766694962978363\n",
      "161 69 0.3041266202926636\n",
      "161 119 0.25486353039741516\n",
      "161 169 0.2231728881597519\n",
      "Validation loss: 0.5991320223139044 MAE: 136.82484\n",
      "162 48 0.2823657989501953\n",
      "162 98 0.4246308505535126\n",
      "162 148 0.44938215613365173\n",
      "Validation loss: 0.6254083406158358 MAE: 142.8256\n",
      "163 27 0.26062631607055664\n",
      "163 77 0.28155842423439026\n",
      "163 127 0.3465765416622162\n",
      "Validation loss: 0.7879029885370131 MAE: 179.9348\n",
      "164 6 0.25282201170921326\n",
      "164 56 0.35803958773612976\n",
      "164 106 0.14508241415023804\n",
      "164 156 0.37558993697166443\n",
      "Validation loss: 0.6209705280281647 MAE: 141.81215\n",
      "165 35 0.2066245675086975\n",
      "165 85 0.39532819390296936\n",
      "165 135 0.332160621881485\n",
      "Validation loss: 0.6592703102624904 MAE: 150.55873\n",
      "166 14 0.2962740957736969\n",
      "166 64 0.2809095084667206\n",
      "166 114 0.20636168122291565\n",
      "166 164 0.2938622534275055\n",
      "Validation loss: 0.6258182346123701 MAE: 142.91922\n",
      "167 43 0.44401639699935913\n",
      "167 93 0.2530561089515686\n",
      "167 143 0.3256583511829376\n",
      "Validation loss: 0.538695496425294 MAE: 123.02284\n",
      "168 22 0.3424103856086731\n",
      "168 72 0.24472039937973022\n",
      "168 122 0.34572678804397583\n",
      "Validation loss: 0.7133601597178052 MAE: 162.91132\n",
      "169 1 0.39014294743537903\n",
      "169 51 0.31985238194465637\n",
      "169 101 0.18858817219734192\n",
      "169 151 0.29324185848236084\n",
      "Validation loss: 0.555799580805483 MAE: 126.92893\n",
      "170 30 0.221449077129364\n",
      "170 80 0.5361022353172302\n",
      "170 130 0.24711976945400238\n",
      "Validation loss: 0.4750539595969239 MAE: 108.48891\n",
      "171 9 0.1388397514820099\n",
      "171 59 0.2583926022052765\n",
      "171 109 0.27739909291267395\n",
      "171 159 0.25231096148490906\n",
      "Validation loss: 0.6943872985784073 MAE: 158.57846\n",
      "172 38 0.4967341721057892\n",
      "172 88 0.40292200446128845\n",
      "172 138 0.31501471996307373\n",
      "Validation loss: 0.5567372488348108 MAE: 127.14307\n",
      "173 17 0.46496057510375977\n",
      "173 67 0.26760250329971313\n",
      "173 117 0.2309841513633728\n",
      "173 167 0.23350821435451508\n",
      "Validation loss: 0.5829434834028545 MAE: 133.12784\n",
      "174 46 0.34343287348747253\n",
      "174 96 0.3839826285839081\n",
      "174 146 0.35666459798812866\n",
      "Validation loss: 0.5477383436515317 MAE: 125.08797\n",
      "175 25 0.37689897418022156\n",
      "175 75 0.28114497661590576\n",
      "175 125 0.4206334948539734\n",
      "Validation loss: 0.6461263093334889 MAE: 147.557\n",
      "176 4 0.34972694516181946\n",
      "176 54 0.298687607049942\n",
      "176 104 0.41629430651664734\n",
      "176 154 0.1785406768321991\n",
      "Validation loss: 0.5725350731994674 MAE: 130.75084\n",
      "177 33 0.2407349795103073\n",
      "177 83 0.3233041763305664\n",
      "177 133 0.21625001728534698\n",
      "Validation loss: 0.6295314999351724 MAE: 143.76723\n",
      "178 12 0.2365991324186325\n",
      "178 62 0.3992452323436737\n",
      "178 112 0.28151077032089233\n",
      "178 162 0.22322377562522888\n",
      "Validation loss: 0.4690777091254965 MAE: 107.12411\n",
      "179 41 0.20997528731822968\n",
      "179 91 0.3816089332103729\n",
      "179 141 0.3106829524040222\n",
      "Validation loss: 0.6307081754444636 MAE: 144.03595\n",
      "180 20 0.2589575946331024\n",
      "180 70 0.3166491389274597\n",
      "180 120 0.3116767704486847\n",
      "180 170 0.38928836584091187\n",
      "Validation loss: 0.5445369492497361 MAE: 124.356865\n",
      "181 49 0.3084898293018341\n",
      "181 99 0.25768470764160156\n",
      "181 149 0.21256685256958008\n",
      "Validation loss: 0.5464194490198504 MAE: 124.78678\n",
      "182 28 0.23123596608638763\n",
      "182 78 0.38160252571105957\n",
      "182 128 0.22484365105628967\n",
      "Validation loss: 0.5347486912158498 MAE: 122.121506\n",
      "183 7 0.21159441769123077\n",
      "183 57 0.23437029123306274\n",
      "183 107 0.29566922783851624\n",
      "183 157 0.3174830377101898\n",
      "Validation loss: 0.5453331579416119 MAE: 124.5387\n",
      "184 36 0.29047486186027527\n",
      "184 86 0.29859334230422974\n",
      "184 136 0.2809962034225464\n",
      "Validation loss: 0.5361350492427224 MAE: 122.4381\n",
      "185 15 0.3235233426094055\n",
      "185 65 0.34490519762039185\n",
      "185 115 0.3986304700374603\n",
      "185 165 0.2612357437610626\n",
      "Validation loss: 0.5690828077277245 MAE: 129.96246\n",
      "186 44 0.35383114218711853\n",
      "186 94 0.22304664552211761\n",
      "186 144 0.24985918402671814\n",
      "Validation loss: 0.5365532437960306 MAE: 122.53362\n",
      "187 23 0.29575857520103455\n",
      "187 73 0.3539963662624359\n",
      "187 123 0.16030482947826385\n",
      "Validation loss: 0.5619385801909262 MAE: 128.3309\n",
      "188 2 0.2243526726961136\n",
      "188 52 0.24338537454605103\n",
      "188 102 0.47393906116485596\n",
      "188 152 0.3304615318775177\n",
      "Validation loss: 0.685837981993692 MAE: 156.62602\n",
      "189 31 0.14461007714271545\n",
      "189 81 0.2566296458244324\n",
      "189 131 0.2539123594760895\n",
      "Validation loss: 0.5564851889833372 MAE: 127.0855\n",
      "190 10 0.19562971591949463\n",
      "190 60 0.29431840777397156\n",
      "190 110 0.23345579206943512\n",
      "190 160 0.302261620759964\n",
      "Validation loss: 0.5585389576460186 MAE: 127.55453\n",
      "191 39 0.38781264424324036\n",
      "191 89 0.3956793546676636\n",
      "191 139 0.23423296213150024\n",
      "Validation loss: 0.7359044551849365 MAE: 168.05981\n",
      "192 18 0.3085789978504181\n",
      "192 68 0.26535236835479736\n",
      "192 118 0.20311400294303894\n",
      "192 168 0.38798102736473083\n",
      "Validation loss: 0.6149020676027265 MAE: 140.42628\n",
      "193 47 0.33961373567581177\n",
      "193 97 0.27497971057891846\n",
      "193 147 0.3228030204772949\n",
      "Validation loss: 0.5577923840249491 MAE: 127.38405\n",
      "194 26 0.18591465055942535\n",
      "194 76 0.3152507245540619\n",
      "194 126 0.23238149285316467\n",
      "Validation loss: 0.4486874378564065 MAE: 102.46755\n",
      "195 5 0.4781433045864105\n",
      "195 55 0.26342475414276123\n",
      "195 105 0.31940725445747375\n",
      "195 155 0.28755855560302734\n",
      "Validation loss: 0.5014332527654213 MAE: 114.51321\n",
      "196 34 0.2820653021335602\n",
      "196 84 0.1893376260995865\n",
      "196 134 0.3913537263870239\n",
      "Validation loss: 0.5077939453529335 MAE: 115.965805\n",
      "197 13 0.3591894805431366\n",
      "197 63 0.37719306349754333\n",
      "197 113 0.35318195819854736\n",
      "197 163 0.31920790672302246\n",
      "Validation loss: 0.6242535339112867 MAE: 142.56189\n",
      "198 42 0.32351505756378174\n",
      "198 92 0.24235528707504272\n",
      "198 142 0.3455354571342468\n",
      "Validation loss: 0.504669811990526 MAE: 115.25234\n",
      "199 21 0.15563440322875977\n",
      "199 71 0.2908867299556732\n",
      "199 121 0.3092518448829651\n",
      "Validation loss: 0.5197963129010117 MAE: 118.70682\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.437998041314227 Test MAE: 100.026375\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'bace', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'classification', 'data_path': 'data/bace/bace.csv', 'target': ['Class']}}\n",
      "Running on: cuda:0\n",
      "1512\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1512\n",
      "Generating scaffold 1000/1512\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.1958696842193604\n",
      "Validation loss: 0.9406500963975262 ROC AUC: 0.5659107016300495\n",
      "1 12 0.5793413519859314\n",
      "Validation loss: 2.2330616333626754 ROC AUC: 0.5090361445783133\n",
      "2 24 0.6499502658843994\n",
      "Validation loss: 0.779240322823556 ROC AUC: 0.58805811481219\n",
      "3 36 0.5143349170684814\n",
      "Validation loss: 1.8808257224543994 ROC AUC: 0.6396172927002126\n",
      "Validation loss: 0.9874691607936329 ROC AUC: 0.5978029766123317\n",
      "5 10 0.443773090839386\n",
      "Validation loss: 0.8979282019943591 ROC AUC: 0.621367824238129\n",
      "6 22 0.5714061260223389\n",
      "Validation loss: 1.2603118561751006 ROC AUC: 0.6144578313253012\n",
      "7 34 0.5785831212997437\n",
      "Validation loss: 1.3207702581456164 ROC AUC: 0.6082565556343019\n",
      "Validation loss: 1.6040532415276332 ROC AUC: 0.6319985825655563\n",
      "9 8 0.5551199316978455\n",
      "Validation loss: 1.3672983496394377 ROC AUC: 0.6327072997873848\n",
      "10 20 0.5584956407546997\n",
      "Validation loss: 1.4729564497802432 ROC AUC: 0.630049610205528\n",
      "11 32 0.5283284783363342\n",
      "Validation loss: 2.1963508302802284 ROC AUC: 0.5869950389794472\n",
      "Validation loss: 1.278605642697669 ROC AUC: 0.6548547129695251\n",
      "13 6 0.46979039907455444\n",
      "Validation loss: 2.125445367484693 ROC AUC: 0.648830616583983\n",
      "14 18 0.41822654008865356\n",
      "Validation loss: 1.2901105774159463 ROC AUC: 0.6254429482636428\n",
      "15 30 0.5380152463912964\n",
      "Validation loss: 1.9803376568863724 ROC AUC: 0.6736357193479802\n",
      "Validation loss: 1.5878176475992265 ROC AUC: 0.6518426647767541\n",
      "17 4 0.3931710124015808\n",
      "Validation loss: 1.5573482560795664 ROC AUC: 0.68781006378455\n",
      "18 16 0.40444058179855347\n",
      "Validation loss: 1.3928971393218894 ROC AUC: 0.6925939050318922\n",
      "19 28 0.4691070020198822\n",
      "Validation loss: 1.4775133432931458 ROC AUC: 0.6940113394755492\n",
      "Validation loss: 1.6030018203305882 ROC AUC: 0.7044649184975195\n",
      "21 2 0.3692771792411804\n",
      "Validation loss: 1.7493206175747296 ROC AUC: 0.6851523742026931\n",
      "22 14 0.6050347089767456\n",
      "Validation loss: 2.505080497817488 ROC AUC: 0.6778880226789511\n",
      "23 26 0.4993065297603607\n",
      "Validation loss: 1.8452539538705586 ROC AUC: 0.7021615875265769\n",
      "Validation loss: 2.028421464345313 ROC AUC: 0.6594613749114103\n",
      "25 0 0.3656446635723114\n",
      "Validation loss: 2.1403266325691677 ROC AUC: 0.6784195605953225\n",
      "26 12 0.5192946195602417\n",
      "Validation loss: 1.582857848792676 ROC AUC: 0.6500708717221828\n",
      "27 24 0.33059585094451904\n",
      "Validation loss: 3.2994575911010338 ROC AUC: 0.6160524450744154\n",
      "28 36 0.38141462206840515\n",
      "Validation loss: 0.9894900014068907 ROC AUC: 0.6645995747696669\n",
      "Validation loss: 2.321695540125007 ROC AUC: 0.6901133947554925\n",
      "30 10 0.38723915815353394\n",
      "Validation loss: 1.1021943881811684 ROC AUC: 0.6669029057406095\n",
      "31 22 0.3085794746875763\n",
      "Validation loss: 1.5876092279194207 ROC AUC: 0.6977321048901487\n",
      "32 34 0.49001649022102356\n",
      "Validation loss: 1.4554664575500993 ROC AUC: 0.6780652019844082\n",
      "Validation loss: 1.8582040229380525 ROC AUC: 0.7197023387668321\n",
      "34 8 0.3461887538433075\n",
      "Validation loss: 2.9050395030849026 ROC AUC: 0.6729270021261518\n",
      "35 20 0.35880377888679504\n",
      "Validation loss: 2.129734055885416 ROC AUC: 0.6490077958894401\n",
      "36 32 0.3696804940700531\n",
      "Validation loss: 2.524625921880962 ROC AUC: 0.666194188518781\n",
      "Validation loss: 1.1473143708626956 ROC AUC: 0.6770021261516654\n",
      "38 6 0.4886959195137024\n",
      "Validation loss: 2.3398910358252114 ROC AUC: 0.7048192771084337\n",
      "39 18 0.37246832251548767\n",
      "Validation loss: 2.0834371633087563 ROC AUC: 0.6708008504606662\n",
      "40 30 0.3626415729522705\n",
      "Validation loss: 2.5710665895449405 ROC AUC: 0.6998582565556344\n",
      "Validation loss: 1.5784142427886558 ROC AUC: 0.6833805811481221\n",
      "42 4 0.47523558139801025\n",
      "Validation loss: 2.1140144629194246 ROC AUC: 0.6688518781006378\n",
      "43 16 0.1757647544145584\n",
      "Validation loss: 1.847736014435623 ROC AUC: 0.6686746987951808\n",
      "44 28 0.510980486869812\n",
      "Validation loss: 1.4085785758416385 ROC AUC: 0.6964918497519489\n",
      "Validation loss: 3.0375965004725174 ROC AUC: 0.6931254429482636\n",
      "46 2 0.3075793981552124\n",
      "Validation loss: 1.1206301063891277 ROC AUC: 0.690822111977321\n",
      "47 14 0.37079474329948425\n",
      "Validation loss: 1.899866664646477 ROC AUC: 0.6931254429482637\n",
      "48 26 0.3650056719779968\n",
      "Validation loss: 1.5565898007904457 ROC AUC: 0.7034018426647768\n",
      "Validation loss: 1.401037204344541 ROC AUC: 0.6993267186392629\n",
      "50 0 0.4343363642692566\n",
      "Validation loss: 2.2121320118177805 ROC AUC: 0.6800141743444365\n",
      "51 12 0.7162993550300598\n",
      "Validation loss: 1.6185896736107126 ROC AUC: 0.6576895818568391\n",
      "52 24 0.4265376925468445\n",
      "Validation loss: 1.2110442317874226 ROC AUC: 0.7262579730687456\n",
      "53 36 0.2637763023376465\n",
      "Validation loss: 1.2952267744683272 ROC AUC: 0.6800141743444366\n",
      "Validation loss: 1.3325025119528866 ROC AUC: 0.7002126151665486\n",
      "55 10 0.2959761917591095\n",
      "Validation loss: 1.1354678142939183 ROC AUC: 0.6959603118355777\n",
      "56 22 0.40524205565452576\n",
      "Validation loss: 1.7050321828450588 ROC AUC: 0.7126151665485472\n",
      "57 34 0.49222230911254883\n",
      "Validation loss: 1.9525416071051793 ROC AUC: 0.6699149539333805\n",
      "Validation loss: 1.4426417603398 ROC AUC: 0.6860382707299787\n",
      "59 8 0.2088451385498047\n",
      "Validation loss: 2.7135178395454456 ROC AUC: 0.6762934089298369\n",
      "60 20 0.3774943947792053\n",
      "Validation loss: 2.463897259030121 ROC AUC: 0.6771793054571226\n",
      "61 32 0.43021485209465027\n",
      "Validation loss: 2.9502098007707405 ROC AUC: 0.6498936924167258\n",
      "Validation loss: 1.4264532722384724 ROC AUC: 0.6865698086463501\n",
      "63 6 0.325757771730423\n",
      "Validation loss: 1.6611738560215528 ROC AUC: 0.6970233876683204\n",
      "64 18 0.3713604807853699\n",
      "Validation loss: 1.3219940907118337 ROC AUC: 0.6800141743444366\n",
      "65 30 0.3237323760986328\n",
      "Validation loss: 1.9179424805356966 ROC AUC: 0.6807228915662651\n",
      "Validation loss: 1.366122083948148 ROC AUC: 0.7028703047484054\n",
      "67 4 0.15385618805885315\n",
      "Validation loss: 1.252486874725645 ROC AUC: 0.6826718639262934\n",
      "68 16 0.35064008831977844\n",
      "Validation loss: 1.9760326281288603 ROC AUC: 0.671863926293409\n",
      "69 28 0.5629534721374512\n",
      "Validation loss: 1.6314509033367335 ROC AUC: 0.6995038979447201\n",
      "Validation loss: 1.4215029904384486 ROC AUC: 0.6982636428065201\n",
      "71 2 0.244157612323761\n",
      "Validation loss: 1.06376151059637 ROC AUC: 0.6715095676824947\n",
      "72 14 0.336459219455719\n",
      "Validation loss: 1.421347020082916 ROC AUC: 0.7156272147413181\n",
      "73 26 0.20452673733234406\n",
      "Validation loss: 1.594148736915841 ROC AUC: 0.6888731396172927\n",
      "Validation loss: 1.6197099464618607 ROC AUC: 0.7181077250177179\n",
      "75 0 0.40762072801589966\n",
      "Validation loss: 1.6259850650433674 ROC AUC: 0.6956059532246635\n",
      "76 12 0.30587249994277954\n",
      "Validation loss: 1.9748561855972997 ROC AUC: 0.6839121190644932\n",
      "77 24 0.24057894945144653\n",
      "Validation loss: 1.6724212643326513 ROC AUC: 0.7042877391920623\n",
      "78 36 0.3294886350631714\n",
      "Validation loss: 2.607755188910377 ROC AUC: 0.6915308291991495\n",
      "Validation loss: 1.5291773901869918 ROC AUC: 0.634479092841956\n",
      "80 10 0.3885888457298279\n",
      "Validation loss: 1.6101313016272538 ROC AUC: 0.6883416017009213\n",
      "81 22 0.1768408566713333\n",
      "Validation loss: 2.4914935819360595 ROC AUC: 0.6846208362863218\n",
      "82 34 0.25509172677993774\n",
      "Validation loss: 1.086667860580596 ROC AUC: 0.7016300496102054\n",
      "Validation loss: 1.5141116333323599 ROC AUC: 0.7166902905740609\n",
      "84 8 0.310955673456192\n",
      "Validation loss: 2.21131511239816 ROC AUC: 0.6720411055988661\n",
      "85 20 0.3481738269329071\n",
      "Validation loss: 2.003897444301883 ROC AUC: 0.6750531537916371\n",
      "86 32 0.4437534809112549\n",
      "Validation loss: 1.8304578042188226 ROC AUC: 0.7072997873848335\n",
      "Validation loss: 1.2287589990540055 ROC AUC: 0.703756201275691\n",
      "88 6 0.2830888628959656\n",
      "Validation loss: 1.5977766430930587 ROC AUC: 0.7142097802976612\n",
      "89 18 0.2847093343734741\n",
      "Validation loss: 0.9552715878612947 ROC AUC: 0.7271438695960313\n",
      "90 30 0.28485095500946045\n",
      "Validation loss: 1.981120902181461 ROC AUC: 0.6970233876683203\n",
      "Validation loss: 3.115885543507456 ROC AUC: 0.6436924167257264\n",
      "92 4 0.24216583371162415\n",
      "Validation loss: 1.4601597288586445 ROC AUC: 0.709603118355776\n",
      "93 16 0.4116876423358917\n",
      "Validation loss: 1.890461808798329 ROC AUC: 0.6789510985116939\n",
      "94 28 0.3452315926551819\n",
      "Validation loss: 1.735953290730912 ROC AUC: 0.7019844082211197\n",
      "Validation loss: 1.5906243024282898 ROC AUC: 0.6934798015591781\n",
      "96 2 0.2932553291320801\n",
      "Validation loss: 0.9957490062082051 ROC AUC: 0.7234231041814316\n",
      "97 14 0.4116666316986084\n",
      "Validation loss: 1.8243420281947054 ROC AUC: 0.6741672572643516\n",
      "98 26 0.284108966588974\n",
      "Validation loss: 2.0811375276931865 ROC AUC: 0.7057051736357193\n",
      "Validation loss: 1.28850061530309 ROC AUC: 0.7165131112686038\n",
      "100 0 0.26190274953842163\n",
      "Validation loss: 2.277266407644512 ROC AUC: 0.6860382707299788\n",
      "101 12 0.18709424138069153\n",
      "Validation loss: 1.2460344895621798 ROC AUC: 0.7021615875265769\n",
      "102 24 0.227916419506073\n",
      "Validation loss: 1.8735581028540402 ROC AUC: 0.6936569808646351\n",
      "103 36 0.2474893480539322\n",
      "Validation loss: 1.6015775495807067 ROC AUC: 0.6757618710134655\n",
      "Validation loss: 1.4892821935628424 ROC AUC: 0.7264351523742026\n",
      "105 10 0.31783246994018555\n",
      "Validation loss: 3.447465667661452 ROC AUC: 0.6389085754783841\n",
      "106 22 0.28918543457984924\n",
      "Validation loss: 1.457496800959505 ROC AUC: 0.7446846208362863\n",
      "107 34 0.3395291268825531\n",
      "Validation loss: 1.537801224664347 ROC AUC: 0.7395464209780297\n",
      "Validation loss: 1.7072053626673112 ROC AUC: 0.6984408221119773\n",
      "109 8 0.25107187032699585\n",
      "Validation loss: 2.237736510125217 ROC AUC: 0.6940113394755493\n",
      "110 20 0.35435035824775696\n",
      "Validation loss: 2.3491207827005955 ROC AUC: 0.6968462083628634\n",
      "111 32 0.264559268951416\n",
      "Validation loss: 1.721790762926569 ROC AUC: 0.7074769666902906\n",
      "Validation loss: 1.5891357399769965 ROC AUC: 0.7025159461374912\n",
      "113 6 0.3680424392223358\n",
      "Validation loss: 1.2342100846056907 ROC AUC: 0.7416725726435152\n",
      "114 18 0.2682492434978485\n",
      "Validation loss: 2.368073885014515 ROC AUC: 0.7205882352941175\n",
      "115 30 0.19737057387828827\n",
      "Validation loss: 2.4016503166678724 ROC AUC: 0.7083628632175761\n",
      "Validation loss: 1.7506928909693333 ROC AUC: 0.7554925584691707\n",
      "117 4 0.4274068772792816\n",
      "Validation loss: 1.6165345157219084 ROC AUC: 0.6968462083628632\n",
      "118 16 0.29606497287750244\n",
      "Validation loss: 2.4686191997780704 ROC AUC: 0.702338766832034\n",
      "119 28 0.3364753723144531\n",
      "Validation loss: 1.954770000565131 ROC AUC: 0.7191708008504606\n",
      "Validation loss: 1.2327537268202826 ROC AUC: 0.7216513111268603\n",
      "121 2 0.2835337817668915\n",
      "Validation loss: 1.721364592874287 ROC AUC: 0.7041105598866052\n",
      "122 14 0.22345058619976044\n",
      "Validation loss: 3.0321974659597637 ROC AUC: 0.7051736357193479\n",
      "123 26 0.345444917678833\n",
      "Validation loss: 2.4251117074726434 ROC AUC: 0.7227143869596031\n",
      "Validation loss: 1.7770387731640545 ROC AUC: 0.7406094968107725\n",
      "125 0 0.21708829700946808\n",
      "Validation loss: 1.3602020329986977 ROC AUC: 0.7225372076541461\n",
      "126 12 0.2650678753852844\n",
      "Validation loss: 1.653465853621628 ROC AUC: 0.7115520907158044\n",
      "127 24 0.1477561891078949\n",
      "Validation loss: 1.3544782171186232 ROC AUC: 0.7338766832034018\n",
      "128 36 0.21913668513298035\n",
      "Validation loss: 1.1497856504869777 ROC AUC: 0.7329907866761163\n",
      "Validation loss: 1.6915499477197002 ROC AUC: 0.6840892983699505\n",
      "130 10 0.28727734088897705\n",
      "Validation loss: 1.2632489559666211 ROC AUC: 0.7363571934798016\n",
      "131 22 0.21683146059513092\n",
      "Validation loss: 1.4291473484986665 ROC AUC: 0.7200566973777462\n",
      "132 34 0.13849888741970062\n",
      "Validation loss: 1.7985508126138852 ROC AUC: 0.6591070163004962\n",
      "Validation loss: 1.6715208773581398 ROC AUC: 0.7119064493267185\n",
      "134 8 0.2316375970840454\n",
      "Validation loss: 1.6527191755787427 ROC AUC: 0.7173990077958894\n",
      "135 20 0.33607780933380127\n",
      "Validation loss: 2.3056098593781327 ROC AUC: 0.7028703047484054\n",
      "136 32 0.38091224431991577\n",
      "Validation loss: 1.2814559975996713 ROC AUC: 0.7602763997165132\n",
      "Validation loss: 1.3159193929457507 ROC AUC: 0.7280297661233168\n",
      "138 6 0.1882438361644745\n",
      "Validation loss: 1.2997879192529136 ROC AUC: 0.7469879518072289\n",
      "139 18 0.18969349563121796\n",
      "Validation loss: 1.5050758952336596 ROC AUC: 0.7363571934798014\n",
      "140 30 0.4227694869041443\n",
      "Validation loss: 1.8674348276971982 ROC AUC: 0.696669029057406\n",
      "Validation loss: 1.451086403518323 ROC AUC: 0.731218993621545\n",
      "142 4 0.2726147174835205\n",
      "Validation loss: 1.406233555433766 ROC AUC: 0.7429128277817151\n",
      "143 16 0.4158696234226227\n",
      "Validation loss: 2.086430933301812 ROC AUC: 0.719879518072289\n",
      "144 28 0.2769286632537842\n",
      "Validation loss: 1.1805611639622822 ROC AUC: 0.7406094968107725\n",
      "Validation loss: 2.6839234750002423 ROC AUC: 0.7236002834868887\n",
      "146 2 0.23355478048324585\n",
      "Validation loss: 1.0777170409429941 ROC AUC: 0.7354712969525159\n",
      "147 14 0.27216392755508423\n",
      "Validation loss: 1.153618758087916 ROC AUC: 0.732813607370659\n",
      "148 26 0.2504863440990448\n",
      "Validation loss: 1.406887236020423 ROC AUC: 0.6948972360028349\n",
      "Validation loss: 1.6508653858639546 ROC AUC: 0.7289156626506024\n",
      "150 0 0.4664253294467926\n",
      "Validation loss: 1.9903656465328292 ROC AUC: 0.7533664068036853\n",
      "151 12 0.30873215198516846\n",
      "Validation loss: 1.4678859994900937 ROC AUC: 0.729978738483345\n",
      "152 24 0.1008017361164093\n",
      "Validation loss: 1.3187263382981156 ROC AUC: 0.7418497519489724\n",
      "153 36 0.22703801095485687\n",
      "Validation loss: 1.2531182315965361 ROC AUC: 0.7429128277817151\n",
      "Validation loss: 1.0083111974577241 ROC AUC: 0.729801559177888\n",
      "155 10 0.15119655430316925\n",
      "Validation loss: 1.3388192385237738 ROC AUC: 0.7629340892983699\n",
      "156 22 0.39447709918022156\n",
      "Validation loss: 1.8229027386532715 ROC AUC: 0.7280297661233168\n",
      "157 34 0.1630033403635025\n",
      "Validation loss: 2.1040191697758557 ROC AUC: 0.7184620836286323\n",
      "Validation loss: 1.0836355796712913 ROC AUC: 0.7069454287739192\n",
      "159 8 0.3350999355316162\n",
      "Validation loss: 1.4980802914954179 ROC AUC: 0.7104890148830617\n",
      "160 20 0.23913413286209106\n",
      "Validation loss: 1.304721229913219 ROC AUC: 0.6980864635010631\n",
      "161 32 0.27861273288726807\n",
      "Validation loss: 2.94083840878594 ROC AUC: 0.6745216158752658\n",
      "Validation loss: 0.9461986817271504 ROC AUC: 0.7436215450035436\n",
      "163 6 0.23440605401992798\n",
      "Validation loss: 1.0891381573203385 ROC AUC: 0.7508858965272855\n",
      "164 18 0.08431153744459152\n",
      "Validation loss: 1.2228777720438724 ROC AUC: 0.7569099929128277\n",
      "165 30 0.22324758768081665\n",
      "Validation loss: 1.3601217917259165 ROC AUC: 0.7285613040396882\n",
      "Validation loss: 1.1024352154194914 ROC AUC: 0.6963146704464918\n",
      "167 4 0.4420575797557831\n",
      "Validation loss: 1.9182262523284812 ROC AUC: 0.7085400425230333\n",
      "168 16 0.1273634284734726\n",
      "Validation loss: 1.3753899091126902 ROC AUC: 0.7560240963855421\n",
      "169 28 0.2241986095905304\n",
      "Validation loss: 1.452248644355117 ROC AUC: 0.7414953933380581\n",
      "Validation loss: 1.61387507568132 ROC AUC: 0.7214741318214033\n",
      "171 2 0.327597439289093\n",
      "Validation loss: 1.5710277391585292 ROC AUC: 0.7250177179305457\n",
      "172 14 0.17267630994319916\n",
      "Validation loss: 1.540403631349273 ROC AUC: 0.7280297661233168\n",
      "173 26 0.2583945691585541\n",
      "Validation loss: 1.176890646779774 ROC AUC: 0.7464564138908575\n",
      "Validation loss: 1.2179077768957378 ROC AUC: 0.7540751240255139\n",
      "175 0 0.1825224757194519\n",
      "Validation loss: 1.2865054287657833 ROC AUC: 0.7368887313961728\n",
      "176 12 0.15531232953071594\n",
      "Validation loss: 1.2701500820008336 ROC AUC: 0.7191708008504607\n",
      "177 24 0.14768999814987183\n",
      "Validation loss: 1.1273333653314224 ROC AUC: 0.7600992204110559\n",
      "178 36 0.182638019323349\n",
      "Validation loss: 1.2507926533553775 ROC AUC: 0.758681785967399\n",
      "Validation loss: 1.32557038992446 ROC AUC: 0.6961374911410347\n",
      "180 10 0.12316899746656418\n",
      "Validation loss: 1.2553874048965656 ROC AUC: 0.7535435861091425\n",
      "181 22 0.14136545360088348\n",
      "Validation loss: 1.3135469441382301 ROC AUC: 0.7360028348688873\n",
      "182 34 0.06605921685695648\n",
      "Validation loss: 1.4836273145991445 ROC AUC: 0.7274982282069454\n",
      "Validation loss: 1.56924298583277 ROC AUC: 0.7280297661233168\n",
      "184 8 0.17110015451908112\n",
      "Validation loss: 2.1561990652652767 ROC AUC: 0.6771793054571226\n",
      "185 20 0.3877263367176056\n",
      "Validation loss: 1.062272124732567 ROC AUC: 0.7303330970942594\n",
      "186 32 0.3222405016422272\n",
      "Validation loss: 1.6671830431515018 ROC AUC: 0.7331679659815733\n",
      "Validation loss: 1.6850121858104175 ROC AUC: 0.7383061658398299\n",
      "188 6 0.08016359806060791\n",
      "Validation loss: 1.21987690357183 ROC AUC: 0.744153082919915\n",
      "189 18 0.20575538277626038\n",
      "Validation loss: 1.3082383168454201 ROC AUC: 0.735648476257973\n",
      "190 30 0.14900606870651245\n",
      "Validation loss: 1.9041936176502152 ROC AUC: 0.7186392629340893\n",
      "Validation loss: 1.8037524010171953 ROC AUC: 0.7147413182140326\n",
      "192 4 0.2821562886238098\n",
      "Validation loss: 1.5263565983993328 ROC AUC: 0.7437987243090007\n",
      "193 16 0.11201325058937073\n",
      "Validation loss: 1.1906929631896366 ROC AUC: 0.7436215450035436\n",
      "194 28 0.17709949612617493\n",
      "Validation loss: 1.7400235640292137 ROC AUC: 0.7083628632175761\n",
      "Validation loss: 1.205696520821148 ROC AUC: 0.7485825655563431\n",
      "196 2 0.23659372329711914\n",
      "Validation loss: 1.957079147660969 ROC AUC: 0.7111977321048901\n",
      "197 14 0.11485093086957932\n",
      "Validation loss: 1.2735120721210706 ROC AUC: 0.735648476257973\n",
      "198 26 0.2960827648639679\n",
      "Validation loss: 1.571463200430207 ROC AUC: 0.7407866761162296\n",
      "Validation loss: 1.1594069019848148 ROC AUC: 0.7698440822111977\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.1523837353053845 Test ROC AUC: 0.8356884057971014\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'bace', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 778, 'task': 'classification', 'data_path': 'data/bace/bace.csv', 'target': ['Class']}}\n",
      "Running on: cuda:0\n",
      "1512\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1512\n",
      "Generating scaffold 1000/1512\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.167389154434204\n",
      "Validation loss: 1.1475311012457539 ROC AUC: 0.5756555634301914\n",
      "1 12 0.6344784498214722\n",
      "Validation loss: 0.7465676203468777 ROC AUC: 0.5717576187101346\n",
      "2 24 0.7782300710678101\n",
      "Validation loss: 1.1753587596463841 ROC AUC: 0.5279943302622254\n",
      "3 36 0.5132144093513489\n",
      "Validation loss: 0.9957645642046897 ROC AUC: 0.589652728561304\n",
      "Validation loss: 1.8433431907994857 ROC AUC: 0.5799078667611623\n",
      "5 10 0.6271876692771912\n",
      "Validation loss: 2.3310593721882396 ROC AUC: 0.6112686038270729\n",
      "6 22 0.5514845252037048\n",
      "Validation loss: 1.5544409396632617 ROC AUC: 0.6169383416017009\n",
      "7 34 0.5755547285079956\n",
      "Validation loss: 1.096008547094484 ROC AUC: 0.6236711552090715\n",
      "Validation loss: 0.9973323629391904 ROC AUC: 0.651665485471297\n",
      "9 8 0.4625900983810425\n",
      "Validation loss: 1.109965473216101 ROC AUC: 0.6575124025513819\n",
      "10 20 0.4795072078704834\n",
      "Validation loss: 2.0143665462140214 ROC AUC: 0.6424521615875266\n",
      "11 32 0.41454941034317017\n",
      "Validation loss: 1.646307508677047 ROC AUC: 0.6054216867469879\n",
      "Validation loss: 1.0996879532637185 ROC AUC: 0.635719347980156\n",
      "13 6 0.2991671860218048\n",
      "Validation loss: 1.431875048094238 ROC AUC: 0.6183557760453579\n",
      "14 18 0.6969812512397766\n",
      "Validation loss: 2.136981994111017 ROC AUC: 0.6020552799433027\n",
      "15 30 0.409026175737381\n",
      "Validation loss: 1.5645739716409848 ROC AUC: 0.6498936924167257\n",
      "Validation loss: 1.134594774404109 ROC AUC: 0.6226080793763289\n",
      "17 4 0.5223333239555359\n",
      "Validation loss: 0.9981255811571286 ROC AUC: 0.6692062367115521\n",
      "18 16 0.41181787848472595\n",
      "Validation loss: 1.2207258592378225 ROC AUC: 0.6293408929836994\n",
      "19 28 0.2890951335430145\n",
      "Validation loss: 1.4254067875691596 ROC AUC: 0.6599929128277817\n",
      "Validation loss: 1.7379069044100528 ROC AUC: 0.5829199149539334\n",
      "21 2 0.38245803117752075\n",
      "Validation loss: 1.4287360164503389 ROC AUC: 0.7122608079376328\n",
      "22 14 0.40098661184310913\n",
      "Validation loss: 1.4323096638483717 ROC AUC: 0.6560949681077249\n",
      "23 26 0.44848376512527466\n",
      "Validation loss: 0.9232292945021825 ROC AUC: 0.6521970233876684\n",
      "Validation loss: 1.10302842294933 ROC AUC: 0.7090715804394045\n",
      "25 0 0.42623665928840637\n",
      "Validation loss: 1.2643274104358344 ROC AUC: 0.6394401133947555\n",
      "26 12 0.44859957695007324\n",
      "Validation loss: 1.1256288250550528 ROC AUC: 0.6599929128277817\n",
      "27 24 0.6258693337440491\n",
      "Validation loss: 0.9361822249873585 ROC AUC: 0.66194188518781\n",
      "28 36 0.638582706451416\n",
      "Validation loss: 1.0511032137649738 ROC AUC: 0.6847980155917789\n",
      "Validation loss: 1.746662043577788 ROC AUC: 0.6302267895109851\n",
      "30 10 0.29569774866104126\n",
      "Validation loss: 1.1699303100440677 ROC AUC: 0.6736357193479802\n",
      "31 22 0.386133074760437\n",
      "Validation loss: 0.8166687670132972 ROC AUC: 0.6800141743444367\n",
      "32 34 0.4197689890861511\n",
      "Validation loss: 0.8432452560260596 ROC AUC: 0.7034018426647768\n",
      "Validation loss: 1.3454136801081777 ROC AUC: 0.6789510985116939\n",
      "34 8 0.5089844465255737\n",
      "Validation loss: 0.8285776258304419 ROC AUC: 0.6918851878100638\n",
      "35 20 0.39666056632995605\n",
      "Validation loss: 1.0407241424977385 ROC AUC: 0.683734939759036\n",
      "36 32 0.31137144565582275\n",
      "Validation loss: 1.0235428257493784 ROC AUC: 0.6894046775336641\n",
      "Validation loss: 1.74626756503882 ROC AUC: 0.6408575478384124\n",
      "38 6 0.2942636013031006\n",
      "Validation loss: 0.9477782734971962 ROC AUC: 0.6332388377037562\n",
      "39 18 0.3186892569065094\n",
      "Validation loss: 0.796098559897467 ROC AUC: 0.7049964564138909\n",
      "40 30 0.3972998559474945\n",
      "Validation loss: 0.80032012438932 ROC AUC: 0.7200566973777464\n",
      "Validation loss: 1.4302140711159106 ROC AUC: 0.6472360028348689\n",
      "42 4 0.46415162086486816\n",
      "Validation loss: 0.931593728381277 ROC AUC: 0.6863926293408931\n",
      "43 16 0.47835150361061096\n",
      "Validation loss: 1.0414445510763206 ROC AUC: 0.7074769666902906\n",
      "44 28 0.41513752937316895\n",
      "Validation loss: 1.3010128799653211 ROC AUC: 0.6816087880935506\n",
      "Validation loss: 1.2652877079730003 ROC AUC: 0.6716867469879518\n",
      "46 2 0.3487902283668518\n",
      "Validation loss: 1.0331128772520861 ROC AUC: 0.7010985116938342\n",
      "47 14 0.7028347849845886\n",
      "Validation loss: 0.7538606595519363 ROC AUC: 0.7374202693125442\n",
      "48 26 0.3401172459125519\n",
      "Validation loss: 1.0930049695716 ROC AUC: 0.676293408929837\n",
      "Validation loss: 0.8570608638769743 ROC AUC: 0.7094259390503189\n",
      "50 0 0.24510325491428375\n",
      "Validation loss: 0.9002605013499986 ROC AUC: 0.7175761871013465\n",
      "51 12 0.31228330731391907\n",
      "Validation loss: 1.0696747085906022 ROC AUC: 0.723954642097803\n",
      "52 24 0.39227139949798584\n",
      "Validation loss: 1.3934226336068665 ROC AUC: 0.6782423812898654\n",
      "53 36 0.3967767655849457\n",
      "Validation loss: 1.3189621575620791 ROC AUC: 0.6649539333805812\n",
      "Validation loss: 1.1616162109059214 ROC AUC: 0.6899362154500354\n",
      "55 10 0.44054409861564636\n",
      "Validation loss: 1.0177939348662925 ROC AUC: 0.7248405386250885\n",
      "56 22 0.28874748945236206\n",
      "Validation loss: 1.0541177755160047 ROC AUC: 0.6943656980864635\n",
      "57 34 0.44671234488487244\n",
      "Validation loss: 0.9159592626900073 ROC AUC: 0.6771793054571226\n",
      "Validation loss: 0.8808658395381953 ROC AUC: 0.6807228915662651\n",
      "59 8 0.20940600335597992\n",
      "Validation loss: 0.9039512327964733 ROC AUC: 0.7035790219702338\n",
      "60 20 0.22158688306808472\n",
      "Validation loss: 1.135727994489354 ROC AUC: 0.6686746987951807\n",
      "61 32 0.3510245978832245\n",
      "Validation loss: 0.9948641330201105 ROC AUC: 0.7136782423812899\n",
      "Validation loss: 0.941967995750983 ROC AUC: 0.6633593196314671\n",
      "63 6 0.2977488934993744\n",
      "Validation loss: 1.0026478791078985 ROC AUC: 0.7071226080793763\n",
      "64 18 0.5835338830947876\n",
      "Validation loss: 0.807914516783708 ROC AUC: 0.7088944011339475\n",
      "65 30 0.26701250672340393\n",
      "Validation loss: 0.7633449320761573 ROC AUC: 0.73706591070163\n",
      "Validation loss: 0.866635952169532 ROC AUC: 0.7115520907158043\n",
      "67 4 0.517892599105835\n",
      "Validation loss: 0.7033095470327415 ROC AUC: 0.7390148830616584\n",
      "68 16 0.39064791798591614\n",
      "Validation loss: 0.8674410597378055 ROC AUC: 0.6952515946137492\n",
      "69 28 0.26514479517936707\n",
      "Validation loss: 0.8355599983243753 ROC AUC: 0.718284904323175\n",
      "Validation loss: 0.9970600265540824 ROC AUC: 0.6952515946137492\n",
      "71 2 0.33017051219940186\n",
      "Validation loss: 0.750647079865664 ROC AUC: 0.6885187810063785\n",
      "72 14 0.21971818804740906\n",
      "Validation loss: 0.931181490816028 ROC AUC: 0.7310418143160878\n",
      "73 26 0.3407253921031952\n",
      "Validation loss: 0.911023739157923 ROC AUC: 0.6902905740609497\n",
      "Validation loss: 1.0448291128044886 ROC AUC: 0.6840892983699504\n",
      "75 0 0.42059388756752014\n",
      "Validation loss: 0.7828436860975051 ROC AUC: 0.722537207654146\n",
      "76 12 0.2350657731294632\n",
      "Validation loss: 0.9256412856626195 ROC AUC: 0.6934798015591779\n",
      "77 24 0.5103873014450073\n",
      "Validation loss: 0.9245137339396192 ROC AUC: 0.7294472005669738\n",
      "78 36 0.29738137125968933\n",
      "Validation loss: 0.8954056675070958 ROC AUC: 0.6858610914245216\n",
      "Validation loss: 1.2066622514598417 ROC AUC: 0.6785967399007796\n",
      "80 10 0.1927206814289093\n",
      "Validation loss: 0.896943917732365 ROC AUC: 0.7244861800141743\n",
      "81 22 0.2933720648288727\n",
      "Validation loss: 0.9774161664065936 ROC AUC: 0.7051736357193479\n",
      "82 34 0.3327839970588684\n",
      "Validation loss: 0.9062760870977743 ROC AUC: 0.6968462083628632\n",
      "Validation loss: 0.9832404101921233 ROC AUC: 0.7012756909992913\n",
      "84 8 0.2437247335910797\n",
      "Validation loss: 0.853697860477776 ROC AUC: 0.7207654145995748\n",
      "85 20 0.20086871087551117\n",
      "Validation loss: 0.9018103721126026 ROC AUC: 0.6635364989369241\n",
      "86 32 0.24962164461612701\n",
      "Validation loss: 0.9789243612857844 ROC AUC: 0.6890503189227498\n",
      "Validation loss: 0.9148831667489563 ROC AUC: 0.7124379872430899\n",
      "88 6 0.19446514546871185\n",
      "Validation loss: 1.0041180272765506 ROC AUC: 0.6679659815733523\n",
      "89 18 0.5556653738021851\n",
      "Validation loss: 0.919181915308466 ROC AUC: 0.7072997873848335\n",
      "90 30 0.31829413771629333\n",
      "Validation loss: 0.9207368457554191 ROC AUC: 0.7228915662650602\n",
      "Validation loss: 0.9701735041788871 ROC AUC: 0.6954287739192062\n",
      "92 4 0.25214746594429016\n",
      "Validation loss: 1.0361336552544145 ROC AUC: 0.672041105598866\n",
      "93 16 0.469147652387619\n",
      "Validation loss: 0.9661124190747343 ROC AUC: 0.7108433734939759\n",
      "94 28 0.25047367811203003\n",
      "Validation loss: 0.9615569383103326 ROC AUC: 0.6874557051736357\n",
      "Validation loss: 0.839616256833866 ROC AUC: 0.7246633593196314\n",
      "96 2 0.25680312514305115\n",
      "Validation loss: 0.9612378328051788 ROC AUC: 0.7035790219702338\n",
      "97 14 0.7159555554389954\n",
      "Validation loss: 0.8899984580791549 ROC AUC: 0.6745216158752658\n",
      "98 26 0.2868845462799072\n",
      "Validation loss: 0.9671820007412639 ROC AUC: 0.6832034018426648\n",
      "Validation loss: 0.9067035502945351 ROC AUC: 0.6888731396172927\n",
      "100 0 0.26228511333465576\n",
      "Validation loss: 0.8474415252540285 ROC AUC: 0.6867469879518072\n",
      "101 12 0.2345861792564392\n",
      "Validation loss: 0.9530460581874216 ROC AUC: 0.6943656980864635\n",
      "102 24 0.16195978224277496\n",
      "Validation loss: 0.997866844499348 ROC AUC: 0.6833805811481218\n",
      "103 36 0.2926921546459198\n",
      "Validation loss: 1.0748165127457372 ROC AUC: 0.6637136782423814\n",
      "Validation loss: 0.9362358300891144 ROC AUC: 0.6745216158752658\n",
      "105 10 0.307018905878067\n",
      "Validation loss: 1.0654706576012618 ROC AUC: 0.719702338766832\n",
      "106 22 0.4068952798843384\n",
      "Validation loss: 1.0464107567900853 ROC AUC: 0.7005669737774628\n",
      "107 34 0.37144073843955994\n",
      "Validation loss: 0.9846202229821919 ROC AUC: 0.6952515946137491\n",
      "Validation loss: 1.0069882546039606 ROC AUC: 0.7026931254429482\n",
      "109 8 0.2432083636522293\n",
      "Validation loss: 0.8614945952465992 ROC AUC: 0.7120836286321758\n",
      "110 20 0.2618170380592346\n",
      "Validation loss: 1.189490308824754 ROC AUC: 0.6752303330970941\n",
      "111 32 0.25448134541511536\n",
      "Validation loss: 1.033534007751389 ROC AUC: 0.6952515946137492\n",
      "Validation loss: 1.1238558856856744 ROC AUC: 0.6408575478384125\n",
      "113 6 0.35204771161079407\n",
      "Validation loss: 0.8996781347603198 ROC AUC: 0.7057051736357194\n",
      "114 18 0.13915807008743286\n",
      "Validation loss: 0.9567894446139305 ROC AUC: 0.6702693125442949\n",
      "115 30 0.15516464412212372\n",
      "Validation loss: 1.1053845475841042 ROC AUC: 0.7129695251594613\n",
      "Validation loss: 0.9465506860357247 ROC AUC: 0.7049964564138909\n",
      "117 4 0.23574823141098022\n",
      "Validation loss: 1.3031065985067 ROC AUC: 0.6817859673990078\n",
      "118 16 0.22193112969398499\n",
      "Validation loss: 1.1290554321364852 ROC AUC: 0.6871013465627214\n",
      "119 28 0.1801719069480896\n",
      "Validation loss: 0.979600322167605 ROC AUC: 0.7193479801559178\n",
      "Validation loss: 0.9457138121522815 ROC AUC: 0.7177533664068037\n",
      "121 2 0.12863901257514954\n",
      "Validation loss: 1.0389619667009014 ROC AUC: 0.7092487597448618\n",
      "122 14 0.22585038840770721\n",
      "Validation loss: 1.116257514385198 ROC AUC: 0.7053508150248051\n",
      "123 26 0.4090888798236847\n",
      "Validation loss: 1.1670675909282355 ROC AUC: 0.6539688164422396\n",
      "Validation loss: 1.0006779977027944 ROC AUC: 0.7099574769666902\n",
      "125 0 0.3143196105957031\n",
      "Validation loss: 1.015215340039588 ROC AUC: 0.7014528703047486\n",
      "126 12 0.2050231397151947\n",
      "Validation loss: 1.037600780954424 ROC AUC: 0.6679659815733522\n",
      "127 24 0.24388468265533447\n",
      "Validation loss: 1.18096289808387 ROC AUC: 0.7069454287739192\n",
      "128 36 0.22757749259471893\n",
      "Validation loss: 1.204918002450703 ROC AUC: 0.6968462083628633\n",
      "Validation loss: 1.0667913311364634 ROC AUC: 0.6941885187810064\n",
      "130 10 0.20661672949790955\n",
      "Validation loss: 1.184034061747671 ROC AUC: 0.72413182140326\n",
      "131 22 0.3728213310241699\n",
      "Validation loss: 1.2677731440951492 ROC AUC: 0.7030474840538625\n",
      "132 34 0.09827465564012527\n",
      "Validation loss: 0.9913246355309392 ROC AUC: 0.7195251594613749\n",
      "Validation loss: 0.9852156047000001 ROC AUC: 0.7193479801559177\n",
      "134 8 0.30617964267730713\n",
      "Validation loss: 1.0334936972485473 ROC AUC: 0.6812544294826364\n",
      "135 20 0.17765487730503082\n",
      "Validation loss: 1.0584533159306506 ROC AUC: 0.7388377037562013\n",
      "136 32 0.24188430607318878\n",
      "Validation loss: 1.030451554731028 ROC AUC: 0.706768249468462\n",
      "Validation loss: 1.2521877936180064 ROC AUC: 0.7035790219702339\n",
      "138 6 0.19346226751804352\n",
      "Validation loss: 1.2713477074705213 ROC AUC: 0.7034018426647768\n",
      "139 18 0.19716115295886993\n",
      "Validation loss: 1.1808155285601585 ROC AUC: 0.6987951807228915\n",
      "140 30 0.16721373796463013\n",
      "Validation loss: 1.0727491149839186 ROC AUC: 0.7135010630758327\n",
      "Validation loss: 0.9529375564183621 ROC AUC: 0.7189936215450035\n",
      "142 4 0.269726037979126\n",
      "Validation loss: 1.1446056255441628 ROC AUC: 0.6853295535081502\n",
      "143 16 0.15675824880599976\n",
      "Validation loss: 0.9550665147257167 ROC AUC: 0.731218993621545\n",
      "144 28 0.35910937190055847\n",
      "Validation loss: 1.0321067634797254 ROC AUC: 0.721119773210489\n",
      "Validation loss: 1.0742185577651522 ROC AUC: 0.7230687455705174\n",
      "146 2 0.2923949658870697\n",
      "Validation loss: 0.9980771707383213 ROC AUC: 0.716690290574061\n",
      "147 14 0.26889628171920776\n",
      "Validation loss: 1.1860884619469674 ROC AUC: 0.713855421686747\n",
      "148 26 0.16219070553779602\n",
      "Validation loss: 1.1069050016782143 ROC AUC: 0.7202338766832035\n",
      "Validation loss: 1.139262649397187 ROC AUC: 0.6856839121190645\n",
      "150 0 0.16897666454315186\n",
      "Validation loss: 1.1369541836100698 ROC AUC: 0.6897590361445782\n",
      "151 12 0.1366943120956421\n",
      "Validation loss: 1.293931258435281 ROC AUC: 0.6972005669737774\n",
      "152 24 0.10716209560632706\n",
      "Validation loss: 1.3005315606167773 ROC AUC: 0.6979092841956059\n",
      "153 36 0.2020042985677719\n",
      "Validation loss: 1.1576791985934933 ROC AUC: 0.709425939050319\n",
      "Validation loss: 1.1646044988505888 ROC AUC: 0.6693834160170092\n",
      "155 10 0.15769779682159424\n",
      "Validation loss: 1.312300367071139 ROC AUC: 0.7042877391920624\n",
      "156 22 0.18109184503555298\n",
      "Validation loss: 1.1825124175343293 ROC AUC: 0.6881644223954642\n",
      "157 34 0.20373578369617462\n",
      "Validation loss: 1.3207905174091161 ROC AUC: 0.6816087880935506\n",
      "Validation loss: 1.1295609466287473 ROC AUC: 0.7172218284904323\n",
      "159 8 0.17698515951633453\n",
      "Validation loss: 1.2949354609116812 ROC AUC: 0.6809000708717222\n",
      "160 20 0.31361961364746094\n",
      "Validation loss: 1.1295428378692527 ROC AUC: 0.6787739192062368\n",
      "161 32 0.16733483970165253\n",
      "Validation loss: 1.2158538371521905 ROC AUC: 0.7108433734939759\n",
      "Validation loss: 1.269941401007949 ROC AUC: 0.6500708717221828\n",
      "163 6 0.36857980489730835\n",
      "Validation loss: 1.2095597295571636 ROC AUC: 0.7145641389085755\n",
      "164 18 0.4412916600704193\n",
      "Validation loss: 1.2213002853835655 ROC AUC: 0.7012756909992913\n",
      "165 30 0.2563965618610382\n",
      "Validation loss: 1.303342846055694 ROC AUC: 0.6750531537916372\n",
      "Validation loss: 1.578388407530374 ROC AUC: 0.6934798015591779\n",
      "167 4 0.2542908787727356\n",
      "Validation loss: 1.2788984617650114 ROC AUC: 0.6901133947554925\n",
      "168 16 0.1696677803993225\n",
      "Validation loss: 1.2997134039733584 ROC AUC: 0.6980864635010631\n",
      "169 28 0.15718691051006317\n",
      "Validation loss: 1.62860196947262 ROC AUC: 0.6832034018426647\n",
      "Validation loss: 1.5472559492714357 ROC AUC: 0.6876328844790929\n",
      "171 2 0.21958470344543457\n",
      "Validation loss: 1.2495575480113756 ROC AUC: 0.6839121190644933\n",
      "172 14 0.15886694192886353\n",
      "Validation loss: 1.3035052288446995 ROC AUC: 0.7064138908575478\n",
      "173 26 0.196136474609375\n",
      "Validation loss: 1.4447500403748443 ROC AUC: 0.6800141743444366\n",
      "Validation loss: 1.4960780056896588 ROC AUC: 0.6596385542168675\n",
      "175 0 0.12941712141036987\n",
      "Validation loss: 1.293314739568344 ROC AUC: 0.7051736357193479\n",
      "176 12 0.13196733593940735\n",
      "Validation loss: 1.211411650607128 ROC AUC: 0.709603118355776\n",
      "177 24 0.17909210920333862\n",
      "Validation loss: 1.4380658257086545 ROC AUC: 0.7136782423812899\n",
      "178 36 0.19840696454048157\n",
      "Validation loss: 1.230493669478309 ROC AUC: 0.718284904323175\n",
      "Validation loss: 1.3522125545716444 ROC AUC: 0.7188164422395464\n",
      "180 10 0.14288559556007385\n",
      "Validation loss: 1.5385752529497967 ROC AUC: 0.71243798724309\n",
      "181 22 0.11705773323774338\n",
      "Validation loss: 1.5191621764606198 ROC AUC: 0.7048192771084337\n",
      "182 34 0.250801682472229\n",
      "Validation loss: 1.1167910367447809 ROC AUC: 0.7076541459957477\n",
      "Validation loss: 1.2918239914818315 ROC AUC: 0.7152728561304039\n",
      "184 8 0.12800978124141693\n",
      "Validation loss: 1.1938561205042908 ROC AUC: 0.713855421686747\n",
      "185 20 0.2285609245300293\n",
      "Validation loss: 1.300094595808067 ROC AUC: 0.7074769666902906\n",
      "186 32 0.39169439673423767\n",
      "Validation loss: 1.136360022405915 ROC AUC: 0.7390148830616584\n",
      "Validation loss: 1.4111710447349295 ROC AUC: 0.6713323883770376\n",
      "188 6 0.15669092535972595\n",
      "Validation loss: 1.4613012943836237 ROC AUC: 0.6925939050318922\n",
      "189 18 0.21547536551952362\n",
      "Validation loss: 1.36340947656442 ROC AUC: 0.682140326009922\n",
      "190 30 0.1827595978975296\n",
      "Validation loss: 1.5342083466763528 ROC AUC: 0.6922395464209781\n",
      "Validation loss: 1.2752945754701728 ROC AUC: 0.716867469879518\n",
      "192 4 0.25268247723579407\n",
      "Validation loss: 1.233566616939393 ROC AUC: 0.7003897944720057\n",
      "193 16 0.15605702996253967\n",
      "Validation loss: 1.3263934092805876 ROC AUC: 0.7035790219702338\n",
      "194 28 0.17937369644641876\n",
      "Validation loss: 1.2862181020098806 ROC AUC: 0.7345854004252304\n",
      "Validation loss: 1.2452708380111794 ROC AUC: 0.6856839121190644\n",
      "196 2 0.1680227816104889\n",
      "Validation loss: 1.3920711995355342 ROC AUC: 0.6589298369950389\n",
      "197 14 0.3045937716960907\n",
      "Validation loss: 1.299018776179939 ROC AUC: 0.674698795180723\n",
      "198 26 0.4494045376777649\n",
      "Validation loss: 1.238784223202838 ROC AUC: 0.6933026222537207\n",
      "Validation loss: 1.3244661842750398 ROC AUC: 0.7177533664068038\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.8655878587772972 Test ROC AUC: 0.8246376811594203\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'bace', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 779, 'task': 'classification', 'data_path': 'data/bace/bace.csv', 'target': ['Class']}}\n",
      "Running on: cuda:0\n",
      "1512\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1512\n",
      "Generating scaffold 1000/1512\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.2292821407318115\n",
      "Validation loss: 1.6460362396492862 ROC AUC: 0.5529766123316796\n",
      "1 12 0.6309611797332764\n",
      "Validation loss: 2.5175504384451353 ROC AUC: 0.588235294117647\n",
      "2 24 0.5464538335800171\n",
      "Validation loss: 1.1873196173977378 ROC AUC: 0.5992204110559887\n",
      "3 36 0.4790303409099579\n",
      "Validation loss: 1.2718829563911387 ROC AUC: 0.5905386250885897\n",
      "Validation loss: 1.2071310400173365 ROC AUC: 0.5136428065201984\n",
      "5 10 0.5969603061676025\n",
      "Validation loss: 1.9296444717621961 ROC AUC: 0.5850460666194188\n",
      "6 22 0.496266633272171\n",
      "Validation loss: 3.1933997924754163 ROC AUC: 0.6070163004961021\n",
      "7 34 0.49734172224998474\n",
      "Validation loss: 1.0777356956178779 ROC AUC: 0.6422749822820695\n",
      "Validation loss: 2.3428864644852694 ROC AUC: 0.6449326718639263\n",
      "9 8 0.5418071150779724\n",
      "Validation loss: 1.5425169483715335 ROC AUC: 0.6057760453579022\n",
      "10 20 0.5576200485229492\n",
      "Validation loss: 1.8973909537523788 ROC AUC: 0.5729978738483344\n",
      "11 32 0.582798421382904\n",
      "Validation loss: 1.9592700920357609 ROC AUC: 0.6624734231041813\n",
      "Validation loss: 1.7162245985687963 ROC AUC: 0.6165839829907866\n",
      "13 6 0.5418170690536499\n",
      "Validation loss: 1.0718115410267912 ROC AUC: 0.6482990786676116\n",
      "14 18 0.46650710701942444\n",
      "Validation loss: 1.7042157721045792 ROC AUC: 0.6394401133947556\n",
      "15 30 0.42012763023376465\n",
      "Validation loss: 1.6285122064565192 ROC AUC: 0.6305811481218995\n",
      "Validation loss: 1.5865169353043007 ROC AUC: 0.6995038979447201\n",
      "17 4 0.4495316743850708\n",
      "Validation loss: 1.4025535251920587 ROC AUC: 0.6591070163004961\n",
      "18 16 0.3198695182800293\n",
      "Validation loss: 1.5235553182513508 ROC AUC: 0.6844436569808645\n",
      "19 28 0.5082128643989563\n",
      "Validation loss: 1.6062162506659299 ROC AUC: 0.6674344436569808\n",
      "Validation loss: 1.4806246552246296 ROC AUC: 0.6481218993621545\n",
      "21 2 0.3901076018810272\n",
      "Validation loss: 1.5349776610633394 ROC AUC: 0.6645995747696669\n",
      "22 14 0.4353680908679962\n",
      "Validation loss: 1.2102246876583984 ROC AUC: 0.6782423812898652\n",
      "23 26 0.3483559489250183\n",
      "Validation loss: 1.4075237125750408 ROC AUC: 0.663359319631467\n",
      "Validation loss: 2.355600593895312 ROC AUC: 0.6394401133947556\n",
      "25 0 0.47872909903526306\n",
      "Validation loss: 1.63310360434829 ROC AUC: 0.6658398299078668\n",
      "26 12 0.33948269486427307\n",
      "Validation loss: 1.285966081335055 ROC AUC: 0.6112686038270729\n",
      "27 24 0.5505977272987366\n",
      "Validation loss: 1.4824725586846965 ROC AUC: 0.6410347271438697\n",
      "28 36 0.39218854904174805\n",
      "Validation loss: 1.44317507822782 ROC AUC: 0.695074415308292\n",
      "Validation loss: 1.6888029338508252 ROC AUC: 0.6261516654854712\n",
      "30 10 0.48217159509658813\n",
      "Validation loss: 1.475564847718801 ROC AUC: 0.6741672572643514\n",
      "31 22 0.4302122890949249\n",
      "Validation loss: 1.556469310987864 ROC AUC: 0.6847980155917788\n",
      "32 34 0.4829673767089844\n",
      "Validation loss: 1.560580202285817 ROC AUC: 0.6731041814316088\n",
      "Validation loss: 0.7653477499816591 ROC AUC: 0.6715095676824947\n",
      "34 8 0.3986137807369232\n",
      "Validation loss: 2.385140109535874 ROC AUC: 0.6249114103472715\n",
      "35 20 0.3482230007648468\n",
      "Validation loss: 2.1215167866637374 ROC AUC: 0.6481218993621545\n",
      "36 32 0.4832311272621155\n",
      "Validation loss: 1.0220280633067453 ROC AUC: 0.6950744153082921\n",
      "Validation loss: 0.8329796751603386 ROC AUC: 0.732636428065202\n",
      "38 6 0.3802470862865448\n",
      "Validation loss: 1.8058600520456074 ROC AUC: 0.6495393338058114\n",
      "39 18 0.3927929997444153\n",
      "Validation loss: 0.9308470507331242 ROC AUC: 0.6529057406094968\n",
      "40 30 0.44515261054039\n",
      "Validation loss: 1.4765700678162228 ROC AUC: 0.6817859673990078\n",
      "Validation loss: 1.1910589988657971 ROC AUC: 0.6888731396172927\n",
      "42 4 0.39448225498199463\n",
      "Validation loss: 1.709240583394537 ROC AUC: 0.625797306874557\n",
      "43 16 0.697070300579071\n",
      "Validation loss: 1.6697702392047604 ROC AUC: 0.6472360028348689\n",
      "44 28 0.34685018658638\n",
      "Validation loss: 0.9268461442151606 ROC AUC: 0.6732813607370659\n",
      "Validation loss: 2.0958930656609946 ROC AUC: 0.705350815024805\n",
      "46 2 0.29591602087020874\n",
      "Validation loss: 2.5733071841940975 ROC AUC: 0.6801913536498937\n",
      "47 14 0.44535893201828003\n",
      "Validation loss: 1.032596473662269 ROC AUC: 0.683557760453579\n",
      "48 26 0.35303133726119995\n",
      "Validation loss: 1.0271757174011886 ROC AUC: 0.6667257264351523\n",
      "Validation loss: 1.4434895199655697 ROC AUC: 0.6553862508858965\n",
      "50 0 0.29910844564437866\n",
      "Validation loss: 1.319884514966548 ROC AUC: 0.6716867469879517\n",
      "51 12 0.24959734082221985\n",
      "Validation loss: 1.482046443894999 ROC AUC: 0.6879872430900071\n",
      "52 24 0.46359243988990784\n",
      "Validation loss: 1.371279410968553 ROC AUC: 0.6702693125442948\n",
      "53 36 0.3990238904953003\n",
      "Validation loss: 0.9511694225254438 ROC AUC: 0.6993267186392629\n",
      "Validation loss: 0.8468749049483546 ROC AUC: 0.7072997873848335\n",
      "55 10 0.3868964612483978\n",
      "Validation loss: 1.1597051983637525 ROC AUC: 0.7003897944720057\n",
      "56 22 0.29770761728286743\n",
      "Validation loss: 0.9412190077320629 ROC AUC: 0.6532600992204111\n",
      "57 34 0.4276300072669983\n",
      "Validation loss: 1.6837955997479672 ROC AUC: 0.6500708717221829\n",
      "Validation loss: 1.1045383735997787 ROC AUC: 0.7223600283486888\n",
      "59 8 0.3964584171772003\n",
      "Validation loss: 0.9081088853198171 ROC AUC: 0.6934798015591779\n",
      "60 20 0.25122323632240295\n",
      "Validation loss: 1.2548048819927191 ROC AUC: 0.667611622962438\n",
      "61 32 0.5062693953514099\n",
      "Validation loss: 1.7630477567382206 ROC AUC: 0.6830262225372076\n",
      "Validation loss: 1.1846320526489358 ROC AUC: 0.7072997873848335\n",
      "63 6 0.15944842994213104\n",
      "Validation loss: 0.9772296161051618 ROC AUC: 0.6684975194897236\n",
      "64 18 0.2913591265678406\n",
      "Validation loss: 1.1660688673423616 ROC AUC: 0.6943656980864635\n",
      "65 30 0.30143511295318604\n",
      "Validation loss: 1.066294031427396 ROC AUC: 0.6684975194897236\n",
      "Validation loss: 1.0405920282104948 ROC AUC: 0.6931254429482636\n",
      "67 4 0.3912803828716278\n",
      "Validation loss: 1.260402042344706 ROC AUC: 0.6954287739192062\n",
      "68 16 0.3491266965866089\n",
      "Validation loss: 1.1776690885720664 ROC AUC: 0.6525513819985825\n",
      "69 28 0.3869512975215912\n",
      "Validation loss: 0.804649793943822 ROC AUC: 0.6569808646350106\n",
      "Validation loss: 0.9098513880312837 ROC AUC: 0.7147413182140325\n",
      "71 2 0.25394144654273987\n",
      "Validation loss: 1.2280701122536564 ROC AUC: 0.6948972360028348\n",
      "72 14 0.37768152356147766\n",
      "Validation loss: 1.5125385380738618 ROC AUC: 0.6723954642097804\n",
      "73 26 0.452380895614624\n",
      "Validation loss: 0.9581991868303311 ROC AUC: 0.6716867469879518\n",
      "Validation loss: 1.2593338465848505 ROC AUC: 0.6929482636428065\n",
      "75 0 0.2843657433986664\n",
      "Validation loss: 1.1986443230647914 ROC AUC: 0.6610559886605245\n",
      "76 12 0.2621985971927643\n",
      "Validation loss: 1.1570611994787556 ROC AUC: 0.7200566973777462\n",
      "77 24 0.24268725514411926\n",
      "Validation loss: 1.27663978282979 ROC AUC: 0.6759390503189228\n",
      "78 36 0.2892610728740692\n",
      "Validation loss: 1.778072898751063 ROC AUC: 0.6607016300496102\n",
      "Validation loss: 1.017134295394089 ROC AUC: 0.7149184975194897\n",
      "80 10 0.2459462285041809\n",
      "Validation loss: 1.0040903620372545 ROC AUC: 0.7076541459957476\n",
      "81 22 0.25175535678863525\n",
      "Validation loss: 1.0694321425545295 ROC AUC: 0.6766477675407513\n",
      "82 34 0.24507610499858856\n",
      "Validation loss: 1.0834882417261995 ROC AUC: 0.6966690290574061\n",
      "Validation loss: 0.8482951458716235 ROC AUC: 0.7223600283486888\n",
      "84 8 0.32461854815483093\n",
      "Validation loss: 1.150093777290243 ROC AUC: 0.7172218284904323\n",
      "85 20 0.3537975251674652\n",
      "Validation loss: 1.0692987481489877 ROC AUC: 0.7159815733522323\n",
      "86 32 0.33902060985565186\n",
      "Validation loss: 1.82220609298605 ROC AUC: 0.6846208362863218\n",
      "Validation loss: 0.9564160961189018 ROC AUC: 0.7074769666902905\n",
      "88 6 0.3795883059501648\n",
      "Validation loss: 1.6348276927771157 ROC AUC: 0.6771793054571227\n",
      "89 18 0.2952086627483368\n",
      "Validation loss: 1.6119024974620895 ROC AUC: 0.6931254429482636\n",
      "90 30 0.23584310710430145\n",
      "Validation loss: 1.3546433361950299 ROC AUC: 0.7074769666902906\n",
      "Validation loss: 1.1130953024554726 ROC AUC: 0.7259036144578312\n",
      "92 4 0.28234755992889404\n",
      "Validation loss: 1.1278392408067817 ROC AUC: 0.7393692416725727\n",
      "93 16 0.36363714933395386\n",
      "Validation loss: 1.3024766216214918 ROC AUC: 0.6667257264351524\n",
      "94 28 0.3544963598251343\n",
      "Validation loss: 1.3131979806533713 ROC AUC: 0.6428065201984409\n",
      "Validation loss: 1.1427472087721162 ROC AUC: 0.6807228915662651\n",
      "96 2 0.32786113023757935\n",
      "Validation loss: 1.2725869196140214 ROC AUC: 0.6672572643515238\n",
      "97 14 0.23379746079444885\n",
      "Validation loss: 1.7468614901927924 ROC AUC: 0.6915308291991495\n",
      "98 26 0.35876840353012085\n",
      "Validation loss: 0.94233698402809 ROC AUC: 0.6943656980864635\n",
      "Validation loss: 0.9934531114748771 ROC AUC: 0.6817859673990078\n",
      "100 0 0.20696590840816498\n",
      "Validation loss: 0.940384002316077 ROC AUC: 0.7136782423812899\n",
      "101 12 0.2444056272506714\n",
      "Validation loss: 1.5224232918379323 ROC AUC: 0.6929482636428065\n",
      "102 24 0.3671858012676239\n",
      "Validation loss: 1.4198585353939739 ROC AUC: 0.664776754075124\n",
      "103 36 0.2919301986694336\n",
      "Validation loss: 1.0726348820901075 ROC AUC: 0.7072997873848335\n",
      "Validation loss: 1.3762668805406584 ROC AUC: 0.6906449326718639\n",
      "105 10 0.24831049144268036\n",
      "Validation loss: 1.1207431452163796 ROC AUC: 0.697909284195606\n",
      "106 22 0.3773309588432312\n",
      "Validation loss: 1.5852111901668524 ROC AUC: 0.7149184975194898\n",
      "107 34 0.24073846638202667\n",
      "Validation loss: 1.01864427367583 ROC AUC: 0.6851523742026931\n",
      "Validation loss: 1.2422130131563605 ROC AUC: 0.6855067328136073\n",
      "109 8 0.4490874111652374\n",
      "Validation loss: 1.578510800734261 ROC AUC: 0.7028703047484054\n",
      "110 20 0.19781629741191864\n",
      "Validation loss: 1.4839893990005089 ROC AUC: 0.699326718639263\n",
      "111 32 0.2473376840353012\n",
      "Validation loss: 1.1539804951244632 ROC AUC: 0.6566265060240964\n",
      "Validation loss: 1.2756617692922125 ROC AUC: 0.6807228915662651\n",
      "113 6 0.151317298412323\n",
      "Validation loss: 1.303435636671963 ROC AUC: 0.7159815733522324\n",
      "114 18 0.28265252709388733\n",
      "Validation loss: 1.3130275595267087 ROC AUC: 0.695251594613749\n",
      "115 30 0.22021538019180298\n",
      "Validation loss: 1.2196975425379166 ROC AUC: 0.6920623671155209\n",
      "Validation loss: 1.075046742988738 ROC AUC: 0.7057051736357194\n",
      "117 4 0.17156191170215607\n",
      "Validation loss: 1.0947261961880108 ROC AUC: 0.6993267186392629\n",
      "118 16 0.20752981305122375\n",
      "Validation loss: 1.5436246284585915 ROC AUC: 0.657512402551382\n",
      "119 28 0.19126422703266144\n",
      "Validation loss: 1.4207677264876712 ROC AUC: 0.6743444365698087\n",
      "Validation loss: 1.3035533428192139 ROC AUC: 0.6883416017009213\n",
      "121 2 0.18516117334365845\n",
      "Validation loss: 1.1416395381586442 ROC AUC: 0.7136782423812899\n",
      "122 14 0.18027184903621674\n",
      "Validation loss: 1.1079266422631724 ROC AUC: 0.728206945428774\n",
      "123 26 0.18466809391975403\n",
      "Validation loss: 1.3615719632597159 ROC AUC: 0.7156272147413182\n",
      "Validation loss: 1.0464378737455962 ROC AUC: 0.6812544294826365\n",
      "125 0 0.28221485018730164\n",
      "Validation loss: 1.2296582878820155 ROC AUC: 0.7152728561304039\n",
      "126 12 0.25749412178993225\n",
      "Validation loss: 1.1148873078112571 ROC AUC: 0.7290928419560595\n",
      "127 24 0.2369377613067627\n",
      "Validation loss: 1.33179927819612 ROC AUC: 0.6819631467044649\n",
      "128 36 0.21480849385261536\n",
      "Validation loss: 1.4044489378960716 ROC AUC: 0.6615875265768958\n",
      "Validation loss: 1.3007987011347386 ROC AUC: 0.7039333805811481\n",
      "130 10 0.21459528803825378\n",
      "Validation loss: 1.604471473504376 ROC AUC: 0.7165131112686038\n",
      "131 22 0.11098357290029526\n",
      "Validation loss: 1.2283711386042715 ROC AUC: 0.6986180014174345\n",
      "132 34 0.20719747245311737\n",
      "Validation loss: 1.2272646281103425 ROC AUC: 0.6754075124025515\n",
      "Validation loss: 1.2101722150448933 ROC AUC: 0.7064138908575479\n",
      "134 8 0.1885606348514557\n",
      "Validation loss: 1.5583916073603346 ROC AUC: 0.7276754075124025\n",
      "135 20 0.20557278394699097\n",
      "Validation loss: 1.1113865738672926 ROC AUC: 0.7135010630758327\n",
      "136 32 0.2051677256822586\n",
      "Validation loss: 1.6050274008946703 ROC AUC: 0.6817859673990078\n",
      "Validation loss: 1.3445973625246264 ROC AUC: 0.7143869596031184\n",
      "138 6 0.23522602021694183\n",
      "Validation loss: 1.5216160688968683 ROC AUC: 0.6886959603118356\n",
      "139 18 0.372486412525177\n",
      "Validation loss: 1.0175362983286775 ROC AUC: 0.7097802976612332\n",
      "140 30 0.2261618822813034\n",
      "Validation loss: 1.2317879602609092 ROC AUC: 0.7104890148830616\n",
      "Validation loss: 1.1540401514792284 ROC AUC: 0.7189936215450036\n",
      "142 4 0.3713337779045105\n",
      "Validation loss: 1.1962802323284527 ROC AUC: 0.725549255846917\n",
      "143 16 0.20914871990680695\n",
      "Validation loss: 1.4680666899838983 ROC AUC: 0.6943656980864634\n",
      "144 28 0.19979403913021088\n",
      "Validation loss: 1.2866357209666675 ROC AUC: 0.709603118355776\n",
      "Validation loss: 1.1535843871287164 ROC AUC: 0.7246633593196316\n",
      "146 2 0.3259389400482178\n",
      "Validation loss: 1.2053015003141188 ROC AUC: 0.7283841247342311\n",
      "147 14 0.16763311624526978\n",
      "Validation loss: 1.4557886171025156 ROC AUC: 0.6970233876683203\n",
      "148 26 0.12998180091381073\n",
      "Validation loss: 1.3664284147174153 ROC AUC: 0.7360028348688873\n",
      "Validation loss: 1.377739733418092 ROC AUC: 0.7049964564138909\n",
      "150 0 0.2009589523077011\n",
      "Validation loss: 1.5069227929146873 ROC AUC: 0.7046420978029766\n",
      "151 12 0.2808837890625\n",
      "Validation loss: 1.4006764829553515 ROC AUC: 0.7131467044649185\n",
      "152 24 0.1954030990600586\n",
      "Validation loss: 1.6141097182469653 ROC AUC: 0.7248405386250887\n",
      "153 36 0.25906437635421753\n",
      "Validation loss: 1.3557843822517142 ROC AUC: 0.7170446491849752\n",
      "Validation loss: 1.1539634501697211 ROC AUC: 0.744330262225372\n",
      "155 10 0.14779670536518097\n",
      "Validation loss: 1.3750758344763951 ROC AUC: 0.6957831325301205\n",
      "156 22 0.13400080800056458\n",
      "Validation loss: 1.2624271950184904 ROC AUC: 0.7088944011339475\n",
      "157 34 0.1602962166070938\n",
      "Validation loss: 1.1647781117862424 ROC AUC: 0.7163359319631467\n",
      "Validation loss: 1.1317210442183034 ROC AUC: 0.7055279943302623\n",
      "159 8 0.1756717562675476\n",
      "Validation loss: 1.0785299721143105 ROC AUC: 0.7429128277817151\n",
      "160 20 0.24112845957279205\n",
      "Validation loss: 1.1826920604074238 ROC AUC: 0.738483345145287\n",
      "161 32 0.19821862876415253\n",
      "Validation loss: 1.07177640823339 ROC AUC: 0.7305102763997164\n",
      "Validation loss: 1.3780584027435605 ROC AUC: 0.6984408221119773\n",
      "163 6 0.18502821028232574\n",
      "Validation loss: 1.0210565995696366 ROC AUC: 0.7280297661233168\n",
      "164 18 0.22302117943763733\n",
      "Validation loss: 1.3126467490038336 ROC AUC: 0.7207654145995748\n",
      "165 30 0.316552996635437\n",
      "Validation loss: 0.9306558512693999 ROC AUC: 0.7193479801559178\n",
      "Validation loss: 1.0870721979646494 ROC AUC: 0.6888731396172928\n",
      "167 4 0.3030129075050354\n",
      "Validation loss: 1.2771339716500794 ROC AUC: 0.6908221119773211\n",
      "168 16 0.26842769980430603\n",
      "Validation loss: 0.9273249621422875 ROC AUC: 0.7188164422395464\n",
      "169 28 0.27196165919303894\n",
      "Validation loss: 1.301740441890742 ROC AUC: 0.6761162296243798\n",
      "Validation loss: 1.144335088350915 ROC AUC: 0.6947200566973777\n",
      "171 2 0.15779097378253937\n",
      "Validation loss: 1.1948575112993354 ROC AUC: 0.7200566973777464\n",
      "172 14 0.11784343421459198\n",
      "Validation loss: 1.2915412965199806 ROC AUC: 0.7065910701630049\n",
      "173 26 0.11720138788223267\n",
      "Validation loss: 1.05005749487719 ROC AUC: 0.7608079376328845\n",
      "Validation loss: 1.1996292341623875 ROC AUC: 0.6890503189227498\n",
      "175 0 0.29452621936798096\n",
      "Validation loss: 1.0721038197050032 ROC AUC: 0.7329907866761163\n",
      "176 12 0.15903514623641968\n",
      "Validation loss: 1.2913212602501674 ROC AUC: 0.6739900779588943\n",
      "177 24 0.08641911298036575\n",
      "Validation loss: 1.2086083904796878 ROC AUC: 0.7344082211197733\n",
      "178 36 0.22832942008972168\n",
      "Validation loss: 1.2241507579159263 ROC AUC: 0.682140326009922\n",
      "Validation loss: 1.2993655504769837 ROC AUC: 0.7321048901488306\n",
      "180 10 0.3059636950492859\n",
      "Validation loss: 1.9119191146054804 ROC AUC: 0.6830262225372077\n",
      "181 22 0.12002620100975037\n",
      "Validation loss: 1.3527970242973983 ROC AUC: 0.7430900070871722\n",
      "182 34 0.1771281212568283\n",
      "Validation loss: 1.373455788126055 ROC AUC: 0.6881644223954642\n",
      "Validation loss: 1.0959370305996068 ROC AUC: 0.7287384833451452\n",
      "184 8 0.11694172769784927\n",
      "Validation loss: 1.2862822267393403 ROC AUC: 0.7422041105598867\n",
      "185 20 0.3429628312587738\n",
      "Validation loss: 1.4438034690768513 ROC AUC: 0.7418497519489723\n",
      "186 32 0.32062697410583496\n",
      "Validation loss: 1.2980955622054093 ROC AUC: 0.7234231041814316\n",
      "Validation loss: 1.442998813477573 ROC AUC: 0.743975903614458\n",
      "188 6 0.13644039630889893\n",
      "Validation loss: 1.3480133884000463 ROC AUC: 0.7562012756909994\n",
      "189 18 0.1435438096523285\n",
      "Validation loss: 1.4698098471622594 ROC AUC: 0.696669029057406\n",
      "190 30 0.11976000666618347\n",
      "Validation loss: 1.4709450851213064 ROC AUC: 0.7503543586109143\n",
      "Validation loss: 1.2817615515348928 ROC AUC: 0.7218284904323174\n",
      "192 4 0.1483270227909088\n",
      "Validation loss: 1.357039318968918 ROC AUC: 0.7446846208362864\n",
      "193 16 0.1391807347536087\n",
      "Validation loss: 1.1137367830371225 ROC AUC: 0.7567328136073707\n",
      "194 28 0.14601950347423553\n",
      "Validation loss: 1.3762332374686437 ROC AUC: 0.7494684620836286\n",
      "Validation loss: 1.5892937214958747 ROC AUC: 0.6587526576895819\n",
      "196 2 0.12391242384910583\n",
      "Validation loss: 1.5656969168328292 ROC AUC: 0.7106661941885188\n",
      "197 14 0.18507109582424164\n",
      "Validation loss: 1.2097955807944796 ROC AUC: 0.7604535790219702\n",
      "198 26 0.15109845995903015\n",
      "Validation loss: 1.2810891910104563 ROC AUC: 0.770198440822112\n",
      "Validation loss: 1.4101571073595263 ROC AUC: 0.7547838412473423\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.1544342668432939 Test ROC AUC: 0.8097826086956522\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'bace', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 780, 'task': 'classification', 'data_path': 'data/bace/bace.csv', 'target': ['Class']}}\n",
      "Running on: cuda:0\n",
      "1512\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1512\n",
      "Generating scaffold 1000/1512\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.1750001907348633\n",
      "Validation loss: 0.9032774117608734 ROC AUC: 0.5024805102763996\n",
      "1 12 0.7133747935295105\n",
      "Validation loss: 0.7480392969207258 ROC AUC: 0.6523742026931254\n",
      "2 24 0.6147761344909668\n",
      "Validation loss: 1.9951719085112314 ROC AUC: 0.5398653437278526\n",
      "3 36 0.5739670991897583\n",
      "Validation loss: 2.2771756459545616 ROC AUC: 0.5744153082919915\n",
      "Validation loss: 2.053307013795865 ROC AUC: 0.5788447909284196\n",
      "5 10 0.5506964921951294\n",
      "Validation loss: 0.8242663145065308 ROC AUC: 0.6732813607370658\n",
      "6 22 0.454838365316391\n",
      "Validation loss: 0.868739574160797 ROC AUC: 0.6851523742026931\n",
      "7 34 0.5519543290138245\n",
      "Validation loss: 1.1126026396719826 ROC AUC: 0.6029411764705882\n",
      "Validation loss: 1.0814471844805786 ROC AUC: 0.6798369950389794\n",
      "9 8 0.6084713339805603\n",
      "Validation loss: 1.3088663784873407 ROC AUC: 0.6608788093550674\n",
      "10 20 0.39113283157348633\n",
      "Validation loss: 1.1383574944458261 ROC AUC: 0.625797306874557\n",
      "11 32 0.794368326663971\n",
      "Validation loss: 0.6596477481703095 ROC AUC: 0.6814316087880936\n",
      "Validation loss: 0.7935353635952173 ROC AUC: 0.6504252303330971\n",
      "13 6 0.40556800365448\n",
      "Validation loss: 1.296269928382722 ROC AUC: 0.6557406094968108\n",
      "14 18 0.6148430109024048\n",
      "Validation loss: 1.207469490979681 ROC AUC: 0.6174698795180723\n",
      "15 30 0.41725707054138184\n",
      "Validation loss: 0.7385311422758545 ROC AUC: 0.6913536498936923\n",
      "Validation loss: 0.6995796146771766 ROC AUC: 0.7156272147413183\n",
      "17 4 0.38127779960632324\n",
      "Validation loss: 1.2336444767895123 ROC AUC: 0.7016300496102055\n",
      "18 16 0.437045693397522\n",
      "Validation loss: 0.6661333587785431 ROC AUC: 0.7150956768249469\n",
      "19 28 0.30901792645454407\n",
      "Validation loss: 1.2575782671669462 ROC AUC: 0.6837349397590361\n",
      "Validation loss: 1.2205365864646356 ROC AUC: 0.57636428065202\n",
      "21 2 0.43254637718200684\n",
      "Validation loss: 0.8016735295586238 ROC AUC: 0.6860382707299787\n",
      "22 14 0.33041441440582275\n",
      "Validation loss: 0.892845370122139 ROC AUC: 0.6578667611622963\n",
      "23 26 0.5605195760726929\n",
      "Validation loss: 0.8157089392081002 ROC AUC: 0.7108433734939759\n",
      "Validation loss: 0.8617632318016709 ROC AUC: 0.6468816442239547\n",
      "25 0 0.3636801540851593\n",
      "Validation loss: 0.7472332337044723 ROC AUC: 0.7145641389085755\n",
      "26 12 0.4378572404384613\n",
      "Validation loss: 0.9164972605294739 ROC AUC: 0.6576895818568391\n",
      "27 24 0.32365745306015015\n",
      "Validation loss: 1.22765354525964 ROC AUC: 0.7333451452870304\n",
      "28 36 0.3834574818611145\n",
      "Validation loss: 1.8485995404767674 ROC AUC: 0.7154500354358612\n",
      "Validation loss: 0.8734633073901499 ROC AUC: 0.6723954642097802\n",
      "30 10 0.26019608974456787\n",
      "Validation loss: 0.9081960703363482 ROC AUC: 0.6844436569808646\n",
      "31 22 0.36712726950645447\n",
      "Validation loss: 1.0583749370069693 ROC AUC: 0.6383770375620127\n",
      "32 34 0.49462971091270447\n",
      "Validation loss: 0.7104836816819299 ROC AUC: 0.693656980864635\n",
      "Validation loss: 0.8114885147044201 ROC AUC: 0.6601700921332389\n",
      "34 8 0.4366525411605835\n",
      "Validation loss: 0.8760696712708631 ROC AUC: 0.660347271438696\n",
      "35 20 0.4521334171295166\n",
      "Validation loss: 0.9455430318188194 ROC AUC: 0.6692062367115521\n",
      "36 32 0.3278487026691437\n",
      "Validation loss: 0.9047051391854192 ROC AUC: 0.6571580439404677\n",
      "Validation loss: 1.0672397550368151 ROC AUC: 0.6392629340892984\n",
      "38 6 0.5336635708808899\n",
      "Validation loss: 1.0530217128084196 ROC AUC: 0.7152728561304039\n",
      "39 18 0.39807021617889404\n",
      "Validation loss: 1.0949004967481095 ROC AUC: 0.6614103472714387\n",
      "40 30 0.385708749294281\n",
      "Validation loss: 0.7014634321067507 ROC AUC: 0.6991495393338059\n",
      "Validation loss: 0.8426527905937852 ROC AUC: 0.6847980155917789\n",
      "42 4 0.31547462940216064\n",
      "Validation loss: 0.9019047945540473 ROC AUC: 0.7035790219702339\n",
      "43 16 0.3747180104255676\n",
      "Validation loss: 0.7784368545803803 ROC AUC: 0.7010985116938341\n",
      "44 28 0.43113312125205994\n",
      "Validation loss: 0.790412929673858 ROC AUC: 0.6975549255846917\n",
      "Validation loss: 0.9958946823284326 ROC AUC: 0.6847980155917789\n",
      "46 2 0.4280245006084442\n",
      "Validation loss: 0.8200490135230766 ROC AUC: 0.7007441530829199\n",
      "47 14 0.19124017655849457\n",
      "Validation loss: 0.7824722145566877 ROC AUC: 0.6607016300496102\n",
      "48 26 0.22525516152381897\n",
      "Validation loss: 0.9193028424749311 ROC AUC: 0.6583982990786676\n",
      "Validation loss: 0.8303753642846416 ROC AUC: 0.6885187810063784\n",
      "50 0 0.4278338849544525\n",
      "Validation loss: 0.6917139402288475 ROC AUC: 0.7195251594613749\n",
      "51 12 0.36194512248039246\n",
      "Validation loss: 0.7464280120584349 ROC AUC: 0.729978738483345\n",
      "52 24 0.3484964668750763\n",
      "Validation loss: 0.8673823266629351 ROC AUC: 0.7030474840538624\n",
      "53 36 0.38509097695350647\n",
      "Validation loss: 0.7984017710022578 ROC AUC: 0.7175761871013465\n",
      "Validation loss: 0.7483912347168322 ROC AUC: 0.7221828490432318\n",
      "55 10 0.3388630449771881\n",
      "Validation loss: 1.024512262533832 ROC AUC: 0.6761162296243799\n",
      "56 22 0.3417344093322754\n",
      "Validation loss: 0.7475751200259126 ROC AUC: 0.742735648476258\n",
      "57 34 0.20950381457805634\n",
      "Validation loss: 0.707259276450075 ROC AUC: 0.7204110559886605\n",
      "Validation loss: 1.0860085309735987 ROC AUC: 0.7216513111268603\n",
      "59 8 0.5029960870742798\n",
      "Validation loss: 0.7648547615436528 ROC AUC: 0.7381289865343728\n",
      "60 20 0.2892894148826599\n",
      "Validation loss: 0.8858740981051464 ROC AUC: 0.6454642097802976\n",
      "61 32 0.31597599387168884\n",
      "Validation loss: 0.7316556857121701 ROC AUC: 0.6984408221119773\n",
      "Validation loss: 0.7689383416775836 ROC AUC: 0.7048192771084337\n",
      "63 6 0.34975528717041016\n",
      "Validation loss: 0.8707185794186119 ROC AUC: 0.7227143869596031\n",
      "64 18 0.44543901085853577\n",
      "Validation loss: 0.7547468456211469 ROC AUC: 0.677710843373494\n",
      "65 30 0.33228570222854614\n",
      "Validation loss: 0.7454235151114054 ROC AUC: 0.6867469879518072\n",
      "Validation loss: 0.8250269822726976 ROC AUC: 0.6809000708717222\n",
      "67 4 0.40636584162712097\n",
      "Validation loss: 0.8118114053018836 ROC AUC: 0.6527285613040397\n",
      "68 16 0.38769444823265076\n",
      "Validation loss: 0.8675146706846376 ROC AUC: 0.7048192771084338\n",
      "69 28 0.38331136107444763\n",
      "Validation loss: 0.8229956172949431 ROC AUC: 0.666194188518781\n",
      "Validation loss: 0.8039365245016995 ROC AUC: 0.6514883061658399\n",
      "71 2 0.2020656317472458\n",
      "Validation loss: 0.802370605879272 ROC AUC: 0.6768249468462083\n",
      "72 14 0.3872299790382385\n",
      "Validation loss: 0.8672240972518921 ROC AUC: 0.7032246633593197\n",
      "73 26 0.24600274860858917\n",
      "Validation loss: 0.8029602726563713 ROC AUC: 0.7083628632175762\n",
      "Validation loss: 1.0233055953158448 ROC AUC: 0.6727498228206945\n",
      "75 0 0.23847147822380066\n",
      "Validation loss: 0.9169273526463287 ROC AUC: 0.702338766832034\n",
      "76 12 0.36469921469688416\n",
      "Validation loss: 0.8877373748267723 ROC AUC: 0.7021615875265769\n",
      "77 24 0.2039129137992859\n",
      "Validation loss: 0.8123050880747915 ROC AUC: 0.6972005669737774\n",
      "78 36 0.43332502245903015\n",
      "Validation loss: 0.8781473612943232 ROC AUC: 0.7207654145995748\n",
      "Validation loss: 0.8808697864709311 ROC AUC: 0.6989723600283486\n",
      "80 10 0.3532356321811676\n",
      "Validation loss: 1.037697624686538 ROC AUC: 0.6598157335223246\n",
      "81 22 0.4132024943828583\n",
      "Validation loss: 1.2105804243624605 ROC AUC: 0.654677533664068\n",
      "82 34 0.17990854382514954\n",
      "Validation loss: 0.9960919172558563 ROC AUC: 0.6754075124025514\n",
      "Validation loss: 0.9713769795878834 ROC AUC: 0.6915308291991495\n",
      "84 8 0.4337160289287567\n",
      "Validation loss: 1.001511377214596 ROC AUC: 0.6592841956059532\n",
      "85 20 0.37254345417022705\n",
      "Validation loss: 1.2260703977370104 ROC AUC: 0.6938341601700921\n",
      "86 32 0.2958969473838806\n",
      "Validation loss: 0.9088438658524822 ROC AUC: 0.6785967399007795\n",
      "Validation loss: 0.9922921977295781 ROC AUC: 0.6995038979447201\n",
      "88 6 0.25015684962272644\n",
      "Validation loss: 0.9745637691573591 ROC AUC: 0.6940113394755494\n",
      "89 18 0.31325972080230713\n",
      "Validation loss: 1.0666341327673552 ROC AUC: 0.7329907866761164\n",
      "90 30 0.3298223316669464\n",
      "Validation loss: 1.0124354488802272 ROC AUC: 0.6670800850460666\n",
      "Validation loss: 0.976417385979204 ROC AUC: 0.7071226080793763\n",
      "92 4 0.23778469860553741\n",
      "Validation loss: 0.9968365312412085 ROC AUC: 0.6628277817150956\n",
      "93 16 0.37299641966819763\n",
      "Validation loss: 0.8916060320588927 ROC AUC: 0.7060595322466335\n",
      "94 28 0.39008334279060364\n",
      "Validation loss: 0.871834208633726 ROC AUC: 0.6881644223954643\n",
      "Validation loss: 0.7720463082490377 ROC AUC: 0.6987951807228916\n",
      "96 2 0.28490570187568665\n",
      "Validation loss: 0.9260551609740352 ROC AUC: 0.6794826364280653\n",
      "97 14 0.2508840560913086\n",
      "Validation loss: 0.9673061187298883 ROC AUC: 0.6888731396172928\n",
      "98 26 0.41467857360839844\n",
      "Validation loss: 1.0138581533305693 ROC AUC: 0.7025159461374911\n",
      "Validation loss: 0.9347332731777469 ROC AUC: 0.6803685329553509\n",
      "100 0 0.2034275084733963\n",
      "Validation loss: 0.928857497032115 ROC AUC: 0.6856839121190645\n",
      "101 12 0.1990308165550232\n",
      "Validation loss: 0.9038131047558311 ROC AUC: 0.72413182140326\n",
      "102 24 0.35545212030410767\n",
      "Validation loss: 0.9083479946812257 ROC AUC: 0.7072997873848333\n",
      "103 36 0.36327171325683594\n",
      "Validation loss: 0.9944229122029234 ROC AUC: 0.6794826364280653\n",
      "Validation loss: 0.924278160594157 ROC AUC: 0.7267895109851169\n",
      "105 10 0.2161124050617218\n",
      "Validation loss: 1.0021309153923135 ROC AUC: 0.7149184975194897\n",
      "106 22 0.3033307194709778\n",
      "Validation loss: 1.1658510632862318 ROC AUC: 0.6761162296243798\n",
      "107 34 0.4503509998321533\n",
      "Validation loss: 1.09031986242888 ROC AUC: 0.6840892983699504\n",
      "Validation loss: 0.9070863850069362 ROC AUC: 0.7246633593196314\n",
      "109 8 0.19904470443725586\n",
      "Validation loss: 0.8439943908855615 ROC AUC: 0.7241318214032602\n",
      "110 20 0.18535321950912476\n",
      "Validation loss: 1.3617798445240552 ROC AUC: 0.66194188518781\n",
      "111 32 0.3080269396305084\n",
      "Validation loss: 1.0603629717763685 ROC AUC: 0.6987951807228915\n",
      "Validation loss: 1.1528920251012638 ROC AUC: 0.6801913536498936\n",
      "113 6 0.25478747487068176\n",
      "Validation loss: 1.1094185445482367 ROC AUC: 0.6894046775336641\n",
      "114 18 0.2579937279224396\n",
      "Validation loss: 0.9229187621975576 ROC AUC: 0.7468107725017719\n",
      "115 30 0.23725277185440063\n",
      "Validation loss: 0.9820974350765052 ROC AUC: 0.741318214032601\n",
      "Validation loss: 1.600573115001451 ROC AUC: 0.6770021261516654\n",
      "117 4 0.2457081377506256\n",
      "Validation loss: 1.134758614546416 ROC AUC: 0.6816087880935506\n",
      "118 16 0.2066030204296112\n",
      "Validation loss: 0.9967980530877777 ROC AUC: 0.7145641389085755\n",
      "119 28 0.4419727325439453\n",
      "Validation loss: 1.2604285628590364 ROC AUC: 0.6927710843373494\n",
      "Validation loss: 1.5945413183692276 ROC AUC: 0.6945428773919207\n",
      "121 2 0.22673839330673218\n",
      "Validation loss: 1.1082291650456308 ROC AUC: 0.7078313253012049\n",
      "122 14 0.3438238203525543\n",
      "Validation loss: 1.391595091251348 ROC AUC: 0.6918851878100638\n",
      "123 26 0.13870124518871307\n",
      "Validation loss: 1.2252499473015994 ROC AUC: 0.6980864635010632\n",
      "Validation loss: 1.0521284231286965 ROC AUC: 0.7177533664068037\n",
      "125 0 0.2057795375585556\n",
      "Validation loss: 1.2994893655082247 ROC AUC: 0.7237774627923458\n",
      "126 12 0.33807843923568726\n",
      "Validation loss: 1.213444817145139 ROC AUC: 0.7062367115520908\n",
      "127 24 0.22973687946796417\n",
      "Validation loss: 1.2169736710605243 ROC AUC: 0.6688518781006378\n",
      "128 36 0.22957803308963776\n",
      "Validation loss: 1.19643455072744 ROC AUC: 0.7034018426647767\n",
      "Validation loss: 1.7235011643921303 ROC AUC: 0.6796598157335223\n",
      "130 10 0.1948019415140152\n",
      "Validation loss: 1.339892890674389 ROC AUC: 0.6754075124025514\n",
      "131 22 0.07247497141361237\n",
      "Validation loss: 1.1906277675502348 ROC AUC: 0.6755846917080084\n",
      "132 34 0.4231645464897156\n",
      "Validation loss: 1.0975774297651075 ROC AUC: 0.6998582565556343\n",
      "Validation loss: 1.1269873169478992 ROC AUC: 0.7218284904323174\n",
      "134 8 0.2084248960018158\n",
      "Validation loss: 0.9968596304094555 ROC AUC: 0.7115520907158044\n",
      "135 20 0.23909060657024384\n",
      "Validation loss: 1.1267196247909244 ROC AUC: 0.7117292700212614\n",
      "136 32 0.21102476119995117\n",
      "Validation loss: 1.302247483209269 ROC AUC: 0.6872785258681786\n",
      "Validation loss: 1.1435340512667271 ROC AUC: 0.7048192771084336\n",
      "138 6 0.2834027111530304\n",
      "Validation loss: 1.5652018272324113 ROC AUC: 0.6458185683912119\n",
      "139 18 0.13278988003730774\n",
      "Validation loss: 1.2357213820842718 ROC AUC: 0.719525159461375\n",
      "140 30 0.304471880197525\n",
      "Validation loss: 1.232209809568544 ROC AUC: 0.7122608079376329\n",
      "Validation loss: 1.761490916574238 ROC AUC: 0.6885187810063785\n",
      "142 4 0.30643925070762634\n",
      "Validation loss: 1.1697023459617666 ROC AUC: 0.7083628632175762\n",
      "143 16 0.2056364119052887\n",
      "Validation loss: 1.3704493314225152 ROC AUC: 0.7119064493267185\n",
      "144 28 0.33085957169532776\n",
      "Validation loss: 1.3076883214988455 ROC AUC: 0.7315733522324593\n",
      "Validation loss: 1.2155703937770515 ROC AUC: 0.6996810772501771\n",
      "146 2 0.23137515783309937\n",
      "Validation loss: 1.085178979974709 ROC AUC: 0.6918851878100638\n",
      "147 14 0.301811158657074\n",
      "Validation loss: 1.0490041679104432 ROC AUC: 0.7361800141743444\n",
      "148 26 0.3154797852039337\n",
      "Validation loss: 1.2621713245151849 ROC AUC: 0.7360028348688874\n",
      "Validation loss: 1.4731890586827765 ROC AUC: 0.6720411055988661\n",
      "150 0 0.1058511957526207\n",
      "Validation loss: 1.5529472275285532 ROC AUC: 0.6881644223954643\n",
      "151 12 0.3444300889968872\n",
      "Validation loss: 1.1368986466862507 ROC AUC: 0.7010985116938341\n",
      "152 24 0.2492019534111023\n",
      "Validation loss: 1.4803909631754388 ROC AUC: 0.7104890148830616\n",
      "153 36 0.2819164991378784\n",
      "Validation loss: 1.9554073526369815 ROC AUC: 0.6917080085046068\n",
      "Validation loss: 1.1947160617799948 ROC AUC: 0.7484053862508859\n",
      "155 10 0.22293755412101746\n",
      "Validation loss: 1.6379507661655248 ROC AUC: 0.6952515946137491\n",
      "156 22 0.3185523748397827\n",
      "Validation loss: 1.2809472214307216 ROC AUC: 0.6982636428065202\n",
      "157 34 0.26216739416122437\n",
      "Validation loss: 1.7474010756473668 ROC AUC: 0.6993267186392629\n",
      "Validation loss: 1.3080794740196884 ROC AUC: 0.6984408221119773\n",
      "159 8 0.1805172711610794\n",
      "Validation loss: 1.126666389948485 ROC AUC: 0.7170446491849751\n",
      "160 20 0.2023862898349762\n",
      "Validation loss: 1.6836636342749691 ROC AUC: 0.6963146704464919\n",
      "161 32 0.17656417191028595\n",
      "Validation loss: 1.4722471363497096 ROC AUC: 0.7133238837703756\n",
      "Validation loss: 0.9576785086795984 ROC AUC: 0.7140326009922041\n",
      "163 6 0.14660313725471497\n",
      "Validation loss: 1.2062384158570245 ROC AUC: 0.6991495393338059\n",
      "164 18 0.17948566377162933\n",
      "Validation loss: 1.5572421487593493 ROC AUC: 0.666194188518781\n",
      "165 30 0.22335517406463623\n",
      "Validation loss: 1.3299945892877136 ROC AUC: 0.7115520907158044\n",
      "Validation loss: 1.3013091055762689 ROC AUC: 0.7090715804394048\n",
      "167 4 0.20272082090377808\n",
      "Validation loss: 1.483041417519778 ROC AUC: 0.719702338766832\n",
      "168 16 0.10746273398399353\n",
      "Validation loss: 1.1971863745064135 ROC AUC: 0.7338766832034018\n",
      "169 28 0.25043728947639465\n",
      "Validation loss: 1.2671896606091633 ROC AUC: 0.719702338766832\n",
      "Validation loss: 1.8366322817391907 ROC AUC: 0.7248405386250886\n",
      "171 2 0.12633346021175385\n",
      "Validation loss: 1.4098416168168681 ROC AUC: 0.7186392629340893\n",
      "172 14 0.0890965536236763\n",
      "Validation loss: 2.022845846138253 ROC AUC: 0.7145641389085755\n",
      "173 26 0.16860567033290863\n",
      "Validation loss: 1.3053290812385003 ROC AUC: 0.7019844082211198\n",
      "Validation loss: 1.5916759762542927 ROC AUC: 0.7019844082211198\n",
      "175 0 0.21021851897239685\n",
      "Validation loss: 1.4637143651381235 ROC AUC: 0.7170446491849752\n",
      "176 12 0.1808047741651535\n",
      "Validation loss: 1.3584483617188914 ROC AUC: 0.7133238837703756\n",
      "177 24 0.17483890056610107\n",
      "Validation loss: 1.9407366340523524 ROC AUC: 0.6856839121190644\n",
      "178 36 0.24532172083854675\n",
      "Validation loss: 1.629273278034286 ROC AUC: 0.7067682494684621\n",
      "Validation loss: 2.397604113383009 ROC AUC: 0.6839121190644932\n",
      "180 10 0.3547743558883667\n",
      "Validation loss: 2.0639605395841283 ROC AUC: 0.6750531537916372\n",
      "181 22 0.3386397957801819\n",
      "Validation loss: 1.539087071718759 ROC AUC: 0.6952515946137491\n",
      "182 34 0.22716335952281952\n",
      "Validation loss: 1.9397152046494137 ROC AUC: 0.7005669737774629\n",
      "Validation loss: 1.7948323922441496 ROC AUC: 0.7065910701630049\n",
      "184 8 0.21450573205947876\n",
      "Validation loss: 2.223575496515691 ROC AUC: 0.6835577604535791\n",
      "185 20 0.0976470559835434\n",
      "Validation loss: 2.1866724759537655 ROC AUC: 0.6895818568391212\n",
      "186 32 0.20017875730991364\n",
      "Validation loss: 1.3087320011972592 ROC AUC: 0.734053862508859\n",
      "Validation loss: 1.541033045740317 ROC AUC: 0.7280297661233167\n",
      "188 6 0.2443358302116394\n",
      "Validation loss: 1.5295455629462438 ROC AUC: 0.7122608079376329\n",
      "189 18 0.29157495498657227\n",
      "Validation loss: 1.2596503215909793 ROC AUC: 0.7161587526576896\n",
      "190 30 0.24783846735954285\n",
      "Validation loss: 1.4730634349860892 ROC AUC: 0.718284904323175\n",
      "Validation loss: 1.6273695688373995 ROC AUC: 0.7321048901488306\n",
      "192 4 0.0905018150806427\n",
      "Validation loss: 1.6273959756686986 ROC AUC: 0.7019844082211197\n",
      "193 16 0.18832409381866455\n",
      "Validation loss: 1.7975648602113028 ROC AUC: 0.7352941176470588\n",
      "194 28 0.07481072843074799\n",
      "Validation loss: 1.4421856150721872 ROC AUC: 0.7101346562721473\n",
      "Validation loss: 1.761014392833836 ROC AUC: 0.7230687455705174\n",
      "196 2 0.10216806083917618\n",
      "Validation loss: 0.9220395727662851 ROC AUC: 0.7319277108433735\n",
      "197 14 0.21929509937763214\n",
      "Validation loss: 1.6154678084992415 ROC AUC: 0.7214741318214033\n",
      "198 26 0.49594998359680176\n",
      "Validation loss: 1.4550575041613043 ROC AUC: 0.7244861800141743\n",
      "Validation loss: 1.6457027504775699 ROC AUC: 0.7175761871013466\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.5804018660595542 Test ROC AUC: 0.7806159420289854\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'bace', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'classification', 'data_path': 'data/bace/bace.csv', 'target': ['Class']}}\n",
      "Running on: cuda:0\n",
      "1512\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1512\n",
      "Generating scaffold 1000/1512\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.1647560596466064\n",
      "Validation loss: 0.8772544387160548 ROC AUC: 0.5510276399716513\n",
      "1 12 0.7547489404678345\n",
      "Validation loss: 0.9681543822320092 ROC AUC: 0.5685683912119065\n",
      "2 24 0.6576246023178101\n",
      "Validation loss: 1.2345420556352629 ROC AUC: 0.5223245924875974\n",
      "3 36 0.6068029999732971\n",
      "Validation loss: 1.1527201679368682 ROC AUC: 0.5687455705173636\n",
      "Validation loss: 1.5949882039960646 ROC AUC: 0.6332388377037562\n",
      "5 10 0.6836977005004883\n",
      "Validation loss: 1.3520699131567746 ROC AUC: 0.6151665485471297\n",
      "6 22 0.5036436915397644\n",
      "Validation loss: 1.505879769262099 ROC AUC: 0.582388377037562\n",
      "7 34 0.5469391345977783\n",
      "Validation loss: 0.7714795004453091 ROC AUC: 0.6266832034018426\n",
      "Validation loss: 0.6998188471952022 ROC AUC: 0.6552090715804394\n",
      "9 8 0.6192741990089417\n",
      "Validation loss: 1.5324609208580673 ROC AUC: 0.6265060240963856\n",
      "10 20 0.5587289929389954\n",
      "Validation loss: 1.1180684598076422 ROC AUC: 0.6082565556343018\n",
      "11 32 0.5959662199020386\n",
      "Validation loss: 1.5098989617745608 ROC AUC: 0.6397944720056697\n",
      "Validation loss: 0.8241694403799954 ROC AUC: 0.6495393338058115\n",
      "13 6 0.5479630827903748\n",
      "Validation loss: 1.0766944972095112 ROC AUC: 0.6559177888022678\n",
      "14 18 0.6425131559371948\n",
      "Validation loss: 1.1040749451182537 ROC AUC: 0.6344790928419561\n",
      "15 30 0.5054842829704285\n",
      "Validation loss: 0.9774549717934716 ROC AUC: 0.6527285613040397\n",
      "Validation loss: 0.9756983858070626 ROC AUC: 0.6511339475549255\n",
      "17 4 0.5061320662498474\n",
      "Validation loss: 0.8906434300719508 ROC AUC: 0.6628277817150956\n",
      "18 16 0.6403369307518005\n",
      "Validation loss: 1.0322452227011423 ROC AUC: 0.6412119064493267\n",
      "19 28 0.4236706793308258\n",
      "Validation loss: 0.6947007870042561 ROC AUC: 0.6610559886605244\n",
      "Validation loss: 0.9682520264821337 ROC AUC: 0.6500708717221828\n",
      "21 2 0.3869420886039734\n",
      "Validation loss: 1.3449166918432476 ROC AUC: 0.673458540042523\n",
      "22 14 0.41275396943092346\n",
      "Validation loss: 1.195820664333192 ROC AUC: 0.6635364989369241\n",
      "23 26 0.5441040396690369\n",
      "Validation loss: 1.1005727194792387 ROC AUC: 0.6871013465627215\n",
      "Validation loss: 0.6828837276294532 ROC AUC: 0.6945428773919207\n",
      "25 0 0.27459388971328735\n",
      "Validation loss: 0.9836708465159334 ROC AUC: 0.6929482636428065\n",
      "26 12 0.32769304513931274\n",
      "Validation loss: 0.9671520239470021 ROC AUC: 0.6915308291991495\n",
      "27 24 0.3677619993686676\n",
      "Validation loss: 0.7171645500012581 ROC AUC: 0.7016300496102055\n",
      "28 36 0.5704489946365356\n",
      "Validation loss: 1.1030923151812018 ROC AUC: 0.6327072997873848\n",
      "Validation loss: 0.8770166438146932 ROC AUC: 0.681963146704465\n",
      "30 10 0.5977974534034729\n",
      "Validation loss: 0.9687667303527427 ROC AUC: 0.683557760453579\n",
      "31 22 0.3765185475349426\n",
      "Validation loss: 0.8263304711177649 ROC AUC: 0.6952515946137491\n",
      "32 34 0.55843585729599\n",
      "Validation loss: 0.9836957202052439 ROC AUC: 0.6771793054571226\n",
      "Validation loss: 0.7428904515228524 ROC AUC: 0.682140326009922\n",
      "34 8 0.20863817632198334\n",
      "Validation loss: 0.8047278618180989 ROC AUC: 0.6706236711552089\n",
      "35 20 0.3612532317638397\n",
      "Validation loss: 0.6813365426284588 ROC AUC: 0.6943656980864635\n",
      "36 32 0.2628527283668518\n",
      "Validation loss: 0.7306621137833753 ROC AUC: 0.6950744153082921\n",
      "Validation loss: 0.7052846953568869 ROC AUC: 0.7078313253012047\n",
      "38 6 0.5297286510467529\n",
      "Validation loss: 0.7865473726727316 ROC AUC: 0.6670800850460666\n",
      "39 18 0.6152538061141968\n",
      "Validation loss: 0.6874889711670528 ROC AUC: 0.7188164422395464\n",
      "40 30 0.37887078523635864\n",
      "Validation loss: 1.0309332549966723 ROC AUC: 0.6240255138199857\n",
      "Validation loss: 0.7636825592312592 ROC AUC: 0.6915308291991495\n",
      "42 4 0.29875901341438293\n",
      "Validation loss: 0.7324652022478596 ROC AUC: 0.7400779588944012\n",
      "43 16 0.3156242072582245\n",
      "Validation loss: 0.6738869259689028 ROC AUC: 0.7016300496102055\n",
      "44 28 0.42779645323753357\n",
      "Validation loss: 0.779057205118091 ROC AUC: 0.6920623671155209\n",
      "Validation loss: 0.7088022535999879 ROC AUC: 0.681963146704465\n",
      "46 2 0.5196809768676758\n",
      "Validation loss: 0.8003744788911958 ROC AUC: 0.7030474840538625\n",
      "47 14 0.29871153831481934\n",
      "Validation loss: 0.8149360742000554 ROC AUC: 0.7005669737774628\n",
      "48 26 0.38670769333839417\n",
      "Validation loss: 0.844627919576026 ROC AUC: 0.7149184975194898\n",
      "Validation loss: 0.819714833569053 ROC AUC: 0.6862154500354358\n",
      "50 0 0.5830721855163574\n",
      "Validation loss: 0.7823400773749446 ROC AUC: 0.7303330970942594\n",
      "51 12 0.311010479927063\n",
      "Validation loss: 0.7347867050707735 ROC AUC: 0.6991495393338059\n",
      "52 24 0.38789790868759155\n",
      "Validation loss: 0.843482056200899 ROC AUC: 0.6911764705882353\n",
      "53 36 0.5888211727142334\n",
      "Validation loss: 0.7646521546982772 ROC AUC: 0.7039333805811481\n",
      "Validation loss: 0.840295170316633 ROC AUC: 0.6885187810063784\n",
      "55 10 0.3375871777534485\n",
      "Validation loss: 0.6874598059433186 ROC AUC: 0.7200566973777462\n",
      "56 22 0.4626080095767975\n",
      "Validation loss: 0.797093322734959 ROC AUC: 0.702338766832034\n",
      "57 34 0.33968642354011536\n",
      "Validation loss: 0.7935486889832857 ROC AUC: 0.705173635719348\n",
      "Validation loss: 0.8114918186175113 ROC AUC: 0.6874557051736356\n",
      "59 8 0.38934656977653503\n",
      "Validation loss: 0.7528870480739518 ROC AUC: 0.6644223954642099\n",
      "60 20 0.3929611146450043\n",
      "Validation loss: 0.7502160869686809 ROC AUC: 0.728206945428774\n",
      "61 32 0.4313187897205353\n",
      "Validation loss: 0.6996721846378402 ROC AUC: 0.7018072289156627\n",
      "Validation loss: 0.9918795085900667 ROC AUC: 0.6670800850460666\n",
      "63 6 0.3680226802825928\n",
      "Validation loss: 0.7579296945736108 ROC AUC: 0.7221828490432317\n",
      "64 18 0.29637178778648376\n",
      "Validation loss: 0.7867265708793868 ROC AUC: 0.7106661941885187\n",
      "65 30 0.25736328959465027\n",
      "Validation loss: 0.8187306914108479 ROC AUC: 0.654500354358611\n",
      "Validation loss: 0.9462602876669524 ROC AUC: 0.6784195605953225\n",
      "67 4 0.21993303298950195\n",
      "Validation loss: 0.6707194388307482 ROC AUC: 0.7243090007087172\n",
      "68 16 0.35669106245040894\n",
      "Validation loss: 0.7669624473085467 ROC AUC: 0.6840892983699504\n",
      "69 28 0.4367436468601227\n",
      "Validation loss: 0.8613885305575187 ROC AUC: 0.7065910701630049\n",
      "Validation loss: 0.7571296798472373 ROC AUC: 0.7248405386250886\n",
      "71 2 0.4532485604286194\n",
      "Validation loss: 0.7415928607744886 ROC AUC: 0.7120836286321757\n",
      "72 14 0.31960007548332214\n",
      "Validation loss: 0.7285804409064994 ROC AUC: 0.72413182140326\n",
      "73 26 0.36531463265419006\n",
      "Validation loss: 0.7150334644791306 ROC AUC: 0.6991495393338059\n",
      "Validation loss: 0.8021334054454273 ROC AUC: 0.6911764705882353\n",
      "75 0 0.22447870671749115\n",
      "Validation loss: 0.8903863043185102 ROC AUC: 0.7062367115520907\n",
      "76 12 0.3131524622440338\n",
      "Validation loss: 0.7621254439385522 ROC AUC: 0.703756201275691\n",
      "77 24 0.28221121430397034\n",
      "Validation loss: 0.8849749916436657 ROC AUC: 0.6785967399007796\n",
      "78 36 0.32618993520736694\n",
      "Validation loss: 0.7987683439096868 ROC AUC: 0.684975194897236\n",
      "Validation loss: 1.0122849293891958 ROC AUC: 0.672041105598866\n",
      "80 10 0.30131056904792786\n",
      "Validation loss: 0.8256775796018689 ROC AUC: 0.6596385542168675\n",
      "81 22 0.34550419449806213\n",
      "Validation loss: 0.8303658812251312 ROC AUC: 0.6745216158752658\n",
      "82 34 0.30465883016586304\n",
      "Validation loss: 0.8219447447764163 ROC AUC: 0.7099574769666903\n",
      "Validation loss: 0.8086616278484168 ROC AUC: 0.682140326009922\n",
      "84 8 0.39395344257354736\n",
      "Validation loss: 0.9151034544635293 ROC AUC: 0.6810772501771793\n",
      "85 20 0.22052204608917236\n",
      "Validation loss: 0.9995909976643442 ROC AUC: 0.6823175053153792\n",
      "86 32 0.408069908618927\n",
      "Validation loss: 0.8307461604377292 ROC AUC: 0.6940113394755493\n",
      "Validation loss: 0.7598415032917301 ROC AUC: 0.7083628632175761\n",
      "88 6 0.42139512300491333\n",
      "Validation loss: 0.914026267481166 ROC AUC: 0.6723954642097802\n",
      "89 18 0.28896480798721313\n",
      "Validation loss: 0.831392021368671 ROC AUC: 0.7044649184975196\n",
      "90 30 0.40558433532714844\n",
      "Validation loss: 0.9664834729883055 ROC AUC: 0.684975194897236\n",
      "Validation loss: 0.9551125685900252 ROC AUC: 0.7019844082211198\n",
      "92 4 0.16677874326705933\n",
      "Validation loss: 0.8471131885288566 ROC AUC: 0.6968462083628633\n",
      "93 16 0.4535236060619354\n",
      "Validation loss: 0.833002290978337 ROC AUC: 0.6973777462792345\n",
      "94 28 0.2537905275821686\n",
      "Validation loss: 0.8294695299982235 ROC AUC: 0.705173635719348\n",
      "Validation loss: 0.9371365715336326 ROC AUC: 0.7037562012756909\n",
      "96 2 0.3180657625198364\n",
      "Validation loss: 0.935512084834623 ROC AUC: 0.667611622962438\n",
      "97 14 0.34273016452789307\n",
      "Validation loss: 0.8722562363605626 ROC AUC: 0.7030474840538625\n",
      "98 26 0.41514959931373596\n",
      "Validation loss: 0.8284626907070741 ROC AUC: 0.7018072289156627\n",
      "Validation loss: 0.8382740423379355 ROC AUC: 0.6796598157335224\n",
      "100 0 0.2002413421869278\n",
      "Validation loss: 0.8441690336789517 ROC AUC: 0.7067682494684621\n",
      "101 12 0.33508390188217163\n",
      "Validation loss: 0.8271375626128241 ROC AUC: 0.6739900779588944\n",
      "102 24 0.4266963303089142\n",
      "Validation loss: 0.9546942505615437 ROC AUC: 0.6867469879518073\n",
      "103 36 0.24857406318187714\n",
      "Validation loss: 0.7949966065931005 ROC AUC: 0.6851523742026931\n",
      "Validation loss: 0.8505973808023314 ROC AUC: 0.6844436569808646\n",
      "105 10 0.2639344334602356\n",
      "Validation loss: 1.0624501042018664 ROC AUC: 0.6794826364280652\n",
      "106 22 0.2860367000102997\n",
      "Validation loss: 0.8631088567885342 ROC AUC: 0.729801559177888\n",
      "107 34 0.31142714619636536\n",
      "Validation loss: 1.1194027382016971 ROC AUC: 0.6699149539333805\n",
      "Validation loss: 0.7954012869999109 ROC AUC: 0.7168674698795181\n",
      "109 8 0.33476996421813965\n",
      "Validation loss: 0.7842609740250948 ROC AUC: 0.6817859673990079\n",
      "110 20 0.2744312584400177\n",
      "Validation loss: 0.9387665844910982 ROC AUC: 0.667611622962438\n",
      "111 32 0.2865898609161377\n",
      "Validation loss: 0.8615054902651452 ROC AUC: 0.686392629340893\n",
      "Validation loss: 0.9727866641733031 ROC AUC: 0.6970233876683203\n",
      "113 6 0.24754975736141205\n",
      "Validation loss: 1.0214202238234462 ROC AUC: 0.6973777462792345\n",
      "114 18 0.536230742931366\n",
      "Validation loss: 0.8536224223130586 ROC AUC: 0.6941885187810063\n",
      "115 30 0.4032011926174164\n",
      "Validation loss: 0.8892515581964657 ROC AUC: 0.6934798015591779\n",
      "Validation loss: 0.9084333185328554 ROC AUC: 0.6785967399007796\n",
      "117 4 0.16245435178279877\n",
      "Validation loss: 0.8814550819775916 ROC AUC: 0.6966690290574061\n",
      "118 16 0.24919287860393524\n",
      "Validation loss: 0.8408362983867822 ROC AUC: 0.6938341601700921\n",
      "119 28 0.2661901116371155\n",
      "Validation loss: 1.0139268463021083 ROC AUC: 0.677710843373494\n",
      "Validation loss: 0.999052760616833 ROC AUC: 0.667788802267895\n",
      "121 2 0.3578830361366272\n",
      "Validation loss: 0.8639858297954331 ROC AUC: 0.7025159461374911\n",
      "122 14 0.2111702561378479\n",
      "Validation loss: 0.8959459938750362 ROC AUC: 0.7026931254429483\n",
      "123 26 0.4519435465335846\n",
      "Validation loss: 0.7841903164686747 ROC AUC: 0.6872785258681786\n",
      "Validation loss: 0.91076533841771 ROC AUC: 0.696669029057406\n",
      "125 0 0.25319403409957886\n",
      "Validation loss: 1.0021331943818275 ROC AUC: 0.7228915662650602\n",
      "126 12 0.24324147403240204\n",
      "Validation loss: 1.0281917330445043 ROC AUC: 0.7019844082211197\n",
      "127 24 0.24868007004261017\n",
      "Validation loss: 0.9227598033203984 ROC AUC: 0.7060595322466336\n",
      "128 36 0.19831272959709167\n",
      "Validation loss: 1.1835664404149087 ROC AUC: 0.7057051736357194\n",
      "Validation loss: 0.964443569151771 ROC AUC: 0.7090715804394048\n",
      "130 10 0.23062552511692047\n",
      "Validation loss: 1.000332662206612 ROC AUC: 0.6892274982282071\n",
      "131 22 0.4631015658378601\n",
      "Validation loss: 0.9703208397555825 ROC AUC: 0.6839121190644932\n",
      "132 34 0.33988475799560547\n",
      "Validation loss: 0.8956819638511203 ROC AUC: 0.6725726435152375\n",
      "Validation loss: 0.7633896766119446 ROC AUC: 0.7028703047484054\n",
      "134 8 0.26085159182548523\n",
      "Validation loss: 0.8322515542933483 ROC AUC: 0.6886959603118356\n",
      "135 20 0.3131575584411621\n",
      "Validation loss: 0.8716353478021179 ROC AUC: 0.6894046775336641\n",
      "136 32 0.18711158633232117\n",
      "Validation loss: 1.1345018614206883 ROC AUC: 0.7135010630758327\n",
      "Validation loss: 1.0883189870032253 ROC AUC: 0.7147413182140326\n",
      "138 6 0.2308899611234665\n",
      "Validation loss: 1.0813712015846708 ROC AUC: 0.6729270021261518\n",
      "139 18 0.22206491231918335\n",
      "Validation loss: 0.8626114208966691 ROC AUC: 0.6684975194897236\n",
      "140 30 0.4912227988243103\n",
      "Validation loss: 0.87818463748654 ROC AUC: 0.7221828490432317\n",
      "Validation loss: 1.0084992832695412 ROC AUC: 0.7071226080793763\n",
      "142 4 0.18824537098407745\n",
      "Validation loss: 0.923716916943228 ROC AUC: 0.7220056697377746\n",
      "143 16 0.22901922464370728\n",
      "Validation loss: 0.9311080867091551 ROC AUC: 0.6998582565556344\n",
      "144 28 0.24668481945991516\n",
      "Validation loss: 1.0620314143351373 ROC AUC: 0.6924167257264352\n",
      "Validation loss: 1.25889005724168 ROC AUC: 0.6909992912827781\n",
      "146 2 0.1525128036737442\n",
      "Validation loss: 0.9726167526466167 ROC AUC: 0.7007441530829199\n",
      "147 14 0.31623926758766174\n",
      "Validation loss: 1.0057251283664577 ROC AUC: 0.695074415308292\n",
      "148 26 0.20283274352550507\n",
      "Validation loss: 0.8836060028202486 ROC AUC: 0.7150956768249468\n",
      "Validation loss: 0.9385445354790087 ROC AUC: 0.7071226080793763\n",
      "150 0 0.18490205705165863\n",
      "Validation loss: 0.9987252354621887 ROC AUC: 0.7289156626506024\n",
      "151 12 0.15946412086486816\n",
      "Validation loss: 0.8298493236895429 ROC AUC: 0.6993267186392629\n",
      "152 24 0.24735231697559357\n",
      "Validation loss: 0.977967690158364 ROC AUC: 0.7111977321048901\n",
      "153 36 0.165272057056427\n",
      "Validation loss: 0.8414458071948677 ROC AUC: 0.7345854004252304\n",
      "Validation loss: 0.9466084707651706 ROC AUC: 0.7147413182140326\n",
      "155 10 0.21557334065437317\n",
      "Validation loss: 0.9842666075719113 ROC AUC: 0.7069454287739192\n",
      "156 22 0.24538138508796692\n",
      "Validation loss: 1.0524471569929692 ROC AUC: 0.7035790219702338\n",
      "157 34 0.23573216795921326\n",
      "Validation loss: 0.8276387113609062 ROC AUC: 0.7361800141743444\n",
      "Validation loss: 1.0801077587715049 ROC AUC: 0.7035790219702339\n",
      "159 8 0.13435101509094238\n",
      "Validation loss: 1.261613239910429 ROC AUC: 0.6933026222537207\n",
      "160 20 0.2130475491285324\n",
      "Validation loss: 0.8756567634494099 ROC AUC: 0.7115520907158044\n",
      "161 32 0.4074380397796631\n",
      "Validation loss: 0.9184928271944159 ROC AUC: 0.690822111977321\n",
      "Validation loss: 0.971113227850554 ROC AUC: 0.7140326009922041\n",
      "163 6 0.30108484625816345\n",
      "Validation loss: 0.7792801594497353 ROC AUC: 0.7060595322466335\n",
      "164 18 0.16258707642555237\n",
      "Validation loss: 0.8524081221479454 ROC AUC: 0.6993267186392629\n",
      "165 30 0.4095724821090698\n",
      "Validation loss: 0.9835463750441342 ROC AUC: 0.7168674698795181\n",
      "Validation loss: 1.05346040062557 ROC AUC: 0.6830262225372077\n",
      "167 4 0.18003207445144653\n",
      "Validation loss: 1.1806228595064177 ROC AUC: 0.6828490432317506\n",
      "168 16 0.13865426182746887\n",
      "Validation loss: 0.9190181474022517 ROC AUC: 0.7007441530829199\n",
      "169 28 0.1526157557964325\n",
      "Validation loss: 1.0282333276129716 ROC AUC: 0.716690290574061\n",
      "Validation loss: 0.9353728602264101 ROC AUC: 0.721119773210489\n",
      "171 2 0.34942513704299927\n",
      "Validation loss: 1.0157819633057574 ROC AUC: 0.7048192771084337\n",
      "172 14 0.09043700248003006\n",
      "Validation loss: 1.1009239282039618 ROC AUC: 0.6888731396172927\n",
      "173 26 0.49747079610824585\n",
      "Validation loss: 1.2214031266850351 ROC AUC: 0.6771793054571227\n",
      "Validation loss: 1.0506756597796814 ROC AUC: 0.7236002834868887\n",
      "175 0 0.18348409235477448\n",
      "Validation loss: 1.0027127100142421 ROC AUC: 0.6970233876683204\n",
      "176 12 0.16285011172294617\n",
      "Validation loss: 1.0016230707926466 ROC AUC: 0.7115520907158044\n",
      "177 24 0.17033132910728455\n",
      "Validation loss: 1.1692386139307591 ROC AUC: 0.709603118355776\n",
      "178 36 0.45475128293037415\n",
      "Validation loss: 1.2173594260057867 ROC AUC: 0.6867469879518072\n",
      "Validation loss: 1.1017702154765856 ROC AUC: 0.7161587526576896\n",
      "180 10 0.0753876268863678\n",
      "Validation loss: 0.9477958043679496 ROC AUC: 0.7296243798724309\n",
      "181 22 0.22837531566619873\n",
      "Validation loss: 0.9184264339358601 ROC AUC: 0.7220056697377746\n",
      "182 34 0.26876166462898254\n",
      "Validation loss: 1.0735941667430449 ROC AUC: 0.7005669737774628\n",
      "Validation loss: 1.2676555684070714 ROC AUC: 0.6828490432317504\n",
      "184 8 0.20368386805057526\n",
      "Validation loss: 1.3851594877558828 ROC AUC: 0.6957831325301205\n",
      "185 20 0.320300430059433\n",
      "Validation loss: 1.0676417936947171 ROC AUC: 0.7117292700212615\n",
      "186 32 0.4789077043533325\n",
      "Validation loss: 1.1576182111999056 ROC AUC: 0.696669029057406\n",
      "Validation loss: 1.1377795895203848 ROC AUC: 0.703756201275691\n",
      "188 6 0.23995226621627808\n",
      "Validation loss: 1.4134116062265358 ROC AUC: 0.6791282778171509\n",
      "189 18 0.3521290123462677\n",
      "Validation loss: 1.154478586272688 ROC AUC: 0.7186392629340893\n",
      "190 30 0.20033705234527588\n",
      "Validation loss: 1.4863557973444856 ROC AUC: 0.7220056697377746\n",
      "Validation loss: 1.1554880892204134 ROC AUC: 0.7088944011339476\n",
      "192 4 0.13834255933761597\n",
      "Validation loss: 1.3746296159479001 ROC AUC: 0.7010985116938341\n",
      "193 16 0.19601373374462128\n",
      "Validation loss: 1.1888993899553817 ROC AUC: 0.7390148830616583\n",
      "194 28 0.06553436070680618\n",
      "Validation loss: 1.4409798517921903 ROC AUC: 0.7076541459957477\n",
      "Validation loss: 1.0907287901600464 ROC AUC: 0.7049964564138909\n",
      "196 2 0.2243417203426361\n",
      "Validation loss: 1.2499590930559776 ROC AUC: 0.7106661941885187\n",
      "197 14 0.25680822134017944\n",
      "Validation loss: 1.3504221273573818 ROC AUC: 0.7016300496102055\n",
      "198 26 0.23494462668895721\n",
      "Validation loss: 1.2843327403858007 ROC AUC: 0.6881644223954642\n",
      "Validation loss: 1.1694493246394277 ROC AUC: 0.7363571934798014\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.869608245397869 Test ROC AUC: 0.8054347826086956\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'bbbp', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 777, 'task': 'classification', 'data_path': 'data/bbbp/BBBP.csv', 'target': ['p_np']}}\n",
      "Running on: cuda:0\n",
      "2038\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/2038\n",
      "Generating scaffold 1000/2038\n",
      "Generating scaffold 2000/2038\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.3025331497192383\n",
      "0 50 0.425006240606308\n",
      "Validation loss: 1.0287145422954185 ROC AUC: 0.890430900621118\n",
      "1 49 0.35399389266967773\n",
      "Validation loss: 1.2770393736222212 ROC AUC: 0.811238354037267\n",
      "2 48 0.3170517683029175\n",
      "Validation loss: 1.0249278335010303 ROC AUC: 0.9106172360248447\n",
      "3 47 0.454935759305954\n",
      "Validation loss: 1.9658263150383444 ROC AUC: 0.8337538819875776\n",
      "4 46 0.4319803714752197\n",
      "Validation loss: 1.7749700265772201 ROC AUC: 0.8227872670807452\n",
      "5 45 0.4066561758518219\n",
      "Validation loss: 1.060486944282756 ROC AUC: 0.8999417701863355\n",
      "6 44 0.2130858153104782\n",
      "Validation loss: 0.7972165360754612 ROC AUC: 0.8501552795031055\n",
      "7 43 0.23058360815048218\n",
      "Validation loss: 1.017927134738249 ROC AUC: 0.8932453416149069\n",
      "8 42 0.2872694730758667\n",
      "Validation loss: 0.9021518300561344 ROC AUC: 0.8817934782608695\n",
      "9 41 0.3755202293395996\n",
      "Validation loss: 3.384219124621036 ROC AUC: 0.845205745341615\n",
      "10 40 0.3572915196418762\n",
      "Validation loss: 1.0942415384685291 ROC AUC: 0.890042701863354\n",
      "11 39 0.22597768902778625\n",
      "Validation loss: 1.46967066970526 ROC AUC: 0.8857725155279503\n",
      "12 38 0.26507291197776794\n",
      "Validation loss: 1.8263461262572045 ROC AUC: 0.8673330745341615\n",
      "13 37 0.22393237054347992\n",
      "Validation loss: 1.1170523926323535 ROC AUC: 0.9200310559006212\n",
      "14 36 0.19708004593849182\n",
      "Validation loss: 1.335173578823314 ROC AUC: 0.8579192546583851\n",
      "15 35 0.2686196565628052\n",
      "Validation loss: 1.9808378780589384 ROC AUC: 0.8724767080745343\n",
      "16 34 0.31572631001472473\n",
      "Validation loss: 0.8353290338726604 ROC AUC: 0.8937305900621119\n",
      "17 33 0.33710455894470215\n",
      "Validation loss: 1.7966545890359318 ROC AUC: 0.8610248447204969\n",
      "18 32 0.3762111961841583\n",
      "Validation loss: 1.7913136061500101 ROC AUC: 0.828416149068323\n",
      "19 31 0.1792677938938141\n",
      "Validation loss: 1.1015053099276972 ROC AUC: 0.890625\n",
      "20 30 0.27668535709381104\n",
      "Validation loss: 1.609870155652364 ROC AUC: 0.8541343167701864\n",
      "21 29 0.2204016149044037\n",
      "Validation loss: 1.1003902659696692 ROC AUC: 0.890333850931677\n",
      "22 28 0.6172977089881897\n",
      "Validation loss: 0.594707707564036 ROC AUC: 0.9261451863354038\n",
      "23 27 0.13917507231235504\n",
      "Validation loss: 2.677589453902899 ROC AUC: 0.7694099378881987\n",
      "24 26 0.14472843706607819\n",
      "Validation loss: 0.9156089804920495 ROC AUC: 0.8837344720496894\n",
      "25 25 0.472182959318161\n",
      "Validation loss: 0.437076925647025 ROC AUC: 0.9171195652173912\n",
      "26 24 0.17968113720417023\n",
      "Validation loss: 0.6934448024805855 ROC AUC: 0.9387616459627328\n",
      "27 23 0.1910124570131302\n",
      "Validation loss: 0.5984394830815932 ROC AUC: 0.890819099378882\n",
      "28 22 0.32344111800193787\n",
      "Validation loss: 1.3565751547906912 ROC AUC: 0.8940217391304347\n",
      "29 21 0.11126555502414703\n",
      "Validation loss: 0.9482872278666964 ROC AUC: 0.8673330745341615\n",
      "30 20 0.21117940545082092\n",
      "Validation loss: 1.3563801061873342 ROC AUC: 0.8931482919254659\n",
      "31 19 0.23047985136508942\n",
      "Validation loss: 1.2585935803020702 ROC AUC: 0.9236218944099379\n",
      "32 18 0.19278323650360107\n",
      "Validation loss: 0.5725569349585795 ROC AUC: 0.9284743788819876\n",
      "33 17 0.19164784252643585\n",
      "Validation loss: 1.1157339974945666 ROC AUC: 0.9053765527950309\n",
      "34 16 0.1998281180858612\n",
      "Validation loss: 0.6549684931250179 ROC AUC: 0.9304153726708074\n",
      "35 15 0.3197653889656067\n",
      "Validation loss: 1.5316310749918807 ROC AUC: 0.8995535714285714\n",
      "36 14 0.12474959343671799\n",
      "Validation loss: 0.8315306925306133 ROC AUC: 0.892080745341615\n",
      "37 13 0.08085334300994873\n",
      "Validation loss: 0.698954561177422 ROC AUC: 0.9465256211180124\n",
      "38 12 0.15082408487796783\n",
      "Validation loss: 1.4813022520027908 ROC AUC: 0.8934394409937887\n",
      "39 11 0.3145996332168579\n",
      "Validation loss: 1.3893350736767638 ROC AUC: 0.9308035714285715\n",
      "40 10 0.10475700348615646\n",
      "Validation loss: 0.8230556109372307 ROC AUC: 0.8338509316770186\n",
      "41 9 0.15410630404949188\n",
      "Validation loss: 1.3771362024195053 ROC AUC: 0.9168284161490684\n",
      "42 8 0.21169739961624146\n",
      "Validation loss: 0.44485946342933413 ROC AUC: 0.9243982919254659\n",
      "43 7 0.06821657717227936\n",
      "Validation loss: 1.0193505637785967 ROC AUC: 0.9065411490683231\n",
      "44 6 0.22277411818504333\n",
      "Validation loss: 0.7201702174018411 ROC AUC: 0.9325504658385093\n",
      "45 5 0.23657386004924774\n",
      "Validation loss: 0.6806184848149618 ROC AUC: 0.9422554347826086\n",
      "46 4 0.4125502109527588\n",
      "Validation loss: 0.6868693925002042 ROC AUC: 0.9176048136645962\n",
      "47 3 0.16362430155277252\n",
      "Validation loss: 0.5071082085955376 ROC AUC: 0.9479813664596273\n",
      "48 2 0.09457182884216309\n",
      "Validation loss: 0.9483008665197036 ROC AUC: 0.9263392857142857\n",
      "49 1 0.04691707342863083\n",
      "Validation loss: 0.8334200130227734 ROC AUC: 0.9111995341614907\n",
      "50 0 0.11049792170524597\n",
      "50 50 0.19202417135238647\n",
      "Validation loss: 1.151300825324713 ROC AUC: 0.8712150621118012\n",
      "51 49 0.1544153392314911\n",
      "Validation loss: 1.3546966384438908 ROC AUC: 0.9293478260869564\n",
      "52 48 0.3496796190738678\n",
      "Validation loss: 1.2047433993395638 ROC AUC: 0.8580163043478262\n",
      "53 47 0.06607185304164886\n",
      "Validation loss: 1.4736997052734973 ROC AUC: 0.8974184782608695\n",
      "54 46 0.34677746891975403\n",
      "Validation loss: 0.7906523358588126 ROC AUC: 0.9372088509316769\n",
      "55 45 0.16770657896995544\n",
      "Validation loss: 2.4762090187446746 ROC AUC: 0.8731560559006211\n",
      "56 44 0.2576305568218231\n",
      "Validation loss: 0.5924085816916298 ROC AUC: 0.9318711180124224\n",
      "57 43 0.13014186918735504\n",
      "Validation loss: 0.6359173930158802 ROC AUC: 0.9351708074534162\n",
      "58 42 0.12836478650569916\n",
      "Validation loss: 0.956599578553555 ROC AUC: 0.9308035714285714\n",
      "59 41 0.2626519799232483\n",
      "Validation loss: 1.3843030321831797 ROC AUC: 0.9288625776397516\n",
      "60 40 0.20841990411281586\n",
      "Validation loss: 0.6098521643993902 ROC AUC: 0.9249805900621118\n",
      "61 39 0.07783014327287674\n",
      "Validation loss: 0.9319019300096175 ROC AUC: 0.9054736024844721\n",
      "62 38 0.14100965857505798\n",
      "Validation loss: 0.6591523768855077 ROC AUC: 0.9319681677018633\n",
      "63 37 0.04415769502520561\n",
      "Validation loss: 0.7878682999049916 ROC AUC: 0.9243982919254657\n",
      "64 36 0.06805866211652756\n",
      "Validation loss: 1.1856126668406468 ROC AUC: 0.9309006211180124\n",
      "65 35 0.3535560071468353\n",
      "Validation loss: 0.7573565104428459 ROC AUC: 0.9157608695652173\n",
      "66 34 0.19714370369911194\n",
      "Validation loss: 1.453532649605882 ROC AUC: 0.889848602484472\n",
      "67 33 0.09408393502235413\n",
      "Validation loss: 0.7831063036825142 ROC AUC: 0.9153726708074534\n",
      "68 32 0.1463986486196518\n",
      "Validation loss: 0.9088712509940652 ROC AUC: 0.8624805900621118\n",
      "69 31 0.04291291534900665\n",
      "Validation loss: 1.0235994282890768 ROC AUC: 0.9171195652173912\n",
      "70 30 0.11824040114879608\n",
      "Validation loss: 0.8235556325491737 ROC AUC: 0.9000388198757764\n",
      "71 29 0.22292307019233704\n",
      "Validation loss: 1.5745742899530075 ROC AUC: 0.890139751552795\n",
      "72 28 0.12310674041509628\n",
      "Validation loss: 1.0463487985087376 ROC AUC: 0.9203222049689441\n",
      "73 27 0.11198116093873978\n",
      "Validation loss: 1.1828684073452855 ROC AUC: 0.8781055900621118\n",
      "74 26 0.08367565274238586\n",
      "Validation loss: 1.0355346740460862 ROC AUC: 0.8929541925465838\n",
      "75 25 0.06587130576372147\n",
      "Validation loss: 1.2970814155597312 ROC AUC: 0.8978066770186336\n",
      "76 24 0.07148509472608566\n",
      "Validation loss: 0.8523985147476196 ROC AUC: 0.8998447204968943\n",
      "77 23 0.025218507274985313\n",
      "Validation loss: 0.8368577887030209 ROC AUC: 0.8931482919254659\n",
      "78 22 0.043597783893346786\n",
      "Validation loss: 0.8301422899844599 ROC AUC: 0.8798524844720497\n",
      "79 21 0.14064478874206543\n",
      "Validation loss: 1.6875638728048288 ROC AUC: 0.8895574534161491\n",
      "80 20 0.1062256246805191\n",
      "Validation loss: 1.903033969449062 ROC AUC: 0.9034355590062111\n",
      "81 19 0.14072342216968536\n",
      "Validation loss: 1.0083807087412067 ROC AUC: 0.8815023291925466\n",
      "82 18 0.036092936992645264\n",
      "Validation loss: 0.9886583894783375 ROC AUC: 0.8488936335403726\n",
      "83 17 0.19526773691177368\n",
      "Validation loss: 0.6836798407283484 ROC AUC: 0.9230395962732919\n",
      "84 16 0.06886717677116394\n",
      "Validation loss: 0.7098377159997529 ROC AUC: 0.9242041925465838\n",
      "85 15 0.3324146270751953\n",
      "Validation loss: 1.3586353063583374 ROC AUC: 0.9147903726708074\n",
      "86 14 0.22660605609416962\n",
      "Validation loss: 0.496542515707951 ROC AUC: 0.9264363354037267\n",
      "87 13 0.07015154510736465\n",
      "Validation loss: 0.6906217640521479 ROC AUC: 0.9046972049689441\n",
      "88 12 0.09922382235527039\n",
      "Validation loss: 1.1181751068900614 ROC AUC: 0.8941187888198757\n",
      "89 11 0.07980190217494965\n",
      "Validation loss: 1.4346336690234203 ROC AUC: 0.9131405279503105\n",
      "90 10 0.1325460821390152\n",
      "Validation loss: 0.757942680050345 ROC AUC: 0.9111024844720497\n",
      "91 9 0.23890025913715363\n",
      "Validation loss: 0.6721344420722887 ROC AUC: 0.9235248447204968\n",
      "92 8 0.3527466058731079\n",
      "Validation loss: 0.8316093683242798 ROC AUC: 0.9203222049689441\n",
      "93 7 0.15658977627754211\n",
      "Validation loss: 1.0503883583872926 ROC AUC: 0.9103260869565217\n",
      "94 6 0.1820869892835617\n",
      "Validation loss: 1.2234193086624146 ROC AUC: 0.8851902173913043\n",
      "95 5 0.11484670639038086\n",
      "Validation loss: 1.0065286977618348 ROC AUC: 0.92381599378882\n",
      "96 4 0.2010422945022583\n",
      "Validation loss: 0.9205188854214024 ROC AUC: 0.9270186335403726\n",
      "97 3 0.09874361753463745\n",
      "Validation loss: 1.2213226001636655 ROC AUC: 0.9118788819875776\n",
      "98 2 0.08249448239803314\n",
      "Validation loss: 0.7071037163921431 ROC AUC: 0.9382763975155279\n",
      "99 1 0.0917564183473587\n",
      "Validation loss: 1.2288620916067385 ROC AUC: 0.92090450310559\n",
      "100 0 0.0616484172642231\n",
      "100 50 0.10597838461399078\n",
      "Validation loss: 0.8586737104490691 ROC AUC: 0.9257569875776397\n",
      "101 49 0.06526358425617218\n",
      "Validation loss: 1.2476154393425174 ROC AUC: 0.9328416149068324\n",
      "102 48 0.2937159836292267\n",
      "Validation loss: 1.5262636822812699 ROC AUC: 0.9362383540372671\n",
      "103 47 0.11969399452209473\n",
      "Validation loss: 0.8312981397497887 ROC AUC: 0.9237189440993788\n",
      "104 46 0.3004656136035919\n",
      "Validation loss: 0.8767592930326275 ROC AUC: 0.9384704968944099\n",
      "105 45 0.12232699245214462\n",
      "Validation loss: 1.206569444461196 ROC AUC: 0.9382763975155279\n",
      "106 44 0.05435607209801674\n",
      "Validation loss: 0.668896810827302 ROC AUC: 0.9108113354037267\n",
      "107 43 0.18243448436260223\n",
      "Validation loss: 0.9312569650949216 ROC AUC: 0.921001552795031\n",
      "108 42 0.19955244660377502\n",
      "Validation loss: 1.338216167454626 ROC AUC: 0.906832298136646\n",
      "109 41 0.13692869246006012\n",
      "Validation loss: 0.8946919733402776 ROC AUC: 0.9098408385093167\n",
      "110 40 0.12223251163959503\n",
      "Validation loss: 1.2005345282309197 ROC AUC: 0.8963509316770186\n",
      "111 39 0.23682649433612823\n",
      "Validation loss: 1.2040955529493444 ROC AUC: 0.8964479813664596\n",
      "112 38 0.167145773768425\n",
      "Validation loss: 0.6999209084931541 ROC AUC: 0.9470108695652174\n",
      "113 37 0.24630597233772278\n",
      "Validation loss: 0.9191157969773984 ROC AUC: 0.9412849378881988\n",
      "114 36 0.085999496281147\n",
      "Validation loss: 1.147329657685523 ROC AUC: 0.9330357142857144\n",
      "115 35 0.16721166670322418\n",
      "Validation loss: 0.7144839722736209 ROC AUC: 0.9123641304347827\n",
      "116 34 0.09129137545824051\n",
      "Validation loss: 1.058798206203124 ROC AUC: 0.9351708074534161\n",
      "117 33 0.04467200115323067\n",
      "Validation loss: 0.595531854522871 ROC AUC: 0.9325504658385094\n",
      "118 32 0.21736596524715424\n",
      "Validation loss: 0.7996698647153144 ROC AUC: 0.9141110248447204\n",
      "119 31 0.14981380105018616\n",
      "Validation loss: 0.702022006114324 ROC AUC: 0.9277950310559007\n",
      "120 30 0.057424239814281464\n",
      "Validation loss: 0.8147202993140501 ROC AUC: 0.9090644409937888\n",
      "121 29 0.14328517019748688\n",
      "Validation loss: 1.1904264787832897 ROC AUC: 0.8919836956521738\n",
      "122 28 0.2573893368244171\n",
      "Validation loss: 1.2685399788486607 ROC AUC: 0.8907220496894409\n",
      "123 27 0.04638899117708206\n",
      "Validation loss: 1.3595262041278915 ROC AUC: 0.9046001552795031\n",
      "124 26 0.22631195187568665\n",
      "Validation loss: 0.9321999923855651 ROC AUC: 0.9173136645962733\n",
      "125 25 0.0708741769194603\n",
      "Validation loss: 0.7524226167622734 ROC AUC: 0.9106172360248448\n",
      "126 24 0.07440271228551865\n",
      "Validation loss: 0.5750935638652128 ROC AUC: 0.9467197204968943\n",
      "127 23 0.07563208788633347\n",
      "Validation loss: 1.0413270780871458 ROC AUC: 0.936432453416149\n",
      "128 22 0.17853473126888275\n",
      "Validation loss: 1.1142368082906686 ROC AUC: 0.8817934782608696\n",
      "129 21 0.0761035829782486\n",
      "Validation loss: 0.8247434438443652 ROC AUC: 0.935947204968944\n",
      "130 20 0.08763989061117172\n",
      "Validation loss: 0.9469236090194946 ROC AUC: 0.9230395962732919\n",
      "131 19 0.09141591936349869\n",
      "Validation loss: 0.9767122455671722 ROC AUC: 0.8923718944099378\n",
      "132 18 0.040668923407793045\n",
      "Validation loss: 0.8638810971203972 ROC AUC: 0.9349767080745341\n",
      "133 17 0.04731454327702522\n",
      "Validation loss: 1.1818099816640217 ROC AUC: 0.9063470496894409\n",
      "134 16 0.11414539068937302\n",
      "Validation loss: 0.9106221987920649 ROC AUC: 0.9267274844720497\n",
      "135 15 0.11418955028057098\n",
      "Validation loss: 0.9246641677968642 ROC AUC: 0.9099378881987578\n",
      "136 14 0.031371526420116425\n",
      "Validation loss: 0.8062325961449567 ROC AUC: 0.9203222049689442\n",
      "137 13 0.08961974829435349\n",
      "Validation loss: 1.0273664511886298 ROC AUC: 0.90527950310559\n",
      "138 12 0.04046746715903282\n",
      "Validation loss: 1.2800028511122161 ROC AUC: 0.9328416149068323\n",
      "139 11 0.11366647481918335\n",
      "Validation loss: 0.901609738667806 ROC AUC: 0.9285714285714286\n",
      "140 10 0.08506526052951813\n",
      "Validation loss: 1.1250345297888213 ROC AUC: 0.9166343167701864\n",
      "141 9 0.10176985710859299\n",
      "Validation loss: 1.0005108398549698 ROC AUC: 0.907317546583851\n",
      "142 8 0.10758782923221588\n",
      "Validation loss: 0.7631095811432483 ROC AUC: 0.936820652173913\n",
      "143 7 0.1996982842683792\n",
      "Validation loss: 0.9092934762730318 ROC AUC: 0.9336180124223602\n",
      "144 6 0.03866147622466087\n",
      "Validation loss: 1.11786953608195 ROC AUC: 0.9243982919254657\n",
      "145 5 0.08563680946826935\n",
      "Validation loss: 0.8016916712125143 ROC AUC: 0.9465256211180124\n",
      "146 4 0.10330928862094879\n",
      "Validation loss: 1.0467885335286458 ROC AUC: 0.9285714285714286\n",
      "147 3 0.11836698651313782\n",
      "Validation loss: 0.9305040088354373 ROC AUC: 0.9232336956521738\n",
      "148 2 0.05357588827610016\n",
      "Validation loss: 0.9062826329586553 ROC AUC: 0.9317740683229813\n",
      "149 1 0.01165308803319931\n",
      "Validation loss: 0.8246956350756627 ROC AUC: 0.922554347826087\n",
      "150 0 0.023762349039316177\n",
      "150 50 0.04301614686846733\n",
      "Validation loss: 0.7238974150489358 ROC AUC: 0.9398291925465838\n",
      "151 49 0.05026981607079506\n",
      "Validation loss: 1.020928741889257 ROC AUC: 0.9338121118012424\n",
      "152 48 0.11269835382699966\n",
      "Validation loss: 0.6991026401519775 ROC AUC: 0.9230395962732919\n",
      "153 47 0.07419101893901825\n",
      "Validation loss: 1.9495268896514295 ROC AUC: 0.905182453416149\n",
      "154 46 0.1561141312122345\n",
      "Validation loss: 1.27248054041582 ROC AUC: 0.9038237577639752\n",
      "155 45 0.10506661981344223\n",
      "Validation loss: 0.7910762657137478 ROC AUC: 0.8883928571428571\n",
      "156 44 0.05884804576635361\n",
      "Validation loss: 2.112078194524728 ROC AUC: 0.9046001552795031\n",
      "157 43 0.08060606569051743\n",
      "Validation loss: 0.9347110139388665 ROC AUC: 0.8777173913043479\n",
      "158 42 0.25167298316955566\n",
      "Validation loss: 1.4685351287617403 ROC AUC: 0.904988354037267\n",
      "159 41 0.19149446487426758\n",
      "Validation loss: 1.028059389076981 ROC AUC: 0.9113936335403726\n",
      "160 40 0.14913976192474365\n",
      "Validation loss: 1.1897593105540556 ROC AUC: 0.9280861801242235\n",
      "161 39 0.06116953119635582\n",
      "Validation loss: 0.8910208020140143 ROC AUC: 0.9290566770186335\n",
      "162 38 0.013997637666761875\n",
      "Validation loss: 0.9444332438356736 ROC AUC: 0.9324534161490683\n",
      "163 37 0.12070007622241974\n",
      "Validation loss: 0.6785371037674885 ROC AUC: 0.9153726708074534\n",
      "164 36 0.1440267264842987\n",
      "Validation loss: 2.081067954792696 ROC AUC: 0.8782026397515528\n",
      "165 35 0.05706045776605606\n",
      "Validation loss: 1.2859028086942785 ROC AUC: 0.9151785714285714\n",
      "166 34 0.08566966652870178\n",
      "Validation loss: 1.5633499688085388 ROC AUC: 0.9173136645962733\n",
      "167 33 0.11916184425354004\n",
      "Validation loss: 1.6027156161326988 ROC AUC: 0.9149844720496894\n",
      "168 32 0.036683958023786545\n",
      "Validation loss: 1.5486746044719921 ROC AUC: 0.9079968944099378\n",
      "169 31 0.3160226345062256\n",
      "Validation loss: 1.5027971781936347 ROC AUC: 0.9236218944099379\n",
      "170 30 0.055993758141994476\n",
      "Validation loss: 1.1290281862020493 ROC AUC: 0.9161490683229813\n",
      "171 29 0.07349250465631485\n",
      "Validation loss: 1.0160519001530666 ROC AUC: 0.9369177018633541\n",
      "172 28 0.0811009630560875\n",
      "Validation loss: 1.6971825665118647 ROC AUC: 0.9240100931677019\n",
      "173 27 0.04060941934585571\n",
      "Validation loss: 1.7021239762212717 ROC AUC: 0.9049883540372671\n",
      "174 26 0.28330036997795105\n",
      "Validation loss: 1.3049617140900855 ROC AUC: 0.9256599378881987\n",
      "175 25 0.06630416959524155\n",
      "Validation loss: 1.1744571462565778 ROC AUC: 0.8894604037267081\n",
      "176 24 0.0656755194067955\n",
      "Validation loss: 2.5254177556318393 ROC AUC: 0.8993594720496895\n",
      "177 23 0.08804940432310104\n",
      "Validation loss: 1.465328033063926 ROC AUC: 0.9079968944099379\n",
      "178 22 0.11298053711652756\n",
      "Validation loss: 0.9815085880896625 ROC AUC: 0.906638198757764\n",
      "179 21 0.041520100086927414\n",
      "Validation loss: 1.5093725114768626 ROC AUC: 0.8849961180124224\n",
      "180 20 0.06962525844573975\n",
      "Validation loss: 1.2211230034921683 ROC AUC: 0.9159549689440994\n",
      "181 19 0.08015289157629013\n",
      "Validation loss: 1.17346011540469 ROC AUC: 0.9114906832298136\n",
      "182 18 0.18504278361797333\n",
      "Validation loss: 1.1357554223607569 ROC AUC: 0.9010093167701863\n",
      "183 17 0.04590277373790741\n",
      "Validation loss: 1.123723446154127 ROC AUC: 0.9104231366459626\n",
      "184 16 0.04926116764545441\n",
      "Validation loss: 1.3221722747765334 ROC AUC: 0.9173136645962734\n",
      "185 15 0.033961765468120575\n",
      "Validation loss: 1.2556982928631353 ROC AUC: 0.92381599378882\n",
      "186 14 0.08035407960414886\n",
      "Validation loss: 1.6521283224517225 ROC AUC: 0.9080939440993789\n",
      "187 13 0.12374783307313919\n",
      "Validation loss: 1.4167312804390402 ROC AUC: 0.875873447204969\n",
      "188 12 0.14214709401130676\n",
      "Validation loss: 1.005684281900233 ROC AUC: 0.921389751552795\n",
      "189 11 0.1029336228966713\n",
      "Validation loss: 0.9597037264177868 ROC AUC: 0.9210986024844721\n",
      "190 10 0.0617419071495533\n",
      "Validation loss: 0.9097698500343397 ROC AUC: 0.9189635093167701\n",
      "191 9 0.03330560773611069\n",
      "Validation loss: 0.8557558644051645 ROC AUC: 0.9249805900621118\n",
      "192 8 0.06471775472164154\n",
      "Validation loss: 0.9191988133916668 ROC AUC: 0.9295419254658386\n",
      "193 7 0.015913918614387512\n",
      "Validation loss: 1.2412348074071549 ROC AUC: 0.9333268633540374\n",
      "194 6 0.12384126335382462\n",
      "Validation loss: 0.8523771596670735 ROC AUC: 0.9243012422360248\n",
      "195 5 0.06618122011423111\n",
      "Validation loss: 1.2073745669103135 ROC AUC: 0.93944099378882\n",
      "196 4 0.17332135140895844\n",
      "Validation loss: 1.4101721889832441 ROC AUC: 0.9080939440993789\n",
      "197 3 0.04786686971783638\n",
      "Validation loss: 1.19521728647398 ROC AUC: 0.9082880434782609\n",
      "198 2 0.03277304768562317\n",
      "Validation loss: 1.193879529541614 ROC AUC: 0.922651397515528\n",
      "199 1 0.11004872620105743\n",
      "Validation loss: 1.3211611275579416 ROC AUC: 0.888198757763975\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.9512778637455959 Test ROC AUC: 0.6866750168609692\n",
      "/tf/MolCLR-master -  - /finetuneReconTop.py:712: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([existing_df, df], ignore_index=True)\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'bbbp', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 778, 'task': 'classification', 'data_path': 'data/bbbp/BBBP.csv', 'target': ['p_np']}}\n",
      "Running on: cuda:0\n",
      "2038\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/2038\n",
      "Generating scaffold 1000/2038\n",
      "Generating scaffold 2000/2038\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.1914222240447998\n",
      "0 50 0.6608637571334839\n",
      "Validation loss: 0.7979505506216311 ROC AUC: 0.8552018633540371\n",
      "1 49 0.32464486360549927\n",
      "Validation loss: 0.9956319355497173 ROC AUC: 0.8424883540372671\n",
      "2 48 0.24141497910022736\n",
      "Validation loss: 1.380330574278738 ROC AUC: 0.8614130434782609\n",
      "3 47 0.35631683468818665\n",
      "Validation loss: 1.4371372344447118 ROC AUC: 0.905376552795031\n",
      "4 46 0.4374528229236603\n",
      "Validation loss: 0.8727323927131354 ROC AUC: 0.9090644409937887\n",
      "5 45 0.22484761476516724\n",
      "Validation loss: 0.3606216369890699 ROC AUC: 0.9419642857142857\n",
      "6 44 0.506425678730011\n",
      "Validation loss: 0.6869356293304294 ROC AUC: 0.9105201863354037\n",
      "7 43 0.3738202154636383\n",
      "Validation loss: 0.601021522400426 ROC AUC: 0.9277950310559007\n",
      "8 42 0.1809665709733963\n",
      "Validation loss: 0.7639775130094266 ROC AUC: 0.8720885093167703\n",
      "9 41 0.3890727162361145\n",
      "Validation loss: 1.0138123093866835 ROC AUC: 0.923039596273292\n",
      "10 40 0.3111743628978729\n",
      "Validation loss: 0.8557941516240438 ROC AUC: 0.8976125776397516\n",
      "11 39 0.27936750650405884\n",
      "Validation loss: 0.9109333058198293 ROC AUC: 0.8789790372670807\n",
      "12 38 0.5498504638671875\n",
      "Validation loss: 0.8028981732387169 ROC AUC: 0.9215838509316769\n",
      "13 37 0.3892958462238312\n",
      "Validation loss: 0.8861725444302839 ROC AUC: 0.8531638198757764\n",
      "14 36 0.21773271262645721\n",
      "Validation loss: 0.605504694376506 ROC AUC: 0.9177989130434782\n",
      "15 35 0.3322933614253998\n",
      "Validation loss: 0.8133678144099665 ROC AUC: 0.8993594720496894\n",
      "16 34 0.2226456254720688\n",
      "Validation loss: 0.9069308603511137 ROC AUC: 0.8878105590062111\n",
      "17 33 0.3606569170951843\n",
      "Validation loss: 0.8465787037914875 ROC AUC: 0.9248835403726708\n",
      "18 32 0.34826627373695374\n",
      "Validation loss: 0.7127765019734701 ROC AUC: 0.8830551242236025\n",
      "19 31 0.13986694812774658\n",
      "Validation loss: 0.8361607883490768 ROC AUC: 0.858501552795031\n",
      "20 30 0.38581979274749756\n",
      "Validation loss: 0.5726436283074173 ROC AUC: 0.9309976708074534\n",
      "21 29 0.17611686885356903\n",
      "Validation loss: 0.6256140207543093 ROC AUC: 0.8875194099378882\n",
      "22 28 0.21657899022102356\n",
      "Validation loss: 0.5154503128107857 ROC AUC: 0.9045031055900621\n",
      "23 27 0.156173437833786\n",
      "Validation loss: 0.7841637905906228 ROC AUC: 0.8833462732919255\n",
      "24 26 0.2244761884212494\n",
      "Validation loss: 0.6235974284948087 ROC AUC: 0.9295419254658385\n",
      "25 25 0.13087087869644165\n",
      "Validation loss: 0.5598249143245173 ROC AUC: 0.904988354037267\n",
      "26 24 0.2855539619922638\n",
      "Validation loss: 0.7214909133081343 ROC AUC: 0.9282802795031055\n",
      "27 23 0.17800496518611908\n",
      "Validation loss: 0.654644316610168 ROC AUC: 0.9184782608695652\n",
      "28 22 0.18572378158569336\n",
      "Validation loss: 0.9248679759455662 ROC AUC: 0.8933423913043478\n",
      "29 21 0.195887491106987\n",
      "Validation loss: 0.6808793416210249 ROC AUC: 0.9110054347826086\n",
      "30 20 0.1842888593673706\n",
      "Validation loss: 0.6693015694618225 ROC AUC: 0.8847049689440996\n",
      "31 19 0.16109921038150787\n",
      "Validation loss: 0.6345467357074513 ROC AUC: 0.9116847826086957\n",
      "32 18 0.14815263450145721\n",
      "Validation loss: 0.6884379807640525 ROC AUC: 0.9231366459627328\n",
      "33 17 0.3442092537879944\n",
      "Validation loss: 0.6767609274270487 ROC AUC: 0.9051824534161489\n",
      "34 16 0.10383181273937225\n",
      "Validation loss: 0.7672364308553583 ROC AUC: 0.9201281055900621\n",
      "35 15 0.1715289056301117\n",
      "Validation loss: 0.6279169823609146 ROC AUC: 0.9011063664596273\n",
      "36 14 0.14576539397239685\n",
      "Validation loss: 0.9250403928990457 ROC AUC: 0.922263198757764\n",
      "37 13 0.6141746640205383\n",
      "Validation loss: 0.7255052281361 ROC AUC: 0.9261451863354038\n",
      "38 12 0.27934446930885315\n",
      "Validation loss: 0.5881005584024915 ROC AUC: 0.9191576086956521\n",
      "39 11 0.1102217510342598\n",
      "Validation loss: 0.8734977747879776 ROC AUC: 0.9222631987577639\n",
      "40 10 0.43582451343536377\n",
      "Validation loss: 0.5864991477380196 ROC AUC: 0.9193517080745341\n",
      "41 9 0.15772473812103271\n",
      "Validation loss: 0.6861991695329255 ROC AUC: 0.9097437888198758\n",
      "42 8 0.6294581294059753\n",
      "Validation loss: 0.8798987210965624 ROC AUC: 0.8829580745341615\n",
      "43 7 0.2675114870071411\n",
      "Validation loss: 0.5604218070157895 ROC AUC: 0.9264363354037266\n",
      "44 6 0.1820169985294342\n",
      "Validation loss: 0.7831126556676977 ROC AUC: 0.874805900621118\n",
      "45 5 0.10413385927677155\n",
      "Validation loss: 0.7095309227120643 ROC AUC: 0.8695652173913043\n",
      "46 4 0.19314046204090118\n",
      "Validation loss: 1.207013443404553 ROC AUC: 0.827251552795031\n",
      "47 3 0.11201232671737671\n",
      "Validation loss: 0.6293157900080961 ROC AUC: 0.9016886645962733\n",
      "48 2 0.18637719750404358\n",
      "Validation loss: 0.6473016773953157 ROC AUC: 0.9054736024844721\n",
      "49 1 0.316651314496994\n",
      "Validation loss: 0.7204924722512563 ROC AUC: 0.9024650621118013\n",
      "50 0 0.34685754776000977\n",
      "50 50 0.3499723970890045\n",
      "Validation loss: 1.2548911033892165 ROC AUC: 0.8575310559006211\n",
      "51 49 0.09578537940979004\n",
      "Validation loss: 0.5760252108322639 ROC AUC: 0.9134316770186336\n",
      "52 48 0.05889945849776268\n",
      "Validation loss: 0.6138603161363041 ROC AUC: 0.9113936335403727\n",
      "53 47 0.26001378893852234\n",
      "Validation loss: 0.5371954067080629 ROC AUC: 0.9137228260869565\n",
      "54 46 0.3322206735610962\n",
      "Validation loss: 0.7425088039508053 ROC AUC: 0.9033385093167702\n",
      "55 45 0.2553800940513611\n",
      "Validation loss: 0.8560265781832677 ROC AUC: 0.875291149068323\n",
      "56 44 0.14413142204284668\n",
      "Validation loss: 0.7610328571469176 ROC AUC: 0.9100349378881988\n",
      "57 43 0.23943841457366943\n",
      "Validation loss: 0.7191648950763777 ROC AUC: 0.922069099378882\n",
      "58 42 0.22282744944095612\n",
      "Validation loss: 0.8503440314648198 ROC AUC: 0.9025621118012422\n",
      "59 41 0.06266240775585175\n",
      "Validation loss: 0.6739659730125876 ROC AUC: 0.9097437888198758\n",
      "60 40 0.11517443507909775\n",
      "Validation loss: 0.8913171793900284 ROC AUC: 0.8872282608695652\n",
      "61 39 0.24404141306877136\n",
      "Validation loss: 1.2824999023886288 ROC AUC: 0.8984860248447204\n",
      "62 38 0.19494333863258362\n",
      "Validation loss: 0.9344896849463967 ROC AUC: 0.8973214285714286\n",
      "63 37 0.24636229872703552\n",
      "Validation loss: 0.6907848341792238 ROC AUC: 0.9161490683229815\n",
      "64 36 0.31447964906692505\n",
      "Validation loss: 0.9906890018313539 ROC AUC: 0.9128493788819876\n",
      "65 35 0.540867269039154\n",
      "Validation loss: 0.9403471888280382 ROC AUC: 0.875485248447205\n",
      "66 34 0.17559731006622314\n",
      "Validation loss: 0.9564604221605787 ROC AUC: 0.9124611801242236\n",
      "67 33 0.1766587644815445\n",
      "Validation loss: 0.6743557686899223 ROC AUC: 0.907802795031056\n",
      "68 32 0.2181127965450287\n",
      "Validation loss: 0.9291407077335844 ROC AUC: 0.8888781055900621\n",
      "69 31 0.11056344211101532\n",
      "Validation loss: 0.8253616456891976 ROC AUC: 0.9206133540372671\n",
      "70 30 0.07315676659345627\n",
      "Validation loss: 1.0280882856425118 ROC AUC: 0.9018827639751552\n",
      "71 29 0.12608197331428528\n",
      "Validation loss: 1.1102004331700943 ROC AUC: 0.9116847826086957\n",
      "72 28 0.10643813759088516\n",
      "Validation loss: 0.6893946738804088 ROC AUC: 0.8970302795031055\n",
      "73 27 0.061744771897792816\n",
      "Validation loss: 0.6208834890641418 ROC AUC: 0.9167313664596274\n",
      "74 26 0.18011152744293213\n",
      "Validation loss: 0.88703939260221 ROC AUC: 0.873447204968944\n",
      "75 25 0.09606218338012695\n",
      "Validation loss: 0.7853136880725038 ROC AUC: 0.9034355590062111\n",
      "76 24 0.1130739077925682\n",
      "Validation loss: 0.6060520644281425 ROC AUC: 0.9162461180124224\n",
      "77 23 0.19855451583862305\n",
      "Validation loss: 0.7965331597655427 ROC AUC: 0.9181871118012422\n",
      "78 22 0.1906723976135254\n",
      "Validation loss: 0.5462065850402794 ROC AUC: 0.9385675465838509\n",
      "79 21 0.1414715200662613\n",
      "Validation loss: 1.150580089977559 ROC AUC: 0.8482142857142857\n",
      "80 20 0.2029646635055542\n",
      "Validation loss: 0.5469319750280941 ROC AUC: 0.9255628881987578\n",
      "81 19 0.24806100130081177\n",
      "Validation loss: 0.6959352294603983 ROC AUC: 0.9166343167701863\n",
      "82 18 0.21860027313232422\n",
      "Validation loss: 1.0639456580666935 ROC AUC: 0.8764557453416149\n",
      "83 17 0.1384449601173401\n",
      "Validation loss: 0.9365558530770096 ROC AUC: 0.904503105590062\n",
      "84 16 0.10953554511070251\n",
      "Validation loss: 1.1216216274336273 ROC AUC: 0.9137228260869565\n",
      "85 15 0.11664796620607376\n",
      "Validation loss: 0.6161737184898526 ROC AUC: 0.9189635093167702\n",
      "86 14 0.12475906312465668\n",
      "Validation loss: 0.6181139647960663 ROC AUC: 0.8920807453416149\n",
      "87 13 0.10383523255586624\n",
      "Validation loss: 0.631324794362573 ROC AUC: 0.9098408385093167\n",
      "88 12 0.06626155227422714\n",
      "Validation loss: 1.0218439219044704 ROC AUC: 0.9201281055900621\n",
      "89 11 0.08342275768518448\n",
      "Validation loss: 0.9084869018372368 ROC AUC: 0.8540372670807452\n",
      "90 10 0.33012616634368896\n",
      "Validation loss: 0.4945696735864176 ROC AUC: 0.9146933229813665\n",
      "91 9 0.05768006667494774\n",
      "Validation loss: 0.6775670863834082 ROC AUC: 0.921875\n",
      "92 8 0.05042622610926628\n",
      "Validation loss: 0.6675203956809699 ROC AUC: 0.906638198757764\n",
      "93 7 0.1938471496105194\n",
      "Validation loss: 0.6125726910198436 ROC AUC: 0.8947981366459627\n",
      "94 6 0.24202540516853333\n",
      "Validation loss: 0.46931912969140444 ROC AUC: 0.9290566770186336\n",
      "95 5 0.12993571162223816\n",
      "Validation loss: 1.1327141196120019 ROC AUC: 0.9051824534161489\n",
      "96 4 0.0805012583732605\n",
      "Validation loss: 0.8060662559434479 ROC AUC: 0.9017857142857143\n",
      "97 3 0.12834638357162476\n",
      "Validation loss: 0.5663400806632697 ROC AUC: 0.9255628881987578\n",
      "98 2 0.13804756104946136\n",
      "Validation loss: 1.507286720416125 ROC AUC: 0.858792701863354\n",
      "99 1 0.06451848149299622\n",
      "Validation loss: 0.599871530736267 ROC AUC: 0.9313858695652173\n",
      "100 0 0.10703971982002258\n",
      "100 50 0.09927642345428467\n",
      "Validation loss: 1.367924260158165 ROC AUC: 0.8886840062111802\n",
      "101 49 0.05347098037600517\n",
      "Validation loss: 0.8352877339896034 ROC AUC: 0.9115877329192547\n",
      "102 48 0.14973855018615723\n",
      "Validation loss: 1.6594403210808248 ROC AUC: 0.8933423913043479\n",
      "103 47 0.05016433447599411\n",
      "Validation loss: 0.7566242726410136 ROC AUC: 0.8974184782608695\n",
      "104 46 0.07773678004741669\n",
      "Validation loss: 1.0661301566105263 ROC AUC: 0.890333850931677\n",
      "105 45 0.04140825942158699\n",
      "Validation loss: 0.7273072460118462 ROC AUC: 0.8859666149068324\n",
      "106 44 0.08052464574575424\n",
      "Validation loss: 1.0182630875713976 ROC AUC: 0.9191576086956522\n",
      "107 43 0.05539461225271225\n",
      "Validation loss: 0.7655419146313387 ROC AUC: 0.9080939440993787\n",
      "108 42 0.06932276487350464\n",
      "Validation loss: 1.55537337882846 ROC AUC: 0.8828610248447204\n",
      "109 41 0.05840510502457619\n",
      "Validation loss: 0.6255872880711275 ROC AUC: 0.906055900621118\n",
      "110 40 0.3249228596687317\n",
      "Validation loss: 0.8640853295139238 ROC AUC: 0.8786878881987578\n",
      "111 39 0.10662202537059784\n",
      "Validation loss: 0.9054639140764872 ROC AUC: 0.9121700310559007\n",
      "112 38 0.19090726971626282\n",
      "Validation loss: 0.8167818223728853 ROC AUC: 0.890042701863354\n",
      "113 37 0.12364823371171951\n",
      "Validation loss: 0.8309987932991456 ROC AUC: 0.9258540372670807\n",
      "114 36 0.11006558686494827\n",
      "Validation loss: 0.8207069027657602 ROC AUC: 0.8915954968944099\n",
      "115 35 0.2580130696296692\n",
      "Validation loss: 0.9158881949443444 ROC AUC: 0.8863548136645963\n",
      "116 34 0.10022855550050735\n",
      "Validation loss: 0.6607052321527519 ROC AUC: 0.9160520186335404\n",
      "117 33 0.15205319225788116\n",
      "Validation loss: 0.751810928514483 ROC AUC: 0.9017857142857142\n",
      "118 32 0.05564621463418007\n",
      "Validation loss: 0.9041931399454674 ROC AUC: 0.906638198757764\n",
      "119 31 0.06768583506345749\n",
      "Validation loss: 0.7536059723180883 ROC AUC: 0.888586956521739\n",
      "120 30 0.16277176141738892\n",
      "Validation loss: 1.2673757286632763 ROC AUC: 0.9068322981366459\n",
      "121 29 0.09455529600381851\n",
      "Validation loss: 1.0126538563008403 ROC AUC: 0.8808229813664594\n",
      "122 28 0.34968188405036926\n",
      "Validation loss: 1.2484134494089614 ROC AUC: 0.8794642857142857\n",
      "123 27 0.07378699630498886\n",
      "Validation loss: 0.7048729798373055 ROC AUC: 0.9060559006211181\n",
      "124 26 0.12373843789100647\n",
      "Validation loss: 1.0109107494354248 ROC AUC: 0.9095496894409939\n",
      "125 25 0.15060345828533173\n",
      "Validation loss: 1.26304544654547 ROC AUC: 0.8823757763975154\n",
      "126 24 0.07768472284078598\n",
      "Validation loss: 1.4306478056253171 ROC AUC: 0.8780085403726708\n",
      "127 23 0.10331413149833679\n",
      "Validation loss: 0.9776642077109393 ROC AUC: 0.921875\n",
      "128 22 0.11278852075338364\n",
      "Validation loss: 0.7065558082917157 ROC AUC: 0.8689829192546583\n",
      "129 21 0.1817391812801361\n",
      "Validation loss: 0.837493505452157 ROC AUC: 0.9188664596273292\n",
      "130 20 0.09982270747423172\n",
      "Validation loss: 1.0853546553967046 ROC AUC: 0.8994565217391305\n",
      "131 19 0.23910000920295715\n",
      "Validation loss: 1.099726494620828 ROC AUC: 0.8837344720496895\n",
      "132 18 0.09762328118085861\n",
      "Validation loss: 1.214049716790517 ROC AUC: 0.8698563664596273\n",
      "133 17 0.07803172618150711\n",
      "Validation loss: 1.0606332143732147 ROC AUC: 0.9135287267080746\n",
      "134 16 0.12132544815540314\n",
      "Validation loss: 0.7285262685196072 ROC AUC: 0.9260481366459627\n",
      "135 15 0.14795729517936707\n",
      "Validation loss: 0.9239266707981918 ROC AUC: 0.8990683229813663\n",
      "136 14 0.1363053321838379\n",
      "Validation loss: 1.0527635672513176 ROC AUC: 0.9005240683229813\n",
      "137 13 0.32670408487319946\n",
      "Validation loss: 0.8369093350335663 ROC AUC: 0.8923718944099379\n",
      "138 12 0.18419046700000763\n",
      "Validation loss: 1.376891201617671 ROC AUC: 0.8930512422360248\n",
      "139 11 0.019703207537531853\n",
      "Validation loss: 1.228507207889183 ROC AUC: 0.8844138198757765\n",
      "140 10 0.0714641809463501\n",
      "Validation loss: 1.1620516847161686 ROC AUC: 0.8806288819875777\n",
      "141 9 0.16947004199028015\n",
      "Validation loss: 0.7310667049651053 ROC AUC: 0.9195458074534162\n",
      "142 8 0.1966300755739212\n",
      "Validation loss: 1.3064427422542197 ROC AUC: 0.9203222049689441\n",
      "143 7 0.13580597937107086\n",
      "Validation loss: 1.274749241623224 ROC AUC: 0.892274844720497\n",
      "144 6 0.10316604375839233\n",
      "Validation loss: 0.8767465247827417 ROC AUC: 0.8969332298136645\n",
      "145 5 0.07926944643259048\n",
      "Validation loss: 0.8738512759115181 ROC AUC: 0.9123641304347826\n",
      "146 4 0.04798666387796402\n",
      "Validation loss: 0.7970537695230222 ROC AUC: 0.907123447204969\n",
      "147 3 0.09415573626756668\n",
      "Validation loss: 0.8024700996922511 ROC AUC: 0.8857725155279504\n",
      "148 2 0.06694202125072479\n",
      "Validation loss: 0.6836325000314152 ROC AUC: 0.9101319875776397\n",
      "149 1 0.10650743544101715\n",
      "Validation loss: 0.9439785701094889 ROC AUC: 0.9013004658385093\n",
      "150 0 0.04516135901212692\n",
      "150 50 0.05132964625954628\n",
      "Validation loss: 1.032244671793545 ROC AUC: 0.8614130434782609\n",
      "151 49 0.09825842082500458\n",
      "Validation loss: 1.0566681857202567 ROC AUC: 0.8993594720496895\n",
      "152 48 0.0881274938583374\n",
      "Validation loss: 0.6794660173210443 ROC AUC: 0.8999417701863354\n",
      "153 47 0.18047863245010376\n",
      "Validation loss: 0.8709218922783347 ROC AUC: 0.8969332298136646\n",
      "154 46 0.10581661760807037\n",
      "Validation loss: 1.0972460752133937 ROC AUC: 0.8965450310559007\n",
      "155 45 0.07490454614162445\n",
      "Validation loss: 1.1004411215875662 ROC AUC: 0.8830551242236024\n",
      "156 44 0.02864474058151245\n",
      "Validation loss: 1.3101145753673478 ROC AUC: 0.8788819875776398\n",
      "157 43 0.030711587518453598\n",
      "Validation loss: 1.1823100365844428 ROC AUC: 0.9011063664596274\n",
      "158 42 0.14990726113319397\n",
      "Validation loss: 1.0435610401864146 ROC AUC: 0.9019798136645962\n",
      "159 41 0.04406009986996651\n",
      "Validation loss: 0.599821548835904 ROC AUC: 0.936626552795031\n",
      "160 40 0.0388745442032814\n",
      "Validation loss: 1.2012508897220386 ROC AUC: 0.8850931677018633\n",
      "161 39 0.17222540080547333\n",
      "Validation loss: 1.261142553652034 ROC AUC: 0.9035326086956522\n",
      "162 38 0.1041567400097847\n",
      "Validation loss: 0.8406211336453756 ROC AUC: 0.9155667701863355\n",
      "163 37 0.04268423840403557\n",
      "Validation loss: 1.4703496624441708 ROC AUC: 0.8960597826086958\n",
      "164 36 0.10555113852024078\n",
      "Validation loss: 1.0937756416844386 ROC AUC: 0.9153726708074533\n",
      "165 35 0.19241097569465637\n",
      "Validation loss: 0.664446489775882 ROC AUC: 0.9280861801242236\n",
      "166 34 0.13028457760810852\n",
      "Validation loss: 0.8202628310696751 ROC AUC: 0.8918866459627328\n",
      "167 33 0.060785479843616486\n",
      "Validation loss: 0.5811595905060861 ROC AUC: 0.9195458074534162\n",
      "168 32 0.0427471287548542\n",
      "Validation loss: 0.750713094776752 ROC AUC: 0.921777950310559\n",
      "169 31 0.043588411062955856\n",
      "Validation loss: 0.9993218475697088 ROC AUC: 0.9026591614906831\n",
      "170 30 0.09858854860067368\n",
      "Validation loss: 0.9271021613887712 ROC AUC: 0.9145962732919255\n",
      "171 29 0.15945075452327728\n",
      "Validation loss: 0.9734526942758 ROC AUC: 0.906735248447205\n",
      "172 28 0.030398927628993988\n",
      "Validation loss: 1.160586864340539 ROC AUC: 0.9044060559006211\n",
      "173 27 0.2597200572490692\n",
      "Validation loss: 1.3163182314704447 ROC AUC: 0.9036296583850931\n",
      "174 26 0.0747118666768074\n",
      "Validation loss: 0.9559710691956913 ROC AUC: 0.92284549689441\n",
      "175 25 0.053937651216983795\n",
      "Validation loss: 1.4100898658244998 ROC AUC: 0.9015916149068323\n",
      "176 24 0.12061765044927597\n",
      "Validation loss: 1.2532660119673784 ROC AUC: 0.8980978260869565\n",
      "177 23 0.19700700044631958\n",
      "Validation loss: 0.9119713855724708 ROC AUC: 0.9034355590062112\n",
      "178 22 0.019157880917191505\n",
      "Validation loss: 1.1298855005526076 ROC AUC: 0.9039208074534162\n",
      "179 21 0.05583205819129944\n",
      "Validation loss: 1.119163945609448 ROC AUC: 0.8966420807453416\n",
      "180 20 0.037168003618717194\n",
      "Validation loss: 0.7694483356842515 ROC AUC: 0.9117818322981367\n",
      "181 19 0.032052941620349884\n",
      "Validation loss: 0.9069547065415 ROC AUC: 0.9166343167701864\n",
      "182 18 0.029053939506411552\n",
      "Validation loss: 1.3067358414010217 ROC AUC: 0.8993594720496894\n",
      "183 17 0.02930719032883644\n",
      "Validation loss: 1.6551476436502792 ROC AUC: 0.8745147515527949\n",
      "184 16 0.10024383664131165\n",
      "Validation loss: 0.9975915498593274 ROC AUC: 0.8872282608695653\n",
      "185 15 0.034620750695466995\n",
      "Validation loss: 0.7322300929649204 ROC AUC: 0.9181871118012422\n",
      "186 14 0.06618297100067139\n",
      "Validation loss: 1.081633081623152 ROC AUC: 0.9190605590062112\n",
      "187 13 0.04443147033452988\n",
      "Validation loss: 1.3247798844879748 ROC AUC: 0.8584045031055901\n",
      "188 12 0.07579512149095535\n",
      "Validation loss: 1.3815266720804513 ROC AUC: 0.8784937888198757\n",
      "189 11 0.052077025175094604\n",
      "Validation loss: 1.5021644900826847 ROC AUC: 0.8899456521739131\n",
      "190 10 0.04303410276770592\n",
      "Validation loss: 0.9048300093295527 ROC AUC: 0.9270186335403727\n",
      "191 9 0.022748302668333054\n",
      "Validation loss: 0.9666099548339844 ROC AUC: 0.9139169254658385\n",
      "192 8 0.217131108045578\n",
      "Validation loss: 1.119490992789175 ROC AUC: 0.9005240683229813\n",
      "193 7 0.021094568073749542\n",
      "Validation loss: 1.2385921151030297 ROC AUC: 0.8654891304347826\n",
      "194 6 0.04899612069129944\n",
      "Validation loss: 1.3174095995285933 ROC AUC: 0.889363354037267\n",
      "195 5 0.043196581304073334\n",
      "Validation loss: 1.1859496557245068 ROC AUC: 0.8901397515527949\n",
      "196 4 0.10676781088113785\n",
      "Validation loss: 1.205294926961263 ROC AUC: 0.8958656832298136\n",
      "197 3 0.05062142014503479\n",
      "Validation loss: 1.1150341875412886 ROC AUC: 0.9041149068322981\n",
      "198 2 0.15001116693019867\n",
      "Validation loss: 1.556683853560803 ROC AUC: 0.9109083850931676\n",
      "199 1 0.05711280554533005\n",
      "Validation loss: 1.1085557727252735 ROC AUC: 0.9173136645962732\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.2181382763619517 Test ROC AUC: 0.7085461027073899\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'bbbp', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 779, 'task': 'classification', 'data_path': 'data/bbbp/BBBP.csv', 'target': ['p_np']}}\n",
      "Running on: cuda:0\n",
      "2038\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/2038\n",
      "Generating scaffold 1000/2038\n",
      "Generating scaffold 2000/2038\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.2034428119659424\n",
      "0 50 0.4814463257789612\n",
      "Validation loss: 0.5734456760041854 ROC AUC: 0.8452057453416149\n",
      "1 49 0.2658068835735321\n",
      "Validation loss: 0.8078121671489641 ROC AUC: 0.8882958074534161\n",
      "2 48 0.41517698764801025\n",
      "Validation loss: 1.8873089341556324 ROC AUC: 0.8089091614906834\n",
      "3 47 0.30577459931373596\n",
      "Validation loss: 1.5652969982109817 ROC AUC: 0.8563664596273292\n",
      "4 46 0.3146255314350128\n",
      "Validation loss: 1.4339807173785042 ROC AUC: 0.8184200310559007\n",
      "5 45 0.18960236012935638\n",
      "Validation loss: 1.7891745263454961 ROC AUC: 0.8226902173913043\n",
      "6 44 0.5321802496910095\n",
      "Validation loss: 1.5333009023292392 ROC AUC: 0.8442352484472049\n",
      "7 43 0.29074153304100037\n",
      "Validation loss: 0.8530123467538872 ROC AUC: 0.8954774844720497\n",
      "8 42 0.263860821723938\n",
      "Validation loss: 1.5362194005180807 ROC AUC: 0.8103649068322982\n",
      "9 41 0.22469350695610046\n",
      "Validation loss: 2.0800363269506716 ROC AUC: 0.843167701863354\n",
      "10 40 0.29063695669174194\n",
      "Validation loss: 1.206363546205502 ROC AUC: 0.8508346273291926\n",
      "11 39 0.16070276498794556\n",
      "Validation loss: 1.4960769882389144 ROC AUC: 0.8524844720496895\n",
      "12 38 0.43028324842453003\n",
      "Validation loss: 1.8072885602128272 ROC AUC: 0.8640333850931677\n",
      "13 37 0.1322154998779297\n",
      "Validation loss: 0.5993190220758027 ROC AUC: 0.9304153726708074\n",
      "14 36 0.19940544664859772\n",
      "Validation loss: 0.6852167555514503 ROC AUC: 0.9185753105590062\n",
      "15 35 0.16095729172229767\n",
      "Validation loss: 1.9853774940266329 ROC AUC: 0.8753881987577639\n",
      "16 34 0.15416276454925537\n",
      "Validation loss: 2.2160382738300397 ROC AUC: 0.7424301242236024\n",
      "17 33 0.2436479777097702\n",
      "Validation loss: 1.1555004867852903 ROC AUC: 0.8980978260869564\n",
      "18 32 0.1257418990135193\n",
      "Validation loss: 1.0289729383646273 ROC AUC: 0.8535520186335404\n",
      "19 31 0.09523062407970428\n",
      "Validation loss: 1.1984667041722465 ROC AUC: 0.9003299689440993\n",
      "20 30 0.1505287140607834\n",
      "Validation loss: 1.2297474706874174 ROC AUC: 0.8665566770186335\n",
      "21 29 0.2556838393211365\n",
      "Validation loss: 0.6245202544857474 ROC AUC: 0.9111024844720497\n",
      "22 28 0.26544082164764404\n",
      "Validation loss: 1.2128577489478916 ROC AUC: 0.936820652173913\n",
      "23 27 0.13191534578800201\n",
      "Validation loss: 1.4701141282623889 ROC AUC: 0.8924689440993789\n",
      "24 26 0.26701369881629944\n",
      "Validation loss: 1.0462410870720358 ROC AUC: 0.8708268633540373\n",
      "25 25 0.2278294712305069\n",
      "Validation loss: 0.8536741266063615 ROC AUC: 0.8863548136645963\n",
      "26 24 0.375313937664032\n",
      "Validation loss: 1.0274361009691275 ROC AUC: 0.8892663043478262\n",
      "27 23 0.3346579670906067\n",
      "Validation loss: 1.381378476526223 ROC AUC: 0.8804347826086957\n",
      "28 22 0.3098929226398468\n",
      "Validation loss: 1.2697181654911416 ROC AUC: 0.8882958074534162\n",
      "29 21 0.2500079870223999\n",
      "Validation loss: 0.9340803437665397 ROC AUC: 0.9333268633540373\n",
      "30 20 0.11264944821596146\n",
      "Validation loss: 0.8352747512798683 ROC AUC: 0.9134316770186336\n",
      "31 19 0.1181110143661499\n",
      "Validation loss: 1.7559798932542987 ROC AUC: 0.8895574534161491\n",
      "32 18 0.23616445064544678\n",
      "Validation loss: 1.5330524935441858 ROC AUC: 0.8969332298136645\n",
      "33 17 0.0999099463224411\n",
      "Validation loss: 1.1822753016855203 ROC AUC: 0.8982919254658385\n",
      "34 16 0.3236698806285858\n",
      "Validation loss: 0.9278816896326402 ROC AUC: 0.8830551242236024\n",
      "35 15 0.2183617651462555\n",
      "Validation loss: 0.9075143267126644 ROC AUC: 0.9390527950310559\n",
      "36 14 0.1020015999674797\n",
      "Validation loss: 0.9718278424412596 ROC AUC: 0.8760675465838509\n",
      "37 13 0.20870453119277954\n",
      "Validation loss: 0.8979692050054962 ROC AUC: 0.9094526397515528\n",
      "38 12 0.299361914396286\n",
      "Validation loss: 1.5902226356899036 ROC AUC: 0.923427795031056\n",
      "39 11 0.25303953886032104\n",
      "Validation loss: 1.2175538247706843 ROC AUC: 0.921972049689441\n",
      "40 10 0.07414074242115021\n",
      "Validation loss: 1.2653245838249432 ROC AUC: 0.8879076086956522\n",
      "41 9 0.33431488275527954\n",
      "Validation loss: 1.77608323097229 ROC AUC: 0.8626746894409938\n",
      "42 8 0.10498876124620438\n",
      "Validation loss: 0.6864079423979217 ROC AUC: 0.8924689440993788\n",
      "43 7 0.3996489346027374\n",
      "Validation loss: 1.4123353971277965 ROC AUC: 0.8491847826086956\n",
      "44 6 0.1135208010673523\n",
      "Validation loss: 1.0946920733241474 ROC AUC: 0.8809200310559006\n",
      "45 5 0.1689997762441635\n",
      "Validation loss: 1.4575076523949118 ROC AUC: 0.8827639751552796\n",
      "46 4 0.14645101130008698\n",
      "Validation loss: 1.4101506062582427 ROC AUC: 0.9102290372670807\n",
      "47 3 0.22610580921173096\n",
      "Validation loss: 0.7347067536092272 ROC AUC: 0.9122670807453415\n",
      "48 2 0.16381937265396118\n",
      "Validation loss: 1.7372306024326998 ROC AUC: 0.890916149068323\n",
      "49 1 0.13250434398651123\n",
      "Validation loss: 1.4982613722483318 ROC AUC: 0.9208074534161491\n",
      "50 0 0.20722851157188416\n",
      "50 50 0.15221786499023438\n",
      "Validation loss: 1.783243366316253 ROC AUC: 0.9381793478260869\n",
      "51 49 0.13817183673381805\n",
      "Validation loss: 1.1514088359533572 ROC AUC: 0.936044254658385\n",
      "52 48 0.26298487186431885\n",
      "Validation loss: 1.9929496774486466 ROC AUC: 0.9108113354037266\n",
      "53 47 0.12085159122943878\n",
      "Validation loss: 1.6444157338609882 ROC AUC: 0.9192546583850931\n",
      "54 46 0.06332193315029144\n",
      "Validation loss: 1.907069958892523 ROC AUC: 0.9189635093167702\n",
      "55 45 0.23375974595546722\n",
      "Validation loss: 1.0265957736501508 ROC AUC: 0.9335209627329193\n",
      "56 44 0.2817406952381134\n",
      "Validation loss: 1.701661282894658 ROC AUC: 0.8932453416149069\n",
      "57 43 0.3003329038619995\n",
      "Validation loss: 0.756055212050092 ROC AUC: 0.9181871118012424\n",
      "58 42 0.35161155462265015\n",
      "Validation loss: 1.043062736006344 ROC AUC: 0.9049883540372671\n",
      "59 41 0.11480893939733505\n",
      "Validation loss: 1.11868712013843 ROC AUC: 0.8836374223602484\n",
      "60 40 0.3074990212917328\n",
      "Validation loss: 1.3153963836969114 ROC AUC: 0.8995535714285714\n",
      "61 39 0.253266304731369\n",
      "Validation loss: 0.9158455279527926 ROC AUC: 0.9250776397515527\n",
      "62 38 0.0603865422308445\n",
      "Validation loss: 0.9243843871004441 ROC AUC: 0.9208074534161491\n",
      "63 37 0.24275532364845276\n",
      "Validation loss: 0.9112540763967177 ROC AUC: 0.9175077639751553\n",
      "64 36 0.10890362411737442\n",
      "Validation loss: 1.293426277590733 ROC AUC: 0.905764751552795\n",
      "65 35 0.20566482841968536\n",
      "Validation loss: 0.9984196693289513 ROC AUC: 0.9286684782608695\n",
      "66 34 0.2093222290277481\n",
      "Validation loss: 1.2284691567514456 ROC AUC: 0.9312888198757764\n",
      "67 33 0.22000879049301147\n",
      "Validation loss: 1.5250772401398303 ROC AUC: 0.9029503105590063\n",
      "68 32 0.08067797869443893\n",
      "Validation loss: 1.335435604347902 ROC AUC: 0.9014945652173914\n",
      "69 31 0.1151079460978508\n",
      "Validation loss: 0.9878744050568226 ROC AUC: 0.891013198757764\n",
      "70 30 0.08432710915803909\n",
      "Validation loss: 1.9620573637532253 ROC AUC: 0.8841226708074534\n",
      "71 29 0.1984773576259613\n",
      "Validation loss: 1.219337220285453 ROC AUC: 0.8908190993788818\n",
      "72 28 0.16322612762451172\n",
      "Validation loss: 1.6389011863399954 ROC AUC: 0.9061529503105591\n",
      "73 27 0.23877540230751038\n",
      "Validation loss: 1.712058306909075 ROC AUC: 0.8962538819875776\n",
      "74 26 0.3206135928630829\n",
      "Validation loss: 1.2203146271845873 ROC AUC: 0.891013198757764\n",
      "75 25 0.23504109680652618\n",
      "Validation loss: 1.9242839228873159 ROC AUC: 0.9148874223602484\n",
      "76 24 0.1459614336490631\n",
      "Validation loss: 2.3108029926524445 ROC AUC: 0.9002329192546584\n",
      "77 23 0.1349518895149231\n",
      "Validation loss: 2.0545461084328447 ROC AUC: 0.906152950310559\n",
      "78 22 0.2121511846780777\n",
      "Validation loss: 0.5863157125080333 ROC AUC: 0.9081909937888197\n",
      "79 21 0.24515250325202942\n",
      "Validation loss: 1.0133335333244473 ROC AUC: 0.9142080745341614\n",
      "80 20 0.13062377274036407\n",
      "Validation loss: 1.4175816143260282 ROC AUC: 0.9272127329192547\n",
      "81 19 0.19128455221652985\n",
      "Validation loss: 1.5595769204345404 ROC AUC: 0.905570652173913\n",
      "82 18 0.06894601881504059\n",
      "Validation loss: 1.6883071567498 ROC AUC: 0.9078998447204969\n",
      "83 17 0.04703159257769585\n",
      "Validation loss: 1.3874198315190334 ROC AUC: 0.9152756211180124\n",
      "84 16 0.3520267605781555\n",
      "Validation loss: 2.795866610957127 ROC AUC: 0.8433618012422359\n",
      "85 15 0.26561465859413147\n",
      "Validation loss: 1.368701235190326 ROC AUC: 0.9144992236024846\n",
      "86 14 0.22293664515018463\n",
      "Validation loss: 1.326315494144664 ROC AUC: 0.8991653726708075\n",
      "87 13 0.2791801989078522\n",
      "Validation loss: 2.166651191664677 ROC AUC: 0.8964479813664596\n",
      "88 12 0.08676460385322571\n",
      "Validation loss: 1.612840404697493 ROC AUC: 0.9029503105590062\n",
      "89 11 0.12853030860424042\n",
      "Validation loss: 0.9721628221518853 ROC AUC: 0.8788819875776398\n",
      "90 10 0.195937380194664\n",
      "Validation loss: 1.2445221533085786 ROC AUC: 0.8916925465838509\n",
      "91 9 0.15176783502101898\n",
      "Validation loss: 1.820836930882697 ROC AUC: 0.9093555900621118\n",
      "92 8 0.06883139163255692\n",
      "Validation loss: 1.041256852557554 ROC AUC: 0.8980007763975156\n",
      "93 7 0.4053977429866791\n",
      "Validation loss: 1.7223504898594875 ROC AUC: 0.8800465838509317\n",
      "94 6 0.07859480381011963\n",
      "Validation loss: 1.123323456913817 ROC AUC: 0.8721855590062111\n",
      "95 5 0.16447842121124268\n",
      "Validation loss: 1.1332200625363518 ROC AUC: 0.8681094720496895\n",
      "96 4 0.1219409704208374\n",
      "Validation loss: 0.9515734957713707 ROC AUC: 0.8986801242236024\n",
      "97 3 0.09911986440420151\n",
      "Validation loss: 0.9345021166053473 ROC AUC: 0.8923718944099379\n",
      "98 2 0.09038840234279633\n",
      "Validation loss: 1.1732144878729813 ROC AUC: 0.889266304347826\n",
      "99 1 0.09738147258758545\n",
      "Validation loss: 0.9422031892280952 ROC AUC: 0.9045031055900621\n",
      "100 0 0.1569948047399521\n",
      "100 50 0.11244174838066101\n",
      "Validation loss: 1.179686331281475 ROC AUC: 0.8990683229813665\n",
      "101 49 0.05560504272580147\n",
      "Validation loss: 1.2275287871267282 ROC AUC: 0.8849961180124225\n",
      "102 48 0.04050682112574577\n",
      "Validation loss: 0.9453161823398927 ROC AUC: 0.9034355590062111\n",
      "103 47 0.2594442665576935\n",
      "Validation loss: 1.3075210837756885 ROC AUC: 0.8931482919254659\n",
      "104 46 0.07853138446807861\n",
      "Validation loss: 1.09076607577941 ROC AUC: 0.8660714285714285\n",
      "105 45 0.14518576860427856\n",
      "Validation loss: 1.1298553923181458 ROC AUC: 0.9046001552795031\n",
      "106 44 0.036697469651699066\n",
      "Validation loss: 1.689855556862027 ROC AUC: 0.8614130434782608\n",
      "107 43 0.30602943897247314\n",
      "Validation loss: 2.305404331169876 ROC AUC: 0.9144021739130436\n",
      "108 42 0.05587092787027359\n",
      "Validation loss: 1.0110165371614344 ROC AUC: 0.8947981366459626\n",
      "109 41 0.04722423851490021\n",
      "Validation loss: 1.1683582932341332 ROC AUC: 0.8819875776397514\n",
      "110 40 0.11459681391716003\n",
      "Validation loss: 1.279321972061606 ROC AUC: 0.8916925465838509\n",
      "111 39 0.0640607476234436\n",
      "Validation loss: 0.9351359746035408 ROC AUC: 0.9111024844720497\n",
      "112 38 0.08631730079650879\n",
      "Validation loss: 1.035045187847287 ROC AUC: 0.9084821428571428\n",
      "113 37 0.09636673331260681\n",
      "Validation loss: 0.8049384232829598 ROC AUC: 0.889751552795031\n",
      "114 36 0.05781955644488335\n",
      "Validation loss: 1.0149852367592793 ROC AUC: 0.857919254658385\n",
      "115 35 0.11979994177818298\n",
      "Validation loss: 1.087769859561733 ROC AUC: 0.8887810559006212\n",
      "116 34 0.05897877365350723\n",
      "Validation loss: 1.3007618761530109 ROC AUC: 0.8663625776397516\n",
      "117 33 0.048185572028160095\n",
      "Validation loss: 1.0326231273950315 ROC AUC: 0.8812111801242236\n",
      "118 32 0.19538764655590057\n",
      "Validation loss: 1.1557733661988203 ROC AUC: 0.8633540372670807\n",
      "119 31 0.3845025897026062\n",
      "Validation loss: 1.3107099930445354 ROC AUC: 0.8708268633540374\n",
      "120 30 0.13282734155654907\n",
      "Validation loss: 1.1200020698940052 ROC AUC: 0.921680900621118\n",
      "121 29 0.10579629242420197\n",
      "Validation loss: 1.410889735116678 ROC AUC: 0.8889751552795031\n",
      "122 28 0.036076273769140244\n",
      "Validation loss: 1.7107335936789418 ROC AUC: 0.8706327639751553\n",
      "123 27 0.1461152732372284\n",
      "Validation loss: 1.8335110191621034 ROC AUC: 0.9163431677018633\n",
      "124 26 0.08454199880361557\n",
      "Validation loss: 1.778201116066353 ROC AUC: 0.8794642857142857\n",
      "125 25 0.07963646948337555\n",
      "Validation loss: 1.3569079006419462 ROC AUC: 0.8964479813664596\n",
      "126 24 0.04930014908313751\n",
      "Validation loss: 1.437654362005346 ROC AUC: 0.8942158385093167\n",
      "127 23 0.03675397112965584\n",
      "Validation loss: 1.0330863536572923 ROC AUC: 0.8995535714285714\n",
      "128 22 0.09913543611764908\n",
      "Validation loss: 0.8609037890153772 ROC AUC: 0.9306094720496894\n",
      "129 21 0.06449698656797409\n",
      "Validation loss: 1.9013031463997037 ROC AUC: 0.8789790372670806\n",
      "130 20 0.22092320024967194\n",
      "Validation loss: 0.9027121601735845 ROC AUC: 0.9023680124223602\n",
      "131 19 0.03985445201396942\n",
      "Validation loss: 1.5131530633890162 ROC AUC: 0.8889751552795031\n",
      "132 18 0.07885483652353287\n",
      "Validation loss: 1.1384833303152346 ROC AUC: 0.905667701863354\n",
      "133 17 0.06481900811195374\n",
      "Validation loss: 1.0118318726034725 ROC AUC: 0.9066381987577641\n",
      "134 16 0.08854763209819794\n",
      "Validation loss: 1.7029366997417574 ROC AUC: 0.9005240683229814\n",
      "135 15 0.09191671758890152\n",
      "Validation loss: 2.0355991241978666 ROC AUC: 0.89256599378882\n",
      "136 14 0.06659325212240219\n",
      "Validation loss: 1.6603909754285626 ROC AUC: 0.8844138198757764\n",
      "137 13 0.10295770317316055\n",
      "Validation loss: 1.8538720866336542 ROC AUC: 0.903726708074534\n",
      "138 12 0.0388450063765049\n",
      "Validation loss: 2.1218702676249483 ROC AUC: 0.8930512422360248\n",
      "139 11 0.05971648916602135\n",
      "Validation loss: 1.4742126488218121 ROC AUC: 0.9101319875776398\n",
      "140 10 0.11322221904993057\n",
      "Validation loss: 1.2356936230378992 ROC AUC: 0.905085403726708\n",
      "141 9 0.08740120381116867\n",
      "Validation loss: 1.8957705918480368 ROC AUC: 0.9125582298136646\n",
      "142 8 0.06874432414770126\n",
      "Validation loss: 1.34080069380648 ROC AUC: 0.8933423913043478\n",
      "143 7 0.060180895030498505\n",
      "Validation loss: 2.0360333779278923 ROC AUC: 0.9088703416149069\n",
      "144 6 0.05381690710783005\n",
      "Validation loss: 1.684375332851036 ROC AUC: 0.8943128881987578\n",
      "145 5 0.06549657136201859\n",
      "Validation loss: 1.6584291130888695 ROC AUC: 0.9006211180124224\n",
      "146 4 0.02892952784895897\n",
      "Validation loss: 1.91360450258442 ROC AUC: 0.8657802795031055\n",
      "147 3 0.03824678063392639\n",
      "Validation loss: 1.702149759978056 ROC AUC: 0.9035326086956521\n",
      "148 2 0.0695173442363739\n",
      "Validation loss: 2.3273960562313305 ROC AUC: 0.8925659937888197\n",
      "149 1 0.10138536989688873\n",
      "Validation loss: 2.524686872959137 ROC AUC: 0.9117818322981367\n",
      "150 0 0.10787880420684814\n",
      "150 50 0.033787425607442856\n",
      "Validation loss: 1.9442617191987879 ROC AUC: 0.873641304347826\n",
      "151 49 0.013538101688027382\n",
      "Validation loss: 1.1758765215967215 ROC AUC: 0.904794254658385\n",
      "152 48 0.07121843099594116\n",
      "Validation loss: 1.6787625481100643 ROC AUC: 0.9153726708074534\n",
      "153 47 0.047773417085409164\n",
      "Validation loss: 1.514594134162454 ROC AUC: 0.922360248447205\n",
      "154 46 0.034601397812366486\n",
      "Validation loss: 2.183083001305075 ROC AUC: 0.8815023291925466\n",
      "155 45 0.08323410898447037\n",
      "Validation loss: 1.6078257841222428 ROC AUC: 0.9016886645962734\n",
      "156 44 0.10954783856868744\n",
      "Validation loss: 1.9784751452651679 ROC AUC: 0.8484083850931678\n",
      "157 43 0.07012786716222763\n",
      "Validation loss: 2.47825073260887 ROC AUC: 0.9021739130434784\n",
      "158 42 0.35007530450820923\n",
      "Validation loss: 1.5776019236620735 ROC AUC: 0.8745147515527951\n",
      "159 41 0.03774046152830124\n",
      "Validation loss: 1.4214647564233518 ROC AUC: 0.9091614906832298\n",
      "160 40 0.04048456624150276\n",
      "Validation loss: 1.4123467693890572 ROC AUC: 0.8909161490683231\n",
      "161 39 0.11444171518087387\n",
      "Validation loss: 2.468590072557038 ROC AUC: 0.8768439440993788\n",
      "162 38 0.08797678351402283\n",
      "Validation loss: 1.9441708489960314 ROC AUC: 0.8932453416149069\n",
      "163 37 0.0941607803106308\n",
      "Validation loss: 1.3463030414034922 ROC AUC: 0.905958850931677\n",
      "164 36 0.06016618385910988\n",
      "Validation loss: 1.757104004130644 ROC AUC: 0.8804347826086956\n",
      "165 35 0.03718766197562218\n",
      "Validation loss: 1.6426370529567493 ROC AUC: 0.8948951863354037\n",
      "166 34 0.0776652917265892\n",
      "Validation loss: 1.7027465105056763 ROC AUC: 0.8819875776397514\n",
      "167 33 0.04389174282550812\n",
      "Validation loss: 1.560126166717679 ROC AUC: 0.8864518633540373\n",
      "168 32 0.05496957153081894\n",
      "Validation loss: 2.1760257879892984 ROC AUC: 0.8790760869565217\n",
      "169 31 0.11506079882383347\n",
      "Validation loss: 1.4830934113147212 ROC AUC: 0.921195652173913\n",
      "170 30 0.039002612233161926\n",
      "Validation loss: 1.683939024513843 ROC AUC: 0.9099378881987576\n",
      "171 29 0.17262008786201477\n",
      "Validation loss: 1.4622132287305944 ROC AUC: 0.9176048136645962\n",
      "172 28 0.006783949211239815\n",
      "Validation loss: 1.0424320733576429 ROC AUC: 0.9176048136645963\n",
      "173 27 0.04017813131213188\n",
      "Validation loss: 2.1965343502222323 ROC AUC: 0.9087732919254659\n",
      "174 26 0.06029466167092323\n",
      "Validation loss: 2.6325710474276076 ROC AUC: 0.8813082298136646\n",
      "175 25 0.016189536079764366\n",
      "Validation loss: 2.4462715270472506 ROC AUC: 0.9085791925465838\n",
      "176 24 0.09582298994064331\n",
      "Validation loss: 1.5990970523334016 ROC AUC: 0.9011063664596273\n",
      "177 23 0.02650463581085205\n",
      "Validation loss: 1.6128933897205429 ROC AUC: 0.9175077639751552\n",
      "178 22 0.11790085583925247\n",
      "Validation loss: 2.2934076458800075 ROC AUC: 0.8730590062111802\n",
      "179 21 0.0392548143863678\n",
      "Validation loss: 1.4724234190641665 ROC AUC: 0.9322593167701863\n",
      "180 20 0.09760923683643341\n",
      "Validation loss: 1.3686928211473952 ROC AUC: 0.906152950310559\n",
      "181 19 0.1371258944272995\n",
      "Validation loss: 1.804226134337631 ROC AUC: 0.8996506211180124\n",
      "182 18 0.12140321731567383\n",
      "Validation loss: 2.2001215383118273 ROC AUC: 0.8944099378881988\n",
      "183 17 0.01937941089272499\n",
      "Validation loss: 2.283650286057416 ROC AUC: 0.8578222049689441\n",
      "184 16 0.09205697476863861\n",
      "Validation loss: 1.3494040495624728 ROC AUC: 0.9158579192546584\n",
      "185 15 0.0641772598028183\n",
      "Validation loss: 1.4796244408570083 ROC AUC: 0.907123447204969\n",
      "186 14 0.04577808082103729\n",
      "Validation loss: 1.8470544394324808 ROC AUC: 0.9185753105590062\n",
      "187 13 0.17236453294754028\n",
      "Validation loss: 1.9823313857994826 ROC AUC: 0.8929541925465839\n",
      "188 12 0.10833154618740082\n",
      "Validation loss: 1.773001979379093 ROC AUC: 0.9105201863354038\n",
      "189 11 0.14065326750278473\n",
      "Validation loss: 2.140077590942383 ROC AUC: 0.8935364906832298\n",
      "190 10 0.06357221305370331\n",
      "Validation loss: 2.229145798028684 ROC AUC: 0.9015916149068323\n",
      "191 9 0.049922533333301544\n",
      "Validation loss: 2.3200622680140475 ROC AUC: 0.8859666149068323\n",
      "192 8 0.027310246601700783\n",
      "Validation loss: 2.1705205844094357 ROC AUC: 0.906541149068323\n",
      "193 7 0.12374294549226761\n",
      "Validation loss: 1.7693839278619956 ROC AUC: 0.906832298136646\n",
      "194 6 0.0660078376531601\n",
      "Validation loss: 1.8783818711252773 ROC AUC: 0.8709239130434782\n",
      "195 5 0.049077775329351425\n",
      "Validation loss: 1.2692019553745495 ROC AUC: 0.8983889751552796\n",
      "196 4 0.019407209008932114\n",
      "Validation loss: 2.2863757516823564 ROC AUC: 0.9031444099378881\n",
      "197 3 0.15325739979743958\n",
      "Validation loss: 1.59602530907803 ROC AUC: 0.8838315217391304\n",
      "198 2 0.06378279626369476\n",
      "Validation loss: 3.18717903249404 ROC AUC: 0.8374417701863354\n",
      "199 1 0.06867073476314545\n",
      "Validation loss: 1.9367178655138202 ROC AUC: 0.8742236024844721\n",
      "Loaded trained model with success.\n",
      "Test loss: 2.4923925446529016 Test ROC AUC: 0.7088351478947876\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'bbbp', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 780, 'task': 'classification', 'data_path': 'data/bbbp/BBBP.csv', 'target': ['p_np']}}\n",
      "Running on: cuda:0\n",
      "2038\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/2038\n",
      "Generating scaffold 1000/2038\n",
      "Generating scaffold 2000/2038\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.3193657398223877\n",
      "0 50 0.3452173173427582\n",
      "Validation loss: 0.7579951613557105 ROC AUC: 0.813373447204969\n",
      "1 49 0.1988932490348816\n",
      "Validation loss: 0.7974257749669692 ROC AUC: 0.873156055900621\n",
      "2 48 0.4607250690460205\n",
      "Validation loss: 1.2756675645416857 ROC AUC: 0.8610248447204969\n",
      "3 47 0.2522236108779907\n",
      "Validation loss: 0.7558954924929375 ROC AUC: 0.9159549689440993\n",
      "4 46 0.3895376920700073\n",
      "Validation loss: 1.1265127466005438 ROC AUC: 0.8842197204968943\n",
      "5 45 0.29220643639564514\n",
      "Validation loss: 1.1303529172551399 ROC AUC: 0.8622864906832297\n",
      "6 44 0.1265459507703781\n",
      "Validation loss: 0.8687383348450941 ROC AUC: 0.9233307453416149\n",
      "7 43 0.2890126705169678\n",
      "Validation loss: 1.285959541797638 ROC AUC: 0.8664596273291926\n",
      "8 42 0.19127558171749115\n",
      "Validation loss: 1.2327819384780585 ROC AUC: 0.8812111801242236\n",
      "9 41 0.35744327306747437\n",
      "Validation loss: 0.8335720137053845 ROC AUC: 0.9082880434782609\n",
      "10 40 0.3808440566062927\n",
      "Validation loss: 1.0003912519006168 ROC AUC: 0.8820846273291926\n",
      "11 39 0.22547174990177155\n",
      "Validation loss: 1.0035166763791852 ROC AUC: 0.9161490683229814\n",
      "12 38 0.17443516850471497\n",
      "Validation loss: 0.7414435744285583 ROC AUC: 0.9113936335403725\n",
      "13 37 0.274924099445343\n",
      "Validation loss: 0.5164125585088543 ROC AUC: 0.9248835403726706\n",
      "14 36 0.33913740515708923\n",
      "Validation loss: 0.4061965022016974 ROC AUC: 0.9006211180124224\n",
      "15 35 0.14255523681640625\n",
      "Validation loss: 0.9911631906733793 ROC AUC: 0.872961956521739\n",
      "16 34 0.15704825520515442\n",
      "Validation loss: 1.1459058640049953 ROC AUC: 0.9022709627329191\n",
      "17 33 0.3951130509376526\n",
      "Validation loss: 0.7809339469554377 ROC AUC: 0.8961568322981366\n",
      "18 32 0.3168066442012787\n",
      "Validation loss: 0.736378552866917 ROC AUC: 0.9033385093167702\n",
      "19 31 0.2993607521057129\n",
      "Validation loss: 1.0934548635108798 ROC AUC: 0.8365683229813664\n",
      "20 30 0.09827021509408951\n",
      "Validation loss: 0.5143257169162526 ROC AUC: 0.8876164596273292\n",
      "21 29 0.198140487074852\n",
      "Validation loss: 1.289119120906381 ROC AUC: 0.8410326086956522\n",
      "22 28 0.48828625679016113\n",
      "Validation loss: 1.1389735352759267 ROC AUC: 0.8790760869565217\n",
      "23 27 0.18195945024490356\n",
      "Validation loss: 0.9431751101624732 ROC AUC: 0.8713121118012422\n",
      "24 26 0.1208651065826416\n",
      "Validation loss: 0.8810948974945966 ROC AUC: 0.8753881987577639\n",
      "25 25 0.1734037846326828\n",
      "Validation loss: 1.09255256839827 ROC AUC: 0.906444099378882\n",
      "26 24 0.25306686758995056\n",
      "Validation loss: 0.6884549900012857 ROC AUC: 0.90430900621118\n",
      "27 23 0.157616525888443\n",
      "Validation loss: 0.9140184813854741 ROC AUC: 0.9078998447204969\n",
      "28 22 0.27312326431274414\n",
      "Validation loss: 0.5285987912439832 ROC AUC: 0.9322593167701864\n",
      "29 21 0.4253592789173126\n",
      "Validation loss: 0.6443827012005974 ROC AUC: 0.9165372670807453\n",
      "30 20 0.22944700717926025\n",
      "Validation loss: 0.5002555550605643 ROC AUC: 0.8869371118012422\n",
      "31 19 0.3259497582912445\n",
      "Validation loss: 1.2245758561527027 ROC AUC: 0.9014945652173912\n",
      "32 18 0.16792692244052887\n",
      "Validation loss: 0.8361753155203426 ROC AUC: 0.9248835403726708\n",
      "33 17 0.29405292868614197\n",
      "Validation loss: 0.8220533483168658 ROC AUC: 0.9203222049689441\n",
      "34 16 0.08254796266555786\n",
      "Validation loss: 0.6945218321155099 ROC AUC: 0.9080939440993789\n",
      "35 15 0.21095505356788635\n",
      "Validation loss: 0.8570260350026336 ROC AUC: 0.921486801242236\n",
      "36 14 0.08369443565607071\n",
      "Validation loss: 1.5664540272133023 ROC AUC: 0.8806288819875777\n",
      "37 13 0.10333336889743805\n",
      "Validation loss: 0.6603626386792052 ROC AUC: 0.8865489130434783\n",
      "38 12 0.33815833926200867\n",
      "Validation loss: 1.3863559143216002 ROC AUC: 0.8493788819875776\n",
      "39 11 0.24785318970680237\n",
      "Validation loss: 0.9157698890742134 ROC AUC: 0.889848602484472\n",
      "40 10 0.23524172604084015\n",
      "Validation loss: 0.8171849952024572 ROC AUC: 0.9263392857142858\n",
      "41 9 0.17609204351902008\n",
      "Validation loss: 0.9082841709548352 ROC AUC: 0.9375\n",
      "42 8 0.330820232629776\n",
      "Validation loss: 0.7742879349811405 ROC AUC: 0.8961568322981367\n",
      "43 7 0.19192247092723846\n",
      "Validation loss: 1.6067312114378984 ROC AUC: 0.9088703416149069\n",
      "44 6 0.08853685110807419\n",
      "Validation loss: 0.9731197275367438 ROC AUC: 0.9026591614906833\n",
      "45 5 0.14230862259864807\n",
      "Validation loss: 1.1211628750258802 ROC AUC: 0.907317546583851\n",
      "46 4 0.11645926535129547\n",
      "Validation loss: 2.2654602013382257 ROC AUC: 0.859860248447205\n",
      "47 3 0.2716897428035736\n",
      "Validation loss: 1.2210648246839935 ROC AUC: 0.9294448757763976\n",
      "48 2 0.23516108095645905\n",
      "Validation loss: 0.8382590015729269 ROC AUC: 0.921292701863354\n",
      "49 1 0.07276038080453873\n",
      "Validation loss: 0.9727534266079173 ROC AUC: 0.921389751552795\n",
      "50 0 0.06974901258945465\n",
      "50 50 0.057472966611385345\n",
      "Validation loss: 0.6734712567983889 ROC AUC: 0.90722049689441\n",
      "51 49 0.15022672712802887\n",
      "Validation loss: 0.739148032431509 ROC AUC: 0.8559782608695653\n",
      "52 48 0.09400832653045654\n",
      "Validation loss: 1.1011519210011351 ROC AUC: 0.8545225155279504\n",
      "53 47 0.1488078087568283\n",
      "Validation loss: 1.090926542001612 ROC AUC: 0.8849961180124223\n",
      "54 46 0.1513630896806717\n",
      "Validation loss: 0.9425458814583573 ROC AUC: 0.8738354037267081\n",
      "55 45 0.3997877538204193\n",
      "Validation loss: 1.2510684787058364 ROC AUC: 0.9142080745341615\n",
      "56 44 0.059820983558893204\n",
      "Validation loss: 0.9205403503249673 ROC AUC: 0.8728649068322981\n",
      "57 43 0.1358630657196045\n",
      "Validation loss: 1.131686790901072 ROC AUC: 0.891983695652174\n",
      "58 42 0.048033617436885834\n",
      "Validation loss: 0.7378425691642013 ROC AUC: 0.9071234472049688\n",
      "59 41 0.1462610810995102\n",
      "Validation loss: 1.0270722286373961 ROC AUC: 0.8713121118012421\n",
      "60 40 0.14590346813201904\n",
      "Validation loss: 0.5532223138154722 ROC AUC: 0.9286684782608696\n",
      "61 39 0.06751511991024017\n",
      "Validation loss: 0.7064561691938662 ROC AUC: 0.9160520186335404\n",
      "62 38 0.08274983614683151\n",
      "Validation loss: 0.8336350660698086 ROC AUC: 0.9171195652173914\n",
      "63 37 0.2631596326828003\n",
      "Validation loss: 1.3304736941468482 ROC AUC: 0.8957686335403727\n",
      "64 36 0.14859336614608765\n",
      "Validation loss: 1.4560881245370005 ROC AUC: 0.8515139751552795\n",
      "65 35 0.3455967605113983\n",
      "Validation loss: 0.9137926826290056 ROC AUC: 0.9241071428571428\n",
      "66 34 0.07413354516029358\n",
      "Validation loss: 1.1359604433471082 ROC AUC: 0.9139169254658386\n",
      "67 33 0.10965698212385178\n",
      "Validation loss: 0.7095293916907965 ROC AUC: 0.9267274844720497\n",
      "68 32 0.12802958488464355\n",
      "Validation loss: 1.6844677130381267 ROC AUC: 0.8711180124223602\n",
      "69 31 0.18791116774082184\n",
      "Validation loss: 0.7183142316107657 ROC AUC: 0.9262422360248448\n",
      "70 30 0.26295655965805054\n",
      "Validation loss: 1.1051343983294917 ROC AUC: 0.9226513975155279\n",
      "71 29 0.23621447384357452\n",
      "Validation loss: 1.2321391397831487 ROC AUC: 0.9177018633540373\n",
      "72 28 0.09339471906423569\n",
      "Validation loss: 0.9705689444261438 ROC AUC: 0.9259510869565217\n",
      "73 27 0.08995906263589859\n",
      "Validation loss: 0.8639196595724892 ROC AUC: 0.9275038819875776\n",
      "74 26 0.23342713713645935\n",
      "Validation loss: 1.0472994622062235 ROC AUC: 0.8929541925465838\n",
      "75 25 0.08548729866743088\n",
      "Validation loss: 1.1257536154167325 ROC AUC: 0.9046972049689441\n",
      "76 24 0.20365288853645325\n",
      "Validation loss: 0.7844594717025757 ROC AUC: 0.908676242236025\n",
      "77 23 0.34620532393455505\n",
      "Validation loss: 0.8451060208619809 ROC AUC: 0.8980978260869565\n",
      "78 22 0.15920564532279968\n",
      "Validation loss: 0.7102772009138968 ROC AUC: 0.9012034161490683\n",
      "79 21 0.03812222182750702\n",
      "Validation loss: 1.8975752755707385 ROC AUC: 0.9078027950310559\n",
      "80 20 0.1647147685289383\n",
      "Validation loss: 1.0873726197317535 ROC AUC: 0.9311917701863355\n",
      "81 19 0.10307680070400238\n",
      "Validation loss: 1.170020671451793 ROC AUC: 0.8922748447204969\n",
      "82 18 0.19390955567359924\n",
      "Validation loss: 0.6817870508222019 ROC AUC: 0.9139169254658385\n",
      "83 17 0.1077055111527443\n",
      "Validation loss: 0.6986306379823124 ROC AUC: 0.905764751552795\n",
      "84 16 0.09756971895694733\n",
      "Validation loss: 0.982200870326921 ROC AUC: 0.9257569875776397\n",
      "85 15 0.1352035254240036\n",
      "Validation loss: 1.0194114832317127 ROC AUC: 0.8972243788819876\n",
      "86 14 0.06765587627887726\n",
      "Validation loss: 1.3196149421673196 ROC AUC: 0.9135287267080744\n",
      "87 13 0.10632199048995972\n",
      "Validation loss: 0.8487727758931178 ROC AUC: 0.9119759316770186\n",
      "88 12 0.0769578367471695\n",
      "Validation loss: 1.4383746221953748 ROC AUC: 0.888392857142857\n",
      "89 11 0.19732923805713654\n",
      "Validation loss: 0.6828524517443251 ROC AUC: 0.9171195652173914\n",
      "90 10 0.17186126112937927\n",
      "Validation loss: 0.9474906068222195 ROC AUC: 0.9169254658385093\n",
      "91 9 0.17954063415527344\n",
      "Validation loss: 1.1089673696779738 ROC AUC: 0.9191576086956521\n",
      "92 8 0.1381720006465912\n",
      "Validation loss: 0.5663836449384689 ROC AUC: 0.9303183229813664\n",
      "93 7 0.06109991669654846\n",
      "Validation loss: 1.5680991317711623 ROC AUC: 0.9052795031055901\n",
      "94 6 0.2811122536659241\n",
      "Validation loss: 1.0622924101703308 ROC AUC: 0.8973214285714285\n",
      "95 5 0.17743459343910217\n",
      "Validation loss: 1.365352638796264 ROC AUC: 0.890819099378882\n",
      "96 4 0.07601489126682281\n",
      "Validation loss: 1.1782159780462582 ROC AUC: 0.9115877329192547\n",
      "97 3 0.061649490147829056\n",
      "Validation loss: 1.0191083505165344 ROC AUC: 0.9002329192546584\n",
      "98 2 0.09660223126411438\n",
      "Validation loss: 0.7440273748601184 ROC AUC: 0.9274068322981366\n",
      "99 1 0.13997438549995422\n",
      "Validation loss: 0.8047892766840318 ROC AUC: 0.9337150621118012\n",
      "100 0 0.0844247043132782\n",
      "100 50 0.12279489636421204\n",
      "Validation loss: 1.0478097457511752 ROC AUC: 0.9113936335403726\n",
      "101 49 0.12452486157417297\n",
      "Validation loss: 0.9986578138435588 ROC AUC: 0.9273097826086956\n",
      "102 48 0.1438259780406952\n",
      "Validation loss: 1.580207000176112 ROC AUC: 0.9194487577639752\n",
      "103 47 0.04948434978723526\n",
      "Validation loss: 2.034248443210826 ROC AUC: 0.889266304347826\n",
      "104 46 0.10083416849374771\n",
      "Validation loss: 1.824219769122554 ROC AUC: 0.8952833850931677\n",
      "105 45 0.15155044198036194\n",
      "Validation loss: 1.2806838376849305 ROC AUC: 0.90625\n",
      "106 44 0.09965874254703522\n",
      "Validation loss: 1.2486194638060588 ROC AUC: 0.8887810559006211\n",
      "107 43 0.1400727927684784\n",
      "Validation loss: 0.8714667365831488 ROC AUC: 0.9222631987577639\n",
      "108 42 0.12559698522090912\n",
      "Validation loss: 1.9159444266674566 ROC AUC: 0.9153726708074534\n",
      "109 41 0.10148866474628448\n",
      "Validation loss: 1.9871317896188474 ROC AUC: 0.9049883540372671\n",
      "110 40 0.06035031005740166\n",
      "Validation loss: 1.15399267393 ROC AUC: 0.9141110248447204\n",
      "111 39 0.09075044840574265\n",
      "Validation loss: 1.2047756933698468 ROC AUC: 0.9110054347826086\n",
      "112 38 0.030755750834941864\n",
      "Validation loss: 1.2706528995551316 ROC AUC: 0.905861801242236\n",
      "113 37 0.1608990877866745\n",
      "Validation loss: 0.6859618124926427 ROC AUC: 0.9467197204968943\n",
      "114 36 0.0953037217259407\n",
      "Validation loss: 1.043547366179672 ROC AUC: 0.9167313664596274\n",
      "115 35 0.4223533868789673\n",
      "Validation loss: 1.0985302095319711 ROC AUC: 0.9136257763975155\n",
      "116 34 0.09862516075372696\n",
      "Validation loss: 1.157552251628801 ROC AUC: 0.8713121118012422\n",
      "117 33 0.13573935627937317\n",
      "Validation loss: 1.45088543845158 ROC AUC: 0.8838315217391305\n",
      "118 32 0.17497451603412628\n",
      "Validation loss: 1.6467224943871592 ROC AUC: 0.9298330745341614\n",
      "119 31 0.31702423095703125\n",
      "Validation loss: 1.0331996515685438 ROC AUC: 0.9345885093167702\n",
      "120 30 0.08619300276041031\n",
      "Validation loss: 1.284115003604515 ROC AUC: 0.9404114906832298\n",
      "121 29 0.06916159391403198\n",
      "Validation loss: 0.8896119019345325 ROC AUC: 0.9390527950310559\n",
      "122 28 0.07561500370502472\n",
      "Validation loss: 0.9564939154878113 ROC AUC: 0.9297360248447205\n",
      "123 27 0.1606123447418213\n",
      "Validation loss: 1.2135977745056152 ROC AUC: 0.9178959627329193\n",
      "124 26 0.20810796320438385\n",
      "Validation loss: 1.4342864027210311 ROC AUC: 0.9020768633540374\n",
      "125 25 0.1188848540186882\n",
      "Validation loss: 1.2215580706502878 ROC AUC: 0.9255628881987578\n",
      "126 24 0.09864631295204163\n",
      "Validation loss: 0.9510869953562232 ROC AUC: 0.9266304347826088\n",
      "127 23 0.02899998240172863\n",
      "Validation loss: 1.0794274980184055 ROC AUC: 0.9033385093167702\n",
      "128 22 0.16040094196796417\n",
      "Validation loss: 1.4617616756289613 ROC AUC: 0.90625\n",
      "129 21 0.2547377347946167\n",
      "Validation loss: 1.695452430668999 ROC AUC: 0.8981948757763976\n",
      "130 20 0.10810806602239609\n",
      "Validation loss: 0.9653626236261106 ROC AUC: 0.8879076086956522\n",
      "131 19 0.23956769704818726\n",
      "Validation loss: 1.5293800012738097 ROC AUC: 0.8837344720496894\n",
      "132 18 0.07968293130397797\n",
      "Validation loss: 1.3205611986272476 ROC AUC: 0.9049883540372671\n",
      "133 17 0.12812834978103638\n",
      "Validation loss: 1.5163566411710252 ROC AUC: 0.904988354037267\n",
      "134 16 0.2196834236383438\n",
      "Validation loss: 1.417236891447329 ROC AUC: 0.9166343167701864\n",
      "135 15 0.04877222329378128\n",
      "Validation loss: 2.053990683755746 ROC AUC: 0.9007181677018633\n",
      "136 14 0.1465531438589096\n",
      "Validation loss: 2.150268379379721 ROC AUC: 0.8886840062111802\n",
      "137 13 0.22623984515666962\n",
      "Validation loss: 1.9517352908265357 ROC AUC: 0.8938276397515528\n",
      "138 12 0.33224841952323914\n",
      "Validation loss: 1.4511579672495525 ROC AUC: 0.9267274844720497\n",
      "139 11 0.08736386895179749\n",
      "Validation loss: 1.069991686180526 ROC AUC: 0.9028532608695652\n",
      "140 10 0.09739738702774048\n",
      "Validation loss: 1.3584633154027603 ROC AUC: 0.921777950310559\n",
      "141 9 0.016551252454519272\n",
      "Validation loss: 1.3671974200828403 ROC AUC: 0.9186723602484472\n",
      "142 8 0.01414342038333416\n",
      "Validation loss: 1.900697810977113 ROC AUC: 0.906929347826087\n",
      "143 7 0.09047046303749084\n",
      "Validation loss: 1.6138067572724586 ROC AUC: 0.9176048136645963\n",
      "144 6 0.1453821063041687\n",
      "Validation loss: 1.057358141038932 ROC AUC: 0.9474961180124224\n",
      "145 5 0.1247589960694313\n",
      "Validation loss: 0.6904498198453117 ROC AUC: 0.9168284161490683\n",
      "146 4 0.1872102916240692\n",
      "Validation loss: 0.5722391488505345 ROC AUC: 0.9425465838509317\n",
      "147 3 0.08119556307792664\n",
      "Validation loss: 1.0758633146099015 ROC AUC: 0.9317740683229815\n",
      "148 2 0.13808974623680115\n",
      "Validation loss: 1.3576463817381392 ROC AUC: 0.9010093167701863\n",
      "149 1 0.049425672739744186\n",
      "Validation loss: 1.5677177719041413 ROC AUC: 0.9282802795031055\n",
      "150 0 0.0792800784111023\n",
      "150 50 0.27080902457237244\n",
      "Validation loss: 1.1190583331912172 ROC AUC: 0.937888198757764\n",
      "151 49 0.1016521081328392\n",
      "Validation loss: 1.356152670056212 ROC AUC: 0.9324534161490684\n",
      "152 48 0.059208326041698456\n",
      "Validation loss: 0.9124888228435143 ROC AUC: 0.9375\n",
      "153 47 0.08512388169765472\n",
      "Validation loss: 1.0065492080414997 ROC AUC: 0.9156638198757764\n",
      "154 46 0.1518591344356537\n",
      "Validation loss: 1.3880759874979656 ROC AUC: 0.9422554347826086\n",
      "155 45 0.09998787194490433\n",
      "Validation loss: 1.0169205998673159 ROC AUC: 0.937014751552795\n",
      "156 44 0.13256289064884186\n",
      "Validation loss: 1.29904413690754 ROC AUC: 0.9283773291925466\n",
      "157 43 0.0948341116309166\n",
      "Validation loss: 1.6169425342597215 ROC AUC: 0.9236218944099379\n",
      "158 42 0.09702739864587784\n",
      "Validation loss: 0.7992103063300544 ROC AUC: 0.9545807453416149\n",
      "159 41 0.0895618423819542\n",
      "Validation loss: 0.9566894196996502 ROC AUC: 0.9420613354037266\n",
      "160 40 0.02663770690560341\n",
      "Validation loss: 1.6909432419959236 ROC AUC: 0.9009122670807455\n",
      "161 39 0.037553999572992325\n",
      "Validation loss: 1.030756204735999 ROC AUC: 0.9411878881987578\n",
      "162 38 0.051912374794483185\n",
      "Validation loss: 1.6380402480854708 ROC AUC: 0.937888198757764\n",
      "163 37 0.18526752293109894\n",
      "Validation loss: 1.3955336277391397 ROC AUC: 0.9114906832298136\n",
      "164 36 0.048783283680677414\n",
      "Validation loss: 1.5045615861228867 ROC AUC: 0.8898486024844721\n",
      "165 35 0.06051964685320854\n",
      "Validation loss: 1.4963251410746108 ROC AUC: 0.9447787267080745\n",
      "166 34 0.05142915993928909\n",
      "Validation loss: 1.5232404400320614 ROC AUC: 0.9210986024844721\n",
      "167 33 0.016489632427692413\n",
      "Validation loss: 1.4647009138967477 ROC AUC: 0.9201281055900621\n",
      "168 32 0.14060935378074646\n",
      "Validation loss: 1.436259952245974 ROC AUC: 0.9441964285714286\n",
      "169 31 0.027736075222492218\n",
      "Validation loss: 1.3483683992834652 ROC AUC: 0.9319681677018633\n",
      "170 30 0.12246626615524292\n",
      "Validation loss: 1.5912633679616583 ROC AUC: 0.9280861801242236\n",
      "171 29 0.1285085529088974\n",
      "Validation loss: 1.914031247882282 ROC AUC: 0.9298330745341615\n",
      "172 28 0.05433623120188713\n",
      "Validation loss: 1.6489742795626323 ROC AUC: 0.9141110248447204\n",
      "173 27 0.09499993175268173\n",
      "Validation loss: 1.7989188479442222 ROC AUC: 0.9211956521739131\n",
      "174 26 0.017246615141630173\n",
      "Validation loss: 1.1015868327196907 ROC AUC: 0.9439052795031055\n",
      "175 25 0.10653334110975266\n",
      "Validation loss: 1.6571580954626495 ROC AUC: 0.921680900621118\n",
      "176 24 0.06249629333615303\n",
      "Validation loss: 1.2847665127585917 ROC AUC: 0.9357531055900621\n",
      "177 23 0.10399280488491058\n",
      "Validation loss: 2.6051052014033 ROC AUC: 0.8983889751552795\n",
      "178 22 0.07068727165460587\n",
      "Validation loss: 1.2156036951962639 ROC AUC: 0.9442934782608696\n",
      "179 21 0.02432265877723694\n",
      "Validation loss: 1.2099323728505302 ROC AUC: 0.9331327639751553\n",
      "180 20 0.13684013485908508\n",
      "Validation loss: 1.8583818416969449 ROC AUC: 0.9285714285714286\n",
      "181 19 0.09260394424200058\n",
      "Validation loss: 1.4794835974188412 ROC AUC: 0.9342973602484471\n",
      "182 18 0.019500086084008217\n",
      "Validation loss: 1.93690414054721 ROC AUC: 0.9322593167701864\n",
      "183 17 0.12042165547609329\n",
      "Validation loss: 1.2717821716385729 ROC AUC: 0.9416731366459627\n",
      "184 16 0.3310592472553253\n",
      "Validation loss: 1.7593083492681092 ROC AUC: 0.9372088509316769\n",
      "185 15 0.15376773476600647\n",
      "Validation loss: 0.9894038532294479 ROC AUC: 0.9246894409937888\n",
      "186 14 0.09224645048379898\n",
      "Validation loss: 1.109084073235007 ROC AUC: 0.9343944099378882\n",
      "187 13 0.1689467579126358\n",
      "Validation loss: 1.2513107233772092 ROC AUC: 0.9201281055900621\n",
      "188 12 0.07924508303403854\n",
      "Validation loss: 1.280766930532135 ROC AUC: 0.9568128881987578\n",
      "189 11 0.034417398273944855\n",
      "Validation loss: 1.5464257679733575 ROC AUC: 0.9158579192546584\n",
      "190 10 0.099373459815979\n",
      "Validation loss: 1.3461033550967627 ROC AUC: 0.9310947204968943\n",
      "191 9 0.09278261661529541\n",
      "Validation loss: 1.0607381953912622 ROC AUC: 0.9310947204968943\n",
      "192 8 0.06738407909870148\n",
      "Validation loss: 0.836670089074794 ROC AUC: 0.9291537267080745\n",
      "193 7 0.043413128703832626\n",
      "Validation loss: 1.2271966641978818 ROC AUC: 0.9307065217391304\n",
      "194 6 0.1459442526102066\n",
      "Validation loss: 1.123153345257628 ROC AUC: 0.9362383540372671\n",
      "195 5 0.1270442008972168\n",
      "Validation loss: 1.2698918919937283 ROC AUC: 0.9295419254658385\n",
      "196 4 0.05512718856334686\n",
      "Validation loss: 1.0750439494263893 ROC AUC: 0.9440023291925466\n",
      "197 3 0.09167574346065521\n",
      "Validation loss: 0.7387718733619241 ROC AUC: 0.9418672360248448\n",
      "198 2 0.03809434175491333\n",
      "Validation loss: 0.912240694240466 ROC AUC: 0.9389557453416149\n",
      "199 1 0.06849417090415955\n",
      "Validation loss: 1.1415824609644272 ROC AUC: 0.9356560559006211\n",
      "Loaded trained model with success.\n",
      "Test loss: 4.711065918791528 Test ROC AUC: 0.706330089604008\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'bbbp', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 781, 'task': 'classification', 'data_path': 'data/bbbp/BBBP.csv', 'target': ['p_np']}}\n",
      "Running on: cuda:0\n",
      "2038\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/2038\n",
      "Generating scaffold 1000/2038\n",
      "Generating scaffold 2000/2038\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 1.394050121307373\n",
      "0 50 0.43464767932891846\n",
      "Validation loss: 1.075636696581747 ROC AUC: 0.8648097826086956\n",
      "1 49 0.33646783232688904\n",
      "Validation loss: 0.7570047372696447 ROC AUC: 0.9051824534161491\n",
      "2 48 0.5099356770515442\n",
      "Validation loss: 0.7408964213202981 ROC AUC: 0.9019798136645962\n",
      "3 47 0.2168015092611313\n",
      "Validation loss: 0.919876451585807 ROC AUC: 0.8321040372670807\n",
      "4 46 0.6601449251174927\n",
      "Validation loss: 0.38835303573047414 ROC AUC: 0.9211956521739131\n",
      "5 45 0.3215392231941223\n",
      "Validation loss: 0.6294123939439362 ROC AUC: 0.9245923913043478\n",
      "6 44 0.23849833011627197\n",
      "Validation loss: 0.6455265686792486 ROC AUC: 0.904211956521739\n",
      "7 43 0.5865505933761597\n",
      "Validation loss: 0.5478238895827648 ROC AUC: 0.905958850931677\n",
      "8 42 0.4355776309967041\n",
      "Validation loss: 0.600755584006216 ROC AUC: 0.9099378881987576\n",
      "9 41 0.20757801830768585\n",
      "Validation loss: 0.5089949676949604 ROC AUC: 0.9243012422360248\n",
      "10 40 0.4609709084033966\n",
      "Validation loss: 0.5360990353659087 ROC AUC: 0.8937305900621119\n",
      "11 39 0.17560605704784393\n",
      "Validation loss: 0.7247598334854725 ROC AUC: 0.889848602484472\n",
      "12 38 0.29935330152511597\n",
      "Validation loss: 0.7095242890657163 ROC AUC: 0.8723796583850931\n",
      "13 37 0.14766548573970795\n",
      "Validation loss: 0.7609474705714806 ROC AUC: 0.8639363354037267\n",
      "14 36 0.18754881620407104\n",
      "Validation loss: 0.4908221457518783 ROC AUC: 0.9077057453416147\n",
      "15 35 0.4150889813899994\n",
      "Validation loss: 0.5422194226115358 ROC AUC: 0.9024650621118011\n",
      "16 34 0.28133508563041687\n",
      "Validation loss: 0.4106457324004641 ROC AUC: 0.9202251552795031\n",
      "17 33 0.2267334908246994\n",
      "Validation loss: 0.6319471410676545 ROC AUC: 0.891692546583851\n",
      "18 32 0.284106582403183\n",
      "Validation loss: 0.45617931029375863 ROC AUC: 0.9157608695652174\n",
      "19 31 0.20575129985809326\n",
      "Validation loss: 0.3594643762883018 ROC AUC: 0.9266304347826086\n",
      "20 30 0.18123884499073029\n",
      "Validation loss: 0.48869190730300605 ROC AUC: 0.9246894409937889\n",
      "21 29 0.10420122742652893\n",
      "Validation loss: 0.7081127353743011 ROC AUC: 0.907802795031056\n",
      "22 28 0.2644510269165039\n",
      "Validation loss: 0.5320879308616414 ROC AUC: 0.9136257763975155\n",
      "23 27 0.16662085056304932\n",
      "Validation loss: 0.5000347121089113 ROC AUC: 0.9450698757763976\n",
      "24 26 0.31897276639938354\n",
      "Validation loss: 0.5020632675173236 ROC AUC: 0.921195652173913\n",
      "25 25 0.19176776707172394\n",
      "Validation loss: 0.47039656428729787 ROC AUC: 0.9121700310559007\n",
      "26 24 0.574317216873169\n",
      "Validation loss: 0.3672213414136101 ROC AUC: 0.938373447204969\n",
      "27 23 0.4088607728481293\n",
      "Validation loss: 0.511728969859142 ROC AUC: 0.9163431677018633\n",
      "28 22 0.38922587037086487\n",
      "Validation loss: 0.8163323098537969 ROC AUC: 0.9057647515527951\n",
      "29 21 0.27864545583724976\n",
      "Validation loss: 0.5849499982946059 ROC AUC: 0.9332298136645962\n",
      "30 20 0.2638046443462372\n",
      "Validation loss: 0.6202696965021246 ROC AUC: 0.906638198757764\n",
      "31 19 0.27568233013153076\n",
      "Validation loss: 0.5742992992494621 ROC AUC: 0.9005240683229814\n",
      "32 18 0.27244770526885986\n",
      "Validation loss: 0.3259502529513602 ROC AUC: 0.9412849378881987\n",
      "33 17 0.2266206294298172\n",
      "Validation loss: 0.5332783110001508 ROC AUC: 0.9318711180124224\n",
      "34 16 0.3621228039264679\n",
      "Validation loss: 0.4467688331417009 ROC AUC: 0.9273097826086956\n",
      "35 15 0.36580535769462585\n",
      "Validation loss: 0.5145073427873499 ROC AUC: 0.9129464285714285\n",
      "36 14 0.08338350057601929\n",
      "Validation loss: 0.3663645819121716 ROC AUC: 0.9405085403726707\n",
      "37 13 0.25937026739120483\n",
      "Validation loss: 0.8220107508640663 ROC AUC: 0.8940217391304349\n",
      "38 12 0.19834120571613312\n",
      "Validation loss: 0.471208380133498 ROC AUC: 0.9344914596273292\n",
      "39 11 0.17964306473731995\n",
      "Validation loss: 0.5757750231845706 ROC AUC: 0.905182453416149\n",
      "40 10 0.18970201909542084\n",
      "Validation loss: 0.40661834034265254 ROC AUC: 0.9471079192546584\n",
      "41 9 0.12649844586849213\n",
      "Validation loss: 0.3860594291313022 ROC AUC: 0.9276979813664596\n",
      "42 8 0.29054000973701477\n",
      "Validation loss: 0.5138813339027704 ROC AUC: 0.9167313664596274\n",
      "43 7 0.3798699975013733\n",
      "Validation loss: 0.42336177533748104 ROC AUC: 0.9292507763975155\n",
      "44 6 0.2146647870540619\n",
      "Validation loss: 0.5928941415805443 ROC AUC: 0.8950892857142857\n",
      "45 5 0.1156696304678917\n",
      "Validation loss: 0.45998163616248205 ROC AUC: 0.9330357142857142\n",
      "46 4 0.2359752357006073\n",
      "Validation loss: 0.44579702615737915 ROC AUC: 0.9165372670807453\n",
      "47 3 0.4340035319328308\n",
      "Validation loss: 0.5251697325238994 ROC AUC: 0.9260481366459627\n",
      "48 2 0.31022176146507263\n",
      "Validation loss: 0.6934098899364471 ROC AUC: 0.9271156832298137\n",
      "49 1 0.13376140594482422\n",
      "Validation loss: 0.5651909583339504 ROC AUC: 0.9350737577639753\n",
      "50 0 0.11375773698091507\n",
      "50 50 0.2024051398038864\n",
      "Validation loss: 0.47445251193701055 ROC AUC: 0.9247864906832298\n",
      "51 49 0.269100546836853\n",
      "Validation loss: 0.4742853138961044 ROC AUC: 0.9180900621118012\n",
      "52 48 0.43956854939460754\n",
      "Validation loss: 0.4262281165403478 ROC AUC: 0.9341032608695652\n",
      "53 47 0.08569695055484772\n",
      "Validation loss: 0.37338801371116265 ROC AUC: 0.9463315217391305\n",
      "54 46 0.16561025381088257\n",
      "Validation loss: 0.4695867961820434 ROC AUC: 0.9176048136645962\n",
      "55 45 0.3308747708797455\n",
      "Validation loss: 0.43491434758784725 ROC AUC: 0.919448757763975\n",
      "56 44 0.09885237365961075\n",
      "Validation loss: 0.6293945102130666 ROC AUC: 0.9229425465838509\n",
      "57 43 0.14542314410209656\n",
      "Validation loss: 0.6373883579291549 ROC AUC: 0.9293478260869565\n",
      "58 42 0.1650019735097885\n",
      "Validation loss: 0.6147984038381016 ROC AUC: 0.9450698757763976\n",
      "59 41 0.13927537202835083\n",
      "Validation loss: 0.5634176298683765 ROC AUC: 0.9277950310559006\n",
      "60 40 0.2983178198337555\n",
      "Validation loss: 0.5844777378381467 ROC AUC: 0.9162461180124224\n",
      "61 39 0.1292359083890915\n",
      "Validation loss: 0.6505888747233971 ROC AUC: 0.8964479813664595\n",
      "62 38 0.2771468162536621\n",
      "Validation loss: 0.6185648908802107 ROC AUC: 0.9030473602484473\n",
      "63 37 0.053196873515844345\n",
      "Validation loss: 0.6120717700789956 ROC AUC: 0.8922748447204969\n",
      "64 36 0.2750867009162903\n",
      "Validation loss: 0.4586649390996671 ROC AUC: 0.9178959627329193\n",
      "65 35 0.16063939034938812\n",
      "Validation loss: 0.5465244978081947 ROC AUC: 0.9103260869565217\n",
      "66 34 0.22010844945907593\n",
      "Validation loss: 0.742830374661614 ROC AUC: 0.8949922360248447\n",
      "67 33 0.164004385471344\n",
      "Validation loss: 0.7072639360147364 ROC AUC: 0.8822787267080745\n",
      "68 32 0.1367938071489334\n",
      "Validation loss: 0.4986656924673155 ROC AUC: 0.9090644409937889\n",
      "69 31 0.1313897669315338\n",
      "Validation loss: 0.6670235886293299 ROC AUC: 0.9122670807453416\n",
      "70 30 0.22328779101371765\n",
      "Validation loss: 0.787383917499991 ROC AUC: 0.8842197204968945\n",
      "71 29 0.07597082853317261\n",
      "Validation loss: 0.5828634585966083 ROC AUC: 0.9099378881987578\n",
      "72 28 0.1550791710615158\n",
      "Validation loss: 0.5200280211135453 ROC AUC: 0.921486801242236\n",
      "73 27 0.11029049009084702\n",
      "Validation loss: 0.751912512031256 ROC AUC: 0.9050854037267081\n",
      "74 26 0.2340971976518631\n",
      "Validation loss: 0.828879199775995 ROC AUC: 0.873641304347826\n",
      "75 25 0.10721656680107117\n",
      "Validation loss: 0.5573811910900415 ROC AUC: 0.9168284161490684\n",
      "76 24 0.10698290914297104\n",
      "Validation loss: 0.5264249829684987 ROC AUC: 0.8972243788819876\n",
      "77 23 0.13713937997817993\n",
      "Validation loss: 0.622980986740075 ROC AUC: 0.9103260869565217\n",
      "78 22 0.3900039494037628\n",
      "Validation loss: 0.48333830693188834 ROC AUC: 0.9120729813664596\n",
      "79 21 0.06590628623962402\n",
      "Validation loss: 0.6108152614358593 ROC AUC: 0.8992624223602486\n",
      "80 20 0.07133569568395615\n",
      "Validation loss: 0.5578870358420354 ROC AUC: 0.9107142857142857\n",
      "81 19 0.18738240003585815\n",
      "Validation loss: 0.6693318427777758 ROC AUC: 0.9110054347826086\n",
      "82 18 0.07528169453144073\n",
      "Validation loss: 0.43692120033151965 ROC AUC: 0.9280861801242236\n",
      "83 17 0.08600670844316483\n",
      "Validation loss: 0.6763174276725918 ROC AUC: 0.9141110248447205\n",
      "84 16 0.09070825576782227\n",
      "Validation loss: 0.5164824022966272 ROC AUC: 0.9089673913043479\n",
      "85 15 0.1055152490735054\n",
      "Validation loss: 0.5373002910146526 ROC AUC: 0.9164402173913043\n",
      "86 14 0.19236260652542114\n",
      "Validation loss: 0.5262220548648461 ROC AUC: 0.905085403726708\n",
      "87 13 0.24956469237804413\n",
      "Validation loss: 0.5311055609992906 ROC AUC: 0.9243982919254657\n",
      "88 12 0.11768031865358353\n",
      "Validation loss: 0.6662003526500627 ROC AUC: 0.9175077639751552\n",
      "89 11 0.04959624633193016\n",
      "Validation loss: 0.6297496609828052 ROC AUC: 0.9163431677018633\n",
      "90 10 0.048698727041482925\n",
      "Validation loss: 0.7220791511091531 ROC AUC: 0.89256599378882\n",
      "91 9 0.061711087822914124\n",
      "Validation loss: 0.4826042091145235 ROC AUC: 0.9372088509316769\n",
      "92 8 0.13837668299674988\n",
      "Validation loss: 0.48402274765220343 ROC AUC: 0.9205163043478262\n",
      "93 7 0.04709640145301819\n",
      "Validation loss: 0.5052743670987148 ROC AUC: 0.92284549689441\n",
      "94 6 0.11469228565692902\n",
      "Validation loss: 0.676519950523096 ROC AUC: 0.9023680124223602\n",
      "95 5 0.0741896778345108\n",
      "Validation loss: 0.5311383572863597 ROC AUC: 0.9240100931677019\n",
      "96 4 0.2202616035938263\n",
      "Validation loss: 0.5360570305264464 ROC AUC: 0.9068322981366459\n",
      "97 3 0.10544086992740631\n",
      "Validation loss: 0.5743991463792091 ROC AUC: 0.9262422360248448\n",
      "98 2 0.08698134869337082\n",
      "Validation loss: 0.6395784587252373 ROC AUC: 0.9024650621118012\n",
      "99 1 0.0688595324754715\n",
      "Validation loss: 0.769597097939136 ROC AUC: 0.9038237577639752\n",
      "100 0 0.038586828857660294\n",
      "100 50 0.4776252210140228\n",
      "Validation loss: 0.8423336907929065 ROC AUC: 0.8911102484472049\n",
      "101 49 0.05441756173968315\n",
      "Validation loss: 0.6582503442232516 ROC AUC: 0.9074145962732919\n",
      "102 48 0.27798959612846375\n",
      "Validation loss: 0.664615600716834 ROC AUC: 0.9086762422360248\n",
      "103 47 0.08194258064031601\n",
      "Validation loss: 0.727415022458516 ROC AUC: 0.9127523291925467\n",
      "104 46 0.2952653169631958\n",
      "Validation loss: 0.7151088072717482 ROC AUC: 0.9012034161490683\n",
      "105 45 0.05667884647846222\n",
      "Validation loss: 0.8882327114834505 ROC AUC: 0.8893633540372671\n",
      "106 44 0.2054859697818756\n",
      "Validation loss: 0.6902469960497875 ROC AUC: 0.8958656832298135\n",
      "107 43 0.1325131505727768\n",
      "Validation loss: 0.7811723421601688 ROC AUC: 0.9154697204968943\n",
      "108 42 0.20468354225158691\n",
      "Validation loss: 0.6079755530637854 ROC AUC: 0.9127523291925466\n",
      "109 41 0.08312073349952698\n",
      "Validation loss: 0.5885121286572779 ROC AUC: 0.9345885093167701\n",
      "110 40 0.09224618226289749\n",
      "Validation loss: 0.6011576857052597 ROC AUC: 0.937305900621118\n",
      "111 39 0.08967579901218414\n",
      "Validation loss: 0.6758216271797816 ROC AUC: 0.9379852484472049\n",
      "112 38 0.06831121444702148\n",
      "Validation loss: 0.6682404700447532 ROC AUC: 0.9298330745341614\n",
      "113 37 0.08233873546123505\n",
      "Validation loss: 0.5360796020603648 ROC AUC: 0.9544836956521738\n",
      "114 36 0.10754396766424179\n",
      "Validation loss: 0.5131496378019744 ROC AUC: 0.9342003105590061\n",
      "115 35 0.24821637570858002\n",
      "Validation loss: 0.7959396231408212 ROC AUC: 0.9037267080745341\n",
      "116 34 0.20839233696460724\n",
      "Validation loss: 1.009574759240244 ROC AUC: 0.889169254658385\n",
      "117 33 0.34705376625061035\n",
      "Validation loss: 0.5274220459601459 ROC AUC: 0.8960597826086957\n",
      "118 32 0.03480164706707001\n",
      "Validation loss: 0.6397214157908571 ROC AUC: 0.9119759316770186\n",
      "119 31 0.04186590015888214\n",
      "Validation loss: 0.54894478356137 ROC AUC: 0.9135287267080745\n",
      "120 30 0.04989073798060417\n",
      "Validation loss: 0.6297959020616961 ROC AUC: 0.9307065217391304\n",
      "121 29 0.053122714161872864\n",
      "Validation loss: 0.9027122446134979 ROC AUC: 0.9195458074534162\n",
      "122 28 0.09823667258024216\n",
      "Validation loss: 0.8289989355732413 ROC AUC: 0.9128493788819876\n",
      "123 27 0.10243432968854904\n",
      "Validation loss: 0.761126601228527 ROC AUC: 0.9081909937888198\n",
      "124 26 0.03368818014860153\n",
      "Validation loss: 0.5827396921083039 ROC AUC: 0.9267274844720497\n",
      "125 25 0.16576562821865082\n",
      "Validation loss: 0.691095616522373 ROC AUC: 0.9079968944099379\n",
      "126 24 0.1618444174528122\n",
      "Validation loss: 0.7087653507204617 ROC AUC: 0.9126552795031057\n",
      "127 23 0.03888697177171707\n",
      "Validation loss: 0.9167710072269627 ROC AUC: 0.8961568322981367\n",
      "128 22 0.050349533557891846\n",
      "Validation loss: 0.7467176575286716 ROC AUC: 0.921875\n",
      "129 21 0.04078422486782074\n",
      "Validation loss: 1.0536883298088522 ROC AUC: 0.8576281055900622\n",
      "130 20 0.13484644889831543\n",
      "Validation loss: 0.8694342164432302 ROC AUC: 0.875\n",
      "131 19 0.04792746528983116\n",
      "Validation loss: 0.7897438290802872 ROC AUC: 0.9146933229813664\n",
      "132 18 0.1215747818350792\n",
      "Validation loss: 0.9832406978981167 ROC AUC: 0.9007181677018634\n",
      "133 17 0.08406996726989746\n",
      "Validation loss: 0.8579156936383715 ROC AUC: 0.8961568322981366\n",
      "134 16 0.05636652186512947\n",
      "Validation loss: 0.7073076734794121 ROC AUC: 0.9152756211180124\n",
      "135 15 0.10071857273578644\n",
      "Validation loss: 0.7371173512701895 ROC AUC: 0.922942546583851\n",
      "136 14 0.07871229946613312\n",
      "Validation loss: 0.7938222557890648 ROC AUC: 0.9017857142857143\n",
      "137 13 0.10760568082332611\n",
      "Validation loss: 0.7613567020378861 ROC AUC: 0.921195652173913\n",
      "138 12 0.16644929349422455\n",
      "Validation loss: 0.7411448698417813 ROC AUC: 0.9181871118012422\n",
      "139 11 0.08434146642684937\n",
      "Validation loss: 1.2528681194081026 ROC AUC: 0.873447204968944\n",
      "140 10 0.07640181481838226\n",
      "Validation loss: 0.7402320015883329 ROC AUC: 0.9145962732919254\n",
      "141 9 0.17271006107330322\n",
      "Validation loss: 0.8211165918037295 ROC AUC: 0.9355590062111802\n",
      "142 8 0.14947400987148285\n",
      "Validation loss: 0.8289174542707556 ROC AUC: 0.9190605590062112\n",
      "143 7 0.05830885097384453\n",
      "Validation loss: 0.8103751201255649 ROC AUC: 0.9184782608695652\n",
      "144 6 0.10043990612030029\n",
      "Validation loss: 0.834728009560529 ROC AUC: 0.9253687888198758\n",
      "145 5 0.037175942212343216\n",
      "Validation loss: 1.074628140412125 ROC AUC: 0.8871312111801242\n",
      "146 4 0.013484636321663857\n",
      "Validation loss: 1.102335374802351 ROC AUC: 0.8969332298136645\n",
      "147 3 0.0962923988699913\n",
      "Validation loss: 1.3127451844367326 ROC AUC: 0.8825698757763976\n",
      "148 2 0.07806374132633209\n",
      "Validation loss: 0.8233284070795658 ROC AUC: 0.8977096273291925\n",
      "149 1 0.02210840955376625\n",
      "Validation loss: 0.696187325552398 ROC AUC: 0.9022709627329193\n",
      "150 0 0.050311051309108734\n",
      "150 50 0.06970786303281784\n",
      "Validation loss: 0.7180385636348351 ROC AUC: 0.9138198757763976\n",
      "151 49 0.11466243863105774\n",
      "Validation loss: 0.9206318002121121 ROC AUC: 0.9073175465838509\n",
      "152 48 0.04408740997314453\n",
      "Validation loss: 0.6517489353815714 ROC AUC: 0.9263392857142857\n",
      "153 47 0.04215738922357559\n",
      "Validation loss: 0.7111630866340563 ROC AUC: 0.9266304347826086\n",
      "154 46 0.10086651891469955\n",
      "Validation loss: 0.917636003820043 ROC AUC: 0.9089673913043479\n",
      "155 45 0.051731400191783905\n",
      "Validation loss: 1.7002849520421495 ROC AUC: 0.8608307453416149\n",
      "156 44 0.12274014204740524\n",
      "Validation loss: 0.8662192209934195 ROC AUC: 0.9126552795031055\n",
      "157 43 0.1753516048192978\n",
      "Validation loss: 1.1028819107541852 ROC AUC: 0.9124611801242236\n",
      "158 42 0.04259592667222023\n",
      "Validation loss: 0.9976274593203676 ROC AUC: 0.8922748447204969\n",
      "159 41 0.06254753470420837\n",
      "Validation loss: 0.8539856730722913 ROC AUC: 0.8737383540372671\n",
      "160 40 0.12648263573646545\n",
      "Validation loss: 1.0758137445823819 ROC AUC: 0.8668478260869565\n",
      "161 39 0.19989237189292908\n",
      "Validation loss: 0.9099762217671263 ROC AUC: 0.9068322981366459\n",
      "162 38 0.06851492822170258\n",
      "Validation loss: 1.0312634659748452 ROC AUC: 0.907608695652174\n",
      "163 37 0.07693132758140564\n",
      "Validation loss: 0.8373969265935468 ROC AUC: 0.9138198757763976\n",
      "164 36 0.10087965428829193\n",
      "Validation loss: 0.950836277475544 ROC AUC: 0.8982919254658386\n",
      "165 35 0.08259385824203491\n",
      "Validation loss: 0.8476727371122322 ROC AUC: 0.9030473602484472\n",
      "166 34 0.15290102362632751\n",
      "Validation loss: 0.8219656523536233 ROC AUC: 0.9159549689440994\n",
      "167 33 0.13810446858406067\n",
      "Validation loss: 1.0928602055007337 ROC AUC: 0.9086762422360248\n",
      "168 32 0.01731000281870365\n",
      "Validation loss: 0.6751520872234786 ROC AUC: 0.9289596273291926\n",
      "169 31 0.07073773443698883\n",
      "Validation loss: 0.824610107085284 ROC AUC: 0.9234277950310559\n",
      "170 30 0.03338401019573212\n",
      "Validation loss: 0.9467872778574625 ROC AUC: 0.9015916149068324\n",
      "171 29 0.045902546495199203\n",
      "Validation loss: 0.8271942185420617 ROC AUC: 0.9174107142857142\n",
      "172 28 0.14857037365436554\n",
      "Validation loss: 0.8666783542025323 ROC AUC: 0.8987771739130435\n",
      "173 27 0.27654480934143066\n",
      "Validation loss: 0.770019112848768 ROC AUC: 0.9155667701863354\n",
      "174 26 0.16140136122703552\n",
      "Validation loss: 0.8113367434810189 ROC AUC: 0.9123641304347827\n",
      "175 25 0.12537699937820435\n",
      "Validation loss: 0.970309726747812 ROC AUC: 0.9093555900621118\n",
      "176 24 0.046683620661497116\n",
      "Validation loss: 0.7088678502569011 ROC AUC: 0.9268245341614907\n",
      "177 23 0.09308728575706482\n",
      "Validation loss: 0.8613880358490289 ROC AUC: 0.9116847826086957\n",
      "178 22 0.08060691505670547\n",
      "Validation loss: 0.8355493452034745 ROC AUC: 0.9143051242236024\n",
      "179 21 0.24140360951423645\n",
      "Validation loss: 0.7936782182431689 ROC AUC: 0.9246894409937888\n",
      "180 20 0.01487906463444233\n",
      "Validation loss: 0.814756762017222 ROC AUC: 0.9333268633540374\n",
      "181 19 0.09740421175956726\n",
      "Validation loss: 0.773657616045253 ROC AUC: 0.9143051242236024\n",
      "182 18 0.06470218300819397\n",
      "Validation loss: 0.8152147157519471 ROC AUC: 0.9143051242236024\n",
      "183 17 0.09436142444610596\n",
      "Validation loss: 0.7728401317315943 ROC AUC: 0.9154697204968943\n",
      "184 16 0.12479425966739655\n",
      "Validation loss: 0.8093118761100021 ROC AUC: 0.9319681677018634\n",
      "185 15 0.023548094555735588\n",
      "Validation loss: 1.2278602690088982 ROC AUC: 0.9076086956521738\n",
      "186 14 0.023389915004372597\n",
      "Validation loss: 0.8305884506188187 ROC AUC: 0.9123641304347827\n",
      "187 13 0.10864170640707016\n",
      "Validation loss: 0.7735166224632778 ROC AUC: 0.9285714285714286\n",
      "188 12 0.05588361620903015\n",
      "Validation loss: 0.8259361044448965 ROC AUC: 0.9190605590062111\n",
      "189 11 0.03732876479625702\n",
      "Validation loss: 1.2452031687340315 ROC AUC: 0.8938276397515528\n",
      "190 10 0.1161687970161438\n",
      "Validation loss: 0.8686708562514361 ROC AUC: 0.9321622670807452\n",
      "191 9 0.08964619785547256\n",
      "Validation loss: 0.8382473883091235 ROC AUC: 0.920613354037267\n",
      "192 8 0.07296835631132126\n",
      "Validation loss: 1.4285984319799088 ROC AUC: 0.8948951863354037\n",
      "193 7 0.0655834749341011\n",
      "Validation loss: 0.8133944763856775 ROC AUC: 0.9282802795031057\n",
      "194 6 0.04191919043660164\n",
      "Validation loss: 1.0295828241927951 ROC AUC: 0.9351708074534162\n",
      "195 5 0.19002671539783478\n",
      "Validation loss: 0.9110328216178745 ROC AUC: 0.9149844720496894\n",
      "196 4 0.04854774475097656\n",
      "Validation loss: 0.9924031104527268 ROC AUC: 0.9292507763975155\n",
      "197 3 0.08892616629600525\n",
      "Validation loss: 0.7928919424028957 ROC AUC: 0.9279891304347826\n",
      "198 2 0.08429621160030365\n",
      "Validation loss: 0.9321974189495486 ROC AUC: 0.9388586956521741\n",
      "199 1 0.10174757987260818\n",
      "Validation loss: 0.8995897426616912 ROC AUC: 0.9140139751552795\n",
      "Loaded trained model with success.\n",
      "Test loss: 2.400873347824695 Test ROC AUC: 0.7262742075344445\n"
     ]
    }
   ],
   "source": [
    "datasets = ['toxcast', 'tox21', 'sider',]\n",
    "seeds = [777, 778, 779, 780, 781]\n",
    "\n",
    "for dataset in datasets:\n",
    "    for seed in seeds:\n",
    "        if dataset == 'FreeSolv':\n",
    "            # FreeSolv     \n",
    "            !python finetuneReconTop.py \\\n",
    "            --task_name {dataset} \\\n",
    "            --seed {seed} \\\n",
    "            --dropout 0.5 \\\n",
    "            --num_layer 3 \\\n",
    "            --emb_dim 64 \\\n",
    "            --feat_dim 64 \\\n",
    "            --alpha 0.1 \\\n",
    "            --random_masking 1 \\\n",
    "            \n",
    "        else:\n",
    "            #      \n",
    "            !python finetuneReconTop.py \\\n",
    "            --task_name {dataset} \\\n",
    "            --seed {seed} \\\n",
    "            --alpha 0.1 \\\n",
    "            --random_masking 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2a46ae-a6b6-4a66-befc-c4e38c83fdb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'freesolv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'random', 'seed': 777, 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'target': ['expt']}}\n",
      "Running on: cuda:0\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 14.321107864379883\n",
      "Validation loss: 20.91863441467285 RMSE: 4.5736895\n",
      "Validation loss: 17.256500959396362 RMSE: 4.154094\n",
      "2 16 1.6740686893463135\n",
      "Validation loss: 9.5014009475708 RMSE: 3.0824342\n",
      "Validation loss: 18.261054039001465 RMSE: 4.2732954\n",
      "Validation loss: 4.354099988937378 RMSE: 2.0866482\n",
      "5 15 2.0978336334228516\n",
      "Validation loss: 2.7761409282684326 RMSE: 1.6661755\n",
      "Validation loss: 6.134705543518066 RMSE: 2.4768338\n",
      "Validation loss: 6.321134567260742 RMSE: 2.5141869\n",
      "8 14 3.4172286987304688\n",
      "Validation loss: 5.5209267139434814 RMSE: 2.3496654\n",
      "Validation loss: 13.93534231185913 RMSE: 3.7330072\n",
      "Validation loss: 5.228390216827393 RMSE: 2.2865674\n",
      "11 13 3.121549129486084\n",
      "Validation loss: 7.373233079910278 RMSE: 2.7153695\n",
      "Validation loss: 4.980787515640259 RMSE: 2.231768\n",
      "Validation loss: 4.149728178977966 RMSE: 2.0370882\n",
      "14 12 3.0783309936523438\n",
      "Validation loss: 5.393917560577393 RMSE: 2.322481\n",
      "Validation loss: 9.424787402153015 RMSE: 3.069982\n",
      "Validation loss: 3.304729461669922 RMSE: 1.8178914\n",
      "17 11 2.1237094402313232\n",
      "Validation loss: 13.586473822593689 RMSE: 3.6859837\n",
      "Validation loss: 2.705667734146118 RMSE: 1.6448911\n",
      "Validation loss: 4.860611200332642 RMSE: 2.204679\n",
      "20 10 2.180887460708618\n",
      "Validation loss: 9.186617851257324 RMSE: 3.0309432\n",
      "Validation loss: 6.59820419549942 RMSE: 2.5686972\n",
      "Validation loss: 5.45841646194458 RMSE: 2.3363254\n",
      "23 9 2.2084107398986816\n",
      "Validation loss: 10.025069236755371 RMSE: 3.1662388\n",
      "Validation loss: 2.3286338448524475 RMSE: 1.5259862\n",
      "Validation loss: 8.440638542175293 RMSE: 2.9052775\n",
      "26 8 1.3372224569320679\n",
      "Validation loss: 6.463868141174316 RMSE: 2.5424137\n",
      "Validation loss: 12.901103496551514 RMSE: 3.5918105\n",
      "Validation loss: 12.712461471557617 RMSE: 3.565454\n",
      "29 7 3.387467861175537\n",
      "Validation loss: 1.6997678875923157 RMSE: 1.3037512\n",
      "Validation loss: 8.209753513336182 RMSE: 2.865267\n",
      "Validation loss: 3.7261006832122803 RMSE: 1.9303108\n",
      "32 6 1.3978638648986816\n",
      "Validation loss: 3.634792923927307 RMSE: 1.9065133\n",
      "Validation loss: 23.70071315765381 RMSE: 4.8683376\n",
      "Validation loss: 2.1626139879226685 RMSE: 1.4705827\n",
      "35 5 2.1506173610687256\n",
      "Validation loss: 7.431595802307129 RMSE: 2.7260954\n",
      "Validation loss: 6.668334126472473 RMSE: 2.5823119\n",
      "Validation loss: 2.303868055343628 RMSE: 1.5178498\n",
      "38 4 5.720208168029785\n",
      "Validation loss: 10.526123046875 RMSE: 3.2443988\n",
      "Validation loss: 4.498493194580078 RMSE: 2.1209652\n",
      "Validation loss: 4.741388440132141 RMSE: 2.1774728\n",
      "41 3 1.1128249168395996\n",
      "Validation loss: 15.646967649459839 RMSE: 3.9556246\n",
      "Validation loss: 1.95924711227417 RMSE: 1.3997312\n",
      "Validation loss: 3.023181438446045 RMSE: 1.7387301\n",
      "44 2 1.488884449005127\n",
      "Validation loss: 8.31072986125946 RMSE: 2.8828337\n",
      "Validation loss: 3.8074792623519897 RMSE: 1.9512762\n",
      "Validation loss: 15.148390293121338 RMSE: 3.8920937\n",
      "47 1 1.3609793186187744\n",
      "Validation loss: 11.078186750411987 RMSE: 3.3283908\n",
      "Validation loss: 2.7154356241226196 RMSE: 1.6478577\n",
      "Validation loss: 9.06560730934143 RMSE: 3.0109143\n",
      "50 0 1.7610065937042236\n",
      "Validation loss: 5.494647741317749 RMSE: 2.3440666\n",
      "Validation loss: 4.9150495529174805 RMSE: 2.216991\n",
      "52 16 4.530332565307617\n",
      "Validation loss: 2.4536731243133545 RMSE: 1.5664204\n",
      "Validation loss: 7.778294801712036 RMSE: 2.7889593\n",
      "Validation loss: 11.89563512802124 RMSE: 3.4490044\n",
      "55 15 1.5943224430084229\n",
      "Validation loss: 8.33542251586914 RMSE: 2.887113\n",
      "Validation loss: 4.603169918060303 RMSE: 2.1454997\n",
      "Validation loss: 8.7169189453125 RMSE: 2.9524424\n",
      "58 14 6.113883972167969\n",
      "Validation loss: 3.524573802947998 RMSE: 1.8773848\n",
      "Validation loss: 3.1536667346954346 RMSE: 1.7758563\n",
      "Validation loss: 2.669476866722107 RMSE: 1.6338534\n",
      "61 13 3.593710422515869\n",
      "Validation loss: 2.729556918144226 RMSE: 1.6521369\n",
      "Validation loss: 1.4966734647750854 RMSE: 1.223386\n",
      "Validation loss: 10.484611511230469 RMSE: 3.2379944\n",
      "64 12 1.4421100616455078\n",
      "Validation loss: 15.941698551177979 RMSE: 3.9927056\n",
      "Validation loss: 2.03757643699646 RMSE: 1.4274371\n",
      "Validation loss: 4.891714930534363 RMSE: 2.2117226\n",
      "67 11 0.8361790180206299\n",
      "Validation loss: 1.9478195905685425 RMSE: 1.3956432\n",
      "Validation loss: 4.604289650917053 RMSE: 2.1457608\n",
      "Validation loss: 6.783350348472595 RMSE: 2.6044862\n",
      "70 10 2.0118415355682373\n",
      "Validation loss: 5.839918375015259 RMSE: 2.4165924\n",
      "Validation loss: 8.688260555267334 RMSE: 2.9475856\n",
      "Validation loss: 2.0918793082237244 RMSE: 1.446333\n",
      "73 9 0.996292233467102\n",
      "Validation loss: 2.770226240158081 RMSE: 1.6643996\n",
      "Validation loss: 3.364711880683899 RMSE: 1.8343152\n",
      "Validation loss: 2.3308213353157043 RMSE: 1.5267028\n",
      "76 8 1.6383395195007324\n",
      "Validation loss: 2.394361436367035 RMSE: 1.5473725\n",
      "Validation loss: 1.2451589703559875 RMSE: 1.1158668\n",
      "Validation loss: 9.45081090927124 RMSE: 3.0742173\n",
      "79 7 2.138673782348633\n",
      "Validation loss: 6.314155101776123 RMSE: 2.5127983\n",
      "Validation loss: 11.514304161071777 RMSE: 3.3932729\n",
      "Validation loss: 1.5443845093250275 RMSE: 1.2427326\n",
      "82 6 1.8259228467941284\n",
      "Validation loss: 2.806889295578003 RMSE: 1.6753772\n",
      "Validation loss: 2.180079460144043 RMSE: 1.4765092\n",
      "Validation loss: 13.70202922821045 RMSE: 3.7016258\n",
      "85 5 1.7427281141281128\n",
      "Validation loss: 2.6307966709136963 RMSE: 1.6219732\n",
      "Validation loss: 5.62000185251236 RMSE: 2.370654\n",
      "Validation loss: 2.6636844873428345 RMSE: 1.6320797\n",
      "88 4 0.8470762968063354\n",
      "Validation loss: 1.5560477375984192 RMSE: 1.2474165\n",
      "Validation loss: 6.000298738479614 RMSE: 2.4495509\n",
      "Validation loss: 3.4865431785583496 RMSE: 1.867229\n",
      "91 3 0.5117723345756531\n",
      "Validation loss: 1.3801007866859436 RMSE: 1.1747768\n",
      "Validation loss: 3.1592814922332764 RMSE: 1.7774367\n",
      "Validation loss: 2.77260684967041 RMSE: 1.6651146\n",
      "94 2 2.832580327987671\n",
      "Validation loss: 2.2825942039489746 RMSE: 1.5108255\n",
      "Validation loss: 1.2492355108261108 RMSE: 1.117692\n",
      "Validation loss: 4.164891719818115 RMSE: 2.0408063\n",
      "97 1 2.0177931785583496\n",
      "Validation loss: 3.6904574632644653 RMSE: 1.9210564\n",
      "Validation loss: 5.913467675447464 RMSE: 2.4317622\n",
      "Validation loss: 1.072115421295166 RMSE: 1.0354302\n",
      "100 0 1.43095862865448\n",
      "Validation loss: 2.359165281057358 RMSE: 1.5359572\n",
      "Validation loss: 3.742803692817688 RMSE: 1.9346328\n",
      "102 16 0.6668446660041809\n",
      "Validation loss: 2.897221565246582 RMSE: 1.7021226\n",
      "Validation loss: 1.9340905249118805 RMSE: 1.3907158\n",
      "Validation loss: 3.806449294090271 RMSE: 1.9510124\n",
      "105 15 2.747955322265625\n",
      "Validation loss: 2.2267810106277466 RMSE: 1.4922402\n",
      "Validation loss: 2.8945993185043335 RMSE: 1.7013521\n",
      "Validation loss: 2.2886324524879456 RMSE: 1.5128231\n",
      "108 14 1.856547236442566\n",
      "Validation loss: 5.9955174922943115 RMSE: 2.4485748\n",
      "Validation loss: 1.249184787273407 RMSE: 1.1176693\n",
      "Validation loss: 3.0336804389953613 RMSE: 1.7417461\n",
      "111 13 0.8801333904266357\n",
      "Validation loss: 1.4764221906661987 RMSE: 1.2150811\n",
      "Validation loss: 6.9158570766448975 RMSE: 2.6298018\n",
      "Validation loss: 1.338023066520691 RMSE: 1.1567296\n",
      "114 12 1.0879697799682617\n",
      "Validation loss: 2.7781455516815186 RMSE: 1.6667773\n",
      "Validation loss: 4.137959718704224 RMSE: 2.0341976\n",
      "Validation loss: 2.805605858564377 RMSE: 1.6749942\n",
      "117 11 1.7006199359893799\n",
      "Validation loss: 2.56577730178833 RMSE: 1.6018044\n",
      "Validation loss: 1.2324445247650146 RMSE: 1.1101552\n",
      "Validation loss: 1.9795788526535034 RMSE: 1.4069748\n",
      "120 10 1.2716553211212158\n",
      "Validation loss: 1.340436190366745 RMSE: 1.157772\n",
      "Validation loss: 1.4255233108997345 RMSE: 1.1939527\n",
      "Validation loss: 6.794361591339111 RMSE: 2.6065993\n",
      "123 9 1.2550132274627686\n",
      "Validation loss: 1.4356001019477844 RMSE: 1.1981653\n",
      "Validation loss: 5.750680923461914 RMSE: 2.3980577\n",
      "Validation loss: 1.3114582300186157 RMSE: 1.145189\n",
      "126 8 1.7500109672546387\n",
      "Validation loss: 4.8761069774627686 RMSE: 2.208191\n",
      "Validation loss: 1.45756334066391 RMSE: 1.2072957\n",
      "Validation loss: 1.1161895394325256 RMSE: 1.0564988\n",
      "129 7 0.6116553544998169\n",
      "Validation loss: 1.739623486995697 RMSE: 1.3189479\n",
      "Validation loss: 3.356816291809082 RMSE: 1.8321614\n",
      "Validation loss: 3.7187633514404297 RMSE: 1.9284096\n",
      "132 6 1.253115177154541\n",
      "Validation loss: 1.6520788371562958 RMSE: 1.2853323\n",
      "Validation loss: 1.0393221378326416 RMSE: 1.0194714\n",
      "Validation loss: 2.311925768852234 RMSE: 1.5205017\n",
      "135 5 0.5788388848304749\n",
      "Validation loss: 2.79392671585083 RMSE: 1.6715044\n",
      "Validation loss: 2.091659724712372 RMSE: 1.4462571\n",
      "Validation loss: 1.4883313179016113 RMSE: 1.2199719\n",
      "138 4 1.0223125219345093\n",
      "Validation loss: 2.0054184198379517 RMSE: 1.4161279\n",
      "Validation loss: 1.3556776642799377 RMSE: 1.1643357\n",
      "Validation loss: 1.5639651715755463 RMSE: 1.2505859\n",
      "141 3 1.521355152130127\n",
      "Validation loss: 0.9317711591720581 RMSE: 0.9652828\n",
      "Validation loss: 1.3833388686180115 RMSE: 1.1761543\n",
      "Validation loss: 1.6674079895019531 RMSE: 1.2912816\n",
      "144 2 1.359778642654419\n",
      "Validation loss: 6.275326251983643 RMSE: 2.5050602\n",
      "Validation loss: 2.056834638118744 RMSE: 1.4341669\n",
      "Validation loss: 1.3124879002571106 RMSE: 1.1456387\n",
      "147 1 1.4902451038360596\n",
      "Validation loss: 1.7479283809661865 RMSE: 1.3220924\n",
      "Validation loss: 3.0501595735549927 RMSE: 1.7464706\n",
      "Validation loss: 2.12426096200943 RMSE: 1.4574845\n",
      "150 0 0.7807320356369019\n",
      "Validation loss: 1.9108963012695312 RMSE: 1.3823519\n",
      "Validation loss: 1.4102342128753662 RMSE: 1.1875328\n",
      "152 16 0.3569975197315216\n",
      "Validation loss: 1.5386036038398743 RMSE: 1.2404047\n",
      "Validation loss: 0.9323343336582184 RMSE: 0.9655746\n",
      "Validation loss: 1.196922391653061 RMSE: 1.0940394\n",
      "155 15 1.0107722282409668\n",
      "Validation loss: 3.7611218690872192 RMSE: 1.9393616\n",
      "Validation loss: 3.757067382335663 RMSE: 1.9383152\n",
      "Validation loss: 5.740548729896545 RMSE: 2.395944\n",
      "158 14 2.9125609397888184\n",
      "Validation loss: 1.1788890063762665 RMSE: 1.0857666\n",
      "Validation loss: 1.6328120231628418 RMSE: 1.2778153\n",
      "Validation loss: 1.2574752569198608 RMSE: 1.1213721\n",
      "161 13 1.1761541366577148\n",
      "Validation loss: 4.028734087944031 RMSE: 2.0071704\n",
      "Validation loss: 0.9544443190097809 RMSE: 0.97695667\n",
      "Validation loss: 1.6894562244415283 RMSE: 1.2997906\n",
      "164 12 0.6288465261459351\n",
      "Validation loss: 1.0672178864479065 RMSE: 1.0330625\n",
      "Validation loss: 0.966910719871521 RMSE: 0.98331624\n",
      "Validation loss: 1.1631883382797241 RMSE: 1.0785121\n",
      "167 11 0.9410708546638489\n",
      "Validation loss: 1.181836485862732 RMSE: 1.087123\n",
      "Validation loss: 1.3985340595245361 RMSE: 1.1825962\n",
      "Validation loss: 3.3499534130096436 RMSE: 1.8302876\n",
      "170 10 1.0085904598236084\n",
      "Validation loss: 2.5982906818389893 RMSE: 1.6119213\n",
      "Validation loss: 1.89385986328125 RMSE: 1.3761758\n",
      "Validation loss: 1.6625536680221558 RMSE: 1.2894006\n",
      "173 9 0.9965384006500244\n",
      "Validation loss: 4.122945308685303 RMSE: 2.0305035\n",
      "Validation loss: 1.4736483097076416 RMSE: 1.2139392\n",
      "Validation loss: 0.7938440442085266 RMSE: 0.8909793\n",
      "176 8 1.9352898597717285\n",
      "Validation loss: 1.3663355112075806 RMSE: 1.1689036\n",
      "Validation loss: 1.0736965537071228 RMSE: 1.0361933\n",
      "Validation loss: 5.307312250137329 RMSE: 2.3037603\n",
      "179 7 1.3857712745666504\n",
      "Validation loss: 1.7182368636131287 RMSE: 1.3108155\n",
      "Validation loss: 1.4312275648117065 RMSE: 1.1963391\n",
      "Validation loss: 0.9997207522392273 RMSE: 0.9998604\n",
      "182 6 0.9685672521591187\n",
      "Validation loss: 1.9417122602462769 RMSE: 1.3934534\n",
      "Validation loss: 1.6379902362823486 RMSE: 1.27984\n",
      "Validation loss: 1.0898262858390808 RMSE: 1.0439473\n",
      "185 5 1.3943133354187012\n",
      "Validation loss: 1.1425244808197021 RMSE: 1.0688894\n",
      "Validation loss: 1.9647348523139954 RMSE: 1.4016898\n",
      "Validation loss: 1.6245195865631104 RMSE: 1.2745663\n",
      "188 4 0.5735785961151123\n",
      "Validation loss: 2.1779500246047974 RMSE: 1.4757879\n",
      "Validation loss: 1.380947470664978 RMSE: 1.1751372\n",
      "Validation loss: 1.5370616912841797 RMSE: 1.239783\n",
      "191 3 0.5352512001991272\n",
      "Validation loss: 2.5072742700576782 RMSE: 1.5834376\n",
      "Validation loss: 1.66990065574646 RMSE: 1.2922465\n",
      "Validation loss: 3.1005266904830933 RMSE: 1.7608316\n",
      "194 2 1.3924925327301025\n",
      "Validation loss: 4.185925126075745 RMSE: 2.0459528\n",
      "Validation loss: 0.7411659359931946 RMSE: 0.86090994\n",
      "Validation loss: 4.66570520401001 RMSE: 2.1600242\n",
      "197 1 1.9714056253433228\n",
      "Validation loss: 2.1266363859176636 RMSE: 1.4582992\n",
      "Validation loss: 0.8483651876449585 RMSE: 0.9210674\n",
      "Validation loss: 3.0864381194114685 RMSE: 1.7568266\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.9685813188552856 Test RMSE: 1.4030615\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'freesolv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'random', 'seed': 778, 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'target': ['expt']}}\n",
      "Running on: cuda:0\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 16.177167892456055\n",
      "Validation loss: 24.261737823486328 RMSE: 4.9256206\n",
      "Validation loss: 19.728859424591064 RMSE: 4.441718\n",
      "2 16 17.045284271240234\n",
      "Validation loss: 19.012720108032227 RMSE: 4.360358\n",
      "Validation loss: 6.400212526321411 RMSE: 2.5298643\n",
      "Validation loss: 17.22266435623169 RMSE: 4.1500196\n",
      "5 15 3.8309154510498047\n",
      "Validation loss: 5.235531568527222 RMSE: 2.2881284\n",
      "Validation loss: 27.575143814086914 RMSE: 5.251204\n",
      "Validation loss: 5.97870135307312 RMSE: 2.4451385\n",
      "8 14 3.077336311340332\n",
      "Validation loss: 6.119457244873047 RMSE: 2.4737537\n",
      "Validation loss: 5.8354332447052 RMSE: 2.4156642\n",
      "Validation loss: 7.723174333572388 RMSE: 2.7790601\n",
      "11 13 3.958364963531494\n",
      "Validation loss: 6.013454914093018 RMSE: 2.4522345\n",
      "Validation loss: 5.204346179962158 RMSE: 2.2813036\n",
      "Validation loss: 6.283418893814087 RMSE: 2.506675\n",
      "14 12 2.3135015964508057\n",
      "Validation loss: 4.100240707397461 RMSE: 2.0249052\n",
      "Validation loss: 9.616214275360107 RMSE: 3.1010022\n",
      "Validation loss: 7.279036045074463 RMSE: 2.6979687\n",
      "17 11 3.8547940254211426\n",
      "Validation loss: 9.974107682704926 RMSE: 3.1581812\n",
      "Validation loss: 3.30516254901886 RMSE: 1.8180106\n",
      "Validation loss: 2.5077884197235107 RMSE: 1.5835998\n",
      "20 10 2.145199775695801\n",
      "Validation loss: 3.2945258617401123 RMSE: 1.815083\n",
      "Validation loss: 7.0554587841033936 RMSE: 2.6562114\n",
      "Validation loss: 3.3896178603172302 RMSE: 1.8410914\n",
      "23 9 1.5921759605407715\n",
      "Validation loss: 5.975407600402832 RMSE: 2.4444647\n",
      "Validation loss: 3.8915568590164185 RMSE: 1.9727031\n",
      "Validation loss: 3.271517276763916 RMSE: 1.8087337\n",
      "26 8 1.3833270072937012\n",
      "Validation loss: 3.5469539165496826 RMSE: 1.8833357\n",
      "Validation loss: 3.483122944831848 RMSE: 1.8663127\n",
      "Validation loss: 6.065205097198486 RMSE: 2.4627638\n",
      "29 7 1.1739394664764404\n",
      "Validation loss: 6.60438871383667 RMSE: 2.5699005\n",
      "Validation loss: 3.480749785900116 RMSE: 1.8656768\n",
      "Validation loss: 2.2743804454803467 RMSE: 1.508105\n",
      "32 6 1.3863418102264404\n",
      "Validation loss: 8.4001704454422 RMSE: 2.8983047\n",
      "Validation loss: 3.368551254272461 RMSE: 1.8353615\n",
      "Validation loss: 7.511385917663574 RMSE: 2.7406907\n",
      "35 5 2.5965898036956787\n",
      "Validation loss: 3.83659827709198 RMSE: 1.9587238\n",
      "Validation loss: 3.257595717906952 RMSE: 1.804881\n",
      "Validation loss: 2.791750907897949 RMSE: 1.6708534\n",
      "38 4 1.881471037864685\n",
      "Validation loss: 9.365322828292847 RMSE: 3.0602813\n",
      "Validation loss: 11.13070011138916 RMSE: 3.3362706\n",
      "Validation loss: 6.849674940109253 RMSE: 2.6171882\n",
      "41 3 3.5577640533447266\n",
      "Validation loss: 4.5565197467803955 RMSE: 2.1346006\n",
      "Validation loss: 5.489298582077026 RMSE: 2.3429246\n",
      "Validation loss: 2.858259618282318 RMSE: 1.6906388\n",
      "44 2 2.3805320262908936\n",
      "Validation loss: 4.33515477180481 RMSE: 2.0821033\n",
      "Validation loss: 3.2206575870513916 RMSE: 1.7946192\n",
      "Validation loss: 5.4128406047821045 RMSE: 2.326551\n",
      "47 1 1.824760913848877\n",
      "Validation loss: 3.548068881034851 RMSE: 1.883632\n",
      "Validation loss: 4.326249122619629 RMSE: 2.0799637\n",
      "Validation loss: 3.7500126361846924 RMSE: 1.9364951\n",
      "50 0 2.920224189758301\n",
      "Validation loss: 2.8610774278640747 RMSE: 1.6914718\n",
      "Validation loss: 4.7691570520401 RMSE: 2.18384\n",
      "52 16 8.06419563293457\n",
      "Validation loss: 5.873327732086182 RMSE: 2.423495\n",
      "Validation loss: 4.766313314437866 RMSE: 2.1831892\n",
      "Validation loss: 5.336477994918823 RMSE: 2.310082\n",
      "55 15 0.8392414450645447\n",
      "Validation loss: 4.3221787214279175 RMSE: 2.0789852\n",
      "Validation loss: 4.687639951705933 RMSE: 2.1650958\n",
      "Validation loss: 5.042495012283325 RMSE: 2.2455502\n",
      "58 14 0.9096124768257141\n",
      "Validation loss: 3.4262540340423584 RMSE: 1.8510143\n",
      "Validation loss: 3.1890887022018433 RMSE: 1.7858019\n",
      "Validation loss: 8.866388320922852 RMSE: 2.9776487\n",
      "61 13 1.245629072189331\n",
      "Validation loss: 4.22921359539032 RMSE: 2.0565054\n",
      "Validation loss: 5.495846509933472 RMSE: 2.344322\n",
      "Validation loss: 3.5939204692840576 RMSE: 1.8957638\n",
      "64 12 0.957255482673645\n",
      "Validation loss: 3.9504001140594482 RMSE: 1.9875616\n",
      "Validation loss: 3.2795557975769043 RMSE: 1.8109546\n",
      "Validation loss: 6.611280679702759 RMSE: 2.5712411\n",
      "67 11 0.6362749338150024\n",
      "Validation loss: 3.502771496772766 RMSE: 1.8715692\n",
      "Validation loss: 4.1181793212890625 RMSE: 2.0293298\n",
      "Validation loss: 7.210947036743164 RMSE: 2.6853206\n",
      "70 10 2.4402623176574707\n",
      "Validation loss: 2.392658770084381 RMSE: 1.5468222\n",
      "Validation loss: 4.481552720069885 RMSE: 2.1169677\n",
      "Validation loss: 4.823304891586304 RMSE: 2.1962025\n",
      "73 9 0.842302680015564\n",
      "Validation loss: 7.994356632232666 RMSE: 2.8274293\n",
      "Validation loss: 2.0276458263397217 RMSE: 1.4239542\n",
      "Validation loss: 2.9081162214279175 RMSE: 1.70532\n",
      "76 8 1.0372307300567627\n",
      "Validation loss: 2.5272045135498047 RMSE: 1.5897183\n",
      "Validation loss: 3.901069402694702 RMSE: 1.9751126\n",
      "Validation loss: 1.6934426426887512 RMSE: 1.3013235\n",
      "79 7 5.582481861114502\n",
      "Validation loss: 4.278210818767548 RMSE: 2.0683837\n",
      "Validation loss: 2.150050461292267 RMSE: 1.4663051\n",
      "Validation loss: 4.639265656471252 RMSE: 2.1538954\n",
      "82 6 1.0610411167144775\n",
      "Validation loss: 3.7479405403137207 RMSE: 1.9359597\n",
      "Validation loss: 2.750980257987976 RMSE: 1.658608\n",
      "Validation loss: 7.1140453815460205 RMSE: 2.6672168\n",
      "85 5 2.820385456085205\n",
      "Validation loss: 2.742839813232422 RMSE: 1.6561521\n",
      "Validation loss: 6.140491247177124 RMSE: 2.4780014\n",
      "Validation loss: 4.836590051651001 RMSE: 2.199225\n",
      "88 4 1.0982080698013306\n",
      "Validation loss: 3.1317538022994995 RMSE: 1.7696763\n",
      "Validation loss: 6.137798070907593 RMSE: 2.477458\n",
      "Validation loss: 2.7881836891174316 RMSE: 1.6697855\n",
      "91 3 0.6676109433174133\n",
      "Validation loss: 3.0917364358901978 RMSE: 1.7583334\n",
      "Validation loss: 3.5074254274368286 RMSE: 1.8728125\n",
      "Validation loss: 3.1494717597961426 RMSE: 1.7746753\n",
      "94 2 1.818185567855835\n",
      "Validation loss: 3.318026840686798 RMSE: 1.8215451\n",
      "Validation loss: 3.2647088766098022 RMSE: 1.8068506\n",
      "Validation loss: 3.2623045444488525 RMSE: 1.806185\n",
      "97 1 3.451174736022949\n",
      "Validation loss: 4.204235553741455 RMSE: 2.0504236\n",
      "Validation loss: 2.0708935260772705 RMSE: 1.4390599\n",
      "Validation loss: 2.3481072187423706 RMSE: 1.5323536\n",
      "100 0 0.7608904838562012\n",
      "Validation loss: 1.9471333026885986 RMSE: 1.3953973\n",
      "Validation loss: 1.894763708114624 RMSE: 1.3765043\n",
      "102 16 0.40318411588668823\n",
      "Validation loss: 3.6346575021743774 RMSE: 1.906478\n",
      "Validation loss: 2.1790401935577393 RMSE: 1.4761574\n",
      "Validation loss: 2.420938491821289 RMSE: 1.5559366\n",
      "105 15 6.433834075927734\n",
      "Validation loss: 1.8929924964904785 RMSE: 1.3758606\n",
      "Validation loss: 2.8596739768981934 RMSE: 1.6910571\n",
      "Validation loss: 8.327637195587158 RMSE: 2.8857648\n",
      "108 14 0.6014808416366577\n",
      "Validation loss: 14.256386280059814 RMSE: 3.775763\n",
      "Validation loss: 15.315126657485962 RMSE: 3.9134548\n",
      "Validation loss: 2.776508629322052 RMSE: 1.666286\n",
      "111 13 1.560638666152954\n",
      "Validation loss: 4.6485559940338135 RMSE: 2.156051\n",
      "Validation loss: 2.097421407699585 RMSE: 1.4482478\n",
      "Validation loss: 2.6311044096946716 RMSE: 1.6220679\n",
      "114 12 1.1249645948410034\n",
      "Validation loss: 2.067474067211151 RMSE: 1.4378713\n",
      "Validation loss: 2.8440637588500977 RMSE: 1.6864352\n",
      "Validation loss: 10.749679565429688 RMSE: 3.2786703\n",
      "117 11 0.7704058885574341\n",
      "Validation loss: 2.4998421669006348 RMSE: 1.5810889\n",
      "Validation loss: 2.1385265588760376 RMSE: 1.4623704\n",
      "Validation loss: 2.2349127531051636 RMSE: 1.4949625\n",
      "120 10 2.030350923538208\n",
      "Validation loss: 2.8448140621185303 RMSE: 1.6866575\n",
      "Validation loss: 6.282335042953491 RMSE: 2.506459\n",
      "Validation loss: 3.8403666019439697 RMSE: 1.9596854\n",
      "123 9 0.34163355827331543\n",
      "Validation loss: 4.635653853416443 RMSE: 2.153057\n",
      "Validation loss: 3.7509816884994507 RMSE: 1.936745\n",
      "Validation loss: 4.0451420545578 RMSE: 2.011254\n",
      "126 8 0.39654847979545593\n",
      "Validation loss: 2.977458953857422 RMSE: 1.7255315\n",
      "Validation loss: 1.9943581819534302 RMSE: 1.4122175\n",
      "Validation loss: 9.022719502449036 RMSE: 3.0037842\n",
      "129 7 0.6537832021713257\n",
      "Validation loss: 2.475521445274353 RMSE: 1.573379\n",
      "Validation loss: 3.081158995628357 RMSE: 1.7553228\n",
      "Validation loss: 6.174708366394043 RMSE: 2.484896\n",
      "132 6 2.7577638626098633\n",
      "Validation loss: 6.466942071914673 RMSE: 2.5430183\n",
      "Validation loss: 2.8816038370132446 RMSE: 1.697529\n",
      "Validation loss: 2.4262691736221313 RMSE: 1.5576488\n",
      "135 5 1.3890268802642822\n",
      "Validation loss: 3.71411395072937 RMSE: 1.9272038\n",
      "Validation loss: 5.127269744873047 RMSE: 2.2643476\n",
      "Validation loss: 6.524946093559265 RMSE: 2.554398\n",
      "138 4 0.7051113247871399\n",
      "Validation loss: 2.26407253742218 RMSE: 1.5046835\n",
      "Validation loss: 5.4928752183914185 RMSE: 2.3436882\n",
      "Validation loss: 5.883825302124023 RMSE: 2.4256597\n",
      "141 3 3.058467149734497\n",
      "Validation loss: 2.166216492652893 RMSE: 1.4718072\n",
      "Validation loss: 2.9101377725601196 RMSE: 1.7059125\n",
      "Validation loss: 6.473652362823486 RMSE: 2.5443375\n",
      "144 2 1.248665452003479\n",
      "Validation loss: 3.6994166374206543 RMSE: 1.9233868\n",
      "Validation loss: 3.130277633666992 RMSE: 1.7692591\n",
      "Validation loss: 4.930642366409302 RMSE: 2.2205055\n",
      "147 1 1.0608155727386475\n",
      "Validation loss: 5.398394346237183 RMSE: 2.3234441\n",
      "Validation loss: 1.9192267656326294 RMSE: 1.3853614\n",
      "Validation loss: 2.368110775947571 RMSE: 1.5388666\n",
      "150 0 0.34353500604629517\n",
      "Validation loss: 3.953379511833191 RMSE: 1.9883107\n",
      "Validation loss: 2.4039742946624756 RMSE: 1.5504756\n",
      "152 16 8.636552810668945\n",
      "Validation loss: 2.7699525356292725 RMSE: 1.6643175\n",
      "Validation loss: 2.876649796962738 RMSE: 1.696069\n",
      "Validation loss: 6.884784698486328 RMSE: 2.6238875\n",
      "155 15 0.9985655546188354\n",
      "Validation loss: 1.9693673849105835 RMSE: 1.4033415\n",
      "Validation loss: 2.6073597073554993 RMSE: 1.6147323\n",
      "Validation loss: 2.4745023250579834 RMSE: 1.5730551\n",
      "158 14 1.2581570148468018\n",
      "Validation loss: 4.624174475669861 RMSE: 2.1503892\n",
      "Validation loss: 2.2568711042404175 RMSE: 1.5022886\n",
      "Validation loss: 3.3900887966156006 RMSE: 1.8412194\n",
      "161 13 0.8555150032043457\n",
      "Validation loss: 2.448672890663147 RMSE: 1.5648235\n",
      "Validation loss: 4.446964740753174 RMSE: 2.1087828\n",
      "Validation loss: 3.0658514499664307 RMSE: 1.7509575\n",
      "164 12 0.4280672073364258\n",
      "Validation loss: 2.7690131664276123 RMSE: 1.6640353\n",
      "Validation loss: 2.9017393589019775 RMSE: 1.7034489\n",
      "Validation loss: 2.7440223693847656 RMSE: 1.6565093\n",
      "167 11 4.516729354858398\n",
      "Validation loss: 16.870887279510498 RMSE: 4.1074195\n",
      "Validation loss: 4.072938561439514 RMSE: 2.0181525\n",
      "Validation loss: 3.5237984657287598 RMSE: 1.8771784\n",
      "170 10 3.036881923675537\n",
      "Validation loss: 3.036983370780945 RMSE: 1.7426944\n",
      "Validation loss: 2.44356369972229 RMSE: 1.5631903\n",
      "Validation loss: 3.3137908577919006 RMSE: 1.820382\n",
      "173 9 0.9306402206420898\n",
      "Validation loss: 3.2512301206588745 RMSE: 1.803117\n",
      "Validation loss: 2.7262980937957764 RMSE: 1.6511506\n",
      "Validation loss: 3.3111889362335205 RMSE: 1.819667\n",
      "176 8 1.9048376083374023\n",
      "Validation loss: 3.0413849353790283 RMSE: 1.7439568\n",
      "Validation loss: 2.903261661529541 RMSE: 1.703896\n",
      "Validation loss: 2.482684373855591 RMSE: 1.5756537\n",
      "179 7 1.1275672912597656\n",
      "Validation loss: 3.1045680046081543 RMSE: 1.7619786\n",
      "Validation loss: 2.8164854645729065 RMSE: 1.6782386\n",
      "Validation loss: 3.712785482406616 RMSE: 1.926859\n",
      "182 6 0.6586277484893799\n",
      "Validation loss: 10.226084232330322 RMSE: 3.197825\n",
      "Validation loss: 1.4486350417137146 RMSE: 1.2035925\n",
      "Validation loss: 2.521359086036682 RMSE: 1.5878788\n",
      "185 5 0.3939151465892792\n",
      "Validation loss: 2.095668315887451 RMSE: 1.4476424\n",
      "Validation loss: 2.631614923477173 RMSE: 1.6222253\n",
      "Validation loss: 2.4122458696365356 RMSE: 1.5531406\n",
      "188 4 0.7573904991149902\n",
      "Validation loss: 3.088388741016388 RMSE: 1.7573813\n",
      "Validation loss: 2.1823490858078003 RMSE: 1.4772775\n",
      "Validation loss: 2.7811315059661865 RMSE: 1.6676725\n",
      "191 3 0.6242269277572632\n",
      "Validation loss: 2.3720672130584717 RMSE: 1.5401515\n",
      "Validation loss: 1.6066965460777283 RMSE: 1.2675554\n",
      "Validation loss: 1.9161116480827332 RMSE: 1.3842369\n",
      "194 2 0.40893393754959106\n",
      "Validation loss: 2.829254627227783 RMSE: 1.682039\n",
      "Validation loss: 3.5460554361343384 RMSE: 1.883097\n",
      "Validation loss: 3.258698523044586 RMSE: 1.8051865\n",
      "197 1 0.43936824798583984\n",
      "Validation loss: 2.2613322734832764 RMSE: 1.5037729\n",
      "Validation loss: 3.0301384925842285 RMSE: 1.7407295\n",
      "Validation loss: 2.5140167474746704 RMSE: 1.5855651\n",
      "Loaded trained model with success.\n",
      "Test loss: 1.296982854604721 Test RMSE: 1.1388515\n",
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'freesolv', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'random', 'seed': 779, 'task': 'regression', 'data_path': 'data/freesolv/freesolv.csv', 'target': ['expt']}}\n",
      "Running on: cuda:0\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 25.34465789794922\n",
      "Validation loss: 12.407707452774048 RMSE: 3.5224576\n",
      "Validation loss: 10.950044393539429 RMSE: 3.3090851\n",
      "2 16 9.865896224975586\n",
      "Validation loss: 7.281047344207764 RMSE: 2.6983416\n",
      "Validation loss: 3.1205453872680664 RMSE: 1.7665067\n",
      "Validation loss: 8.189875364303589 RMSE: 2.8617957\n",
      "5 15 5.4235687255859375\n",
      "Validation loss: 11.925300598144531 RMSE: 3.4533033\n",
      "Validation loss: 11.280821323394775 RMSE: 3.3586934\n",
      "Validation loss: 9.048739194869995 RMSE: 3.0081117\n",
      "8 14 3.725132942199707\n",
      "Validation loss: 8.653762340545654 RMSE: 2.9417279\n",
      "Validation loss: 8.24027967453003 RMSE: 2.8705888\n",
      "Validation loss: 13.310264706611633 RMSE: 3.6483235\n",
      "11 13 3.842151165008545\n",
      "Validation loss: 13.993754386901855 RMSE: 3.7408228\n",
      "Validation loss: 40.17470169067383 RMSE: 6.3383517\n",
      "Validation loss: 5.9025468826293945 RMSE: 2.429516\n",
      "14 12 2.875326633453369\n",
      "Validation loss: 15.69568932056427 RMSE: 3.9617782\n",
      "Validation loss: 12.538475036621094 RMSE: 3.5409706\n",
      "Validation loss: 2.867928624153137 RMSE: 1.6934958\n",
      "17 11 1.5011425018310547\n",
      "Validation loss: 11.986506223678589 RMSE: 3.4621537\n",
      "Validation loss: 19.080206632614136 RMSE: 4.368089\n",
      "Validation loss: 9.991400957107544 RMSE: 3.1609185\n",
      "20 10 2.6338210105895996\n",
      "Validation loss: 7.560392141342163 RMSE: 2.7496164\n",
      "Validation loss: 6.972215056419373 RMSE: 2.640495\n",
      "Validation loss: 20.8851158618927 RMSE: 4.5700235\n",
      "23 9 2.8116395473480225\n",
      "Validation loss: 8.898826122283936 RMSE: 2.9830902\n",
      "Validation loss: 13.516381740570068 RMSE: 3.6764634\n",
      "Validation loss: 8.907856225967407 RMSE: 2.9846036\n",
      "26 8 3.271012306213379\n",
      "Validation loss: 4.919792026281357 RMSE: 2.21806\n",
      "Validation loss: 15.52579927444458 RMSE: 3.9402792\n",
      "Validation loss: 16.0887770652771 RMSE: 4.0110817\n",
      "29 7 2.6327834129333496\n",
      "Validation loss: 9.56667709350586 RMSE: 3.093005\n",
      "Validation loss: 18.736005783081055 RMSE: 4.328511\n",
      "Validation loss: 9.579350233078003 RMSE: 3.0950525\n",
      "32 6 7.236246109008789\n",
      "Validation loss: 13.506068885326385 RMSE: 3.6750605\n",
      "Validation loss: 7.609158158302307 RMSE: 2.7584705\n",
      "Validation loss: 9.251606613397598 RMSE: 3.0416455\n",
      "35 5 2.20535945892334\n",
      "Validation loss: 9.817100524902344 RMSE: 3.1332252\n",
      "Validation loss: 5.903929233551025 RMSE: 2.4298003\n",
      "Validation loss: 8.708036184310913 RMSE: 2.9509382\n",
      "38 4 2.9949190616607666\n",
      "Validation loss: 7.169894695281982 RMSE: 2.6776655\n",
      "Validation loss: 12.196779012680054 RMSE: 3.4923887\n",
      "Validation loss: 17.020306825637817 RMSE: 4.1255674\n",
      "41 3 0.8254646062850952\n",
      "Validation loss: 11.572498798370361 RMSE: 3.4018376\n",
      "Validation loss: 10.738515615463257 RMSE: 3.2769675\n",
      "Validation loss: 12.545060276985168 RMSE: 3.5419002\n",
      "44 2 1.2029037475585938\n",
      "Validation loss: 15.750840663909912 RMSE: 3.9687326\n",
      "Validation loss: 23.04930591583252 RMSE: 4.800969\n",
      "Validation loss: 5.263496160507202 RMSE: 2.2942312\n",
      "47 1 2.828524112701416\n",
      "Validation loss: 5.428640604019165 RMSE: 2.3299444\n",
      "Validation loss: 8.358381688594818 RMSE: 2.8910866\n",
      "Validation loss: 12.04343867301941 RMSE: 3.4703658\n",
      "50 0 3.5597305297851562\n",
      "Validation loss: 4.632461130619049 RMSE: 2.1523154\n",
      "Validation loss: 10.834916353225708 RMSE: 3.2916436\n",
      "52 16 0.014107247814536095\n",
      "Validation loss: 7.682161629199982 RMSE: 2.7716713\n",
      "Validation loss: 9.323116421699524 RMSE: 3.0533776\n",
      "Validation loss: 10.95346474647522 RMSE: 3.3096018\n",
      "55 15 1.3543438911437988\n",
      "Validation loss: 10.487406373023987 RMSE: 3.2384264\n",
      "Validation loss: 12.428297877311707 RMSE: 3.5253794\n",
      "Validation loss: 17.106172800064087 RMSE: 4.135961\n",
      "58 14 1.1939666271209717\n",
      "Validation loss: 3.819244623184204 RMSE: 1.9542888\n",
      "Validation loss: 8.40926730632782 RMSE: 2.8998737\n",
      "Validation loss: 4.636030197143555 RMSE: 2.1531446\n",
      "61 13 0.6500518321990967\n",
      "Validation loss: 11.045481145381927 RMSE: 3.3234744\n",
      "Validation loss: 12.095356941223145 RMSE: 3.477838\n",
      "Validation loss: 2.532334089279175 RMSE: 1.591331\n",
      "64 12 1.9962137937545776\n",
      "Validation loss: 12.296108186244965 RMSE: 3.5065806\n",
      "Validation loss: 9.195169925689697 RMSE: 3.0323539\n",
      "Validation loss: 7.6196160316467285 RMSE: 2.7603652\n",
      "67 11 0.8398916721343994\n",
      "Validation loss: 11.689944744110107 RMSE: 3.419056\n",
      "Validation loss: 11.393112003803253 RMSE: 3.3753684\n",
      "Validation loss: 8.976502358913422 RMSE: 2.996081\n",
      "70 10 0.8679982423782349\n",
      "Validation loss: 4.520162433385849 RMSE: 2.1260674\n",
      "Validation loss: 13.051826000213623 RMSE: 3.612731\n",
      "Validation loss: 5.0417174100875854 RMSE: 2.2453768\n",
      "73 9 3.008023262023926\n",
      "Validation loss: 13.149206697940826 RMSE: 3.6261835\n",
      "Validation loss: 6.895186543464661 RMSE: 2.6258693\n",
      "Validation loss: 10.904086887836456 RMSE: 3.3021333\n",
      "76 8 3.3582215309143066\n",
      "Validation loss: 6.922343492507935 RMSE: 2.6310346\n",
      "Validation loss: 8.562838077545166 RMSE: 2.9262328\n",
      "Validation loss: 9.650052189826965 RMSE: 3.1064532\n",
      "79 7 0.5592973232269287\n",
      "Validation loss: 5.833475112915039 RMSE: 2.415259\n",
      "Validation loss: 9.370941936969757 RMSE: 3.0611997\n",
      "Validation loss: 2.1663047075271606 RMSE: 1.471837\n",
      "82 6 2.181236505508423\n",
      "Validation loss: 8.572536408901215 RMSE: 2.9278898\n",
      "Validation loss: 14.920010566711426 RMSE: 3.862643\n",
      "Validation loss: 7.8420023918151855 RMSE: 2.800358\n",
      "85 5 1.2096376419067383\n",
      "Validation loss: 7.246490836143494 RMSE: 2.6919308\n",
      "Validation loss: 6.272541761398315 RMSE: 2.5045042\n",
      "Validation loss: 2.543134033679962 RMSE: 1.5947206\n",
      "88 4 1.7187529802322388\n",
      "Validation loss: 6.0916712284088135 RMSE: 2.4681315\n",
      "Validation loss: 9.425927877426147 RMSE: 3.0701678\n",
      "Validation loss: 11.839131355285645 RMSE: 3.4408035\n",
      "91 3 1.6918084621429443\n",
      "Validation loss: 4.942620515823364 RMSE: 2.2232006\n",
      "Validation loss: 8.239064931869507 RMSE: 2.870377\n",
      "Validation loss: 6.177694797515869 RMSE: 2.485497\n",
      "94 2 3.3657453060150146\n",
      "Validation loss: 5.081050276756287 RMSE: 2.254119\n",
      "Validation loss: 6.333524644374847 RMSE: 2.5166495\n",
      "Validation loss: 4.724359154701233 RMSE: 2.173559\n",
      "97 1 1.5374150276184082\n",
      "Validation loss: 10.146036028862 RMSE: 3.1852846\n",
      "Validation loss: 3.6952667236328125 RMSE: 1.9223077\n",
      "Validation loss: 4.303432643413544 RMSE: 2.0744717\n",
      "100 0 1.144290804862976\n",
      "Validation loss: 3.2733246088027954 RMSE: 1.8092335\n",
      "Validation loss: 6.557059973478317 RMSE: 2.5606756\n",
      "102 16 26.50275993347168\n",
      "Validation loss: 4.829246401786804 RMSE: 2.1975548\n",
      "Validation loss: 4.797077119350433 RMSE: 2.190223\n",
      "Validation loss: 1.6351289749145508 RMSE: 1.2787216\n",
      "105 15 1.4952147006988525\n",
      "Validation loss: 16.360883355140686 RMSE: 4.044859\n",
      "Validation loss: 13.22340178489685 RMSE: 3.6363995\n",
      "Validation loss: 2.176056385040283 RMSE: 1.4751463\n",
      "108 14 1.1397364139556885\n",
      "Validation loss: 2.25118088722229 RMSE: 1.5003936\n",
      "Validation loss: 2.4837217330932617 RMSE: 1.5759828\n",
      "Validation loss: 2.353823661804199 RMSE: 1.5342176\n",
      "111 13 1.7176434993743896\n",
      "Validation loss: 5.941526770591736 RMSE: 2.4375246\n",
      "Validation loss: 7.349184036254883 RMSE: 2.710938\n",
      "Validation loss: 5.214462041854858 RMSE: 2.2835197\n",
      "114 12 1.4763509035110474\n",
      "Validation loss: 3.8320605754852295 RMSE: 1.9575648\n",
      "Validation loss: 4.372048258781433 RMSE: 2.0909443\n",
      "Validation loss: 4.4103734493255615 RMSE: 2.100089\n",
      "117 11 1.1774027347564697\n",
      "Validation loss: 8.59807574748993 RMSE: 2.9322476\n",
      "Validation loss: 3.3164197206497192 RMSE: 1.8211039\n",
      "Validation loss: 7.782244324684143 RMSE: 2.7896674\n",
      "120 10 1.4214004278182983\n",
      "Validation loss: 2.061392664909363 RMSE: 1.4357553\n",
      "Validation loss: 3.192260265350342 RMSE: 1.7866898\n",
      "Validation loss: 2.5014848709106445 RMSE: 1.5816084\n",
      "123 9 1.549255132675171\n",
      "Validation loss: 7.7422440350055695 RMSE: 2.7824883\n",
      "Validation loss: 4.844755828380585 RMSE: 2.201081\n",
      "Validation loss: 2.65641325712204 RMSE: 1.6298505\n",
      "126 8 1.752204418182373\n",
      "Validation loss: 7.358728766441345 RMSE: 2.7126977\n",
      "Validation loss: 5.25514554977417 RMSE: 2.2924106\n",
      "Validation loss: 3.194562792778015 RMSE: 1.787334\n",
      "129 7 1.192499041557312\n",
      "Validation loss: 2.7923807501792908 RMSE: 1.6710418\n",
      "Validation loss: 13.555424094200134 RMSE: 3.6817691\n",
      "Validation loss: 3.234817624092102 RMSE: 1.7985598\n",
      "132 6 1.3933422565460205\n",
      "Validation loss: 3.969472259283066 RMSE: 1.9923533\n",
      "Validation loss: 4.381146192550659 RMSE: 2.093119\n",
      "Validation loss: 5.872615694999695 RMSE: 2.423348\n",
      "135 5 1.9760018587112427\n",
      "Validation loss: 3.626494348049164 RMSE: 1.9043357\n",
      "Validation loss: 3.935815393924713 RMSE: 1.9838895\n",
      "Validation loss: 8.364284634590149 RMSE: 2.8921072\n",
      "138 4 2.033379316329956\n",
      "Validation loss: 6.116712212562561 RMSE: 2.4731987\n",
      "Validation loss: 4.067933976650238 RMSE: 2.0169122\n",
      "Validation loss: 5.310504674911499 RMSE: 2.3044527\n",
      "141 3 1.7096061706542969\n",
      "Validation loss: 1.2207102179527283 RMSE: 1.1048576\n",
      "Validation loss: 4.561801373958588 RMSE: 2.135837\n",
      "Validation loss: 2.648259162902832 RMSE: 1.6273472\n",
      "144 2 0.7973589897155762\n",
      "Validation loss: 2.383908271789551 RMSE: 1.5439911\n",
      "Validation loss: 5.260348558425903 RMSE: 2.293545\n",
      "Validation loss: 4.5857884883880615 RMSE: 2.1414452\n",
      "147 1 0.9492155313491821\n",
      "Validation loss: 6.9498714208602905 RMSE: 2.6362607\n",
      "Validation loss: 3.611623227596283 RMSE: 1.9004271\n",
      "Validation loss: 2.5452182292938232 RMSE: 1.595374\n",
      "150 0 0.3967480957508087\n",
      "Validation loss: 3.5009982585906982 RMSE: 1.8710954\n",
      "Validation loss: 3.1697704792022705 RMSE: 1.7803854\n",
      "152 16 28.2015380859375\n",
      "Validation loss: 7.195996642112732 RMSE: 2.682536\n",
      "Validation loss: 2.9755430817604065 RMSE: 1.7249761\n",
      "Validation loss: 1.8819925785064697 RMSE: 1.3718574\n",
      "155 15 1.3871794939041138\n",
      "Validation loss: 9.145497441291809 RMSE: 3.0241523\n",
      "Validation loss: 2.7685552835464478 RMSE: 1.6638978\n",
      "Validation loss: 9.539920210838318 RMSE: 3.088676\n",
      "158 14 0.4960346817970276\n",
      "Validation loss: 1.184550404548645 RMSE: 1.0883704\n",
      "Validation loss: 4.768923878669739 RMSE: 2.1837866\n",
      "Validation loss: 4.139249265193939 RMSE: 2.0345144\n",
      "161 13 2.6640396118164062\n",
      "Validation loss: 3.756318509578705 RMSE: 1.9381224\n",
      "Validation loss: 2.733267068862915 RMSE: 1.6532598\n"
     ]
    }
   ],
   "source": [
    "seeds = list(range(777,782))\n",
    "# datasets = [\"bace\",  \"bbbp\", \"tox21\", \"toxcast\", \"sider\",  ]\n",
    "datasets = [\"freeSolv\",  \"lipo\", \"esol\", \"qm7\", \"bace\",  \"bbbp\", ]\n",
    "\n",
    "for dataset in datasets:\n",
    "    for seed in seeds: \n",
    "        !python finetuneRecon.py \\\n",
    "        --task_name {dataset} \\\n",
    "        --splitting scaffold \\\n",
    "        --seed {seed} \\\n",
    "        --alpha 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6764b07a-c44b-44d3-ab6b-161100c0d53b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'esol', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 751, 'task': 'regression', 'data_path': 'data/esol/esol.csv', 'target': ['measured log solubility in mols per litre']}}\n",
      "Running on: cuda:0\n",
      "1127\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/1127\n",
      "Generating scaffold 1000/1127\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "tensor([[ 0.0806, -0.0410, -0.0872,  ..., -0.0789, -0.0887, -0.1107],\n",
      "        [ 0.0313,  0.0164,  0.1077,  ..., -0.0785,  0.1171,  0.1046],\n",
      "        [-0.0002, -0.0291, -0.0762,  ...,  0.0110,  0.0630,  0.0511],\n",
      "        ...,\n",
      "        [ 0.0313,  0.0164,  0.1077,  ..., -0.0785,  0.1171,  0.1046],\n",
      "        [-0.0175,  0.1190, -0.0096,  ...,  0.0821,  0.0621,  0.0488],\n",
      "        [ 0.0313,  0.0164,  0.1077,  ..., -0.0785,  0.1171,  0.1046]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "0 0 8.955981254577637\n",
      "tensor([[ 0.0312,  0.0165,  0.1078,  ..., -0.0786,  0.1172,  0.1047],\n",
      "        [ 0.0312,  0.0165,  0.1078,  ..., -0.0786,  0.1172,  0.1047],\n",
      "        [ 0.0312,  0.0165,  0.1078,  ..., -0.0786,  0.1172,  0.1047],\n",
      "        ...,\n",
      "        [ 0.0312,  0.0165,  0.1078,  ..., -0.0786,  0.1172,  0.1047],\n",
      "        [ 0.0312,  0.0165,  0.1078,  ..., -0.0786,  0.1172,  0.1047],\n",
      "        [ 0.0312,  0.0165,  0.1078,  ..., -0.0786,  0.1172,  0.1047]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0004, -0.0289, -0.0764,  ...,  0.0108,  0.0629,  0.0509],\n",
      "        [-0.0004, -0.0289, -0.0764,  ...,  0.0108,  0.0629,  0.0509],\n",
      "        [-0.0004, -0.0289, -0.0764,  ...,  0.0108,  0.0629,  0.0509],\n",
      "        ...,\n",
      "        [ 0.0311,  0.0166,  0.1079,  ..., -0.0787,  0.1173,  0.1048],\n",
      "        [ 0.0311,  0.0166,  0.1079,  ..., -0.0787,  0.1173,  0.1048],\n",
      "        [ 0.0311,  0.0166,  0.1079,  ..., -0.0787,  0.1173,  0.1048]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0004, -0.0288, -0.0764,  ...,  0.0108,  0.0629,  0.0509],\n",
      "        [-0.0004, -0.0288, -0.0764,  ...,  0.0108,  0.0629,  0.0509],\n",
      "        [ 0.0311,  0.0167,  0.1079,  ..., -0.0788,  0.1174,  0.1048],\n",
      "        ...,\n",
      "        [ 0.0187, -0.0968, -0.0305,  ...,  0.0381, -0.0655, -0.0279],\n",
      "        [ 0.0311,  0.0167,  0.1079,  ..., -0.0788,  0.1174,  0.1048],\n",
      "        [ 0.0311,  0.0167,  0.1079,  ..., -0.0788,  0.1174,  0.1048]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0310,  0.0168,  0.1079,  ..., -0.0789,  0.1174,  0.1049],\n",
      "        [-0.0003, -0.0287, -0.0764,  ...,  0.0107,  0.0629,  0.0509],\n",
      "        [-0.0003, -0.0287, -0.0764,  ...,  0.0107,  0.0629,  0.0509],\n",
      "        ...,\n",
      "        [ 0.0310,  0.0168,  0.1079,  ..., -0.0789,  0.1174,  0.1049],\n",
      "        [ 0.0310,  0.0168,  0.1079,  ..., -0.0789,  0.1174,  0.1049],\n",
      "        [ 0.0310,  0.0168,  0.1079,  ..., -0.0789,  0.1174,  0.1049]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0309,  0.0168,  0.1080,  ..., -0.0789,  0.1175,  0.1050],\n",
      "        [ 0.0309,  0.0168,  0.1080,  ..., -0.0789,  0.1175,  0.1050],\n",
      "        [-0.0961, -0.0527,  0.0569,  ...,  0.0218, -0.0656,  0.0982],\n",
      "        ...,\n",
      "        [ 0.0309,  0.0168,  0.1080,  ..., -0.0789,  0.1175,  0.1050],\n",
      "        [-0.0961, -0.0527,  0.0569,  ...,  0.0218, -0.0656,  0.0982],\n",
      "        [ 0.0065, -0.1107,  0.0619,  ...,  0.0173,  0.0921, -0.0094]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0065, -0.1107,  0.0619,  ...,  0.0174,  0.0921, -0.0095],\n",
      "        [ 0.0065, -0.1107,  0.0619,  ...,  0.0174,  0.0921, -0.0095],\n",
      "        [ 0.0309,  0.0169,  0.1080,  ..., -0.0790,  0.1176,  0.1050],\n",
      "        ...,\n",
      "        [-0.0961, -0.0528,  0.0569,  ...,  0.0219, -0.0655,  0.0981],\n",
      "        [ 0.0309,  0.0169,  0.1080,  ..., -0.0790,  0.1176,  0.1050],\n",
      "        [ 0.0065, -0.1107,  0.0619,  ...,  0.0174,  0.0921, -0.0095]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0002, -0.0285, -0.0763,  ...,  0.0108,  0.0630,  0.0507],\n",
      "        [-0.0002, -0.0285, -0.0763,  ...,  0.0108,  0.0630,  0.0507],\n",
      "        [ 0.0309,  0.0169,  0.1081,  ..., -0.0791,  0.1177,  0.1051],\n",
      "        ...,\n",
      "        [ 0.0309,  0.0169,  0.1081,  ..., -0.0791,  0.1177,  0.1051],\n",
      "        [ 0.0309,  0.0169,  0.1081,  ..., -0.0791,  0.1177,  0.1051],\n",
      "        [-0.0123,  0.1087, -0.0120,  ...,  0.0790,  0.0517, -0.0861]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0961, -0.0528,  0.0569,  ...,  0.0220, -0.0653,  0.0979],\n",
      "        [-0.0961, -0.0528,  0.0569,  ...,  0.0220, -0.0653,  0.0979],\n",
      "        [ 0.0804, -0.0412, -0.0873,  ..., -0.0789, -0.0891, -0.1105],\n",
      "        ...,\n",
      "        [ 0.0309,  0.0170,  0.1081,  ..., -0.0791,  0.1178,  0.1052],\n",
      "        [ 0.0309,  0.0170,  0.1081,  ..., -0.0791,  0.1178,  0.1052],\n",
      "        [-0.0961, -0.0528,  0.0569,  ...,  0.0220, -0.0653,  0.0979]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0002, -0.0284, -0.0764,  ...,  0.0108,  0.0631,  0.0506],\n",
      "        [-0.0002, -0.0284, -0.0764,  ...,  0.0108,  0.0631,  0.0506],\n",
      "        [ 0.0309,  0.0170,  0.1082,  ..., -0.0792,  0.1179,  0.1052],\n",
      "        ...,\n",
      "        [ 0.0309,  0.0170,  0.1082,  ..., -0.0792,  0.1179,  0.1052],\n",
      "        [ 0.0309,  0.0170,  0.1082,  ..., -0.0792,  0.1179,  0.1052],\n",
      "        [ 0.0309,  0.0170,  0.1082,  ..., -0.0792,  0.1179,  0.1052]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0310,  0.0170,  0.1083,  ..., -0.0792,  0.1179,  0.1053],\n",
      "        [-0.0002, -0.0284, -0.0765,  ...,  0.0108,  0.0631,  0.0505],\n",
      "        [-0.0002, -0.0284, -0.0765,  ...,  0.0108,  0.0631,  0.0505],\n",
      "        ...,\n",
      "        [ 0.0310,  0.0170,  0.1083,  ..., -0.0792,  0.1179,  0.1053],\n",
      "        [ 0.0310,  0.0170,  0.1083,  ..., -0.0792,  0.1179,  0.1053],\n",
      "        [ 0.0310,  0.0170,  0.1083,  ..., -0.0792,  0.1179,  0.1053]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0310,  0.0171,  0.1083,  ..., -0.0793,  0.1179,  0.1054],\n",
      "        [ 0.0070, -0.1110,  0.0617,  ...,  0.0178,  0.0925, -0.0099],\n",
      "        [ 0.0310,  0.0171,  0.1083,  ..., -0.0793,  0.1179,  0.1054],\n",
      "        ...,\n",
      "        [ 0.0310,  0.0171,  0.1083,  ..., -0.0793,  0.1179,  0.1054],\n",
      "        [ 0.0310,  0.0171,  0.1083,  ..., -0.0793,  0.1179,  0.1054],\n",
      "        [-0.0961, -0.0529,  0.0568,  ...,  0.0223, -0.0651,  0.0977]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0309,  0.0171,  0.1084,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1084,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [-0.0961, -0.0529,  0.0568,  ...,  0.0223, -0.0650,  0.0976],\n",
      "        ...,\n",
      "        [ 0.0309,  0.0171,  0.1084,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1084,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1084,  ..., -0.0794,  0.1179,  0.1054]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0961, -0.0529,  0.0568,  ...,  0.0224, -0.0649,  0.0975],\n",
      "        [-0.0003, -0.0284, -0.0766,  ...,  0.0107,  0.0633,  0.0504],\n",
      "        [-0.0003, -0.0284, -0.0766,  ...,  0.0107,  0.0633,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0309,  0.0171,  0.1085,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [ 0.0071, -0.1112,  0.0617,  ...,  0.0179,  0.0926, -0.0100],\n",
      "        [ 0.0309,  0.0171,  0.1085,  ..., -0.0794,  0.1179,  0.1054]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0309,  0.0171,  0.1085,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1085,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1085,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        ...,\n",
      "        [ 0.0071, -0.1112,  0.0616,  ...,  0.0180,  0.0927, -0.0100],\n",
      "        [ 0.0309,  0.0171,  0.1085,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1085,  ..., -0.0794,  0.1179,  0.1054]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0309,  0.0171,  0.1086,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1086,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1086,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        ...,\n",
      "        [ 0.0309,  0.0171,  0.1086,  ..., -0.0794,  0.1179,  0.1054],\n",
      "        [-0.0962, -0.0529,  0.0568,  ...,  0.0225, -0.0647,  0.0974],\n",
      "        [-0.0127,  0.1084, -0.0120,  ...,  0.0788,  0.0512, -0.0857]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0309,  0.0171,  0.1087,  ..., -0.0795,  0.1179,  0.1054],\n",
      "        [-0.0002, -0.0284, -0.0766,  ...,  0.0107,  0.0632,  0.0503],\n",
      "        [-0.0002, -0.0284, -0.0766,  ...,  0.0107,  0.0632,  0.0503],\n",
      "        ...,\n",
      "        [ 0.0309,  0.0171,  0.1087,  ..., -0.0795,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1087,  ..., -0.0795,  0.1179,  0.1054],\n",
      "        [ 0.0309,  0.0171,  0.1087,  ..., -0.0795,  0.1179,  0.1054]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 3.0917e-02,  1.7134e-02,  1.0878e-01,  ..., -7.9471e-02,\n",
      "          1.1795e-01,  1.0532e-01],\n",
      "        [-1.1599e-04, -2.8463e-02, -7.6550e-02,  ...,  1.0742e-02,\n",
      "          6.3165e-02,  5.0226e-02],\n",
      "        [-1.1599e-04, -2.8463e-02, -7.6550e-02,  ...,  1.0742e-02,\n",
      "          6.3165e-02,  5.0226e-02],\n",
      "        ...,\n",
      "        [ 3.0917e-02,  1.7134e-02,  1.0878e-01,  ..., -7.9471e-02,\n",
      "          1.1795e-01,  1.0532e-01],\n",
      "        [ 3.0917e-02,  1.7134e-02,  1.0878e-01,  ..., -7.9471e-02,\n",
      "          1.1795e-01,  1.0532e-01],\n",
      "        [ 3.0917e-02,  1.7134e-02,  1.0878e-01,  ..., -7.9471e-02,\n",
      "          1.1795e-01,  1.0532e-01]], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0309,  0.0172,  0.1088,  ..., -0.0795,  0.1180,  0.1053],\n",
      "        [ 0.0309,  0.0172,  0.1088,  ..., -0.0795,  0.1180,  0.1053],\n",
      "        [ 0.0309,  0.0172,  0.1088,  ..., -0.0795,  0.1180,  0.1053],\n",
      "        ...,\n",
      "        [ 0.0074, -0.1113,  0.0618,  ...,  0.0180,  0.0929, -0.0100],\n",
      "        [ 0.0309,  0.0172,  0.1088,  ..., -0.0795,  0.1180,  0.1053],\n",
      "        [-0.0964, -0.0527,  0.0568,  ...,  0.0224, -0.0647,  0.0975]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-9.6424e-02, -5.2667e-02,  5.6764e-02,  ...,  2.2343e-02,\n",
      "         -6.4659e-02,  9.7490e-02],\n",
      "        [ 3.0807e-02,  1.7243e-02,  1.0880e-01,  ..., -7.9564e-02,\n",
      "          1.1803e-01,  1.0522e-01],\n",
      "        [-1.7022e-05, -2.8596e-02, -7.6470e-02,  ...,  1.0681e-02,\n",
      "          6.3049e-02,  5.0292e-02],\n",
      "        ...,\n",
      "        [ 3.0807e-02,  1.7243e-02,  1.0880e-01,  ..., -7.9564e-02,\n",
      "          1.1803e-01,  1.0522e-01],\n",
      "        [-1.7267e-02,  1.1858e-01, -1.0125e-02,  ...,  8.2536e-02,\n",
      "          6.1876e-02,  4.8307e-02],\n",
      "        [ 3.0807e-02,  1.7243e-02,  1.0880e-01,  ..., -7.9564e-02,\n",
      "          1.1803e-01,  1.0522e-01]], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 3.0753e-02,  1.7299e-02,  1.0883e-01,  ..., -7.9583e-02,\n",
      "          1.1807e-01,  1.0516e-01],\n",
      "        [ 3.0753e-02,  1.7299e-02,  1.0883e-01,  ..., -7.9583e-02,\n",
      "          1.1807e-01,  1.0516e-01],\n",
      "        [ 4.1295e-05, -2.8627e-02, -7.6411e-02,  ...,  1.0639e-02,\n",
      "          6.3006e-02,  5.0348e-02],\n",
      "        ...,\n",
      "        [ 3.0753e-02,  1.7299e-02,  1.0883e-01,  ..., -7.9583e-02,\n",
      "          1.1807e-01,  1.0516e-01],\n",
      "        [-1.2426e-02,  1.0806e-01, -1.2240e-02,  ...,  7.9107e-02,\n",
      "          5.1456e-02, -8.5975e-02],\n",
      "        [ 3.0753e-02,  1.7299e-02,  1.0883e-01,  ..., -7.9583e-02,\n",
      "          1.1807e-01,  1.0516e-01]], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0307,  0.0173,  0.1089,  ..., -0.0796,  0.1181,  0.1051],\n",
      "        [ 0.0307,  0.0173,  0.1089,  ..., -0.0796,  0.1181,  0.1051],\n",
      "        [ 0.0307,  0.0173,  0.1089,  ..., -0.0796,  0.1181,  0.1051],\n",
      "        ...,\n",
      "        [ 0.0076, -0.1114,  0.0619,  ...,  0.0181,  0.0930, -0.0100],\n",
      "        [ 0.0307,  0.0173,  0.1089,  ..., -0.0796,  0.1181,  0.1051],\n",
      "        [ 0.0307,  0.0173,  0.1089,  ..., -0.0796,  0.1181,  0.1051]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0307,  0.0174,  0.1089,  ..., -0.0796,  0.1181,  0.1051],\n",
      "        [ 0.0808, -0.0411, -0.0881,  ..., -0.0790, -0.0893, -0.1108],\n",
      "        [ 0.0076, -0.1113,  0.0619,  ...,  0.0181,  0.0930, -0.0100],\n",
      "        ...,\n",
      "        [ 0.0307,  0.0174,  0.1089,  ..., -0.0796,  0.1181,  0.1051],\n",
      "        [-0.0966, -0.0525,  0.0567,  ...,  0.0222, -0.0646,  0.0975],\n",
      "        [-0.0966, -0.0525,  0.0567,  ...,  0.0222, -0.0646,  0.0975]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0001, -0.0288, -0.0764,  ...,  0.0106,  0.0630,  0.0504],\n",
      "        [ 0.0898,  0.0321,  0.0691,  ...,  0.0426, -0.0070,  0.0773],\n",
      "        [ 0.0001, -0.0288, -0.0764,  ...,  0.0106,  0.0630,  0.0504],\n",
      "        ...,\n",
      "        [-0.0967, -0.0524,  0.0567,  ...,  0.0222, -0.0646,  0.0975],\n",
      "        [ 0.0307,  0.0174,  0.1089,  ..., -0.0797,  0.1182,  0.1051],\n",
      "        [-0.0967, -0.0524,  0.0567,  ...,  0.0222, -0.0646,  0.0975]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0968, -0.0523,  0.0567,  ...,  0.0222, -0.0646,  0.0974],\n",
      "        [ 0.0001, -0.0288, -0.0764,  ...,  0.0106,  0.0630,  0.0504],\n",
      "        [ 0.0001, -0.0288, -0.0764,  ...,  0.0106,  0.0630,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0307,  0.0174,  0.1090,  ..., -0.0797,  0.1182,  0.1052],\n",
      "        [-0.0968, -0.0523,  0.0567,  ...,  0.0222, -0.0646,  0.0974],\n",
      "        [ 0.0307,  0.0174,  0.1090,  ..., -0.0797,  0.1182,  0.1052]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0306,  0.0174,  0.1090,  ..., -0.0798,  0.1182,  0.1052],\n",
      "        [ 0.0001, -0.0289, -0.0764,  ...,  0.0106,  0.0630,  0.0504],\n",
      "        [ 0.0001, -0.0289, -0.0764,  ...,  0.0106,  0.0630,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0306,  0.0174,  0.1090,  ..., -0.0798,  0.1182,  0.1052],\n",
      "        [-0.0968, -0.0523,  0.0566,  ...,  0.0222, -0.0646,  0.0974],\n",
      "        [-0.0122,  0.1078, -0.0123,  ...,  0.0793,  0.0515, -0.0860]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0122,  0.1078, -0.0123,  ...,  0.0793,  0.0516, -0.0860],\n",
      "        [ 0.0306,  0.0174,  0.1091,  ..., -0.0798,  0.1182,  0.1053],\n",
      "        [ 0.0306,  0.0174,  0.1091,  ..., -0.0798,  0.1182,  0.1053],\n",
      "        ...,\n",
      "        [ 0.0306,  0.0174,  0.1091,  ..., -0.0798,  0.1182,  0.1053],\n",
      "        [ 0.0306,  0.0174,  0.1091,  ..., -0.0798,  0.1182,  0.1053],\n",
      "        [ 0.0306,  0.0174,  0.1091,  ..., -0.0798,  0.1182,  0.1053]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0306,  0.0174,  0.1091,  ..., -0.0799,  0.1182,  0.1053],\n",
      "        [-0.0121,  0.1078, -0.0122,  ...,  0.0793,  0.0516, -0.0860],\n",
      "        [ 0.0306,  0.0174,  0.1091,  ..., -0.0799,  0.1182,  0.1053],\n",
      "        ...,\n",
      "        [ 0.0306,  0.0174,  0.1091,  ..., -0.0799,  0.1182,  0.1053],\n",
      "        [ 0.0306,  0.0174,  0.1091,  ..., -0.0799,  0.1182,  0.1053],\n",
      "        [-0.0170,  0.1189, -0.0102,  ...,  0.0827,  0.0622,  0.0487]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0121,  0.1077, -0.0122,  ...,  0.0793,  0.0516, -0.0860],\n",
      "        [ 0.0305,  0.0174,  0.1092,  ..., -0.0799,  0.1182,  0.1053],\n",
      "        [ 0.0305,  0.0174,  0.1092,  ..., -0.0799,  0.1182,  0.1053],\n",
      "        ...,\n",
      "        [ 0.0305,  0.0174,  0.1092,  ..., -0.0799,  0.1182,  0.1053],\n",
      "        [ 0.0001, -0.0291, -0.0765,  ...,  0.0107,  0.0630,  0.0504],\n",
      "        [ 0.0001, -0.0291, -0.0765,  ...,  0.0107,  0.0630,  0.0504]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Validation loss: 2.2496231530619935 RMSE: 1.4998744\n",
      "tensor([[ 0.0305,  0.0174,  0.1092,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [-0.0970, -0.0521,  0.0565,  ...,  0.0224, -0.0646,  0.0973],\n",
      "        [ 0.0001, -0.0292, -0.0766,  ...,  0.0107,  0.0630,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0305,  0.0174,  0.1092,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [ 0.0305,  0.0174,  0.1092,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [ 0.0305,  0.0174,  0.1092,  ..., -0.0800,  0.1182,  0.1054]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0002, -0.0292, -0.0766,  ...,  0.0108,  0.0630,  0.0504],\n",
      "        [ 0.0305,  0.0174,  0.1092,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [ 0.0305,  0.0174,  0.1092,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        ...,\n",
      "        [ 0.0305,  0.0174,  0.1092,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [-0.0971, -0.0521,  0.0565,  ...,  0.0224, -0.0646,  0.0972],\n",
      "        [ 0.0078, -0.1111,  0.0621,  ...,  0.0182,  0.0933, -0.0101]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0971, -0.0521,  0.0565,  ...,  0.0224, -0.0647,  0.0972],\n",
      "        [ 0.0002, -0.0292, -0.0766,  ...,  0.0108,  0.0630,  0.0504],\n",
      "        [ 0.0002, -0.0292, -0.0766,  ...,  0.0108,  0.0630,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0305,  0.0174,  0.1093,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [ 0.0305,  0.0174,  0.1093,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [ 0.0078, -0.1111,  0.0621,  ...,  0.0182,  0.0934, -0.0101]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0304,  0.0174,  0.1093,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [ 0.0304,  0.0174,  0.1093,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [ 0.0002, -0.0293, -0.0766,  ...,  0.0108,  0.0630,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0304,  0.0174,  0.1093,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [ 0.0304,  0.0174,  0.1093,  ..., -0.0800,  0.1182,  0.1054],\n",
      "        [ 0.0304,  0.0174,  0.1093,  ..., -0.0800,  0.1182,  0.1054]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [-0.0120,  0.1077, -0.0121,  ...,  0.0793,  0.0515, -0.0860],\n",
      "        ...,\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [ 0.0809, -0.0410, -0.0884,  ..., -0.0791, -0.0894, -0.1111],\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [ 0.0003, -0.0293, -0.0766,  ...,  0.0108,  0.0631,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [-0.0120,  0.1076, -0.0121,  ...,  0.0793,  0.0515, -0.0860]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        ...,\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055],\n",
      "        [ 0.0304,  0.0174,  0.1094,  ..., -0.0800,  0.1182,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0304,  0.0174,  0.1095,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        [ 0.0304,  0.0174,  0.1095,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        [ 0.0304,  0.0174,  0.1095,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        ...,\n",
      "        [-0.0974, -0.0521,  0.0564,  ...,  0.0225, -0.0648,  0.0970],\n",
      "        [ 0.0233,  0.0582, -0.1101,  ...,  0.0704,  0.0737,  0.0701],\n",
      "        [-0.0974, -0.0521,  0.0564,  ...,  0.0225, -0.0648,  0.0970]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0303,  0.0174,  0.1095,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        [ 0.0303,  0.0174,  0.1095,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        [ 0.0003, -0.0294, -0.0767,  ...,  0.0108,  0.0631,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0303,  0.0174,  0.1095,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        [ 0.0303,  0.0174,  0.1095,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        [-0.0974, -0.0522,  0.0564,  ...,  0.0225, -0.0649,  0.0970]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0003, -0.0295, -0.0767,  ...,  0.0108,  0.0631,  0.0503],\n",
      "        [ 0.0003, -0.0295, -0.0767,  ...,  0.0108,  0.0631,  0.0503],\n",
      "        [ 0.0303,  0.0174,  0.1096,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        ...,\n",
      "        [ 0.0303,  0.0174,  0.1096,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        [ 0.0303,  0.0174,  0.1096,  ..., -0.0801,  0.1182,  0.1055],\n",
      "        [ 0.0303,  0.0174,  0.1096,  ..., -0.0801,  0.1182,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0303,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1055],\n",
      "        [ 0.0003, -0.0295, -0.0767,  ...,  0.0108,  0.0631,  0.0503],\n",
      "        [ 0.0003, -0.0295, -0.0767,  ...,  0.0108,  0.0631,  0.0503],\n",
      "        ...,\n",
      "        [-0.0167,  0.1191, -0.0102,  ...,  0.0827,  0.0622,  0.0491],\n",
      "        [-0.0167,  0.1191, -0.0102,  ...,  0.0827,  0.0622,  0.0491],\n",
      "        [ 0.0303,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0302,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1055],\n",
      "        [ 0.0004, -0.0296, -0.0768,  ...,  0.0108,  0.0631,  0.0503],\n",
      "        [ 0.0004, -0.0296, -0.0768,  ...,  0.0108,  0.0631,  0.0503],\n",
      "        ...,\n",
      "        [ 0.0302,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1055],\n",
      "        [ 0.0302,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1055],\n",
      "        [ 0.0302,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0079, -0.1110,  0.0623,  ...,  0.0182,  0.0935, -0.0101],\n",
      "        [-0.0976, -0.0523,  0.0563,  ...,  0.0225, -0.0650,  0.0970],\n",
      "        [ 0.0302,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0302,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0302,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0302,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0302,  0.0174,  0.1097,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0302,  0.0174,  0.1097,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0302,  0.0174,  0.1097,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        ...,\n",
      "        [-0.0977, -0.0523,  0.0563,  ...,  0.0225, -0.0649,  0.0970],\n",
      "        [ 0.0302,  0.0174,  0.1097,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0302,  0.0174,  0.1097,  ..., -0.0802,  0.1182,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [-0.0977, -0.0524,  0.0563,  ...,  0.0225, -0.0649,  0.0969],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0802,  0.1182,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0118,  0.1075, -0.0120,  ...,  0.0793,  0.0513, -0.0859],\n",
      "        [-0.0118,  0.1075, -0.0120,  ...,  0.0793,  0.0513, -0.0859],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0803,  0.1182,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0803,  0.1182,  0.1056],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0803,  0.1182,  0.1056],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0803,  0.1182,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0003, -0.0297, -0.0768,  ...,  0.0108,  0.0631,  0.0504],\n",
      "        [ 0.0003, -0.0297, -0.0768,  ...,  0.0108,  0.0631,  0.0504],\n",
      "        [ 0.0003, -0.0297, -0.0768,  ...,  0.0108,  0.0631,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0082, -0.1109,  0.0626,  ...,  0.0178,  0.0937, -0.0099],\n",
      "        [ 0.0301,  0.0174,  0.1096,  ..., -0.0803,  0.1181,  0.1056],\n",
      "        [ 0.0813, -0.0407, -0.0882,  ..., -0.0792, -0.0893, -0.1111]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0300,  0.0174,  0.1096,  ..., -0.0804,  0.1181,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0804,  0.1181,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0804,  0.1181,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0804,  0.1181,  0.1056],\n",
      "        [ 0.0082, -0.1109,  0.0626,  ...,  0.0178,  0.0938, -0.0099],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0804,  0.1181,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0002, -0.0298, -0.0769,  ...,  0.0107,  0.0631,  0.0504],\n",
      "        [ 0.0002, -0.0298, -0.0769,  ...,  0.0107,  0.0631,  0.0504],\n",
      "        [ 0.0002, -0.0298, -0.0769,  ...,  0.0107,  0.0631,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0804,  0.1181,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0804,  0.1181,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0804,  0.1181,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0300,  0.0174,  0.1096,  ..., -0.0805,  0.1181,  0.1055],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0805,  0.1181,  0.1055],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0805,  0.1181,  0.1055],\n",
      "        ...,\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0805,  0.1181,  0.1055],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0805,  0.1181,  0.1055],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0805,  0.1181,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0174,  0.1097,  ..., -0.0805,  0.1181,  0.1055],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0805,  0.1181,  0.1055],\n",
      "        [ 0.0001, -0.0298, -0.0769,  ...,  0.0107,  0.0631,  0.0504],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0805,  0.1181,  0.1055],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0805,  0.1181,  0.1055],\n",
      "        [ 0.0900,  0.0317,  0.0689,  ...,  0.0427, -0.0067,  0.0771]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "1 21 1.6086289882659912\n",
      "tensor([[ 0.0299,  0.0174,  0.1097,  ..., -0.0806,  0.1181,  0.1055],\n",
      "        [ 0.0083, -0.1108,  0.0627,  ...,  0.0176,  0.0939, -0.0098],\n",
      "        [ 0.0083, -0.1108,  0.0627,  ...,  0.0176,  0.0939, -0.0098],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0806,  0.1181,  0.1055],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0806,  0.1181,  0.1055],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0806,  0.1181,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0174,  0.1097,  ..., -0.0806,  0.1181,  0.1056],\n",
      "        [-0.0983, -0.0523,  0.0559,  ...,  0.0224, -0.0645,  0.0968],\n",
      "        [-0.0983, -0.0523,  0.0559,  ...,  0.0224, -0.0645,  0.0968],\n",
      "        ...,\n",
      "        [ 0.0083, -0.1107,  0.0627,  ...,  0.0175,  0.0939, -0.0097],\n",
      "        [-0.0983, -0.0523,  0.0559,  ...,  0.0224, -0.0645,  0.0968],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0806,  0.1181,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0174,  0.1097,  ..., -0.0807,  0.1182,  0.1056],\n",
      "        [ 0.0002, -0.0300, -0.0769,  ...,  0.0107,  0.0631,  0.0505],\n",
      "        [ 0.0002, -0.0300, -0.0769,  ...,  0.0107,  0.0631,  0.0505],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0807,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0807,  0.1182,  0.1056],\n",
      "        [ 0.0901,  0.0316,  0.0689,  ...,  0.0427, -0.0068,  0.0770]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0174,  0.1097,  ..., -0.0807,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0807,  0.1182,  0.1056],\n",
      "        [ 0.0003, -0.0300, -0.0769,  ...,  0.0106,  0.0631,  0.0506],\n",
      "        ...,\n",
      "        [ 0.0901,  0.0316,  0.0689,  ...,  0.0427, -0.0069,  0.0771],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0807,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0807,  0.1182,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0174,  0.1097,  ..., -0.0808,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0808,  0.1182,  0.1056],\n",
      "        [-0.0116,  0.1073, -0.0120,  ...,  0.0794,  0.0513, -0.0860],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0808,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0808,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0808,  0.1182,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0986, -0.0523,  0.0560,  ...,  0.0223, -0.0644,  0.0966],\n",
      "        [ 0.0299,  0.0175,  0.1097,  ..., -0.0808,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0175,  0.1097,  ..., -0.0808,  0.1182,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0175,  0.1097,  ..., -0.0808,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0175,  0.1097,  ..., -0.0808,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0175,  0.1097,  ..., -0.0808,  0.1182,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0082, -0.1106,  0.0628,  ...,  0.0174,  0.0939, -0.0098],\n",
      "        [-0.0987, -0.0523,  0.0560,  ...,  0.0223, -0.0644,  0.0966],\n",
      "        [ 0.0004, -0.0301, -0.0769,  ...,  0.0105,  0.0631,  0.0508],\n",
      "        ...,\n",
      "        [ 0.0004, -0.0301, -0.0769,  ...,  0.0105,  0.0631,  0.0508],\n",
      "        [ 0.0004, -0.0301, -0.0769,  ...,  0.0105,  0.0631,  0.0508],\n",
      "        [ 0.0004, -0.0301, -0.0769,  ...,  0.0105,  0.0631,  0.0508]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Validation loss: 17.010034324848547 RMSE: 4.1243224\n",
      "tensor([[ 0.0004, -0.0302, -0.0769,  ...,  0.0105,  0.0631,  0.0508],\n",
      "        [-0.0115,  0.1073, -0.0120,  ...,  0.0794,  0.0512, -0.0860],\n",
      "        [ 0.0299,  0.0175,  0.1096,  ..., -0.0809,  0.1182,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0082, -0.1106,  0.0628,  ...,  0.0174,  0.0939, -0.0097],\n",
      "        [ 0.0299,  0.0175,  0.1096,  ..., -0.0809,  0.1182,  0.1056],\n",
      "        [ 0.0299,  0.0175,  0.1096,  ..., -0.0809,  0.1182,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0175,  0.1096,  ..., -0.0809,  0.1181,  0.1056],\n",
      "        [ 0.0004, -0.0302, -0.0769,  ...,  0.0105,  0.0631,  0.0508],\n",
      "        [ 0.0004, -0.0302, -0.0769,  ...,  0.0105,  0.0631,  0.0508],\n",
      "        ...,\n",
      "        [-0.0989, -0.0523,  0.0560,  ...,  0.0224, -0.0644,  0.0966],\n",
      "        [ 0.0299,  0.0175,  0.1096,  ..., -0.0809,  0.1181,  0.1056],\n",
      "        [ 0.0299,  0.0175,  0.1096,  ..., -0.0809,  0.1181,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0175,  0.1096,  ..., -0.0810,  0.1181,  0.1056],\n",
      "        [ 0.0004, -0.0302, -0.0769,  ...,  0.0105,  0.0631,  0.0508],\n",
      "        [ 0.0004, -0.0302, -0.0769,  ...,  0.0105,  0.0631,  0.0508],\n",
      "        ...,\n",
      "        [-0.0989, -0.0523,  0.0560,  ...,  0.0225, -0.0644,  0.0966],\n",
      "        [ 0.0299,  0.0175,  0.1096,  ..., -0.0810,  0.1181,  0.1056],\n",
      "        [-0.0115,  0.1073, -0.0119,  ...,  0.0795,  0.0512, -0.0860]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0174,  0.1096,  ..., -0.0810,  0.1181,  0.1056],\n",
      "        [ 0.0004, -0.0303, -0.0770,  ...,  0.0104,  0.0630,  0.0508],\n",
      "        [ 0.0004, -0.0303, -0.0770,  ...,  0.0104,  0.0630,  0.0508],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0810,  0.1181,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0810,  0.1181,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0810,  0.1181,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056],\n",
      "        [-0.0115,  0.1073, -0.0118,  ...,  0.0795,  0.0512, -0.0859],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1096,  ..., -0.0811,  0.1180,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0300,  0.0174,  0.1096,  ..., -0.0811,  0.1179,  0.1056],\n",
      "        [-0.0993, -0.0524,  0.0558,  ...,  0.0228, -0.0645,  0.0966],\n",
      "        [ 0.0004, -0.0304, -0.0772,  ...,  0.0104,  0.0629,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0811,  0.1179,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0811,  0.1179,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0811,  0.1179,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056],\n",
      "        [-0.0115,  0.1073, -0.0117,  ...,  0.0795,  0.0512, -0.0859],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0994, -0.0524,  0.0558,  ...,  0.0229, -0.0646,  0.0966],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1179,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1178,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1178,  0.1056],\n",
      "        [ 0.0003, -0.0305, -0.0773,  ...,  0.0104,  0.0628,  0.0506],\n",
      "        ...,\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1178,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1178,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0812,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0995, -0.0524,  0.0558,  ...,  0.0229, -0.0646,  0.0966],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        ...,\n",
      "        [-0.0995, -0.0524,  0.0558,  ...,  0.0229, -0.0646,  0.0966],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0300,  0.0174,  0.1096,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0299,  0.0174,  0.1097,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0004, -0.0305, -0.0774,  ...,  0.0104,  0.0628,  0.0506],\n",
      "        [ 0.0004, -0.0305, -0.0774,  ...,  0.0104,  0.0628,  0.0506],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1097,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0165,  0.1185, -0.0105,  ...,  0.0828,  0.0629,  0.0487],\n",
      "        [ 0.0299,  0.0174,  0.1098,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0004, -0.0305, -0.0774,  ...,  0.0104,  0.0627,  0.0506],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1098,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1098,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1098,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0115,  0.1073, -0.0117,  ...,  0.0795,  0.0511, -0.0859],\n",
      "        [ 0.0299,  0.0174,  0.1098,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [-0.0997, -0.0524,  0.0558,  ...,  0.0230, -0.0647,  0.0966],\n",
      "        ...,\n",
      "        [ 0.0299,  0.0174,  0.1098,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1098,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0299,  0.0174,  0.1098,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0298,  0.0175,  0.1099,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        ...,\n",
      "        [-0.0998, -0.0524,  0.0558,  ...,  0.0230, -0.0647,  0.0966],\n",
      "        [ 0.0234,  0.0589, -0.1091,  ...,  0.0714,  0.0753,  0.0714],\n",
      "        [ 0.0808, -0.0412, -0.0879,  ..., -0.0785, -0.0889, -0.1103]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0004, -0.0305, -0.0774,  ...,  0.0103,  0.0626,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        ...,\n",
      "        [-0.0998, -0.0524,  0.0558,  ...,  0.0230, -0.0647,  0.0966],\n",
      "        [ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1100,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0005, -0.0305, -0.0774,  ...,  0.0103,  0.0626,  0.0507],\n",
      "        [ 0.0005, -0.0305, -0.0774,  ...,  0.0103,  0.0626,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0005, -0.0306, -0.0774,  ...,  0.0102,  0.0626,  0.0507],\n",
      "        [ 0.0005, -0.0306, -0.0774,  ...,  0.0102,  0.0626,  0.0507],\n",
      "        [ 0.0005, -0.0306, -0.0774,  ...,  0.0102,  0.0626,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.1000, -0.0523,  0.0557,  ...,  0.0230, -0.0646,  0.0964],\n",
      "        [ 0.0005, -0.0306, -0.0775,  ...,  0.0103,  0.0625,  0.0507],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0806, -0.0413, -0.0879,  ..., -0.0785, -0.0888, -0.1102],\n",
      "        [-0.1000, -0.0523,  0.0557,  ...,  0.0230, -0.0646,  0.0964],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0005, -0.0305, -0.0775,  ...,  0.0103,  0.0625,  0.0507],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0005, -0.0305, -0.0776,  ...,  0.0103,  0.0625,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0813,  0.1178,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [ 0.0005, -0.0305, -0.0776,  ...,  0.0103,  0.0625,  0.0507],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [-0.1001, -0.0524,  0.0557,  ...,  0.0231, -0.0646,  0.0963],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0112,  0.1071, -0.0116,  ...,  0.0795,  0.0511, -0.0860],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [ 0.0087, -0.1107,  0.0631,  ...,  0.0173,  0.0944, -0.0097],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [-0.1001, -0.0524,  0.0557,  ...,  0.0232, -0.0646,  0.0963],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.1001, -0.0524,  0.0556,  ...,  0.0232, -0.0645,  0.0963],\n",
      "        [-0.1001, -0.0524,  0.0556,  ...,  0.0232, -0.0645,  0.0963],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1102,  ..., -0.0812,  0.1177,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [ 0.0005, -0.0306, -0.0777,  ...,  0.0103,  0.0624,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [-0.1002, -0.0524,  0.0556,  ...,  0.0232, -0.0645,  0.0962],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1177,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.1002, -0.0524,  0.0556,  ...,  0.0233, -0.0645,  0.0962],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1177,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1177,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1176,  0.1056],\n",
      "        [ 0.0005, -0.0305, -0.0778,  ...,  0.0104,  0.0624,  0.0506],\n",
      "        [ 0.0089, -0.1107,  0.0631,  ...,  0.0172,  0.0945, -0.0097],\n",
      "        ...,\n",
      "        [-0.1002, -0.0524,  0.0556,  ...,  0.0233, -0.0645,  0.0962],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1176,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Validation loss: 3.044654910543324 RMSE: 1.744894\n",
      "tensor([[ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1176,  0.1056],\n",
      "        ...,\n",
      "        [-0.1002, -0.0523,  0.0556,  ...,  0.0233, -0.0645,  0.0962],\n",
      "        [ 0.0297,  0.0176,  0.1101,  ..., -0.0812,  0.1176,  0.1056],\n",
      "        [ 0.0089, -0.1107,  0.0632,  ...,  0.0171,  0.0946, -0.0098]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0005, -0.0306, -0.0779,  ...,  0.0104,  0.0623,  0.0507],\n",
      "        [ 0.0005, -0.0306, -0.0779,  ...,  0.0104,  0.0623,  0.0507],\n",
      "        [ 0.0297,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0005, -0.0306, -0.0779,  ...,  0.0105,  0.0622,  0.0507],\n",
      "        [ 0.0005, -0.0306, -0.0779,  ...,  0.0105,  0.0622,  0.0507],\n",
      "        [ 0.0005, -0.0306, -0.0779,  ...,  0.0105,  0.0622,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0175,  0.1100,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0175,  0.1100,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0175,  0.1100,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0175,  0.1100,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [-0.1002, -0.0523,  0.0556,  ...,  0.0233, -0.0645,  0.0962],\n",
      "        [ 0.0297,  0.0175,  0.1100,  ..., -0.0811,  0.1176,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0175,  0.1099,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [-0.1002, -0.0523,  0.0556,  ...,  0.0233, -0.0645,  0.0962],\n",
      "        [ 0.0005, -0.0306, -0.0779,  ...,  0.0105,  0.0621,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0811,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0811,  0.1176,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0113,  0.1071, -0.0114,  ...,  0.0795,  0.0511, -0.0859],\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0005, -0.0306, -0.0779,  ...,  0.0105,  0.0621,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0297,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0005, -0.0306, -0.0779,  ...,  0.0105,  0.0621,  0.0507],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [-0.1003, -0.0524,  0.0556,  ...,  0.0234, -0.0646,  0.0962],\n",
      "        [ 0.0297,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0909,  0.0324,  0.0702,  ...,  0.0420, -0.0075,  0.0781],\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [-0.1003, -0.0525,  0.0556,  ...,  0.0234, -0.0645,  0.0961],\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056],\n",
      "        [ 0.0298,  0.0175,  0.1099,  ..., -0.0810,  0.1176,  0.1056]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0298,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1055],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0811,  0.1176,  0.1055],\n",
      "        [-0.1004, -0.0525,  0.0556,  ...,  0.0234, -0.0645,  0.0961]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.1004, -0.0525,  0.0556,  ...,  0.0234, -0.0645,  0.0961],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1176,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1176,  0.1055],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1176,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1176,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1176,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0005, -0.0305, -0.0779,  ...,  0.0106,  0.0620,  0.0506],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [-0.1004, -0.0525,  0.0556,  ...,  0.0234, -0.0643,  0.0961],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        ...,\n",
      "        [ 0.0088, -0.1103,  0.0630,  ...,  0.0169,  0.0950, -0.0102],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "3 13 1.791797399520874\n",
      "tensor([[ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0239,  0.0583, -0.1088,  ...,  0.0713,  0.0755,  0.0716],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        ...,\n",
      "        [ 0.0089, -0.1103,  0.0630,  ...,  0.0169,  0.0951, -0.0102],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1055]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0910,  0.0325,  0.0701,  ...,  0.0420, -0.0072,  0.0780],\n",
      "        [ 0.0005, -0.0306, -0.0780,  ...,  0.0108,  0.0618,  0.0505],\n",
      "        [ 0.0005, -0.0306, -0.0780,  ...,  0.0108,  0.0618,  0.0505],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1054],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1054],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1175,  0.1054]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[-0.0111,  0.1072, -0.0113,  ...,  0.0795,  0.0512, -0.0859],\n",
      "        [-0.1005, -0.0524,  0.0556,  ...,  0.0235, -0.0642,  0.0960],\n",
      "        [ 0.0298,  0.0176,  0.1101,  ..., -0.0810,  0.1174,  0.1054],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0176,  0.1101,  ..., -0.0810,  0.1174,  0.1054],\n",
      "        [ 0.0298,  0.0176,  0.1101,  ..., -0.0810,  0.1174,  0.1054],\n",
      "        [ 0.0298,  0.0176,  0.1101,  ..., -0.0810,  0.1174,  0.1054]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([[ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1174,  0.1054],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1174,  0.1054],\n",
      "        [ 0.0005, -0.0306, -0.0780,  ...,  0.0108,  0.0617,  0.0505],\n",
      "        ...,\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1174,  0.1054],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1174,  0.1054],\n",
      "        [ 0.0298,  0.0176,  0.1100,  ..., -0.0810,  0.1174,  0.1054]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "seeds = [range(777,782)]\n",
    "for seed in seeds:\n",
    "    !python finetuneReconTop.py \\\n",
    "    --task_name bbbp \\\n",
    "    --splitting scaffold \\\n",
    "    --seed {seed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ce4ecd8-eaee-4c19-8a8d-195f56a1af16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
      "{'batch_size': 32, 'epochs': 1, 'eval_every_n_epochs': 1, 'fine_tune_from': 'pretrained_gin', 'log_every_n_steps': 50, 'fp16_precision': False, 'init_lr': 0.0005, 'init_base_lr': 0.0001, 'weight_decay': '1e-6', 'gpu': 'cuda:0', 'task_name': 'bbbp', 'model_type': 'gin', 'model': {'num_layer': 5, 'emb_dim': 300, 'feat_dim': 300, 'drop_ratio': 0.3, 'pool': 'mean'}, 'dataset': {'num_workers': 4, 'valid_size': 0.1, 'test_size': 0.1, 'splitting': 'scaffold', 'seed': 750, 'task': 'classification', 'data_path': 'data/bbbp/BBBP.csv', 'target': ['p_np']}}\n",
      "Running on: cuda:0\n",
      "2038\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/2038\n",
      "Generating scaffold 1000/2038\n",
      "Generating scaffold 2000/2038\n",
      "About to sort in scaffold sets\n",
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n",
      "0 0 5.474230766296387\n",
      "0 50 0.8621382713317871\n",
      "Validation loss: 0.7955456983809378 ROC AUC: 0.8099767080745343\n",
      "Loaded trained model with success.\n",
      "Test loss: 0.9124684696104012 Test ROC AUC: 0.645726948646305\n"
     ]
    }
   ],
   "source": [
    "!python finetuneReconTop.py \\\n",
    "--task_name bbbp \\\n",
    "--splitting scaffold \\\n",
    "--seed 750 \\\n",
    "--random_masking 1 \\\n",
    "--epochs 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066714a4-1761-414e-8f25-d0e70cd9a597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
