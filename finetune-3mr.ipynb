{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b0aed4-34de-4964-8ad8-dfaca1cc0d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "\n",
    "from dataset.dataset_test_rich2 import MolTestDatasetWrapperRich\n",
    "\n",
    "from dataset.get_config import get_config \n",
    "import argparse\n",
    "from torch_geometric.utils import  scatter, softmax\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c41f6a-013d-4dac-ab42-7397a7bfe63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n"
     ]
    }
   ],
   "source": [
    "apex_support = False\n",
    "try:\n",
    "    sys.path.append('./apex')\n",
    "    from apex import amp\n",
    "\n",
    "    apex_support = True\n",
    "except:\n",
    "    print(\"Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\")\n",
    "    apex_support = False\n",
    "\n",
    "\n",
    "def _save_config_file(model_checkpoints_folder):\n",
    "    if not os.path.exists(model_checkpoints_folder):\n",
    "        os.makedirs(model_checkpoints_folder)\n",
    "        shutil.copy('./config_finetune.yaml', os.path.join(model_checkpoints_folder, 'config_finetune.yaml'))\n",
    "\n",
    "def get_roc_auc_score(y_true, y_pred, is_valid):\n",
    "    roc_list = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        #AUC is only defined when there is at least one positive data.\n",
    "        if np.sum(y_true[:,i] == 1) > 0 and np.sum(y_true[:,i] == -1) > 0:\n",
    "            is_valid = y_true[:,i]**2 > 0\n",
    "            roc_list.append(roc_auc_score((y_true[is_valid,i] + 1)/2, y_pred[is_valid,i]))\n",
    "\n",
    "    if len(roc_list) < y_true.shape[1]:\n",
    "        print(\"Some target is missing!\")\n",
    "        print(\"Missing ratio: %f\" %(1 - float(len(roc_list))/y_true.shape[1]))\n",
    "\n",
    "    return  sum(roc_list)/len(roc_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Normalizer(object):\n",
    "    \"\"\"Normalize a Tensor and restore it later. \"\"\"\n",
    "\n",
    "    def __init__(self, tensor):\n",
    "        \"\"\"tensor is taken as a sample to calculate the mean and std\"\"\"\n",
    "        self.mean = torch.mean(tensor)\n",
    "        self.std = torch.std(tensor)\n",
    "\n",
    "    def norm(self, tensor):\n",
    "        return (tensor - self.mean) / self.std\n",
    "\n",
    "    def denorm(self, normed_tensor):\n",
    "        return normed_tensor * self.std + self.mean\n",
    "\n",
    "    def state_dict(self):\n",
    "        return {'mean': self.mean,\n",
    "                'std': self.std}\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.mean = state_dict['mean']\n",
    "        self.std = state_dict['std']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a86cb44-58ef-42cc-a2ed-37c26d40252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    batch_size = 32\n",
    "    epochs = 200\n",
    "    init_lr = 0.0005\n",
    "    init_base_lr = 0.0001\n",
    "    weight_decay = 1e-6\n",
    "    \n",
    "    gpu = 'cuda:1'\n",
    "    model_type = 'gin'\n",
    "    num_layer = 5\n",
    "    emb_dim = 300\n",
    "    feat_dim = 300\n",
    "    dropout = 0.3\n",
    "    pool = 'mean'\n",
    "    seed = '42'\n",
    "\n",
    "    task_name = '3mr'\n",
    "    splitting = 'scaffold'\n",
    "    random_masking = 1\n",
    "    mask_rate = 3\n",
    "    mask_edge = 0 \n",
    "    alpha = 0.1\n",
    "    reduceTrain = 1\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eee7561c-363f-4a42-8de5-b22b4beaba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(\"config_finetune.yaml\", \"r\"), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be0ac5f0-d577-4be4-8323-19c35dc647f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = args.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c18dcf43-bdee-40a9-a8f4-433029ba59cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['batch_size'] = args.batch_size\n",
    "config['epochs'] = args.epochs\n",
    "config['init_lr'] = args.init_lr\n",
    "config['init_base_lr'] = args.init_base_lr\n",
    "# config['weight_decay'] = args.weight_decay\n",
    "config['gpu'] = args.gpu   \n",
    "config['model']['num_layer'] = args.num_layer\n",
    "config['model']['emb_dim'] = args.emb_dim\n",
    "config['model']['feat_dim'] = args.feat_dim\n",
    "config['model']['drop_ratio'] = args.dropout\n",
    "config['model']['pool'] = args.pool\n",
    "\n",
    "config['task_name'] = args.task_name\n",
    "config['dataset']['seed'] = seed\n",
    "\n",
    "config['dataset']['splitting'] = args.splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dc712c3-244f-448e-9d43-99cddafaac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed =  int(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90a636dc-8159-4763-87f4-c6fe1ba50a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    config['task_name'] = config['task_name'].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1d988de-9285-4bef-ace9-6a3227fadaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb7ee7-1560-4c35-8fbb-631e03767bdc",
   "metadata": {},
   "source": [
    "### main으로 넘어옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d9f3d30-3e31-49a8-b3c5-f83379976148",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MolTestDatasetWrapperRich(config['batch_size'],\n",
    "                                **config['dataset'],\n",
    "                                random_masking=args.random_masking,\n",
    "                                mask_rate=args.mask_rate,\n",
    "                                mask_edge=args.mask_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf54e6d-2cef-45bf-88c7-479488ac5400",
   "metadata": {},
   "source": [
    "## step 과 test 옮기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a68709b-b6ca-4450-9800-d679ef74268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _get_device():\n",
    "        if torch.cuda.is_available() and config['gpu'] != 'cpu':\n",
    "            device = config['gpu']\n",
    "            torch.cuda.set_device(device)\n",
    "            args.deviceName = \"cuda\" + str(device[-1])\n",
    "\n",
    "        else:\n",
    "            device = 'cpu'\n",
    "            args.deviceName = 'cpu'\n",
    "\n",
    "        print(\"Running on:\", device)\n",
    "\n",
    "        return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8327c0cf-2d42-45fa-88ea-26f062449ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = _get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4237d4c3-d5dc-405a-85f1-8e68975ab766",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefilename = 'finetune3mrtop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43b775ad-1124-4987-b333-fc269fa324b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = {\n",
    "    \"recon\": {\n",
    "        \"loss_end\": [\"Multiline\", [\"loss_end/train\", \"loss_end/validation\"]],\n",
    "        \"loss_recon_node\" : [\"Multiline\", [\"loss_recon_node/train\"]],\n",
    "        \"loss_recon_edge\" : [\"Multiline\", [\"loss_recon_edge/train\"]],\n",
    "        \"loss_total\" : [\"Multiline\", [\"loss_total/train\", \"loss_total/validation\"]],\n",
    "        \"accuracy\": [\"Multiline\", [ \"accuracy/validation\"]],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e4b42a9-4ec6-414d-8fc1-895222979bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "dir_name =  savefilename + config['task_name'] + '_' + str(args.num_layer) + '_' \\\n",
    "+ str(args.emb_dim) + '_' + str(args.feat_dim)  + '_' + str(args.dropout) + '_' \\\n",
    "+ str(args.splitting) + '_' + str(args.deviceName) + '_' + str(args.seed) + '_' + str(current_time)\n",
    "\n",
    "log_dir = os.path.join('finetune', dir_name)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "writer.add_custom_scalars(layout)\n",
    "\n",
    "dataset = dataset\n",
    "if config['dataset']['task'] == 'classification':\n",
    "    criterion =  nn.BCEWithLogitsLoss(reduction = \"none\")\n",
    "elif config['dataset']['task'] == 'regression':\n",
    "    if config[\"task_name\"] in ['qm7', 'qm8', 'qm9']:\n",
    "        criterion = nn.L1Loss()\n",
    "    else:\n",
    "        criterion = nn.MSELoss()\n",
    "criterion_recon = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0db90373-846a-42e7-9ae5-a538f7e994f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['model']['mask_rate'] = args.mask_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "546abf17-3639-44d1-b445-d48e35ee8118",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2876\n",
      "About to generate scaffolds\n",
      "Generating scaffold 0/2876\n",
      "Generating scaffold 1000/2876\n",
      "Generating scaffold 2000/2876\n",
      "About to sort in scaffold sets\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, test_loader = dataset.get_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a67f5053-8b25-42fd-ab3b-6c3cebb02a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = None\n",
    "if config[\"task_name\"] in ['qm7', 'qm9']:\n",
    "    labels = []\n",
    "    for d  in train_loader:\n",
    "        labels.append(d.y)\n",
    "    labels = torch.cat(labels)\n",
    "    normalizer = Normalizer(labels)\n",
    "    print(normalizer.mean, normalizer.std, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "776348b9-60bf-4a23-8118-e8e2c6a1f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool\n",
    "\n",
    "num_atom_type = 120 # including the extra mask tokens\n",
    "num_chirality_tag = 3\n",
    "\n",
    "num_bond_type = 6 # including aromatic and self-loop edge\n",
    "num_bond_direction = 4\n",
    "\n",
    "from util import topk, bottomk\n",
    "\n",
    "\n",
    "class GINEConv(MessagePassing):\n",
    "    def __init__(self, emb_dim):\n",
    "        super(GINEConv, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim, 2*emb_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(2*emb_dim, emb_dim)\n",
    "        )\n",
    "        self.edge_embedding1 = nn.Embedding(num_bond_type, emb_dim)\n",
    "        self.edge_embedding2 = nn.Embedding(num_bond_direction, emb_dim)\n",
    "        self.edge_embedding3 = nn.Linear(8, emb_dim)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.edge_embedding1.weight.data)\n",
    "        nn.init.xavier_uniform_(self.edge_embedding2.weight.data)\n",
    "        nn.init.xavier_uniform_(self.edge_embedding3.weight.data)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # add self loops in the edge space\n",
    "        edge_index = add_self_loops(edge_index, num_nodes=x.size(0))[0]\n",
    "\n",
    "        # add features corresponding to self-loop edges.\n",
    "        self_loop_attr = torch.zeros(x.size(0), 10)\n",
    "        self_loop_attr[:,0] = 4 # bond type for self-loop edge\n",
    "        self_loop_attr = self_loop_attr.to(edge_attr.device).to(edge_attr.dtype)\n",
    "\n",
    "        edge_attr = torch.cat((edge_attr, self_loop_attr), dim=0)\n",
    "        \n",
    "\n",
    "        edge_embeddings = self.edge_embedding1(edge_attr[:,0]) + \\\n",
    "            self.edge_embedding2(edge_attr[:,1])  + self.edge_embedding3(edge_attr[:,2:].float())\n",
    "\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_embeddings)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        return x_j + edge_attr\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return self.mlp(aggr_out)\n",
    "\n",
    "\n",
    "\n",
    "class GINetRecon_rich_top(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        num_layer (int): the number of GNN layers\n",
    "        emb_dim (int): dimensionality of embeddings\n",
    "        drop_ratio (float): dropout rate\n",
    "        gnn_type: gin, gcn, graphsage, gat\n",
    "    Output:\n",
    "        node representations\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "        task='classification', num_layer=5, emb_dim=300, feat_dim=512, \n",
    "        drop_ratio=0, pool='mean', pred_n_layer=2, pred_act='softplus', num_task = 1, mask_rate = None,\n",
    "    ):\n",
    "        super(GINetRecon_rich_top, self).__init__()\n",
    "        self.num_layer = num_layer\n",
    "        self.emb_dim = emb_dim\n",
    "        self.feat_dim = feat_dim\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.task = task\n",
    "        self.num_task = num_task\n",
    "        self.mask_rate = mask_rate\n",
    "\n",
    "        self.x_embedding1 = nn.Embedding(num_atom_type, emb_dim)\n",
    "        self.x_embedding2 = nn.Embedding(num_chirality_tag, emb_dim)\n",
    "        self.x_embedding3 = nn.Linear(40, emb_dim)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.x_embedding1.weight.data)\n",
    "        nn.init.xavier_uniform_(self.x_embedding2.weight.data)\n",
    "        nn.init.xavier_uniform_(self.x_embedding3.weight.data)\n",
    "\n",
    "\n",
    "        # List of MLPs\n",
    "        self.gnns = nn.ModuleList()\n",
    "        for layer in range(num_layer):\n",
    "            self.gnns.append(GINEConv(emb_dim))\n",
    "\n",
    "        # List of batchnorms\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        for layer in range(num_layer):\n",
    "            self.batch_norms.append(nn.BatchNorm1d(emb_dim))\n",
    "\n",
    "        if pool == 'mean':\n",
    "            self.pool = global_mean_pool\n",
    "        elif pool == 'max':\n",
    "            self.pool = global_max_pool\n",
    "        elif pool == 'add':\n",
    "            self.pool = global_add_pool\n",
    "        self.feat_lin = nn.Linear(self.emb_dim + 200, self.feat_dim)\n",
    "\n",
    "\n",
    "        \n",
    "        self.pred_n_layer = max(1, pred_n_layer)\n",
    "\n",
    "        if pred_act == 'relu':\n",
    "            pred_head = [\n",
    "                nn.Linear(self.feat_dim, self.feat_dim//2), \n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            for _ in range(self.pred_n_layer - 1):\n",
    "                pred_head.extend([\n",
    "                    nn.Linear(self.feat_dim//2, self.feat_dim//2), \n",
    "                    nn.ReLU(inplace=True),\n",
    "                ])\n",
    "            pred_head.append(nn.Linear(self.feat_dim//2, num_task))\n",
    "\n",
    "        elif pred_act == 'softplus':\n",
    "            pred_head = [\n",
    "                nn.Linear(self.feat_dim, self.feat_dim//2), \n",
    "                nn.Softplus()\n",
    "            ]\n",
    "            for _ in range(self.pred_n_layer - 1):\n",
    "                pred_head.extend([\n",
    "                    nn.Linear(self.feat_dim//2, self.feat_dim//2), \n",
    "                    nn.Softplus()\n",
    "                ])\n",
    "        else:\n",
    "            raise ValueError('Undefined activation function')\n",
    "        \n",
    "        self.dense_score = nn.Linear(self.feat_dim, 1)  # for node score\n",
    "\n",
    "        pred_head.append(nn.Linear(self.feat_dim//2, num_task))\n",
    "        self.pred_head = nn.Sequential(*pred_head)\n",
    "\n",
    "    def forward(self, data, mask_rate = None, rank_method = 'topk'):\n",
    "\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        x_add = data.x_add\n",
    "        \n",
    "\n",
    "\n",
    "        h = self.x_embedding1(x[:,0].long()) + self.x_embedding2(x[:,1].long()) + self.x_embedding3(x[:,2:].float()) \n",
    "\n",
    "        for layer in range(self.num_layer):\n",
    "            h = self.gnns[layer](h, edge_index, edge_attr)\n",
    "            h = self.batch_norms[layer](h)\n",
    "            if layer == self.num_layer - 1:\n",
    "                h = F.dropout(h, self.drop_ratio, training=self.training)\n",
    "            else:\n",
    "                h = F.dropout(F.relu(h), self.drop_ratio, training=self.training)\n",
    "\n",
    "        h_node = h\n",
    "\n",
    "        h  = self.pool(h, data.batch)\n",
    "\n",
    "        h = torch.cat((h, x_add), dim=1)\n",
    "\n",
    "        h = self.feat_lin(h)\n",
    "\n",
    "        if  mask_rate is not None:\n",
    "            score = self.dense_score(h_node).squeeze()\n",
    "\n",
    "            mask_rate = float(mask_rate)\n",
    "\n",
    "            if rank_method == 'topk':\n",
    "                node = topk(score, mask_rate, batch = data.batch) \n",
    "            elif rank_method == 'bottomk':\n",
    "                node = bottomk(score, mask_rate, batch = data.batch)\n",
    "\n",
    "            return  h_node, self.pred_head(h), node\n",
    "        \n",
    "        else:\n",
    "\n",
    "            return  h_node, self.pred_head(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3767c452-a32a-4fcc-8b44-530b2caeae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = GINetRecon_rich_top(config['dataset']['task'], **config[\"model\"]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06db7d6f-bd6e-4a03-93fc-519b2a754a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_head.0.weight True\n",
      "pred_head.0.bias True\n",
      "pred_head.2.weight True\n",
      "pred_head.2.bias True\n",
      "pred_head.4.weight True\n",
      "pred_head.4.bias True\n"
     ]
    }
   ],
   "source": [
    "layer_list = []\n",
    "for name, param in model.named_parameters():\n",
    "    if 'pred_head' in name:\n",
    "        print(name, param.requires_grad)\n",
    "        layer_list.append(name)\n",
    "\n",
    "params = list(map(lambda x: x[1],list(filter(lambda kv: kv[0] in layer_list, model.named_parameters()))))\n",
    "base_params = list(map(lambda x: x[1],list(filter(lambda kv: kv[0] not in layer_list, model.named_parameters()))))\n",
    "\n",
    "linear_pred_atoms = torch.nn.Linear(args.emb_dim, 119).to(device)\n",
    "linear_pred_bonds = torch.nn.Linear(args.emb_dim, 4).to(device)\n",
    "\n",
    "\n",
    "optimizer_model = torch.optim.Adam(\n",
    "    [{'params': base_params, 'lr': config['init_base_lr']}, {'params': params}],\n",
    "    config['init_lr'], weight_decay=eval(config['weight_decay'])\n",
    ")\n",
    "\n",
    "optimizer_linear_pred_atoms = torch.optim.Adam(linear_pred_atoms.parameters(), lr=args.init_base_lr, weight_decay=args.weight_decay)\n",
    "optimizer_linear_pred_bonds = torch.optim.Adam(linear_pred_bonds.parameters(), lr=args.init_base_lr, weight_decay=args.weight_decay)\n",
    "\n",
    "model_list = [model, linear_pred_atoms, linear_pred_bonds]\n",
    "optimizer_list = [optimizer_model, optimizer_linear_pred_atoms, optimizer_linear_pred_bonds]\n",
    "\n",
    "if apex_support and config['fp16_precision']:\n",
    "    model, optimizer = amp.initialize(\n",
    "        model, optimizer, opt_level='O2', keep_batchnorm_fp32=True\n",
    "    )\n",
    "\n",
    "model_checkpoints_folder = os.path.join(writer.log_dir, 'checkpoints')\n",
    "\n",
    "# save config file\n",
    "_save_config_file(model_checkpoints_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3eff6f96-fc93-4063-9f66-ae7dfcdcddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _step( model_list, data, n_iter):\n",
    "        model, linear_pred_atoms, linear_pred_bonds = model_list\n",
    "\n",
    "\n",
    "        num_atom_type = 119\n",
    "        num_edge_type = 4\n",
    "\n",
    "        # get the prediction\n",
    "        node_rep, pred,node_top = model(data,3 )  # [N,C]\n",
    "\n",
    " \n",
    "        mask_node_labels_list = []\n",
    "        for atom_idx in node_top:\n",
    "            mask_node_labels_list.append(data.x[atom_idx].view(1, -1))\n",
    "\n",
    "        mask_node_label = torch.cat(mask_node_labels_list, dim=0)\n",
    "        masked_atom_indices = torch.tensor(node_top)\n",
    "\n",
    "        masked_x = data.x.clone()\n",
    "\n",
    "        for atom_idx in masked_atom_indices:\n",
    "            masked_x[atom_idx] = torch.zeros(42).to(device)\n",
    "            masked_x[atom_idx, 0] = num_atom_type\n",
    "\n",
    "\n",
    "        if args.mask_edge:\n",
    "            # edge_index 찾기\n",
    "            connected_edge_indices = []\n",
    "            for bond_idx, (u, v) in enumerate(data.edge_index.cpu().numpy().T):\n",
    "                for atom_idx in masked_atom_indices:\n",
    "                    if atom_idx in set((u, v)) and \\\n",
    "                        bond_idx not in connected_edge_indices:\n",
    "                        connected_edge_indices.append(bond_idx)\n",
    "\n",
    "            if len(connected_edge_indices) > 0:\n",
    "                # create mask edge labels by copying bond features of the bonds connected to\n",
    "                # the mask atoms\n",
    "                mask_edge_labels_list = []\n",
    "                for bond_idx in connected_edge_indices[::2]: # because the\n",
    "                    # edge ordering is such that two directions of a single\n",
    "                    # edge occur in pairs, so to get the unique undirected\n",
    "                    \n",
    "                    # edge indices, we take every 2nd edge index from list\n",
    "                    mask_edge_labels_list.append(\n",
    "                        data.edge_attr[bond_idx].view(1, -1))\n",
    "\n",
    "                mask_edge_label = torch.cat(mask_edge_labels_list, dim=0)\n",
    "                # modify the original bond features of the bonds connected to the mask atoms\n",
    "\n",
    "                connected_edge_indices = torch.tensor(\n",
    "                    connected_edge_indices[::2])\n",
    "            else:\n",
    "                mask_edge_label = torch.empty((0, 2)).to(torch.int64)\n",
    "                connected_edge_indices = torch.tensor(\n",
    "                    connected_edge_indices).to(torch.int64)\n",
    "\n",
    "            # 데이터 마스킹 하고 예측하기   \n",
    "            masked_edge_attr = data.edge_attr.clone()\n",
    "\n",
    "            for edge_idx in connected_edge_indices:\n",
    "                masked_edge_attr[edge_idx] = torch.tensor([num_edge_type, 0]).to(device)\n",
    "\n",
    "            masked_edge_index = data.edge_index[:, data.connected_edge_indices]\n",
    "\n",
    "            masked_data = Data(x = masked_x ,edge_index = data.edge_index, edge_attr = masked_edge_attr) \n",
    "\n",
    "            node_rep_masked, output2_masked = model(data)\n",
    "\n",
    "            # edge_rep      \n",
    "            edge_rep = node_rep_masked[masked_edge_index[0]] + node_rep_masked[masked_edge_index[1]]\n",
    "            pred_edge = linear_pred_bonds(edge_rep)\n",
    "           \n",
    "            loss_recon_edge = criterion_recon(pred_edge.double(),  mask_edge_label[:,0])\n",
    "\n",
    "\n",
    "            pred_node = linear_pred_atoms(node_rep_masked[masked_atom_indices])\n",
    "            loss_recon_node = criterion_recon(pred_node.float(), data.mask_node_label[:,0])\n",
    "        \n",
    "        else: \n",
    "            masked_data = Data(x =  masked_x ,edge_index = data.edge_index, edge_attr = data.edge_attr, x_add = data.x_add, batch = data.batch) \n",
    "\n",
    "            node_repre2, output2_masked= model(masked_data, mask_rate = None)\n",
    "            \n",
    "            pred_node = linear_pred_atoms(node_repre2[masked_atom_indices])\n",
    "            loss_recon_node = criterion_recon(pred_node.double(), mask_node_label[:,0].long())\n",
    "\n",
    "        if config['dataset']['task'] == 'classification':\n",
    "\n",
    "            is_valid = data.y**2 > 0\n",
    "            \n",
    "            loss_mat = criterion(pred, (data.y+1)/2)\n",
    "            loss_mat = torch.where(is_valid, loss_mat, torch.zeros(loss_mat.shape).to(loss_mat.device).to(loss_mat.dtype))\n",
    "\n",
    "\n",
    "            loss = torch.sum(loss_mat) / torch.sum(is_valid)\n",
    "\n",
    "\n",
    "\n",
    "        elif config['dataset']['task'] == 'regression':\n",
    "            if normalizer:\n",
    "                loss = criterion(pred, normalizer.norm(data.y))\n",
    "            else:\n",
    "                loss = criterion(pred, data.y)\n",
    "\n",
    "        \n",
    "        if args.mask_edge:\n",
    "            total_loss = loss + args.alpha * (loss_recon_node + loss_recon_edge)\n",
    "            return pred, total_loss, loss, loss_recon_node, loss_recon_edge\n",
    "        else:\n",
    "            total_loss = loss + args.alpha * loss_recon_node\n",
    "            return pred, total_loss, loss, loss_recon_node, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e186794f-34b6-48d8-8e62-977bec846cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _step_test(model, data, n_iter):\n",
    "    # get the prediction\n",
    "    __, pred = model(data)  # [N,C]\n",
    "\n",
    "    if config['dataset']['task'] == 'classification':\n",
    "\n",
    "        is_valid = data.y**2 > 0\n",
    "\n",
    "        loss_mat = criterion(pred, (data.y+1)/2)\n",
    "        loss_mat = torch.where(is_valid, loss_mat, torch.zeros(loss_mat.shape).to(loss_mat.device).to(loss_mat.dtype))\n",
    "\n",
    "\n",
    "        loss = torch.sum(loss_mat) / torch.sum(is_valid)\n",
    "\n",
    "    elif config['dataset']['task'] == 'regression':\n",
    "        if normalizer:\n",
    "            loss = criterion(pred, normalizer.norm(data.y))\n",
    "        else:\n",
    "            loss = criterion(pred, data.y)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def _validate( model_list, valid_loader):\n",
    "    model, linear_pred_atoms, linear_pred_bonds = model_list\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        linear_pred_atoms.eval()\n",
    "        linear_pred_bonds.eval()\n",
    "\n",
    "\n",
    "\n",
    "        valid_loss = 0.0\n",
    "        num_data = 0\n",
    "        for bn, data in enumerate(valid_loader):\n",
    "            data = data.to(device)\n",
    "\n",
    "            __, pred = model(data)\n",
    "            loss = _step_test(model, data, bn)\n",
    "\n",
    "            valid_loss += loss.item() * data.y.size(0)\n",
    "            num_data += data.y.size(0)\n",
    "\n",
    "            if normalizer:\n",
    "                pred = normalizer.denorm(pred)\n",
    "\n",
    "            if config['dataset']['task'] == 'classification':\n",
    "                \n",
    "                labels.append(data.y.view(pred.shape))\n",
    "                predictions.append(pred)\n",
    "\n",
    "            else:\n",
    "                if device == 'cpu':\n",
    "                    predictions.extend(pred.detach().numpy())\n",
    "                    labels.extend(data.y.flatten().numpy())\n",
    "                else:\n",
    "                    predictions.extend(pred.cpu().detach().numpy())\n",
    "                    labels.extend(data.y.cpu().flatten().numpy())\n",
    "\n",
    "        valid_loss /= num_data\n",
    "    \n",
    "    model.train()\n",
    "    linear_pred_atoms.train()\n",
    "    linear_pred_bonds.train()\n",
    "\n",
    "\n",
    "    if config['dataset']['task'] == 'regression':\n",
    "        predictions = np.array(predictions)\n",
    "        labels = np.array(labels)\n",
    "        if config['task_name'] in ['qm7', 'qm8', 'qm9']:\n",
    "            mae = mean_absolute_error(labels, predictions)\n",
    "            print('Validation loss:', valid_loss, 'MAE:', mae)\n",
    "            return valid_loss, mae\n",
    "        else:\n",
    "            rmse = root_mean_squared_error(labels, predictions, )\n",
    "            print('Validation loss:', valid_loss, 'RMSE:', rmse)\n",
    "            return valid_loss, rmse\n",
    "\n",
    "    elif config['dataset']['task'] == 'classification':\n",
    "        \n",
    "        labels = torch.cat(labels, dim=0).cpu().numpy()\n",
    "        predictions = torch.cat(predictions, dim=0).cpu().detach().numpy()\n",
    "\n",
    "        is_valid = labels**2 > 0\n",
    "        roc_auc = get_roc_auc_score(labels, predictions, is_valid)\n",
    "        print('Validation loss:', valid_loss, 'ROC AUC:', roc_auc)\n",
    "        return valid_loss, roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5531a68-1f36-429f-8381-853603308f07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.014037195985841598\n",
      "0 50 0.3151921223094337\n",
      "Validation loss: 0.05285738160212835 ROC AUC: 0.9997326203208556\n",
      "1 28 0.10194165907438743\n",
      "Validation loss: 0.049250520662301116 ROC AUC: 1.0\n",
      "2 6 0.019869464899683668\n",
      "2 56 0.02764710179027557\n",
      "Validation loss: 0.029294417317335803 ROC AUC: 1.0\n",
      "3 34 0.026655240497225716\n",
      "Validation loss: 0.015766658523716615 ROC AUC: 1.0\n",
      "4 12 0.026906578997952558\n",
      "4 62 0.026033845439365762\n",
      "Validation loss: 0.018133596879326634 ROC AUC: 1.0\n",
      "5 40 0.01854728865253659\n",
      "Validation loss: 0.09059055681831928 ROC AUC: 1.0\n",
      "6 18 0.017252193945484218\n",
      "6 68 0.015022678818879124\n",
      "Validation loss: 0.001097645701116158 ROC AUC: 1.0\n",
      "7 46 0.02914288134867304\n",
      "Validation loss: 0.1433944098042856 ROC AUC: 0.9923796791443851\n",
      "8 24 0.01821323148219973\n",
      "Validation loss: 0.01621436920989557 ROC AUC: 1.0\n",
      "9 2 0.019156410954065593\n",
      "9 52 0.005356572291744472\n",
      "Validation loss: 0.010616890519271591 ROC AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "n_iter = 0\n",
    "valid_n_iter = 0\n",
    "best_valid_loss = np.inf\n",
    "best_valid_rgr = np.inf\n",
    "best_valid_cls = 0\n",
    "\n",
    "# for epoch_counter in range(config['epochs']):\n",
    "for epoch_counter in range(10):\n",
    "    \n",
    "    for bn, data in enumerate(train_loader):\n",
    "        predictions = []\n",
    "        labels = []\n",
    "\n",
    "        optimizer_model.zero_grad()\n",
    "        optimizer_linear_pred_atoms.zero_grad()\n",
    "        if args.mask_edge:\n",
    "            optimizer_linear_pred_bonds.zero_grad()\n",
    "\n",
    "        data = data.to(device)\n",
    "        pred, total_loss, loss_end, loss_recon, loss_recon_edge = _step(model_list, data, n_iter)\n",
    "\n",
    "        if n_iter % config['log_every_n_steps'] == 0:\n",
    "            # writer.add_scalar('loss_total/train', total_loss, global_step=n_iter)\n",
    "            writer.add_scalar('loss_total/train_loss_total', total_loss, epoch_counter)\n",
    "            writer.add_scalar('loss_end/train_loss_end', loss_end, epoch_counter)\n",
    "            writer.add_scalar('loss_recon_node/train_loss_recon_node', loss_recon, epoch_counter)\n",
    "            writer.add_scalar('loss_recon_edge/train_loss_recon_edge', loss_recon_edge, epoch_counter)\n",
    "        \n",
    "\n",
    "            print(epoch_counter, bn, total_loss.item())\n",
    "\n",
    "        if apex_support and config['fp16_precision']:\n",
    "            with amp.scale_loss(total_loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            total_loss.backward()\n",
    "\n",
    "        optimizer_model.step()\n",
    "        optimizer_linear_pred_atoms.step()\n",
    "        if args.mask_edge:\n",
    "            optimizer_linear_pred_bonds.step()\n",
    "\n",
    "        n_iter += 1\n",
    "\n",
    "\n",
    "    # validate the model if requested\n",
    "    if epoch_counter % config['eval_every_n_epochs'] == 0:\n",
    "        if config['dataset']['task'] == 'classification': \n",
    "\n",
    "\n",
    "            valid_loss, valid_cls = _validate(model_list, valid_loader)\n",
    "            if valid_cls > best_valid_cls:\n",
    "                # save the model weights\n",
    "                best_valid_cls = valid_cls\n",
    "                torch.save(model.state_dict(), os.path.join(model_checkpoints_folder, 'model.pth'))\n",
    "\n",
    "            writer.add_scalar('accuracy/validation', valid_cls, epoch_counter)\n",
    "        elif config['dataset']['task'] == 'regression':\n",
    "\n",
    "     \n",
    "            valid_loss, valid_rgr = _validate(model_list, valid_loader)\n",
    "            if valid_rgr < best_valid_rgr:\n",
    "                # save the model weights\n",
    "                best_valid_rgr = valid_rgr\n",
    "                torch.save(model.state_dict(), os.path.join(model_checkpoints_folder, 'model.pth'))\n",
    "            writer.add_scalar('accuracy/validation', valid_rgr, epoch_counter)\n",
    "\n",
    "        writer.add_scalar('loss_end/validation_loss_end', valid_loss, epoch_counter)\n",
    "        writer.add_scalar('loss_total/validation_loss_total', valid_loss, epoch_counter)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        valid_n_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "48fbeed4-1a0b-4424-9dab-4da50d5b1db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trained model with success.\n"
     ]
    }
   ],
   "source": [
    "    model_path = os.path.join(writer.log_dir, 'checkpoints', 'model.pth')\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(\"Loaded trained model with success.\")\n",
    "\n",
    "    num_atom_type = 119\n",
    "    num_edge_type = 4\n",
    "\n",
    "    predictions_node = []\n",
    "    labels_node = []\n",
    "    predictions_edge = []\n",
    "    labels_edge = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "91b502d3-dc36-4eb0-b947-d70127ac78a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_atom_type = 119\n",
    "num_edge_type = 4\n",
    "\n",
    "predictions_node = []\n",
    "labels_node = []\n",
    "predictions_edge = []\n",
    "labels_edge = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    linear_pred_atoms.eval()\n",
    "    linear_pred_bonds.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572eba5b-4717-47e5-914e-ee4beb6f1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdchem import HybridizationType\n",
    "from rdkit.Chem.rdchem import BondType as BT\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Scaffolds.MurckoScaffold import MurckoScaffoldSmiles\n",
    "from rdkit import RDLogger\n",
    "\n",
    "ATOM_LIST = list(range(1,119))\n",
    "CHIRALITY_LIST = [\n",
    "    Chem.rdchem.ChiralType.CHI_UNSPECIFIED,\n",
    "    Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
    "    Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CCW,\n",
    "    Chem.rdchem.ChiralType.CHI_OTHER\n",
    "]\n",
    "BOND_LIST = [BT.SINGLE, BT.DOUBLE, BT.TRIPLE, BT.AROMATIC]\n",
    "BONDDIR_LIST = [\n",
    "    Chem.rdchem.BondDir.NONE,\n",
    "    Chem.rdchem.BondDir.ENDUPRIGHT,\n",
    "    Chem.rdchem.BondDir.ENDDOWNRIGHT\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "28aa340e-3bad-4eba-8659-bde0fa616b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = 'COc1cccc(C2OC2C(=O)c2cc3c(cc2N)OCO3)c1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "68434d95-81ac-45b6-a011-efc20bc833c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = Chem.MolFromSmiles(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aa1e47be-56b9-4f6d-bfe9-9951292938c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classification'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['dataset']['task']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "15328811-7d54-4c1c-99c3-8cd5891c7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "96833730-40f1-4d1c-a97a-7f331662960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm as core_tqdm\n",
    "from typing import List, Set, Tuple, Union, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "def onek_encoding_unk(value : int, choices: List[int]) -> List[int]:\n",
    "    \"\"\"\n",
    "        Creates a one-hot encoding.\n",
    "\n",
    "    :param value: The value for which the encoding should be one.\n",
    "    :param choices: A list of possible values.\n",
    "    :return: A one-hot encoding of the value in a list of length len(choices) + 1.\n",
    "    If value is not in the list of choices, then the final element in the encoding is 1.\n",
    "\n",
    "    \"\"\"\n",
    "    encoding = [0] * len(choices)\n",
    "    if value in choices:\n",
    "        encoding[choices.index(value)] = 1\n",
    "    else:\n",
    "        encoding[-1] = 1\n",
    "    return encoding\n",
    "\n",
    "# rich_feature로 사용할 feature\n",
    "ATOM_FEATURES = {\n",
    "    'atomic_num' : list(range(1, 119)),\n",
    "    'degree' : [0,1,2,3,4,5],\n",
    "    'formal_charge' : [0, -1, -2, 1, 2],\n",
    "    'chiral_tag' : [0,1,2,3],\n",
    "    'num_Hs' : [0,1,2,3,4],\n",
    "    'hybridization': [\n",
    "\n",
    "        Chem.rdchem.HybridizationType.SP,\n",
    "        Chem.rdchem.HybridizationType.SP2,\n",
    "        Chem.rdchem.HybridizationType.SP3,\n",
    "        Chem.rdchem.HybridizationType.SP3D,\n",
    "        Chem.rdchem.HybridizationType.SP3D2\n",
    "    ],\n",
    "}\n",
    "\n",
    "from descriptastorus.descriptors import rdDescriptors, rdNormalizedDescriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "da78c32a-8b3e-464f-8100-4a21a6495cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classification'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['dataset']['task']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d96329c3-d57a-49aa-a242-a46811bc2960",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = Chem.AddHs(mol)\n",
    "\n",
    "N = mol.GetNumAtoms()\n",
    "M = mol.GetNumBonds()\n",
    "\n",
    "type_idx = []\n",
    "chirality_idx = []\n",
    "atomic_number = []\n",
    "formal_charge = []\n",
    "total_numHs = []\n",
    "hybridzation = []\n",
    "aromatic = []\n",
    "mass = []\n",
    "\n",
    "implicitValence_list = []\n",
    "hydrogen_acceptor_match_list = []\n",
    "hydrogen_donor_match_list = []\n",
    "acidic_match_list = []\n",
    "basic_match_list = []\n",
    "ring_info_list = []\n",
    "\n",
    "degree = []\n",
    "\n",
    "\n",
    "hydrogen_donor = Chem.MolFromSmarts(\"[$([N;!H0;v3,v4&+1]),$([O,S;H1;+0]),n&H1&+0]\")\n",
    "hydrogen_acceptor = Chem.MolFromSmarts(\n",
    "    \"[$([O,S;H1;v2;!$(*-*=[O,N,P,S])]),$([O,S;H0;v2]),$([O,S;-]),$([N;v3;!$(N-*=[O,N,P,S])]),\"\n",
    "    \"n&H0&+0,$([o,s;+0;!$([o,s]:n);!$([o,s]:c:n)])]\")\n",
    "acidic = Chem.MolFromSmarts(\"[$([C,S](=[O,S,P])-[O;H1,-1])]\")\n",
    "basic = Chem.MolFromSmarts(\n",
    "    \"[#7;+,$([N;H2&+0][$([C,a]);!$([C,a](=O))]),$([N;H1&+0]([$([C,a]);!$([C,a](=O))])[$([C,a]);\"\n",
    "\"!$([C,a](=O))]),$([N;H0&+0]([C;!$(C(=O))])([C;!$(C(=O))])[C;!$(C(=O))])]\")\n",
    "\n",
    "\n",
    "for atom in mol.GetAtoms():\n",
    "    type_idx.append(ATOM_LIST.index(atom.GetAtomicNum()))\n",
    "    chirality_idx.append(CHIRALITY_LIST.index(atom.GetChiralTag()))\n",
    "    degree.append( onek_encoding_unk(atom.GetTotalDegree(), ATOM_FEATURES['degree']) )\n",
    "    formal_charge.append( onek_encoding_unk(atom.GetFormalCharge(), ATOM_FEATURES['formal_charge']) )\n",
    "    total_numHs.append( onek_encoding_unk(int(atom.GetTotalNumHs()), ATOM_FEATURES['num_Hs']) )\n",
    "    hybridzation.append( onek_encoding_unk(int(atom.GetHybridization()), ATOM_FEATURES['hybridization']) )\n",
    "    aromatic.append([1 if atom.GetIsAromatic() else 0])\n",
    "    mass.append([atom.GetMass() * 0.01])\n",
    "\n",
    "    atom_idx = atom.GetIdx()\n",
    "\n",
    "    hydrogen_donor_match = sum(mol.GetSubstructMatches(hydrogen_donor), ())\n",
    "    hydrogen_acceptor_match = sum(mol.GetSubstructMatches(hydrogen_acceptor), ())\n",
    "    acidic_match = sum(mol.GetSubstructMatches(acidic), ())\n",
    "    basic_match = sum(mol.GetSubstructMatches(basic), ())\n",
    "\n",
    "    implicitValence_list.append(onek_encoding_unk(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5, 6]))\n",
    "    hydrogen_acceptor_match_list.append([atom_idx in hydrogen_acceptor_match])\n",
    "    hydrogen_donor_match_list.append([atom_idx in hydrogen_donor_match])\n",
    "    acidic_match_list.append([atom_idx in acidic_match])\n",
    "    basic_match_list.append([atom_idx in basic_match])\n",
    "\n",
    "    ring_info = mol.GetRingInfo()\n",
    "    ring_info_list.append(                [ring_info.IsAtomInRingOfSize(atom_idx, 3),\n",
    "            ring_info.IsAtomInRingOfSize(atom_idx, 4),\n",
    "            ring_info.IsAtomInRingOfSize(atom_idx, 5),\n",
    "            ring_info.IsAtomInRingOfSize(atom_idx, 6),\n",
    "            ring_info.IsAtomInRingOfSize(atom_idx, 7),\n",
    "            ring_info.IsAtomInRingOfSize(atom_idx, 8)])\n",
    "                                   \n",
    "                   \n",
    "x1 = torch.tensor(type_idx, dtype=torch.long).view(-1, 1)\n",
    "x2 = torch.tensor(chirality_idx, dtype=torch.long).view(-1, 1)\n",
    "x3 = torch.tensor(degree, dtype=torch.long)\n",
    "x4 = torch.tensor(formal_charge, dtype=torch.long)\n",
    "x5 = torch.tensor(total_numHs, dtype=torch.long)\n",
    "x6 = torch.tensor(hybridzation, dtype=torch.long)\n",
    "x7 = torch.tensor(aromatic, dtype=torch.long)\n",
    "x8 = torch.tensor(mass, dtype=torch.float)\n",
    "\n",
    "x9 = torch.tensor(implicitValence_list, dtype=torch.long)\n",
    "x10 = torch.tensor(hydrogen_acceptor_match_list, dtype=torch.long)\n",
    "x11 = torch.tensor(hydrogen_donor_match_list, dtype=torch.long)\n",
    "x12 = torch.tensor(acidic_match_list, dtype=torch.long)\n",
    "x13 = torch.tensor(basic_match_list, dtype=torch.long)\n",
    "x14 = torch.tensor(ring_info_list, dtype=torch.long)\n",
    "\n",
    "\n",
    "x = torch.cat([x1, x2, x3, x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14], dim=1)\n",
    "\n",
    "row, col, edge_feat = [], [], []\n",
    "for bond in mol.GetBonds():\n",
    "    start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "    row += [start, end]\n",
    "    col += [end, start]\n",
    "    bt = bond.GetBondType()\n",
    "    feat1 = [\n",
    "        BOND_LIST.index(bond.GetBondType()),\n",
    "        BONDDIR_LIST.index(bond.GetBondDir()),\n",
    "        bond.GetIsConjugated() if bt is not None else 0,\n",
    "        bond.IsInRing() if bt is not None else 0,\n",
    "        *onek_encoding_unk(int(bond.GetStereo()), list(range(6)))\n",
    "    ]\n",
    "    edge_feat.append(feat1)\n",
    "\n",
    "    # 반대 방향의 엣지(또는 같은 특성을 반복) 특성 계산\n",
    "    # 여기서는 예시로 feat1을 그대로 사용합니다. 필요에 따라 다른 계산을 할 수 있습니다.\n",
    "    feat2 = feat1  # 또는 반대 방향에 대한 다른 계산 결과\n",
    "    edge_feat.append(feat2)\n",
    "        \n",
    "\n",
    "edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "edge_attr = torch.tensor(np.array(edge_feat), dtype=torch.long)\n",
    "if config['dataset']['task'] == 'classification':\n",
    "    y = torch.tensor(labels, dtype=torch.long).view(1,-1)\n",
    "elif config['dataset']['task'] == 'regression':\n",
    "    y = torch.tensor(labels * conversion, dtype=torch.float).view(1,-1)\n",
    "\n",
    "\n",
    "normalized_2d_generator = rdNormalizedDescriptors.RDKit2DNormalized()\n",
    "x_add = normalized_2d_generator.process(smiles)\n",
    "if x_add is None:\n",
    "    # x_add가 None인 경우, 처리 방식 결정\n",
    "    # 예: 빈 특성 리스트 또는 기본값 설정\n",
    "    print(f\"Warning: No features generated for SMILES: {smiles}\")\n",
    "    x_add = [] # 예시 기본값\n",
    "else:\n",
    "    # x_add를 텐서로 변환\n",
    "\n",
    "    x_add = torch.tensor(np.array(x_add[1:]), dtype=torch.long).view(1, -1)\n",
    "\n",
    "\n",
    "data = Data(x=x, y=y, edge_index=edge_index, edge_attr=edge_attr, x_add = x_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d29cf482-9dab-41c7-91d4-05392b6474b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dd5a1b1e-8670-44e9-837b-6780368a4b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.batch = torch.zeros(x.size(0), dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0cbe1e8d-a42e-4f98-a36b-8229cdfbece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_node, pred, node = model(data,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9eef16e4-5d55-4c06-b5f7-a48f153fd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = mol.GetNumAtoms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7fa8e531-f6f9-4b47-b10d-0b3151fd7b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAEsCAIAAAD2HxkiAAAD5XRFWHRyZGtpdFBLTCByZGtpdCAyMDIyLjA5LjUA776t3gAAAAANAAAAAAAAAAIAAAAmAAAAKQAAAIABBiBgAAAABAMIICgAAAADAgZgKAAAAAMEBmBoAAAAAwQBBmBoAAAAAwQBBmBoAAAAAwQBBmAoAAAAAwQGIGAAAAAEAQggIAAAAAIGIGAAAAAEAQYgKAAAAAMECCAoAAAAAwIGYCgAAAADBAZgaAAAAAMEAQZgKAAAAAMEBmAoAAAAAwQGYGgAAAADBAEGYCgAAAADBAcgaAAAAAMDAgggKAAAAAMCBiBgAAAABAIIICgAAAADAgZgaAAAAAMEAQEAKAAAAAABAQAoAAAAAAEBACgAAAAAAQEAKAAAAAABAQAoAAAAAAEBACgAAAAAAQEAKAAAAAABAQAoAAAAAAEBACgAAAAAAQEAKAAAAAABAQAoAAAAAAEBACgAAAAAAQEAKAAAAAABAQAoAAAAAAEBACgAAAAAAQsAAQABAiACA2gCAwRgBAVoAgUGYAYHAAcIAAgJAAkKAAoLKAIKDCAMDWgCDQ5gDg9oAg8QYBARaAIREiAPEyATFAAUFQAGFmgCFgJgCQcAEQxgFQ4gABcAABgAABkAAxoABBsABRwABx0ACR4ADR8AECAAEiEAEiIAFCMAFCQAFiUAFAQAAAAGAhYGBQQDAwgHCQYNDg8QEQwFEw8OFRQX0gEAAAEAAAAAAAAAACY7C+1Ar9khPwAAAAAMpMFA9OqiPwAAAAD2L5pA9D7WPgAAAAAQI55AlsmJvwAAAAD0XW1AzST3vwAAAACWjxZAsCalvwAAAABjqQ5AFJVRPgAAAAAVbF8/fWFYPwAAAADH8h6/Abh7PwAAAAAVEtE7hC/CvgAAAABE/5y/GOedvwAAAADeMo2/NaAuwAAAAAAATiXA99EXvwAAAAArNnTAMkS5vwAAAABEgqXALIxOvwAAAABedanAeiYwPwAAAABIAYLAdG7FPwAAAAAzNC3Ar+BmPwAAAAAQmLy/jsvgPwAAAADELNjAFi6EPwAAAAD8GPHA50h/vgAAAADGyNHA1m2xvwAAAACOkV1A2Y2HPwAAAAA1OQxBbaIIvAAAAABhxQBBk4n+PwAAAACzi9hAyV85vwAAAAA/islAssfbvwAAAAAnRHVAED9bwAAAAAAQC7k/VlMGwAAAAACET6I/lLMSQAAAAADZ6z8/L5GrvwAAAAD4T2zAw048wAAAAABi9IXA42NCQAAAAAB2ZMy/cBJQQAAAAAAADjG/a9fMPwAAAAArpQvBycUoPwAAAACcAAnBRLCrvwAAAABbq1VAlnMjQAAAAAAWuvxEfAAACc10RVh0TU9MIHJka2l0IDIwMjIuMDkuNQAKICAgICBSREtpdCAgICAgICAgICAyRAoKICAwICAwICAwICAwICAwICAwICAwICAwICAwICAwOTk5IFYzMDAwCk0gIFYzMCBCRUdJTiBDVEFCCk0gIFYzMCBDT1VOVFMgMzggNDEgMCAwIDAKTSAgVjMwIEJFR0lOIEFUT00KTSAgVjMwIDEgQyA3LjQwNzYyMSAwLjYzMjIyOCAwLjAwMDAwMCAwCk0gIFYzMCAyIE8gNi4wNTEyNzUgMS4yNzI3OTUgMC4wMDAwMDAgMApNICBWMzAgMyBDIDQuODE4MzU1IDAuNDE4NDQ5IDAuMDAwMDAwIDAKTSAgVjMwIDQgQyA0Ljk0MTc4MCAtMS4wNzY0NjQgMC4wMDAwMDAgMApNICBWMzAgNSBDIDMuNzA4ODU5IC0xLjkzMDgxMSAwLjAwMDAwMCAwCk0gIFYzMCA2IEMgMi4zNTI1MTQgLTEuMjkwMjQzIDAuMDAwMDAwIDAKTSAgVjMwIDcgQyAyLjIyOTA4OSAwLjIwNDY3MCAwLjAwMDAwMCAwCk0gIFYzMCA4IEMgMC44NzI3NDMgMC44NDUyMzggMC4wMDAwMDAgMApNICBWMzAgOSBPIC0wLjYyMDg5MiAwLjk4MzI3NiAwLjAwMDAwMCAwCk0gIFYzMCAxMCBDIDAuMDA2MzgwIC0wLjM3OTI2OSAwLjAwMDAwMCAwCk0gIFYzMCAxMSBDIC0xLjIyNjU0MCAtMS4yMzM2MTUgMC4wMDAwMDAgMApNICBWMzAgMTIgTyAtMS4xMDMxMTUgLTIuNzI4NTI4IDAuMDAwMDAwIDAKTSAgVjMwIDEzIEMgLTIuNTgyODg2IC0wLjU5MzA0OCAwLjAwMDAwMCAwCk0gIFYzMCAxNCBDIC0zLjgxNTgwNiAtMS40NDczOTQgMC4wMDAwMDAgMApNICBWMzAgMTUgQyAtNS4xNzIxNTIgLTAuODA2ODI2IDAuMDAwMDAwIDAKTSAgVjMwIDE2IEMgLTUuMjk1NTc3IDAuNjg4MDg3IDAuMDAwMDAwIDAKTSAgVjMwIDE3IEMgLTQuMDYyNjU3IDEuNTQyNDMzIDAuMDAwMDAwIDAKTSAgVjMwIDE4IEMgLTIuNzA2MzExIDAuOTAxODY2IDAuMDAwMDAwIDAKTSAgVjMwIDE5IE4gLTEuNDczMzkxIDEuNzU2MjEyIDAuMDAwMDAwIDAKTSAgVjMwIDIwIE8gLTYuNzU1NDY1IDEuMDMyNjU2IDAuMDAwMDAwIDAKTSAgVjMwIDIxIEMgLTcuNTM0MzAwIC0wLjI0OTMwMiAwLjAwMDAwMCAwCk0gIFYzMCAyMiBPIC02LjU1NTc1OCAtMS4zODYxNjQgMC4wMDAwMDAgMApNICBWMzAgMjMgQyAzLjQ2MjAwOSAxLjA1OTAxNiAwLjAwMDAwMCAwCk0gIFYzMCAyNCBIIDguNzYzOTY2IC0wLjAwODM0MCAwLjAwMDAwMCAwCk0gIFYzMCAyNSBIIDguMDQ4MTg4IDEuOTg4NTczIDAuMDAwMDAwIDAKTSAgVjMwIDI2IEggNi43NjcwNTMgLTAuNzI0MTE4IDAuMDAwMDAwIDAKTSAgVjMwIDI3IEggNi4yOTgxMjYgLTEuNzE3MDMyIDAuMDAwMDAwIDAKTSAgVjMwIDI4IEggMy44MzIyODUgLTMuNDI1NzI0IDAuMDAwMDAwIDAKTSAgVjMwIDI5IEggMS40NDU2NTAgLTIuMDk4ODM2IDAuMDAwMDAwIDAKTSAgVjMwIDMwIEggMS4yNjgwNTIgMi4yOTIyMTEgMC4wMDAwMDAgMApNICBWMzAgMzEgSCAwLjc0OTY5MyAtMS4zNDAzNjggMC4wMDAwMDAgMApNICBWMzAgMzIgSCAtMy42OTIzODEgLTIuOTQyMzA3IDAuMDAwMDAwIDAKTSAgVjMwIDMzIEggLTQuMTg2MDgyIDMuMDM3MzQ3IDAuMDAwMDAwIDAKTSAgVjMwIDM0IEggLTEuNTk2ODE2IDMuMjUxMTI1IDAuMDAwMDAwIDAKTSAgVjMwIDM1IEggLTAuNjkxNjIwIDEuNjAwMzI0IDAuMDAwMDAwIDAKTSAgVjMwIDM2IEggLTguNzI3ODI0IDAuNjU5MjY4IDAuMDAwMDAwIDAKTSAgVjMwIDM3IEggLTguNTYyNjQ5IC0xLjM0MTMxNyAwLjAwMDAwMCAwCk0gIFYzMCAzOCBIIDMuMzM4NTg0IDIuNTUzOTMwIDAuMDAwMDAwIDAKTSAgVjMwIEVORCBBVE9NCk0gIFYzMCBCRUdJTiBCT05ECk0gIFYzMCAxIDEgMSAyCk0gIFYzMCAyIDEgMiAzCk0gIFYzMCAzIDQgMyA0Ck0gIFYzMCA0IDQgNCA1Ck0gIFYzMCA1IDQgNSA2Ck0gIFYzMCA2IDQgNiA3Ck0gIFYzMCA3IDEgNyA4Ck0gIFYzMCA4IDEgOCA5Ck0gIFYzMCA5IDEgOSAxMApNICBWMzAgMTAgMSAxMCAxMQpNICBWMzAgMTEgMiAxMSAxMgpNICBWMzAgMTIgMSAxMSAxMwpNICBWMzAgMTMgNCAxMyAxNApNICBWMzAgMTQgNCAxNCAxNQpNICBWMzAgMTUgNCAxNSAxNgpNICBWMzAgMTYgNCAxNiAxNwpNICBWMzAgMTcgNCAxNyAxOApNICBWMzAgMTggMSAxOCAxOQpNICBWMzAgMTkgMSAxNiAyMApNICBWMzAgMjAgMSAyMCAyMQpNICBWMzAgMjEgMSAyMSAyMgpNICBWMzAgMjIgNCA3IDIzCk0gIFYzMCAyMyA0IDIzIDMKTSAgVjMwIDI0IDEgMTAgOApNICBWMzAgMjUgNCAxOCAxMwpNICBWMzAgMjYgMSAyMiAxNQpNICBWMzAgMjcgMSAxIDI0Ck0gIFYzMCAyOCAxIDEgMjUKTSAgVjMwIDI5IDEgMSAyNgpNICBWMzAgMzAgMSA0IDI3Ck0gIFYzMCAzMSAxIDUgMjgKTSAgVjMwIDMyIDEgNiAyOQpNICBWMzAgMzMgMSA4IDMwCk0gIFYzMCAzNCAxIDEwIDMxCk0gIFYzMCAzNSAxIDE0IDMyCk0gIFYzMCAzNiAxIDE3IDMzCk0gIFYzMCAzNyAxIDE5IDM0Ck0gIFYzMCAzOCAxIDE5IDM1Ck0gIFYzMCAzOSAxIDIxIDM2Ck0gIFYzMCA0MCAxIDIxIDM3Ck0gIFYzMCA0MSAxIDIzIDM4Ck0gIFYzMCBFTkQgQk9ORApNICBWMzAgRU5EIENUQUIKTSAgRU5ECoPuSf8AAAQ6dEVYdFNNSUxFUyByZGtpdCAyMDIyLjA5LjUAW0hdYzFjKFtIXSljKEMyKFtIXSlPQzIoW0hdKUMoPU8pYzJjKFtIXSljM2MoT0MoW0hdKShbSF0pTzMpYyhbSF0pYzJOKFtIXSlbSF0pYyhbSF0pYyhPQyhbSF0pKFtIXSlbSF0pYzFbSF0gfCgzLjgzMjI4LC0zLjQyNTcyLDszLjcwODg2LC0xLjkzMDgxLDsyLjM1MjUxLC0xLjI5MDI0LDsxLjQ0NTY1LC0yLjA5ODg0LDsyLjIyOTA5LDAuMjA0NjcsOzAuODcyNzQzLDAuODQ1MjM4LDsxLjI2ODA1LDIuMjkyMjEsOy0wLjYyMDg5MiwwLjk4MzI3Niw7MC4wMDYzODAzMywtMC4zNzkyNjksOzAuNzQ5NjkzLC0xLjM0MDM3LDstMS4yMjY1NCwtMS4yMzM2MSw7LTEuMTAzMTEsLTIuNzI4NTMsOy0yLjU4Mjg5LC0wLjU5MzA0OCw7LTMuODE1ODEsLTEuNDQ3MzksOy0zLjY5MjM4LC0yLjk0MjMxLDstNS4xNzIxNSwtMC44MDY4MjYsOy01LjI5NTU4LDAuNjg4MDg3LDstNi43NTU0NiwxLjAzMjY2LDstNy41MzQzLC0wLjI0OTMwMiw7LTguNzI3ODIsMC42NTkyNjgsOy04LjU2MjY1LC0xLjM0MTMyLDstNi41NTU3NiwtMS4zODYxNiw7LTQuMDYyNjYsMS41NDI0Myw7LTQuMTg2MDgsMy4wMzczNSw7LTIuNzA2MzEsMC45MDE4NjYsOy0xLjQ3MzM5LDEuNzU2MjEsOy0xLjU5NjgyLDMuMjUxMTMsOy0wLjY5MTYyLDEuNjAwMzIsOzMuNDYyMDEsMS4wNTkwMiw7My4zMzg1OCwyLjU1MzkzLDs0LjgxODM1LDAuNDE4NDQ5LDs2LjA1MTI4LDEuMjcyOCw7Ny40MDc2MiwwLjYzMjIyOCw7OC43NjM5NywtMC4wMDgzMzk1MSw7OC4wNDgxOSwxLjk4ODU3LDs2Ljc2NzA1LC0wLjcyNDExOCw7NC45NDE3OCwtMS4wNzY0Niw7Ni4yOTgxMywtMS43MTcwMywpLGF0b21Qcm9wOjAuaXNJbXBsaWNpdC4xOjMuaXNJbXBsaWNpdC4xOjYuaXNJbXBsaWNpdC4xOjkuaXNJbXBsaWNpdC4xOjE0LmlzSW1wbGljaXQuMToxOS5pc0ltcGxpY2l0LjE6MjAuaXNJbXBsaWNpdC4xOjIzLmlzSW1wbGljaXQuMToyNi5pc0ltcGxpY2l0LjE6MjcuaXNJbXBsaWNpdC4xOjI5LmlzSW1wbGljaXQuMTozMy5pc0ltcGxpY2l0LjE6MzQuaXNJbXBsaWNpdC4xOjM1LmlzSW1wbGljaXQuMTozNy5pc0ltcGxpY2l0LjF8xn76lwAAKplJREFUeJzt3XlcVNX7B/DnDtuwSoqQRiiIphmaaSpqLilqRmYZLSqVVmhJU1qGWTraYqSZg2Vl/uobpS2UWhSKmuaC4r6ioiIC4sIiMuzO9vz+ODCOLOMwc+cehOf98o8Lztxzgfnce849554jICIQQviR8T4AQlo6CiEhnFEICeGMQkgIZxRCQjijEBLCGYWQEM4ohIRwRiEkhDMKISGcUQgJ4czRfrsWBIFtWD481Yq3iLVP48usKJ29l0bhEuvcIoS2fDQR0fTtt2T8KAuCIAiCJcVZcngWHgZ7e6MO2IrXE1KXRVdC02CYRsX0f43bbEOaT6fp8Zh+v96rX61XinLVtS66hJhqdJvQ9GPX0HZDwZDmw1r3eOoeeUOvqbsrChixN4tCWG+o2JeWX/oQUZpWk+VXp6ZzzKQls7Q6Kspr7KpWPdmSpiD3YyYEAG5x/8N8Y8/MN2sFoKHG2y2Lgwauw3XLrVVQQxo6ZjO7MnPM9b7LTOmE1GXRTUi+LLxTSshtqql31lMCSbPX1ENICSTNXlMPISHNHoWQEM4ohIRwRiEkhDMKISGcUQgJ4YxCSAhnFEJCOKMQEsIZhZAQziiEhHBGISSEMwohIZxRCAnhjEJICGcUQkI4oxASwhmFkBDOKISEcEYhJIQzCiEhnFEICeGMQkgIZxRCQjijEBLCGYWQEM4ohIRwRiEkhDMKISGcUQgJ4YxCSAhnFEJCOKMQEsIZhZAQziiEhHBGISSEMwohIZxRCAnhjEJICGcUQkI4oxASwhmFkBDOKISEcEYhJIQzCiEhnFEICeGMQkgIZxRCQjijEBLCGYWQEM4ohIRwRiEkhDMKISGcUQgJ4YxCSAhnFEJCOKMQEsIZhZAQziiEhHBGISSEMwohIZxRCAnhjEJICGcUQkI4oxASwhmFkBDOKISEcEYhJIQzCiEhnFEICeGMQkgIZxRCQjijEBLCGYWQEM4ohNJRq9XDhg0zftmrVy+OB0OaDgqhdAwGQ3FxsfHLa9eu8TsW0oQ48j6AlqWqquro0aNsW6vV8j0Y0kS00BBu2bLl2rVrTz31FACcPXv277//njlzpgTlFhUV/fTTT2y7oqJCghJJ09dCQ5iVlXXp0iW2XVRUtHfvXmnKbd++/Weffca2//jjD2kKJU0ctQkJ4ayFXgkBID4+fseOHQBQUlLSsWNHCUp0dXV96aWXjF9Onz5dgkJJ09dyQ/jCCy/MnTsXAPbu3fv5559LUKJcLo+Ojs7Ozn711Vdbt269atUqCQolTV/LDSEvMplsw4YN/v7+vA+ENBUtNIR+fn4ODg5s29PT85577pGs6LZt2wJAQUGBZCWSJk5ARN7HwE1qauqmTZsGDRo0fPhwKcv19PQsKytTq9VeXl5SlmtvlZWVqampDz/8MPvyn3/+CQ8P53tIt4UWfXc0JSVl/vz5ycnJEpfbXC+GhYWFSqXS+GV0dDTHg7mNtOgQ8gpDcw0hsU4LbRMyLAz5+flcym2WIczIyJg2bRrbrqys5HswtwsKIYcwdOs2rLjYu6ysrcTlAsDBgwd9fX3vvvtuADh37lxFRUVISIiI+/f393/nnXfY9vr160XcczNGIeQQQpnsrV274LHHJC4WAGDVqlWDBw9mIdy+fXtubq64IZTL5UFBQWxbJmvRjR3Ltehfk6+vL/BpEwIANMfaKLFGi74Suru7u7m5VVRUVFRUuLm5SVYuC6HkTdFqX375ZWJiIgCcPXt25MiRIu65ffv2a9as0el0ubm5Go0mNTVVxJ3zpNHAqVOQmwsODhAQAPfcAzWdzKJo0SEEAB8fn5ycnPz8fGmGjzJ8r4TPPffc6NGjAeC3334rLy8Xcc8ODg6+vr779u3r169fnz599u/fL+LOucnKgt9+A4MBNBoAgCNHwNkZJk4EPz+xSmjR1VHg1Cz09QXgF8I2bdr4+/v7+/vfcccd9tg/r0q+XeTnwy+/qLZt25uZyb7x19Gjv6amwv/+B2VlYhXS0kPI5RPTvNuEzaoDZv160GjOXL16taa75WJpaY5aDTodbN0qViEtPYRcPjEshFevSllmtVmzZjk6OrKH+idMmPDWW2+JXoRpS1v0nUtKp4MLF9gmIhoQDYjVwzz1ekhPF6scCqHUIdRoID0d8vOhtBR0OhH/lBbZtWvX2LFjn3jiCQCQy+Xu7u72KMXHxwd4jIIQWUWF8QaMctu2MatXj1m9+itjQ7eqSqxyKIRShzAvD/r0gc2bQRCguBgmT5asZACATZs2AYBxjLWdNJMaqZsb6PVs84Nhw5InTUqeNGl6377V/yuXi1UOhZDDyLUBA+Czz8Bk9kPp/PvvvwAgbs9EXc0khI6O0LEjCEI9/+XgAN27i1UOhZDDx8XdHWbMgDlzqr+8dAmOHgWd7sYLNm/evHDhQradnZ09WaTLZXp6elZWlo+PT8+ePUXZYUOaSQgBYMwYcHLq4efnV1Nv7+jtHdymDTg7g8k8zjZq6f2EvD4ukybB99/DgQMAAKtXwzvvgFwO48d/4OV1pXfv3p6ensZD0mg0ubm5ohTK6qKjRo2y94Cy5tNL0abN5dGjv/vqq1YeHr3vugsAxnTvDu7uMHEiiDe6o6WHUMqPS1UVJCRUn0AFAb74AiIjQS4HuRw6d4aMDEhN/TUz85RcLv/pp5/KysouXLgAAFeuXBHrADZv3gwAYWFhYu2wIc3nSgiw9JdfDuTmrisufu6hhwAAAgIgKKj+Oqq1WnoIXV1dAeDSpUvp6eldu3a1X0FpaTBpEhw9CnFx1d+57z4YPhx27YLXX4fXXwe1Gg4d+vrQoQPFxcUODg6pqansAdmSkhJRDkCj0Wzbtk0QBAqh5dRq9bfffgsAMR99BL1726sYbMFSU1M7d+7s4ODg4OAgk8nCw8NTU1NFL0WvR5UKnZ0RALt1w9278cyZ6v+qqMBTp+p5y9q1a9988022febMmREjRth+GP/99x8AhISE2L6rW2JjU8PDwyUoy64+/PBDABg1apRdS2mhN2Y0Gs3s2bMHDRp09uzZ7t27P/300y4uLv/8809oaGhYWNiWLVvEKigrC4YNgzffBK0WoqJg/34IDYXOnav/19UV7Hn1vQmri9r7vijD50p4+jQ8+SSEhcGoUfDvv7bvr6KiYtmyZQDw7rvv2r43c+wa8aYpLS3tgQceAABHR8eYmJjr168jYn5+vlKpNA6nvP/+++Pj43U6nS0FxcejhwcC4J13YlJSI954+PDhhIQEtp2Xl6dSqWw5DKZPnz4AkJycbPuubikjIwMAAgMDJSirWlUVdu+OR44gIublYffueO6cjbuMi4sDgH79+olweGa1rBAaDAaVSuXi4sI+Ijt27GDfT0hIWLJkSWlpaUlJiUqlat++PYtip06dVCpVVVVVYwu6cqXk0UcRAAFwwgS8dk3kH6SxCgsLZTKZXC4vLy+XoDi1Wg0AHh4eEpRVbedOfOqpG18uWoRLltiyP41G06FDBwBITEy09dhupWmEUKfDtDTcvx8rKuxXSFZWlnGNzsjIyNLSUvZ9vV7fpUsXAPDy8lIoFJcvX66qqoqPj+9cU2sMCAhQqVSWf3yTkpLatWvXv/8Fb2/86Se7/TyN8csvvwBAWFiYZCXK5XJWo5OovHXr8NVXb3z5ww8YE2PL/v73v/8BQLdu3fR6va3HditNIIT5+ThwIL72Gs6ejb164f799igkISGBVTX9/Pzqntt27txpnCHT3d1doVDk5OTo9frExMTeNffEfHx8lErl1atXzZSiVqtfeOEF9vqnnpp28aJtB33tGq5cibGxuGWLbTvCKVOmAMCiRYts3I/l2BTjOTk5EpV3+DCa3r6aMwdXrMBVq/Czz7DmbGs5g8HQvXt3AFi1apWYB9mAJhDCGTPw22+rt48cwdBQcXefn5/PxisDwPjx4wsKChp6ZUpKSnh4uCAIAODk5BQZGXny5EmDwZCYmDhgwAC2Bw8PD4VCkZubW/ftu3bt6tSpEwC4urrGxsbaega9ehV79sSVK/Hff3HCBJw715adsUlljrAmkyR69OgBAPa421zb77/jG28gIg4bhitXYmEhbtyI996LRUXYqRMCoJcXKhR4+bLlu1yzZg1rsGi1WjsdtakmEML+/TEr68aXAQGo0WDjm2H1Sk5OZg08Ly+vFStWWPKW48ePR0ZGOjo6AgDrt9izZw/WXC1ZRJ2dnSMjI9PT09lbqqqqYmJi2Lz6Dz74oPH7Nvn4Y1y8uHpbo8FOnbC42Lo9nTx5klUBDAaDCAdmgfj4eLlc3r59+9atWyuVyqKiIrsUU1yMkZHVLe9t27C8HD/6CJ95BmfNQnaW3LkTw8OrX+DujgoFWnZlDg0NBYDly5fb5bDraAIh7Nevdgizs9HREXv3RoUCExKwsNCKvZaXlysUCpaZgQMHnmvkvbLz588rFArWlc/2wCqxR44ciYyMZHljEf3111/vv/9+471WjUZjxdHWIzISN2++8eWjj+LBg9ilC4aG4tixOHUqKpW4fDmuW4e7duG5c9hwk1WlUrFmsDgHZlZeXt7YsWPZL61du3Zso1WrVnPmzMnLyxOzpJQUDApCAHR1RZUKzZxfDh7EiAgUBARAJyeMjMSTJ83smI1x9/X1laxB2wRCGB2N8fHV26dOYd++mJSEMln1CQwAZTIMCcHXXsPVqy08k7FeeACQy+W21Azz8vKUSqW3tzf7MPXq1Yv1W5w+ffqll15ydnYGAE9PTwDo2rXrvn37rCulftOn49q1N7586CE8ePDG76TOvx1Dh3p4eHTp0mXQoEHjx4+Pjo7+4IMPVq5cmZiYOHDgQAD48ccfxTy8+qxfv54Fr1WrVqzeYdrYdnFxiYyMPGMcqWC1ykqMian+hPTti6dPW/SuY8dwwgR0dEQAg4dH1MSJBw4cqPeFbGGSTz75xNbjtJilIdy/f//69evZdm5u7nfffSfaIVy8iA8+iPPm4eLF2KcPpqQgIhYXY1ISzpmDDz2Ecrnpp+3VwYMnTZr09ddfp6Wl1a1fabVapVLJrlQhISGitIJYv4XxvB4cHLxixQqNRnPhwgX2Cevatav4Z83ERHzyyeoTfHo6hoSgRoMZGZiSguvW4ZdfolKJU6fi2LHYvz926PBLw48ICoIgk8lefvnlepuyoigpKYmKimLFjRgx4sKFC1euXLlW0zNz+PBh0+pDREREWlqalSUdO4Y9eyIAOjpiTAw2tt5x7hxOm7avZv0fYwXHaN++fazxck3CbiVLQ/jjjz++//77bPvQoUPjxo0Tp/yMDLx6FSsrcds23LAB6733WFWFKSkYG4vh4fqOHR1NngDw9PQcMWKEUqncvHlzZWXliRMnWC+8g4ODsRdeLOXl5cuWLWN9RwDw7LPPIiIbhjJ8+HARC7ph7lwcMACfeAIHDsRDh2758uLi4lOnTm3fvv23336Li4t7//33J0+ezAavGK9FU6dOzcjIEPcwd+/eHRwcbFrvYJfEiRMnmr4sIyNDoVCwTlpBEMLDw3fv3m15KTqdbsmnnxb6+lYP/2vgOmaJhio4iMju4b377rtW79wKXEOo12Pfvti2Le7da/E79MePH1++fPmECRPYHT8juVzO/sDBwcGN+us2ikajiY+Pv/fee9nQkyNHjoBdB2Tq9VhSgno9rlt3U8vZMkuXLgUAHx+fLVu21LrbtF+MriCNRmOsd/To0ePo0aNqtfrFF19kf5GRI0dWVlbWekt2drZCoTDO8squRbe8Y5SRkcFuUD8dGopvvCFKf3KtCk737t1jY2PZkIZLly7Zvn/LNSKEQUFBYWFhYWFh/fv3FyeE33yDANiuHarV1u3g4sWLCQkJCoWid+/egiD4+PgMHz68tPH9Qo2l1+vZ5+bixYsAcOedd9q3vFmzEACjoxv1prS0NHZj6a+//mLfOXfunEKhkNfMyzBw4MDNpvd+GiktLa1Xr15gMvrPeEm8ZSdNQUGBUqls3bo1O5KePXuaGSQYHx/v4eHBfs9JjRr+Z4FaFRwAGDx4sHRjDBCR55WwsBB9fBAAf//d1l0hIuKkSZMAYOXKlVqt9uLFi6JXuuql0WgEQXB0dLTv3f+TJ1EQ0M0NG+7krKWqqoo9Pj916tRa/3XlyhWlUtmqVatGXYtM1Rr9t3PnTtNL4oMPPniq3mdD6igtLVWpVHfddRc7kqCgIJVKZXrxNL3XGhERYX6khC00Gs2SJUsEQWA/Qtu2be3Ys1KH9SE8c+bM33//bX3JkycjAIo3kGr27NkAsHDhwrS0NAC49957xdqzeaxpYfc/2JgxCIDz51v48jfeeIPVzBuqF6jV6tjY2DZt2rCPeEhISHx8vCV901lZWUOHDmXvYqP/0tLSTDtpGtsUv379enx8PBs5yC53SqVSrVavWbOGzdrm7e39k/2H/73++usAMGzYsP79+xvvOCgUiou2jnu6NUtDuGbNmsU1fcdpaWmTJ0/u2bOnIAizZ8+2ZlRBSgoKAjo7oyj92oiIuGTJEgCYMWNGXl4eO5mJtWfzWF/IaQtvlFvtv/8QANu0wbKyW75206ZN7PrMhhmYUVZWplKpjK3rwMBAlUplpjJWa/Sf6SUxKCgohd3ZtopWq129ejUbZwMArP4JAKNGjZIgBoWFhe7u7oIgHD9+HOsbmGHXv6+V/YTst+/k5MTq0I37Nel0eP/9CIDz5llXer1+/PFHAJg4caJOp5PJZDKZzMYHkSzEbhjY8vmzVP/+CIBffmn+VUVFRSxUCxcutHDH7FpknFjA19dXqVTWukdvOvrvqaeeKigoyMrKGjJkCAAIghAVFVVmwdnBEjt37hw6dKi3t7e7u7sIo/8s89577wHA448/bvrNWj0r4eHhDXUt2simzvodO3awQWFt27bduHGjpW/7/HMEwA4dzAzysMKGDRvYHTlEZLWs/Px8EfffkMcffxwA1pp2rNvJ778jAAYGotmqR0REBAAMGjSosecgNmC9b828muyZEnafsO7ov/j4eDZKwc/Pz6ZWSX0kamnXKCkpYZf3Xbt21f1f1rPC7maxnpV6X4ZlZZiVhRcvYuNP/baOmCkoKBg1ahQAODg4KJXKW563Ll68uGDkyEq5HP/5x8aiazlw4AAA9OrVCxHZSf3EiRPiFlGvl19+GQAsHJhqE70eO3dGAPztt4ZesnLlSgBo1apVVuP7M4ySk5ONrT53d3d2CxQAHn74YbaC1bhx44w3SwqtGlRYr9zc3E8//fT//u//ULKWNiIiLlq0CACGDh1q5jWXL1+OiYkxTlh+090stRrj4/HDDzE2Fj/5BD/+GLdvNzeMrg4Rhq0ZDAbWwcL+TleuXDHz4meffRYApj3/vO3l1pKTkwMA/v7+iDh48GAA2LZtm+il1MXmPvjoo48kKAu//hoBLo4cWe9/ZmRksKvT6tWrbS/q4MGDkZGRMpksICDA2dnZtBceTAamiWjv3r0A0KdPH6xpaYszFN6sqqoqdpG3pCpXq2elR48e8d98o/3kk8SJE4tiYnD+fJw/P2XKlLMzZzbqnr9oY0e3bt3q5+fHYlD/9bpmfImbm1tmZqZY5RpVVlYCgIuLCyKOHz8eAH4XqfPDvM8//xwA3mBP09hbRcWbo0c7OTltqfOEoVarZbf1ao1TsRGbg3js2LGIuHHjRvbhCwsLu3DhgoilMOfPnweADh06YE1Le+fOnaKXUss333wDAPfff7/lVd+SkpLFixcbp194OChodHDwyenTWQjfHjAgISICP/7Y0kGtIk70NGzYsAMHDgwcODA3N3fIkCGffvopsvVramg0GnYXeO7cuYGBgWKVaySXyz08PK5fv15aWirlREOSTmrk6tp6wACtVrt48eJa/zN//vw9e/b4+/t/8cUXIhbIhgFWVVUBwIgRIx599NHY2Njk5GT2zK64TH+T0vxW9Xo9u6n+3nvvCRZPJerp6fn222+fP38+fuXKe3x8Hr/nnnpepNXCnj2WHoeVJ5AGaLXamJgY9vOMHTvWtE7/0UcfAUCXLl2smLLFQizbGRkZc+fOBYAFCxbYqSBT7Pog2cwRV69eZbfvDx8+bPxmSkoKm7Xxv//+E7e4gwcPQk1LWwJsOFt5ebk0Le2ff/4ZADp16mTljfScHN3Chdfnzh0dHDwiKGhc167junbt3KZNQkQEzp+Pn31m4W5EnvLQ0dExNjb2zz//vOOOOxITE3v16sWGpefk5HzyyScA8PXXX7NuJXswnj6b7ZUQoHXr1i+99BIAsGowAKjV6kmTJun1+nfffdd4Q0UsEv90rHe+oKBAmpnRWYVizpw5DtatQe/k5CAIzg4OABA7YsRPTz7505NPjjFOaOnkZOFu7DLv6NixYw8fPty3b9/s7OwhQ4bExcW9/vrr5eXlEyZMsOuiXC0hhADw1ltvOTk5/frrr9nZ2QAQHR2dlZXVu3fvefPmiV6WxD+dcZEsCcpNSko6fPiwv78/G/BoDV9fqGlzuTk5eTg7ezg7O7GnfBwcoFMnC3djr8l/O3TosH379qioqKqqqjfffDMxMdHLy+uzzz6zU3GM8fQp5YJnxo8L3twGtp+77747IiJCq9XGxcWtWbNm1apV7u7uq1evZg8Zi8vY0hZrNn7zpDyNxsbGAsDMmTOt/73JZPDQQ/Vf8WQyGDTI0t1YWbwF5HL5ihUrFi5cKAiCl5dX586d77zzTvsVB5yuhC4uLp6enhqNRpqPKcMa3itWrHjllVcAYOnSpffUe3tADFyqFfYudM+ePSkpKa1bt2a/QOsNHAhduyY+/3xXHx/2jdhRo8b37AlPPw01Q+Rvyb7T4J8+fZrNHl1RUXHw4MEPPvjArsVxCSHwqJH26NFj+PDhFRUV165de/zxx239JJkl5cJVtf6C9qvLsEUmFAqFcZCqlQQBnnzS6dlnhU6dwNMT7rjDoXdvWXQ0BAdbvg87rsp04cKFUaNG5efnh4WFRUdHjx8/fsGCBYGBgc8//7ydSjT9EwqCUFhYaDAY7L0WHwD4+vpmZmYWFBQEN+ZXb4tjx45lZma6ublptdq3337brmU1vyvhsWPHNmzY4O7uPn36dHH22LnzjQVGGs9eH9D8/PyRI0dmZ2eHhoauW7du7NixX331FSK+/PLLW7dutVOhxr+co6Ojt7e3Xq8vttua1MeOHWOdLiDtx1Sn03344Yd9+vTJzMx0dnbWarUvv/xyaWmp/UqU8qer1apnY+JEL6Wqqqpfv35Tp071qalD8mWXEKrV6tGjR6enp/fs2TMpKYmNuHvllVdmzJih1WojIiJOnz5tj3JN6zD2++gYDIbFixf37dt37ty569evBwA2Xpw9ZW9X58+fHzZs2Lx583Q6XVRUVEZGRq9evU6fPs2mM7RToVyuhC4uLl5eXiK2tDUaDRsjCgB9+/YNDw9nfWZNgjV9lGaVl5cPGjQIALp06VJrHKler2ePwwQGBoo8CyUi1ox7CggIQEQ2z5/o456Mj7Sy53dKS0uPHz9+9913BwQEtGrVyq6PYxtneQgICNi6dSv75tmzZ9kz8ktsW//EDNaZ9tZbb9lp/6ZSU1OhZiEkNp352bNnRdlzWVmZ6XPeHTt2lGwq5FsSOYTXr19nD1UEBARkZ2fXfUF5efmDDz4IAKsjI7HOLEA2Ki8vBwBXV1dEfPvtt8eMGSPKdEZGpo+0/v333zqdLjY2lt3gNg7qbdWq1bvvvmt+FHtjXbly5bHHHmP7j4iIqJXzv/76iz34s337dhELNfrhhx9AqrmD2ZpqQUFBiMiGwoo1Z1dLCaFOp2Mjp9u3b29mxuvLly9vGjcOBQGfeaZRT3xYgo17EusBU6Naj7QWFhaeP3++1iOtdpnoFvGPP/4wzvLQ0Poks2bNYqcGezyEnpSUBACjR48Wfc91sTXVPD09EZGdd/78809R9lxWVubu7j6ihlwub4Yh1Ov1zz33HAD4+PjcemrXEyfQ2xsBcM4csQ6guLiYTbXg5uY2ZcoUEYf5b9iwgQ2ZNz6/Y3yk9c477/zn5gcj6z6OffDgQevKVavVxhl1R44caWbqXq1Wy84IQ4YMEX0NEzbwsHfv3uLutiFsVGNFRQVbSWrlypWi7Lb5XwkNBsPUqVMBwMvLy9Ia4H//Va/j/vXXNpa+b9++F1980TiTHwuAi4tLVFSUjS0K0wUthg8fnpOTk5eXZ8kjrTZOdIuIW7ZsYbNUuLq6qlSqW35irly5wqYte+eddxpV0C1lZWUZW9oSYD9FTk5OTEwMNGaSDvOafwjfeecd9nFp3HO0331XvUbHpk1WFFpVVZWQkDBixAgWCZlMNmLEiISEBHYtMp3o1rpVIuouaNHYR1qtm+i2srIyJiaGdW/269fP8imGdu/e7ezsLAjCH3/8YeFbLGHa0pYAm7jt4MGDbJDjjBkzRNltRUWF6bPzEiyCbTkRQsgGHzg5Of1jxYwVs2dXryB39Ggj3nX+/Kfz5xs7edq0aTNr1qxardDMzMxaE91avu6x6SyaISEhR48erbvWguUH26iJbo8dO8bmC7VujSf2wfX09LRw5k8L2amlXa+1a9euXr26sLAwPj4eACZNmiRBoXzZGsLly5ezGmBCQoI17zcYcOLE6nmfLFnGcedOjIhAR8f3hg4FgAceeGDFihVmFrK2YqLbugta1F1rwYof9JYT3Zrea+3WrZt1E3sZDAZ2b2zmzJlWvL0hbIJqe8yHYMb777/PWt11pxFoZhodQtNpP7KyslJSUnx8fL41LrVrhcpKDA3Fbt3w/PkGX3PtGi5dil26VK/N5OJy6bXXbjmpppFarVapVMbh4w1NdGswGFasWMHO+oGBgTt27Ki71oK1P2Q1NrmgcbC1n5+fUqksLi4+d+4cmxfH9ukD1Wr1F198kZeXZ+yJLS0ttWXeJ0Ts06cPAOzduxcRz507N2XKFLvO/mJc0ML4fEPfvn3XrVsnzfSH0mt0CIODg411pHHjxh06dEiE+bYKCpD1feXk4LJluHAhGpdZPnUKFQp0d6+OX/v2qFSiVXMZ3nKiW71ezzrijRNL11prwdYfs4ZOp/v555+NE906OjqyFqCXl9e///4rShFxcXHG7vutW7e++OKLtuztkUceAQDW3Jg2bRrcvIaxuExXHV+wYMHSpUuNs7kEBwerVCr7zczAiwghFO1YTp3Cnj3x999xyxYcPRq//RZ//rk6e4KAYWH4559WTOpYC1tWqVu3buzvWmui28zMzKSkpLprLdj6ozXAeKPVeL4Xa8/ihvDRRx8FgNdee02v1ze0hrHtGlp1vKqqKj4+vnPNCOkOHTqoVCozbZDbjjUhXLJkydKlS5cuXRoSEiJmCKdMubE2bVERBgbitWvYrh1GRaHVa0o2wMxEt3UHpolbtCk2F85zzz3Hpg/v3LmzWHuOi4t77LHHFi9evHjx4mnTptkSwj/++MPZ2ZmN6jQ2ZfPz85VKJRs/BDcv8Wed48ePm1/QQq/XJyQkdO/enZXo4+OjVCrtt0SMlKwJYWJiYlJSUlJSUmhoqJghHDAATe9wduuGRUW2X/rM27hxo3FeFjc3t1GjRrFe+Pbt22/YsMGuRSPismXLAGD69OlFRUUA4O3tLdae4+LioqKikpOTk5OTFy1aZHUIVSoVqyoPHz68U818Df7+/p9//nlpaSlb4s+0usjWMG5UEXq93vIFLQwGQ2JiYmhoKCvRw8NDoVDYbwViaTSl6uiYMWi6unWHDo1eDNlahw4dYsNcWEcCG5gmQbm//PILADz99NMGg8HJyUkQBLFanrZXRw0GA+v+FQSBTWDJqg9s6C+rPsTExBQWFtpSXaw7+s/Cw5N4zRa7akohXLYM33yzejs5GR95RLQ9W2bdunWsEShZiVu2bAGAYcOGISK7eSvW4E8bQ3j9+nU2CNHZ2fnnn3+u9b+mo2Td3d0VCkVOTk6t6qIlS/yZGf1noSNHjtQaJLh///6CgoLfTFYKWL58uRV7llKjQ5iSkmLsZzty5EhJSYlox6LR4Kuv4tCh+OijOHIk1vcQhl1duXKF3aqRrMRjx44BwH333YeIISEhAHDEtC5ggwsXLuTk5LDta9euNarvvqSkZOTIkQDg6elpZnL4uteiU6dOWVhdzMvLYwvpgBgLWqSnp0+ZMoX1ZwiCsGzZskdMzuBsSu+mTPznCW2l04n+iJOFtFqtTCZzcHCQrD/q8uXLAODn54eIbDJIW9avFsWlS5fYDZJ27dqZzi/ckGPHjtUaJMi6E7du3RoWFma8iWLar2CnBS3YwIzAwMD9+/dTCG9jrE1YYPGq1DbSarVsiWa9Xv/MM88AQN26n5ROnDgREBAAAPfee2+9j4M2hA0SrNtvwaqLxjHltoz+s5BWqz1x4oSPj09YDcmGnluNQngTNpbl5MmTkpXI7vIXFhZGR0cDQFxcnGRF15KamsqG4/bv39+601BeXp5SqWSrmgHAAw88EB8fr9frWftFlNF/ljhx4gRdCW9jbGIOOz2iXq/dERGnBw0qT08vWrxY06GD1uJV6cW1du1aNth9/PjxlbY1B9ggQVbhZC3e77//fu7cucZeeHEHl9d124XQ7tMB3l6kn0E09PLlLikpbvn5d7i7O2VnO16+LE250dHRBoOBbS9atEgQBJlMFh0dnZCQYHz0xDpeXl5vvPFGRkZGXFxcQEBAWlralClTPvzwQ0EQ5s2bt3v3buO63HYiCIKTyazY9piYXFwUwptIOdFttbZtAQAKCsDXt3pDEsnJycYQ7t69u2PHjocPH/7iiy/EmqbVzc1NoVBkZGT88MMPbEx8UlLSggUL2C0cu+rWrdtff/1l/PLMmTP2LtFGFMKbSH8lvBFC4wYnXbp0EX2fTk5OL7zwArvZYxw6T2qx+2np9sIzhIMHV29IZfTo0ayX7+jRo3YtqG3btunp6QUFBcZx88QUhfAmLepKmJyczCqHtR7mEB2H3+pthaqjN+EZwtatwcEBiopAp5OudElQCM2jEN5EyoUNjUUCABQUgEwGrVsDIly9KkGxDzzwgHGV9q5du7KlCuyEw2/1tkLV0ZvwvBICgK8vFBRAQQH4+dm72ISEBOM2Wy7TfuhKaB5dCW9iXFMNpVp2tzqEWVnwwQdQXg7OznD8uERFS4VCaB5dCW/i5OTUqlWr4uLi4uJi42Pj9rVnD7zwAri4QEUFPP00uLnB+fPw779QM59qM0AhNI9CWFvbtm2Li4sLCgqkCOGRI3D6NLRpA2vXgrs76PWg18MTT8C+fdCxY6NWe23KOAyBuK1QdbQ2SU/b27aBVgsbN0L//hARAc8+C126wPbtoNXCf/9JcQCSoCuheRTC2mbOnPn9998HBQXZvSSNBsrKAAAuXICamUjhvvvg/HkAgLw8ux+AVHx8fKRuad9WKIQ3GTx48Pjx4ydPntyuXbvJkydnZmbasTCdDlgnASLU9BaAo2N1P6HBAM3lI8ta2jqdzn6rl9/WKIQ3ycnJMW5fvnxZo9HYsTBXV2Cjpb29bwyUyc2t7p/w9LyRzNsfdRWaQSGsLatGZWWlfUsSBOjVCxwd4eGH4a+/IC0Njh6FTZtg8GBwcoKaSc2aB2oWmkF3R29iMBg+/vhjtm3fuigzbBikp0NwMHh7Q2YmyGQwYQLccQe0bg01cyU1DxRCMyiEN5HJZCtXrmTbo0ePtnt5Li4QFQVr14IgAFuvRq+HLl1g7FhwcLB76RKiXgozKIS8ubnBpEmgVsPlyyAIcNdd4OHB+5jER1dCMyiEN4mMjDRuP/bYYxINmgGAVq2gZhHFZqlbt25Dhw719/fnfSBNkUBdN8Te1q5d27NnT7aUxa5duwRBGDBgAO+DakLo7iixu6SkpKysLLa9b9++/fv3cz2cJodCSAhn1CYkUoiJiWGzm+fk5Lz66qu8D6dpoRASKXz66afDhw8HgKVLl/I+liaHqqOEcEZXQmJ3Hh4eximxXV1dxZpfuNmgLgpCOKNzEiGcUQgJ4YxCSAhnFEJCOKMQEsIZhZAQziiEhHBGISSEMwohIZxRCAnhjEJICGcUQkI4oxASwhmFkBDOKISEcEYhJIQzCiEhnFEICeGMQkgIZxRCQjijEBLCGYWQEM4ohIRwRiEkhDMKISGcUQgJ4YxCSAhnFEJCOKMQEsIZhZAQziiEhHBGISSEMwohIZxRCAnhjEJICGcUQkI4oxASwhmFkBDOKISEcEYhJIQzCiEhnFEICeGMQkgIZxRCQjijEBLCGYWQEM4ohIRwRiEkhDMKISGcUQgJ4YxCSAhnFEJCOKMQEsIZhZAQziiEhHBGISSEMwohIZxRCAnhjEJICGcUQkI4oxASwhmFkBDOKISEcEYhJIQzCiEhnFEICeGMQkgIZxRCQjijEBLCGYWQEM4ohIRwRiEkhDMKISGcUQgJ4YxCSAhnFEJCOKMQEsIZhZAQziiEhHBGISSEMwohIZxRCAnhjEJICGcUQkI4oxASwhmFkBDOKISEcEYhJIQzCiEhnFEICeGMQkgIZxRCQjijEBLCGYWQEM4ohIRw9v9oIfGLnSHnwAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rdkit.Chem import Draw\n",
    "\n",
    "img = Draw.MolToImage(mol, highlightAtoms=node.tolist())\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "pred_max_index = pred.detach().cpu().numpy().argmax()\n",
    "# 이미지에 텍스트 추가 (예측 결과와 실제 레이블)\n",
    "draw = ImageDraw.Draw(img)\n",
    "text = f\"Pred: {pred_max_index}, Label: {data.y.item()}\"\n",
    "draw.text((10, 10), text, fill=\"black\")\n",
    "\n",
    "# save_path = os.path.join(save_dir, f\"molecule_3mr.png\")\n",
    "# img.save(save_path)  # 파일 이름을 분자의 인덱스에 따라 지정\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9838013-4840-475b-a99d-15652855531f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1198e4-b849-4e2b-b3e8-4ca3a7145dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
